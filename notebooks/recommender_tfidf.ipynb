{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import namedtuple\n",
    "\n",
    "import nbimporter\n",
    "from preprocessed_data_reader import ReaderPreprocessedData\n",
    "from utils_os import UtilsOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    WordInfo = namedtuple('WordInfo', 'word perc_sim idf')\n",
    "    SimData = namedtuple('SimData', 'index similarity words_importance_list')\n",
    "    \n",
    "    def recommend_articles(self, article, how_many=-1):\n",
    "        raise NotImplementedException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender based on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderTFIDF(Recommender):\n",
    "    def _cosine_similarity_on_tfidf_vectors(self, tfidf_1, tfidf_2, on=\"tfidf\"):\n",
    "        admissible_on = [\"tfidf\", \"logtfidf\"]\n",
    "        if on not in admissible_on:\n",
    "            raise ValueError(\"on must be one of {0}\".format(admissible_on))\n",
    "\n",
    "        try:\n",
    "            a = tfidf_1.loc[list(tfidf_2.index)].dropna()\n",
    "            b = tfidf_2.loc[list(tfidf_1.index)].dropna()\n",
    "            prod = np.multiply(a[on].values, b[on].values) \n",
    "            norm_1 = np.linalg.norm(tfidf_1[on].values)\n",
    "            norm_2 = np.linalg.norm(tfidf_2[on].values)\n",
    "            cosine_similarity = np.sum(prod) / (norm_1 * norm_2) # default is norm 2\n",
    "            keys = a.index.values # same as b.index.values\n",
    "            perc_in_similarity = prod / sum(prod)\n",
    "            idf_of_word = a[\"idf\"]# values are a tuple(perc_in_similarity, idf_of_word)\n",
    "            words_importance_list = list(zip(keys, perc_in_similarity, idf_of_word)) # [(word, perc_in_similarity, idf_of_word), ...]\n",
    "            words_importance_list = [Recommender.WordInfo(*t) for t in words_importance_list] # [WordInfo, ...]\n",
    "            return cosine_similarity, words_importance_list\n",
    "        except: # e.g. the case where no index overlaps\n",
    "            return 0, []\n",
    "        \n",
    "    def _order_dataset_by_similarity(self, reference_article):\n",
    "        similarities = []\n",
    "        for i, article in enumerate(self._dataset):\n",
    "            cos_sim, words_importance_list = self._cosine_similarity_on_tfidf_vectors(reference_article[\"tfidf\"], article[\"tfidf\"], on=\"logtfidf\")\n",
    "            words_importance_list = sorted(words_importance_list, key=lambda t:t.perc_sim, reverse=True) # sort by word importance\n",
    "            similarities.append(Recommender.SimData(i, cos_sim, words_importance_list)) # similarities = [SimData, ...]\n",
    "        similarities = sorted(similarities, key=lambda t:t.similarity, reverse=True) # sort by article similarity\n",
    "        return similarities\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self._dataset = dataset\n",
    "        \n",
    "    def recommend_articles(self, article, how_many=-1):\n",
    "        similarities = self._order_dataset_by_similarity(article)\n",
    "        if how_many != -1:\n",
    "            return similarities[:how_many]\n",
    "        return similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
