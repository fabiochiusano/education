{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hidden(l):\n",
    "    return [el for el in l if el[0] != \".\"]\n",
    "\n",
    "def get_relative_path_to_files(start_path):\n",
    "    files = [f for f in listdir(start_path) if isfile(join(start_path, f))]\n",
    "    files = remove_hidden(files)\n",
    "    files = [start_path + \"/\" + file for file in files]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "onlyfiles = get_relative_path_to_files(\"../preprocessed\")\n",
    "read_json_list = []\n",
    "for file in onlyfiles:\n",
    "    with open(file, 'r') as infile:\n",
    "        d = json.load(infile)\n",
    "        d[\"tfidf\"] = pd.DataFrame(d[\"tfidf\"])\n",
    "        dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read stem_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stemmer/stem_dictionary.json', 'r') as infile:\n",
    "    stem_dictionary = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute similarity between two articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_cosine_similarity_on_articles(article_1, article_2):\n",
    "    d = {}\n",
    "    try:\n",
    "        w1 = article_1[\"tfidf\"].loc[list(article_2[\"tfidf\"].index)].dropna()\n",
    "        w2 = article_2[\"tfidf\"].loc[list(article_1[\"tfidf\"].index)].dropna()\n",
    "        norm_1 = 0\n",
    "        norm_2 = 0\n",
    "        for i,row in article_1[\"tfidf\"].iterrows():\n",
    "            norm_1 += row[\"logtfidf\"] * row[\"logtfidf\"]\n",
    "        for i,row in article_2[\"tfidf\"].iterrows():\n",
    "            norm_2 += row[\"logtfidf\"] * row[\"logtfidf\"]\n",
    "        cosine_similarity = 0\n",
    "        for i,row in w1.iterrows():\n",
    "            v1 = row[\"logtfidf\"]\n",
    "            v2 = w2.loc[i][\"logtfidf\"]\n",
    "            delta = (v1 * v2) / (math.sqrt(norm_1) * math.sqrt(norm_2))\n",
    "            cosine_similarity += delta\n",
    "            d[i] = delta\n",
    "        for k in d.keys():\n",
    "            d[k] = d[k] / cosine_similarity\n",
    "        return cosine_similarity, d\n",
    "    except: # e.g. the case where no index overlaps\n",
    "        return 0, d\n",
    "\n",
    "def cosine_similarity_on_articles(article_1, article_2):\n",
    "    d = {}\n",
    "    try:\n",
    "        a = article_1[\"tfidf\"].loc[list(article_2[\"tfidf\"].index)].dropna()\n",
    "        b = article_2[\"tfidf\"].loc[list(article_1[\"tfidf\"].index)].dropna()\n",
    "        prod = np.multiply(a[\"logtfidf\"].values, b[\"logtfidf\"].values) \n",
    "        norm_1 = np.linalg.norm(article_1[\"tfidf\"][\"logtfidf\"].values)\n",
    "        norm_2 = np.linalg.norm(article_2[\"tfidf\"][\"logtfidf\"].values)\n",
    "        cosine_similarity = np.sum(prod) / (norm_1 * norm_2) # default is norm 2\n",
    "        keys = a.index.values\n",
    "        values = list(zip(prod / sum(prod), a[\"idf\"])) # values are a tuple(perc_in_similarity, idf_of_word)\n",
    "        d = dict(zip(keys, values))\n",
    "        return cosine_similarity, d\n",
    "    except: # e.g. the case where no index overlaps\n",
    "        return 0, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.5 ms ± 7.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = old_cosine_similarity_on_articles(dataset[100], dataset[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.24 ms ± 194 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = cosine_similarity_on_articles(dataset[100], dataset[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_article(dataset):\n",
    "    random_index = random.randint(0, len(dataset) - 1)\n",
    "    print(\"Random index: {0}\".format(random_index))\n",
    "    return dataset[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_best_unstemmed_word(stem_word, stem_dictionary):\n",
    "    d = stem_dictionary[stem_word]\n",
    "    return max(d, key=d.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recommender(dataset, top_n=5, max_words=10, max_sim_explained=0.9, idf_threshold=1.5):\n",
    "    random_article = get_random_article(dataset)\n",
    "    \n",
    "    print(\"Selected the following article:\")\n",
    "    print(\"\\tTitle: {0}\".format(random_article[\"title\"]))\n",
    "    print(\"\\tURL: {0}\".format(random_article[\"url\"]))\n",
    "    \n",
    "    print(\"Computing most similar articles...\")\n",
    "    print(\"\")\n",
    "    similarities = []\n",
    "    for i,article in enumerate(dataset):\n",
    "        cos_sim, d = cosine_similarity_on_articles(random_article, article)\n",
    "        d = d.items() # convert to list of tuples (key, (perc, idf))\n",
    "        d = sorted(d, key=lambda t:t[1][0], reverse=True) # sort by word importance\n",
    "        similarities.append((i, cos_sim, d)) # similarities = [(i, cos_sim, {\"w\": [(perc, idf), ...], ...})]\n",
    "    similarities = sorted(similarities, key=lambda t:t[1], reverse=True) # sort by article similarity\n",
    "    \n",
    "    print(\"The top {0} similar articles are:\".format(top_n))\n",
    "    for i in range(1, top_n+1):\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Title: {0}\".format(dataset[similarities[i][0]][\"title\"]))\n",
    "        print(\"URL: {0}\".format(dataset[similarities[i][0]][\"url\"]))\n",
    "        print(\"Similarity score: {0:.2f}%\".format(similarities[i][1]))\n",
    "        print(\"Index: {0}\".format(similarities[i][0]))\n",
    "        print(\"Most important words:\")\n",
    "        sim_tot = 0\n",
    "        for j in range(min(max_words, len(similarities[i][2]))):\n",
    "            sw = similarities[i][2][j][0]\n",
    "            w = retrieve_best_unstemmed_word(sw, stem_dictionary)\n",
    "            score = similarities[i][2][j][1][0]\n",
    "            idf_score = similarities[i][2][j][1][1]\n",
    "            if idf_score >= idf_threshold:\n",
    "                print(\"\\t{0}, with percentage {1:.2f}%\".format(w.capitalize(), score))\n",
    "            sim_tot += score\n",
    "            if sim_tot >= max_sim_explained:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random index: 553\n",
      "Selected the following article:\n",
      "\tTitle: Neopets as We Know It Is About to Be Obliterated\n",
      "\tURL: https://medium.com/s/love-hate/neopets-as-we-know-it-is-about-to-be-obliterated-78db2076412c\n",
      "Computing most similar articles...\n",
      "\n",
      "The top 10 similar articles are:\n",
      "--------------------------------\n",
      "Title: How to get HTTPS working on your local development environment in 5 minutes\n",
      "URL: https://medium.freecodecamp.org/how-to-get-https-working-on-your-local-development-environment-in-5-minutes-7af615770eec\n",
      "Similarity score: 0.04%\n",
      "Index: 694\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.97%\n",
      "--------------------------------\n",
      "Title: What I Gave My Kid Instead of a Smartphone\n",
      "URL: https://humanparts.medium.com/what-i-gave-my-kid-instead-of-a-smartphone-27c0f028ea78\n",
      "Similarity score: 0.04%\n",
      "Index: 886\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.46%\n",
      "\tApp, with percentage 0.13%\n",
      "\tSmartphone, with percentage 0.10%\n",
      "\tKids, with percentage 0.07%\n",
      "\tOpt, with percentage 0.02%\n",
      "\tMedia, with percentage 0.01%\n",
      "\tWeird, with percentage 0.01%\n",
      "\tEmail, with percentage 0.01%\n",
      "--------------------------------\n",
      "Title: Google’s Stadia Could Take Video Games Out of Your Hands\n",
      "URL: https://onezero.medium.com/googles-stadia-could-take-video-games-out-of-your-hands-410bfa8f5bf8\n",
      "Similarity score: 0.04%\n",
      "Index: 429\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.28%\n",
      "\tGame, with percentage 0.28%\n",
      "\tUsers, with percentage 0.14%\n",
      "\tGoogle, with percentage 0.07%\n",
      "\tPlatform, with percentage 0.06%\n",
      "\tPreserve, with percentage 0.02%\n",
      "\tPlayer, with percentage 0.01%\n",
      "\tHardware, with percentage 0.01%\n",
      "--------------------------------\n",
      "Title: Your Productivity Hinges on How You Arrange Your Desk\n",
      "URL: https://medium.com/s/story/your-productivity-hinges-on-how-you-arrange-your-desk-6b278f018daf\n",
      "Similarity score: 0.03%\n",
      "Index: 531\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.59%\n",
      "\tDesktop, with percentage 0.15%\n",
      "\tStuff, with percentage 0.06%\n",
      "\tEmail, with percentage 0.04%\n",
      "\tBees, with percentage 0.02%\n",
      "\tLot, with percentage 0.01%\n",
      "\tSarah, with percentage 0.01%\n",
      "--------------------------------\n",
      "Title: The Ideological Turing Test: How to Be Less Wrong\n",
      "URL: https://medium.com/the-polymath-project/the-ideological-turing-test-how-to-be-less-wrong-6803a8c290cf\n",
      "Similarity score: 0.03%\n",
      "Index: 1061\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.52%\n",
      "\tStuff, with percentage 0.16%\n",
      "\tAren, with percentage 0.04%\n",
      "\tEverything, with percentage 0.03%\n",
      "\tOkay, with percentage 0.02%\n",
      "\tFlaw, with percentage 0.01%\n",
      "\tLot, with percentage 0.01%\n",
      "--------------------------------\n",
      "Title: The top mobile apps are all owned by either Google or Facebook\n",
      "URL: https://medium.freecodecamp.com/all-of-2016s-top-mobile-apps-are-owned-by-either-google-or-facebook-a9c56d77a74b\n",
      "Similarity score: 0.03%\n",
      "Index: 341\n",
      "Most important words:\n",
      "\tApp, with percentage 0.44%\n",
      "\tPokémon, with percentage 0.16%\n",
      "\tMobile, with percentage 0.12%\n",
      "\tAren, with percentage 0.06%\n",
      "\tUsers, with percentage 0.05%\n",
      "\tGoogle, with percentage 0.04%\n",
      "\tSmartphone, with percentage 0.04%\n",
      "--------------------------------\n",
      "Title: How to get over ghosting from a VC 👻👻👻\n",
      "URL: https://medium.com/unfiltered-startup-mental-health/how-to-get-over-ghosting-from-a-vc-92176ac998ad\n",
      "Similarity score: 0.03%\n",
      "Index: 607\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.70%\n",
      "\tInteract, with percentage 0.02%\n",
      "\tEmail, with percentage 0.02%\n",
      "\tThink, with percentage 0.02%\n",
      "\tPreserve, with percentage 0.01%\n",
      "\tGame, with percentage 0.01%\n",
      "\tEverything, with percentage 0.01%\n",
      "\tUnderstand, with percentage 0.01%\n",
      "--------------------------------\n",
      "Title: Using Online Video, Customer Analytics and Big Data to Market Online\n",
      "URL: https://www.smartdatacollective.com/online-video-customer-analytics-big-data-market\n",
      "Similarity score: 0.03%\n",
      "Index: 200\n",
      "Most important words:\n",
      "\tEmail, with percentage 0.17%\n",
      "\tIsn, with percentage 0.10%\n",
      "\tPlatform, with percentage 0.07%\n",
      "\tUsers, with percentage 0.06%\n",
      "\tGoogle, with percentage 0.05%\n",
      "\tOnline, with percentage 0.04%\n",
      "\tOwner, with percentage 0.04%\n",
      "\tLongterm, with percentage 0.04%\n",
      "\tContent, with percentage 0.03%\n",
      "--------------------------------\n",
      "Title: Is privacy dead in our digital age of information?\n",
      "URL: https://medium.com/the-public-ear/is-privacy-dead-in-our-digital-age-of-information-5f7c92b84b60\n",
      "Similarity score: 0.03%\n",
      "Index: 947\n",
      "Most important words:\n",
      "\tIsn, with percentage 0.44%\n",
      "\tUsers, with percentage 0.18%\n",
      "\tPlatform, with percentage 0.13%\n",
      "\tApp, with percentage 0.06%\n",
      "\tOnline, with percentage 0.03%\n",
      "\tDigital, with percentage 0.03%\n",
      "\tMedia, with percentage 0.02%\n",
      "--------------------------------\n",
      "Title: User Adoption – Resistance Is Futile, We Hope\n",
      "URL: https://www.smartdatacollective.com/user-adoption-resistance-it-futile-we-hope\n",
      "Similarity score: 0.03%\n",
      "Index: 884\n",
      "Most important words:\n",
      "\tUsers, with percentage 0.61%\n",
      "\tHasn, with percentage 0.11%\n",
      "\tAren, with percentage 0.09%\n",
      "\tLog, with percentage 0.02%\n",
      "\tSuppose, with percentage 0.02%\n",
      "\tGoogle, with percentage 0.01%\n",
      "\tSoftware, with percentage 0.01%\n",
      "\tAnything, with percentage 0.01%\n",
      "\tPush, with percentage 0.01%\n"
     ]
    }
   ],
   "source": [
    "start_recommender(dataset, top_n=10, max_words=10, max_sim_explained=0.9, idf_threshold=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract content headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = [\"h1\", \"h2\", \"h3\"]\n",
    "\n",
    "for d in dataset:\n",
    "    headers = []\n",
    "    soup = BeautifulSoup(d[\"content_html\"])\n",
    "    for h in hs:\n",
    "        headers += [el.text for el in soup.select(h)]\n",
    "    d[\"headers\"] = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average number of headers per article: {0}\".format(sum([len(d[\"headers\"]) for d in dataset]) / len(dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
