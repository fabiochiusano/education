{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster articles according to TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from preprocessed_data_reader.ipynb\n",
      "Importing Jupyter notebook from utils_os.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "import nbimporter\n",
    "from preprocessed_data_reader import ReaderPreprocessedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReaderPreprocessedData.read_data(\"../preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(n_elements_in_batch, l):\n",
    "    return [l[i:i + n_elements_in_batch] for i in range(0, len(l), n_elements_in_batch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.read_csv(\"../resources/wiki-30k-10-IDF.csv\")\n",
    "idf = idf.set_index('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(grouper(100, dataset)):\n",
    "    rows = [np.log(sample[\"tfidf\"][\"logtfidf\"] + 1.000001) for sample in batch]\n",
    "    if i == 0:\n",
    "        res_matrix = csr_matrix(pd.DataFrame(rows, columns=idf.index).fillna(value=0))\n",
    "    else:\n",
    "        delta_matrix = csr_matrix(pd.DataFrame(rows, columns=idf.index).fillna(value=0))\n",
    "        res_matrix = vstack([res_matrix, delta_matrix])\n",
    "    print(\"{0}/{1}\".format(i + 1, len(dataset) // 100 + 1))\n",
    "    \n",
    "res_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD # PCA does not support sparse input\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def to_tsne(x):\n",
    "    \"\"\"From 1024 to 50 with PCA, from 50 to 2 with TSNE\"\"\"\n",
    "    y = TruncatedSVD(n_components=50).fit_transform(x)\n",
    "    y = TSNE(n_components=2).fit_transform(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_tsne(res_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=15).fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "colors = []\n",
    "for r in range(0, 201, 100):\n",
    "    for g in range(0, 201, 100):\n",
    "        for b in range(0, 201, 100):\n",
    "            colors.append(\"rgb({0},{1},{2})\".format(r,g,b))\n",
    "\n",
    "def get_scatter(sv_list, colors, color_index):\n",
    "    return go.Scatter(\n",
    "        x=[i[1][0] for i in sv_list],\n",
    "        y=[i[1][1] for i in sv_list],\n",
    "        mode='markers',\n",
    "        text=[sv[0][\"title\"] for sv in sv_list],\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            opacity= 0.8,\n",
    "            color=colors[color_index],\n",
    "            #colorscale='Viridis',\n",
    "            showscale=False\n",
    "        ),\n",
    "        name=sv_list[0][0][\"url\"].split(\"/\")[2]\n",
    "    )\n",
    "\n",
    "def scatter_plot(dataset, y, colors, kmeans):\n",
    "    \"\"\"Scatter plot of samples by their 2 dimensions\"\"\"\n",
    "    domains = list(set([sample[\"url\"].split(\"/\")[2] for sample in dataset]))\n",
    "    \n",
    "    d = {}\n",
    "    for sample, vector in zip(dataset, y):\n",
    "        domain = sample[\"url\"].split(\"/\")[2]\n",
    "        if domain in d:\n",
    "            d[domain] += [(sample, vector)]\n",
    "        else:\n",
    "            d[domain] = [(sample, vector)]\n",
    "            \n",
    "    data = [get_scatter(sv_list, colors, color_index) for color_index, (_, sv_list) in enumerate(d.items())]\n",
    "    data.append(go.Scatter(\n",
    "        x=[cc[0] for cc in kmeans.cluster_centers_],\n",
    "        y=[cc[1] for cc in kmeans.cluster_centers_],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=40,\n",
    "            opacity= 0.5,\n",
    "            color=\"rgb(0,0,0)\",\n",
    "            showscale=False\n",
    "        ),\n",
    "        name=\"cluster\"\n",
    "    ))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        yaxis = dict(zeroline = False),\n",
    "        xaxis = dict(zeroline = False)\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    file = plot(fig, filename='Sentence encode.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(dataset, y, colors, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign each sample to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sample in enumerate(dataset):\n",
    "    sample[\"cluster-tfidf\"] = kmeans.predict(y[i].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_cluster_to_article_indices = {}\n",
    "for i,sample in enumerate(dataset):\n",
    "    cluster = sample[\"cluster-tfidf\"]\n",
    "    if cluster not in from_cluster_to_article_indices:\n",
    "        from_cluster_to_article_indices[cluster] = [i]\n",
    "    else:\n",
    "        from_cluster_to_article_indices[cluster] += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 241 elements:\n",
      "\tEphemeral Belief?\n",
      "\tThe Paradox of the Preface\n",
      "\tSkepticism, Godzilla, and the Artificial Computerized Many-Branching You\n",
      "\tCan There Be Non-Obvious Illusions?\n",
      "\tDreaming, Belief, and Emotion (by guest blogger Jonathan Ichikawa )\n",
      "--------------\n",
      "Cluster 1 has 209 elements:\n",
      "\tTwitter’s user growth goes nowhere and the stock is collapsing\n",
      "\tUnderstanding The Nuances of Instagram Data Transparency Policies\n",
      "\tTwitter now says 1.4 million people interacted with Russian trolls during 2016 presidential campaign\n",
      "\t5 Ways to Keep Your Information Secure in the Cloud\n",
      "\tJack Dorsey says Twitter is keeping its 140-character limit, but maybe don’t get too excited\n",
      "--------------\n",
      "Cluster 2 has 352 elements:\n",
      "\tWe Should Be Talking About Money With Our Partners — Here’s Where To Start\n",
      "\t5 email myths you can stop believing now\n",
      "\t14 Galentine's Day Gifts To Show Your Friends Some Love\n",
      "\tHow to Sell Gum at School\n",
      "\tNitroolefins – The Crying Game\n",
      "--------------\n",
      "Cluster 3 has 348 elements:\n",
      "\tJuergen Schmidhuber AMA: The Principles of Intelligence and Machine Learning\n",
      "\tWhy so many data scientists are leaving their jobs\n",
      "\tAn Intuitive Guide to Deep Network Architectures\n",
      "\tTop 10 Machine Learning Projects on Github\n",
      "\tCreativity is Crucial in Data Science\n",
      "--------------\n",
      "Cluster 4 has 284 elements:\n",
      "\tHow to Make Christmas Stockings from Sweaters\n",
      "\tHow to Use Ghee\n",
      "\tHow to Get on a Bike\n",
      "\tHow to Read a Psychrometric Chart\n",
      "\tHow to Draw a Viking\n",
      "--------------\n",
      "Cluster 5 has 365 elements:\n",
      "\tZuckerberg refuses UK parliament summons over Fb data misuse\n",
      "\tFacebook Beats Estimates In Q4 With $3.85B Revenue, User Growth Up To 3.2% QOQ To Hit 1.39B\n",
      "\tInstagram Launches 15-Second Video Sharing Feature, With 13 Filters And Editing\n",
      "\tInstagram could start hiding like counts\n",
      "\tThe U.S. prison system isn't transparent. This nonprofit uses data to expose the truth.\n",
      "--------------\n",
      "Cluster 6 has 231 elements:\n",
      "\tCtrl-Alt-Delete: The Planned Obsolescence of Old Coders\n",
      "\tLet’s Encrypt free HTTPS certification push exits beta\n",
      "\tEmployee Retention - Role of Motivation\n",
      "\tCurrent Affairs February 2019 - Reports\n",
      "\tThis cyberstalker's takedown proves no one stays anonymous on the web\n",
      "--------------\n",
      "Cluster 7 has 198 elements:\n",
      "\tNode.js - NPM\n",
      "\tCurrent Affairs March 2016\n",
      "\tHadoop - Enviornment Setup\n",
      "\tC - Environment Setup\n",
      "\tJavaScript - Syntax\n",
      "--------------\n",
      "Cluster 8 has 340 elements:\n",
      "\tGoogle brings its ARCore technology to China in partnership with Xiaomi\n",
      "\tGoogle Home teams up with UK retailer for voice shopping service\n",
      "\tSorry iPhone X owners, but Pixel takes way better Aurora photos\n",
      "\tI did a half marathon with an AI trainer and ran into its limits\n",
      "\tLocation-Sharing App Highlight Gets Biggest Update Since Launch\n",
      "--------------\n",
      "Cluster 9 has 305 elements:\n",
      "\tBath & Body Works Dropped A Fresh Spring Scent — & It's An Instant Classic\n",
      "\t9 Braided Styles For When You Want To Hit Snooze On Doing Your Hair\n",
      "\tThe International Hair Trends You Won't See On Instagram\n",
      "\t\"Blotox\" For Hair Might Just Make You Toss Your Dry Shampoo\n",
      "\tRefinery29 Readers Confess Their Amazon Hidden Gems\n",
      "--------------\n",
      "Cluster 10 has 413 elements:\n",
      "\tHow Big Data Is Driving Airline Loyalty Programs\n",
      "\t5 Innovative and Diverse Uses of Big Data\n",
      "\tNew Generation of Big Data Security Risks Raises Questions About VPNs\n",
      "\tBringing Big Data Operational Analytics into the 21st Century\n",
      "\tValue Your Customer Data as a Business Asset\n",
      "--------------\n",
      "Cluster 11 has 227 elements:\n",
      "\tSAP NetWeaver Tutorial\n",
      "\t10 Netstat Command Examples on Linux\n",
      "\tHow to Set Up SFML in a Project on Visual Studio 2017\n",
      "\tLinux Firewall Open and Deny Port Commands\n",
      "\tHow to Edit the wikiHow Site Notice\n",
      "--------------\n",
      "Cluster 12 has 217 elements:\n",
      "\tThe Laughter of Ethicists\n",
      "\tCitation Patterns in the Stanford Encyclopedia of Philosophy, Part 1\n",
      "\tOn Debunking V: The Final Chapter\n",
      "\tPossible Backfire Effects of an Excellent Diversity Statement?\n",
      "\tThe Problem of the Ethics Professors\n",
      "--------------\n",
      "Cluster 13 has 335 elements:\n",
      "\tCartoon: the distance between Espresso and Cappuccino\n",
      "\tWhat Has Pokemon Got To Do With Big Data?\n",
      "\tBig Data Innovators Under 35\n",
      "\tSpringboard: Data Science Job, Guaranteed\n",
      "\tHow Data Science Predicts and Reduces Adverse Birth Outcomes\n",
      "--------------\n",
      "Cluster 14 has 378 elements:\n",
      "\tJapan’s Many Socioeconomic Issues\n",
      "\tIs Everything One Big Bubble?\n",
      "\tWhy Did This Have To Happen To Sansa Stark?\n",
      "\tHow Captain America's Final Avengers: Endgame Scene Happened\n",
      "\t18 of the best books written by women in 2018\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for cluster, articles in from_cluster_to_article_indices.items():\n",
    "    random_articles = np.random.choice(articles, size=5, replace=True)\n",
    "    print(\"Cluster {0} has {1} elements:\".format(cluster, len(articles)))\n",
    "    for art_ind in random_articles:\n",
    "        sample = dataset[art_ind]\n",
    "        print(\"\\t{0}\".format(sample[\"title\"]))\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
