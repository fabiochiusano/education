{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from scraper_config_reader.ipynb\n",
      "Importing Jupyter notebook from scraper_requests.ipynb\n",
      "Importing Jupyter notebook from scraper_data_reader.ipynb\n",
      "Importing Jupyter notebook from utils_os.ipynb\n",
      "Importing Jupyter notebook from model_article_url_discriminator.ipynb\n",
      "Importing Jupyter notebook from utils_soup.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "\n",
    "from scraper_config_reader import ScraperConfigReader\n",
    "from scraper_requests import ScraperRequests\n",
    "from scraper_data_reader import ReaderScrapedData\n",
    "from model_article_url_discriminator import URLCleaner\n",
    "from utils_soup import UtilsSoup\n",
    "from utils_os import UtilsOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    \"\"\"\"\"\"\n",
    "    _extensions_banned = [\".jpg\", \".png\", \".zip\", \".xml\"]\n",
    "    \n",
    "    def _manage_article_directory(self, directory, start_from_zero):\n",
    "        exists_directory = UtilsOS.directory_exists(directory)\n",
    "        if start_from_zero and exists_directory:\n",
    "            UtilsOS.directory_remove(directory)\n",
    "        UtilsOS.directory_maybe_create(directory)\n",
    "    \n",
    "    def _check_link_extension(self, link):\n",
    "        for extension in self._extensions_banned:\n",
    "            if link[-len(extension):] == extension:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _normalize_url(self, url):\n",
    "        url = url.split(\"?\")[0]\n",
    "        url = url.split(\"#\")[0]\n",
    "        url = url.split(\"&\")[0]\n",
    "        url = url.split(\"@\")[0]\n",
    "        if url[-1] == \"/\":\n",
    "            url = url[:-1]\n",
    "        return url\n",
    "            \n",
    "    def _clean_links(self, website, links, prefix_url):\n",
    "        links = [prefix_url + link if len(link) > 0 and link[0] == \"/\" else link for link in links] # fix \"/index.html\"\n",
    "        links = [prefix_url + \"/\" + link if \"//\" not in link else link for link in links] # fix \"index.html\"\n",
    "        links = [self._normalize_url(link) for link in links] # remove http parameters (after ?)\n",
    "        links = list(set(links)) # remove duplicates\n",
    "        return links\n",
    "    \n",
    "    def _get_random_url_by_domain(self, data):\n",
    "        # return one url for each domain\n",
    "        res = [] # res = []\n",
    "        domain_urls = [data[dom] for dom in data.keys()]\n",
    "        for urls in domain_urls:\n",
    "            res.append(random.choice(urls)[\"url\"])\n",
    "        return res\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def scrape_website_incremental(self, website, config, max_scraped=-1, max_tries=-1, start_from_zero=False):\n",
    "        \"\"\"Incremental scraping of a website, according to a site configuration\"\"\"\n",
    "        directory = \"../articles/\" + website\n",
    "\n",
    "        # eventually clean \"article\" directory\n",
    "        self._manage_article_directory(directory, start_from_zero)\n",
    "\n",
    "        # create request handler and url cleaner\n",
    "        scraper_requests = ScraperRequests()\n",
    "        url_cleaner = URLCleaner()\n",
    "\n",
    "        # parse already scraped data\n",
    "        scraped_data = ReaderScrapedData.read_data_of_website(website)\n",
    "        titles = set(ReaderScrapedData.get_titles(scraped_data))\n",
    "        urls_by_domain = self._get_random_url_by_domain(scraped_data) # get one url for each domain of the selected website\n",
    "        urls = ReaderScrapedData.get_urls(scraped_data)\n",
    "        urls_not_articles_filename = \"url_not_article.json\"\n",
    "        if not UtilsOS.file_exists(urls_not_articles_filename):\n",
    "            UtilsOS.write_to_json([], urls_not_articles_filename)\n",
    "        url_not_article = UtilsOS.read_json(urls_not_articles_filename) # list of strings\n",
    "            \n",
    "\n",
    "        # decides from which url we start scraping\n",
    "        first_url = config[ScraperConfigReader.first_url_key][0]\n",
    "        if len(urls_by_domain) > 0:\n",
    "            queue = urls_by_domain\n",
    "        else:\n",
    "            queue = [first_url]\n",
    "\n",
    "        # extract prefix url\n",
    "        prefix_url = \"/\".join(first_url.split(\"/\")[:3])\n",
    "\n",
    "        # create the url black list\n",
    "        already_considered = set(urls)\n",
    "        already_considered.add(first_url)\n",
    "\n",
    "        counter = 0\n",
    "        counter_added = 0\n",
    "        counter_delta_incremental = len(urls)\n",
    "\n",
    "        while len(queue) > 0:\n",
    "            # get url to visit\n",
    "            url = queue.pop(0)\n",
    "            \n",
    "            # if we already know that this link does not correspond to an article, we don't visit it\n",
    "            if url in url_not_article:\n",
    "                continue\n",
    "            \n",
    "            print(\"Visiting \" + url)\n",
    "            print(\"URLs in queue: {0}\".format(len(queue)))\n",
    "\n",
    "            # visit url\n",
    "            try:\n",
    "                # make request\n",
    "                response = scraper_requests.make_get(url)\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # get all outer links from url\n",
    "                links = soup.find_all(\"a\")\n",
    "                links = [tag[\"href\"] for tag in links if tag.has_attr(\"href\")]\n",
    "\n",
    "                # clean links\n",
    "                links = self._clean_links(website, links, prefix_url)\n",
    "                links = url_cleaner.filter_urls(links, website)\n",
    "\n",
    "                # add links to queue if not already considered\n",
    "                for link in links:\n",
    "                    if link not in already_considered:\n",
    "                        already_considered.add(link)\n",
    "                        queue.append(link)\n",
    "\n",
    "                # fill data\n",
    "                data = {\"url\": url, \"html\": str(soup)}\n",
    "                data[\"title_html\"], data[\"title\"] = UtilsSoup.get_with_selector(config[ScraperConfigReader.title_selector_key], soup)\n",
    "                data[\"content_html\"], data[\"content\"] = UtilsSoup.get_with_selector(config[ScraperConfigReader.content_selector_key], soup)\n",
    "\n",
    "                # eventually save article\n",
    "                if data[\"title\"] != \"\" and data[\"content\"] != \"\": # we save only if we got the necessary info\n",
    "                    if data[\"title\"] not in titles:\n",
    "                        titles.add(data[\"title\"])\n",
    "                        counter_added += 1\n",
    "                        print(\"{0} - Extracted article: \".format(counter_delta_incremental + counter_added) + data[\"title\"])\n",
    "\n",
    "                        # eventually create domain directory\n",
    "                        sub_directory = directory + \"/\" + url.split(\"/\")[2]\n",
    "                        UtilsOS.directory_maybe_create(sub_directory)\n",
    "\n",
    "                        # write to file\n",
    "                        UtilsOS.write_to_json(data, sub_directory + \"/\" + str(counter_delta_incremental + counter_added) + '.json')\n",
    "\n",
    "                        # eventually end scraping\n",
    "                        if counter_added == max_scraped:\n",
    "                            break\n",
    "                    else:\n",
    "                        print(\"Article already extracted: {0}\".format(data[\"title\"]))\n",
    "                else:\n",
    "                    url_not_article.append(data[\"url\"])\n",
    "                    UtilsOS.write_to_json(url_not_article, \"url_not_article.json\")\n",
    "                    \n",
    "                counter += 1\n",
    "                if counter == max_tries:\n",
    "                    break\n",
    "                \n",
    "                # sleep...\n",
    "                time.sleep(0.2)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"------------\")\n",
    "                time.sleep(1) # time to escape by KeywordInterrupt\n",
    "                continue\n",
    "\n",
    "            print(\"------------\")\n",
    "            \n",
    "    def incremental_scraping_from_configs(self, configs, max_scraped=10, max_tries=30):\n",
    "        items = list(configs.items())\n",
    "        random.shuffle(items)\n",
    "        while True:\n",
    "            for website,conf in items:\n",
    "                self.scrape_website_incremental(website, conf, max_scraped=max_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting https://medium.com\n",
      "URLs in queue: 0\n",
      "------------\n",
      "Visiting https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e\n",
      "URLs in queue: 16\n",
      "1 - Extracted article: Work at Medium  \n",
      "------------\n",
      "Visiting https://about.medium.com\n",
      "URLs in queue: 24\n",
      "------------\n",
      "Visiting https://medium.com/s/story/done-with-the-ding-e8331d66b64e\n",
      "URLs in queue: 33\n",
      "2 - Extracted article: How to Silence the Persistent Ding of Modern Life  \n",
      "------------\n",
      "Visiting https://medium.com/3minread\n",
      "URLs in queue: 34\n",
      "------------\n",
      "Visiting https://medium.com/elemental-by-medium\n",
      "URLs in queue: 52\n",
      "------------\n",
      "Visiting https://help.medium.com\n",
      "URLs in queue: 62\n",
      "------------\n",
      "Visiting https://humanparts.medium.com/riding-in-cars-with-black-boys-1b850402a7e9\n",
      "URLs in queue: 61\n",
      "3 - Extracted article: Riding in Cars With Black Boys  \n",
      "------------\n",
      "Visiting https://medium.com/creators\n",
      "URLs in queue: 68\n",
      "------------\n",
      "Visiting https://medium.com/human-parts\n",
      "URLs in queue: 75\n",
      "------------\n",
      "Visiting https://medium.com/one-zero\n",
      "URLs in queue: 85\n",
      "------------\n",
      "Visiting https://humanparts.medium.com\n",
      "URLs in queue: 102\n",
      "------------\n",
      "Visiting https://humanparts.medium.com/the-palliative-environmentalist-8a3a3fe77a72\n",
      "URLs in queue: 101\n",
      "4 - Extracted article: A Palliative Approach to the End of the World  \n",
      "------------\n",
      "Visiting https://medium.statuspage.io\n",
      "URLs in queue: 102\n",
      "------------\n",
      "Visiting https://medium.com/membership\n",
      "URLs in queue: 107\n",
      "------------\n",
      "Visiting https://elemental.medium.com\n",
      "URLs in queue: 131\n",
      "------------\n",
      "Visiting https://medium.com/s/story/bonfyre-of-the-vanities-ac2e4778e0fa\n",
      "URLs in queue: 130\n",
      "5 - Extracted article: Invasion of the Influencers  \n",
      "------------\n",
      "Visiting https://elemental.medium.com/is-it-a-bad-idea-to-multitask-at-the-gym-1dd5593586f3\n",
      "URLs in queue: 131\n",
      "6 - Extracted article: Is It a Bad Idea to Multitask at the Gym?  \n",
      "------------\n",
      "Visiting https://medium.com/p/959d1a85284e/share/facebook\n",
      "URLs in queue: 132\n",
      "------------\n",
      "Visiting https://medium.design\n",
      "URLs in queue: 153\n",
      "------------\n",
      "Visiting https://blog.medium.com\n",
      "URLs in queue: 169\n",
      "------------\n",
      "Visiting https://medium.com/p/959d1a85284e/share/twitter\n",
      "URLs in queue: 168\n",
      "------------\n",
      "Visiting https://jobs.lever.co/medium\n",
      "URLs in queue: 169\n",
      "------------\n",
      "Visiting https://medium.engineering\n",
      "URLs in queue: 207\n",
      "------------\n",
      "Visiting https://www.keyvalues.com/medium\n",
      "URLs in queue: 222\n",
      "------------\n",
      "Visiting https://blog.medium.com/words-still-matter-6e9163216052\n",
      "URLs in queue: 229\n",
      "7 - Extracted article: Words still matter  \n",
      "------------\n",
      "Visiting https://medium.com/jobs-at-medium\n",
      "URLs in queue: 232\n",
      "------------\n",
      "Visiting https://medium.com/p/5aef45b8e952\n",
      "URLs in queue: 234\n",
      "8 - Extracted article: You Don’t Understand Bitcoin Because You Think Money Is Real  \n",
      "------------\n",
      "Visiting https://medium.com/p/dd31a29a3f08\n",
      "URLs in queue: 236\n",
      "9 - Extracted article: The future of the open internet — and our way of life — is in your hands  \n",
      "------------\n",
      "Visiting https://medium.com/p/aa10583302dc\n",
      "URLs in queue: 241\n",
      "10 - Extracted article: The Boundaries of Artificial Emotional Intelligence  \n",
      "Visiting https://www.kdnuggets.com\n",
      "URLs in queue: 0\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/software/text.html\n",
      "URLs in queue: 90\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/companies/products.html\n",
      "URLs in queue: 94\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/ai-environment.html\n",
      "URLs in queue: 93\n",
      "1 - Extracted article: AI Supporting The Earth  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/meetings/index.html\n",
      "URLs in queue: 97\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\n",
      "URLs in queue: 99\n",
      "2 - Extracted article: Delivering Trusted AI with DataRobot and Microsoft  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/jobs/19/04-19-nasdaq100-leader-data-science.html\n",
      "URLs in queue: 99\n",
      "3 - Extracted article: NASDAQ 100: Leader of Data Science [East Coast]  \n",
      "------------\n",
      "Visiting https://facebook.com/kdnuggets\n",
      "URLs in queue: 99\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/websites/podcasts.html\n",
      "URLs in queue: 107\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/software/index.html\n",
      "URLs in queue: 106\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\n",
      "URLs in queue: 136\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\n",
      "URLs in queue: 135\n",
      "4 - Extracted article: Attention Craving RNNS: Building Up To Transformer Networks  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\n",
      "URLs in queue: 134\n",
      "5 - Extracted article: Fors Marsh Group: Lead Data Scientist [Arlington, VA]  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/tutorials.html\n",
      "URLs in queue: 133\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\n",
      "URLs in queue: 148\n",
      "6 - Extracted article: The problem with data science job postings  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/best-data-visualization-techniques.html\n",
      "URLs in queue: 148\n",
      "7 - Extracted article:  Best Data Visualization Techniques for small and large data  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/jobs/19/04-17-ten-x-data-scientist.html\n",
      "URLs in queue: 151\n",
      "8 - Extracted article: Ten-X: Data Scientist [San Mateo, CA]  \n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/software/suites.html\n",
      "URLs in queue: 151\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/webcasts.html\n",
      "URLs in queue: 151\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/solutions/data-cleaning.html\n",
      "URLs in queue: 153\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/websites/index.html\n",
      "URLs in queue: 153\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/news.html\n",
      "URLs in queue: 170\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/education/usa-canada.html\n",
      "URLs in queue: 178\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\n",
      "URLs in queue: 178\n",
      "9 - Extracted article: Join the new generation of AI technologists  \n",
      "------------\n",
      "Visiting https://www.facebook.com/kdnuggets\n",
      "URLs in queue: 177\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/data_mining_course/index.html\n",
      "URLs in queue: 176\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/contact.html\n",
      "URLs in queue: 193\n",
      "------------\n",
      "Visiting https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\n",
      "URLs in queue: 194\n",
      "10 - Extracted article: Was it Worth Studying a Data Science Masters?  \n",
      "Visiting https://www.wikihow.com\n",
      "URLs in queue: 0\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Special:UserLogin\n",
      "URLs in queue: 132\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Buy-an-Iguana\n",
      "URLs in queue: 133\n",
      "1 - Extracted article: How to Buy an Iguana   \n",
      "------------\n",
      "Visiting https://www.wikihow.com/feed.rss\n",
      "URLs in queue: 143\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Category:Pets-and-Animals\n",
      "URLs in queue: 142\n",
      "------------\n",
      "Visiting https://es.wikihow.com\n",
      "URLs in queue: 462\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Category:Computers-and-Electronics\n",
      "URLs in queue: 549\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Use-Salicylic-Acid\n",
      "URLs in queue: 820\n",
      "2 - Extracted article: How to Use Salicylic Acid   \n",
      "------------\n",
      "Visiting https://www.wikihow.com/Forget-Someone-You-Love\n",
      "URLs in queue: 836\n",
      "3 - Extracted article: How to Forget Someone You Love   \n",
      "------------\n",
      "Visiting https://www.wikihow.com/Make-No-Bake-Cookies\n",
      "URLs in queue: 862\n",
      "4 - Extracted article: How to Make No Bake Cookies   \n",
      "------------\n",
      "Visiting https://nl.wikihow.com\n",
      "URLs in queue: 889\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Category:Personal-Care-and-Style\n",
      "URLs in queue: 973\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Category:Philosophy-and-Religion\n",
      "URLs in queue: 1279\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Category:Education-and-Communications\n",
      "URLs in queue: 1421\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Make-Soft-Pretzels\n",
      "URLs in queue: 1828\n",
      "5 - Extracted article: How to Make Soft Pretzels   \n",
      "------------\n",
      "Visiting https://www.wikihow.com/Terms-of-Use\n",
      "URLs in queue: 1855\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Do-Content-Marketing\n",
      "URLs in queue: 1873\n",
      "6 - Extracted article: How to Do Content Marketing   \n",
      "------------\n",
      "Visiting https://www.wikihow.com/Become-a-Dolphin-Trainer\n",
      "URLs in queue: 1888\n",
      "7 - Extracted article: How to Become a Dolphin Trainer   \n",
      "------------\n",
      "Visiting https://ar.wikihow.com\n",
      "URLs in queue: 1910\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Ace-Your-Medical-Residency-Interview\n",
      "URLs in queue: 1993\n",
      "8 - Extracted article: How to Ace Your Medical Residency Interview   \n",
      "------------\n",
      "Visiting https://www.wikihow.com/Teach-Addition-with-Activities\n",
      "URLs in queue: 2006\n",
      "9 - Extracted article: How to Teach Addition with Activities   \n",
      "------------\n",
      "Visiting https://pinterest.com/wikihow\n",
      "URLs in queue: 2029\n",
      "------------\n",
      "Visiting https://www.wikihow.it\n",
      "URLs in queue: 2028\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Category:Travel\n",
      "URLs in queue: 2109\n",
      "------------\n",
      "Visiting https://www.wikihow.com/Clean-a-Typewriter\n",
      "URLs in queue: 2372\n",
      "10 - Extracted article: How to Clean a Typewriter   \n",
      "Visiting http://www.chemistry-blog.com\n",
      "URLs in queue: 0\n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2009/04/26/alternative-periodic-tables/comment-page-1\n",
      "URLs in queue: 15\n",
      "1 - Extracted article: \n",
      " Alternative Periodic Tables  (Updated.  Now with a Final Thought!)   \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2008/12/28/anti-freeze-and-the-automotive-industry/comment-page-1\n",
      "URLs in queue: 19\n",
      "2 - Extracted article: \n",
      " Anti-Freeze and the Automotive Industry  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2018/06/18/graduating-my-first-phds/comment-page-1\n",
      "URLs in queue: 19\n",
      "3 - Extracted article: \n",
      " Graduating My First PhDs  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/dictionary\n",
      "URLs in queue: 18\n",
      "4 - Extracted article: \n",
      " Chemistry Dictionary for Word Processors  V3.0    \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/wp-login.php\n",
      "URLs in queue: 21\n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2018/04/21/chemistry-blog-needs-you\n",
      "URLs in queue: 20\n",
      "5 - Extracted article: \n",
      " Chemistry Blog needs you!  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2019/02/03/the-sort-of-repeating-table-of-things-that-make-up-everything\n",
      "URLs in queue: 23\n",
      "6 - Extracted article: \n",
      " The sort of repeating table of things that make up everything  \n",
      "  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2018/06/18/graduating-my-first-phds\n",
      "URLs in queue: 22\n",
      "Article already extracted: \n",
      " Graduating My First PhDs  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2018/05/08/2050-a-world-without-plastics\n",
      "URLs in queue: 21\n",
      "7 - Extracted article: \n",
      " 2050 – A world without plastics  \n",
      "  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2014/07/02/memoir-of-a-first-year-assistant-professor\n",
      "URLs in queue: 20\n",
      "8 - Extracted article: \n",
      " Memoir of a First Year Assistant Professor  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2014/07/18/a-year-in-the-life-of-a-new-research-lab-in-less-than-one-minute\n",
      "URLs in queue: 19\n",
      "9 - Extracted article: \n",
      " A Year in the Life of a New Research Lab…in Less than One Minute  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "------------\n",
      "Visiting http://www.chemistry-blog.com/2018/06/22/what-links-self-heating-drinks-and-the-d-day-landings\n",
      "URLs in queue: 20\n",
      "10 - Extracted article: \n",
      " What links self-heating drinks and the D-day landings?  \n",
      "  Recent Comments  Chemistry Twitterverse  Recent Comments  Recent Posts  Archives  Meta  \n",
      "Visiting https://schwitzsplinters.blogspot.com\n",
      "URLs in queue: 0\n",
      "1 - Extracted article: \n",
      " Animal Rights for Animal-Like AIs?  \n",
      "  \n",
      " Contest Idea: Can You Write an Philosophical Argument That Convinces Research Participants to Give Some of Their Bonus Money to Charity?  \n",
      "  \n",
      " Ethics in Publishing Philosophy  \n",
      "  \n",
      " Tell Us How to Fix the Lack of Diversity in Philosophy Departments  \n",
      "  \n",
      " Forthcoming: A Theory of Jerks and Other Philosophical Misadventures  \n",
      "  \n",
      " Gaze of Robot, Gaze of Bird  \n",
      "  \n",
      " Journey 2 Psychology  \n",
      "  \n",
      " Against the Mind-Package View of Minds  \n",
      "  \n",
      " New Podcast Interview: How Little Thou Can Know Thyself  \n",
      "  \n",
      " Most U.S. and German Ethicists Condemn Meat-Eating (or German Philosophers Think Meat Is the Wurst)  \n",
      "  \n",
      " Should You Defer to Ethical Experts?  \n",
      "  \n",
      " Thoughts, Judgments, and Beliefs -- What's the Difference?  \n",
      "  \n",
      " In Philosophy, Departments with More Women Faculty Award More PhDs to Women (Plus Some Other Interesting Facts)  \n",
      "  \n",
      " Seven Principles of Humane PhD Advising  \n",
      "  \n",
      " Studying Ethics Should Influence Your Behavior (But It Doesn't Seem to)  \n",
      "  \n",
      " Is a Blind Person's Consciousness Partly Contained in Her Cane?  \n",
      "  \n",
      "------------\n",
      "Visiting http://schwitzsplinters.blogspot.com/2011/02/german-and-english-philosophers-in-1914.html\n",
      "URLs in queue: 33\n",
      "2 - Extracted article: \n",
      " German and English Philosophers in 1914: \"World War Is a Wonderful Idea!\"  \n",
      "  \n",
      "------------\n",
      "Visiting https://schwitzsplinters.blogspot.com/2019/02/do-you-have-whole-herds-of-swiftly.html\n",
      "URLs in queue: 38\n",
      "3 - Extracted article: \n",
      " Do You Have Whole Herds of Swiftly Forgotten Microbeliefs?  \n",
      "  \n",
      "------------\n",
      "Visiting http://schwitzsplinters.blogspot.com/2015/11/names-in-philosophical-examples.html\n",
      "URLs in queue: 40\n",
      "4 - Extracted article: \n",
      " Names in Philosophical Examples  \n",
      "  \n",
      "------------\n",
      "Visiting http://schwitzsplinters.blogspot.com/2018/09/are-garden-snails-conscious-yes-no-or.html\n",
      "URLs in queue: 46\n",
      "5 - Extracted article: \n",
      " Are Garden Snails Conscious? Yes, No, or *Gong*  \n",
      "  \n",
      "------------\n",
      "Visiting https://schwitzsplinters.blogspot.com/2017/12/philosophy-undergraduate-majors-arent.html\n",
      "URLs in queue: 48\n",
      "6 - Extracted article: \n",
      " Philosophy Undergraduate Majors Aren't Very Black, but Neither Are They As White As You Might Have Thought  \n",
      "  \n",
      "------------\n",
      "Visiting https://schwitzsplinters.blogspot.com/2019/02/seven-principles-of-humane-phd-advising.html\n",
      "URLs in queue: 53\n",
      "7 - Extracted article: \n",
      " Seven Principles of Humane PhD Advising  \n",
      "  \n",
      "------------\n",
      "Visiting http://schwitzsplinters.blogspot.com/2016/01/publications-by-black-authors-in-leiter.html\n",
      "URLs in queue: 52\n",
      "8 - Extracted article: \n",
      " Publications By Black Authors in Leiter Top 15 Journals 2003-2012  \n",
      "  \n",
      "------------\n",
      "Visiting https://schwitzsplinters.blogspot.com/2019/04/gaze-of-robot-gaze-of-bird.html\n",
      "URLs in queue: 56\n",
      "9 - Extracted article: \n",
      " Gaze of Robot, Gaze of Bird  \n",
      "  \n",
      "------------\n",
      "Visiting https://schwitzsplinters.blogspot.com/2019/04/tell-us-how-to-fix-lack-of-diversity-in.html\n",
      "URLs in queue: 55\n",
      "10 - Extracted article: \n",
      " Tell Us How to Fix the Lack of Diversity in Philosophy Departments  \n",
      "  \n",
      "Visiting https://mashable.com\n",
      "URLs in queue: 0\n",
      "------------\n",
      "Visiting https://mashable.com/roundup/best-headphones-for-running\n",
      "URLs in queue: 71\n",
      "1 - Extracted article: Don't sweat it: These are 8 of the best headphones for running or hitting the gym  \n",
      "------------\n",
      "Visiting https://mashable.com/roundup/best-air-fryers\n",
      "URLs in queue: 81\n",
      "2 - Extracted article: Best air fryers 2019: Make fried food without all the guilt  \n",
      "------------\n",
      "Visiting https://mashable.com/subscriptions\n",
      "URLs in queue: 90\n",
      "------------\n",
      "Visiting https://mashable.com/cookie-policy\n",
      "URLs in queue: 89\n",
      "------------\n",
      "Visiting https://mashable.com/mailto:brand_licensing\n",
      "URLs in queue: 91\n",
      "------------\n",
      "Visiting https://mashable.com/roundup/best-vacuums-for-pet-hair\n",
      "URLs in queue: 94\n",
      "3 - Extracted article: These 8 vacuum cleaners are the best for dealing with pet hair  \n",
      "------------\n",
      "Visiting https://mashable.com/article/slack-ipo-privacy-concerns\n",
      "URLs in queue: 99\n",
      "4 - Extracted article: Slack's IPO filing shows it fears a Facebook-style privacy disaster  \n",
      "------------\n",
      "Visiting https://mashable.com/reels/senators-juul\n",
      "URLs in queue: 106\n",
      "string index out of range\n",
      "------------\n",
      "Visiting https://mashable.com/roundup/best-robot-vacuums\n",
      "URLs in queue: 105\n",
      "5 - Extracted article: Best robot vacuums for every budget  \n",
      "------------\n",
      "Visiting https://mashable.com/article/instagram-will-hide-like-count-test\n",
      "URLs in queue: 106\n",
      "6 - Extracted article: Instagram could start hiding like counts  \n",
      "------------\n",
      "Visiting https://mashable.com/roundup/best-cheap-laptops-under-500\n",
      "URLs in queue: 110\n",
      "7 - Extracted article: Best cheap laptops: 10 options for under $500  \n",
      "------------\n",
      "Visiting https://mashable.com/shopping/how-to-donate-credit-card-points-or-rewards-miles-to-charity\n",
      "URLs in queue: 110\n",
      "8 - Extracted article: How to donate your credit card points or reward miles to charity  \n",
      "------------\n",
      "Visiting https://mashable.com/article/daily-caller-facebook-fact-checking-tucker-carlson\n",
      "URLs in queue: 111\n",
      "9 - Extracted article: Why  the hell is The Daily Caller 'fact-checking' for Facebook?  \n",
      "------------\n",
      "Visiting https://twitter.com/mashable\n",
      "URLs in queue: 112\n",
      "------------\n",
      "Visiting https://mashable.com/gifts/best-mothers-day-gifts\n",
      "URLs in queue: 126\n",
      "10 - Extracted article: Best Mother's Day gifts 2019: Show mom some love  \n",
      "Visiting https://www.tutorialspoint.com\n",
      "URLs in queue: 0\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/upsc_ias_exams.htm\n",
      "URLs in queue: 91\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/java8/index.htm\n",
      "URLs in queue: 148\n",
      "1 - Extracted article: Java8 Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/kotlin/index.htm\n",
      "URLs in queue: 165\n",
      "2 - Extracted article: Kotlin Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/codingground.htm\n",
      "URLs in queue: 186\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/ms_project/index.htm\n",
      "URLs in queue: 322\n",
      "3 - Extracted article: MS Project Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/big_data_analytics/index.htm\n",
      "URLs in queue: 335\n",
      "4 - Extracted article: Big Data Analytics Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/articles\n",
      "URLs in queue: 366\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/javascript/index.htm\n",
      "URLs in queue: 365\n",
      "5 - Extracted article: Javascript Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/computer_glossary.htm\n",
      "URLs in queue: 406\n",
      "------------\n",
      "Visiting https://store.tutorialspoint.com\n",
      "URLs in queue: 406\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/questions_and_answers.htm\n",
      "URLs in queue: 432\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/memcached/index.htm\n",
      "URLs in queue: 727\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/xamarin/index.htm\n",
      "URLs in queue: 749\n",
      "6 - Extracted article: Xamarin Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/questions/index.php\n",
      "URLs in queue: 767\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/computer_programming_tutorials.htm\n",
      "URLs in queue: 785\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/database_tutorials.htm\n",
      "URLs in queue: 824\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/academic_tutorials.htm\n",
      "URLs in queue: 846\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/tableau/index.htm\n",
      "URLs in queue: 943\n",
      "7 - Extracted article: Tableau Tutorial  \n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/mongodb/index.htm\n",
      "URLs in queue: 1000\n",
      "8 - Extracted article: MongoDB Tutorial  \n",
      "------------\n",
      "Visiting http://www.tutorialspoint.com\n",
      "URLs in queue: 1043\n",
      "------------\n",
      "Visiting https://www.tutorialspoint.com/cplusplus/index.htm\n",
      "URLs in queue: 1042\n",
      "9 - Extracted article: C++ Tutorial  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Visiting https://www.tutorialspoint.com/scala/index.htm\n",
      "URLs in queue: 1087\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-b925f50f7376>\", line 5, in <module>\n",
      "    scraper.incremental_scraping_from_configs(configs)\n",
      "  File \"<ipython-input-3-97512358c713>\", line 162, in incremental_scraping_from_configs\n",
      "    self.scrape_website_incremental(website, conf, max_scraped=max_scraped)\n",
      "  File \"<ipython-input-3-97512358c713>\", line 98, in scrape_website_incremental\n",
      "    response = scraper_requests.make_get(url)\n",
      "  File \"scraper_requests.ipynb\", line 52, in make_get\n",
      "    \"        session.proxies = {'http':  'socks5://127.0.0.1:9050',\\n\",\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/requests/sessions.py\", line 525, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/requests/sessions.py\", line 512, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/requests/sessions.py\", line 622, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/requests/adapters.py\", line 445, in send\n",
      "    timeout=timeout\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/urllib3/connectionpool.py\", line 343, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/urllib3/connectionpool.py\", line 849, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/urllib3/connection.py\", line 314, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/urllib3/contrib/socks.py\", line 88, in _new_conn\n",
      "    **extra_kw\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/socks.py\", line 252, in create_connection\n",
      "    sock.connect((remote_host, remote_port))\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/socks.py\", line 100, in wrapper\n",
      "    return function(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/socks.py\", line 851, in connect\n",
      "    negotiate(self, dest_addr, dest_port)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/socks.py\", line 497, in _negotiate_SOCKS5\n",
      "    self, CONNECT, dest_addr)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/socks.py\", line 569, in _SOCKS5_request\n",
      "    resp = self._readall(reader, 3)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/socks.py\", line 329, in _readall\n",
      "    d = file.read(count - len(data))\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/socket.py\", line 576, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/inspect.py\", line 1459, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/inspect.py\", line 1417, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/inspect.py\", line 677, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/inspect.py\", line 723, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/posixpath.py\", line 373, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/posixpath.py\", line 406, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/anaconda3/envs/education/lib/python3.5/posixpath.py\", line 71, in join\n",
      "    def join(a, *p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    configs = ScraperConfigReader.get_configs(\"scraper_configs.json\")\n",
    "    scraper = Scraper()\n",
    "    #scraper.scrape_website_incremental(\"tutorialspoint\", configs[\"tutorialspoint\"], max_scraped=5, start_from_zero=False)\n",
    "    scraper.incremental_scraping_from_configs(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraped_data = ReaderScrapedData.read_data_of_website(\"wikihow\")\n",
    "#titles = set(ReaderScrapedData.get_titles(scraped_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "config = {\n",
    "    \"first_url\": [\"https://mashable.com\"],\n",
    "    \"title_selector\": [\".article-header > .title\"],\n",
    "    \"content_selector\": [\".article-content p\"]\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://mashable.com/roundup/best-cheap-laptops-under-500\")\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "title = UtilsSoup.get_with_selector(config[ScraperConfigReader.title_selector_key], soup)[1]\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title in titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
