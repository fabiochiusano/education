{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From dirty data (right after scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hidden(l):\n",
    "    return [el for el in l if el[0] != \".\"]\n",
    "\n",
    "def get_relative_path_to_dirs(start_path):\n",
    "    subdirs = [x[1] for x in os.walk(start_path)][0]\n",
    "    subdirs = remove_hidden(subdirs)\n",
    "    subdirs = [start_path + \"/\" + subdir for subdir in subdirs]\n",
    "    return subdirs\n",
    "\n",
    "def get_relative_path_to_files(start_path):\n",
    "    files = [f for f in listdir(start_path) if isfile(join(start_path, f))]\n",
    "    files = remove_hidden(files)\n",
    "    files = [start_path + \"/\" + file for file in files]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_articles_directory = \"../articles\"\n",
    "\n",
    "subdirs = get_relative_path_to_dirs(home_articles_directory)\n",
    "subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for subdir in subdirs:\n",
    "    subsubdirs = get_relative_path_to_dirs(subdir)\n",
    "    sub_data = {}\n",
    "    for subsubdir in subsubdirs:\n",
    "        onlyfiles = get_relative_path_to_files(subsubdir)\n",
    "        read_json_list = []\n",
    "        for file in onlyfiles:\n",
    "            with open(file, 'r') as infile:\n",
    "                d = json.load(infile)\n",
    "                read_json_list.append(d)\n",
    "        sub_data[subsubdir] = read_json_list\n",
    "    data[subdir] = sub_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of scraped tutorials per website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plt = {}\n",
    "for k,v in data.items():\n",
    "    for k2,v2 in v.items():\n",
    "        data_plt[k2.split(\"/\")[-1]] = len(v2)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.bar(range(len(data_plt)), list(data_plt.values()), align='center')\n",
    "plt.xticks(range(len(data_plt)), list(data_plt.keys()), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average lenght of title html per website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plt = {}\n",
    "for k,v in data.items():\n",
    "    for k2,v2 in v.items():\n",
    "        data_plt[k2.split(\"/\")[-1]] = sum([len(j[\"html\"]) for j in v2]) / len(v2)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.bar(range(len(data_plt)), list(data_plt.values()), align='center')\n",
    "plt.xticks(range(len(data_plt)), list(data_plt.keys()), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average title length per website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plt = {}\n",
    "for k,v in data.items():\n",
    "    for k2,v2 in v.items():\n",
    "        data_plt[k2.split(\"/\")[-1]] = sum([len(j[\"title\"]) for j in v2]) / len(v2)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.bar(range(len(data_plt)), list(data_plt.values()), align='center')\n",
    "plt.xticks(range(len(data_plt)), list(data_plt.keys()), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plt = {}\n",
    "for k,v in data.items():\n",
    "    for k2,v2 in v.items():\n",
    "        data_plt[k2.split(\"/\")[-1]] = sum([len(j[\"title\"].split(\" \")) for j in v2]) / len(v2)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.bar(range(len(data_plt)), list(data_plt.values()), align='center')\n",
    "plt.xticks(range(len(data_plt)), list(data_plt.keys()), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1,v1 in data.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        random_selected = np.random.choice(v2, size=5, replace=True)\n",
    "        titles_and_urls = [(el[\"title\"], el[\"url\"]) for el in random_selected]\n",
    "        print(k2 + \":\")\n",
    "        for t,u in titles_and_urls:\n",
    "            print(t + \" --> \" + u)\n",
    "        print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1,v1 in data.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        random_selected = np.random.choice(v2, size=1, replace=True)\n",
    "        titles_and_urls = [(el[\"content\"], el[\"url\"]) for el in random_selected]\n",
    "        print(k2 + \":\")\n",
    "        for t,u in titles_and_urls:\n",
    "            print(t + \" --> \" + u)\n",
    "        print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample article HTML tag chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1,v1 in data.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        random_selected = np.random.choice(v2, size=5, replace=True)\n",
    "        chtml_and_urls = [(el[\"content_html\"], el[\"url\"]) for el in random_selected]\n",
    "        print(k2 + \":\")\n",
    "        for chtml,u in chtml_and_urls:\n",
    "            soup = BeautifulSoup(chtml)\n",
    "            chain = list(list(soup.select(\"body\")[0].descendants)[0].descendants)\n",
    "            chain_list = []\n",
    "            for el in chain:\n",
    "                if type(el) == Tag:\n",
    "                    chain_list.append(el.name)\n",
    "            print(\" \".join(chain_list) + \" ---> \" + u)\n",
    "        print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queue_length = ...\n",
    "\n",
    "#plt.plot(range(len(queue_length)), queue_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
