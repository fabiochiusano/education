{"content": "comments By Raymond Li . Today, I\u2019m going to explain in plain English the top 10 most influential data mining algorithms as voted on by 3 separate panels in this survey paper . Once you know what they are, how they work, what they do and where you can find them, my hope is you\u2019ll have this blog post as a springboard to learn even more about data mining. What are we waiting for? Let\u2019s get started! Here are the algorithms: 1. C4.5 2. k-means 3. Support vector machines 4. Apriori 5. EM 6. PageRank 7. AdaBoost 8. kNN 9. Naive Bayes 10. CART We also provide interesting resources at the end. 1. C4.5 What does it do? C4.5 constructs a classifier in the form of a decision tree. In order to do this, C4.5 is given a set of data representing things that are already classified. Wait, what\u2019s a classifier? A classifier is a tool in data mining that takes a bunch of data representing things we want to classify and attempts to predict which class the new data belongs to. What\u2019s an example of this? Sure, suppose a dataset contains a bunch of patients. We know various things about each patient like age, pulse, blood pressure, VO 2 max, family history, etc. These are called attributes. Now: Given these attributes, we want to predict whether the patient will get cancer. The patient can fall into 1 of 2 classes: will get cancer or won\u2019t get cancer. C4.5 is told the class for each patient. And here\u2019s the deal: Using a set of patient attributes and the patient\u2019s corresponding class, C4.5 constructs a decision tree that can predict the class for new patients based on their attributes. Cool, so what\u2019s a decision tree? Decision tree learning creates something similar to a flowchart to classify new data. Using the same patient example, one particular path in the flowchart could be: Patient has a history of cancer Patient is expressing a gene highly correlated with cancer patients Patient has tumors Patient\u2019s tumor size is greater than 5cm The bottom line is: At each point in the flowchart is a question about the value of some attribute, and depending on those values, he or she gets classified. You can find lots of examples of decision trees . Is this supervised or unsupervised? This is supervised learning, since the training dataset is labeled with classes. Using the patient example, C4.5 doesn\u2019t learn on its own that a patient will get cancer or won\u2019t get cancer. We told it first, it generated a decision tree, and now it uses the decision tree to classify. You might be wondering how C4.5 is different than other decision tree systems? First, C4.5 uses information gain when generating the decision tree. Second, although other systems also incorporate pruning, C4.5 uses a single-pass pruning process to mitigate over-fitting. Pruning results in many improvements . Third, C4.5 can work with both continuous and discrete data. My understanding is it does this by specifying ranges or thresholds for continuous data thus turning continuous data into discrete data. Finally, incomplete data is dealt with in its own ways . Why use C4.5? Arguably, the best selling point of decision trees is their ease of interpretation and explanation. They are also quite fast, quite popular and the output is human readable . Where is it used? A popular open-source Java implementation can be found over at OpenTox . Orange , an open-source data visualization and analysis tool for data mining, implements C4.5 in their decision tree classifier. Classifiers are great, but make sure to checkout the next algorithm about clustering\u2026 2. k-means What does it do? k-means creates k groups from a set of objects so that the members of a group are more similar. It\u2019s a popular cluster analysis technique for exploring a dataset. Hang on, what\u2019s cluster analysis? Cluster analysis is a family of algorithms designed to form groups such that the group members are more similar versus non-group members. Clusters and groups are synonymous in the world of cluster analysis. Is there an example of this? Definitely, suppose we have a dataset of patients. In cluster analysis, these would be called observations. We know various things about each patient like age, pulse, blood pressure, VO 2 max, cholesterol, etc. This is a vector representing the patient. Look: You can basically think of a vector as a list of numbers we know about the patient. This list can also be interpreted as coordinates in multi-dimensional space. Pulse can be one dimension, blood pressure another dimension and so forth. You might be wondering: Given this set of vectors, how do we cluster together patients that have similar age, pulse, blood pressure, etc? Want to know the best part? You tell k-means how many clusters you want. K-means takes care of the rest. How does k-means take care of the rest? k-means has lots of variations to optimize for certain types of data. At a high level, they all do something like this: k-means picks points in multi-dimensional space to represent each of the k clusters. These are called centroids. Every patient will be closest to 1 of these k centroids. They hopefully won\u2019t all be closest to the same one, so they\u2019ll form a cluster around their nearest centroid. What we have are k clusters, and each patient is now a member of a cluster. k-means then finds the center for each of the k clusters based on its cluster members (yep, using the patient vectors!). This center becomes the new centroid for the cluster. Since the centroid is in a different place now, patients might now be closer to other centroids. In other words, they may change cluster membership. Steps 2-6 are repeated until the centroids no longer change, and the cluster memberships stabilize. This is called convergence. Is this supervised or unsupervised? It depends, but most would classify k-means as unsupervised. Other than specifying the number of clusters, k-means \u201clearns\u201d the clusters on its own without any information about which cluster an observation belongs to. k-means can be semi-supervised . Why use k-means? I don\u2019t think many will have an issue with this: The key selling point of k-means is its simplicity. Its simplicity means it\u2019s generally faster and more efficient than other algorithms, especially over large datasets. It gets better: k-means can be used to pre-cluster a massive dataset followed by a more expensive cluster analysis on the sub-clusters. k-means can also be used to rapidly \u201cplay\u201d with k and explore whether there are overlooked patterns or relationships in the dataset. It\u2019s not all smooth sailing: Two key weaknesses of k-means are its sensitivity to outliers, and its sensitivity to the initial choice of centroids. One final thing to keep in mind is k-means is designed to operate on continuous data \u2014 you\u2019ll need to do some tricks to get it to work on discrete data. Where is it used? A ton of implementations for k-means clustering are available online: Apache Mahout Julia R SciPy Weka MATLAB SAS If decision trees and clustering didn\u2019t impress you, you\u2019re going to love the next algorithm. 3. Support vector machines What does it do? Support vector machine (SVM) learns a hyperplane to classify data into 2 classes. At a high-level, SVM performs a similar task like C4.5 except SVM doesn\u2019t use decision trees at all. Whoa, a hyper-what? A hyperplane is a function like the equation for a line, y = mx + b . In fact, for a simple classification task with just 2 features, the hyperplane can be a line. As it turns out\u2026 SVM can perform a trick to project your data into higher dimensions. Once projected into higher dimensions\u2026 \u2026SVM figures out the best hyperplane which separates your data into the 2 classes. Do you have an example? Absolutely, the simplest example I found starts with a bunch of red and blue balls on a table. If the balls aren\u2019t too mixed together, you could take a stick and without moving the balls, separate them with the stick. You see: When a new ball is added on the table, by knowing which side of the stick the ball is on, you can predict its color. What do the balls, table and stick represent? The balls represent data points, and the red and blue color represent 2 classes. The stick represents the simplest hyperplane which is a line. And the coolest part? SVM figures out the function for the hyperplane. What if things get more complicated? Right, they frequently do. If the balls are mixed together, a straight stick won\u2019t work. Here\u2019s the work-around: Quickly lift up the table throwing the balls in the air. While the balls are in the air and thrown up in just the right way, you use a large sheet of paper to divide the balls in the air. You might be wondering if this is cheating: Nope, lifting up the table is the equivalent of mapping your data into higher dimensions. In this case, we go from the 2 dimensional table surface to the 3 dimensional balls in the air. How does SVM do this? By using a kernel we have a nice way to operate in higher dimensions. The large sheet of paper is still called a hyperplane, but it is now a function for a plane rather than a line. Note from Yuval that once we\u2019re in 3 dimensions, the hyperplane must be a plane rather than a line. I found this visualization super helpful: Reddit also has 2 great threads on this in the ELI5 and ML subreddits. How do balls on a table or in the air map to real-life data? A ball on a table has a location that we can specify using coordinates. For example, a ball could be 20cm from the left edge and 50cm from the bottom edge. Another way to describe the ball is as (x, y) coordinates or (20, 50). x and y are 2 dimensions of the ball. Here\u2019s the deal: If we had a patient dataset, each patient could be described by various measurements like pulse, cholesterol level, blood pressure, etc. Each of these measurements is a dimension. The bottom line is: SVM does its thing, maps them into a higher dimension and then finds the hyperplane to separate the classes. Margins are often associated with SVM? What are they? The margin is the distance between the hyperplane and the 2 closest data points from each respective class. In the ball and table example, the distance between the stick and the closest red and blue ball is the margin. The key is: SVM attempts to maximize the margin, so that the hyperplane is just as far away from red ball as the blue ball. In this way, it decreases the chance of misclassification. Where does SVM get its name from? Using the ball and table example, the hyperplane is equidistant from a red ball and a blue ball. These balls or data points are called support vectors, because they support the hyperplane. Is this supervised or unsupervised? This is a supervised learning, since a dataset is used to first teach the SVM about the classes. Only then is the SVM capable of classifying new data. Why use SVM? SVM along with C4.5 are generally the 2 classifiers to try first . No classifier will be the best in all cases due to the No Free Lunch Theorem . In addition, kernel selection and interpretability are some weaknesses. Where is it used? There are many implementations of SVM. A few of the popular ones are scikit-learn , MATLAB and of course libsvm . The next algorithm is one of my favorites\u2026", "title_html": "<h1 id=\"title\">Top 10 Data Mining Algorithms, Explained</h1> ", "url": "https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html", "tfidf": {"tfidf": {"equival": 4.09175257732, "arguabl": 12.928338762200001, "fall": 1.6945244956799999, "onc": 4.492359932099999, "too": 1.81585268215, "readabl": 74.8867924528, "label": 4.47715736041, "red": 11.11142217245, "new": 6.1073283324, "space": 4.79637462236, "addit": 1.24634950542, "would": 2.1657458563599996, "number": 2.20285833218, "knn": 1443.27272727, "etc": 16.826709062, "dataset": 1742.4878048819999, "function": 7.486325055, "class": 25.39821357156, "belong": 7.0, "pagerank": 1443.27272727, "unsupervis": 1380.5217391320002, "whether": 4.41367806506, "tree": 53.663026521000006, "teach": 3.98594024605, "path": 4.6421052631599995, "sell": 7.02167182662, "higher": 10.609462710499999, "know": 15.559621038900001, "their": 4.0619163362, "yep": 1134.0, "won": 9.26930375128, "sheet": 17.2190889371, "particular": 1.3814827706200001, "measur": 4.82186788154, "creat": 2.4985835694, "express": 1.9120799710900003, "vector": 207.1908646, "how": 11.21752296357, "lunch": 22.68, "bunch": 121.5, "had": 1.0475750577399998, "especi": 1.66712170534, "initi": 1.35, "converg": 15.2947976879, "end": 1.10680423871, "found": 3.34161229215, "correl": 13.1860465116, "lift": 12.75693049418, "form": 3.38267045454, "interest": 1.60331246213, "color": 7.6510843373399995, "will": 7.34886591576, "associ": 1.3263157894700002, "flowchart": 4329.81818181, "dimensions\u2026": 1443.27272727, "second": 1.1130898128, "incorpor": 2.62847682119, "next": 4.485168094920001, "similar": 6.87570376785, "but": 3.04897253697, "throw": 8.39555790587, "adaboost": 1443.27272727, "need": 1.4372623574099999, "classif": 8.067073170730001, "longer": 2.02319357716, "final": 2.6801721955, "point": 8.81930005558, "naiv": 50.2405063291, "key": 6.84015510555, "bottom": 18.81785855394, "level": 3.3088786994599997, "has": 5.218248751, "have": 7.104263887979998, "theorem": 36.164009111599995, "impress": 3.90457452041, "today": 1.74961428257, "use": 21.622413904979997, "optim": 11.5377906977, "resourc": 2.9487369985100003, "onlin": 2.6051854282900004, "reddit": 529.2, "out": 2.12033388982, "quit": 5.769943667100001, "member": 6.60344397305, "panel": 7.57442748092, "cours": 2.15092805853, "absolut": 5.3472549680000006, "julia": 20.9722589168, "togeth": 4.74287990439, "not": 1.01567398119, "far": 1.71022298826, "are": 26.77755433028, "decreas": 4.5230769230800005, "quick": 2.205, "plane": 12.8187323375, "english": 1.7432744043000001, "than": 6.196721311499999, "then": 3.25973581548, "complic": 5.6478121664900005, "separ": 6.404841149759999, "they": 11.33190578157, "design": 2.9165059245, "anoth": 2.27287043664, "blue": 15.3509959389, "turn": 2.7677824267799997, "cancer": 56.07063572152, "let": 3.48616600791, "world": 1.11340206186, "blog": 14.1876675603, "construct": 3.8641840087599997, "away": 1.85142857143, "featur": 1.52712581762, "apriori": 1443.27272727, "blood": 23.7451390966, "simpl": 3.3981164383599998, "until": 1.14852058164, "provid": 1.21552714187, "valu": 4.555523672880001, "coordin": 16.96758104739, "stabil": 6.0618556701, "pattern": 3.79173632673, "checkout": 283.5, "those": 1.19548192771, "explor": 6.79187165776, "without": 2.59094247246, "lot": 8.81755068036, "some": 3.1211009174399997, "synonym": 14.8373831776, "forth": 8.65177111717, "both": 1.05215720061, "locat": 1.59766529134, "super": 7.380753138080001, "result": 1.14611608432, "supervis": 38.70307167235, "subreddit": 1443.27272727, "set": 4.74831763124, "third": 1.4195278969999998, "ani": 1.13383802314, "question": 2.20408163265, "trick": 29.4545454546, "divid": 2.3169877408099997, "improv": 2.04376930999, "from": 9.00510493473, "favorites\u2026": 1443.27272727, "patient": 257.75826819012, "num": 34.010711360340004, "puls": 114.21582733800001, "aren": 481.09090909099996, "free": 1.71818181818, "left": 1.4398693996, "equat": 9.76984615385, "for": 15.004725600150001, "depend": 4.4822134387400006, "predict": 20.7393860222, "output": 7.676982591880001, "closer": 5.5666199158500005, "with": 11.013180298889997, "these": 7.51907983764, "kmean": 27422.181818129997, "max": 14.949152542379998, "better": 2.0065722952500002, "distanc": 6.9509632224199995, "frequent": 2.10501193317, "look": 1.9086318826599997, "popular": 6.03076923076, "chanc": 4.2449197861000005, "surfac": 3.97396745932, "think": 5.81431972166, "work": 4.46080359652, "center": 3.4846356452999996, "capabl": 3.6580645161300005, "versus": 7.77473065622, "map": 12.218573627490002, "group": 6.0498437619, "doe": 13.6465026324, "even": 1.16461267606, "straight": 6.203985932, "could": 4.8174783796, "raymond": 10.9944598338, "vote": 3.0011342155, "side": 1.5989525632, "scipi": 1443.27272727, "place": 1.1004366812200002, "great": 2.53185551392, "told": 6.3087621696800005, "step": 2.8279301745599996, "move": 1.29125660838, "continu": 4.55715823468, "type": 2.0281042411900003, "multidimension": 320.727272728, "note": 1.42449528937, "margin": 24.67132867132, "thing": 16.845839017769997, "machin": 12.073003802279999, "into": 8.12019691832, "paper": 7.988594431410001, "dimens": 74.30265210609, "rapid": 2.62586834271, "where": 5.33575317605, "figur": 4.0686827268, "what": 17.54808147792, "suppos": 8.46043165468, "relationship": 2.39132399458, "overfit": 1443.27272727, "interpret": 9.645200486039998, "influenti": 4.520501138949999, "help": 1.39962972759, "larg": 3.55724848755, "find": 6.917647058839999, "line": 9.92781847421, "own": 3.5353325415600003, "base": 2.2925631769, "deal": 4.36693714758, "fact": 1.73375559681, "tool": 9.99433427762, "due": 1.23789473684, "post": 2.23826307627, "here": 9.69230769232, "incomplet": 14.8930581614, "human": 1.8965476048299998, "thrown": 12.109839816900001, "greater": 2.14801785956, "contain": 1.59814777532, "care": 4.98853102906, "about": 8.51888121272, "threshold": 23.008695652199997, "scikitlearn": 1443.27272727, "out\u2026": 1443.27272727, "mind": 3.5918552036199998, "sure": 14.907042253520002, "just": 4.00740429111, "springboard": 135.692307692, "preclust": 1443.27272727, "air": 9.759036144600001, "she": 2.16, "classifi": 79.406468823, "weak": 9.41078838174, "expens": 3.5453327378300004, "clustering\u2026": 1443.27272727, "ball": 165.99749058975, "rest": 3.9146837627999997, "train": 1.9365698950999999, "massiv": 4.22571200426, "start": 2.53347163488, "love": 2.97303370787, "them": 3.29628347982, "word": 1.7965372864099998, "alreadi": 1.9551724137900002, "keep": 2.04245465071, "observ": 4.44892812106, "order": 1.24625166811, "kernel": 141.12, "famili": 2.97609897834, "whi": 9.769846153860001, "cheat": 31.6886227545, "support": 6.342788653600001, "play": 1.46390041494, "mani": 4.17707031508, "over": 2.05050048434, "age": 4.45871559633, "analysi": 24.34969325152, "explain": 2.60049140049, "mine": 19.503685503679996, "select": 2.02345144022, "whoa": 1134.0, "nope": 1443.27272727, "same": 2.23715916296, "thread": 24.2381679389, "there": 3.12273800157, "coolest": 111.020979021, "inform": 3.1506251240400003, "stick": 80.7645348839, "misclassif": 1443.27272727, "nearest": 15.148854961800001, "semisupervis": 1443.27272727, "best": 6.331405782640001, "repres": 11.75782262544, "right": 2.8109065155799997, "given": 4.06278256419, "membership": 14.1686746988, "take": 4.55846672888, "visual": 10.45505432994, "follow": 1.04640126549, "now": 6.9646852379999995, "might": 8.624745348360001, "tri": 1.8544562551099997, "name": 1.10211732037, "cholesterol": 291.302752294, "singlepass": 1443.27272727, "simplic": 50.8846153846, "high": 2.2955465587, "basic": 2.7301805675, "edg": 8.91409320606, "issu": 1.43921675279, "also": 6.08859060402, "dealt": 11.2755681818, "specifi": 20.761987794240003, "simplest": 56.0989399294, "around": 1.21394708671, "mean": 1.44906900329, "task": 7.77282741738, "first": 4.03046458492, "the": 119.0, "may": 1.05201775893, "certain": 1.8077886586200003, "becom": 1.12492028626, "reallif": 1443.27272727, "prune": 393.61983471, "want": 7.98792452832, "system": 2.77479681902, "centroid": 6350.4, "tumor": 115.4618181818, "various": 3.99697885197, "although": 1.14968498805, "attribut": 17.078313252999997, "weka": 1443.27272727, "histori": 2.4125826305, "maxim": 12.928338762200001, "which": 5.025959224999999, "such": 1.06151377374, "yuval": 496.125, "thus": 1.6463756092500001, "other": 6.05954198472, "techniqu": 3.7293868921800004, "one": 6.03764974332, "fast": 4.8729281768, "hope": 5.01769911504, "see": 1.27242125511, "hyperplan": 11466.0, "algorithm": 195.6549295778, "becaus": 1.1495184997499999, "outlier": 269.084745763, "closest": 34.94991744636, "highlevel": 1443.27272727, "get": 19.64188505235, "still": 1.1866357724799999, "like": 6.8951140065, "orang": 8.204651162789999, "implement": 14.30592475784, "wonder": 21.797711670480002, "equidist": 180.409090909, "except": 1.71948445792, "opensourc": 2886.54545454, "part": 2.08661365578, "attempt": 2.9443620177999996, "mitig": 22.8103448276, "cool": 6.8578833693300005, "repeat": 2.8771293947099994, "tabl": 38.2093862816, "pick": 4.939639079030001, "this": 24.09104704104, "choic": 3.1319786940200003, "top": 1.8387769284200002, "rang": 1.7848229342299997, "discret": 45.017013232500005, "process": 1.69524826482, "chang": 2.3617970842, "wait": 9.10843373494, "perform": 3.0627954085000004, "survey": 3.7791002142300005, "project": 3.5069582505000003, "differ": 2.4730898045, "numcm": 3175.2000000000003, "tell": 3.36142282448, "most": 2.04192926046, "between": 2.06907337416, "everi": 1.47917637194, "definit": 3.24, "java": 31.625498008, "along": 1.2973768080399999, "all": 5.05733944955, "apach": 67.27118644069999, "mix": 5.5705263157800005, "ton": 10.5278514589, "someth": 6.56304257958, "libsvm": 1443.27272727, "case": 2.96997474512, "that": 10.0398406375, "overlook": 11.4051724138, "call": 6.4059179556, "cluster": 287.5181102368, "object": 2.3488681757700003, "more": 6.1030240902, "and": 37.00233070881, "list": 2.72642967542, "correspond": 3.32481675393, "hyperwhat": 1443.27272727, "respect": 1.6443293630200002, "smooth": 11.086592178800002, "hang": 8.31639601886, "pressur": 14.943524096399997, "gain": 1.84819557625, "general": 2.2436404748400003, "faster": 7.61438848921, "sensit": 16.9344, "comment": 3.05954904606, "gene": 9.89775561097, "can": 18.82018226272, "avail": 1.7288467821, "workaround": 407.07692307699995, "describ": 2.94054454528, "make": 1.0762660158600001, "few": 1.31729173581, "way": 6.0953697305, "onli": 1.0256476516600002, "each": 11.897482014400001, "size": 2.49387370405, "eas": 9.04615384615, "subclust": 1443.27272727, "two": 1.01379310345, "data": 87.78732454284, "oper": 3.10958769954, "nongroup": 1443.27272727, "mahout": 1443.27272727, "rather": 3.11385701676, "sinc": 3.2510580204900004, "explan": 6.50922509225, "must": 1.9220338983099996, "exampl": 15.0483412322, "opentox": 1443.27272727, "dimension": 108.3686006826, "understand": 2.96858638743, "variat": 4.704, "decis": 28.080000000000002, "sail": 7.934032983510001, "nice": 17.7583892617, "generat": 4.10550814584, "while": 1.0441988950299999, "plain": 5.49913404919, "often": 1.29452054795, "bay": 4.629921259840001, "learn": 16.259253840550002, "when": 2.0415353951, "effici": 5.09335899904}, "logtfidf": {"equival": 1.40897338129, "arguabl": 2.5594217052, "fall": 0.527402167952, "onc": 1.211297617065, "too": 0.5965551547219999, "readabl": 4.31597753923, "label": 1.49898832727, "red": 3.9926784567349998, "new": 0.1063796811066, "space": 1.749426329944, "addit": 0.220218882972, "would": 0.1592352559294, "number": 0.1932171568372, "knn": 7.2746685411000005, "etc": 5.746692351880001, "dataset": 47.39260109976, "function": 2.743397224782, "class": 8.997266279196001, "belong": 2.505525937, "pagerank": 7.2746685411000005, "unsupervis": 23.375689669639996, "whether": 1.583122379294, "tree": 18.43107354075, "teach": 1.38277323072, "path": 1.5351679838499999, "sell": 2.51170832214, "higher": 3.761541994975, "know": 5.7175181663879995, "their": 0.061442020490800005, "yep": 7.033506484289999, "won": 3.3616556316, "sheet": 4.30574281958, "particular": 0.323157393804, "measur": 1.760028399452, "creat": 0.445153637028, "express": 0.648191639641, "vector": 26.03359102376, "how": 3.30096869851, "lunch": 3.1214834788599997, "bunch": 11.10390592233, "had": 0.0464780244111, "especi": 0.511098609709, "initi": 0.30010459245, "converg": 2.7275127501800003, "end": 0.101476798618, "found": 0.323523372144, "correl": 2.57915918803, "lift": 3.7058550230800003, "form": 0.36015955257300003, "interest": 0.47207177798199995, "color": 2.6834004013599997, "will": 1.2167192094900001, "associ": 0.28240501535100004, "flowchart": 21.824005623300003, "dimensions\u2026": 7.2746685411000005, "second": 0.10713976337999999, "incorpor": 0.9664045229739999, "next": 1.206491056497, "similar": 1.59278046057, "but": 0.0485771162157, "throw": 2.12770274524, "adaboost": 7.2746685411000005, "need": 0.362740163442, "classif": 2.08779073629, "longer": 0.7046772417749999, "final": 0.585467727896, "point": 1.617226513231, "naiv": 3.9168216003199996, "key": 2.4725943568799997, "bottom": 5.50858216008, "level": 1.006924379886, "has": 0.213619724274, "have": 0.1034950163884, "theorem": 3.58806440083, "impress": 1.3621488197100002, "today": 0.559395353679, "use": 0.6133684143636, "optim": 2.4456277954099996, "resourc": 1.08137694258, "onlin": 0.957503854357, "reddit": 6.27136643224, "out": 0.1168527818386, "quit": 2.11903027368, "member": 1.3907670729950001, "panel": 2.02477776846, "cours": 0.765899404133, "absolut": 1.67658333914, "julia": 3.04320056047, "togeth": 1.374096711924, "not": 0.0155524130075, "far": 0.536623764503, "are": 0.7661543131502, "decreas": 1.50919249744, "quick": 0.790727508899, "plane": 3.71552076882, "english": 0.555765186335, "than": 0.1935651733092, "then": 0.24910159569269996, "complic": 1.7312682430000002, "separ": 1.883039091796, "they": 0.3269969424436, "design": 0.754478236044, "anoth": 0.255792723304, "blue": 5.608712207550001, "turn": 0.649798502128, "cancer": 14.564914693069998, "let": 1.2488025672799998, "world": 0.107420248621, "blog": 2.65237310559, "construct": 1.317206711944, "away": 0.615957541869, "featur": 0.423387418142, "apriori": 7.2746685411000005, "blood": 7.789699637399999, "simpl": 1.2232212893899999, "until": 0.138474663439, "provid": 0.19517784432500002, "valu": 1.646386620296, "coordin": 5.19807671262, "stabil": 1.8020159694, "pattern": 1.33282404788, "checkout": 5.647212123169999, "those": 0.17854939087299998, "explor": 2.44515874436, "without": 0.517749035882, "lot": 2.9671939005000003, "some": 0.11872052719350001, "synonym": 2.6971498864499996, "forth": 2.1577640534099998, "both": 0.050842533389300004, "locat": 0.46854337067199997, "super": 1.9988756846400002, "result": 0.136378908381, "supervis": 10.23240527915, "subreddit": 7.2746685411000005, "set": 0.685984045156, "third": 0.35032434942900004, "ani": 0.125608358366, "question": 0.790310929014, "trick": 5.3794021248599995, "divid": 0.8402679544589999, "improv": 0.7147958039319999, "from": 0.005103487519794, "favorites\u2026": 7.2746685411000005, "patient": 60.91700403717, "num": 0.010709673443498002, "puls": 15.643259841699999, "aren": 6.17605625244, "free": 0.5412666492670001, "left": 0.364552414753, "equat": 2.27930071914, "for": 0.004724855930955001, "depend": 1.61393963, "predict": 6.5829609507599995, "output": 2.03822657827, "closer": 1.7167880323700002, "with": 0.01317240884729, "these": 0.5007353358055999, "kmean": 138.2187022809, "max": 4.02301486308, "better": 0.6964279406, "distanc": 2.49146612514, "frequent": 0.7443211360850001, "look": 0.6463866936, "popular": 1.6423208350999998, "chanc": 1.44572292349, "surfac": 1.3797649557, "think": 2.1343532235, "work": 0.436138269092, "center": 1.110432617552, "capabl": 1.2969341868100002, "versus": 2.05087881518, "map": 4.21303480152, "group": 0.952972673985, "doe": 4.272333837735999, "even": 0.152388564834, "straight": 1.82519197774, "could": 0.7438250891600001, "raymond": 2.39739149445, "vote": 1.09899028905, "side": 0.46934876686899996, "scipi": 7.2746685411000005, "place": 0.0957070839572, "great": 0.471610516158, "told": 2.29758461426, "step": 1.03954505698, "move": 0.255615859253, "continu": 0.5216194959480001, "type": 0.707101485387, "multidimension": 10.154887927539999, "note": 0.353817568083, "margin": 7.277389703, "thing": 6.147354742759999, "machin": 4.17707874186, "into": 0.1193029058296, "paper": 2.938207618995, "dimens": 18.99829861479, "rapid": 0.965411638564, "where": 0.3249606937285, "figur": 1.4203442243200002, "what": 3.162422155578, "suppos": 2.88450602954, "relationship": 0.871847185184, "overfit": 7.2746685411000005, "interpret": 3.5035444320000004, "influenti": 1.50862285915, "help": 0.336207721344, "larg": 0.511125181818, "find": 2.191125321152, "line": 2.4460143011640003, "own": 0.492585232263, "base": 0.27304660457400004, "deal": 1.561829402506, "fact": 0.5502899207949999, "tool": 3.21774235926, "due": 0.21341214386399998, "post": 0.8057001527009999, "here": 3.5401527534800006, "incomplet": 2.70089520918, "human": 0.640035183243, "thrown": 2.4940183301400003, "greater": 0.764545491118, "contain": 0.468845318236, "care": 1.8279886058219998, "about": 0.5027478197968, "threshold": 3.1358722163099997, "scikitlearn": 7.2746685411000005, "out\u2026": 7.2746685411000005, "mind": 1.2786688388299998, "sure": 4.0173731104, "just": 0.868594302327, "springboard": 4.91038987911, "preclust": 7.2746685411000005, "air": 3.34377863718, "she": 0.7701082216959999, "classifi": 24.99794452725, "weak": 3.0974191016000003, "expens": 1.26563201674, "clustering\u2026": 7.2746685411000005, "ball": 47.327421161000004, "rest": 1.343174739666, "train": 0.660918312839, "massiv": 1.44118776833, "start": 0.472886738582, "love": 1.08958288195, "them": 0.2825499807279, "word": 0.585861082385, "alreadi": 0.670478380747, "keep": 0.7141523446729999, "observ": 1.5990320298640002, "order": 0.22014038079300002, "kernel": 8.5129268234, "famili": 0.7949323894220001, "whi": 3.54206529141, "cheat": 3.4559577128199996, "support": 1.1894030501850001, "play": 0.38110439064199997, "mani": 0.1732630324884, "over": 0.0498734429914, "age": 1.1887453590090002, "analysi": 8.72626372044, "explain": 0.955700427358, "mine": 6.33723634712, "select": 0.704804687133, "whoa": 7.033506484289999, "nope": 7.2746685411000005, "same": 0.224119299208, "thread": 3.18792857827, "there": 0.12029367877649999, "coolest": 4.70971918364, "inform": 0.908907409324, "stick": 17.119394567869996, "misclassif": 7.2746685411000005, "nearest": 2.71792494902, "semisupervis": 7.2746685411000005, "best": 1.836911731788, "repres": 3.080617862, "right": 0.68071970834, "given": 0.9097674324930001, "membership": 3.9157726802, "take": 0.522767848788, "visual": 3.3078766977200003, "follow": 0.045356911094199995, "now": 0.8945576701260001, "might": 3.0733643061360003, "tri": 0.61759152916, "name": 0.09723316638430002, "cholesterol": 9.962431863339999, "singlepass": 7.2746685411000005, "simplic": 6.4728268910599995, "high": 0.27564757308000004, "basic": 1.00436774895, "edg": 2.9889727000999997, "issu": 0.364099043934, "also": 0.0879429468, "dealt": 2.42263827718, "specifi": 5.80353454863, "simplest": 6.6679394713999995, "around": 0.19387710578200001, "mean": 0.37092128352, "task": 2.71497361322, "first": 0.030349159248639998, "the": 0.0, "may": 0.050709995284400004, "certain": 0.592104362781, "becom": 0.11771217648900001, "reallif": 7.2746685411000005, "prune": 14.63031980493, "want": 2.7665464250199996, "system": 0.65486069117, "centroid": 53.414652322799995, "tumor": 8.11158543248, "various": 0.8607795002099999, "although": 0.139487981418, "attribut": 6.1418575768500006, "weka": 7.2746685411000005, "histori": 0.375101248138, "maxim": 2.5594217052, "which": 0.02589206922715, "such": 0.059695977806, "yuval": 6.2068279111, "thus": 0.49857627139300004, "other": 0.05924848751856, "techniqu": 1.31624384807, "one": 0.037532109873, "fast": 1.5836950247400001, "hope": 1.83964860891, "see": 0.240921585492, "hyperplan": 88.16849672813, "algorithm": 23.31309676626, "becaus": 0.139343158825, "outlier": 5.59502637, "closest": 8.67048698204, "highlevel": 7.2746685411000005, "get": 6.377459063602, "still": 0.17112222142900002, "like": 0.83432145927, "orang": 2.1047012084400003, "implement": 5.09751763628, "wonder": 5.94957811911, "equidist": 5.19522699942, "except": 0.54202451213, "opensourc": 14.549337082200001, "part": 0.08479062196560001, "attempt": 0.7734899615019999, "mitig": 3.1272141535699998, "cool": 1.9253988473800001, "repeat": 1.0567930591299999, "tabl": 13.4049610661, "pick": 1.59729226761, "this": 0.09087477726, "choic": 1.14166497543, "top": 0.609100637788, "rang": 0.579319213803, "discret": 8.12528460444, "process": 0.527829199025, "chang": 0.332551250116, "wait": 3.03210717564, "perform": 0.85236170116, "survey": 1.3294859427299999, "project": 1.123203771814, "differ": 0.424642242624, "numcm": 20.8935408384, "tell": 1.21236434401, "most": 0.041495792591199995, "between": 0.06790736233059999, "everi": 0.391485427421, "definit": 1.1755733298, "java": 3.45396369421, "along": 0.260344385917, "all": 0.057013160488999994, "apach": 4.20873200888, "mix": 2.04868472016, "ton": 2.35402426534, "someth": 2.37661424546, "libsvm": 7.2746685411000005, "case": 0.790812537778, "that": 0.039761483796399995, "overlook": 2.43406697301, "call": 0.3927766466928, "cluster": 58.09320759235, "object": 0.853933584803, "more": 0.10214958959999998, "and": 0.0023306352563532, "list": 0.619691523012, "correspond": 1.20141456099, "hyperwhat": 7.2746685411000005, "respect": 0.49733261904, "smooth": 2.4057364663799996, "hang": 2.11822899018, "pressur": 5.47420061375, "gain": 0.6142097989249999, "general": 0.229905156126, "faster": 2.03003967967, "sensit": 4.272399751, "comment": 1.11826753454, "gene": 2.2923080254799997, "can": 2.597457542304, "avail": 0.547454586289, "workaround": 6.009002167769999, "describ": 0.77089520625, "make": 0.07349765782289999, "few": 0.275577913653, "way": 0.9904575496750001, "onli": 0.025324268329099998, "each": 1.73741689304, "size": 0.9138372060609999, "eas": 2.202339678, "subclust": 7.2746685411000005, "two": 0.0136988443582, "data": 31.6373352048, "oper": 0.882685928694, "nongroup": 7.2746685411000005, "mahout": 7.2746685411000005, "rather": 0.885429951078, "sinc": 0.2411045983731, "explan": 1.87322041569, "must": 0.653383947388, "exampl": 4.086826749989999, "opentox": 7.2746685411000005, "dimension": 7.98478240978, "understand": 1.0880858756799998, "variat": 1.5484132106, "decis": 10.011406882047998, "sail": 2.07116147932, "nice": 2.8768580387299996, "generat": 1.438364683472, "while": 0.04324998379380001, "plain": 1.70459063424, "often": 0.258140393351, "bay": 1.5325398614399999, "learn": 5.899264453215, "when": 0.0411099777168, "effici": 1.62793753414}, "logidf": {"equival": 1.40897338129, "arguabl": 2.5594217052, "fall": 0.527402167952, "onc": 0.403765872355, "too": 0.5965551547219999, "readabl": 4.31597753923, "label": 1.49898832727, "red": 0.798535691347, "new": 0.0177299468511, "space": 0.874713164972, "addit": 0.220218882972, "would": 0.0796176279647, "number": 0.0966085784186, "knn": 7.2746685411000005, "etc": 1.4366730879700003, "dataset": 5.26584456664, "function": 0.914465741594, "class": 0.7497721899330001, "belong": 1.2527629685, "pagerank": 7.2746685411000005, "unsupervis": 5.843922417409999, "whether": 0.791561189647, "tree": 1.41777488775, "teach": 1.38277323072, "path": 1.5351679838499999, "sell": 1.25585416107, "higher": 0.752308398995, "know": 0.952919694398, "their": 0.015360505122700001, "yep": 7.033506484289999, "won": 0.8404139079, "sheet": 2.15287140979, "particular": 0.323157393804, "measur": 0.880014199726, "creat": 0.222576818514, "express": 0.648191639641, "vector": 3.25419887797, "how": 0.47156695693000006, "lunch": 3.1214834788599997, "bunch": 3.70130197411, "had": 0.0464780244111, "especi": 0.511098609709, "initi": 0.30010459245, "converg": 2.7275127501800003, "end": 0.101476798618, "found": 0.107841124048, "correl": 2.57915918803, "lift": 1.8529275115400001, "form": 0.120053184191, "interest": 0.47207177798199995, "color": 1.3417002006799998, "will": 0.202786534915, "associ": 0.28240501535100004, "flowchart": 7.2746685411000005, "dimensions\u2026": 7.2746685411000005, "second": 0.10713976337999999, "incorpor": 0.9664045229739999, "next": 0.402163685499, "similar": 0.318556092114, "but": 0.0161923720719, "throw": 2.12770274524, "adaboost": 7.2746685411000005, "need": 0.362740163442, "classif": 2.08779073629, "longer": 0.7046772417749999, "final": 0.292733863948, "point": 0.23103235903299998, "naiv": 3.9168216003199996, "key": 0.82419811896, "bottom": 1.8361940533599999, "level": 0.503462189943, "has": 0.0427239448548, "have": 0.0147850023412, "theorem": 3.58806440083, "impress": 1.3621488197100002, "today": 0.559395353679, "use": 0.0292080197316, "optim": 2.4456277954099996, "resourc": 1.08137694258, "onlin": 0.957503854357, "reddit": 6.27136643224, "out": 0.0584263909193, "quit": 1.05951513684, "member": 0.278153414599, "panel": 2.02477776846, "cours": 0.765899404133, "absolut": 1.67658333914, "julia": 3.04320056047, "togeth": 0.458032237308, "not": 0.0155524130075, "far": 0.536623764503, "are": 0.0294674735827, "decreas": 1.50919249744, "quick": 0.790727508899, "plane": 1.85776038441, "english": 0.555765186335, "than": 0.0322608622182, "then": 0.08303386523089999, "complic": 1.7312682430000002, "separ": 0.470759772949, "they": 0.0297269947676, "design": 0.377239118022, "anoth": 0.127896361652, "blue": 1.1217424415100001, "turn": 0.324899251064, "cancer": 2.08070209901, "let": 1.2488025672799998, "world": 0.107420248621, "blog": 2.65237310559, "construct": 0.658603355972, "away": 0.615957541869, "featur": 0.423387418142, "apriori": 7.2746685411000005, "blood": 1.5579399274799999, "simpl": 1.2232212893899999, "until": 0.138474663439, "provid": 0.19517784432500002, "valu": 0.823193310148, "coordin": 1.73269223754, "stabil": 1.8020159694, "pattern": 1.33282404788, "checkout": 5.647212123169999, "those": 0.17854939087299998, "explor": 1.22257937218, "without": 0.258874517941, "lot": 1.4835969502500002, "some": 0.0395735090645, "synonym": 2.6971498864499996, "forth": 2.1577640534099998, "both": 0.050842533389300004, "locat": 0.46854337067199997, "super": 1.9988756846400002, "result": 0.136378908381, "supervis": 2.04648105583, "subreddit": 7.2746685411000005, "set": 0.171496011289, "third": 0.35032434942900004, "ani": 0.125608358366, "question": 0.790310929014, "trick": 2.6897010624299997, "divid": 0.8402679544589999, "improv": 0.7147958039319999, "from": 0.000567054168866, "favorites\u2026": 7.2746685411000005, "patient": 2.25618533471, "num": 0.00031499039539700004, "puls": 3.12865196834, "aren": 6.17605625244, "free": 0.5412666492670001, "left": 0.364552414753, "equat": 2.27930071914, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "output": 2.03822657827, "closer": 1.7167880323700002, "with": 0.00119749171339, "these": 0.0715336194008, "kmean": 7.2746685411000005, "max": 2.01150743154, "better": 0.6964279406, "distanc": 1.24573306257, "frequent": 0.7443211360850001, "look": 0.6463866936, "popular": 0.41058020877499996, "chanc": 1.44572292349, "surfac": 1.3797649557, "think": 1.06717661175, "work": 0.109034567273, "center": 0.555216308776, "capabl": 1.2969341868100002, "versus": 2.05087881518, "map": 1.40434493384, "group": 0.190594534797, "doe": 0.5340417297169999, "even": 0.152388564834, "straight": 1.82519197774, "could": 0.18595627229000003, "raymond": 2.39739149445, "vote": 1.09899028905, "side": 0.46934876686899996, "scipi": 7.2746685411000005, "place": 0.0957070839572, "great": 0.235805258079, "told": 1.14879230713, "step": 1.03954505698, "move": 0.255615859253, "continu": 0.13040487398700001, "type": 0.707101485387, "multidimension": 5.0774439637699995, "note": 0.353817568083, "margin": 1.81934742575, "thing": 0.8781935346799999, "machin": 1.39235958062, "into": 0.0149128632287, "paper": 0.979402539665, "dimens": 2.11092206831, "rapid": 0.965411638564, "where": 0.0649921387457, "figur": 0.7101721121600001, "what": 0.225887296827, "suppos": 1.44225301477, "relationship": 0.871847185184, "overfit": 7.2746685411000005, "interpret": 1.1678481440000001, "influenti": 1.50862285915, "help": 0.336207721344, "larg": 0.17037506060600002, "find": 0.547781330288, "line": 0.349430614452, "own": 0.164195077421, "base": 0.13652330228700002, "deal": 0.780914701253, "fact": 0.5502899207949999, "tool": 1.60887117963, "due": 0.21341214386399998, "post": 0.8057001527009999, "here": 0.8850381883700001, "incomplet": 2.70089520918, "human": 0.640035183243, "thrown": 2.4940183301400003, "greater": 0.764545491118, "contain": 0.468845318236, "care": 0.9139943029109999, "about": 0.0628434774746, "threshold": 3.1358722163099997, "scikitlearn": 7.2746685411000005, "out\u2026": 7.2746685411000005, "mind": 1.2786688388299998, "sure": 2.0086865552, "just": 0.289531434109, "springboard": 4.91038987911, "preclust": 7.2746685411000005, "air": 0.668755727436, "she": 0.7701082216959999, "classifi": 1.6665296351499999, "weak": 1.5487095508000002, "expens": 1.26563201674, "clustering\u2026": 7.2746685411000005, "ball": 1.8930968464400002, "rest": 0.671587369833, "train": 0.660918312839, "massiv": 1.44118776833, "start": 0.236443369291, "love": 1.08958288195, "them": 0.0941833269093, "word": 0.585861082385, "alreadi": 0.670478380747, "keep": 0.7141523446729999, "observ": 0.7995160149320001, "order": 0.22014038079300002, "kernel": 4.2564634117, "famili": 0.39746619471100003, "whi": 1.18068843047, "cheat": 3.4559577128199996, "support": 0.237880610037, "play": 0.38110439064199997, "mani": 0.0433157581221, "over": 0.0249367214957, "age": 0.39624845300300005, "analysi": 1.2466091029200002, "explain": 0.955700427358, "mine": 1.58430908678, "select": 0.704804687133, "whoa": 7.033506484289999, "nope": 7.2746685411000005, "same": 0.112059649604, "thread": 3.18792857827, "there": 0.0400978929255, "coolest": 4.70971918364, "inform": 0.454453704662, "stick": 2.4456277954099996, "misclassif": 7.2746685411000005, "nearest": 2.71792494902, "semisupervis": 7.2746685411000005, "best": 0.459227932947, "repres": 0.38507723275, "right": 0.34035985417, "given": 0.303255810831, "membership": 1.9578863401, "take": 0.130691962197, "visual": 1.6539383488600001, "follow": 0.045356911094199995, "now": 0.149092945021, "might": 0.7683410765340001, "tri": 0.61759152916, "name": 0.09723316638430002, "cholesterol": 4.9812159316699995, "singlepass": 7.2746685411000005, "simplic": 3.2364134455299998, "high": 0.13782378654000002, "basic": 1.00436774895, "edg": 1.4944863500499999, "issu": 0.364099043934, "also": 0.0146571578, "dealt": 2.42263827718, "specifi": 1.93451151621, "simplest": 3.3339697356999998, "around": 0.19387710578200001, "mean": 0.37092128352, "task": 1.35748680661, "first": 0.0075872898121599995, "the": 0.0, "may": 0.050709995284400004, "certain": 0.592104362781, "becom": 0.11771217648900001, "reallif": 7.2746685411000005, "prune": 4.87677326831, "want": 0.6916366062549999, "system": 0.327430345585, "centroid": 6.676831540349999, "tumor": 4.05579271624, "various": 0.28692650007, "although": 0.139487981418, "attribut": 1.2283715153700001, "weka": 7.2746685411000005, "histori": 0.187550624069, "maxim": 2.5594217052, "which": 0.00517841384543, "such": 0.059695977806, "yuval": 6.2068279111, "thus": 0.49857627139300004, "other": 0.00987474791976, "techniqu": 1.31624384807, "one": 0.0062553516455, "fast": 1.5836950247400001, "hope": 0.919824304455, "see": 0.240921585492, "hyperplan": 6.7821920560099995, "algorithm": 3.33044239518, "becaus": 0.139343158825, "outlier": 5.59502637, "closest": 2.16762174551, "highlevel": 7.2746685411000005, "get": 0.579769005782, "still": 0.17112222142900002, "like": 0.139053576545, "orang": 2.1047012084400003, "implement": 1.27437940907, "wonder": 1.98319270637, "equidist": 5.19522699942, "except": 0.54202451213, "opensourc": 7.2746685411000005, "part": 0.04239531098280001, "attempt": 0.38674498075099994, "mitig": 3.1272141535699998, "cool": 1.9253988473800001, "repeat": 1.0567930591299999, "tabl": 1.34049610661, "pick": 1.59729226761, "this": 0.0037864490525, "choic": 1.14166497543, "top": 0.609100637788, "rang": 0.579319213803, "discret": 2.70842820148, "process": 0.527829199025, "chang": 0.166275625058, "wait": 1.51605358782, "perform": 0.42618085058, "survey": 1.3294859427299999, "project": 0.561601885907, "differ": 0.212321121312, "numcm": 6.964513612799999, "tell": 1.21236434401, "most": 0.020747896295599998, "between": 0.033953681165299995, "everi": 0.391485427421, "definit": 1.1755733298, "java": 3.45396369421, "along": 0.260344385917, "all": 0.011402632097799998, "apach": 4.20873200888, "mix": 1.02434236008, "ton": 2.35402426534, "someth": 1.18830712273, "libsvm": 7.2746685411000005, "case": 0.395406268889, "that": 0.00397614837964, "overlook": 2.43406697301, "call": 0.0654627744488, "cluster": 2.52579163445, "object": 0.853933584803, "more": 0.017024931599999998, "and": 6.29901420636e-05, "list": 0.309845761506, "correspond": 1.20141456099, "hyperwhat": 7.2746685411000005, "respect": 0.49733261904, "smooth": 2.4057364663799996, "hang": 2.11822899018, "pressur": 1.09484012275, "gain": 0.6142097989249999, "general": 0.114952578063, "faster": 2.03003967967, "sensit": 2.1361998755, "comment": 1.11826753454, "gene": 2.2923080254799997, "can": 0.162341096394, "avail": 0.547454586289, "workaround": 6.009002167769999, "describ": 0.385447603125, "make": 0.07349765782289999, "few": 0.275577913653, "way": 0.19809150993500002, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "eas": 2.202339678, "subclust": 7.2746685411000005, "two": 0.0136988443582, "data": 1.2168205848, "oper": 0.441342964347, "nongroup": 7.2746685411000005, "mahout": 7.2746685411000005, "rather": 0.442714975539, "sinc": 0.0803681994577, "explan": 1.87322041569, "must": 0.653383947388, "exampl": 0.40868267499899996, "opentox": 7.2746685411000005, "dimension": 3.99239120489, "understand": 1.0880858756799998, "variat": 1.5484132106, "decis": 0.7701082216959999, "sail": 2.07116147932, "nice": 2.8768580387299996, "generat": 0.719182341736, "while": 0.04324998379380001, "plain": 1.70459063424, "often": 0.258140393351, "bay": 1.5325398614399999, "learn": 0.842752064745, "when": 0.0205549888584, "effici": 1.62793753414}, "freq": {"equival": 1, "arguabl": 1, "fall": 1, "onc": 3, "too": 1, "readabl": 1, "label": 1, "red": 5, "new": 6, "space": 2, "addit": 1, "would": 2, "number": 2, "knn": 1, "etc": 4, "dataset": 9, "function": 3, "class": 12, "belong": 2, "pagerank": 1, "unsupervis": 4, "whether": 2, "tree": 13, "teach": 1, "path": 1, "sell": 2, "higher": 5, "know": 6, "their": 4, "yep": 1, "won": 4, "sheet": 2, "particular": 1, "measur": 2, "creat": 2, "express": 1, "vector": 8, "how": 7, "lunch": 1, "bunch": 3, "had": 1, "especi": 1, "initi": 1, "converg": 1, "end": 1, "found": 3, "correl": 1, "lift": 2, "form": 3, "interest": 1, "color": 2, "will": 6, "associ": 1, "flowchart": 3, "dimensions\u2026": 1, "second": 1, "incorpor": 1, "next": 3, "similar": 5, "but": 3, "throw": 1, "adaboost": 1, "need": 1, "classif": 1, "longer": 1, "final": 2, "point": 7, "naiv": 1, "key": 3, "bottom": 3, "level": 2, "has": 5, "have": 7, "theorem": 1, "impress": 1, "today": 1, "use": 21, "optim": 1, "resourc": 1, "onlin": 1, "reddit": 1, "out": 2, "quit": 2, "member": 5, "panel": 1, "cours": 1, "absolut": 1, "julia": 1, "togeth": 3, "not": 1, "far": 1, "are": 26, "decreas": 1, "quick": 1, "plane": 2, "english": 1, "than": 6, "then": 3, "complic": 1, "separ": 4, "they": 11, "design": 2, "anoth": 2, "blue": 5, "turn": 2, "cancer": 7, "let": 1, "world": 1, "blog": 1, "construct": 2, "away": 1, "featur": 1, "apriori": 1, "blood": 5, "simpl": 1, "until": 1, "provid": 1, "valu": 2, "coordin": 3, "stabil": 1, "pattern": 1, "checkout": 1, "those": 1, "explor": 2, "without": 2, "lot": 2, "some": 3, "synonym": 1, "forth": 1, "both": 1, "locat": 1, "super": 1, "result": 1, "supervis": 5, "subreddit": 1, "set": 4, "third": 1, "ani": 1, "question": 1, "trick": 2, "divid": 1, "improv": 1, "from": 9, "favorites\u2026": 1, "patient": 27, "num": 34, "puls": 5, "aren": 1, "free": 1, "left": 1, "equat": 1, "for": 15, "depend": 2, "predict": 4, "output": 1, "closer": 1, "with": 11, "these": 7, "kmean": 19, "max": 2, "better": 1, "distanc": 2, "frequent": 1, "look": 1, "popular": 4, "chanc": 1, "surfac": 1, "think": 2, "work": 4, "center": 2, "capabl": 1, "versus": 1, "map": 3, "group": 5, "doe": 8, "even": 1, "straight": 1, "could": 4, "raymond": 1, "vote": 1, "side": 1, "scipi": 1, "place": 1, "great": 2, "told": 2, "step": 1, "move": 1, "continu": 4, "type": 1, "multidimension": 2, "note": 1, "margin": 4, "thing": 7, "machin": 3, "into": 8, "paper": 3, "dimens": 9, "rapid": 1, "where": 5, "figur": 2, "what": 14, "suppos": 2, "relationship": 1, "overfit": 1, "interpret": 3, "influenti": 1, "help": 1, "larg": 3, "find": 4, "line": 7, "own": 3, "base": 2, "deal": 2, "fact": 1, "tool": 2, "due": 1, "post": 1, "here": 4, "incomplet": 1, "human": 1, "thrown": 1, "greater": 1, "contain": 1, "care": 2, "about": 8, "threshold": 1, "scikitlearn": 1, "out\u2026": 1, "mind": 1, "sure": 2, "just": 3, "springboard": 1, "preclust": 1, "air": 5, "she": 1, "classifi": 15, "weak": 2, "expens": 1, "clustering\u2026": 1, "ball": 25, "rest": 2, "train": 1, "massiv": 1, "start": 2, "love": 1, "them": 3, "word": 1, "alreadi": 1, "keep": 1, "observ": 2, "order": 1, "kernel": 2, "famili": 2, "whi": 3, "cheat": 1, "support": 5, "play": 1, "mani": 4, "over": 2, "age": 3, "analysi": 7, "explain": 1, "mine": 4, "select": 1, "whoa": 1, "nope": 1, "same": 2, "thread": 1, "there": 3, "coolest": 1, "inform": 2, "stick": 7, "misclassif": 1, "nearest": 1, "semisupervis": 1, "best": 4, "repres": 8, "right": 2, "given": 3, "membership": 2, "take": 4, "visual": 2, "follow": 1, "now": 6, "might": 4, "tri": 1, "name": 1, "cholesterol": 2, "singlepass": 1, "simplic": 2, "high": 2, "basic": 1, "edg": 2, "issu": 1, "also": 6, "dealt": 1, "specifi": 3, "simplest": 2, "around": 1, "mean": 1, "task": 2, "first": 4, "the": 119, "may": 1, "certain": 1, "becom": 1, "reallif": 1, "prune": 3, "want": 4, "system": 2, "centroid": 8, "tumor": 2, "various": 3, "although": 1, "attribut": 5, "weka": 1, "histori": 2, "maxim": 1, "which": 5, "such": 1, "yuval": 1, "thus": 1, "other": 6, "techniqu": 1, "one": 6, "fast": 1, "hope": 2, "see": 1, "hyperplan": 13, "algorithm": 7, "becaus": 1, "outlier": 1, "closest": 4, "highlevel": 1, "get": 11, "still": 1, "like": 6, "orang": 1, "implement": 4, "wonder": 3, "equidist": 1, "except": 1, "opensourc": 2, "part": 2, "attempt": 2, "mitig": 1, "cool": 1, "repeat": 1, "tabl": 10, "pick": 1, "this": 24, "choic": 1, "top": 1, "rang": 1, "discret": 3, "process": 1, "chang": 2, "wait": 2, "perform": 2, "survey": 1, "project": 2, "differ": 2, "numcm": 3, "tell": 1, "most": 2, "between": 2, "everi": 1, "definit": 1, "java": 1, "along": 1, "all": 5, "apach": 1, "mix": 2, "ton": 1, "someth": 2, "libsvm": 1, "case": 2, "that": 10, "overlook": 1, "call": 6, "cluster": 23, "object": 1, "more": 6, "and": 37, "list": 2, "correspond": 1, "hyperwhat": 1, "respect": 1, "smooth": 1, "hang": 1, "pressur": 5, "gain": 1, "general": 2, "faster": 1, "sensit": 2, "comment": 1, "gene": 1, "can": 16, "avail": 1, "workaround": 1, "describ": 2, "make": 1, "few": 1, "way": 5, "onli": 1, "each": 10, "size": 1, "eas": 1, "subclust": 1, "two": 1, "data": 26, "oper": 2, "nongroup": 1, "mahout": 1, "rather": 2, "sinc": 3, "explan": 1, "must": 1, "exampl": 10, "opentox": 1, "dimension": 2, "understand": 1, "variat": 1, "decis": 13, "sail": 1, "nice": 1, "generat": 2, "while": 1, "plain": 1, "often": 1, "bay": 1, "learn": 7, "when": 2, "effici": 1}, "idf": {"equival": 4.09175257732, "arguabl": 12.928338762200001, "fall": 1.6945244956799999, "onc": 1.4974533106999999, "too": 1.81585268215, "readabl": 74.8867924528, "label": 4.47715736041, "red": 2.22228443449, "new": 1.0178880554, "space": 2.39818731118, "addit": 1.24634950542, "would": 1.0828729281799998, "number": 1.10142916609, "knn": 1443.27272727, "etc": 4.2066772655, "dataset": 193.609756098, "function": 2.495441685, "class": 2.11651779763, "belong": 3.5, "pagerank": 1443.27272727, "unsupervis": 345.13043478300006, "whether": 2.20683903253, "tree": 4.127925117, "teach": 3.98594024605, "path": 4.6421052631599995, "sell": 3.51083591331, "higher": 2.1218925421, "know": 2.59327017315, "their": 1.01547908405, "yep": 1134.0, "won": 2.31732593782, "sheet": 8.60954446855, "particular": 1.3814827706200001, "measur": 2.41093394077, "creat": 1.2492917847, "express": 1.9120799710900003, "vector": 25.898858075, "how": 1.60250328051, "lunch": 22.68, "bunch": 40.5, "had": 1.0475750577399998, "especi": 1.66712170534, "initi": 1.35, "converg": 15.2947976879, "end": 1.10680423871, "found": 1.11387076405, "correl": 13.1860465116, "lift": 6.37846524709, "form": 1.12755681818, "interest": 1.60331246213, "color": 3.8255421686699997, "will": 1.22481098596, "associ": 1.3263157894700002, "flowchart": 1443.27272727, "dimensions\u2026": 1443.27272727, "second": 1.1130898128, "incorpor": 2.62847682119, "next": 1.4950560316400001, "similar": 1.37514075357, "but": 1.01632417899, "throw": 8.39555790587, "adaboost": 1443.27272727, "need": 1.4372623574099999, "classif": 8.067073170730001, "longer": 2.02319357716, "final": 1.34008609775, "point": 1.25990000794, "naiv": 50.2405063291, "key": 2.28005170185, "bottom": 6.27261951798, "level": 1.6544393497299998, "has": 1.0436497502, "have": 1.0148948411399998, "theorem": 36.164009111599995, "impress": 3.90457452041, "today": 1.74961428257, "use": 1.0296387573799999, "optim": 11.5377906977, "resourc": 2.9487369985100003, "onlin": 2.6051854282900004, "reddit": 529.2, "out": 1.06016694491, "quit": 2.8849718335500003, "member": 1.32068879461, "panel": 7.57442748092, "cours": 2.15092805853, "absolut": 5.3472549680000006, "julia": 20.9722589168, "togeth": 1.58095996813, "not": 1.01567398119, "far": 1.71022298826, "are": 1.02990593578, "decreas": 4.5230769230800005, "quick": 2.205, "plane": 6.40936616875, "english": 1.7432744043000001, "than": 1.03278688525, "then": 1.08657860516, "complic": 5.6478121664900005, "separ": 1.6012102874399998, "they": 1.03017325287, "design": 1.45825296225, "anoth": 1.13643521832, "blue": 3.07019918778, "turn": 1.3838912133899999, "cancer": 8.01009081736, "let": 3.48616600791, "world": 1.11340206186, "blog": 14.1876675603, "construct": 1.9320920043799998, "away": 1.85142857143, "featur": 1.52712581762, "apriori": 1443.27272727, "blood": 4.74902781932, "simpl": 3.3981164383599998, "until": 1.14852058164, "provid": 1.21552714187, "valu": 2.2777618364400003, "coordin": 5.65586034913, "stabil": 6.0618556701, "pattern": 3.79173632673, "checkout": 283.5, "those": 1.19548192771, "explor": 3.39593582888, "without": 1.29547123623, "lot": 4.40877534018, "some": 1.04036697248, "synonym": 14.8373831776, "forth": 8.65177111717, "both": 1.05215720061, "locat": 1.59766529134, "super": 7.380753138080001, "result": 1.14611608432, "supervis": 7.74061433447, "subreddit": 1443.27272727, "set": 1.18707940781, "third": 1.4195278969999998, "ani": 1.13383802314, "question": 2.20408163265, "trick": 14.7272727273, "divid": 2.3169877408099997, "improv": 2.04376930999, "from": 1.00056721497, "favorites\u2026": 1443.27272727, "patient": 9.54660252556, "num": 1.00031504001, "puls": 22.843165467600002, "aren": 481.09090909099996, "free": 1.71818181818, "left": 1.4398693996, "equat": 9.76984615385, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "output": 7.676982591880001, "closer": 5.5666199158500005, "with": 1.0011982089899998, "these": 1.07415426252, "kmean": 1443.27272727, "max": 7.474576271189999, "better": 2.0065722952500002, "distanc": 3.4754816112099998, "frequent": 2.10501193317, "look": 1.9086318826599997, "popular": 1.50769230769, "chanc": 4.2449197861000005, "surfac": 3.97396745932, "think": 2.90715986083, "work": 1.11520089913, "center": 1.7423178226499998, "capabl": 3.6580645161300005, "versus": 7.77473065622, "map": 4.0728578758300005, "group": 1.20996875238, "doe": 1.70581282905, "even": 1.16461267606, "straight": 6.203985932, "could": 1.2043695949, "raymond": 10.9944598338, "vote": 3.0011342155, "side": 1.5989525632, "scipi": 1443.27272727, "place": 1.1004366812200002, "great": 1.26592775696, "told": 3.1543810848400002, "step": 2.8279301745599996, "move": 1.29125660838, "continu": 1.13928955867, "type": 2.0281042411900003, "multidimension": 160.363636364, "note": 1.42449528937, "margin": 6.16783216783, "thing": 2.4065484311099996, "machin": 4.02433460076, "into": 1.01502461479, "paper": 2.6628648104700003, "dimens": 8.25585023401, "rapid": 2.62586834271, "where": 1.06715063521, "figur": 2.0343413634, "what": 1.25343439128, "suppos": 4.23021582734, "relationship": 2.39132399458, "overfit": 1443.27272727, "interpret": 3.2150668286799995, "influenti": 4.520501138949999, "help": 1.39962972759, "larg": 1.18574949585, "find": 1.7294117647099998, "line": 1.4182597820299998, "own": 1.17844418052, "base": 1.14628158845, "deal": 2.18346857379, "fact": 1.73375559681, "tool": 4.99716713881, "due": 1.23789473684, "post": 2.23826307627, "here": 2.42307692308, "incomplet": 14.8930581614, "human": 1.8965476048299998, "thrown": 12.109839816900001, "greater": 2.14801785956, "contain": 1.59814777532, "care": 2.49426551453, "about": 1.06486015159, "threshold": 23.008695652199997, "scikitlearn": 1443.27272727, "out\u2026": 1443.27272727, "mind": 3.5918552036199998, "sure": 7.453521126760001, "just": 1.33580143037, "springboard": 135.692307692, "preclust": 1443.27272727, "air": 1.9518072289200001, "she": 2.16, "classifi": 5.2937645882, "weak": 4.70539419087, "expens": 3.5453327378300004, "clustering\u2026": 1443.27272727, "ball": 6.63989962359, "rest": 1.9573418813999999, "train": 1.9365698950999999, "massiv": 4.22571200426, "start": 1.26673581744, "love": 2.97303370787, "them": 1.09876115994, "word": 1.7965372864099998, "alreadi": 1.9551724137900002, "keep": 2.04245465071, "observ": 2.22446406053, "order": 1.24625166811, "kernel": 70.56, "famili": 1.48804948917, "whi": 3.2566153846200003, "cheat": 31.6886227545, "support": 1.2685577307200002, "play": 1.46390041494, "mani": 1.04426757877, "over": 1.02525024217, "age": 1.48623853211, "analysi": 3.47852760736, "explain": 2.60049140049, "mine": 4.875921375919999, "select": 2.02345144022, "whoa": 1134.0, "nope": 1443.27272727, "same": 1.11857958148, "thread": 24.2381679389, "there": 1.04091266719, "coolest": 111.020979021, "inform": 1.5753125620200001, "stick": 11.5377906977, "misclassif": 1443.27272727, "nearest": 15.148854961800001, "semisupervis": 1443.27272727, "best": 1.5828514456600002, "repres": 1.46972782818, "right": 1.4054532577899999, "given": 1.35426085473, "membership": 7.0843373494, "take": 1.13961668222, "visual": 5.22752716497, "follow": 1.04640126549, "now": 1.160780873, "might": 2.1561863370900003, "tri": 1.8544562551099997, "name": 1.10211732037, "cholesterol": 145.651376147, "singlepass": 1443.27272727, "simplic": 25.4423076923, "high": 1.14777327935, "basic": 2.7301805675, "edg": 4.45704660303, "issu": 1.43921675279, "also": 1.01476510067, "dealt": 11.2755681818, "specifi": 6.920662598080001, "simplest": 28.0494699647, "around": 1.21394708671, "mean": 1.44906900329, "task": 3.88641370869, "first": 1.00761614623, "the": 1.0, "may": 1.05201775893, "certain": 1.8077886586200003, "becom": 1.12492028626, "reallif": 1443.27272727, "prune": 131.20661157, "want": 1.99698113208, "system": 1.38739840951, "centroid": 793.8, "tumor": 57.7309090909, "various": 1.3323262839899999, "although": 1.14968498805, "attribut": 3.4156626506, "weka": 1443.27272727, "histori": 1.20629131525, "maxim": 12.928338762200001, "which": 1.005191845, "such": 1.06151377374, "yuval": 496.125, "thus": 1.6463756092500001, "other": 1.00992366412, "techniqu": 3.7293868921800004, "one": 1.00627495722, "fast": 4.8729281768, "hope": 2.50884955752, "see": 1.27242125511, "hyperplan": 882.0, "algorithm": 27.9507042254, "becaus": 1.1495184997499999, "outlier": 269.084745763, "closest": 8.73747936159, "highlevel": 1443.27272727, "get": 1.78562591385, "still": 1.1866357724799999, "like": 1.14918566775, "orang": 8.204651162789999, "implement": 3.57648118946, "wonder": 7.265903890160001, "equidist": 180.409090909, "except": 1.71948445792, "opensourc": 1443.27272727, "part": 1.04330682789, "attempt": 1.4721810088999998, "mitig": 22.8103448276, "cool": 6.8578833693300005, "repeat": 2.8771293947099994, "tabl": 3.82093862816, "pick": 4.939639079030001, "this": 1.00379362671, "choic": 3.1319786940200003, "top": 1.8387769284200002, "rang": 1.7848229342299997, "discret": 15.0056710775, "process": 1.69524826482, "chang": 1.1808985421, "wait": 4.55421686747, "perform": 1.5313977042500002, "survey": 3.7791002142300005, "project": 1.7534791252500002, "differ": 1.23654490225, "numcm": 1058.4, "tell": 3.36142282448, "most": 1.02096463023, "between": 1.03453668708, "everi": 1.47917637194, "definit": 3.24, "java": 31.625498008, "along": 1.2973768080399999, "all": 1.01146788991, "apach": 67.27118644069999, "mix": 2.7852631578900002, "ton": 10.5278514589, "someth": 3.28152128979, "libsvm": 1443.27272727, "case": 1.48498737256, "that": 1.00398406375, "overlook": 11.4051724138, "call": 1.0676529926, "cluster": 12.5007874016, "object": 2.3488681757700003, "more": 1.0171706817, "and": 1.00006299213, "list": 1.36321483771, "correspond": 3.32481675393, "hyperwhat": 1443.27272727, "respect": 1.6443293630200002, "smooth": 11.086592178800002, "hang": 8.31639601886, "pressur": 2.9887048192799996, "gain": 1.84819557625, "general": 1.1218202374200001, "faster": 7.61438848921, "sensit": 8.4672, "comment": 3.05954904606, "gene": 9.89775561097, "can": 1.17626139142, "avail": 1.7288467821, "workaround": 407.07692307699995, "describ": 1.47027227264, "make": 1.0762660158600001, "few": 1.31729173581, "way": 1.2190739461, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "eas": 9.04615384615, "subclust": 1443.27272727, "two": 1.01379310345, "data": 3.37643555934, "oper": 1.55479384977, "nongroup": 1443.27272727, "mahout": 1443.27272727, "rather": 1.55692850838, "sinc": 1.08368600683, "explan": 6.50922509225, "must": 1.9220338983099996, "exampl": 1.50483412322, "opentox": 1443.27272727, "dimension": 54.1843003413, "understand": 2.96858638743, "variat": 4.704, "decis": 2.16, "sail": 7.934032983510001, "nice": 17.7583892617, "generat": 2.05275407292, "while": 1.0441988950299999, "plain": 5.49913404919, "often": 1.29452054795, "bay": 4.629921259840001, "learn": 2.32275054865, "when": 1.02076769755, "effici": 5.09335899904}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Top 10 Data Mining Algorithms, Explained</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Top 10 Data Mining Algorithms, Explained Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2015/05/reduce-data-hoarding-pca-visualization-decisions.html\" rel=\"prev\" title=\"How to reduce Data Hoarding, get Better Visualizations and Decisions\"/>\n<link href=\"https://www.kdnuggets.com/2015/05/trifacta-wrangling-us-flight-data-part2.html\" rel=\"next\" title=\"Trifacta \u2013 Wrangling US Flight Data, part 2\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=34190\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-34190 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 21-May, 2015  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2015/index.html\">2015</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/05/tutorials.html\">Tutorials, Overviews, How-Tos</a> \u00bb Top 10 Data Mining Algorithms, Explained (\u00a0<a href=\"/2015/n17.html\">15:n17</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Top 10 Data Mining Algorithms, Explained</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2015/05/reduce-data-hoarding-pca-visualization-decisions.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2015/05/trifacta-wrangling-us-flight-data-part2.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 1364</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/algorithms\" rel=\"tag\">Algorithms</a>, <a href=\"https://www.kdnuggets.com/tag/apriori\" rel=\"tag\">Apriori</a>, <a href=\"https://www.kdnuggets.com/tag/bayesian\" rel=\"tag\">Bayesian</a>, <a href=\"https://www.kdnuggets.com/tag/boosting\" rel=\"tag\">Boosting</a>, <a href=\"https://www.kdnuggets.com/tag/c4-5\" rel=\"tag\">C4.5</a>, <a href=\"https://www.kdnuggets.com/tag/cart\" rel=\"tag\">CART</a>, <a href=\"https://www.kdnuggets.com/tag/data-mining\" rel=\"tag\">Data Mining</a>, <a href=\"https://www.kdnuggets.com/tag/explained\" rel=\"tag\">Explained</a>, <a href=\"https://www.kdnuggets.com/tag/k-means\" rel=\"tag\">K-means</a>, <a href=\"https://www.kdnuggets.com/tag/k-nearest-neighbors\" rel=\"tag\">K-nearest neighbors</a>, <a href=\"https://www.kdnuggets.com/tag/naive-bayes\" rel=\"tag\">Naive Bayes</a>, <a href=\"https://www.kdnuggets.com/tag/page-rank\" rel=\"tag\">Page Rank</a>, <a href=\"https://www.kdnuggets.com/tag/support-vector-machines\" rel=\"tag\">Support Vector Machines</a>, <a href=\"https://www.kdnuggets.com/tag/top-10\" rel=\"tag\">Top 10</a></div>\n<br/>\n<p class=\"excerpt\">\n     Top 10 data mining algorithms, selected by top researchers, are explained here, including what do they do, the intuition behind the algorithm, available implementations of the algorithms, why use them, and interesting applications.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2015/05/top-10-data-mining-algorithms-explained.html/3#comments\">comments</a></div>\n<p><b>By <a href=\"http://rayli.net\">Raymond Li</a>.</b></p>\n<p>Today, I\u2019m going to explain in plain English the top 10 most influential data mining algorithms as voted on by 3 separate panels in this <a href=\"http://www.cs.uvm.edu/%7Eicdm/algorithms/10Algorithms-08.pdf\" target=\"_blank\" title=\"Top 10 algorithms in data mining\">survey paper</a>.</p>\n<p>Once you know what they are, how they work, what they do and where you can find them, my hope is you\u2019ll have this blog post as a springboard to learn even more about data mining.</p>\n<p>What are we waiting for? Let\u2019s get started!</p>\n<p><img alt=\"top-10-data-mining-algorithms\" class=\"alignnone size-full wp-image-34191\" height=\"259\" sizes=\"(max-width: 495px) 100vw, 495px\" src=\"/wp-content/uploads/top-10-data-mining-algorithms.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/top-10-data-mining-algorithms.jpg 495w, https://www.kdnuggets.com/wp-content/uploads/top-10-data-mining-algorithms-300x156.jpg 300w\" width=\"495\"/></p>\n<p>Here are the algorithms:</p>\n<ul>\n<li>1. C4.5</li>\n<li>2. k-means</li>\n<li>3. Support vector machines</li>\n<li>4. Apriori</li>\n<li>5. EM</li>\n<li>6. PageRank</li>\n<li>7. AdaBoost</li>\n<li>8. kNN</li>\n<li>9. Naive Bayes</li>\n<li>10. CART</li>\n</ul>\n<p>We also provide interesting resources at the end.</p>\n<h3><b>1. C4.5</b></h3>\n<p><strong>What does it do? </strong>C4.5 constructs a classifier in the form of a decision tree. In order to do this, C4.5 is given a set of data representing things that are already classified.</p>\n<p><strong>Wait, what\u2019s a classifier? </strong>A classifier is a tool in data mining that takes a bunch of data representing things we want to classify and attempts to predict which class the new data belongs to.</p>\n<p><strong>What\u2019s an example of this? </strong>Sure, suppose a dataset contains a bunch of patients. We know various things about each patient like age, pulse, blood pressure, VO<sub>2</sub>max, family history, etc. These are called attributes.</p>\n<p>Now:</p>\n<p>Given these attributes, we want to predict whether the patient will get cancer. The patient can fall into 1 of 2 classes: will get cancer or won\u2019t get cancer. C4.5 is told the class for each patient.</p>\n<p>And here\u2019s the deal:</p>\n<p>Using a set of patient attributes and the patient\u2019s corresponding class, C4.5 constructs a decision tree that can predict the class for new patients based on their attributes.</p>\n<p><strong>Cool, so what\u2019s a decision tree?</strong> Decision tree learning creates something similar to a flowchart to classify new data. Using the same patient example, one particular path in the flowchart could be:</p>\n<ul>\n<li>Patient has a history of cancer</li>\n<li>Patient is expressing a gene highly correlated with cancer patients</li>\n<li>Patient has tumors</li>\n<li>Patient\u2019s tumor size is greater than 5cm</li>\n</ul>\n<p>The bottom line is:</p>\n<p>At each point in the flowchart is a question about the value of some attribute, and depending on those values, he or she gets classified. You can find lots of <a href=\"https://www.google.com/search?q=c4.5+decision+tree&amp;tbm=isch\" target=\"_blank\" title=\"C4.5 Decision Trees (Google Images)\">examples of decision trees</a>.</p>\n<p><strong>Is this supervised or unsupervised?</strong> This is supervised learning, since the training dataset is labeled with classes. Using the patient example, C4.5 doesn\u2019t learn on its own that a patient will get cancer or won\u2019t get cancer. We told it first, it generated a decision tree, and now it uses the decision tree to classify.</p>\n<p><strong>You might be wondering how C4.5 is different than other decision tree systems?</strong></p>\n<ul>\n<li>First, C4.5 uses <a href=\"http://en.wikipedia.org/wiki/Entropy_%28information_theory%29\" target=\"_blank\" title=\"Entropy (Wikipedia)\">information gain</a> when generating the decision tree.</li>\n<li>Second, although other systems also incorporate pruning, C4.5 uses a <a href=\"http://www.cs.bc.edu/%7Ealvarez/ML/statPruning.html\" target=\"_blank\" title=\"Decision Tree Pruning based on Confidence Intervals\">single-pass pruning process</a> to mitigate over-fitting. Pruning results in <a href=\"http://stackoverflow.com/questions/10865372/why-does-the-c4-5-algorithm-use-pruning-in-order-to-reduce-the-decision-tree-and\" target=\"_blank\" title=\"Why does the C4.5 algorithm use pruning in order to reduce the decision tree and how does pruning affect the prediction accuracy?\">many improvements</a>.</li>\n<li>Third, C4.5 can work with both continuous and discrete data. My understanding is it does this by specifying ranges or thresholds for continuous data thus turning continuous data into discrete data.</li>\n<li>Finally, incomplete data is dealt with in <a href=\"http://stats.stackexchange.com/questions/96025/how-do-decision-tree-learning-algorithms-deal-with-missing-values-under-the-hoo\" target=\"_blank\" title=\"How do decision tree learning algorithms deal with missing values (under the hood)\">its own ways</a>.</li>\n</ul>\n<p><strong>Why use C4.5?</strong> Arguably, the best selling point of decision trees is their ease of interpretation and explanation. They are also quite fast, quite popular and the output is <a href=\"https://www.google.com/search?q=j4.8+output&amp;tbm=isch\" target=\"_blank\" title=\"J4.8 Output (Google Images)\">human readable</a>.</p>\n<p><strong>Where is it used? </strong>A popular open-source Java implementation can be found over at <a href=\"http://www.opentox.org/dev/documentation/components/j48\" target=\"_blank\" title=\"J48 - OpenTox\">OpenTox</a>. <a href=\"http://orange.biolab.si/\" target=\"_blank\" title=\"Orange\">Orange</a>, an open-source data visualization and analysis tool for data mining, implements C4.5 in their decision tree classifier.</p>\n<p>Classifiers are great, but make sure to checkout the next algorithm about clustering\u2026</p>\n<h3><b>2. k-means</b></h3>\n<p><strong>What does it do? </strong>k-means creates <em>k</em> groups from a set of objects so that the members of a group are more similar. It\u2019s a popular cluster analysis technique for exploring a dataset.</p>\n<p><strong>Hang on, what\u2019s cluster analysis?</strong> Cluster analysis is a family of algorithms designed to form groups such that the group members are more similar versus non-group members. Clusters and groups are synonymous in the world of cluster analysis.</p>\n<p><strong>Is there an example of this? </strong>Definitely, suppose we have a dataset of patients. In cluster analysis, these would be called observations. We know various things about each patient like age, pulse, blood pressure, VO<sub>2</sub>max, cholesterol, etc. This is a vector representing the patient.</p>\n<p>Look:</p>\n<p>You can basically think of a vector as a list of numbers we know about the patient. This list can also be interpreted as coordinates in multi-dimensional space. Pulse can be one dimension, blood pressure another dimension and so forth.</p>\n<p>You might be wondering:</p>\n<p>Given this set of vectors, how do we cluster together patients that have similar age, pulse, blood pressure, etc?</p>\n<p>Want to know the best part?</p>\n<p>You tell k-means how many clusters you want. K-means takes care of the rest.</p>\n<p><strong>How does k-means take care of the rest?</strong> k-means has lots of variations to optimize for certain types of data.</p>\n<p>At a high level, they all do something like this:</p>\n<ol>\n<li>k-means picks points in multi-dimensional space to represent each of the k clusters. These are called centroids.</li>\n<li>Every patient will be closest to 1 of these k centroids. They hopefully won\u2019t all be closest to the same one, so they\u2019ll form a cluster around their nearest centroid.</li>\n<li>What we have are k clusters, and each patient is now a member of a cluster.</li>\n<li>k-means then finds the center for each of the k clusters based on its cluster members (yep, using the patient vectors!).</li>\n<li>This center becomes the new centroid for the cluster.</li>\n<li>Since the centroid is in a different place now, patients might now be closer to other centroids. In other words, they may change cluster membership.</li>\n<li>Steps 2-6 are repeated until the centroids no longer change, and the cluster memberships stabilize. This is called convergence.</li>\n</ol>\n<p><strong>Is this supervised or unsupervised?</strong> It depends, but most would classify k-means as unsupervised. Other than specifying the number of clusters, k-means \u201clearns\u201d the clusters on its own without any information about which cluster an observation belongs to. k-means can be <a href=\"https://www.google.com/search?q=semi+supervised+k+means\" target=\"_blank\" title=\"Semi supervised k means (Google)\">semi-supervised</a>.</p>\n<p><strong>Why use k-means?</strong> I don\u2019t think many will have an issue with this:</p>\n<p>The key selling point of k-means is its simplicity. Its simplicity means it\u2019s generally faster and more efficient than other algorithms, especially over large datasets.</p>\n<p>It gets better:</p>\n<p>k-means can be used to <a href=\"http://stats.stackexchange.com/questions/58855/why-do-we-use-k-means-instead-of-other-algorithms\" target=\"_blank\" title=\"Why do we use k-means instead of other algorithms?\">pre-cluster</a> a massive dataset followed by a more expensive cluster analysis on the sub-clusters. k-means can also be used to rapidly \u201cplay\u201d with k and explore whether there are overlooked patterns or relationships in the dataset.</p>\n<p>It\u2019s not all smooth sailing:</p>\n<p>Two key weaknesses of k-means are its sensitivity to outliers, and its sensitivity to the initial choice of centroids. One final thing to keep in mind is k-means is designed to operate on continuous data \u2014 you\u2019ll need to do some <a href=\"http://stats.stackexchange.com/questions/28170/clustering-a-dataset-with-both-discrete-and-continuous-variables\" target=\"_blank\" title=\"Clustering a dataset with both discrete and continuous variables\">tricks</a> to get it to work on discrete data.</p>\n<p><strong>Where is it used? </strong>A ton of implementations for k-means clustering are available online:</p>\n<ul class=\"three_ul\">\n<li><a href=\"https://mahout.apache.org/users/clustering/k-means-commandline.html\" target=\"_blank\" title=\"Apache Mahout\">Apache Mahout</a></li>\n<li><a href=\"https://github.com/JuliaStats/Clustering.jl\" target=\"_blank\" title=\"Julia\">Julia</a></li>\n<li><a href=\"https://stat.ethz.ch/R-manual/R-devel/library/stats/html/kmeans.html\" target=\"_blank\" title=\"R\">R</a></li>\n<li><a href=\"http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.vq.kmeans.html\" target=\"_blank\" title=\"SciPy\">SciPy</a></li>\n<li><a href=\"http://weka.sourceforge.net/doc.dev/weka/clusterers/SimpleKMeans.html\" target=\"_blank\" title=\"Weka\">Weka</a></li>\n<li><a href=\"http://www.mathworks.com/help/stats/kmeans.html\" target=\"_blank\" title=\"MATLAB\">MATLAB</a></li>\n<li><a href=\"http://support.sas.com/documentation/cdl/en/statugclustering/61759/PDF/default/statugclustering.pdf\" target=\"_blank\" title=\"SAS\">SAS</a></li>\n</ul>\n<p>If decision trees and clustering didn\u2019t impress you, you\u2019re going to love the next algorithm.</p>\n<h3><b>3. Support vector machines</b></h3>\n<p><strong>What does it do? </strong>Support vector machine (SVM) learns a hyperplane to classify data into 2 classes. At a high-level, SVM performs a similar task like C4.5 except SVM doesn\u2019t use decision trees at all.</p>\n<p><strong>Whoa, a hyper-what? </strong>A hyperplane is a function like the equation for a line, <em>y = mx + b</em>. In fact, for a simple classification task with just 2 features, the hyperplane can be a line.</p>\n<p>As it turns out\u2026</p>\n<p>SVM can perform a trick to project your data into higher dimensions. Once projected into higher dimensions\u2026</p>\n<p>\u2026SVM figures out the best hyperplane which separates your data into the 2 classes.</p>\n<p><strong>Do you have an example? </strong>Absolutely, the simplest example I found starts with a bunch of red and blue balls on a table. If the balls aren\u2019t too mixed together, you could take a stick and without moving the balls, separate them with the stick.</p>\n<p>You see:</p>\n<p>When a new ball is added on the table, by knowing which side of the stick the ball is on, you can predict its color.</p>\n<p><strong>What do the balls, table and stick represent?</strong> The balls represent data points, and the red and blue color represent 2 classes. The stick represents the simplest hyperplane which is a line.</p>\n<p>And the coolest part?</p>\n<p>SVM figures out the function for the hyperplane.</p>\n<p><strong>What if things get more complicated? </strong>Right, they frequently do. If the balls are mixed together, a straight stick won\u2019t work.</p>\n<p>Here\u2019s the work-around:</p>\n<p>Quickly lift up the table throwing the balls in the air. While the balls are in the air and thrown up in just the right way, you use a large sheet of paper to divide the balls in the air.</p>\n<p>You might be wondering if this is cheating:</p>\n<p>Nope, lifting up the table is the equivalent of mapping your data into higher dimensions. In this case, we go from the 2 dimensional table surface to the 3 dimensional balls in the air.</p>\n<p><strong>How does SVM do this?</strong> By using a kernel we have a nice way to operate in higher dimensions. The large sheet of paper is still called a hyperplane, but it is now a function for a plane rather than a line. Note from Yuval that once we\u2019re in 3 dimensions, the hyperplane must be a plane rather than a line.</p>\n<p>I found this visualization super helpful:</p>\n<p><iframe allowfullscreen=\"\" frameborder=\"0\" height=\"360\" src=\"https://www.youtube.com/embed/3liCbRZPrZA?rel=0\" width=\"480\"></iframe></p>\n<p>Reddit also has 2 great threads on this in the <a href=\"http://www.reddit.com/r/explainlikeimfive/comments/rkmjp/what_is_support_vector_machine/\" target=\"_blank\" title=\"What is Support Vector Machine?\">ELI5</a> and <a href=\"http://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i\" target=\"_blank\" title=\"Please explain Support Vector Machines (SVM) like I am a 5 year old.\">ML</a> subreddits.</p>\n<p><strong>How do balls on a table or in the air map to real-life data?</strong> A ball on a table has a location that we can specify using coordinates. For example, a ball could be 20cm from the left edge and 50cm from the bottom edge. Another way to describe the ball is as (x, y) coordinates or (20, 50). x and y are 2 dimensions of the ball.</p>\n<p>Here\u2019s the deal:</p>\n<p>If we had a patient dataset, each patient could be described by various measurements like pulse, cholesterol level, blood pressure, etc. Each of these measurements is a dimension.</p>\n<p>The bottom line is:</p>\n<p>SVM does its thing, maps them into a higher dimension and then finds the hyperplane to separate the classes.</p>\n<p><strong>Margins are often associated with SVM? What are they?</strong> The margin is the distance between the hyperplane and the 2 closest data points from each respective class. In the ball and table example, the distance between the stick and the closest red and blue ball is the margin.</p>\n<p>The key is:</p>\n<p>SVM attempts to maximize the margin, so that the hyperplane is just as far away from red ball as the blue ball. In this way, it decreases the chance of misclassification.</p>\n<p><strong>Where does SVM get its name from?</strong> Using the ball and table example, the hyperplane is equidistant from a red ball and a blue ball. These balls or data points are called support vectors, because they support the hyperplane.</p>\n<p><strong>Is this supervised or unsupervised?</strong> This is a supervised learning, since a dataset is used to first teach the SVM about the classes. Only then is the SVM capable of classifying new data.</p>\n<p><strong>Why use SVM?</strong> SVM along with C4.5 are generally the <a href=\"http://www.researchgate.net/post/What_are_pros_and_cons_of_decision_tree_versus_other_classifier_as_KNN_SVM_NN\" target=\"_blank\" title=\"What are pros and cons of decision tree versus other classifier as KNN,SVM,NN?\">2 classifiers to try first</a>. No classifier will be the best in all cases due to the <a href=\"http://en.wikipedia.org/wiki/No_free_lunch_theorem\" target=\"_blank\" title=\"No Free Lunch Theorem (Wikipedia)\">No Free Lunch Theorem</a>. In addition, kernel selection and interpretability are some weaknesses.</p>\n<p><strong>Where is it used? </strong>There are many implementations of SVM. A few of the popular ones are <a href=\"http://scikit-learn.org/stable/modules/svm.html\" target=\"_blank\" title=\"scikit-learn - Support Vector Machines\">scikit-learn</a>, <a href=\"http://www.mathworks.com/help/stats/support-vector-machines-svm.html\" target=\"_blank\" title=\"MATLAB - Support Vector Machines\">MATLAB </a>and of course <a href=\"http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/\" target=\"_blank\" title=\"libsvm\">libsvm</a>.</p>\n<p>The next algorithm is one of my favorites\u2026</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html/2\">2</a> <a href=\"https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html/3\">3</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2015/05/reduce-data-hoarding-pca-visualization-decisions.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2015/05/trifacta-wrangling-us-flight-data-part2.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2015/index.html\">2015</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/05/tutorials.html\">Tutorials, Overviews, How-Tos</a> \u00bb Top 10 Data Mining Algorithms, Explained (\u00a0<a href=\"/2015/n17.html\">15:n17</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556409843\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.802 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 20:04:03 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "raymond", "today", "explain", "plain", "english", "the", "top", "num", "most", "influenti", "data", "mine", "algorithm", "vote", "num", "separ", "panel", "this", "survey", "paper", "onc", "know", "what", "they", "are", "how", "they", "work", "what", "they", "and", "where", "can", "find", "them", "hope", "have", "this", "blog", "post", "springboard", "learn", "even", "more", "about", "data", "mine", "what", "are", "wait", "for", "let", "get", "start", "here", "are", "the", "algorithm", "num", "num", "kmean", "num", "support", "vector", "machin", "num", "apriori", "num", "num", "pagerank", "num", "adaboost", "num", "knn", "num", "naiv", "bay", "num", "also", "provid", "interest", "resourc", "the", "end", "num", "what", "doe", "construct", "classifi", "the", "form", "decis", "tree", "order", "this", "given", "set", "data", "repres", "thing", "that", "are", "alreadi", "classifi", "wait", "what", "classifi", "classifi", "tool", "data", "mine", "that", "take", "bunch", "data", "repres", "thing", "want", "classifi", "and", "attempt", "predict", "which", "class", "the", "new", "data", "belong", "what", "exampl", "this", "sure", "suppos", "dataset", "contain", "bunch", "patient", "know", "various", "thing", "about", "each", "patient", "like", "age", "puls", "blood", "pressur", "num", "max", "famili", "histori", "etc", "these", "are", "call", "attribut", "now", "given", "these", "attribut", "want", "predict", "whether", "the", "patient", "will", "get", "cancer", "the", "patient", "can", "fall", "into", "num", "num", "class", "will", "get", "cancer", "won", "get", "cancer", "told", "the", "class", "for", "each", "patient", "and", "here", "the", "deal", "use", "set", "patient", "attribut", "and", "the", "patient", "correspond", "class", "construct", "decis", "tree", "that", "can", "predict", "the", "class", "for", "new", "patient", "base", "their", "attribut", "cool", "what", "decis", "tree", "decis", "tree", "learn", "creat", "someth", "similar", "flowchart", "classifi", "new", "data", "use", "the", "same", "patient", "exampl", "one", "particular", "path", "the", "flowchart", "could", "patient", "has", "histori", "cancer", "patient", "express", "gene", "high", "correl", "with", "cancer", "patient", "patient", "has", "tumor", "patient", "tumor", "size", "greater", "than", "numcm", "the", "bottom", "line", "each", "point", "the", "flowchart", "question", "about", "the", "valu", "some", "attribut", "and", "depend", "those", "valu", "she", "get", "classifi", "can", "find", "lot", "exampl", "decis", "tree", "this", "supervis", "unsupervis", "this", "supervis", "learn", "sinc", "the", "train", "dataset", "label", "with", "class", "use", "the", "patient", "exampl", "learn", "own", "that", "patient", "will", "get", "cancer", "won", "get", "cancer", "told", "first", "generat", "decis", "tree", "and", "now", "use", "the", "decis", "tree", "classifi", "might", "wonder", "how", "differ", "than", "other", "decis", "tree", "system", "first", "use", "inform", "gain", "when", "generat", "the", "decis", "tree", "second", "although", "other", "system", "also", "incorpor", "prune", "use", "singlepass", "prune", "process", "mitig", "overfit", "prune", "result", "mani", "improv", "third", "can", "work", "with", "both", "continu", "and", "discret", "data", "understand", "doe", "this", "specifi", "rang", "threshold", "for", "continu", "data", "thus", "turn", "continu", "data", "into", "discret", "data", "final", "incomplet", "data", "dealt", "with", "own", "way", "whi", "use", "arguabl", "the", "best", "sell", "point", "decis", "tree", "their", "eas", "interpret", "and", "explan", "they", "are", "also", "quit", "fast", "quit", "popular", "and", "the", "output", "human", "readabl", "where", "use", "popular", "opensourc", "java", "implement", "can", "found", "over", "opentox", "orang", "opensourc", "data", "visual", "and", "analysi", "tool", "for", "data", "mine", "implement", "their", "decis", "tree", "classifi", "classifi", "are", "great", "but", "make", "sure", "checkout", "the", "next", "algorithm", "about", "clustering\u2026", "num", "kmean", "what", "doe", "kmean", "creat", "group", "from", "set", "object", "that", "the", "member", "group", "are", "more", "similar", "popular", "cluster", "analysi", "techniqu", "for", "explor", "dataset", "hang", "what", "cluster", "analysi", "cluster", "analysi", "famili", "algorithm", "design", "form", "group", "such", "that", "the", "group", "member", "are", "more", "similar", "versus", "nongroup", "member", "cluster", "and", "group", "are", "synonym", "the", "world", "cluster", "analysi", "there", "exampl", "this", "definit", "suppos", "have", "dataset", "patient", "cluster", "analysi", "these", "would", "call", "observ", "know", "various", "thing", "about", "each", "patient", "like", "age", "puls", "blood", "pressur", "num", "max", "cholesterol", "etc", "this", "vector", "repres", "the", "patient", "look", "can", "basic", "think", "vector", "list", "number", "know", "about", "the", "patient", "this", "list", "can", "also", "interpret", "coordin", "multidimension", "space", "puls", "can", "one", "dimens", "blood", "pressur", "anoth", "dimens", "and", "forth", "might", "wonder", "given", "this", "set", "vector", "how", "cluster", "togeth", "patient", "that", "have", "similar", "age", "puls", "blood", "pressur", "etc", "want", "know", "the", "best", "part", "tell", "kmean", "how", "mani", "cluster", "want", "kmean", "take", "care", "the", "rest", "how", "doe", "kmean", "take", "care", "the", "rest", "kmean", "has", "lot", "variat", "optim", "for", "certain", "type", "data", "high", "level", "they", "all", "someth", "like", "this", "kmean", "pick", "point", "multidimension", "space", "repres", "each", "the", "cluster", "these", "are", "call", "centroid", "everi", "patient", "will", "closest", "num", "these", "centroid", "they", "hope", "won", "all", "closest", "the", "same", "one", "they", "form", "cluster", "around", "their", "nearest", "centroid", "what", "have", "are", "cluster", "and", "each", "patient", "now", "member", "cluster", "kmean", "then", "find", "the", "center", "for", "each", "the", "cluster", "base", "cluster", "member", "yep", "use", "the", "patient", "vector", "this", "center", "becom", "the", "new", "centroid", "for", "the", "cluster", "sinc", "the", "centroid", "differ", "place", "now", "patient", "might", "now", "closer", "other", "centroid", "other", "word", "they", "may", "chang", "cluster", "membership", "step", "num", "are", "repeat", "until", "the", "centroid", "longer", "chang", "and", "the", "cluster", "membership", "stabil", "this", "call", "converg", "this", "supervis", "unsupervis", "depend", "but", "most", "would", "classifi", "kmean", "unsupervis", "other", "than", "specifi", "the", "number", "cluster", "kmean", "learn", "the", "cluster", "own", "without", "ani", "inform", "about", "which", "cluster", "observ", "belong", "kmean", "can", "semisupervis", "whi", "use", "kmean", "think", "mani", "will", "have", "issu", "with", "this", "the", "key", "sell", "point", "kmean", "simplic", "simplic", "mean", "general", "faster", "and", "more", "effici", "than", "other", "algorithm", "especi", "over", "larg", "dataset", "get", "better", "kmean", "can", "use", "preclust", "massiv", "dataset", "follow", "more", "expens", "cluster", "analysi", "the", "subclust", "kmean", "can", "also", "use", "rapid", "play", "with", "and", "explor", "whether", "there", "are", "overlook", "pattern", "relationship", "the", "dataset", "not", "all", "smooth", "sail", "two", "key", "weak", "kmean", "are", "sensit", "outlier", "and", "sensit", "the", "initi", "choic", "centroid", "one", "final", "thing", "keep", "mind", "kmean", "design", "oper", "continu", "data", "need", "some", "trick", "get", "work", "discret", "data", "where", "use", "ton", "implement", "for", "kmean", "cluster", "are", "avail", "onlin", "apach", "mahout", "julia", "scipi", "weka", "decis", "tree", "and", "cluster", "impress", "love", "the", "next", "algorithm", "num", "support", "vector", "machin", "what", "doe", "support", "vector", "machin", "learn", "hyperplan", "classifi", "data", "into", "num", "class", "highlevel", "perform", "similar", "task", "like", "except", "use", "decis", "tree", "all", "whoa", "hyperwhat", "hyperplan", "function", "like", "the", "equat", "for", "line", "fact", "for", "simpl", "classif", "task", "with", "just", "num", "featur", "the", "hyperplan", "can", "line", "turn", "out\u2026", "can", "perform", "trick", "project", "data", "into", "higher", "dimens", "onc", "project", "into", "higher", "dimensions\u2026", "figur", "out", "the", "best", "hyperplan", "which", "separ", "data", "into", "the", "num", "class", "have", "exampl", "absolut", "the", "simplest", "exampl", "found", "start", "with", "bunch", "red", "and", "blue", "ball", "tabl", "the", "ball", "aren", "too", "mix", "togeth", "could", "take", "stick", "and", "without", "move", "the", "ball", "separ", "them", "with", "the", "stick", "see", "when", "new", "ball", "the", "tabl", "know", "which", "side", "the", "stick", "the", "ball", "can", "predict", "color", "what", "the", "ball", "tabl", "and", "stick", "repres", "the", "ball", "repres", "data", "point", "and", "the", "red", "and", "blue", "color", "repres", "num", "class", "the", "stick", "repres", "the", "simplest", "hyperplan", "which", "line", "and", "the", "coolest", "part", "figur", "out", "the", "function", "for", "the", "hyperplan", "what", "thing", "get", "more", "complic", "right", "they", "frequent", "the", "ball", "are", "mix", "togeth", "straight", "stick", "won", "work", "here", "the", "workaround", "quick", "lift", "the", "tabl", "throw", "the", "ball", "the", "air", "while", "the", "ball", "are", "the", "air", "and", "thrown", "just", "the", "right", "way", "use", "larg", "sheet", "paper", "divid", "the", "ball", "the", "air", "might", "wonder", "this", "cheat", "nope", "lift", "the", "tabl", "the", "equival", "map", "data", "into", "higher", "dimens", "this", "case", "from", "the", "num", "dimension", "tabl", "surfac", "the", "num", "dimension", "ball", "the", "air", "how", "doe", "this", "use", "kernel", "have", "nice", "way", "oper", "higher", "dimens", "the", "larg", "sheet", "paper", "still", "call", "hyperplan", "but", "now", "function", "for", "plane", "rather", "than", "line", "note", "from", "yuval", "that", "onc", "num", "dimens", "the", "hyperplan", "must", "plane", "rather", "than", "line", "found", "this", "visual", "super", "help", "reddit", "also", "has", "num", "great", "thread", "this", "the", "and", "subreddit", "how", "ball", "tabl", "the", "air", "map", "reallif", "data", "ball", "tabl", "has", "locat", "that", "can", "specifi", "use", "coordin", "for", "exampl", "ball", "could", "numcm", "from", "the", "left", "edg", "and", "numcm", "from", "the", "bottom", "edg", "anoth", "way", "describ", "the", "ball", "coordin", "num", "num", "and", "are", "num", "dimens", "the", "ball", "here", "the", "deal", "had", "patient", "dataset", "each", "patient", "could", "describ", "various", "measur", "like", "puls", "cholesterol", "level", "blood", "pressur", "etc", "each", "these", "measur", "dimens", "the", "bottom", "line", "doe", "thing", "map", "them", "into", "higher", "dimens", "and", "then", "find", "the", "hyperplan", "separ", "the", "class", "margin", "are", "often", "associ", "with", "what", "are", "they", "the", "margin", "the", "distanc", "between", "the", "hyperplan", "and", "the", "num", "closest", "data", "point", "from", "each", "respect", "class", "the", "ball", "and", "tabl", "exampl", "the", "distanc", "between", "the", "stick", "and", "the", "closest", "red", "and", "blue", "ball", "the", "margin", "the", "key", "attempt", "maxim", "the", "margin", "that", "the", "hyperplan", "just", "far", "away", "from", "red", "ball", "the", "blue", "ball", "this", "way", "decreas", "the", "chanc", "misclassif", "where", "doe", "get", "name", "from", "use", "the", "ball", "and", "tabl", "exampl", "the", "hyperplan", "equidist", "from", "red", "ball", "and", "blue", "ball", "these", "ball", "data", "point", "are", "call", "support", "vector", "becaus", "they", "support", "the", "hyperplan", "this", "supervis", "unsupervis", "this", "supervis", "learn", "sinc", "dataset", "use", "first", "teach", "the", "about", "the", "class", "onli", "then", "the", "capabl", "classifi", "new", "data", "whi", "use", "along", "with", "are", "general", "the", "num", "classifi", "tri", "first", "classifi", "will", "the", "best", "all", "case", "due", "the", "free", "lunch", "theorem", "addit", "kernel", "select", "and", "interpret", "are", "some", "weak", "where", "use", "there", "are", "mani", "implement", "few", "the", "popular", "one", "are", "scikitlearn", "and", "cours", "libsvm", "the", "next", "algorithm", "one", "favorites\u2026"], "timestamp_scraper": 1556479031.107361, "title": "Top 10 Data Mining Algorithms, Explained", "read_time": 587.6999999999999, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2015/05/top-10-data-mining-algorithms-explained.html/3#comments\">comments</a></div>\n<p><b>By <a href=\"http://rayli.net\">Raymond Li</a>.</b></p>\n<p>Today, I\u2019m going to explain in plain English the top 10 most influential data mining algorithms as voted on by 3 separate panels in this <a href=\"http://www.cs.uvm.edu/%7Eicdm/algorithms/10Algorithms-08.pdf\" target=\"_blank\" title=\"Top 10 algorithms in data mining\">survey paper</a>.</p>\n<p>Once you know what they are, how they work, what they do and where you can find them, my hope is you\u2019ll have this blog post as a springboard to learn even more about data mining.</p>\n<p>What are we waiting for? Let\u2019s get started!</p>\n<p><img alt=\"top-10-data-mining-algorithms\" class=\"alignnone size-full wp-image-34191\" height=\"259\" sizes=\"(max-width: 495px) 100vw, 495px\" src=\"/wp-content/uploads/top-10-data-mining-algorithms.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/top-10-data-mining-algorithms.jpg 495w, https://www.kdnuggets.com/wp-content/uploads/top-10-data-mining-algorithms-300x156.jpg 300w\" width=\"495\"/></p>\n<p>Here are the algorithms:</p>\n<ul>\n<li>1. C4.5</li>\n<li>2. k-means</li>\n<li>3. Support vector machines</li>\n<li>4. Apriori</li>\n<li>5. EM</li>\n<li>6. PageRank</li>\n<li>7. AdaBoost</li>\n<li>8. kNN</li>\n<li>9. Naive Bayes</li>\n<li>10. CART</li>\n</ul>\n<p>We also provide interesting resources at the end.</p>\n<h3><b>1. C4.5</b></h3>\n<p><strong>What does it do? </strong>C4.5 constructs a classifier in the form of a decision tree. In order to do this, C4.5 is given a set of data representing things that are already classified.</p>\n<p><strong>Wait, what\u2019s a classifier? </strong>A classifier is a tool in data mining that takes a bunch of data representing things we want to classify and attempts to predict which class the new data belongs to.</p>\n<p><strong>What\u2019s an example of this? </strong>Sure, suppose a dataset contains a bunch of patients. We know various things about each patient like age, pulse, blood pressure, VO<sub>2</sub>max, family history, etc. These are called attributes.</p>\n<p>Now:</p>\n<p>Given these attributes, we want to predict whether the patient will get cancer. The patient can fall into 1 of 2 classes: will get cancer or won\u2019t get cancer. C4.5 is told the class for each patient.</p>\n<p>And here\u2019s the deal:</p>\n<p>Using a set of patient attributes and the patient\u2019s corresponding class, C4.5 constructs a decision tree that can predict the class for new patients based on their attributes.</p>\n<p><strong>Cool, so what\u2019s a decision tree?</strong> Decision tree learning creates something similar to a flowchart to classify new data. Using the same patient example, one particular path in the flowchart could be:</p>\n<ul>\n<li>Patient has a history of cancer</li>\n<li>Patient is expressing a gene highly correlated with cancer patients</li>\n<li>Patient has tumors</li>\n<li>Patient\u2019s tumor size is greater than 5cm</li>\n</ul>\n<p>The bottom line is:</p>\n<p>At each point in the flowchart is a question about the value of some attribute, and depending on those values, he or she gets classified. You can find lots of <a href=\"https://www.google.com/search?q=c4.5+decision+tree&amp;tbm=isch\" target=\"_blank\" title=\"C4.5 Decision Trees (Google Images)\">examples of decision trees</a>.</p>\n<p><strong>Is this supervised or unsupervised?</strong> This is supervised learning, since the training dataset is labeled with classes. Using the patient example, C4.5 doesn\u2019t learn on its own that a patient will get cancer or won\u2019t get cancer. We told it first, it generated a decision tree, and now it uses the decision tree to classify.</p>\n<p><strong>You might be wondering how C4.5 is different than other decision tree systems?</strong></p>\n<ul>\n<li>First, C4.5 uses <a href=\"http://en.wikipedia.org/wiki/Entropy_%28information_theory%29\" target=\"_blank\" title=\"Entropy (Wikipedia)\">information gain</a> when generating the decision tree.</li>\n<li>Second, although other systems also incorporate pruning, C4.5 uses a <a href=\"http://www.cs.bc.edu/%7Ealvarez/ML/statPruning.html\" target=\"_blank\" title=\"Decision Tree Pruning based on Confidence Intervals\">single-pass pruning process</a> to mitigate over-fitting. Pruning results in <a href=\"http://stackoverflow.com/questions/10865372/why-does-the-c4-5-algorithm-use-pruning-in-order-to-reduce-the-decision-tree-and\" target=\"_blank\" title=\"Why does the C4.5 algorithm use pruning in order to reduce the decision tree and how does pruning affect the prediction accuracy?\">many improvements</a>.</li>\n<li>Third, C4.5 can work with both continuous and discrete data. My understanding is it does this by specifying ranges or thresholds for continuous data thus turning continuous data into discrete data.</li>\n<li>Finally, incomplete data is dealt with in <a href=\"http://stats.stackexchange.com/questions/96025/how-do-decision-tree-learning-algorithms-deal-with-missing-values-under-the-hoo\" target=\"_blank\" title=\"How do decision tree learning algorithms deal with missing values (under the hood)\">its own ways</a>.</li>\n</ul>\n<p><strong>Why use C4.5?</strong> Arguably, the best selling point of decision trees is their ease of interpretation and explanation. They are also quite fast, quite popular and the output is <a href=\"https://www.google.com/search?q=j4.8+output&amp;tbm=isch\" target=\"_blank\" title=\"J4.8 Output (Google Images)\">human readable</a>.</p>\n<p><strong>Where is it used? </strong>A popular open-source Java implementation can be found over at <a href=\"http://www.opentox.org/dev/documentation/components/j48\" target=\"_blank\" title=\"J48 - OpenTox\">OpenTox</a>. <a href=\"http://orange.biolab.si/\" target=\"_blank\" title=\"Orange\">Orange</a>, an open-source data visualization and analysis tool for data mining, implements C4.5 in their decision tree classifier.</p>\n<p>Classifiers are great, but make sure to checkout the next algorithm about clustering\u2026</p>\n<h3><b>2. k-means</b></h3>\n<p><strong>What does it do? </strong>k-means creates <em>k</em> groups from a set of objects so that the members of a group are more similar. It\u2019s a popular cluster analysis technique for exploring a dataset.</p>\n<p><strong>Hang on, what\u2019s cluster analysis?</strong> Cluster analysis is a family of algorithms designed to form groups such that the group members are more similar versus non-group members. Clusters and groups are synonymous in the world of cluster analysis.</p>\n<p><strong>Is there an example of this? </strong>Definitely, suppose we have a dataset of patients. In cluster analysis, these would be called observations. We know various things about each patient like age, pulse, blood pressure, VO<sub>2</sub>max, cholesterol, etc. This is a vector representing the patient.</p>\n<p>Look:</p>\n<p>You can basically think of a vector as a list of numbers we know about the patient. This list can also be interpreted as coordinates in multi-dimensional space. Pulse can be one dimension, blood pressure another dimension and so forth.</p>\n<p>You might be wondering:</p>\n<p>Given this set of vectors, how do we cluster together patients that have similar age, pulse, blood pressure, etc?</p>\n<p>Want to know the best part?</p>\n<p>You tell k-means how many clusters you want. K-means takes care of the rest.</p>\n<p><strong>How does k-means take care of the rest?</strong> k-means has lots of variations to optimize for certain types of data.</p>\n<p>At a high level, they all do something like this:</p>\n<ol>\n<li>k-means picks points in multi-dimensional space to represent each of the k clusters. These are called centroids.</li>\n<li>Every patient will be closest to 1 of these k centroids. They hopefully won\u2019t all be closest to the same one, so they\u2019ll form a cluster around their nearest centroid.</li>\n<li>What we have are k clusters, and each patient is now a member of a cluster.</li>\n<li>k-means then finds the center for each of the k clusters based on its cluster members (yep, using the patient vectors!).</li>\n<li>This center becomes the new centroid for the cluster.</li>\n<li>Since the centroid is in a different place now, patients might now be closer to other centroids. In other words, they may change cluster membership.</li>\n<li>Steps 2-6 are repeated until the centroids no longer change, and the cluster memberships stabilize. This is called convergence.</li>\n</ol>\n<p><strong>Is this supervised or unsupervised?</strong> It depends, but most would classify k-means as unsupervised. Other than specifying the number of clusters, k-means \u201clearns\u201d the clusters on its own without any information about which cluster an observation belongs to. k-means can be <a href=\"https://www.google.com/search?q=semi+supervised+k+means\" target=\"_blank\" title=\"Semi supervised k means (Google)\">semi-supervised</a>.</p>\n<p><strong>Why use k-means?</strong> I don\u2019t think many will have an issue with this:</p>\n<p>The key selling point of k-means is its simplicity. Its simplicity means it\u2019s generally faster and more efficient than other algorithms, especially over large datasets.</p>\n<p>It gets better:</p>\n<p>k-means can be used to <a href=\"http://stats.stackexchange.com/questions/58855/why-do-we-use-k-means-instead-of-other-algorithms\" target=\"_blank\" title=\"Why do we use k-means instead of other algorithms?\">pre-cluster</a> a massive dataset followed by a more expensive cluster analysis on the sub-clusters. k-means can also be used to rapidly \u201cplay\u201d with k and explore whether there are overlooked patterns or relationships in the dataset.</p>\n<p>It\u2019s not all smooth sailing:</p>\n<p>Two key weaknesses of k-means are its sensitivity to outliers, and its sensitivity to the initial choice of centroids. One final thing to keep in mind is k-means is designed to operate on continuous data \u2014 you\u2019ll need to do some <a href=\"http://stats.stackexchange.com/questions/28170/clustering-a-dataset-with-both-discrete-and-continuous-variables\" target=\"_blank\" title=\"Clustering a dataset with both discrete and continuous variables\">tricks</a> to get it to work on discrete data.</p>\n<p><strong>Where is it used? </strong>A ton of implementations for k-means clustering are available online:</p>\n<ul class=\"three_ul\">\n<li><a href=\"https://mahout.apache.org/users/clustering/k-means-commandline.html\" target=\"_blank\" title=\"Apache Mahout\">Apache Mahout</a></li>\n<li><a href=\"https://github.com/JuliaStats/Clustering.jl\" target=\"_blank\" title=\"Julia\">Julia</a></li>\n<li><a href=\"https://stat.ethz.ch/R-manual/R-devel/library/stats/html/kmeans.html\" target=\"_blank\" title=\"R\">R</a></li>\n<li><a href=\"http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.vq.kmeans.html\" target=\"_blank\" title=\"SciPy\">SciPy</a></li>\n<li><a href=\"http://weka.sourceforge.net/doc.dev/weka/clusterers/SimpleKMeans.html\" target=\"_blank\" title=\"Weka\">Weka</a></li>\n<li><a href=\"http://www.mathworks.com/help/stats/kmeans.html\" target=\"_blank\" title=\"MATLAB\">MATLAB</a></li>\n<li><a href=\"http://support.sas.com/documentation/cdl/en/statugclustering/61759/PDF/default/statugclustering.pdf\" target=\"_blank\" title=\"SAS\">SAS</a></li>\n</ul>\n<p>If decision trees and clustering didn\u2019t impress you, you\u2019re going to love the next algorithm.</p>\n<h3><b>3. Support vector machines</b></h3>\n<p><strong>What does it do? </strong>Support vector machine (SVM) learns a hyperplane to classify data into 2 classes. At a high-level, SVM performs a similar task like C4.5 except SVM doesn\u2019t use decision trees at all.</p>\n<p><strong>Whoa, a hyper-what? </strong>A hyperplane is a function like the equation for a line, <em>y = mx + b</em>. In fact, for a simple classification task with just 2 features, the hyperplane can be a line.</p>\n<p>As it turns out\u2026</p>\n<p>SVM can perform a trick to project your data into higher dimensions. Once projected into higher dimensions\u2026</p>\n<p>\u2026SVM figures out the best hyperplane which separates your data into the 2 classes.</p>\n<p><strong>Do you have an example? </strong>Absolutely, the simplest example I found starts with a bunch of red and blue balls on a table. If the balls aren\u2019t too mixed together, you could take a stick and without moving the balls, separate them with the stick.</p>\n<p>You see:</p>\n<p>When a new ball is added on the table, by knowing which side of the stick the ball is on, you can predict its color.</p>\n<p><strong>What do the balls, table and stick represent?</strong> The balls represent data points, and the red and blue color represent 2 classes. The stick represents the simplest hyperplane which is a line.</p>\n<p>And the coolest part?</p>\n<p>SVM figures out the function for the hyperplane.</p>\n<p><strong>What if things get more complicated? </strong>Right, they frequently do. If the balls are mixed together, a straight stick won\u2019t work.</p>\n<p>Here\u2019s the work-around:</p>\n<p>Quickly lift up the table throwing the balls in the air. While the balls are in the air and thrown up in just the right way, you use a large sheet of paper to divide the balls in the air.</p>\n<p>You might be wondering if this is cheating:</p>\n<p>Nope, lifting up the table is the equivalent of mapping your data into higher dimensions. In this case, we go from the 2 dimensional table surface to the 3 dimensional balls in the air.</p>\n<p><strong>How does SVM do this?</strong> By using a kernel we have a nice way to operate in higher dimensions. The large sheet of paper is still called a hyperplane, but it is now a function for a plane rather than a line. Note from Yuval that once we\u2019re in 3 dimensions, the hyperplane must be a plane rather than a line.</p>\n<p>I found this visualization super helpful:</p>\n<p><iframe allowfullscreen=\"\" frameborder=\"0\" height=\"360\" src=\"https://www.youtube.com/embed/3liCbRZPrZA?rel=0\" width=\"480\"></iframe></p>\n<p>Reddit also has 2 great threads on this in the <a href=\"http://www.reddit.com/r/explainlikeimfive/comments/rkmjp/what_is_support_vector_machine/\" target=\"_blank\" title=\"What is Support Vector Machine?\">ELI5</a> and <a href=\"http://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i\" target=\"_blank\" title=\"Please explain Support Vector Machines (SVM) like I am a 5 year old.\">ML</a> subreddits.</p>\n<p><strong>How do balls on a table or in the air map to real-life data?</strong> A ball on a table has a location that we can specify using coordinates. For example, a ball could be 20cm from the left edge and 50cm from the bottom edge. Another way to describe the ball is as (x, y) coordinates or (20, 50). x and y are 2 dimensions of the ball.</p>\n<p>Here\u2019s the deal:</p>\n<p>If we had a patient dataset, each patient could be described by various measurements like pulse, cholesterol level, blood pressure, etc. Each of these measurements is a dimension.</p>\n<p>The bottom line is:</p>\n<p>SVM does its thing, maps them into a higher dimension and then finds the hyperplane to separate the classes.</p>\n<p><strong>Margins are often associated with SVM? What are they?</strong> The margin is the distance between the hyperplane and the 2 closest data points from each respective class. In the ball and table example, the distance between the stick and the closest red and blue ball is the margin.</p>\n<p>The key is:</p>\n<p>SVM attempts to maximize the margin, so that the hyperplane is just as far away from red ball as the blue ball. In this way, it decreases the chance of misclassification.</p>\n<p><strong>Where does SVM get its name from?</strong> Using the ball and table example, the hyperplane is equidistant from a red ball and a blue ball. These balls or data points are called support vectors, because they support the hyperplane.</p>\n<p><strong>Is this supervised or unsupervised?</strong> This is a supervised learning, since a dataset is used to first teach the SVM about the classes. Only then is the SVM capable of classifying new data.</p>\n<p><strong>Why use SVM?</strong> SVM along with C4.5 are generally the <a href=\"http://www.researchgate.net/post/What_are_pros_and_cons_of_decision_tree_versus_other_classifier_as_KNN_SVM_NN\" target=\"_blank\" title=\"What are pros and cons of decision tree versus other classifier as KNN,SVM,NN?\">2 classifiers to try first</a>. No classifier will be the best in all cases due to the <a href=\"http://en.wikipedia.org/wiki/No_free_lunch_theorem\" target=\"_blank\" title=\"No Free Lunch Theorem (Wikipedia)\">No Free Lunch Theorem</a>. In addition, kernel selection and interpretability are some weaknesses.</p>\n<p><strong>Where is it used? </strong>There are many implementations of SVM. A few of the popular ones are <a href=\"http://scikit-learn.org/stable/modules/svm.html\" target=\"_blank\" title=\"scikit-learn - Support Vector Machines\">scikit-learn</a>, <a href=\"http://www.mathworks.com/help/stats/support-vector-machines-svm.html\" target=\"_blank\" title=\"MATLAB - Support Vector Machines\">MATLAB </a>and of course <a href=\"http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/\" target=\"_blank\" title=\"libsvm\">libsvm</a>.</p>\n<p>The next algorithm is one of my favorites\u2026</p>\n</div> ", "website": "kdnuggets"}