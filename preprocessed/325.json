{"content": "comments By Brandon Morris , Arizona State University Efficiently training deep neural networks can often be an art as much as a science. Industry-grade libraries like\u00a0 PyTorch \u00a0and\u00a0 TensorFlow \u00a0have rapidly increased the speed with which efficient deep learning code can be written, but there are still a lot of work required to create a performant model. Let\u2019s say, for example, you want to build an image classifier model. A convolutional neural network would be the proper approach to utilize deep learning. But how many layers go in your network? How much momentum and weight decay should you use? What\u2019s the best dropout probability? The reality is that these questions don\u2019t have definitive answers. What works great on one dataset might not work nearly as well on another. There are sensible defaults and good rules of thumb, but finding the best combination is nontrivial. These kinds of decisions are known as\u00a0 hyperparameters : values that are determined prior to actually executing the training algorithm. Figuring out the optimal set of hyperparameters can be one of the most time consuming portions of creating a machine learning model, and that\u2019s particularly true in deep learning. \u00a0 Difficulties in Finding the Right Hyperparameters \u00a0 Unlike the parameters inside the model, the hyperparameters are difficult to optimize. While it\u2019s possible to optimize hyperparameters with\u00a0 Bayesian methods , this is almost never done in practice. Instead, the best set of hyperparameters is typically sought through a brute force search. Part of the difficulty of finding the right hyperparameter values is their complex interplay between each other. One value of weight decay may work well for a particular learning rate and poorly for another. Changing one value impacts many others in ways that are difficult to control. A tempting, naive method is to set up reasonable steps for each hyperparameter, and loop over a range, trying different values for each one. This is known as\u00a0 grid search , and it\u2019s generally a bad idea for two reasons. First, the model has to be completely retrained for each set of hyperparameters, and the number of sets grows exponentially with the number of hyperparameters. Most of these values will be suboptimal, meaning that we\u2019re wasting a great deal of time and energy unnecessarily retraining out model. The second reason is a little more subtle. Our steps will need to have a reasonable size to reduce the number of times we need to retrain the model, meaning we\u2019re jumping over a decent bit of the search space with each iteration. There\u2019s no reason our particular intervals are likely to contain good values, so it very possible we will entirely skip over good values. In fact, just doing a random search will usually yield better results that stepping across a fixed interval. The picture below depicts this visually. Unfortunately, the state of the art in hyperparameter selection is little more than a random search. Most values have sensible defaults, but picking the best possible set can have a significant impact on the model\u2019s final performance. Many machine learning researchers and practitioners develop intuitions about good values and how hyperparameters interact, but it takes a lot of time and practice. However, some recent and exciting research has outlined techniques for finding arguable the most important hyperparameter: the\u00a0 learning rate . \u00a0 What is the Learning\u00a0Rate? \u00a0 Neural network training is typically performed as stochastic optimization. We start out with a random set of network parameters, find out which direction they should move to be improved, then take a step in that direction. This process is known as\u00a0 gradient descent \u00a0(the stochastic portion comes from the fact that we find our improvement direction on a random subset of the training data). The learning rate determines how big of a step we take in updating the parameters. # w is our weight, and dw is the derivative w += -learning_rate * dw The above parameter update occurs every iteration of the training process (though modern networks almost always use a more sophisticated update that adds extra terms). Without a doubt,\u00a0 the learning rate is the single most important hyperparameter for a deep neural network . If the learning rate is too small, the parameters will only change in tiny ways, and the model will take too long to converge. On the other hand, if the learning rate is too large, the parameters could jump over low spaces of the loss function, and the network may never converge. 3e-4 is the best learning rate for Adam, hands\u00a0down. \u2014 Andrej Karpathy (@karpathy)\u00a0 November 24,\u00a02016 Picking the learning rate is pretty arbitrary. There are a range of reasonable values, but that range and the optimal value will vary with the architecture and dataset. As Andrej Karpathy joked in a tweet seen above, saying that one learning rate is \u201cthe best\u201d is pretty preposterous. Commonly, the ideal learning rate will change during training. Most world-class deep architectures are trained with a piecewise annealing strategy: train the network for a while with one learning rate, and when the model stops improving, decrease the learning rate by some factor and keep going. Intuitively, this makes some sense: if the model gets to a low spot in the loss space, the steps we take may be too big to keep from jumping across deeper valleys. Decreasing the learning rate allows for a more fine-grained training. While piecewise annealing works in practice, we\u2019ll soon see that it is suboptimal. There are better ways that we can (1) systematically find appropriate learning  for our particular problem, and (2) schedule the learning rate to automatically vary for faster training and improved performance. \u00a0 Cyclical Learning\u00a0Rates \u00a0 Picking the perfect learning rate is hard. In fact, it\u2019s probably too hard to find the singular best value. Instead, we can pick a\u00a0 range of learning rates \u00a0and move through them during training. Kind of surprisingly, this method of\u00a0 cyclical learning rates \u00a0 works pretty well . Cycling through values for the learning rate during training alleviates two of the problems with picking the learning rate. First, we don\u2019t need to find an exactly perfect value, just a range of potentially good values. If we pick our range well (more on that shortly), we will be close to the optimal value for most of the training cycle, which is much better than randomly searching for the perfect learning rate. Additionally, we no longer need to manually schedule the learning rate to decrease during training, since the cycle does it for us. Just be sure to start the cycle with a high rate, and decrease it to a low rate. You might be asking yourself why immediately reset the learning rate to a high value instead of allowing it to gradually climb back up. Resetting to a high learning rate gives us the benefit of a\u00a0 warm restart \u00a0in our optimization and can improve our generalization. Remember that in machine learning, our primary goal is not to create a model that works well on the training data, but has high performance on the\u00a0 test \u00a0data. This means that we not only want to find a low spot in the loss space during training, but we also want a very\u00a0 wide space. That way, even when our model is presented with new data that moves it around in loss space, it\u2019s still likely to be at very low spot, and hence very accurate. Warm restarts helps us find those low and wide spaces that we\u2019re looking for. Even if we find a cozy low valley with our low learning rate, restarting it to a high value at the start of a new cycle will pop us right out of that space if it\u2019s not wide enough. There are several ways to tinker with cyclical learning rates that might improve the final results. The length of a cycle is usually about an epoch, but longer cycles are possible. We can even increase the length of the cycle after each cycle. For instance, start with a cycle length of one epoch, then two epochs, then four, and so on. Schedules like this often give good results in part because they spend more time at lower rates during the end of training, allowing the model to hone in on an optimal space of the loss. Cyclical learning rates allow us to circumvent the difficulty of picking a good learning rate. All we need are approximate bounds, and we can spend the majority of our training time being close to the optimal value, even as that optimal value changes during training. Additionally, we get the added benefit of restarts that will help us find wide areas in the loss space, improving our generalization ability. Now all we need is a method to find the approximate bounds to cycle through. \u00a0 The LR Range\u00a0Test \u00a0 Cyclical learning rates preclude us from needing to find an optimal learning rate, but we still need an upper and lower bound for our cycles. Luckily, we don\u2019t need to resort to the guessing game and random search that plagued or initial hyperparameter search. Instead, the\u00a0 paper \u00a0that described the cyclical learning rate method also introduced a systematic method for finding good boundaries: the\u00a0 LR Range Test . The LR Range Test is simple to understand and cheap to execute. Start with your initialized network, and pick a very small learning rate (much smaller than you would ever likely use). As you train, exponentially increase the learning rate. Keep track of the loss function for each value of the learning rate. If you\u2019re in the right range, the loss should drop, then increase as the learning rate gets too high. Below is a graph of the loss value as a function of the learning rate. Looking at a plot of the loss vs. the learning rate, we can find our boundaries to use for our cycles. The place to look for is the learning rate where the loss stops decreasing: the minimum value. In the graph above it\u2019s roughly\u00a0. This value is probably too high to use as our boundary, which is why the loss stopped decreasing here. We need to go back just a bit to a smaller value for our maximum boundary to use in our cycles. A good one to use here would be\u00a0. At that point the loss is still decreasing with some gusto. We wouldn\u2019t want to pick the value with the steepest slope, since this will be the maximum, and the cycle will only spend a little while at that point. For the minimum, we can use any value that is smaller; typically we can divide the maximum by a factor such as 3 or 10. Cyclical learning rates work well in practice, but there\u2019s actually a way to take it a step further. The technique was introduced by Leslie Smith again and dubbed\u00a0 super-convergence . This strategy is a modification of the cyclical learning rate, and allows for training to converge substantially faster, hence the name. To exploit super-convergence, instead of iterating over cycles of the learning rate, we use a single \u201c1cycle\u201d policy. We derive the maximum and minimum learning rate from the LR Range Test as before. Now, we take one long cycle, moving up from the minimum to the maximum, and back down again. Then we continue training and decreasing the learning rate. We also inversely cycle the momentum, going from a high to low, and allowing it to continue increasing. A plot of the learning rate and momentum schedules are shown below. Amazingly, adopting the 1cycle policy permits incredibly fast training. The original authors reported training deep networks on large datasets in a fraction of the epochs required by other training regimes. Recently, fast.ai\u00a0 leveraged super-convergence \u00a0to train an ImageNet model in less than three hours, and a CIFAR10 model\u00a0 in lest than three minutes . \u00a0 Conclusion \u00a0 There are many difficulties in training deep neural networks. The best practitioners have spent a long time cutting their teeth and developing intuitions about the best values for hyperparameters. Fortunately, research has shown us better ways to pick the learning rate than wasting time and computing power fumbling around in the dark. The LR Range Test provides a quick way to find suitable boundaries for the learning rate, which we can cycle through during training to completely avoid having to find an optimal value. This means more time can be spent training more networks, and less time searching for hyperparameters. Additionally, the 1cycle policy lets us train neural nets at breakneck speeds, creating performant models in a fraction of the training time. Special thanks to the\u00a0 fast.ai \u00a0course for providing the inspiration and instruction for this blog post. \u00a0 Bio: Brandon Morris is a Ph.D. student of Computer Science with a focus on Artificial Intelligence at Arizona State University. He is currently studying deep learning and with a particular focus on multimodal models combining computer vision and natural language processing. Original . Reposted with permission. Related: Understanding Learning Rates and How It Improves Performance in Deep Learning Estimating an Optimal Learning Rate For a Deep Neural Network Is Learning Rate Useful in Artificial Neural Networks?", "title_html": "<h1 id=\"title\">Mastering the Learning Rate to Speed Up Deep Learning</h1> ", "url": "https://www.kdnuggets.com/2018/11/mastering-learning-rate-speed-up-deep-learning.html", "tfidf": {"tfidf": {"after": 1.02070207021, "hand": 3.2304405331200003, "art": 3.9989924433199997, "arguabl": 12.928338762200001, "anneal": 520.524590164, "too": 12.71096877505, "occur": 1.7453825857499998, "plot": 10.767039674460001, "tempt": 48.2553191489, "immedi": 2.02862254025, "fastai": 1867.764705882, "space": 23.9818731118, "extra": 5.33826496301, "addit": 3.73904851626, "would": 3.2486187845399996, "thank": 6.00681044268, "number": 3.30428749827, "boundari": 24.2900856793, "decreas": 36.184615384640004, "dataset": 580.829268294, "function": 7.486325055, "vari": 4.994023277759999, "decay": 32.170212766, "descent": 8.494382022469999, "suboptim": 1176.0, "three": 2.13243787778, "well": 6.393449224799999, "unlik": 2.42529789184, "done": 2.3302509907499998, "abov": 5.7114761961900005, "never": 3.11538461538, "big": 5.480151881259999, "complet": 2.48043121632, "approach": 2.07556543339, "yield": 6.46943765281, "their": 2.0309581681, "gusto": 429.081081081, "automat": 6.787516032490001, "momentum": 50.506892895, "particular": 6.9074138531000004, "ever": 1.9697270471500001, "creat": 4.9971671388, "how": 8.01251640255, "test": 15.94242677826, "instruct": 4.169117647059999, "repost": 933.882352941, "present": 1.25551601423, "than": 6.196721311499999, "deeper": 15.0769230769, "special": 1.4881889763799998, "initi": 2.7, "converg": 45.884393063699996, "end": 1.10680423871, "deep": 39.907678244939994, "joke": 11.1098670399, "report": 1.3634489866, "exploit": 5.79416058394, "pop": 7.33302540416, "difficulti": 15.342836433920002, "second": 1.1130898128, "wide": 6.2393397524, "updat": 16.69400630916, "portion": 6.603993344419999, "kind": 5.1612483745199995, "below": 6.76822509591, "near": 1.28769567686, "but": 11.17956596889, "definit": 3.24, "need": 14.372623574099999, "our": 44.79417879421, "longer": 4.04638715432, "final": 2.6801721955, "preclud": 34.588235294099995, "doubt": 5.31325301205, "amaz": 15.250720461099998, "naiv": 50.2405063291, "grow": 2.27287043665, "has": 4.1745990008, "have": 7.104263887979998, "paramet": 103.53913043460001, "stop": 6.535126234920001, "tensorflow": 933.882352941, "brandon": 79.7788944724, "use": 10.296387573799999, "default": 42.2796271638, "out": 5.30083472455, "model": 37.6307611272, "andrej": 738.418604652, "good": 13.67834577831, "alway": 2.06745670009, "excit": 9.818181818180001, "written": 1.9573418813999999, "much": 4.7768918309199995, "introduc": 3.4516795303800003, "cours": 2.15092805853, "hyperparamet": 15875.999999997, "optim": 149.9912790701, "around": 2.42789417342, "reason": 10.34042553192, "loss": 31.528872593920003, "short": 1.41295834817, "climb": 9.284210526319999, "not": 4.06269592476, "arbitrari": 17.8181818182, "length": 11.07370378983, "determin": 4.331787175980001, "bound": 16.222070844690002, "less": 2.93809567872, "four": 1.20950784702, "restart": 129.0731707316, "quick": 2.205, "true": 2.55569864778, "adopt": 2.0442956477000003, "shown": 5.53846153846, "appropri": 4.31413043478, "though": 1.36076112111, "scienc": 4.63939216832, "bayesian": 178.38202247200002, "they": 2.06034650574, "anoth": 2.27287043664, "jump": 24.21352313166, "let": 6.97233201582, "minimum": 24.11849601216, "general": 3.3654607122600004, "pytorch": 933.882352941, "blog": 14.1876675603, "stochast": 256.06451613, "unnecessarili": 118.47761194, "practic": 6.81739130436, "simpl": 3.3981164383599998, "that": 29.115537848749998, "provid": 2.43105428374, "subtl": 18.0, "valu": 68.33285509320001, "two": 3.04137931035, "develop": 2.3911439114400004, "such": 1.06151377374, "spot": 13.588587731819999, "sever": 1.07241286139, "those": 1.19548192771, "with": 20.023964179799997, "network": 38.9054076132, "deriv": 5.5675960021, "lot": 8.81755068036, "some": 4.16146788992, "phd": 22.3605633803, "small": 2.7189587258, "control": 1.46959178006, "add": 4.61243463103, "may": 3.15605327679, "result": 3.43834825296, "subset": 27.3253012048, "dropout": 167.115789474, "adam": 4.43092380687, "brute": 86.28260869569999, "languag": 2.29488291414, "set": 8.30955585467, "ani": 1.13383802314, "question": 2.20408163265, "sophist": 10.0037807183, "divid": 2.3169877408099997, "and": 49.00308661437, "from": 6.00340328982, "henc": 10.781663837019998, "train": 60.033666748099996, "answer": 4.64890190337, "tweet": 92.8421052632, "learningr": 933.882352941, "num": 6.00189024006, "instanc": 3.2572835453400004, "sought": 3.4513043478300007, "valley": 8.43346613546, "idea": 2.0930784443, "incred": 18.227324913900002, "for": 34.010711360340004, "difficult": 4.97914379802, "finegrain": 933.882352941, "seen": 1.61079545455, "practition": 37.7550535078, "lest": 62.015625, "forc": 1.32399299475, "new": 2.0357761108, "these": 3.22246278756, "are": 15.4485890367, "poor": 2.42196796339, "better": 8.026289181000001, "current": 1.5325803649, "sens": 2.8365195640499996, "look": 5.725895647979999, "veri": 6.29400570885, "steepest": 352.8, "reset": 130.6666666666, "work": 8.92160719304, "combin": 3.39520958084, "karpathi": 2801.647058823, "wast": 14.998582900339999, "net": 6.96315789474, "focus": 4.02025829324, "industrygrad": 933.882352941, "mean": 5.79627601316, "again": 3.01767724768, "cut": 2.4663663197099996, "then": 5.432893025799999, "singular": 16.8, "doe": 1.70581282905, "even": 4.65845070424, "littl": 4.649809626089999, "give": 2.7306501548, "dub": 7.55640171347, "proper": 3.3388012618299996, "circumv": 44.974504249300004, "retrain": 541.227272727, "place": 1.1004366812200002, "great": 2.53185551392, "avoid": 2.45986984816, "goal": 3.28152128979, "move": 5.16502643352, "ask": 2.1744966443, "librari": 2.68266306185, "probabl": 7.936677220469999, "machin": 12.073003802279999, "iter": 112.33018867919999, "paper": 2.6628648104700003, "prior": 2.17807655371, "realiti": 4.563380281690001, "rapid": 2.62586834271, "requir": 3.05689804564, "where": 1.06715063521, "figur": 2.0343413634, "what": 3.7603031738399997, "allow": 7.629635562660001, "exponenti": 78.4, "guess": 25.0410094637, "help": 2.79925945518, "breakneck": 721.636363636, "larg": 2.3714989917, "find": 32.858823529489996, "instead": 7.973081558850001, "potenti": 2.52080025405, "manual": 7.72930866602, "conclus": 4.84615384615, "approxim": 4.426599749059999, "natur": 1.5392670157100001, "deal": 2.18346857379, "fact": 5.20126679043, "hour": 2.25960717336, "teeth": 19.4083129584, "pictur": 3.4953764861300005, "univers": 2.49779735682, "permiss": 6.280063291139999, "the": 145.0, "post": 2.23826307627, "here": 4.84615384616, "lower": 4.20111140514, "ideal": 4.65571847507, "factor": 5.78255326898, "upper": 3.41052631579, "maximum": 24.003628666450002, "worldclass": 933.882352941, "through": 5.35374654345, "allevi": 22.6153846154, "long": 3.7971777086699996, "surpris": 4.36633663366, "layer": 8.14153846154, "contain": 1.59814777532, "about": 3.19458045477, "problem": 3.53349655018, "epoch": 153.391304348, "neural": 475.6853932584, "sure": 7.453521126760001, "just": 5.34320572148, "entir": 1.59365589239, "tini": 12.928338762200001, "nontrivi": 294.0, "cheap": 14.4327272727, "dure": 8.402778696639999, "classifi": 5.2937645882, "should": 4.99297620297, "across": 3.4637285916800002, "rememb": 4.88793103448, "complex": 2.34021226415, "plagu": 11.086592178800002, "start": 6.3336790872, "warm": 13.522998296419999, "intuit": 83.1204188481, "them": 1.09876115994, "fraction": 27.9507042254, "speed": 7.740614334480001, "studi": 1.53184098804, "keep": 6.12736395213, "bad": 3.3944836433599996, "energi": 3.66566612792, "systemat": 16.676470588239997, "execut": 4.4727426398, "singl": 3.21897810218, "whi": 6.513230769240001, "modif": 9.5753920386, "track": 3.1276595744700004, "mani": 4.17707031508, "over": 5.1262512108500005, "skip": 26.111842105300003, "increas": 6.60124740125, "build": 1.6341739578, "numcycl": 2801.647058823, "depict": 4.0131445905000005, "algorithm": 27.9507042254, "select": 2.02345144022, "consum": 4.93043478261, "unfortun": 9.966101694919999, "graph": 75.4204275534, "exact": 3.46864758575, "there": 8.32730133752, "primari": 2.2373167981999997, "fumbl": 176.4, "possibl": 5.6694937952, "way": 9.7525915688, "say": 3.5088960106, "best": 14.245663010940003, "exampl": 1.50483412322, "continu": 2.27857911734, "spend": 12.47786219544, "spent": 6.01591511936, "take": 7.97731677554, "visual": 5.22752716497, "hone": 66.15, "now": 2.321561746, "might": 6.468559011270001, "strategi": 8.88416340236, "further": 1.3618116315, "name": 1.10211732037, "code": 3.8807137619199996, "hard": 5.46506024096, "usual": 3.45017928936, "interact": 4.4185917061, "slope": 12.7620578778, "high": 9.1821862348, "power": 1.3396337861799998, "leverag": 35.7567567568, "fix": 4.4346368715099995, "also": 3.04429530201, "typic": 6.762459179339999, "invers": 21.483085250300004, "modern": 1.5319888063299998, "morri": 21.65893588, "will": 15.92254281748, "major": 1.14852058164, "research": 5.8260550458600004, "signific": 1.4529147982100001, "interplay": 73.8418604651, "area": 1.3881262568900001, "polici": 7.588910133839999, "arizona": 25.483146067399996, "describ": 1.47027227264, "piecewis": 1587.6, "want": 7.98792452832, "util": 4.65981802172, "howev": 1.0945191313299998, "intellig": 4.19334389857, "actual": 3.74964572508, "regim": 6.603993344430001, "minut": 3.11233091551, "dark": 3.98594024605, "which": 5.025959224999999, "like": 5.745928338750001, "imagenet": 933.882352941, "term": 1.39520168732, "estim": 2.34991119005, "other": 4.03969465648, "techniqu": 7.458773784360001, "one": 10.062749572200001, "inspir": 2.8487349721900004, "numenum": 567.0, "known": 3.25772913816, "impact": 5.95052473764, "see": 1.27242125511, "suitabl": 6.23811394892, "becaus": 1.1495184997499999, "imag": 2.70137825421, "loop": 13.5114893617, "get": 5.35687774155, "still": 4.746543089919999, "random": 43.1413043478, "lesli": 16.249744114600002, "could": 1.2043695949, "drop": 2.4594887684, "relat": 1.23750876919, "preposter": 260.262295082, "tri": 1.8544562551099997, "part": 2.08661365578, "outlin": 6.38102893891, "recent": 3.0881151527, "rule": 1.7415533128599998, "smith": 3.40102827763, "grid": 18.1232876712, "pick": 49.39639079030001, "this": 13.049317147230001, "pretti": 47.25, "rang": 21.417875210759995, "decent": 35.5964125561, "substanti": 3.4777656078900003, "step": 19.79551122192, "process": 5.08574479446, "back": 3.7821011673299996, "chang": 4.7235941684, "bit": 16.66771653544, "perform": 10.719783929750001, "smaller": 7.781081522639999, "differ": 1.23654490225, "novemb": 1.49393055425, "decis": 2.16, "most": 7.14675241161, "between": 1.03453668708, "low": 19.176486377670003, "interv": 26.5484949832, "game": 2.57978550536, "multimod": 256.064516129, "soon": 1.9817750592900003, "vision": 4.88041807562, "all": 2.02293577982, "fortun": 6.211267605630001, "gradient": 41.889182058, "tinker": 92.8421052632, "almost": 3.07168424108, "author": 1.4229631621399998, "weight": 14.636754763379997, "architectur": 10.25581395348, "cycl": 102.77478705282999, "rate": 113.44586760134999, "more": 8.1373654536, "improv": 16.35015447992, "permit": 3.7549668874199997, "rough": 3.29582727839, "benefit": 6.13683803634, "yourself": 26.592964824099997, "artifici": 16.63279203772, "faster": 15.22877697842, "befor": 1.10036041031, "comment": 3.05954904606, "point": 2.51980001588, "state": 3.1431399722699993, "close": 2.5697636775599997, "can": 16.46765947988, "comput": 11.783275606140002, "make": 1.0762660158600001, "sensibl": 48.328767123199995, "search": 29.28550932567, "onli": 3.0769429549800007, "each": 8.32823741008, "size": 2.49387370405, "superconverg": 2801.647058823, "student": 2.47174217655, "accur": 5.768895348840001, "schedul": 14.659279778399998, "common": 1.4025974025999999, "cozi": 278.526315789, "data": 13.50574223736, "reduc": 1.98698372966, "cyclic": 363.9197707736, "method": 15.428571428580002, "thumb": 33.3529411765, "perfect": 13.458038994059999, "fast": 4.8729281768, "sinc": 2.16737201366, "convolut": 101.121019108, "bio": 42.336000000000006, "come": 1.32831325301, "origin": 2.27449856734, "time": 11.12402063828, "abil": 2.70875277256, "insid": 2.7396031061299997, "right": 5.621813031159999, "understand": 5.93717277486, "direct": 3.66679498038, "import": 2.6803984467400004, "first": 2.01523229246, "everi": 1.47917637194, "luckili": 191.277108434, "enough": 2.2319696330700003, "while": 4.176795580119999, "resort": 8.16246786632, "without": 1.29547123623, "often": 2.5890410959, "gradual": 3.7890214797099997, "down": 2.71779508688, "learn": 137.04228237035002, "when": 2.0415353951, "effici": 10.18671799808}, "logtfidf": {"after": 0.020490694648099998, "hand": 0.958942670672, "art": 1.3857905193239999, "arguabl": 2.5594217052, "anneal": 11.123379899460001, "too": 4.175886083053999, "occur": 0.556973778473, "plot": 3.36668481018, "tempt": 3.87650606314, "immedi": 0.707357011133, "fastai": 13.6787009397, "space": 8.74713164972, "extra": 1.67490068688, "addit": 0.6606566489160001, "would": 0.23885288389409998, "thank": 1.7928938993, "number": 0.2898257352558, "boundari": 7.903151789600001, "decreas": 12.07353997952, "dataset": 15.79753369992, "function": 2.743397224782, "vari": 1.830189344864, "decay": 5.555787548940001, "descent": 2.13940500645, "suboptim": 12.7534538958, "three": 0.12823737644980002, "well": 0.3810866298936, "unlik": 0.885954358842, "done": 0.845975983129, "abov": 1.9315956894480002, "never": 0.886410872182, "big": 2.01597127114, "complet": 0.430570484094, "approach": 0.7302336145810001, "yield": 1.86708918863, "their": 0.030721010245400002, "gusto": 6.0616459012599995, "automat": 1.9150850473199998, "momentum": 8.47049259381, "particular": 1.61578696902, "ever": 0.6778949784020001, "creat": 0.890307274056, "how": 2.3578347846500005, "test": 5.863346622618, "instruct": 1.42770441799, "repost": 6.83935046985, "present": 0.227546654799, "than": 0.1935651733092, "deeper": 2.7131653017699997, "special": 0.39755992860100003, "initi": 0.6002091849, "converg": 8.18253825054, "end": 0.101476798618, "deep": 14.1754081678, "joke": 2.40783363597, "report": 0.31001750903700004, "exploit": 1.7568506145200002, "pop": 1.99238817347, "difficulti": 5.3774172886, "second": 0.10713976337999999, "wide": 1.7783200270159998, "updat": 5.149312388069999, "portion": 2.3890546753799997, "kind": 1.896062605434, "below": 2.440879775808, "near": 0.252854324034, "but": 0.1781160927909, "definit": 1.1755733298, "need": 3.62740163442, "our": 16.295145069458002, "longer": 1.4093544835499998, "final": 0.585467727896, "preclud": 3.54351360384, "doubt": 1.67020426765, "amaz": 2.7246267452900006, "naiv": 3.9168216003199996, "grow": 0.821043542212, "has": 0.1708957794192, "have": 0.1034950163884, "paramet": 17.089140863159997, "stop": 2.335738124889, "tensorflow": 6.83935046985, "brandon": 7.3722236172399995, "use": 0.292080197316, "default": 6.102316324279999, "out": 0.2921319545965, "model": 13.274101315998001, "andrej": 11.82272739642, "good": 3.7673046441629996, "alway": 0.726319204572, "excit": 2.28423595433, "written": 0.671587369833, "much": 0.7099829172040001, "introduc": 1.0914275048520001, "cours": 0.765899404133, "hyperparamet": 116.26895798745001, "optim": 31.793161340329995, "around": 0.38775421156400003, "reason": 3.265809317772, "loss": 11.517406664946, "short": 0.345685625679, "climb": 2.2283151644099997, "not": 0.06220965203, "arbitrari": 2.88021938643, "length": 3.9178829433600004, "determin": 1.545666038044, "bound": 5.06328127251, "less": 0.7692289252, "four": 0.190213538869, "restart": 13.89634038964, "quick": 0.790727508899, "true": 0.938325629634, "adopt": 0.7150533036110001, "shown": 2.03713916198, "appropri": 1.4618957827399999, "though": 0.308044191079, "scienc": 1.682872357782, "bayesian": 5.18392744417, "they": 0.0594539895352, "anoth": 0.255792723304, "jump": 6.264896986530001, "let": 2.4976051345599997, "minimum": 7.18673861764, "general": 0.344857734189, "pytorch": 6.83935046985, "blog": 2.65237310559, "stochast": 9.7045644966, "unnecessarili": 4.77472401395, "practic": 2.132730123468, "simpl": 1.2232212893899999, "that": 0.11530830300955999, "provid": 0.39035568865000003, "subtl": 2.8903717579, "valu": 24.69579930444, "two": 0.041096533074600004, "develop": 0.357249389826, "such": 0.059695977806, "spot": 4.53185404329, "sever": 0.06991112039689999, "those": 0.17854939087299998, "with": 0.0239498342678, "network": 14.296245795779999, "deriv": 2.0476323655, "lot": 2.9671939005000003, "some": 0.158294036258, "phd": 3.10729884387, "small": 0.614203610118, "control": 0.38498466158600003, "add": 1.52875583713, "may": 0.1521299858532, "result": 0.40913672514300004, "subset": 3.3078130570499997, "dropout": 5.1186869223, "adam": 1.4886080966, "brute": 4.45762805629, "languag": 0.8306818244059999, "set": 1.200472079023, "ani": 0.125608358366, "question": 0.790310929014, "sophist": 2.30296309338, "divid": 0.8402679544589999, "and": 0.0030865169611164, "from": 0.0034023250131959997, "henc": 3.36939943564, "train": 20.488467698009, "answer": 1.5366310419, "tweet": 4.5309002574, "learningr": 6.83935046985, "num": 0.0018899423723820002, "instanc": 1.18089357972, "sought": 1.23875223143, "valley": 2.8781213473400005, "idea": 0.73863592212, "incred": 2.9029218370499996, "for": 0.010709673443498002, "difficult": 1.824221535176, "finegrain": 6.83935046985, "seen": 0.47672812813, "practition": 5.87594430786, "lest": 4.12738636942, "forc": 0.280652166524, "new": 0.0354598937022, "these": 0.2146008582024, "are": 0.4420121037405, "poor": 0.8845804177050001, "better": 2.7857117624, "current": 0.42695282784500005, "sens": 1.04257779501, "look": 1.9391600808, "veri": 1.15079896619, "steepest": 5.86590132413, "reset": 8.35900474112, "work": 0.872276538184, "combin": 1.058436621502, "karpathi": 20.51805140955, "wast": 4.02961708554, "net": 1.9406330919499999, "focus": 1.3963979441119998, "industrygrad": 6.83935046985, "mean": 1.48368513408, "again": 0.822680463224, "cut": 0.90274594185, "then": 0.4151693261545, "singular": 2.82137888641, "doe": 0.5340417297169999, "even": 0.609554259336, "littl": 1.314641968398, "give": 0.622785104448, "dub": 2.02239511306, "proper": 1.2056118389200001, "circumv": 3.8060957569699996, "retrain": 15.585680998259999, "place": 0.0957070839572, "great": 0.471610516158, "avoid": 0.900108441291, "goal": 1.18830712273, "move": 1.022463437012, "ask": 0.776797209847, "librari": 0.986809980943, "probabl": 2.918647238739, "machin": 4.17707874186, "iter": 10.868491076009999, "paper": 0.979402539665, "prior": 0.778442172521, "realiti": 1.51806363875, "rapid": 0.965411638564, "requir": 0.84850702135, "where": 0.0649921387457, "figur": 0.7101721121600001, "what": 0.677661890481, "allow": 1.441683667134, "exponenti": 7.3373534936, "guess": 3.22051485947, "help": 0.672415442688, "breakneck": 6.58152136054, "larg": 0.34075012121200005, "find": 10.407845275472, "instead": 2.333165752075, "potenti": 0.9245764122419999, "manual": 2.04501942341, "conclus": 1.57818536893, "approxim": 1.5889691155540002, "natur": 0.431306339292, "deal": 0.780914701253, "fact": 1.6508697623849997, "hour": 0.815190981077, "teeth": 2.9657014773, "pictur": 1.25144109124, "univers": 0.444524211372, "permiss": 1.8373800586400002, "the": 0.0, "post": 0.8057001527009999, "here": 1.7700763767400003, "lower": 1.484403859988, "ideal": 1.53809624363, "factor": 2.12339629324, "upper": 1.22686662419, "maximum": 7.843835504600001, "worldclass": 6.83935046985, "through": 0.3417934594245, "allevi": 3.1186304098799997, "long": 0.706937381634, "surpris": 1.47392435861, "layer": 2.0969791623500003, "contain": 0.468845318236, "about": 0.18853043242380002, "problem": 1.138281448546, "epoch": 14.586791360320001, "neural": 32.682521244, "sure": 2.0086865552, "just": 1.158125736436, "entir": 0.46603068026999994, "tini": 2.5594217052, "nontrivi": 5.6835797673399995, "cheap": 2.66949835512, "dure": 0.3929672535152, "classifi": 1.6665296351499999, "should": 1.5282596302740001, "across": 1.098396911882, "rememb": 1.5867691126199999, "complex": 0.8502416364309999, "plagu": 2.4057364663799996, "start": 1.182216846455, "warm": 3.8224892659, "intuit": 9.965034291570001, "them": 0.0941833269093, "fraction": 5.27459042924, "speed": 2.7066677505400003, "studi": 0.426470272221, "keep": 2.142457034019, "bad": 1.2221516561799999, "energi": 1.29901007269, "systemat": 4.2417031971, "execut": 1.609709211728, "singl": 0.951833538118, "whi": 2.36137686094, "modif": 2.25919647821, "track": 1.14028498507, "mani": 0.1732630324884, "over": 0.1246836074785, "skip": 3.26238893194, "increas": 1.389103594645, "build": 0.491137452091, "numcycl": 20.51805140955, "depict": 1.38957512116, "algorithm": 3.33044239518, "select": 0.704804687133, "consum": 1.5954271753600002, "unfortun": 2.29918950399, "graph": 7.259861960439999, "exact": 1.2437647732500001, "there": 0.320783143404, "primari": 0.805277289914, "fumbl": 5.17275414357, "possibl": 1.395221899564, "way": 1.5847320794800002, "say": 1.124308561104, "best": 4.133051396523, "exampl": 0.40868267499899996, "continu": 0.26080974797400003, "spend": 4.27603128348, "spent": 2.20252259368, "take": 0.914843735379, "visual": 1.6539383488600001, "hone": 4.19192489056, "now": 0.298185890042, "might": 2.3050232296020003, "strategi": 2.98224623636, "further": 0.308815895297, "name": 0.09723316638430002, "code": 1.35601909597, "hard": 2.01045592812, "usual": 1.090558034128, "interact": 1.4858210267899998, "slope": 2.5464765406, "high": 1.1025902923200002, "power": 0.292396282715, "leverag": 3.5767392514699994, "fix": 1.48944573451, "also": 0.0439714734, "typic": 2.438322957474, "invers": 3.06726589295, "modern": 0.426566764719, "morri": 4.76454186292, "will": 2.6362249538950002, "major": 0.138474663439, "research": 1.991183454414, "signific": 0.373571744332, "interplay": 4.30192578578, "area": 0.327954821122, "polici": 2.78422710015, "arizona": 5.089740229119999, "describ": 0.385447603125, "piecewis": 13.353663080699999, "want": 2.7665464250199996, "util": 1.5389763962399998, "howev": 0.0903151173475, "intellig": 1.43349848213, "actual": 1.257028363296, "regim": 1.8876745182499999, "minut": 1.1353719359799999, "dark": 1.38277323072, "which": 0.02589206922715, "like": 0.6952678827250001, "imagenet": 6.83935046985, "term": 0.33303898354600003, "estim": 0.854377535975, "other": 0.03949899167904, "techniqu": 2.63248769614, "one": 0.062553516455, "inspir": 1.04687502633, "numenum": 6.340359303730001, "known": 0.2472542417976, "impact": 2.18066445262, "see": 0.240921585492, "suitabl": 1.83067788492, "becaus": 0.139343158825, "imag": 0.99376210729, "loop": 2.60354038732, "get": 1.739307017346, "still": 0.6844888857160001, "random": 11.836328439059999, "lesli": 2.78807716186, "could": 0.18595627229000003, "drop": 0.8999535106219999, "relat": 0.21310030165399999, "preposter": 5.561689949730001, "tri": 0.61759152916, "part": 0.08479062196560001, "outlin": 1.85332936004, "recent": 0.868827482576, "rule": 0.554777423537, "smith": 1.2240778205, "grid": 2.89719772297, "pick": 15.972922676100001, "this": 0.0492238376825, "pretti": 8.27052109581, "rang": 6.9518305656359995, "decent": 3.5722448618800002, "substanti": 1.24639002087, "step": 7.27681539886, "process": 1.583487597075, "back": 0.695002292691, "chang": 0.665102500232, "bit": 4.24065305268, "perform": 2.98326595406, "smaller": 2.8592491591559996, "differ": 0.212321121312, "novemb": 0.40141060253, "decis": 0.7701082216959999, "most": 0.14523527406919998, "between": 0.033953681165299995, "low": 6.8081425501410004, "interv": 5.17165175878, "game": 0.9477062580210001, "multimod": 5.54542942886, "soon": 0.6839929376880001, "vision": 1.58523088743, "all": 0.022805264195599997, "fortun": 1.8263649984099999, "gradient": 3.73502760882, "tinker": 4.5309002574, "almost": 0.8581576866680001, "author": 0.35274143130999996, "weight": 4.7547705783600005, "architectur": 3.26939515838, "cycl": 32.07392055116, "rate": 40.334795224798, "more": 0.13619945279999998, "improv": 5.718366431455999, "permit": 1.32307946691, "rough": 1.1926572072700001, "benefit": 2.24232490232, "yourself": 3.28064670051, "artifici": 4.23645798036, "faster": 4.06007935934, "befor": 0.0956377718795, "comment": 1.11826753454, "point": 0.46206471806599997, "state": 0.13983000830040002, "close": 0.501333519728, "can": 2.272775349516, "comput": 4.104206747819999, "make": 0.07349765782289999, "sensibl": 6.36975959084, "search": 10.618814286809998, "onli": 0.0759728049873, "each": 1.216191825128, "size": 0.9138372060609999, "superconverg": 20.51805140955, "student": 0.904923236645, "accur": 1.75248061485, "schedul": 5.195116823119999, "common": 0.338325805271, "cozi": 5.62951254607, "data": 4.8672823392, "reduc": 0.686617775143, "cyclic": 30.5399351336, "method": 5.666769653046, "thumb": 3.5071459596699994, "perfect": 4.50289300068, "fast": 1.5836950247400001, "sinc": 0.1607363989154, "convolut": 4.61631800855, "bio": 3.7456377879300002, "come": 0.28390990653000003, "origin": 0.257224875174, "time": 0.1233267074886, "abil": 0.996488297427, "insid": 1.00781305813, "right": 1.36143941668, "understand": 2.1761717513599996, "direct": 0.6021170684880001, "import": 0.585636554132, "first": 0.015174579624319999, "everi": 0.391485427421, "luckili": 5.25372320611, "enough": 0.802884439169, "while": 0.17299993517520004, "resort": 2.09954655785, "without": 0.258874517941, "often": 0.516280786702, "gradual": 1.3321078009899998, "down": 0.613347482372, "learn": 49.722371819955, "when": 0.0411099777168, "effici": 3.25587506828}, "logidf": {"after": 0.020490694648099998, "hand": 0.479471335336, "art": 0.6928952596619999, "arguabl": 2.5594217052, "anneal": 5.561689949730001, "too": 0.5965551547219999, "occur": 0.556973778473, "plot": 1.68334240509, "tempt": 3.87650606314, "immedi": 0.707357011133, "fastai": 6.83935046985, "space": 0.874713164972, "extra": 1.67490068688, "addit": 0.220218882972, "would": 0.0796176279647, "thank": 1.7928938993, "number": 0.0966085784186, "boundari": 1.58063035792, "decreas": 1.50919249744, "dataset": 5.26584456664, "function": 0.914465741594, "vari": 0.915094672432, "decay": 2.7778937744700003, "descent": 2.13940500645, "suboptim": 6.3767269479, "three": 0.06411868822490001, "well": 0.0635144383156, "unlik": 0.885954358842, "done": 0.845975983129, "abov": 0.643865229816, "never": 0.443205436091, "big": 1.00798563557, "complet": 0.215285242047, "approach": 0.7302336145810001, "yield": 1.86708918863, "their": 0.015360505122700001, "gusto": 6.0616459012599995, "automat": 1.9150850473199998, "momentum": 2.82349753127, "particular": 0.323157393804, "ever": 0.6778949784020001, "creat": 0.222576818514, "how": 0.47156695693000006, "test": 0.977224437103, "instruct": 1.42770441799, "repost": 6.83935046985, "present": 0.227546654799, "than": 0.0322608622182, "deeper": 2.7131653017699997, "special": 0.39755992860100003, "initi": 0.30010459245, "converg": 2.7275127501800003, "end": 0.101476798618, "deep": 1.2886734698, "joke": 2.40783363597, "report": 0.31001750903700004, "exploit": 1.7568506145200002, "pop": 1.99238817347, "difficulti": 1.34435432215, "second": 0.10713976337999999, "wide": 0.44458000675399995, "updat": 1.7164374626899999, "portion": 1.1945273376899999, "kind": 0.948031302717, "below": 0.813626591936, "near": 0.252854324034, "but": 0.0161923720719, "definit": 1.1755733298, "need": 0.362740163442, "our": 0.8576392141820001, "longer": 0.7046772417749999, "final": 0.292733863948, "preclud": 3.54351360384, "doubt": 1.67020426765, "amaz": 2.7246267452900006, "naiv": 3.9168216003199996, "grow": 0.821043542212, "has": 0.0427239448548, "have": 0.0147850023412, "paramet": 2.8481901438599997, "stop": 0.778579374963, "tensorflow": 6.83935046985, "brandon": 3.6861118086199998, "use": 0.0292080197316, "default": 3.0511581621399997, "out": 0.0584263909193, "model": 0.7374500731110001, "andrej": 5.91136369821, "good": 0.418589404907, "alway": 0.726319204572, "excit": 2.28423595433, "written": 0.671587369833, "much": 0.17749572930100002, "introduc": 0.5457137524260001, "cours": 0.765899404133, "hyperparamet": 6.83935046985, "optim": 2.4456277954099996, "around": 0.19387710578200001, "reason": 0.544301552962, "loss": 0.885954358842, "short": 0.345685625679, "climb": 2.2283151644099997, "not": 0.0155524130075, "arbitrari": 2.88021938643, "length": 1.3059609811200001, "determin": 0.772833019022, "bound": 1.68776042417, "less": 0.3846144626, "four": 0.190213538869, "restart": 3.47408509741, "quick": 0.790727508899, "true": 0.938325629634, "adopt": 0.7150533036110001, "shown": 1.01856958099, "appropri": 1.4618957827399999, "though": 0.308044191079, "scienc": 0.841436178891, "bayesian": 5.18392744417, "they": 0.0297269947676, "anoth": 0.127896361652, "jump": 2.08829899551, "let": 1.2488025672799998, "minimum": 1.79668465441, "general": 0.114952578063, "pytorch": 6.83935046985, "blog": 2.65237310559, "stochast": 4.8522822483, "unnecessarili": 4.77472401395, "practic": 0.533182530867, "simpl": 1.2232212893899999, "that": 0.00397614837964, "provid": 0.19517784432500002, "subtl": 2.8903717579, "valu": 0.823193310148, "two": 0.0136988443582, "develop": 0.178624694913, "such": 0.059695977806, "spot": 1.5106180144299999, "sever": 0.06991112039689999, "those": 0.17854939087299998, "with": 0.00119749171339, "network": 0.9530830530519999, "deriv": 1.02381618275, "lot": 1.4835969502500002, "some": 0.0395735090645, "phd": 3.10729884387, "small": 0.307101805059, "control": 0.38498466158600003, "add": 1.52875583713, "may": 0.050709995284400004, "result": 0.136378908381, "subset": 3.3078130570499997, "dropout": 5.1186869223, "adam": 1.4886080966, "brute": 4.45762805629, "languag": 0.8306818244059999, "set": 0.171496011289, "ani": 0.125608358366, "question": 0.790310929014, "sophist": 2.30296309338, "divid": 0.8402679544589999, "and": 6.29901420636e-05, "from": 0.000567054168866, "henc": 1.68469971782, "train": 0.660918312839, "answer": 1.5366310419, "tweet": 4.5309002574, "learningr": 6.83935046985, "num": 0.00031499039539700004, "instanc": 1.18089357972, "sought": 1.23875223143, "valley": 1.4390606736700002, "idea": 0.73863592212, "incred": 2.9029218370499996, "for": 0.00031499039539700004, "difficult": 0.912110767588, "finegrain": 6.83935046985, "seen": 0.47672812813, "practition": 2.93797215393, "lest": 4.12738636942, "forc": 0.280652166524, "new": 0.0177299468511, "these": 0.0715336194008, "are": 0.0294674735827, "poor": 0.8845804177050001, "better": 0.6964279406, "current": 0.42695282784500005, "sens": 1.04257779501, "look": 0.6463866936, "veri": 0.230159793238, "steepest": 5.86590132413, "reset": 4.17950237056, "work": 0.109034567273, "combin": 0.529218310751, "karpathi": 6.83935046985, "wast": 2.01480854277, "net": 1.9406330919499999, "focus": 0.6981989720559999, "industrygrad": 6.83935046985, "mean": 0.37092128352, "again": 0.411340231612, "cut": 0.90274594185, "then": 0.08303386523089999, "singular": 2.82137888641, "doe": 0.5340417297169999, "even": 0.152388564834, "littl": 0.438213989466, "give": 0.311392552224, "dub": 2.02239511306, "proper": 1.2056118389200001, "circumv": 3.8060957569699996, "retrain": 5.19522699942, "place": 0.0957070839572, "great": 0.235805258079, "avoid": 0.900108441291, "goal": 1.18830712273, "move": 0.255615859253, "ask": 0.776797209847, "librari": 0.986809980943, "probabl": 0.972882412913, "machin": 1.39235958062, "iter": 3.62283035867, "paper": 0.979402539665, "prior": 0.778442172521, "realiti": 1.51806363875, "rapid": 0.965411638564, "requir": 0.424253510675, "where": 0.0649921387457, "figur": 0.7101721121600001, "what": 0.225887296827, "allow": 0.24028061118900002, "exponenti": 3.6686767468, "guess": 3.22051485947, "help": 0.336207721344, "breakneck": 6.58152136054, "larg": 0.17037506060600002, "find": 0.547781330288, "instead": 0.46663315041500003, "potenti": 0.9245764122419999, "manual": 2.04501942341, "conclus": 1.57818536893, "approxim": 0.7944845577770001, "natur": 0.431306339292, "deal": 0.780914701253, "fact": 0.5502899207949999, "hour": 0.815190981077, "teeth": 2.9657014773, "pictur": 1.25144109124, "univers": 0.222262105686, "permiss": 1.8373800586400002, "the": 0.0, "post": 0.8057001527009999, "here": 0.8850381883700001, "lower": 0.742201929994, "ideal": 1.53809624363, "factor": 1.06169814662, "upper": 1.22686662419, "maximum": 1.5687671009200002, "worldclass": 6.83935046985, "through": 0.0683586918849, "allevi": 3.1186304098799997, "long": 0.235645793878, "surpris": 1.47392435861, "layer": 2.0969791623500003, "contain": 0.468845318236, "about": 0.0628434774746, "problem": 0.569140724273, "epoch": 3.6466978400800003, "neural": 4.0853151555, "sure": 2.0086865552, "just": 0.289531434109, "entir": 0.46603068026999994, "tini": 2.5594217052, "nontrivi": 5.6835797673399995, "cheap": 2.66949835512, "dure": 0.0491209066894, "classifi": 1.6665296351499999, "should": 0.509419876758, "across": 0.549198455941, "rememb": 1.5867691126199999, "complex": 0.8502416364309999, "plagu": 2.4057364663799996, "start": 0.236443369291, "warm": 1.91124463295, "intuit": 3.3216780971900004, "them": 0.0941833269093, "fraction": 2.63729521462, "speed": 1.3533338752700002, "studi": 0.426470272221, "keep": 0.7141523446729999, "bad": 1.2221516561799999, "energi": 1.29901007269, "systemat": 2.12085159855, "execut": 0.804854605864, "singl": 0.475916769059, "whi": 1.18068843047, "modif": 2.25919647821, "track": 1.14028498507, "mani": 0.0433157581221, "over": 0.0249367214957, "skip": 3.26238893194, "increas": 0.277820718929, "build": 0.491137452091, "numcycl": 6.83935046985, "depict": 1.38957512116, "algorithm": 3.33044239518, "select": 0.704804687133, "consum": 1.5954271753600002, "unfortun": 2.29918950399, "graph": 3.6299309802199997, "exact": 1.2437647732500001, "there": 0.0400978929255, "primari": 0.805277289914, "fumbl": 5.17275414357, "possibl": 0.348805474891, "way": 0.19809150993500002, "say": 0.562154280552, "best": 0.459227932947, "exampl": 0.40868267499899996, "continu": 0.13040487398700001, "spend": 1.42534376116, "spent": 1.10126129684, "take": 0.130691962197, "visual": 1.6539383488600001, "hone": 4.19192489056, "now": 0.149092945021, "might": 0.7683410765340001, "strategi": 1.49112311818, "further": 0.308815895297, "name": 0.09723316638430002, "code": 1.35601909597, "hard": 1.00522796406, "usual": 0.545279017064, "interact": 1.4858210267899998, "slope": 2.5464765406, "high": 0.13782378654000002, "power": 0.292396282715, "leverag": 3.5767392514699994, "fix": 1.48944573451, "also": 0.0146571578, "typic": 0.812774319158, "invers": 3.06726589295, "modern": 0.426566764719, "morri": 2.38227093146, "will": 0.202786534915, "major": 0.138474663439, "research": 0.663727818138, "signific": 0.373571744332, "interplay": 4.30192578578, "area": 0.327954821122, "polici": 0.92807570005, "arizona": 2.5448701145599997, "describ": 0.385447603125, "piecewis": 6.676831540349999, "want": 0.6916366062549999, "util": 1.5389763962399998, "howev": 0.0903151173475, "intellig": 1.43349848213, "actual": 0.628514181648, "regim": 1.8876745182499999, "minut": 1.1353719359799999, "dark": 1.38277323072, "which": 0.00517841384543, "like": 0.139053576545, "imagenet": 6.83935046985, "term": 0.33303898354600003, "estim": 0.854377535975, "other": 0.00987474791976, "techniqu": 1.31624384807, "one": 0.0062553516455, "inspir": 1.04687502633, "numenum": 6.340359303730001, "known": 0.0824180805992, "impact": 1.09033222631, "see": 0.240921585492, "suitabl": 1.83067788492, "becaus": 0.139343158825, "imag": 0.99376210729, "loop": 2.60354038732, "get": 0.579769005782, "still": 0.17112222142900002, "random": 1.9727214065099998, "lesli": 2.78807716186, "could": 0.18595627229000003, "drop": 0.8999535106219999, "relat": 0.21310030165399999, "preposter": 5.561689949730001, "tri": 0.61759152916, "part": 0.04239531098280001, "outlin": 1.85332936004, "recent": 0.434413741288, "rule": 0.554777423537, "smith": 1.2240778205, "grid": 2.89719772297, "pick": 1.59729226761, "this": 0.0037864490525, "pretti": 2.75684036527, "rang": 0.579319213803, "decent": 3.5722448618800002, "substanti": 1.24639002087, "step": 1.03954505698, "process": 0.527829199025, "back": 0.23166743089699998, "chang": 0.166275625058, "bit": 2.12032652634, "perform": 0.42618085058, "smaller": 0.9530830530519999, "differ": 0.212321121312, "novemb": 0.40141060253, "decis": 0.7701082216959999, "most": 0.020747896295599998, "between": 0.033953681165299995, "low": 0.7564602833490001, "interv": 2.58582587939, "game": 0.9477062580210001, "multimod": 5.54542942886, "soon": 0.6839929376880001, "vision": 1.58523088743, "all": 0.011402632097799998, "fortun": 1.8263649984099999, "gradient": 3.73502760882, "tinker": 4.5309002574, "almost": 0.42907884333400004, "author": 0.35274143130999996, "weight": 1.58492352612, "architectur": 1.63469757919, "cycl": 1.68810108164, "rate": 0.761033872166, "more": 0.017024931599999998, "improv": 0.7147958039319999, "permit": 1.32307946691, "rough": 1.1926572072700001, "benefit": 1.12116245116, "yourself": 3.28064670051, "artifici": 2.11822899018, "faster": 2.03003967967, "befor": 0.0956377718795, "comment": 1.11826753454, "point": 0.23103235903299998, "state": 0.0466100027668, "close": 0.250666759864, "can": 0.162341096394, "comput": 1.36806891594, "make": 0.07349765782289999, "sensibl": 3.18487979542, "search": 1.1798682540899998, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "superconverg": 6.83935046985, "student": 0.904923236645, "accur": 1.75248061485, "schedul": 1.2987792057799998, "common": 0.338325805271, "cozi": 5.62951254607, "data": 1.2168205848, "reduc": 0.686617775143, "cyclic": 3.8174918917, "method": 0.944461608841, "thumb": 3.5071459596699994, "perfect": 1.50096433356, "fast": 1.5836950247400001, "sinc": 0.0803681994577, "convolut": 4.61631800855, "bio": 3.7456377879300002, "come": 0.28390990653000003, "origin": 0.128612437587, "time": 0.0112115188626, "abil": 0.996488297427, "insid": 1.00781305813, "right": 0.34035985417, "understand": 1.0880858756799998, "direct": 0.200705689496, "import": 0.292818277066, "first": 0.0075872898121599995, "everi": 0.391485427421, "luckili": 5.25372320611, "enough": 0.802884439169, "while": 0.04324998379380001, "resort": 2.09954655785, "without": 0.258874517941, "often": 0.258140393351, "gradual": 1.3321078009899998, "down": 0.306673741186, "learn": 0.842752064745, "when": 0.0205549888584, "effici": 1.62793753414}, "freq": {"after": 1, "hand": 2, "art": 2, "arguabl": 1, "anneal": 2, "too": 7, "occur": 1, "plot": 2, "tempt": 1, "immedi": 1, "fastai": 2, "space": 10, "extra": 1, "addit": 3, "would": 3, "thank": 1, "number": 3, "boundari": 5, "decreas": 8, "dataset": 3, "function": 3, "vari": 2, "decay": 2, "descent": 1, "suboptim": 2, "three": 2, "well": 6, "unlik": 1, "done": 1, "abov": 3, "never": 2, "big": 2, "complet": 2, "approach": 1, "yield": 1, "their": 2, "gusto": 1, "automat": 1, "momentum": 3, "particular": 5, "ever": 1, "creat": 4, "how": 5, "test": 6, "instruct": 1, "repost": 1, "present": 1, "than": 6, "deeper": 1, "special": 1, "initi": 2, "converg": 3, "end": 1, "deep": 11, "joke": 1, "report": 1, "exploit": 1, "pop": 1, "difficulti": 4, "second": 1, "wide": 4, "updat": 3, "portion": 2, "kind": 2, "below": 3, "near": 1, "but": 11, "definit": 1, "need": 10, "our": 19, "longer": 2, "final": 2, "preclud": 1, "doubt": 1, "amaz": 1, "naiv": 1, "grow": 1, "has": 4, "have": 7, "paramet": 6, "stop": 3, "tensorflow": 1, "brandon": 2, "use": 10, "default": 2, "out": 5, "model": 18, "andrej": 2, "good": 9, "alway": 1, "excit": 1, "written": 1, "much": 4, "introduc": 2, "cours": 1, "hyperparamet": 17, "optim": 13, "around": 2, "reason": 6, "loss": 13, "short": 1, "climb": 1, "not": 4, "arbitrari": 1, "length": 3, "determin": 2, "bound": 3, "less": 2, "four": 1, "restart": 4, "quick": 1, "true": 1, "adopt": 1, "shown": 2, "appropri": 1, "though": 1, "scienc": 2, "bayesian": 1, "they": 2, "anoth": 2, "jump": 3, "let": 2, "minimum": 4, "general": 3, "pytorch": 1, "blog": 1, "stochast": 2, "unnecessarili": 1, "practic": 4, "simpl": 1, "that": 29, "provid": 2, "subtl": 1, "valu": 30, "two": 3, "develop": 2, "such": 1, "spot": 3, "sever": 1, "those": 1, "with": 20, "network": 15, "deriv": 2, "lot": 2, "some": 4, "phd": 1, "small": 2, "control": 1, "add": 1, "may": 3, "result": 3, "subset": 1, "dropout": 1, "adam": 1, "brute": 1, "languag": 1, "set": 7, "ani": 1, "question": 1, "sophist": 1, "divid": 1, "and": 49, "from": 6, "henc": 2, "train": 31, "answer": 1, "tweet": 1, "learningr": 1, "num": 6, "instanc": 1, "sought": 1, "valley": 2, "idea": 1, "incred": 1, "for": 34, "difficult": 2, "finegrain": 1, "seen": 1, "practition": 2, "lest": 1, "forc": 1, "new": 2, "these": 3, "are": 15, "poor": 1, "better": 4, "current": 1, "sens": 1, "look": 3, "veri": 5, "steepest": 1, "reset": 2, "work": 8, "combin": 2, "karpathi": 3, "wast": 2, "net": 1, "focus": 2, "industrygrad": 1, "mean": 4, "again": 2, "cut": 1, "then": 5, "singular": 1, "doe": 1, "even": 4, "littl": 3, "give": 2, "dub": 1, "proper": 1, "circumv": 1, "retrain": 3, "place": 1, "great": 2, "avoid": 1, "goal": 1, "move": 4, "ask": 1, "librari": 1, "probabl": 3, "machin": 3, "iter": 3, "paper": 1, "prior": 1, "realiti": 1, "rapid": 1, "requir": 2, "where": 1, "figur": 1, "what": 3, "allow": 6, "exponenti": 2, "guess": 1, "help": 2, "breakneck": 1, "larg": 2, "find": 19, "instead": 5, "potenti": 1, "manual": 1, "conclus": 1, "approxim": 2, "natur": 1, "deal": 1, "fact": 3, "hour": 1, "teeth": 1, "pictur": 1, "univers": 2, "permiss": 1, "the": 145, "post": 1, "here": 2, "lower": 2, "ideal": 1, "factor": 2, "upper": 1, "maximum": 5, "worldclass": 1, "through": 5, "allevi": 1, "long": 3, "surpris": 1, "layer": 1, "contain": 1, "about": 3, "problem": 2, "epoch": 4, "neural": 8, "sure": 1, "just": 4, "entir": 1, "tini": 1, "nontrivi": 1, "cheap": 1, "dure": 8, "classifi": 1, "should": 3, "across": 2, "rememb": 1, "complex": 1, "plagu": 1, "start": 5, "warm": 2, "intuit": 3, "them": 1, "fraction": 2, "speed": 2, "studi": 1, "keep": 3, "bad": 1, "energi": 1, "systemat": 2, "execut": 2, "singl": 2, "whi": 2, "modif": 1, "track": 1, "mani": 4, "over": 5, "skip": 1, "increas": 5, "build": 1, "numcycl": 3, "depict": 1, "algorithm": 1, "select": 1, "consum": 1, "unfortun": 1, "graph": 2, "exact": 1, "there": 8, "primari": 1, "fumbl": 1, "possibl": 4, "way": 8, "say": 2, "best": 9, "exampl": 1, "continu": 2, "spend": 3, "spent": 2, "take": 7, "visual": 1, "hone": 1, "now": 2, "might": 3, "strategi": 2, "further": 1, "name": 1, "code": 1, "hard": 2, "usual": 2, "interact": 1, "slope": 1, "high": 8, "power": 1, "leverag": 1, "fix": 1, "also": 3, "typic": 3, "invers": 1, "modern": 1, "morri": 2, "will": 13, "major": 1, "research": 3, "signific": 1, "interplay": 1, "area": 1, "polici": 3, "arizona": 2, "describ": 1, "piecewis": 2, "want": 4, "util": 1, "howev": 1, "intellig": 1, "actual": 2, "regim": 1, "minut": 1, "dark": 1, "which": 5, "like": 5, "imagenet": 1, "term": 1, "estim": 1, "other": 4, "techniqu": 2, "one": 10, "inspir": 1, "numenum": 1, "known": 3, "impact": 2, "see": 1, "suitabl": 1, "becaus": 1, "imag": 1, "loop": 1, "get": 3, "still": 4, "random": 6, "lesli": 1, "could": 1, "drop": 1, "relat": 1, "preposter": 1, "tri": 1, "part": 2, "outlin": 1, "recent": 2, "rule": 1, "smith": 1, "grid": 1, "pick": 10, "this": 13, "pretti": 3, "rang": 12, "decent": 1, "substanti": 1, "step": 7, "process": 3, "back": 3, "chang": 4, "bit": 2, "perform": 7, "smaller": 3, "differ": 1, "novemb": 1, "decis": 1, "most": 7, "between": 1, "low": 9, "interv": 2, "game": 1, "multimod": 1, "soon": 1, "vision": 1, "all": 2, "fortun": 1, "gradient": 1, "tinker": 1, "almost": 2, "author": 1, "weight": 3, "architectur": 2, "cycl": 19, "rate": 53, "more": 8, "improv": 8, "permit": 1, "rough": 1, "benefit": 2, "yourself": 1, "artifici": 2, "faster": 2, "befor": 1, "comment": 1, "point": 2, "state": 3, "close": 2, "can": 14, "comput": 3, "make": 1, "sensibl": 2, "search": 9, "onli": 3, "each": 7, "size": 1, "superconverg": 3, "student": 1, "accur": 1, "schedul": 4, "common": 1, "cozi": 1, "data": 4, "reduc": 1, "cyclic": 8, "method": 6, "thumb": 1, "perfect": 3, "fast": 1, "sinc": 2, "convolut": 1, "bio": 1, "come": 1, "origin": 2, "time": 11, "abil": 1, "insid": 1, "right": 4, "understand": 2, "direct": 3, "import": 2, "first": 2, "everi": 1, "luckili": 1, "enough": 1, "while": 4, "resort": 1, "without": 1, "often": 2, "gradual": 1, "down": 2, "learn": 59, "when": 2, "effici": 2}, "idf": {"after": 1.02070207021, "hand": 1.6152202665600002, "art": 1.9994962216599999, "arguabl": 12.928338762200001, "anneal": 260.262295082, "too": 1.81585268215, "occur": 1.7453825857499998, "plot": 5.383519837230001, "tempt": 48.2553191489, "immedi": 2.02862254025, "fastai": 933.882352941, "space": 2.39818731118, "extra": 5.33826496301, "addit": 1.24634950542, "would": 1.0828729281799998, "thank": 6.00681044268, "number": 1.10142916609, "boundari": 4.85801713586, "decreas": 4.5230769230800005, "dataset": 193.609756098, "function": 2.495441685, "vari": 2.4970116388799997, "decay": 16.085106383, "descent": 8.494382022469999, "suboptim": 588.0, "three": 1.06621893889, "well": 1.0655748708, "unlik": 2.42529789184, "done": 2.3302509907499998, "abov": 1.90382539873, "never": 1.55769230769, "big": 2.7400759406299997, "complet": 1.24021560816, "approach": 2.07556543339, "yield": 6.46943765281, "their": 1.01547908405, "gusto": 429.081081081, "automat": 6.787516032490001, "momentum": 16.835630965, "particular": 1.3814827706200001, "ever": 1.9697270471500001, "creat": 1.2492917847, "how": 1.60250328051, "test": 2.65707112971, "instruct": 4.169117647059999, "repost": 933.882352941, "present": 1.25551601423, "than": 1.03278688525, "deeper": 15.0769230769, "special": 1.4881889763799998, "initi": 1.35, "converg": 15.2947976879, "end": 1.10680423871, "deep": 3.6279707495399998, "joke": 11.1098670399, "report": 1.3634489866, "exploit": 5.79416058394, "pop": 7.33302540416, "difficulti": 3.8357091084800006, "second": 1.1130898128, "wide": 1.5598349381, "updat": 5.56466876972, "portion": 3.3019966722099996, "kind": 2.5806241872599998, "below": 2.25607503197, "near": 1.28769567686, "but": 1.01632417899, "definit": 3.24, "need": 1.4372623574099999, "our": 2.35758835759, "longer": 2.02319357716, "final": 1.34008609775, "preclud": 34.588235294099995, "doubt": 5.31325301205, "amaz": 15.250720461099998, "naiv": 50.2405063291, "grow": 2.27287043665, "has": 1.0436497502, "have": 1.0148948411399998, "paramet": 17.256521739100002, "stop": 2.1783754116400003, "tensorflow": 933.882352941, "brandon": 39.8894472362, "use": 1.0296387573799999, "default": 21.1398135819, "out": 1.06016694491, "model": 2.0905978404, "andrej": 369.209302326, "good": 1.51981619759, "alway": 2.06745670009, "excit": 9.818181818180001, "written": 1.9573418813999999, "much": 1.1942229577299999, "introduc": 1.7258397651900002, "cours": 2.15092805853, "hyperparamet": 933.882352941, "optim": 11.5377906977, "around": 1.21394708671, "reason": 1.72340425532, "loss": 2.42529789184, "short": 1.41295834817, "climb": 9.284210526319999, "not": 1.01567398119, "arbitrari": 17.8181818182, "length": 3.69123459661, "determin": 2.1658935879900003, "bound": 5.40735694823, "less": 1.46904783936, "four": 1.20950784702, "restart": 32.2682926829, "quick": 2.205, "true": 2.55569864778, "adopt": 2.0442956477000003, "shown": 2.76923076923, "appropri": 4.31413043478, "though": 1.36076112111, "scienc": 2.31969608416, "bayesian": 178.38202247200002, "they": 1.03017325287, "anoth": 1.13643521832, "jump": 8.07117437722, "let": 3.48616600791, "minimum": 6.02962400304, "general": 1.1218202374200001, "pytorch": 933.882352941, "blog": 14.1876675603, "stochast": 128.032258065, "unnecessarili": 118.47761194, "practic": 1.70434782609, "simpl": 3.3981164383599998, "that": 1.00398406375, "provid": 1.21552714187, "subtl": 18.0, "valu": 2.2777618364400003, "two": 1.01379310345, "develop": 1.1955719557200002, "such": 1.06151377374, "spot": 4.52952924394, "sever": 1.07241286139, "those": 1.19548192771, "with": 1.0011982089899998, "network": 2.59369384088, "deriv": 2.78379800105, "lot": 4.40877534018, "some": 1.04036697248, "phd": 22.3605633803, "small": 1.3594793629, "control": 1.46959178006, "add": 4.61243463103, "may": 1.05201775893, "result": 1.14611608432, "subset": 27.3253012048, "dropout": 167.115789474, "adam": 4.43092380687, "brute": 86.28260869569999, "languag": 2.29488291414, "set": 1.18707940781, "ani": 1.13383802314, "question": 2.20408163265, "sophist": 10.0037807183, "divid": 2.3169877408099997, "and": 1.00006299213, "from": 1.00056721497, "henc": 5.390831918509999, "train": 1.9365698950999999, "answer": 4.64890190337, "tweet": 92.8421052632, "learningr": 933.882352941, "num": 1.00031504001, "instanc": 3.2572835453400004, "sought": 3.4513043478300007, "valley": 4.21673306773, "idea": 2.0930784443, "incred": 18.227324913900002, "for": 1.00031504001, "difficult": 2.48957189901, "finegrain": 933.882352941, "seen": 1.61079545455, "practition": 18.8775267539, "lest": 62.015625, "forc": 1.32399299475, "new": 1.0178880554, "these": 1.07415426252, "are": 1.02990593578, "poor": 2.42196796339, "better": 2.0065722952500002, "current": 1.5325803649, "sens": 2.8365195640499996, "look": 1.9086318826599997, "veri": 1.25880114177, "steepest": 352.8, "reset": 65.3333333333, "work": 1.11520089913, "combin": 1.69760479042, "karpathi": 933.882352941, "wast": 7.499291450169999, "net": 6.96315789474, "focus": 2.01012914662, "industrygrad": 933.882352941, "mean": 1.44906900329, "again": 1.50883862384, "cut": 2.4663663197099996, "then": 1.08657860516, "singular": 16.8, "doe": 1.70581282905, "even": 1.16461267606, "littl": 1.5499365420299998, "give": 1.3653250774, "dub": 7.55640171347, "proper": 3.3388012618299996, "circumv": 44.974504249300004, "retrain": 180.409090909, "place": 1.1004366812200002, "great": 1.26592775696, "avoid": 2.45986984816, "goal": 3.28152128979, "move": 1.29125660838, "ask": 2.1744966443, "librari": 2.68266306185, "probabl": 2.64555907349, "machin": 4.02433460076, "iter": 37.4433962264, "paper": 2.6628648104700003, "prior": 2.17807655371, "realiti": 4.563380281690001, "rapid": 2.62586834271, "requir": 1.52844902282, "where": 1.06715063521, "figur": 2.0343413634, "what": 1.25343439128, "allow": 1.2716059271100002, "exponenti": 39.2, "guess": 25.0410094637, "help": 1.39962972759, "breakneck": 721.636363636, "larg": 1.18574949585, "find": 1.7294117647099998, "instead": 1.59461631177, "potenti": 2.52080025405, "manual": 7.72930866602, "conclus": 4.84615384615, "approxim": 2.2132998745299997, "natur": 1.5392670157100001, "deal": 2.18346857379, "fact": 1.73375559681, "hour": 2.25960717336, "teeth": 19.4083129584, "pictur": 3.4953764861300005, "univers": 1.24889867841, "permiss": 6.280063291139999, "the": 1.0, "post": 2.23826307627, "here": 2.42307692308, "lower": 2.10055570257, "ideal": 4.65571847507, "factor": 2.89127663449, "upper": 3.41052631579, "maximum": 4.80072573329, "worldclass": 933.882352941, "through": 1.07074930869, "allevi": 22.6153846154, "long": 1.2657259028899999, "surpris": 4.36633663366, "layer": 8.14153846154, "contain": 1.59814777532, "about": 1.06486015159, "problem": 1.76674827509, "epoch": 38.347826087, "neural": 59.4606741573, "sure": 7.453521126760001, "just": 1.33580143037, "entir": 1.59365589239, "tini": 12.928338762200001, "nontrivi": 294.0, "cheap": 14.4327272727, "dure": 1.0503473370799998, "classifi": 5.2937645882, "should": 1.6643254009900001, "across": 1.7318642958400001, "rememb": 4.88793103448, "complex": 2.34021226415, "plagu": 11.086592178800002, "start": 1.26673581744, "warm": 6.7614991482099995, "intuit": 27.7068062827, "them": 1.09876115994, "fraction": 13.9753521127, "speed": 3.8703071672400005, "studi": 1.53184098804, "keep": 2.04245465071, "bad": 3.3944836433599996, "energi": 3.66566612792, "systemat": 8.338235294119999, "execut": 2.2363713199, "singl": 1.60948905109, "whi": 3.2566153846200003, "modif": 9.5753920386, "track": 3.1276595744700004, "mani": 1.04426757877, "over": 1.02525024217, "skip": 26.111842105300003, "increas": 1.32024948025, "build": 1.6341739578, "numcycl": 933.882352941, "depict": 4.0131445905000005, "algorithm": 27.9507042254, "select": 2.02345144022, "consum": 4.93043478261, "unfortun": 9.966101694919999, "graph": 37.7102137767, "exact": 3.46864758575, "there": 1.04091266719, "primari": 2.2373167981999997, "fumbl": 176.4, "possibl": 1.4173734488, "way": 1.2190739461, "say": 1.7544480053, "best": 1.5828514456600002, "exampl": 1.50483412322, "continu": 1.13928955867, "spend": 4.15928739848, "spent": 3.00795755968, "take": 1.13961668222, "visual": 5.22752716497, "hone": 66.15, "now": 1.160780873, "might": 2.1561863370900003, "strategi": 4.44208170118, "further": 1.3618116315, "name": 1.10211732037, "code": 3.8807137619199996, "hard": 2.73253012048, "usual": 1.72508964468, "interact": 4.4185917061, "slope": 12.7620578778, "high": 1.14777327935, "power": 1.3396337861799998, "leverag": 35.7567567568, "fix": 4.4346368715099995, "also": 1.01476510067, "typic": 2.2541530597799997, "invers": 21.483085250300004, "modern": 1.5319888063299998, "morri": 10.82946794, "will": 1.22481098596, "major": 1.14852058164, "research": 1.9420183486200002, "signific": 1.4529147982100001, "interplay": 73.8418604651, "area": 1.3881262568900001, "polici": 2.52963671128, "arizona": 12.741573033699998, "describ": 1.47027227264, "piecewis": 793.8, "want": 1.99698113208, "util": 4.65981802172, "howev": 1.0945191313299998, "intellig": 4.19334389857, "actual": 1.87482286254, "regim": 6.603993344430001, "minut": 3.11233091551, "dark": 3.98594024605, "which": 1.005191845, "like": 1.14918566775, "imagenet": 933.882352941, "term": 1.39520168732, "estim": 2.34991119005, "other": 1.00992366412, "techniqu": 3.7293868921800004, "one": 1.00627495722, "inspir": 2.8487349721900004, "numenum": 567.0, "known": 1.0859097127200001, "impact": 2.97526236882, "see": 1.27242125511, "suitabl": 6.23811394892, "becaus": 1.1495184997499999, "imag": 2.70137825421, "loop": 13.5114893617, "get": 1.78562591385, "still": 1.1866357724799999, "random": 7.1902173913, "lesli": 16.249744114600002, "could": 1.2043695949, "drop": 2.4594887684, "relat": 1.23750876919, "preposter": 260.262295082, "tri": 1.8544562551099997, "part": 1.04330682789, "outlin": 6.38102893891, "recent": 1.54405757635, "rule": 1.7415533128599998, "smith": 3.40102827763, "grid": 18.1232876712, "pick": 4.939639079030001, "this": 1.00379362671, "pretti": 15.75, "rang": 1.7848229342299997, "decent": 35.5964125561, "substanti": 3.4777656078900003, "step": 2.8279301745599996, "process": 1.69524826482, "back": 1.26070038911, "chang": 1.1808985421, "bit": 8.33385826772, "perform": 1.5313977042500002, "smaller": 2.59369384088, "differ": 1.23654490225, "novemb": 1.49393055425, "decis": 2.16, "most": 1.02096463023, "between": 1.03453668708, "low": 2.13072070863, "interv": 13.2742474916, "game": 2.57978550536, "multimod": 256.064516129, "soon": 1.9817750592900003, "vision": 4.88041807562, "all": 1.01146788991, "fortun": 6.211267605630001, "gradient": 41.889182058, "tinker": 92.8421052632, "almost": 1.53584212054, "author": 1.4229631621399998, "weight": 4.878918254459999, "architectur": 5.12790697674, "cycl": 5.40919931857, "rate": 2.14048806795, "more": 1.0171706817, "improv": 2.04376930999, "permit": 3.7549668874199997, "rough": 3.29582727839, "benefit": 3.06841901817, "yourself": 26.592964824099997, "artifici": 8.31639601886, "faster": 7.61438848921, "befor": 1.10036041031, "comment": 3.05954904606, "point": 1.25990000794, "state": 1.0477133240899998, "close": 1.2848818387799998, "can": 1.17626139142, "comput": 3.9277585353800006, "make": 1.0762660158600001, "sensibl": 24.164383561599998, "search": 3.2539454806299997, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "superconverg": 933.882352941, "student": 2.47174217655, "accur": 5.768895348840001, "schedul": 3.6648199445999996, "common": 1.4025974025999999, "cozi": 278.526315789, "data": 3.37643555934, "reduc": 1.98698372966, "cyclic": 45.4899713467, "method": 2.5714285714300003, "thumb": 33.3529411765, "perfect": 4.48601299802, "fast": 4.8729281768, "sinc": 1.08368600683, "convolut": 101.121019108, "bio": 42.336000000000006, "come": 1.32831325301, "origin": 1.13724928367, "time": 1.01127460348, "abil": 2.70875277256, "insid": 2.7396031061299997, "right": 1.4054532577899999, "understand": 2.96858638743, "direct": 1.22226499346, "import": 1.3401992233700002, "first": 1.00761614623, "everi": 1.47917637194, "luckili": 191.277108434, "enough": 2.2319696330700003, "while": 1.0441988950299999, "resort": 8.16246786632, "without": 1.29547123623, "often": 1.29452054795, "gradual": 3.7890214797099997, "down": 1.35889754344, "learn": 2.32275054865, "when": 1.02076769755, "effici": 5.09335899904}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Mastering the Learning Rate to Speed Up Deep Learning</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/mastering-learning-rate-speed-up-deep-learning.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Mastering the Learning Rate to Speed Up Deep Learning Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/top-news-week-1029-1104.html\" rel=\"prev\" title=\"Top Stories, Oct 29 \u2013 Nov 4: The Most in Demand Skills for Data Scientists; How Machines Understand Our Language\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/building-surveillance-system-usb-camera-wireless-connected-raspberry-pi.html\" rel=\"next\" title=\"Building Surveillance System Using USB Camera and Wireless-Connected Raspberry Pi\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/11/mastering-learning-rate-speed-up-deep-learning.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=86874\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/mastering-learning-rate-speed-up-deep-learning.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-86874 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 6-Nov, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/tutorials.html\">Tutorials, Overviews</a> \u00bb Mastering the Learning Rate to Speed Up Deep Learning (\u00a0<a href=\"/2018/n42.html\">18:n42</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Mastering the Learning Rate to Speed Up Deep Learning</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/11/top-news-week-1029-1104.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/11/building-surveillance-system-usb-camera-wireless-connected-raspberry-pi.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/hyperparameter\" rel=\"tag\">Hyperparameter</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a></div>\n<br/>\n<p class=\"excerpt\">\n     Figuring out the optimal set of hyperparameters can be one of the most time consuming portions of creating a machine learning model, and that\u2019s particularly true in deep learning.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://brandonlmorris.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Brandon Morris</a>, Arizona State University</b></p>\n<p>Efficiently training deep neural networks can often be an art as much as a science. Industry-grade libraries like\u00a0<a href=\"https://pytorch.org/\" rel=\"noopener noreferrer\" target=\"_blank\">PyTorch</a>\u00a0and\u00a0<a href=\"https://www.tensorflow.org/\" rel=\"noopener noreferrer\" target=\"_blank\">TensorFlow</a>\u00a0have rapidly increased the speed with which efficient deep learning code can be written, but there are still a lot of work required to create a performant model.</p>\n<p>Let\u2019s say, for example, you want to build an image classifier model. A convolutional neural network would be the proper approach to utilize deep learning. But how many layers go in your network? How much momentum and weight decay should you use? What\u2019s the best dropout probability?</p>\n<p>The reality is that these questions don\u2019t have definitive answers. What works great on one dataset might not work nearly as well on another. There are sensible defaults and good rules of thumb, but finding the best combination is nontrivial. These kinds of decisions are known as\u00a0<strong>hyperparameters</strong>: values that are determined prior to actually executing the training algorithm. Figuring out the optimal set of hyperparameters can be one of the most time consuming portions of creating a machine learning model, and that\u2019s particularly true in deep learning.</p>\n<p>\u00a0</p>\n<h3>Difficulties in Finding the Right Hyperparameters</h3>\n<p>\u00a0<br>\nUnlike the parameters inside the model, the hyperparameters are difficult to optimize. While it\u2019s possible to optimize hyperparameters with\u00a0<a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization\" rel=\"noopener noreferrer\" target=\"_blank\">Bayesian methods</a>, this is almost never done in practice. Instead, the best set of hyperparameters is typically sought through a brute force search.</br></p>\n<p>Part of the difficulty of finding the right hyperparameter values is their complex interplay between each other. One value of weight decay may work well for a particular learning rate and poorly for another. Changing one value impacts many others in ways that are difficult to control.</p>\n<p>A tempting, naive method is to set up reasonable steps for each hyperparameter, and loop over a range, trying different values for each one. This is known as\u00a0<strong>grid search</strong>, and it\u2019s generally a bad idea for two reasons. First, the model has to be completely retrained for each set of hyperparameters, and the number of sets grows exponentially with the number of hyperparameters. Most of these values will be suboptimal, meaning that we\u2019re wasting a great deal of time and energy unnecessarily retraining out model. The second reason is a little more subtle. Our steps will need to have a reasonable size to reduce the number of times we need to retrain the model, meaning we\u2019re jumping over a decent bit of the search space with each iteration. There\u2019s no reason our particular intervals are likely to contain good values, so it very possible we will entirely skip over good values. In fact, just doing a random search will usually yield better results that stepping across a fixed interval. The picture below depicts this visually.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*t1dJMqFqlO5cb1Jw.jpeg\" width=\"99%\"/></p>\n<p>Unfortunately, the state of the art in hyperparameter selection is little more than a random search. Most values have sensible defaults, but picking the best possible set can have a significant impact on the model\u2019s final performance. Many machine learning researchers and practitioners develop intuitions about good values and how hyperparameters interact, but it takes a lot of time and practice. However, some recent and exciting research has outlined techniques for finding arguable the most important hyperparameter: the\u00a0<strong>learning rate</strong>.</p>\n<p>\u00a0</p>\n<h3>What is the Learning\u00a0Rate?</h3>\n<p>\u00a0<br>\nNeural network training is typically performed as stochastic optimization. We start out with a random set of network parameters, find out which direction they should move to be improved, then take a step in that direction. This process is known as\u00a0<strong>gradient descent</strong>\u00a0(the stochastic portion comes from the fact that we find our improvement direction on a random subset of the training data). The learning rate determines how big of a step we take in updating the parameters.</br></p>\n<p><code># w is our weight, and dw is the derivative<br>\nw += -learning_rate * dw</br></code></p>\n<p>The above parameter update occurs every iteration of the training process (though modern networks almost always use a more sophisticated update that adds extra terms). Without a doubt,\u00a0<strong>the learning rate is the single most important hyperparameter for a deep neural network</strong>. If the learning rate is too small, the parameters will only change in tiny ways, and the model will take too long to converge. On the other hand, if the learning rate is too large, the parameters could jump over low spaces of the loss function, and the network may never converge.</p>\n<blockquote><p><em>3e-4 is the best learning rate for Adam, hands\u00a0down.</em></p>\n<p><em>\u2014 Andrej Karpathy (@karpathy)\u00a0</em><a href=\"https://twitter.com/karpathy/status/801621764144971776?ref_src=twsrc%5Etfw\" rel=\"noopener noreferrer\" target=\"_blank\"><em>November 24,\u00a02016</em></a></p></blockquote>\n<p>Picking the learning rate is pretty arbitrary. There are a range of reasonable values, but that range and the optimal value will vary with the architecture and dataset. As Andrej Karpathy joked in a tweet seen above, saying that one learning rate is \u201cthe best\u201d is pretty preposterous.</p>\n<p>Commonly, the ideal learning rate will change during training. Most world-class deep architectures are trained with a piecewise annealing strategy: train the network for a while with one learning rate, and when the model stops improving, decrease the learning rate by some factor and keep going. Intuitively, this makes some sense: if the model gets to a low spot in the loss space, the steps we take may be too big to keep from jumping across deeper valleys. Decreasing the learning rate allows for a more fine-grained training.</p>\n<p>While piecewise annealing works in practice, we\u2019ll soon see that it is suboptimal. There are better ways that we can (1) systematically find appropriate learning rate(s) for our particular problem, and (2) schedule the learning rate to automatically vary for faster training and improved performance.</p>\n<p>\u00a0</p>\n<h3>Cyclical Learning\u00a0Rates</h3>\n<p>\u00a0<br>\nPicking the perfect learning rate is hard. In fact, it\u2019s probably too hard to find the singular best value. Instead, we can pick a\u00a0<em>range of learning rates</em>\u00a0and move through them during training. Kind of surprisingly, this method of\u00a0<strong>cyclical learning rates</strong>\u00a0<a href=\"https://arxiv.org/abs/1506.01186\" rel=\"noopener noreferrer\" target=\"_blank\">works pretty well</a>.</br></p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*LdedQ9TLZzASjZt0.png\" width=\"85%\"/></p>\n<p>Cycling through values for the learning rate during training alleviates two of the problems with picking the learning rate. First, we don\u2019t need to find an exactly perfect value, just a range of potentially good values. If we pick our range well (more on that shortly), we will be close to the optimal value for most of the training cycle, which is much better than randomly searching for the perfect learning rate. Additionally, we no longer need to manually schedule the learning rate to decrease during training, since the cycle does it for us. Just be sure to start the cycle with a high rate, and decrease it to a low rate.</p>\n<p>You might be asking yourself why immediately reset the learning rate to a high value instead of allowing it to gradually climb back up. Resetting to a high learning rate gives us the benefit of a\u00a0<a href=\"http://arxiv.org/abs/1608.03983\" rel=\"noopener noreferrer\" target=\"_blank\">warm restart</a>\u00a0in our optimization and can improve our generalization. Remember that in machine learning, our primary goal is not to create a model that works well on the training data, but has high performance on the\u00a0<em>test</em>\u00a0data. This means that we not only want to find a low spot in the loss space during training, but we also want a very\u00a0<em>wide</em>space. That way, even when our model is presented with new data that moves it around in loss space, it\u2019s still likely to be at very low spot, and hence very accurate. Warm restarts helps us find those low and wide spaces that we\u2019re looking for. Even if we find a cozy low valley with our low learning rate, restarting it to a high value at the start of a new cycle will pop us right out of that space if it\u2019s not wide enough.</p>\n<p>There are several ways to tinker with cyclical learning rates that might improve the final results. The length of a cycle is usually about an epoch, but longer cycles are possible. We can even increase the length of the cycle after each cycle. For instance, start with a cycle length of one epoch, then two epochs, then four, and so on. Schedules like this often give good results in part because they spend more time at lower rates during the end of training, allowing the model to hone in on an optimal space of the loss.</p>\n<p>Cyclical learning rates allow us to circumvent the difficulty of picking a good learning rate. All we need are approximate bounds, and we can spend the majority of our training time being close to the optimal value, even as that optimal value changes during training. Additionally, we get the added benefit of restarts that will help us find wide areas in the loss space, improving our generalization ability. Now all we need is a method to find the approximate bounds to cycle through.</p>\n<p>\u00a0</p>\n<h3>The LR Range\u00a0Test</h3>\n<p>\u00a0<br/>\nCyclical learning rates preclude us from needing to find an optimal learning rate, but we still need an upper and lower bound for our cycles. Luckily, we don\u2019t need to resort to the guessing game and random search that plagued or initial hyperparameter search. Instead, the\u00a0<a href=\"https://arxiv.org/abs/1506.01186\" rel=\"noopener noreferrer\" target=\"_blank\">paper</a>\u00a0that described the cyclical learning rate method also introduced a systematic method for finding good boundaries: the\u00a0<strong>LR Range Test</strong>.</p>\n<p>The LR Range Test is simple to understand and cheap to execute. Start with your initialized network, and pick a very small learning rate (much smaller than you would ever likely use). As you train, exponentially increase the learning rate. Keep track of the loss function for each value of the learning rate. If you\u2019re in the right range, the loss should drop, then increase as the learning rate gets too high. Below is a graph of the loss value as a function of the learning rate.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*SvJTcIu1W5MZ62FQ.png\" width=\"85%\"/></p>\n<p>Looking at a plot of the loss vs. the learning rate, we can find our boundaries to use for our cycles. The place to look for is the learning rate where the loss stops decreasing: the minimum value. In the graph above it\u2019s roughly\u00a0. This value is probably too high to use as our boundary, which is why the loss stopped decreasing here. We need to go back just a bit to a smaller value for our maximum boundary to use in our cycles. A good one to use here would be\u00a0. At that point the loss is still decreasing with some gusto. We wouldn\u2019t want to pick the value with the steepest slope, since this will be the maximum, and the cycle will only spend a little while at that point. For the minimum, we can use any value that is smaller; typically we can divide the maximum by a factor such as 3 or 10.</p>\n<p>Cyclical learning rates work well in practice, but there\u2019s actually a way to take it a step further. The technique was introduced by Leslie Smith again and dubbed\u00a0<a href=\"http://arxiv.org/abs/1708.07120\" rel=\"noopener noreferrer\" target=\"_blank\">super-convergence</a>. This strategy is a modification of the cyclical learning rate, and allows for training to converge substantially faster, hence the name.</p>\n<p>To exploit super-convergence, instead of iterating over cycles of the learning rate, we use a single \u201c1cycle\u201d policy. We derive the maximum and minimum learning rate from the LR Range Test as before. Now, we take one long cycle, moving up from the minimum to the maximum, and back down again. Then we continue training and decreasing the learning rate. We also inversely cycle the momentum, going from a high to low, and allowing it to continue increasing. A plot of the learning rate and momentum schedules are shown below.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*NDc4vysd-_3AK2le.png\" width=\"99%\"/></p>\n<p>Amazingly, adopting the 1cycle policy permits incredibly fast training. The original authors reported training deep networks on large datasets in a fraction of the epochs required by other training regimes. Recently, fast.ai\u00a0<a href=\"https://dawn.cs.stanford.edu/benchmark/\" rel=\"noopener noreferrer\" target=\"_blank\">leveraged super-convergence</a>\u00a0to train an ImageNet model in less than three hours, and a CIFAR10 model\u00a0<strong>in lest than three minutes</strong>.</p>\n<p>\u00a0</p>\n<h3>Conclusion</h3>\n<p>\u00a0<br/>\nThere are many difficulties in training deep neural networks. The best practitioners have spent a long time cutting their teeth and developing intuitions about the best values for hyperparameters. Fortunately, research has shown us better ways to pick the learning rate than wasting time and computing power fumbling around in the dark. The LR Range Test provides a quick way to find suitable boundaries for the learning rate, which we can cycle through during training to completely avoid having to find an optimal value. This means more time can be spent training more networks, and less time searching for hyperparameters. Additionally, the 1cycle policy lets us train neural nets at breakneck speeds, creating performant models in a fraction of the training time.</p>\n<p><em>Special thanks to the\u00a0</em><a href=\"https://course.fasta.ai/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>fast.ai</em></a><em>\u00a0course for providing the inspiration and instruction for this blog post.</em></p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://brandonlmorris.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Brandon Morris</a></b> is a Ph.D. student of Computer Science with a focus on Artificial Intelligence at Arizona State University. He is currently studying deep learning and with a particular focus on multimodal models combining computer vision and natural language processing.</p>\n<p><a href=\"https://medium.com/@brandon.morris95/mastering-the-learning-rate-to-speed-up-deep-learning-e212cfdd63a2\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/02/understanding-learning-rates-improves-performance-deep-learning.html\">Understanding Learning Rates and How It Improves Performance in Deep Learning</a>\n<li><a href=\"/2017/11/estimating-optimal-learning-rate-deep-neural-network.html\">Estimating an Optimal Learning Rate For a Deep Neural Network</a>\n<li><a href=\"/2018/01/learning-rate-useful-neural-network.html\">Is Learning Rate Useful in Artificial Neural Networks?</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/11/top-news-week-1029-1104.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/11/building-surveillance-system-usb-camera-wireless-connected-raspberry-pi.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/tutorials.html\">Tutorials, Overviews</a> \u00bb Mastering the Learning Rate to Speed Up Deep Learning (\u00a0<a href=\"/2018/n42.html\">18:n42</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556355367\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.714 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 04:56:07 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "brandon", "morri", "arizona", "state", "univers", "effici", "train", "deep", "neural", "network", "can", "often", "art", "much", "scienc", "industrygrad", "librari", "like", "pytorch", "and", "tensorflow", "have", "rapid", "increas", "the", "speed", "with", "which", "effici", "deep", "learn", "code", "can", "written", "but", "there", "are", "still", "lot", "work", "requir", "creat", "perform", "model", "let", "say", "for", "exampl", "want", "build", "imag", "classifi", "model", "convolut", "neural", "network", "would", "the", "proper", "approach", "util", "deep", "learn", "but", "how", "mani", "layer", "network", "how", "much", "momentum", "and", "weight", "decay", "should", "use", "what", "the", "best", "dropout", "probabl", "the", "realiti", "that", "these", "question", "have", "definit", "answer", "what", "work", "great", "one", "dataset", "might", "not", "work", "near", "well", "anoth", "there", "are", "sensibl", "default", "and", "good", "rule", "thumb", "but", "find", "the", "best", "combin", "nontrivi", "these", "kind", "decis", "are", "known", "hyperparamet", "valu", "that", "are", "determin", "prior", "actual", "execut", "the", "train", "algorithm", "figur", "out", "the", "optim", "set", "hyperparamet", "can", "one", "the", "most", "time", "consum", "portion", "creat", "machin", "learn", "model", "and", "that", "particular", "true", "deep", "learn", "difficulti", "find", "the", "right", "hyperparamet", "unlik", "the", "paramet", "insid", "the", "model", "the", "hyperparamet", "are", "difficult", "optim", "while", "possibl", "optim", "hyperparamet", "with", "bayesian", "method", "this", "almost", "never", "done", "practic", "instead", "the", "best", "set", "hyperparamet", "typic", "sought", "through", "brute", "forc", "search", "part", "the", "difficulti", "find", "the", "right", "hyperparamet", "valu", "their", "complex", "interplay", "between", "each", "other", "one", "valu", "weight", "decay", "may", "work", "well", "for", "particular", "learn", "rate", "and", "poor", "for", "anoth", "chang", "one", "valu", "impact", "mani", "other", "way", "that", "are", "difficult", "control", "tempt", "naiv", "method", "set", "reason", "step", "for", "each", "hyperparamet", "and", "loop", "over", "rang", "tri", "differ", "valu", "for", "each", "one", "this", "known", "grid", "search", "and", "general", "bad", "idea", "for", "two", "reason", "first", "the", "model", "has", "complet", "retrain", "for", "each", "set", "hyperparamet", "and", "the", "number", "set", "grow", "exponenti", "with", "the", "number", "hyperparamet", "most", "these", "valu", "will", "suboptim", "mean", "that", "wast", "great", "deal", "time", "and", "energi", "unnecessarili", "retrain", "out", "model", "the", "second", "reason", "littl", "more", "subtl", "our", "step", "will", "need", "have", "reason", "size", "reduc", "the", "number", "time", "need", "retrain", "the", "model", "mean", "jump", "over", "decent", "bit", "the", "search", "space", "with", "each", "iter", "there", "reason", "our", "particular", "interv", "are", "like", "contain", "good", "valu", "veri", "possibl", "will", "entir", "skip", "over", "good", "valu", "fact", "just", "random", "search", "will", "usual", "yield", "better", "result", "that", "step", "across", "fix", "interv", "the", "pictur", "below", "depict", "this", "visual", "unfortun", "the", "state", "the", "art", "hyperparamet", "select", "littl", "more", "than", "random", "search", "most", "valu", "have", "sensibl", "default", "but", "pick", "the", "best", "possibl", "set", "can", "have", "signific", "impact", "the", "model", "final", "perform", "mani", "machin", "learn", "research", "and", "practition", "develop", "intuit", "about", "good", "valu", "and", "how", "hyperparamet", "interact", "but", "take", "lot", "time", "and", "practic", "howev", "some", "recent", "and", "excit", "research", "has", "outlin", "techniqu", "for", "find", "arguabl", "the", "most", "import", "hyperparamet", "the", "learn", "rate", "what", "the", "learn", "rate", "neural", "network", "train", "typic", "perform", "stochast", "optim", "start", "out", "with", "random", "set", "network", "paramet", "find", "out", "which", "direct", "they", "should", "move", "improv", "then", "take", "step", "that", "direct", "this", "process", "known", "gradient", "descent", "the", "stochast", "portion", "come", "from", "the", "fact", "that", "find", "our", "improv", "direct", "random", "subset", "the", "train", "data", "the", "learn", "rate", "determin", "how", "big", "step", "take", "updat", "the", "paramet", "our", "weight", "and", "the", "deriv", "learningr", "the", "abov", "paramet", "updat", "occur", "everi", "iter", "the", "train", "process", "though", "modern", "network", "almost", "alway", "use", "more", "sophist", "updat", "that", "add", "extra", "term", "without", "doubt", "the", "learn", "rate", "the", "singl", "most", "import", "hyperparamet", "for", "deep", "neural", "network", "the", "learn", "rate", "too", "small", "the", "paramet", "will", "onli", "chang", "tini", "way", "and", "the", "model", "will", "take", "too", "long", "converg", "the", "other", "hand", "the", "learn", "rate", "too", "larg", "the", "paramet", "could", "jump", "over", "low", "space", "the", "loss", "function", "and", "the", "network", "may", "never", "converg", "numenum", "the", "best", "learn", "rate", "for", "adam", "hand", "down", "andrej", "karpathi", "karpathi", "novemb", "num", "num", "pick", "the", "learn", "rate", "pretti", "arbitrari", "there", "are", "rang", "reason", "valu", "but", "that", "rang", "and", "the", "optim", "valu", "will", "vari", "with", "the", "architectur", "and", "dataset", "andrej", "karpathi", "joke", "tweet", "seen", "abov", "say", "that", "one", "learn", "rate", "the", "best", "pretti", "preposter", "common", "the", "ideal", "learn", "rate", "will", "chang", "dure", "train", "most", "worldclass", "deep", "architectur", "are", "train", "with", "piecewis", "anneal", "strategi", "train", "the", "network", "for", "while", "with", "one", "learn", "rate", "and", "when", "the", "model", "stop", "improv", "decreas", "the", "learn", "rate", "some", "factor", "and", "keep", "intuit", "this", "make", "some", "sens", "the", "model", "get", "low", "spot", "the", "loss", "space", "the", "step", "take", "may", "too", "big", "keep", "from", "jump", "across", "deeper", "valley", "decreas", "the", "learn", "rate", "allow", "for", "more", "finegrain", "train", "while", "piecewis", "anneal", "work", "practic", "soon", "see", "that", "suboptim", "there", "are", "better", "way", "that", "can", "num", "systemat", "find", "appropri", "learn", "for", "our", "particular", "problem", "and", "num", "schedul", "the", "learn", "rate", "automat", "vari", "for", "faster", "train", "and", "improv", "perform", "cyclic", "learn", "rate", "pick", "the", "perfect", "learn", "rate", "hard", "fact", "probabl", "too", "hard", "find", "the", "singular", "best", "valu", "instead", "can", "pick", "rang", "learn", "rate", "and", "move", "through", "them", "dure", "train", "kind", "surpris", "this", "method", "cyclic", "learn", "rate", "work", "pretti", "well", "cycl", "through", "valu", "for", "the", "learn", "rate", "dure", "train", "allevi", "two", "the", "problem", "with", "pick", "the", "learn", "rate", "first", "need", "find", "exact", "perfect", "valu", "just", "rang", "potenti", "good", "valu", "pick", "our", "rang", "well", "more", "that", "short", "will", "close", "the", "optim", "valu", "for", "most", "the", "train", "cycl", "which", "much", "better", "than", "random", "search", "for", "the", "perfect", "learn", "rate", "addit", "longer", "need", "manual", "schedul", "the", "learn", "rate", "decreas", "dure", "train", "sinc", "the", "cycl", "doe", "for", "just", "sure", "start", "the", "cycl", "with", "high", "rate", "and", "decreas", "low", "rate", "might", "ask", "yourself", "whi", "immedi", "reset", "the", "learn", "rate", "high", "valu", "instead", "allow", "gradual", "climb", "back", "reset", "high", "learn", "rate", "give", "the", "benefit", "warm", "restart", "our", "optim", "and", "can", "improv", "our", "general", "rememb", "that", "machin", "learn", "our", "primari", "goal", "not", "creat", "model", "that", "work", "well", "the", "train", "data", "but", "has", "high", "perform", "the", "test", "data", "this", "mean", "that", "not", "onli", "want", "find", "low", "spot", "the", "loss", "space", "dure", "train", "but", "also", "want", "veri", "wide", "space", "that", "way", "even", "when", "our", "model", "present", "with", "new", "data", "that", "move", "around", "loss", "space", "still", "like", "veri", "low", "spot", "and", "henc", "veri", "accur", "warm", "restart", "help", "find", "those", "low", "and", "wide", "space", "that", "look", "for", "even", "find", "cozi", "low", "valley", "with", "our", "low", "learn", "rate", "restart", "high", "valu", "the", "start", "new", "cycl", "will", "pop", "right", "out", "that", "space", "not", "wide", "enough", "there", "are", "sever", "way", "tinker", "with", "cyclic", "learn", "rate", "that", "might", "improv", "the", "final", "result", "the", "length", "cycl", "usual", "about", "epoch", "but", "longer", "cycl", "are", "possibl", "can", "even", "increas", "the", "length", "the", "cycl", "after", "each", "cycl", "for", "instanc", "start", "with", "cycl", "length", "one", "epoch", "then", "two", "epoch", "then", "four", "and", "schedul", "like", "this", "often", "give", "good", "result", "part", "becaus", "they", "spend", "more", "time", "lower", "rate", "dure", "the", "end", "train", "allow", "the", "model", "hone", "optim", "space", "the", "loss", "cyclic", "learn", "rate", "allow", "circumv", "the", "difficulti", "pick", "good", "learn", "rate", "all", "need", "are", "approxim", "bound", "and", "can", "spend", "the", "major", "our", "train", "time", "close", "the", "optim", "valu", "even", "that", "optim", "valu", "chang", "dure", "train", "addit", "get", "the", "benefit", "restart", "that", "will", "help", "find", "wide", "area", "the", "loss", "space", "improv", "our", "general", "abil", "now", "all", "need", "method", "find", "the", "approxim", "bound", "cycl", "through", "the", "rang", "test", "cyclic", "learn", "rate", "preclud", "from", "need", "find", "optim", "learn", "rate", "but", "still", "need", "upper", "and", "lower", "bound", "for", "our", "cycl", "luckili", "need", "resort", "the", "guess", "game", "and", "random", "search", "that", "plagu", "initi", "hyperparamet", "search", "instead", "the", "paper", "that", "describ", "the", "cyclic", "learn", "rate", "method", "also", "introduc", "systemat", "method", "for", "find", "good", "boundari", "the", "rang", "test", "the", "rang", "test", "simpl", "understand", "and", "cheap", "execut", "start", "with", "initi", "network", "and", "pick", "veri", "small", "learn", "rate", "much", "smaller", "than", "would", "ever", "like", "use", "train", "exponenti", "increas", "the", "learn", "rate", "keep", "track", "the", "loss", "function", "for", "each", "valu", "the", "learn", "rate", "the", "right", "rang", "the", "loss", "should", "drop", "then", "increas", "the", "learn", "rate", "get", "too", "high", "below", "graph", "the", "loss", "valu", "function", "the", "learn", "rate", "look", "plot", "the", "loss", "the", "learn", "rate", "can", "find", "our", "boundari", "use", "for", "our", "cycl", "the", "place", "look", "for", "the", "learn", "rate", "where", "the", "loss", "stop", "decreas", "the", "minimum", "valu", "the", "graph", "abov", "rough", "this", "valu", "probabl", "too", "high", "use", "our", "boundari", "which", "whi", "the", "loss", "stop", "decreas", "here", "need", "back", "just", "bit", "smaller", "valu", "for", "our", "maximum", "boundari", "use", "our", "cycl", "good", "one", "use", "here", "would", "that", "point", "the", "loss", "still", "decreas", "with", "some", "gusto", "want", "pick", "the", "valu", "with", "the", "steepest", "slope", "sinc", "this", "will", "the", "maximum", "and", "the", "cycl", "will", "onli", "spend", "littl", "while", "that", "point", "for", "the", "minimum", "can", "use", "ani", "valu", "that", "smaller", "typic", "can", "divid", "the", "maximum", "factor", "such", "num", "num", "cyclic", "learn", "rate", "work", "well", "practic", "but", "there", "actual", "way", "take", "step", "further", "the", "techniqu", "introduc", "lesli", "smith", "again", "and", "dub", "superconverg", "this", "strategi", "modif", "the", "cyclic", "learn", "rate", "and", "allow", "for", "train", "converg", "substanti", "faster", "henc", "the", "name", "exploit", "superconverg", "instead", "iter", "over", "cycl", "the", "learn", "rate", "use", "singl", "numcycl", "polici", "deriv", "the", "maximum", "and", "minimum", "learn", "rate", "from", "the", "rang", "test", "befor", "now", "take", "one", "long", "cycl", "move", "from", "the", "minimum", "the", "maximum", "and", "back", "down", "again", "then", "continu", "train", "and", "decreas", "the", "learn", "rate", "also", "invers", "cycl", "the", "momentum", "from", "high", "low", "and", "allow", "continu", "increas", "plot", "the", "learn", "rate", "and", "momentum", "schedul", "are", "shown", "below", "amaz", "adopt", "the", "numcycl", "polici", "permit", "incred", "fast", "train", "the", "origin", "author", "report", "train", "deep", "network", "larg", "dataset", "fraction", "the", "epoch", "requir", "other", "train", "regim", "recent", "fastai", "leverag", "superconverg", "train", "imagenet", "model", "less", "than", "three", "hour", "and", "model", "lest", "than", "three", "minut", "conclus", "there", "are", "mani", "difficulti", "train", "deep", "neural", "network", "the", "best", "practition", "have", "spent", "long", "time", "cut", "their", "teeth", "and", "develop", "intuit", "about", "the", "best", "valu", "for", "hyperparamet", "fortun", "research", "has", "shown", "better", "way", "pick", "the", "learn", "rate", "than", "wast", "time", "and", "comput", "power", "fumbl", "around", "the", "dark", "the", "rang", "test", "provid", "quick", "way", "find", "suitabl", "boundari", "for", "the", "learn", "rate", "which", "can", "cycl", "through", "dure", "train", "complet", "avoid", "have", "find", "optim", "valu", "this", "mean", "more", "time", "can", "spent", "train", "more", "network", "and", "less", "time", "search", "for", "hyperparamet", "addit", "the", "numcycl", "polici", "let", "train", "neural", "net", "breakneck", "speed", "creat", "perform", "model", "fraction", "the", "train", "time", "special", "thank", "the", "fastai", "cours", "for", "provid", "the", "inspir", "and", "instruct", "for", "this", "blog", "post", "bio", "brandon", "morri", "phd", "student", "comput", "scienc", "with", "focus", "artifici", "intellig", "arizona", "state", "univers", "current", "studi", "deep", "learn", "and", "with", "particular", "focus", "multimod", "model", "combin", "comput", "vision", "and", "natur", "languag", "process", "origin", "repost", "with", "permiss", "relat", "understand", "learn", "rate", "and", "how", "improv", "perform", "deep", "learn", "estim", "optim", "learn", "rate", "for", "deep", "neural", "network", "learn", "rate", "use", "artifici", "neural", "network"], "timestamp_scraper": 1556366714.579076, "title": "Mastering the Learning Rate to Speed Up Deep Learning", "read_time": 659.4, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://brandonlmorris.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Brandon Morris</a>, Arizona State University</b></p>\n<p>Efficiently training deep neural networks can often be an art as much as a science. Industry-grade libraries like\u00a0<a href=\"https://pytorch.org/\" rel=\"noopener noreferrer\" target=\"_blank\">PyTorch</a>\u00a0and\u00a0<a href=\"https://www.tensorflow.org/\" rel=\"noopener noreferrer\" target=\"_blank\">TensorFlow</a>\u00a0have rapidly increased the speed with which efficient deep learning code can be written, but there are still a lot of work required to create a performant model.</p>\n<p>Let\u2019s say, for example, you want to build an image classifier model. A convolutional neural network would be the proper approach to utilize deep learning. But how many layers go in your network? How much momentum and weight decay should you use? What\u2019s the best dropout probability?</p>\n<p>The reality is that these questions don\u2019t have definitive answers. What works great on one dataset might not work nearly as well on another. There are sensible defaults and good rules of thumb, but finding the best combination is nontrivial. These kinds of decisions are known as\u00a0<strong>hyperparameters</strong>: values that are determined prior to actually executing the training algorithm. Figuring out the optimal set of hyperparameters can be one of the most time consuming portions of creating a machine learning model, and that\u2019s particularly true in deep learning.</p>\n<p>\u00a0</p>\n<h3>Difficulties in Finding the Right Hyperparameters</h3>\n<p>\u00a0<br>\nUnlike the parameters inside the model, the hyperparameters are difficult to optimize. While it\u2019s possible to optimize hyperparameters with\u00a0<a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization\" rel=\"noopener noreferrer\" target=\"_blank\">Bayesian methods</a>, this is almost never done in practice. Instead, the best set of hyperparameters is typically sought through a brute force search.</br></p>\n<p>Part of the difficulty of finding the right hyperparameter values is their complex interplay between each other. One value of weight decay may work well for a particular learning rate and poorly for another. Changing one value impacts many others in ways that are difficult to control.</p>\n<p>A tempting, naive method is to set up reasonable steps for each hyperparameter, and loop over a range, trying different values for each one. This is known as\u00a0<strong>grid search</strong>, and it\u2019s generally a bad idea for two reasons. First, the model has to be completely retrained for each set of hyperparameters, and the number of sets grows exponentially with the number of hyperparameters. Most of these values will be suboptimal, meaning that we\u2019re wasting a great deal of time and energy unnecessarily retraining out model. The second reason is a little more subtle. Our steps will need to have a reasonable size to reduce the number of times we need to retrain the model, meaning we\u2019re jumping over a decent bit of the search space with each iteration. There\u2019s no reason our particular intervals are likely to contain good values, so it very possible we will entirely skip over good values. In fact, just doing a random search will usually yield better results that stepping across a fixed interval. The picture below depicts this visually.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*t1dJMqFqlO5cb1Jw.jpeg\" width=\"99%\"/></p>\n<p>Unfortunately, the state of the art in hyperparameter selection is little more than a random search. Most values have sensible defaults, but picking the best possible set can have a significant impact on the model\u2019s final performance. Many machine learning researchers and practitioners develop intuitions about good values and how hyperparameters interact, but it takes a lot of time and practice. However, some recent and exciting research has outlined techniques for finding arguable the most important hyperparameter: the\u00a0<strong>learning rate</strong>.</p>\n<p>\u00a0</p>\n<h3>What is the Learning\u00a0Rate?</h3>\n<p>\u00a0<br>\nNeural network training is typically performed as stochastic optimization. We start out with a random set of network parameters, find out which direction they should move to be improved, then take a step in that direction. This process is known as\u00a0<strong>gradient descent</strong>\u00a0(the stochastic portion comes from the fact that we find our improvement direction on a random subset of the training data). The learning rate determines how big of a step we take in updating the parameters.</br></p>\n<p><code># w is our weight, and dw is the derivative<br>\nw += -learning_rate * dw</br></code></p>\n<p>The above parameter update occurs every iteration of the training process (though modern networks almost always use a more sophisticated update that adds extra terms). Without a doubt,\u00a0<strong>the learning rate is the single most important hyperparameter for a deep neural network</strong>. If the learning rate is too small, the parameters will only change in tiny ways, and the model will take too long to converge. On the other hand, if the learning rate is too large, the parameters could jump over low spaces of the loss function, and the network may never converge.</p>\n<blockquote><p><em>3e-4 is the best learning rate for Adam, hands\u00a0down.</em></p>\n<p><em>\u2014 Andrej Karpathy (@karpathy)\u00a0</em><a href=\"https://twitter.com/karpathy/status/801621764144971776?ref_src=twsrc%5Etfw\" rel=\"noopener noreferrer\" target=\"_blank\"><em>November 24,\u00a02016</em></a></p></blockquote>\n<p>Picking the learning rate is pretty arbitrary. There are a range of reasonable values, but that range and the optimal value will vary with the architecture and dataset. As Andrej Karpathy joked in a tweet seen above, saying that one learning rate is \u201cthe best\u201d is pretty preposterous.</p>\n<p>Commonly, the ideal learning rate will change during training. Most world-class deep architectures are trained with a piecewise annealing strategy: train the network for a while with one learning rate, and when the model stops improving, decrease the learning rate by some factor and keep going. Intuitively, this makes some sense: if the model gets to a low spot in the loss space, the steps we take may be too big to keep from jumping across deeper valleys. Decreasing the learning rate allows for a more fine-grained training.</p>\n<p>While piecewise annealing works in practice, we\u2019ll soon see that it is suboptimal. There are better ways that we can (1) systematically find appropriate learning rate(s) for our particular problem, and (2) schedule the learning rate to automatically vary for faster training and improved performance.</p>\n<p>\u00a0</p>\n<h3>Cyclical Learning\u00a0Rates</h3>\n<p>\u00a0<br>\nPicking the perfect learning rate is hard. In fact, it\u2019s probably too hard to find the singular best value. Instead, we can pick a\u00a0<em>range of learning rates</em>\u00a0and move through them during training. Kind of surprisingly, this method of\u00a0<strong>cyclical learning rates</strong>\u00a0<a href=\"https://arxiv.org/abs/1506.01186\" rel=\"noopener noreferrer\" target=\"_blank\">works pretty well</a>.</br></p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*LdedQ9TLZzASjZt0.png\" width=\"85%\"/></p>\n<p>Cycling through values for the learning rate during training alleviates two of the problems with picking the learning rate. First, we don\u2019t need to find an exactly perfect value, just a range of potentially good values. If we pick our range well (more on that shortly), we will be close to the optimal value for most of the training cycle, which is much better than randomly searching for the perfect learning rate. Additionally, we no longer need to manually schedule the learning rate to decrease during training, since the cycle does it for us. Just be sure to start the cycle with a high rate, and decrease it to a low rate.</p>\n<p>You might be asking yourself why immediately reset the learning rate to a high value instead of allowing it to gradually climb back up. Resetting to a high learning rate gives us the benefit of a\u00a0<a href=\"http://arxiv.org/abs/1608.03983\" rel=\"noopener noreferrer\" target=\"_blank\">warm restart</a>\u00a0in our optimization and can improve our generalization. Remember that in machine learning, our primary goal is not to create a model that works well on the training data, but has high performance on the\u00a0<em>test</em>\u00a0data. This means that we not only want to find a low spot in the loss space during training, but we also want a very\u00a0<em>wide</em>space. That way, even when our model is presented with new data that moves it around in loss space, it\u2019s still likely to be at very low spot, and hence very accurate. Warm restarts helps us find those low and wide spaces that we\u2019re looking for. Even if we find a cozy low valley with our low learning rate, restarting it to a high value at the start of a new cycle will pop us right out of that space if it\u2019s not wide enough.</p>\n<p>There are several ways to tinker with cyclical learning rates that might improve the final results. The length of a cycle is usually about an epoch, but longer cycles are possible. We can even increase the length of the cycle after each cycle. For instance, start with a cycle length of one epoch, then two epochs, then four, and so on. Schedules like this often give good results in part because they spend more time at lower rates during the end of training, allowing the model to hone in on an optimal space of the loss.</p>\n<p>Cyclical learning rates allow us to circumvent the difficulty of picking a good learning rate. All we need are approximate bounds, and we can spend the majority of our training time being close to the optimal value, even as that optimal value changes during training. Additionally, we get the added benefit of restarts that will help us find wide areas in the loss space, improving our generalization ability. Now all we need is a method to find the approximate bounds to cycle through.</p>\n<p>\u00a0</p>\n<h3>The LR Range\u00a0Test</h3>\n<p>\u00a0<br/>\nCyclical learning rates preclude us from needing to find an optimal learning rate, but we still need an upper and lower bound for our cycles. Luckily, we don\u2019t need to resort to the guessing game and random search that plagued or initial hyperparameter search. Instead, the\u00a0<a href=\"https://arxiv.org/abs/1506.01186\" rel=\"noopener noreferrer\" target=\"_blank\">paper</a>\u00a0that described the cyclical learning rate method also introduced a systematic method for finding good boundaries: the\u00a0<strong>LR Range Test</strong>.</p>\n<p>The LR Range Test is simple to understand and cheap to execute. Start with your initialized network, and pick a very small learning rate (much smaller than you would ever likely use). As you train, exponentially increase the learning rate. Keep track of the loss function for each value of the learning rate. If you\u2019re in the right range, the loss should drop, then increase as the learning rate gets too high. Below is a graph of the loss value as a function of the learning rate.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*SvJTcIu1W5MZ62FQ.png\" width=\"85%\"/></p>\n<p>Looking at a plot of the loss vs. the learning rate, we can find our boundaries to use for our cycles. The place to look for is the learning rate where the loss stops decreasing: the minimum value. In the graph above it\u2019s roughly\u00a0. This value is probably too high to use as our boundary, which is why the loss stopped decreasing here. We need to go back just a bit to a smaller value for our maximum boundary to use in our cycles. A good one to use here would be\u00a0. At that point the loss is still decreasing with some gusto. We wouldn\u2019t want to pick the value with the steepest slope, since this will be the maximum, and the cycle will only spend a little while at that point. For the minimum, we can use any value that is smaller; typically we can divide the maximum by a factor such as 3 or 10.</p>\n<p>Cyclical learning rates work well in practice, but there\u2019s actually a way to take it a step further. The technique was introduced by Leslie Smith again and dubbed\u00a0<a href=\"http://arxiv.org/abs/1708.07120\" rel=\"noopener noreferrer\" target=\"_blank\">super-convergence</a>. This strategy is a modification of the cyclical learning rate, and allows for training to converge substantially faster, hence the name.</p>\n<p>To exploit super-convergence, instead of iterating over cycles of the learning rate, we use a single \u201c1cycle\u201d policy. We derive the maximum and minimum learning rate from the LR Range Test as before. Now, we take one long cycle, moving up from the minimum to the maximum, and back down again. Then we continue training and decreasing the learning rate. We also inversely cycle the momentum, going from a high to low, and allowing it to continue increasing. A plot of the learning rate and momentum schedules are shown below.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/720/0*NDc4vysd-_3AK2le.png\" width=\"99%\"/></p>\n<p>Amazingly, adopting the 1cycle policy permits incredibly fast training. The original authors reported training deep networks on large datasets in a fraction of the epochs required by other training regimes. Recently, fast.ai\u00a0<a href=\"https://dawn.cs.stanford.edu/benchmark/\" rel=\"noopener noreferrer\" target=\"_blank\">leveraged super-convergence</a>\u00a0to train an ImageNet model in less than three hours, and a CIFAR10 model\u00a0<strong>in lest than three minutes</strong>.</p>\n<p>\u00a0</p>\n<h3>Conclusion</h3>\n<p>\u00a0<br/>\nThere are many difficulties in training deep neural networks. The best practitioners have spent a long time cutting their teeth and developing intuitions about the best values for hyperparameters. Fortunately, research has shown us better ways to pick the learning rate than wasting time and computing power fumbling around in the dark. The LR Range Test provides a quick way to find suitable boundaries for the learning rate, which we can cycle through during training to completely avoid having to find an optimal value. This means more time can be spent training more networks, and less time searching for hyperparameters. Additionally, the 1cycle policy lets us train neural nets at breakneck speeds, creating performant models in a fraction of the training time.</p>\n<p><em>Special thanks to the\u00a0</em><a href=\"https://course.fasta.ai/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>fast.ai</em></a><em>\u00a0course for providing the inspiration and instruction for this blog post.</em></p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://brandonlmorris.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Brandon Morris</a></b> is a Ph.D. student of Computer Science with a focus on Artificial Intelligence at Arizona State University. He is currently studying deep learning and with a particular focus on multimodal models combining computer vision and natural language processing.</p>\n<p><a href=\"https://medium.com/@brandon.morris95/mastering-the-learning-rate-to-speed-up-deep-learning-e212cfdd63a2\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/02/understanding-learning-rates-improves-performance-deep-learning.html\">Understanding Learning Rates and How It Improves Performance in Deep Learning</a>\n<li><a href=\"/2017/11/estimating-optimal-learning-rate-deep-neural-network.html\">Estimating an Optimal Learning Rate For a Deep Neural Network</a>\n<li><a href=\"/2018/01/learning-rate-useful-neural-network.html\">Is Learning Rate Useful in Artificial Neural Networks?</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}