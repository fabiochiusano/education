{"content": "By George McIntire, Contributing Data Science Writer, ODSC \u201cA lie gets halfway around the world before the truth has a chance to get its pants on.\u201d \u2013\u00a0Winston Churchill Since the 2016 presidential election, one topic dominating political discourse is the issue of \u201cFake News\u201d.\u00a0A number of political pundits\u00a0claim that the rise of significantly biased and/or untrue news influenced the election, though\u00a0a\u00a0 study by researchers from Stanford and New York University concluded otherwise. Nonetheless,\u00a0fake news posts have exploited\u00a0Facebook users\u2019 feeds to propagate throughout the internet. \u201cWhat is fake news?\u201d Obviously, a deliberately misleading story is \u201cfake news\u201d but lately blathering social media discourse, \u00a0is changing\u00a0its definition. Some now use the term to dismiss facts counter to their preferred viewpoints, the most prominent example being President Trump . Such a vaguely-defined term is ripe for a cynical manipulation. The data science community has responded by\u00a0 taking action to fight the problem . There\u2019s a Kaggle-style competition called the \u201c Fake News Challenge \u201d\u00a0and Facebook is employing AI \u00a0to filter fake news stories out of users\u2019 feeds. Combating fake news is a classic text classification project with a straight-forward proposition: Can you build a model that can differentiate between \u201cReal\u201d news vs \u201cFake\u201d news. And that\u2019s exactly what\u00a0I attempted to do for this project. I assembled a dataset of fake and real news and\u00a0employed a Naive\u00a0Bayes classifier in order to create a model to classify an article as fake or real based on its words and phrases. Data Gather/Wrangling \u00a0 There were two parts to the data acquisition\u00a0process, getting the \u201cfake news\u201d and getting the real news. The first part was quick,\u00a0Kaggle released a\u00a0 fake news dataset comprising of 13,000 articles published during the 2016 election cycle. The second part was\u2026 a lot more difficult. \u00a0To acquire the real news side of the dataset, I turned to All Sides , a website dedicated to hosting news and opinion articles from across the political spectrum. Articles on the website are categorized by topic (environment, economy, abortion, etc\u2026) and by political leaning (left, center, and right).\u00a0I used\u00a0All Sides because it was the best way\u00a0to web scrape thousands of articles from numerous media outlets of differing\u00a0biases. Plus, it allowed to me download the full text of an article, something you cannot do with the New York Times and NPR APIs. After a long and arduous process I ended up scraping a total of 5279 articles . The articles in my real news dataset came from\u00a0media organizations such as the New York Times, WSJ, Bloomberg, NPR, and the Guardian\u00a0and\u00a0were published in\u00a02015 or\u00a02016. I decided to construct my full dataset with equal parts\u00a0fake and real articles, thus making my model\u2019s null accuracy 50%. I randomly selected 5279 articles from my fake news dataset to use in my complete dataset and left the remaining articles to be used as a testing set when my model was complete. My finalized dataset was comprised of 10558 total articles with their headlines and full body text and their labels (real vs fake). The data is located here in this github repo . Purpose and Expectations \u00a0 When I first started this project, I\u00a0conceded that this would not be the perfect project. The purpose of this project was to see how far I could get in creating a fake news classification and what insights could be drawn from that, then used towards a better model. My game plan was to treat this project the same way as a routine spam detection project. Building a model based on a count vectorizer (using word tallies) or a tfidf matrix (word tallies relative to how often they\u2019re used in other articles in your dataset) can only get you so far. These methods\u00a0do not consider important qualities\u00a0like the word ordering\u00a0and context. It\u2019s very possible for two articles\u00a0that are similar in their word counts to be totally different in their meaning. I did not expect my model to be adept at handling\u00a0fake and real articles\u00a0whose words and phrases overlap. Nonetheless, I expect some valuable insights to come from this project. Modeling \u00a0 Since this is a text classification project, I only used a Naive Bayes classifier as is standard for text-based data science projects. The real work in formulating a model was the text transformation\u00a0(count vectorizer vs tfidf vectorizer) and choosing which type of text to use (headlines vs full text). This gave me four pairs of reconfigured datasets to work with. The next step was to determine the most optimal parameters for either a countvectorizer or tfidf-vectorizer. For those of you who are unfamiliar with text machine learning, this means using a n-number of the most common words, using\u00a0words and/or phrases, lower casing or not, removing stop words (common words such as the,\u00a0when, and there) and only using words that appear at\u00a0least a given number of times in\u00a0a\u00a0text corpus (a term for a text dataset or a collection of texts). To test the performance of multiple parameters and their numerous combinations, I utilized the Sci-kit Learn\u2019s GridSearch functionality to efficiently execute this task. To learn more about how to\u00a0perfect your algorithm parameters, please review this tutorial . After the grid search\u00a0cross validation process, I\u00a0found that\u00a0my model worked best with\u00a0a\u00a0count vectorizer instead of a tfidf and produced higher scores when\u00a0trained on the full text of articles instead of their headlines.\u00a0The optimal parameters for\u00a0count vectorizer are no lowercasing, two-word phrases not single words, and\u00a0to only use words that appear at least three times in the corpus. Given my expectations that I outlined earlier in this post, I was surprised and almost baffled at the high scores\u00a0my model produced.\u00a0My model\u2019s cross-validated accuracy score is 91.7%, recall (true positive rate) score is\u00a092.6%, and its AUC score is 95%. Here is the ROC Curve for my model. If I\u00a0were to decide on a threshold for a model based on this graph, I would choose one that produces a FPR at around 0.08 and a TPR at around 0.90, because at that point in the graph the trade off between false positives and true positives is equal. Results & Conclusion \u00a0 The true test of my model\u2019s quality would be to see how fake news articles in the test set (those not used in the creation of my model) it could accurately classify. Out of the 5234 articles left in the other fake news datasets, my model was able to correctly identify 88.2% of them as fake. This is 3.5 percentage points lower than my cross-validated accuracy score, but in my opinion it is pretty decent evaluation of my model. It turns out that my hypothesis\u00a0predicting that model would\u00a0struggle at classifying news articles was quite wrong. I\u00a0thought that an accuracy score in the upper 60s or lower 70s would be\u00a0excellent and I managed to surpass that by a significant margin. Even though I created what appears to be a pretty good model given the complexity of the task, I am not entirely convinced that it is as good as it appears to be and here\u2019s why. To be better understand why this might have happened, let\u2019s take a look at the \u201cfakest\u201d and \u201crealest\u201d words in the data\u2014I\u2019ll explain what I mean by that. Using a technique I borrowed from Kevin Markham of Data School, here\u2019s how I derived the \u201cfakest\u201d and \u201crealest\u201d words in the corpus. First I started off with a table two columns wide\u00a0and\u00a010558 rows long (that\u2019s how many words there are in the corpus). The first column represented how many times a given word appeared in articles classified as \u201cFAKE\u201d and the second column was how many times a word\u00a0appeared in a \u201cREAL\u201d article. \u00a0Then I divided\u00a0the fake column by the total number of fake articles my model classified and\u00a0so on for the real column.\u00a0Next, I added the number one to every value in the data because I created a new column of \u201cFake:Real\u201d ratios and didn\u2019t want to get an error by dividing zero. This \u201cFake:Real\u201d is a pretty good but by no means perfect metric of just how \u201cfake\u201d or \u201creal a certain word. The\u00a0logic is pretty simple, if a word shows up a bunch in \u201cfake\u201d articles and rarely in \u201creal\u201d articles then\u00a0its fake to real ratio score will be pretty high. Here are the top 20 \u201cfakest\u201d and \u201crealest\u201d words in my dataset. These two graphics exhibit some baffling results. The words in the \u201cfake\u201d chart are a mixed bag that includes some\u00a0typical internet\u00a0terminology such as PLEASE, Share, Posted, html, and Widget\u00a0and words that aren\u2019t even words such as tzrwu.\u00a0However I was not surprised to see infowars mentioned nor terms like \u201cSheeple\u201d or \u201cUFO\u201d make it in the top 20 \u201cfakest\u201d words. Infowars is a right-wing conspiracy-laden outlet led by Alex Jones that promotes conspiracy theories about chemtrails and 9/11. The \u201creal\u201d chart\u00a0is dominated by names and politicians and words frequently used in political articles, comprising 60% of the bars in the chart. Seven of the twenty terms, including four of the top six,\u00a0are politician names. This begs the question,\u00a0are articles\u00a0about politicians more likely to be true? No of course not, if anything you\u2019d expect there to be numerous fake news articles\u00a0spreading falsehoods\u00a0about politicians. I would be committing a huge error if I came to the conclusion that articles mentioning\u00a0politicians are more likely to be to factual. One big assumption\u00a0underlying this project is that there is considerable overlap in the topics covered by each class of article. As we witnessed above, just because a certain word\u00a0shows up more often in \u201creal\u201d news than\u00a0\u201cfake\u201d news it doesn\u2019t mean that articles with those terms are guaranteed to be \u201creal\u201d, but instead could just mean that those words are used in topics more common in the real news dataset and vice versa for the fake news dataset. I\u00a0and another party had a considerable amount of influence in shaping\u00a0this dataset. I made the decision on which articles to use for the \u201creal\u201d dataset.\u00a0The articles in the \u201cfake\u201d\u00a0dataset were determined by a\u00a0 chrome extension called \u201cBS Detector\u201d \u00a0made by Daniel Sieradski. There is a\u00a0significantly high\u00a0amount of subjectivity going into determining what is and what isn\u2019t \u201cfake news\u201d. The reason why politician names are\u00a0rated\u00a0as \u201creal\u201d so highly is\u00a0most likely because that half of the corpura\u00a0disproportionately comes\u00a0from political news. In addition, I did find a couple of articles from what I find to be reputable sources of news. One such article came from The Intercept, a news organization\u00a0with high journalism standards. And yes, my model did indeed flag this supposed \u201cfake news\u201d article as real. To make\u00a0matters even more complicated,\u00a0we have to decide how to set the threshold probability for our model. If I was a data scientist at Facebook tasked with implementing a model that sorts out real and fake news in users\u2019 feeds, I\u2019d be faced with\u00a0the dilemma between choosing a model that blocks all or most fake news and some real news or a model that allows all or most real news and some fake news. But before I make that decision, I need\u00a0to figure\u00a0what is the cost of failing to prevent fake news vs the cost of blocking real news? How does\u00a0one attempt to answer such an abstract question? Unless we can train a model with a 100% true positive rate and 0% false positive rate, we\u2019ll be stuck with this quandary. In conclusion, while I think that a standard Naive Bayes text classification model can provide insight into addressing this issue,\u00a0a more powerful deep-learning tool should be employed to combat fake news in a professional setting. Classifying \u201cfake news\u201d provides a novel challenge to the data science community. \u00a0In many machine learning projects, the distinction between the different classes you want to predict is clear, whereas it\u2019s a lot murkier in this case. This\u00a0project validates the notion in data science\u00a0that intuition and intimacy with your data is just as or more important than any model or tool at your disposal. Bio: George McIntire is a journalist turned data scientist/journalist hybrid. Looking for opportunities in data science and/or journalism. Impossibly curious and passionate about learning new things. Before completing the Metis Data Science Bootcamp, he worked as a freelance journalist in San Francisco for Vice, Salon, SF Weekly, San Francisco Magazine, and more. Original . Reposted with permission. Related: It\u2019s Getting Hot In Here: Data Science vs Fake News What Happened Last Night in Sweden: Data Science vs Fake News Beware of Two Data Obfuscation Tactics", "title_html": "<h1 id=\"title\">Machine Learning Finds \u201cFake News\u201d with 88% Accuracy</h1> ", "url": "https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html", "tfidf": {"tfidf": {"after": 2.04140414042, "real": 61.58793103452, "understand": 2.96858638743, "unless": 5.44818119423, "scientistjournalist": 1587.6, "vector": 129.494290375, "typic": 2.2541530597799997, "magazin": 2.4312404287900002, "outlet": 23.159737418000002, "guardian": 6.58481957694, "repo": 369.209302326, "new": 5.0894402770000005, "vice": 10.38325703074, "fact": 1.73375559681, "addit": 1.24634950542, "would": 6.497237569079999, "what": 12.534343912799999, "markham": 121.190839695, "web": 5.17133550489, "dataset": 3484.9756097639997, "function": 2.495441685, "class": 4.23303559526, "spectrum": 12.6401273885, "logic": 8.929133858270001, "salon": 37.3552941176, "thought": 1.9854927463699998, "viewpoint": 19.2203389831, "quandari": 369.209302326, "abov": 1.90382539873, "convinc": 4.4051054384, "assembl": 3.0011342155, "creat": 4.9971671388, "complet": 3.72064682448, "higher": 2.1218925421, "sweden": 7.50638297872, "their": 7.108353588350001, "yes": 14.1876675603, "equal": 5.08438751, "data\u2014i": 1587.6, "left": 4.3196081988, "instead": 4.78384893531, "least": 3.2330719886000003, "conced": 18.102622577, "multipl": 2.74813917258, "alex": 10.655033557000001, "how": 17.62753608561, "test": 10.62828451884, "scrape": 141.12, "news": 89.51848937833999, "dismiss": 5.2137931034500005, "bunch": 40.5, "truth": 5.745928338759999, "had": 1.0475750577399998, "was\u2026": 1587.6, "end": 1.10680423871, "found": 1.11387076405, "given": 5.41704341892, "word": 50.30304401947999, "guarante": 6.57119205298, "exhibit": 3.5934812132199996, "difficult": 2.48957189901, "will": 1.22481098596, "exploit": 5.79416058394, "consid": 1.2397313759200002, "predict": 10.3696930111, "those": 4.78192771084, "null": 1587.6, "purpos": 4.46833661694, "intimaci": 71.1928251121, "otherwis": 3.72151898734, "repost": 933.882352941, "vaguelydefin": 1587.6, "next": 2.9901120632800002, "fakest": 6350.4, "claim": 1.52697893623, "perform": 1.5313977042500002, "but": 5.0816208949499995, "definit": 3.24, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 32.268292682920006, "commit": 2.8860207235, "cost": 4.63871439006, "final": 1.34008609775, "perfect": 13.458038994059999, "expect": 11.00055432375, "parti": 2.06369426752, "naiv": 150.7215189873, "review": 2.2099109131400003, "domin": 4.641426692, "organ": 3.2774566474, "pant": 41.023255814, "has": 2.0872995004, "have": 3.0446845234199995, "paramet": 69.02608695640001, "stop": 2.1783754116400003, "transform": 3.42007755278, "formul": 9.86086956522, "optim": 23.0755813954, "threshold": 46.01739130439999, "bootcamp": 1587.6, "out": 4.24066777964, "model": 60.6273373716, "treat": 3.59023066486, "good": 4.55944859277, "number": 4.40571666436, "under": 1.0781663837, "cours": 2.15092805853, "numer": 5.49976905312, "huge": 4.38927287808, "count": 17.40789473685, "around": 3.6418412601299996, "start": 2.53347163488, "when": 4.0830707902, "some": 6.2422018348799995, "not": 10.1567398119, "far": 3.42044597652, "gridsearch": 1587.6, "late": 1.31740104556, "wrong": 5.478260869570001, "someth": 3.28152128979, "disproportion": 32.33401222, "happen": 5.92719805862, "quick": 2.205, "pleas": 9.12938470385, "metric": 22.235294117600002, "handl": 3.9229058561900003, "almost": 1.53584212054, "corpura": 1587.6, "then": 3.25973581548, "complic": 5.6478121664900005, "graphic": 9.035856573710001, "anoth": 1.13643521832, "rightw": 1587.6, "adept": 55.7052631579, "turn": 4.151673640169999, "last": 1.2117234010100002, "let": 3.48616600791, "world": 1.11340206186, "scienc": 20.87726475744, "task": 11.65924112607, "employ": 6.49590834696, "github": 1587.6, "construct": 1.9320920043799998, "passion": 8.14571575167, "polit": 10.61111729976, "internet": 9.96923076924, "journalist": 10.02272727272, "feed": 23.33561979423, "conspiracyladen": 1587.6, "simpl": 3.3981164383599998, "influenc": 3.54493692084, "stuck": 18.945107398599998, "algorithm": 27.9507042254, "theori": 3.02745995423, "respond": 3.17329602239, "sort": 5.188235294119999, "either": 1.5830092731099998, "curious": 23.381443299, "such": 7.43059641618, "accuraci": 51.0482315112, "thousand": 2.4767550702000003, "elect": 7.568409343710001, "with": 16.019171343839997, "lie": 3.2157180474000002, "whose": 1.73508196721, "politician": 28.3415650104, "deriv": 2.78379800105, "lot": 8.81755068036, "andor": 2070.782608695, "sourc": 1.69760479042, "just": 5.34320572148, "locat": 1.59766529134, "discours": 32.937759336, "classic": 2.4087391898, "filter": 16.8893617021, "rate": 8.5619522718, "html": 71.1928251121, "arduous": 98.0, "media": 7.781081522639999, "acquisit": 10.3764705882, "ani": 1.13383802314, "question": 4.4081632653, "divid": 4.633975481619999, "talli": 62.875247524799995, "from": 11.00623936467, "answer": 4.64890190337, "allow": 2.5432118542200004, "work": 4.46080359652, "num": 26.00819104026, "veri": 1.25880114177, "churchil": 18.185567010299998, "aren": 481.09090909099996, "spam": 217.479452055, "obfusc": 182.482758621, "environ": 3.43561999567, "curv": 11.1098670399, "acquir": 3.10563380282, "for": 16.00504064016, "economi": 3.6446280991699997, "manipul": 9.145161290319999, "face": 1.80327124035, "creation": 3.0601387818, "releas": 1.8377126982299998, "sieradski": 1587.6, "competit": 3.06960556845, "zero": 8.75192943771, "determin": 6.497680763970001, "topic": 21.830182193200002, "true": 12.7784932389, "better": 4.0131445905000005, "result": 2.29223216864, "frequent": 2.10501193317, "sheepl": 1587.6, "look": 3.8172637653199994, "spread": 2.8344938403900004, "bag": 15.8601398601, "kevin": 7.82068965517, "chanc": 4.2449197861000005, "fake": 768.1935483852, "bar": 3.8854625550699997, "ratio": 14.42616992276, "think": 2.90715986083, "writer": 2.75816539263, "center": 1.7423178226499998, "combin": 1.69760479042, "percentag": 6.08275862069, "util": 4.65981802172, "reput": 4.06451612903, "column": 42.46812304950001, "though": 2.72152224222, "toward": 1.6303142329, "remov": 2.0058117498400003, "fight": 2.50370604006, "websit": 5.04320203304, "doe": 1.70581282905, "lowercas": 162.0, "could": 4.8174783796, "valid": 13.22448979592, "three": 1.06621893889, "probabl": 2.64555907349, "side": 4.7968576895999995, "train": 3.8731397901999998, "they": 1.03017325287, "bodi": 1.8618505922400002, "assumpt": 9.21951219512, "step": 2.8279301745599996, "error": 12.08219178082, "chart": 25.36102236423, "big": 2.7400759406299997, "type": 2.0281042411900003, "matter": 2.44773358002, "fals": 12.43226311668, "row": 5.549108703250001, "presid": 1.9842519685, "scientist": 4.69426374926, "machin": 8.04866920152, "action": 1.81855670103, "bias": 27.4671280276, "bloomberg": 42.563002681, "came": 4.38039179619, "sinc": 2.16737201366, "download": 14.6457564576, "presidenti": 6.325099601590001, "flag": 5.95275590551, "figur": 2.0343413634, "gave": 1.85121268657, "earlier": 1.86776470588, "choos": 12.536983416690001, "meti": 352.8, "opportun": 3.0119521912400002, "clear": 1.85423966363, "find": 3.4588235294199996, "trump": 62.015625, "overlap": 24.1827875096, "borrow": 8.02223345124, "consider": 4.59840695148, "conclus": 14.53846153845, "even": 3.49383802818, "nor": 3.3479544496, "base": 3.43884476535, "relat": 2.47501753838, "label": 4.47715736041, "blather": 1587.6, "drawn": 4.6030733546, "who": 1.06279287723, "decid": 5.777292576420001, "univers": 1.24889867841, "hot": 4.6178010471199995, "permiss": 6.280063291139999, "post": 6.71478922881, "here": 14.53846153848, "dispos": 10.4378698225, "lower": 6.301667107709999, "upper": 3.41052631579, "were": 4.09835430784, "long": 2.5314518057799997, "realest": 4762.799999999999, "surpris": 8.73267326732, "counter": 6.77592829706, "evalu": 6.9509632224199995, "than": 3.0983606557499996, "struggl": 3.36, "plus": 4.6914893617, "about": 5.324300757950001, "problem": 1.76674827509, "intuit": 27.7068062827, "communiti": 3.92242124768, "francisco": 10.5875291764, "distinct": 2.2836593786000003, "daniel": 4.36994219653, "context": 4.25972632144, "kagglestyl": 1587.6, "entir": 1.59365589239, "lean": 16.729188619600002, "deeplearn": 1587.6, "conspiraci": 12.928338762200001, "correct": 3.6631287494199998, "standard": 5.674728940770001, "dure": 1.0503473370799998, "posit": 6.8626264373, "classifi": 42.3501167056, "should": 1.6643254009900001, "contribut": 1.9255306246200001, "led": 1.33782758911, "across": 1.7318642958400001, "complex": 2.34021226415, "notion": 7.356811862839999, "categor": 15.0198675497, "reconfigur": 70.2477876106, "conclud": 3.02284843869, "articl": 70.63175289169999, "deliber": 6.280063291139999, "singl": 1.60948905109, "them": 1.09876115994, "insight": 35.4111524163, "studi": 1.53184098804, "whi": 9.769846153860001, "explain": 2.60049140049, "execut": 2.2363713199, "anyth": 4.58843930636, "georg": 3.7558552164599996, "quit": 2.8849718335500003, "abl": 1.8208510150200001, "mani": 4.17707031508, "data": 60.77584006812, "the": 101.0, "build": 3.2683479156, "wit": 4.386847195360001, "provid": 2.43105428374, "total": 6.184049079759999, "journal": 4.73769024172, "freelanc": 61.0615384615, "tactic": 6.432739059969999, "order": 2.49250333622, "throughout": 1.5217099587799998, "show": 2.5340782123, "exact": 3.46864758575, "there": 7.28638867033, "surpass": 10.1185468451, "valu": 2.2777618364400003, "wide": 1.5598349381, "matrix": 22.6153846154, "cross": 2.33127753304, "possibl": 1.4173734488, "way": 2.4381478922, "nonetheless": 15.75, "best": 3.1657028913200005, "origin": 1.13724928367, "right": 1.4054532577899999, "trade": 2.37522441652, "recal": 5.30614973262, "appear": 7.9287497919, "mislead": 22.6153846154, "textbas": 1587.6, "take": 2.27923336444, "now": 1.160780873, "might": 2.1561863370900003, "untru": 94.5, "name": 3.3063519611100003, "see": 3.81726376533, "high": 5.73886639675, "publish": 2.73771339886, "power": 1.3396337861799998, "suppos": 4.23021582734, "issu": 2.87843350558, "tutori": 59.4606741573, "coupl": 3.2572835453400004, "versa": 23.381443299, "hypothesi": 13.580838323399998, "mean": 8.69441401974, "widget": 337.787234043, "user": 23.13161728995, "seven": 1.93940874664, "compris": 11.57986870896, "shape": 3.20338983051, "york": 4.6008500772900005, "research": 1.9420183486200002, "plan": 1.5356935577500002, "signific": 4.35874439463, "etc\u2026": 1587.6, "wherea": 4.13868613139, "challeng": 5.11633902674, "six": 1.5552507837, "promin": 2.39746300211, "want": 3.99396226416, "propag": 18.8104265403, "text": 40.66758620691, "into": 2.03004922958, "ripe": 72.16363636359999, "gatherwrangl": 1587.6, "extens": 1.99171998495, "howev": 1.0945191313299998, "share": 1.8566249561500001, "san": 6.60262008734, "week": 1.80532181033, "which": 2.01038369, "random": 7.1902173913, "tfidfvector": 1587.6, "term": 8.37121012392, "bewar": 131.20661157, "thus": 1.6463756092500001, "falsehood": 108.739726027, "other": 2.01984732824, "techniqu": 3.7293868921800004, "twoword": 1587.6, "one": 6.03764974332, "graph": 75.4204275534, "second": 2.2261796256, "terminolog": 17.6989966555, "prefer": 3.0216977540900003, "full": 8.33648393195, "routin": 7.997984886649999, "margin": 6.16783216783, "becaus": 5.74759249875, "facebook": 85.6618705035, "four": 2.41901569404, "corpus": 96.364188164, "get": 14.2850073108, "winston": 16.8, "like": 5.745928338750001, "implement": 3.57648118946, "beg": 21.541383989099998, "manag": 1.6448404475799998, "select": 2.02345144022, "collect": 1.64109985528, "dilemma": 27.9507042254, "opinion": 7.6089144500399994, "detect": 5.41288782816, "part": 4.17322731156, "attempt": 2.9443620177999996, "baffl": 180.409090909, "rare": 2.7259615384599996, "outlin": 6.38102893891, "includ": 2.0381282495599997, "abort": 13.627467811199999, "tabl": 3.82093862816, "straightforward": 27.7552447552, "scikit": 1587.6, "grid": 18.1232876712, "phrase": 24.73860537592, "this": 25.094840667750002, "pretti": 78.75, "decent": 35.5964125561, "time": 6.06764762088, "api": 84.44680851060001, "process": 5.08574479446, "chang": 1.1808985421, "similar": 1.37514075357, "project": 22.79522862825, "differ": 3.7096347067499997, "decis": 4.32, "profession": 2.6389627659599997, "mcintir": 1323.0, "halfway": 26.862944162399998, "valuabl": 7.46754468485, "most": 6.12578778138, "between": 4.13814674832, "everi": 1.47917637194, "certain": 3.6155773172400005, "excel": 4.84467500763, "obvious": 6.44841592201, "fail": 1.9281029876099998, "all": 4.04587155964, "top": 5.516330785260001, "headlin": 38.9117647059, "mix": 2.7852631578900002, "school": 1.64008264463, "chemtrail": 1587.6, "reason": 1.72340425532, "countvector": 1587.6, "proposit": 21.9281767956, "combat": 10.02589201136, "intercept": 15.8285144566, "case": 2.96997474512, "produc": 4.10798688978, "hybrid": 12.630071599, "that": 33.131474103749994, "pair": 4.36873968079, "subject": 1.8715077213299998, "twenti": 5.1562195518000005, "call": 2.1353059852, "cycl": 5.40919931857, "off": 3.0242880274400004, "more": 10.171706816999999, "and": 59.003716535669994, "while": 1.0441988950299999, "dedic": 3.20533010297, "novel": 4.06555697823, "these": 2.14830852504, "stanford": 12.6, "jone": 4.97368421053, "tzrwu": 1587.6, "amount": 4.54054054054, "made": 2.14077669902, "nnumber": 1587.6, "night": 2.26670474015, "befor": 3.30108123093, "cynic": 36.3295194508, "point": 2.51980001588, "crossvalid": 3175.2, "detector": 45.6206896552, "stori": 4.04793472718, "can": 7.05756834852, "make": 4.305064063440001, "set": 4.74831763124, "kaggl": 1587.6, "search": 3.2539454806299997, "onli": 4.102590606640001, "each": 1.18974820144, "promot": 2.0172808132099997, "half": 1.75813953488, "are": 13.38877716514, "thing": 2.4065484311099996, "accur": 5.768895348840001, "rise": 2.02940048575, "unfamiliar": 37.7102137767, "two": 5.0689655172500006, "remain": 1.16598119859, "common": 4.2077922078, "imposs": 4.96125, "pundit": 71.8371040724, "block": 6.40548718984, "qualiti": 5.8658784408, "address": 2.86157173756, "prevent": 2.16117615029, "method": 2.5714285714300003, "factual": 37.8, "murkier": 1587.6, "repres": 1.46972782818, "bio": 42.336000000000006, "come": 2.65662650602, "abstract": 9.966101694919999, "exampl": 1.50483412322, "chrome": 65.6033057851, "learn": 11.61375274325, "identifi": 2.30187037843, "differenti": 7.759530791789999, "import": 2.6803984467400004, "first": 4.03046458492, "game": 2.57978550536, "cover": 1.69380134429, "tfidf": 4762.799999999999, "use": 18.533497632839996, "tool": 9.99433427762, "score": 34.307941653200004, "social": 1.9904714142400002, "host": 2.7092150170599996, "often": 2.5890410959, "infowar": 3175.2, "bay": 13.889763779520003, "inde": 4.43092380687, "same": 1.11857958148, "mention": 5.07788261634, "effici": 5.09335899904}, "logtfidf": {"after": 0.040981389296199995, "real": 22.264984635498, "understand": 1.0880858756799998, "unless": 1.69528182715, "scientistjournalist": 7.369978720910001, "vector": 16.27099438985, "typic": 0.812774319158, "magazin": 0.888401591632, "outlet": 4.89853626868, "guardian": 1.8847669357199999, "repo": 5.91136369821, "new": 0.08864973425549999, "vice": 3.29409485482, "fact": 0.5502899207949999, "addit": 0.220218882972, "would": 0.47770576778819995, "what": 2.25887296827, "markham": 4.7973664907, "web": 1.6431309733200001, "dataset": 94.78520219952, "function": 0.914465741594, "class": 1.4995443798660002, "spectrum": 2.53687646687, "logic": 2.18931939783, "salon": 3.6204746449800003, "thought": 0.685867118283, "viewpoint": 2.95596904038, "quandari": 5.91136369821, "abov": 0.643865229816, "convinc": 1.4827641951700001, "assembl": 1.09899028905, "creat": 0.890307274056, "complet": 0.6458557261410001, "higher": 0.752308398995, "sweden": 2.01575372242, "their": 0.10752353585890001, "yes": 2.65237310559, "equal": 1.866054782686, "data\u2014i": 7.369978720910001, "left": 1.093657244259, "instead": 1.399899451245, "least": 0.96057116949, "conced": 2.8960568215299998, "multipl": 1.01092401812, "alex": 2.36603241496, "how": 5.18723652623, "test": 3.908897748412, "scrape": 8.5129268234, "news": 31.529538159855, "dismiss": 1.6513076337600001, "bunch": 3.70130197411, "truth": 1.74849148898, "had": 0.0464780244111, "was\u2026": 7.369978720910001, "end": 0.101476798618, "found": 0.107841124048, "given": 1.213023243324, "word": 16.40411030678, "guarante": 1.8826952548500002, "exhibit": 1.2791214299200002, "difficult": 0.912110767588, "will": 0.202786534915, "exploit": 1.7568506145200002, "consid": 0.214894723824, "predict": 3.2914804753799998, "those": 0.7141975634919999, "null": 7.369978720910001, "purpos": 1.607738074644, "intimaci": 4.26539204244, "otherwis": 1.3141319148700001, "repost": 6.83935046985, "vaguelydefin": 7.369978720910001, "next": 0.804327370998, "fakest": 29.479914883640003, "claim": 0.423291231925, "perform": 0.42618085058, "but": 0.0809618603595, "definit": 1.1755733298, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 8.35116294516, "commit": 1.0598786410299998, "cost": 1.68258015236, "final": 0.292733863948, "perfect": 4.50289300068, "expect": 3.9425387608, "parti": 0.724497710444, "naiv": 11.75046480096, "review": 0.7929522039210001, "domin": 1.683749230284, "organ": 0.9878410573399999, "pant": 3.7141391208699996, "has": 0.0854478897096, "have": 0.0443550070236, "paramet": 11.392760575439999, "stop": 0.778579374963, "transform": 1.22966322707, "formul": 2.2885743559200002, "optim": 4.891255590819999, "threshold": 6.271744432619999, "bootcamp": 7.369978720910001, "out": 0.2337055636772, "model": 21.386052120219002, "treat": 1.27821645249, "good": 1.2557682147209999, "number": 0.3864343136744, "under": 0.07526180538319999, "cours": 0.765899404133, "numer": 1.818281437038, "huge": 1.47916358195, "count": 6.2374295569500005, "around": 0.581631317346, "start": 0.472886738582, "when": 0.0822199554336, "some": 0.23744105438700003, "not": 0.155524130075, "far": 1.073247529006, "gridsearch": 7.369978720910001, "late": 0.275660890876, "wrong": 1.70078769102, "someth": 1.18830712273, "disproportion": 3.47611968611, "happen": 2.17280883604, "quick": 0.790727508899, "pleas": 2.21149829955, "metric": 3.1016808515599994, "handl": 1.36683266903, "almost": 0.42907884333400004, "corpura": 7.369978720910001, "then": 0.24910159569269996, "complic": 1.7312682430000002, "graphic": 2.20120072572, "anoth": 0.127896361652, "rightw": 7.369978720910001, "adept": 4.02007463363, "turn": 0.974697753192, "last": 0.19204364461100001, "let": 1.2488025672799998, "world": 0.107420248621, "scienc": 7.572925610018999, "task": 4.0724604198300005, "employ": 2.317680614829, "github": 7.369978720910001, "construct": 0.658603355972, "passion": 2.0974921144, "polit": 3.420856704876, "internet": 3.2127124918, "journalist": 3.22341612194, "feed": 6.154105953270001, "conspiracyladen": 7.369978720910001, "simpl": 1.2232212893899999, "influenc": 1.144746370856, "stuck": 2.94154571342, "algorithm": 3.33044239518, "theori": 1.10772396902, "respond": 1.15477080241, "sort": 1.64639361896, "either": 0.459327638815, "curious": 3.15194268634, "such": 0.417871844642, "accuraci": 10.1859061624, "thousand": 0.906949263988, "elect": 2.776111891128, "with": 0.01915986741424, "lie": 1.16805067564, "whose": 0.5510546556329999, "politician": 9.31541991708, "deriv": 1.02381618275, "lot": 2.9671939005000003, "andor": 19.61120879391, "sourc": 0.529218310751, "just": 1.158125736436, "locat": 0.46854337067199997, "discours": 5.602945038580001, "classic": 0.8791034528499999, "filter": 2.82668393864, "rate": 3.044135488664, "html": 4.26539204244, "arduous": 4.584967478669999, "media": 2.8592491591559996, "acquisit": 2.3395407995200004, "ani": 0.125608358366, "question": 1.580621858028, "divid": 1.6805359089179999, "talli": 6.896010769260001, "from": 0.006237595857525999, "answer": 1.5366310419, "allow": 0.48056122237800003, "work": 0.436138269092, "num": 0.008189750280322, "veri": 0.230159793238, "churchil": 2.90062825806, "aren": 6.17605625244, "spam": 5.38210437275, "obfusc": 5.206655695249999, "environ": 1.2341974030299998, "curv": 2.40783363597, "acquir": 1.1332178178499999, "for": 0.005039846326352001, "economi": 1.2932543298499999, "manipul": 2.21322491868, "face": 0.589602371257, "creation": 1.11846026847, "releas": 0.608521699544, "sieradski": 7.369978720910001, "competit": 1.12154907401, "zero": 2.1692741832299998, "determin": 2.318499057066, "topic": 6.7879966216400005, "true": 4.69162814817, "better": 1.3928558812, "result": 0.272757816762, "frequent": 0.7443211360850001, "sheepl": 7.369978720910001, "look": 1.2927733872, "spread": 1.04186338169, "bag": 2.76380903459, "kevin": 2.05677274187, "chanc": 1.44572292349, "fake": 122.06762816808002, "bar": 1.35724203853, "ratio": 3.95179346476, "think": 1.06717661175, "writer": 1.0145657459, "center": 0.555216308776, "combin": 0.529218310751, "percentag": 1.8054583135900002, "util": 1.5389763962399998, "reput": 1.40229470247, "column": 11.74196567628, "though": 0.616088382158, "toward": 0.48877277716000006, "remov": 0.6960488415880001, "fight": 0.917772050203, "websit": 1.849788047612, "doe": 0.5340417297169999, "lowercas": 5.08759633523, "could": 0.7438250891600001, "valid": 3.7778464353600003, "three": 0.06411868822490001, "probabl": 0.972882412913, "side": 1.4080463006069999, "train": 1.321836625678, "they": 0.0297269947676, "bodi": 0.6215709351609999, "assumpt": 2.2213221289200002, "step": 1.03954505698, "error": 3.5971708686, "chart": 6.40380346239, "big": 1.00798563557, "type": 0.707101485387, "matter": 0.8951625270360001, "fals": 3.6542955546199996, "row": 1.71363732085, "presid": 0.6852420010529999, "scientist": 1.54634128444, "machin": 2.78471916124, "action": 0.598043165069, "bias": 5.23968552934, "bloomberg": 3.7509853942599998, "came": 1.135577648715, "sinc": 0.1607363989154, "download": 2.6841506319, "presidenti": 1.84452578178, "flag": 1.78385428972, "figur": 0.7101721121600001, "gave": 0.615840930592, "earlier": 0.624742371425, "choos": 4.29021198216, "meti": 5.86590132413, "opportun": 1.10258843705, "clear": 0.617474727198, "find": 1.095562660576, "trump": 4.12738636942, "overlap": 4.9849878792, "borrow": 2.0822168683, "consider": 1.6651254961200002, "conclus": 4.73455610679, "even": 0.45716569450200006, "nor": 1.2083495472799999, "base": 0.40956990686100003, "relat": 0.42620060330799997, "label": 1.49898832727, "blather": 7.369978720910001, "drawn": 1.52672420097, "who": 0.0609002329859, "decid": 1.965968615679, "univers": 0.222262105686, "hot": 1.52991862796, "permiss": 1.8373800586400002, "post": 2.4171004581029996, "here": 5.310229130220001, "dispos": 2.34544052164, "lower": 2.226605789982, "upper": 1.22686662419, "were": 0.09716457472439999, "long": 0.471291587756, "realest": 22.10993616273, "surpris": 2.94784871722, "counter": 1.9133763754, "evalu": 1.9388802431299998, "than": 0.0967825866546, "struggl": 1.2119409739799998, "plus": 1.54575009318, "about": 0.31421738737300003, "problem": 0.569140724273, "intuit": 3.3216780971900004, "communiti": 1.347123895582, "francisco": 3.3330592702999997, "distinct": 0.825779146958, "daniel": 1.47474978168, "context": 1.44920491442, "kagglestyl": 7.369978720910001, "entir": 0.46603068026999994, "lean": 2.8171550152900005, "deeplearn": 7.369978720910001, "conspiraci": 2.5594217052, "correct": 1.29831763181, "standard": 1.91223152946, "dure": 0.0491209066894, "posit": 1.58326159304, "classifi": 13.332237081199999, "should": 0.509419876758, "contribut": 0.655201578909, "led": 0.29104709623799996, "across": 0.549198455941, "complex": 0.8502416364309999, "notion": 1.9956266680799999, "categor": 2.70937382803, "reconfigur": 4.252028814630001, "conclud": 1.1061995784799998, "articl": 24.57461088509, "deliber": 1.8373800586400002, "singl": 0.475916769059, "them": 0.0941833269093, "insight": 7.40524356561, "studi": 0.426470272221, "whi": 3.54206529141, "explain": 0.955700427358, "execut": 0.804854605864, "anyth": 1.52353994585, "georg": 1.260337665552, "quit": 1.05951513684, "abl": 0.599303982475, "mani": 0.1732630324884, "data": 21.9027705264, "the": 0.0, "build": 0.982274904182, "wit": 1.47861079034, "provid": 0.39035568865000003, "total": 1.7427155468200002, "journal": 1.7248050912119999, "freelanc": 4.1118821828900005, "tactic": 1.86140042888, "order": 0.44028076158600005, "throughout": 0.41983467543499997, "show": 0.473365532026, "exact": 1.2437647732500001, "there": 0.2806852504785, "surpass": 2.31437006117, "valu": 0.823193310148, "wide": 0.44458000675399995, "matrix": 3.1186304098799997, "cross": 0.846416414759, "possibl": 0.348805474891, "way": 0.39618301987000004, "nonetheless": 4.12738636942, "best": 0.918455865894, "origin": 0.128612437587, "right": 0.34035985417, "trade": 0.865091924188, "recal": 1.6688664748100002, "appear": 1.6724153909580002, "mislead": 3.1186304098799997, "textbas": 7.369978720910001, "take": 0.261383924394, "now": 0.149092945021, "might": 0.7683410765340001, "untru": 4.5485998345, "name": 0.29169949915290005, "see": 0.722764756476, "high": 0.6891189327000001, "publish": 0.627951730934, "power": 0.292396282715, "suppos": 1.44225301477, "issu": 0.728198087868, "tutori": 4.0853151555, "coupl": 1.18089357972, "versa": 3.15194268634, "hypothesi": 2.60865985243, "mean": 2.22552770112, "widget": 5.822416212189999, "user": 6.127764320639999, "seven": 0.662383156851, "compris": 4.05196753701, "shape": 1.16420957115, "york": 1.282886391486, "research": 0.663727818138, "plan": 0.428982108147, "signific": 1.120715232996, "etc\u2026": 7.369978720910001, "wherea": 1.4203783778999999, "challeng": 1.8785839377900002, "six": 0.441636808318, "promin": 0.8744110957960001, "want": 1.3832732125099998, "propag": 2.93441131931, "text": 14.82626612987, "into": 0.0298257264574, "ripe": 4.27893626755, "gatherwrangl": 7.369978720910001, "extens": 0.6889985794750001, "howev": 0.0903151173475, "share": 0.618760299747, "san": 2.3886387452599998, "week": 0.5907388641619999, "which": 0.01035682769086, "random": 1.9727214065099998, "tfidfvector": 7.369978720910001, "term": 1.9982339012760002, "bewar": 4.87677326831, "thus": 0.49857627139300004, "falsehood": 4.68895719219, "other": 0.01974949583952, "techniqu": 1.31624384807, "twoword": 7.369978720910001, "one": 0.037532109873, "graph": 7.259861960439999, "second": 0.21427952675999998, "terminolog": 2.87350795184, "prefer": 1.10581884366, "full": 2.55601812074, "routin": 2.07918962078, "margin": 1.81934742575, "becaus": 0.6967157941250001, "facebook": 10.055386558949998, "four": 0.380427077738, "corpus": 12.7273611176, "get": 4.638152046256, "winston": 2.82137888641, "like": 0.6952678827250001, "implement": 1.27437940907, "beg": 3.06997592171, "manag": 0.497643387158, "select": 0.704804687133, "collect": 0.49536666052, "dilemma": 3.33044239518, "opinion": 2.67234666662, "detect": 1.68878274493, "part": 0.16958124393120003, "attempt": 0.7734899615019999, "baffl": 9.004159637719999, "rare": 1.00282122403, "outlin": 1.85332936004, "includ": 0.037769362781, "abort": 2.6120874479, "tabl": 1.34049610661, "straightforward": 3.3234248225200003, "scikit": 7.369978720910001, "grid": 2.89719772297, "phrase": 7.28828253212, "this": 0.0946612263125, "pretti": 13.78420182635, "decent": 3.5722448618800002, "time": 0.0672691131756, "api": 4.43612185107, "process": 1.583487597075, "chang": 0.166275625058, "similar": 0.318556092114, "project": 7.300824516791, "differ": 0.6369633639360001, "decis": 1.5402164433919998, "profession": 0.970385948273, "mcintir": 12.989019967119999, "halfway": 3.2907477965, "valuabl": 2.010566255, "most": 0.12448737777359999, "between": 0.13581472466119998, "everi": 0.391485427421, "certain": 1.184208725562, "excel": 1.5778801652, "obvious": 1.86383450716, "fail": 0.656536611573, "all": 0.04561052839119999, "top": 1.8273019133640003, "headlin": 7.68805305249, "mix": 1.02434236008, "school": 0.494746633632, "chemtrail": 7.369978720910001, "reason": 0.544301552962, "countvector": 7.369978720910001, "proposit": 3.08777242152, "combat": 3.22404753472, "intercept": 2.7618130259400004, "case": 0.790812537778, "produc": 0.942962436009, "hybrid": 2.53608060531, "that": 0.13121289652812, "pair": 1.47447456495, "subject": 0.6267443740950001, "twenti": 1.64020366598, "call": 0.1309255488976, "cycl": 1.68810108164, "off": 0.8270570407760001, "more": 0.17024931599999998, "and": 0.0037164183817523996, "while": 0.04324998379380001, "dedic": 1.16481508131, "novel": 1.40255075163, "these": 0.1430672388016, "stanford": 2.53369681396, "jone": 1.60416085533, "tzrwu": 7.369978720910001, "amount": 1.639797772398, "made": 0.1360430521946, "nnumber": 7.369978720910001, "night": 0.8183271204970001, "befor": 0.2869133156385, "cynic": 3.59263061881, "point": 0.46206471806599997, "crossvalid": 14.739957441820001, "detector": 3.8203613341300007, "stori": 1.410119253174, "can": 0.974046578364, "make": 0.29399063129159997, "set": 0.685984045156, "kaggl": 7.369978720910001, "search": 1.1798682540899998, "onli": 0.10129707331639999, "each": 0.173741689304, "promot": 0.7017504724920001, "half": 0.564256167492, "are": 0.3830771565751, "thing": 0.8781935346799999, "accur": 1.75248061485, "rise": 0.707740422218, "unfamiliar": 3.6299309802199997, "two": 0.06849422179100001, "remain": 0.15356296309, "common": 1.014977415813, "imposs": 1.60165772512, "pundit": 4.2744011123900005, "block": 2.32801563176, "qualiti": 2.15201013422, "address": 1.05137103247, "prevent": 0.7706525875229999, "method": 0.944461608841, "factual": 3.6323091026300003, "murkier": 7.369978720910001, "repres": 0.38507723275, "bio": 3.7456377879300002, "come": 0.5678198130600001, "abstract": 2.29918950399, "exampl": 0.40868267499899996, "chrome": 4.1836260877499996, "learn": 4.213760323724999, "identifi": 0.833722000472, "differenti": 2.0489218673900003, "import": 0.585636554132, "first": 0.030349159248639998, "game": 0.9477062580210001, "cover": 0.526975319156, "tfidf": 22.10993616273, "use": 0.5257443551688, "tool": 3.21774235926, "score": 11.647482566160003, "social": 0.688371502261, "host": 0.996658931332, "often": 0.516280786702, "infowar": 14.739957441820001, "bay": 4.597619584319999, "inde": 1.4886080966, "same": 0.112059649604, "mention": 1.863494372672, "effici": 1.62793753414}, "logidf": {"after": 0.020490694648099998, "real": 0.824629060574, "understand": 1.0880858756799998, "unless": 1.69528182715, "scientistjournalist": 7.369978720910001, "vector": 3.25419887797, "typic": 0.812774319158, "magazin": 0.888401591632, "outlet": 2.44926813434, "guardian": 1.8847669357199999, "repo": 5.91136369821, "new": 0.0177299468511, "vice": 1.64704742741, "fact": 0.5502899207949999, "addit": 0.220218882972, "would": 0.0796176279647, "what": 0.225887296827, "markham": 4.7973664907, "web": 1.6431309733200001, "dataset": 5.26584456664, "function": 0.914465741594, "class": 0.7497721899330001, "spectrum": 2.53687646687, "logic": 2.18931939783, "salon": 3.6204746449800003, "thought": 0.685867118283, "viewpoint": 2.95596904038, "quandari": 5.91136369821, "abov": 0.643865229816, "convinc": 1.4827641951700001, "assembl": 1.09899028905, "creat": 0.222576818514, "complet": 0.215285242047, "higher": 0.752308398995, "sweden": 2.01575372242, "their": 0.015360505122700001, "yes": 2.65237310559, "equal": 0.933027391343, "data\u2014i": 7.369978720910001, "left": 0.364552414753, "instead": 0.46663315041500003, "least": 0.480285584745, "conced": 2.8960568215299998, "multipl": 1.01092401812, "alex": 2.36603241496, "how": 0.47156695693000006, "test": 0.977224437103, "scrape": 4.2564634117, "news": 0.733245073485, "dismiss": 1.6513076337600001, "bunch": 3.70130197411, "truth": 1.74849148898, "had": 0.0464780244111, "was\u2026": 7.369978720910001, "end": 0.101476798618, "found": 0.107841124048, "given": 0.303255810831, "word": 0.585861082385, "guarante": 1.8826952548500002, "exhibit": 1.2791214299200002, "difficult": 0.912110767588, "will": 0.202786534915, "exploit": 1.7568506145200002, "consid": 0.214894723824, "predict": 1.6457402376899999, "those": 0.17854939087299998, "null": 7.369978720910001, "purpos": 0.803869037322, "intimaci": 4.26539204244, "otherwis": 1.3141319148700001, "repost": 6.83935046985, "vaguelydefin": 7.369978720910001, "next": 0.402163685499, "fakest": 7.369978720910001, "claim": 0.423291231925, "perform": 0.42618085058, "but": 0.0161923720719, "definit": 1.1755733298, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "commit": 1.0598786410299998, "cost": 0.84129007618, "final": 0.292733863948, "perfect": 1.50096433356, "expect": 0.78850775216, "parti": 0.724497710444, "naiv": 3.9168216003199996, "review": 0.7929522039210001, "domin": 0.841874615142, "organ": 0.49392052866999997, "pant": 3.7141391208699996, "has": 0.0427239448548, "have": 0.0147850023412, "paramet": 2.8481901438599997, "stop": 0.778579374963, "transform": 1.22966322707, "formul": 2.2885743559200002, "optim": 2.4456277954099996, "threshold": 3.1358722163099997, "bootcamp": 7.369978720910001, "out": 0.0584263909193, "model": 0.7374500731110001, "treat": 1.27821645249, "good": 0.418589404907, "number": 0.0966085784186, "under": 0.07526180538319999, "cours": 0.765899404133, "numer": 0.606093812346, "huge": 1.47916358195, "count": 1.24748591139, "around": 0.19387710578200001, "start": 0.236443369291, "when": 0.0205549888584, "some": 0.0395735090645, "not": 0.0155524130075, "far": 0.536623764503, "gridsearch": 7.369978720910001, "late": 0.275660890876, "wrong": 1.70078769102, "someth": 1.18830712273, "disproportion": 3.47611968611, "happen": 1.08640441802, "quick": 0.790727508899, "pleas": 2.21149829955, "metric": 3.1016808515599994, "handl": 1.36683266903, "almost": 0.42907884333400004, "corpura": 7.369978720910001, "then": 0.08303386523089999, "complic": 1.7312682430000002, "graphic": 2.20120072572, "anoth": 0.127896361652, "rightw": 7.369978720910001, "adept": 4.02007463363, "turn": 0.324899251064, "last": 0.19204364461100001, "let": 1.2488025672799998, "world": 0.107420248621, "scienc": 0.841436178891, "task": 1.35748680661, "employ": 0.7725602049429999, "github": 7.369978720910001, "construct": 0.658603355972, "passion": 2.0974921144, "polit": 0.570142784146, "internet": 1.6063562459, "journalist": 1.61170806097, "feed": 2.05136865109, "conspiracyladen": 7.369978720910001, "simpl": 1.2232212893899999, "influenc": 0.572373185428, "stuck": 2.94154571342, "algorithm": 3.33044239518, "theori": 1.10772396902, "respond": 1.15477080241, "sort": 1.64639361896, "either": 0.459327638815, "curious": 3.15194268634, "such": 0.059695977806, "accuraci": 2.5464765406, "thousand": 0.906949263988, "elect": 0.925370630376, "with": 0.00119749171339, "lie": 1.16805067564, "whose": 0.5510546556329999, "politician": 1.55256998618, "deriv": 1.02381618275, "lot": 1.4835969502500002, "andor": 6.5370695979699995, "sourc": 0.529218310751, "just": 0.289531434109, "locat": 0.46854337067199997, "discours": 2.8014725192900003, "classic": 0.8791034528499999, "filter": 2.82668393864, "rate": 0.761033872166, "html": 4.26539204244, "arduous": 4.584967478669999, "media": 0.9530830530519999, "acquisit": 2.3395407995200004, "ani": 0.125608358366, "question": 0.790310929014, "divid": 0.8402679544589999, "talli": 3.4480053846300005, "from": 0.000567054168866, "answer": 1.5366310419, "allow": 0.24028061118900002, "work": 0.109034567273, "num": 0.00031499039539700004, "veri": 0.230159793238, "churchil": 2.90062825806, "aren": 6.17605625244, "spam": 5.38210437275, "obfusc": 5.206655695249999, "environ": 1.2341974030299998, "curv": 2.40783363597, "acquir": 1.1332178178499999, "for": 0.00031499039539700004, "economi": 1.2932543298499999, "manipul": 2.21322491868, "face": 0.589602371257, "creation": 1.11846026847, "releas": 0.608521699544, "sieradski": 7.369978720910001, "competit": 1.12154907401, "zero": 2.1692741832299998, "determin": 0.772833019022, "topic": 1.6969991554100001, "true": 0.938325629634, "better": 0.6964279406, "result": 0.136378908381, "frequent": 0.7443211360850001, "sheepl": 7.369978720910001, "look": 0.6463866936, "spread": 1.04186338169, "bag": 2.76380903459, "kevin": 2.05677274187, "chanc": 1.44572292349, "fake": 2.9063720992400004, "bar": 1.35724203853, "ratio": 1.97589673238, "think": 1.06717661175, "writer": 1.0145657459, "center": 0.555216308776, "combin": 0.529218310751, "percentag": 1.8054583135900002, "util": 1.5389763962399998, "reput": 1.40229470247, "column": 1.95699427938, "though": 0.308044191079, "toward": 0.48877277716000006, "remov": 0.6960488415880001, "fight": 0.917772050203, "websit": 0.924894023806, "doe": 0.5340417297169999, "lowercas": 5.08759633523, "could": 0.18595627229000003, "valid": 1.8889232176800002, "three": 0.06411868822490001, "probabl": 0.972882412913, "side": 0.46934876686899996, "train": 0.660918312839, "they": 0.0297269947676, "bodi": 0.6215709351609999, "assumpt": 2.2213221289200002, "step": 1.03954505698, "error": 1.7985854343, "chart": 2.13460115413, "big": 1.00798563557, "type": 0.707101485387, "matter": 0.8951625270360001, "fals": 1.8271477773099998, "row": 1.71363732085, "presid": 0.6852420010529999, "scientist": 1.54634128444, "machin": 1.39235958062, "action": 0.598043165069, "bias": 2.61984276467, "bloomberg": 3.7509853942599998, "came": 0.378525882905, "sinc": 0.0803681994577, "download": 2.6841506319, "presidenti": 1.84452578178, "flag": 1.78385428972, "figur": 0.7101721121600001, "gave": 0.615840930592, "earlier": 0.624742371425, "choos": 1.43007066072, "meti": 5.86590132413, "opportun": 1.10258843705, "clear": 0.617474727198, "find": 0.547781330288, "trump": 4.12738636942, "overlap": 2.4924939396, "borrow": 2.0822168683, "consider": 0.8325627480600001, "conclus": 1.57818536893, "even": 0.152388564834, "nor": 1.2083495472799999, "base": 0.13652330228700002, "relat": 0.21310030165399999, "label": 1.49898832727, "blather": 7.369978720910001, "drawn": 1.52672420097, "who": 0.0609002329859, "decid": 0.655322871893, "univers": 0.222262105686, "hot": 1.52991862796, "permiss": 1.8373800586400002, "post": 0.8057001527009999, "here": 0.8850381883700001, "dispos": 2.34544052164, "lower": 0.742201929994, "upper": 1.22686662419, "were": 0.024291143681099997, "long": 0.235645793878, "realest": 7.369978720910001, "surpris": 1.47392435861, "counter": 1.9133763754, "evalu": 1.9388802431299998, "than": 0.0322608622182, "struggl": 1.2119409739799998, "plus": 1.54575009318, "about": 0.0628434774746, "problem": 0.569140724273, "intuit": 3.3216780971900004, "communiti": 0.673561947791, "francisco": 1.6665296351499999, "distinct": 0.825779146958, "daniel": 1.47474978168, "context": 1.44920491442, "kagglestyl": 7.369978720910001, "entir": 0.46603068026999994, "lean": 2.8171550152900005, "deeplearn": 7.369978720910001, "conspiraci": 2.5594217052, "correct": 1.29831763181, "standard": 0.63741050982, "dure": 0.0491209066894, "posit": 0.316652318608, "classifi": 1.6665296351499999, "should": 0.509419876758, "contribut": 0.655201578909, "led": 0.29104709623799996, "across": 0.549198455941, "complex": 0.8502416364309999, "notion": 1.9956266680799999, "categor": 2.70937382803, "reconfigur": 4.252028814630001, "conclud": 1.1061995784799998, "articl": 0.702131739574, "deliber": 1.8373800586400002, "singl": 0.475916769059, "them": 0.0941833269093, "insight": 2.46841452187, "studi": 0.426470272221, "whi": 1.18068843047, "explain": 0.955700427358, "execut": 0.804854605864, "anyth": 1.52353994585, "georg": 0.630168832776, "quit": 1.05951513684, "abl": 0.599303982475, "mani": 0.0433157581221, "data": 1.2168205848, "the": 0.0, "build": 0.491137452091, "wit": 1.47861079034, "provid": 0.19517784432500002, "total": 0.43567888670500005, "journal": 0.8624025456059999, "freelanc": 4.1118821828900005, "tactic": 1.86140042888, "order": 0.22014038079300002, "throughout": 0.41983467543499997, "show": 0.236682766013, "exact": 1.2437647732500001, "there": 0.0400978929255, "surpass": 2.31437006117, "valu": 0.823193310148, "wide": 0.44458000675399995, "matrix": 3.1186304098799997, "cross": 0.846416414759, "possibl": 0.348805474891, "way": 0.19809150993500002, "nonetheless": 2.06369318471, "best": 0.459227932947, "origin": 0.128612437587, "right": 0.34035985417, "trade": 0.865091924188, "recal": 1.6688664748100002, "appear": 0.278735898493, "mislead": 3.1186304098799997, "textbas": 7.369978720910001, "take": 0.130691962197, "now": 0.149092945021, "might": 0.7683410765340001, "untru": 4.5485998345, "name": 0.09723316638430002, "see": 0.240921585492, "high": 0.13782378654000002, "publish": 0.313975865467, "power": 0.292396282715, "suppos": 1.44225301477, "issu": 0.364099043934, "tutori": 4.0853151555, "coupl": 1.18089357972, "versa": 3.15194268634, "hypothesi": 2.60865985243, "mean": 0.37092128352, "widget": 5.822416212189999, "user": 2.04258810688, "seven": 0.662383156851, "compris": 1.35065584567, "shape": 1.16420957115, "york": 0.42762879716200003, "research": 0.663727818138, "plan": 0.428982108147, "signific": 0.373571744332, "etc\u2026": 7.369978720910001, "wherea": 1.4203783778999999, "challeng": 0.9392919688950001, "six": 0.441636808318, "promin": 0.8744110957960001, "want": 0.6916366062549999, "propag": 2.93441131931, "text": 1.14048200999, "into": 0.0149128632287, "ripe": 4.27893626755, "gatherwrangl": 7.369978720910001, "extens": 0.6889985794750001, "howev": 0.0903151173475, "share": 0.618760299747, "san": 1.1943193726299999, "week": 0.5907388641619999, "which": 0.00517841384543, "random": 1.9727214065099998, "tfidfvector": 7.369978720910001, "term": 0.33303898354600003, "bewar": 4.87677326831, "thus": 0.49857627139300004, "falsehood": 4.68895719219, "other": 0.00987474791976, "techniqu": 1.31624384807, "twoword": 7.369978720910001, "one": 0.0062553516455, "graph": 3.6299309802199997, "second": 0.10713976337999999, "terminolog": 2.87350795184, "prefer": 1.10581884366, "full": 0.511203624148, "routin": 2.07918962078, "margin": 1.81934742575, "becaus": 0.139343158825, "facebook": 3.3517955196499996, "four": 0.190213538869, "corpus": 3.1818402794, "get": 0.579769005782, "winston": 2.82137888641, "like": 0.139053576545, "implement": 1.27437940907, "beg": 3.06997592171, "manag": 0.497643387158, "select": 0.704804687133, "collect": 0.49536666052, "dilemma": 3.33044239518, "opinion": 1.33617333331, "detect": 1.68878274493, "part": 0.04239531098280001, "attempt": 0.38674498075099994, "baffl": 4.5020798188599995, "rare": 1.00282122403, "outlin": 1.85332936004, "includ": 0.0188846813905, "abort": 2.6120874479, "tabl": 1.34049610661, "straightforward": 3.3234248225200003, "scikit": 7.369978720910001, "grid": 2.89719772297, "phrase": 1.82207063303, "this": 0.0037864490525, "pretti": 2.75684036527, "decent": 3.5722448618800002, "time": 0.0112115188626, "api": 4.43612185107, "process": 0.527829199025, "chang": 0.166275625058, "similar": 0.318556092114, "project": 0.561601885907, "differ": 0.212321121312, "decis": 0.7701082216959999, "profession": 0.970385948273, "mcintir": 6.4945099835599995, "halfway": 3.2907477965, "valuabl": 2.010566255, "most": 0.020747896295599998, "between": 0.033953681165299995, "everi": 0.391485427421, "certain": 0.592104362781, "excel": 1.5778801652, "obvious": 1.86383450716, "fail": 0.656536611573, "all": 0.011402632097799998, "top": 0.609100637788, "headlin": 2.56268435083, "mix": 1.02434236008, "school": 0.494746633632, "chemtrail": 7.369978720910001, "reason": 0.544301552962, "countvector": 7.369978720910001, "proposit": 3.08777242152, "combat": 1.61202376736, "intercept": 2.7618130259400004, "case": 0.395406268889, "produc": 0.314320812003, "hybrid": 2.53608060531, "that": 0.00397614837964, "pair": 1.47447456495, "subject": 0.6267443740950001, "twenti": 1.64020366598, "call": 0.0654627744488, "cycl": 1.68810108164, "off": 0.41352852038800003, "more": 0.017024931599999998, "and": 6.29901420636e-05, "while": 0.04324998379380001, "dedic": 1.16481508131, "novel": 1.40255075163, "these": 0.0715336194008, "stanford": 2.53369681396, "jone": 1.60416085533, "tzrwu": 7.369978720910001, "amount": 0.819898886199, "made": 0.0680215260973, "nnumber": 7.369978720910001, "night": 0.8183271204970001, "befor": 0.0956377718795, "cynic": 3.59263061881, "point": 0.23103235903299998, "crossvalid": 7.369978720910001, "detector": 3.8203613341300007, "stori": 0.705059626587, "can": 0.162341096394, "make": 0.07349765782289999, "set": 0.171496011289, "kaggl": 7.369978720910001, "search": 1.1798682540899998, "onli": 0.025324268329099998, "each": 0.173741689304, "promot": 0.7017504724920001, "half": 0.564256167492, "are": 0.0294674735827, "thing": 0.8781935346799999, "accur": 1.75248061485, "rise": 0.707740422218, "unfamiliar": 3.6299309802199997, "two": 0.0136988443582, "remain": 0.15356296309, "common": 0.338325805271, "imposs": 1.60165772512, "pundit": 4.2744011123900005, "block": 1.16400781588, "qualiti": 1.07600506711, "address": 1.05137103247, "prevent": 0.7706525875229999, "method": 0.944461608841, "factual": 3.6323091026300003, "murkier": 7.369978720910001, "repres": 0.38507723275, "bio": 3.7456377879300002, "come": 0.28390990653000003, "abstract": 2.29918950399, "exampl": 0.40868267499899996, "chrome": 4.1836260877499996, "learn": 0.842752064745, "identifi": 0.833722000472, "differenti": 2.0489218673900003, "import": 0.292818277066, "first": 0.0075872898121599995, "game": 0.9477062580210001, "cover": 0.526975319156, "tfidf": 7.369978720910001, "use": 0.0292080197316, "tool": 1.60887117963, "score": 1.4559353207700003, "social": 0.688371502261, "host": 0.996658931332, "often": 0.258140393351, "infowar": 7.369978720910001, "bay": 1.5325398614399999, "inde": 1.4886080966, "same": 0.112059649604, "mention": 0.931747186336, "effici": 1.62793753414}, "freq": {"after": 2, "real": 27, "understand": 1, "unless": 1, "scientistjournalist": 1, "vector": 5, "typic": 1, "magazin": 1, "outlet": 2, "guardian": 1, "repo": 1, "new": 5, "vice": 2, "fact": 1, "addit": 1, "would": 6, "what": 10, "markham": 1, "web": 1, "dataset": 18, "function": 1, "class": 2, "spectrum": 1, "logic": 1, "salon": 1, "thought": 1, "viewpoint": 1, "quandari": 1, "abov": 1, "convinc": 1, "assembl": 1, "creat": 4, "complet": 3, "higher": 1, "sweden": 1, "their": 7, "yes": 1, "equal": 2, "data\u2014i": 1, "left": 3, "instead": 3, "least": 2, "conced": 1, "multipl": 1, "alex": 1, "how": 11, "test": 4, "scrape": 2, "news": 43, "dismiss": 1, "bunch": 1, "truth": 1, "had": 1, "was\u2026": 1, "end": 1, "found": 1, "given": 4, "word": 28, "guarante": 1, "exhibit": 1, "difficult": 1, "will": 1, "exploit": 1, "consid": 1, "predict": 2, "those": 4, "null": 1, "purpos": 2, "intimaci": 1, "otherwis": 1, "repost": 1, "vaguelydefin": 1, "next": 2, "fakest": 4, "claim": 1, "perform": 1, "but": 5, "definit": 1, "need": 1, "our": 1, "classif": 4, "commit": 1, "cost": 2, "final": 1, "perfect": 3, "expect": 5, "parti": 1, "naiv": 3, "review": 1, "domin": 2, "organ": 2, "pant": 1, "has": 2, "have": 3, "paramet": 4, "stop": 1, "transform": 1, "formul": 1, "optim": 2, "threshold": 2, "bootcamp": 1, "out": 4, "model": 29, "treat": 1, "good": 3, "number": 4, "under": 1, "cours": 1, "numer": 3, "huge": 1, "count": 5, "around": 3, "start": 2, "when": 4, "some": 6, "not": 10, "far": 2, "gridsearch": 1, "late": 1, "wrong": 1, "someth": 1, "disproportion": 1, "happen": 2, "quick": 1, "pleas": 1, "metric": 1, "handl": 1, "almost": 1, "corpura": 1, "then": 3, "complic": 1, "graphic": 1, "anoth": 1, "rightw": 1, "adept": 1, "turn": 3, "last": 1, "let": 1, "world": 1, "scienc": 9, "task": 3, "employ": 3, "github": 1, "construct": 1, "passion": 1, "polit": 6, "internet": 2, "journalist": 2, "feed": 3, "conspiracyladen": 1, "simpl": 1, "influenc": 2, "stuck": 1, "algorithm": 1, "theori": 1, "respond": 1, "sort": 1, "either": 1, "curious": 1, "such": 7, "accuraci": 4, "thousand": 1, "elect": 3, "with": 16, "lie": 1, "whose": 1, "politician": 6, "deriv": 1, "lot": 2, "andor": 3, "sourc": 1, "just": 4, "locat": 1, "discours": 2, "classic": 1, "filter": 1, "rate": 4, "html": 1, "arduous": 1, "media": 3, "acquisit": 1, "ani": 1, "question": 2, "divid": 2, "talli": 2, "from": 11, "answer": 1, "allow": 2, "work": 4, "num": 26, "veri": 1, "churchil": 1, "aren": 1, "spam": 1, "obfusc": 1, "environ": 1, "curv": 1, "acquir": 1, "for": 16, "economi": 1, "manipul": 1, "face": 1, "creation": 1, "releas": 1, "sieradski": 1, "competit": 1, "zero": 1, "determin": 3, "topic": 4, "true": 5, "better": 2, "result": 2, "frequent": 1, "sheepl": 1, "look": 2, "spread": 1, "bag": 1, "kevin": 1, "chanc": 1, "fake": 42, "bar": 1, "ratio": 2, "think": 1, "writer": 1, "center": 1, "combin": 1, "percentag": 1, "util": 1, "reput": 1, "column": 6, "though": 2, "toward": 1, "remov": 1, "fight": 1, "websit": 2, "doe": 1, "lowercas": 1, "could": 4, "valid": 2, "three": 1, "probabl": 1, "side": 3, "train": 2, "they": 1, "bodi": 1, "assumpt": 1, "step": 1, "error": 2, "chart": 3, "big": 1, "type": 1, "matter": 1, "fals": 2, "row": 1, "presid": 1, "scientist": 1, "machin": 2, "action": 1, "bias": 2, "bloomberg": 1, "came": 3, "sinc": 2, "download": 1, "presidenti": 1, "flag": 1, "figur": 1, "gave": 1, "earlier": 1, "choos": 3, "meti": 1, "opportun": 1, "clear": 1, "find": 2, "trump": 1, "overlap": 2, "borrow": 1, "consider": 2, "conclus": 3, "even": 3, "nor": 1, "base": 3, "relat": 2, "label": 1, "blather": 1, "drawn": 1, "who": 1, "decid": 3, "univers": 1, "hot": 1, "permiss": 1, "post": 3, "here": 6, "dispos": 1, "lower": 3, "upper": 1, "were": 4, "long": 2, "realest": 3, "surpris": 2, "counter": 1, "evalu": 1, "than": 3, "struggl": 1, "plus": 1, "about": 5, "problem": 1, "intuit": 1, "communiti": 2, "francisco": 2, "distinct": 1, "daniel": 1, "context": 1, "kagglestyl": 1, "entir": 1, "lean": 1, "deeplearn": 1, "conspiraci": 1, "correct": 1, "standard": 3, "dure": 1, "posit": 5, "classifi": 8, "should": 1, "contribut": 1, "led": 1, "across": 1, "complex": 1, "notion": 1, "categor": 1, "reconfigur": 1, "conclud": 1, "articl": 35, "deliber": 1, "singl": 1, "them": 1, "insight": 3, "studi": 1, "whi": 3, "explain": 1, "execut": 1, "anyth": 1, "georg": 2, "quit": 1, "abl": 1, "mani": 4, "data": 18, "the": 101, "build": 2, "wit": 1, "provid": 2, "total": 4, "journal": 2, "freelanc": 1, "tactic": 1, "order": 2, "throughout": 1, "show": 2, "exact": 1, "there": 7, "surpass": 1, "valu": 1, "wide": 1, "matrix": 1, "cross": 1, "possibl": 1, "way": 2, "nonetheless": 2, "best": 2, "origin": 1, "right": 1, "trade": 1, "recal": 1, "appear": 6, "mislead": 1, "textbas": 1, "take": 2, "now": 1, "might": 1, "untru": 1, "name": 3, "see": 3, "high": 5, "publish": 2, "power": 1, "suppos": 1, "issu": 2, "tutori": 1, "coupl": 1, "versa": 1, "hypothesi": 1, "mean": 6, "widget": 1, "user": 3, "seven": 1, "compris": 3, "shape": 1, "york": 3, "research": 1, "plan": 1, "signific": 3, "etc\u2026": 1, "wherea": 1, "challeng": 2, "six": 1, "promin": 1, "want": 2, "propag": 1, "text": 13, "into": 2, "ripe": 1, "gatherwrangl": 1, "extens": 1, "howev": 1, "share": 1, "san": 2, "week": 1, "which": 2, "random": 1, "tfidfvector": 1, "term": 6, "bewar": 1, "thus": 1, "falsehood": 1, "other": 2, "techniqu": 1, "twoword": 1, "one": 6, "graph": 2, "second": 2, "terminolog": 1, "prefer": 1, "full": 5, "routin": 1, "margin": 1, "becaus": 5, "facebook": 3, "four": 2, "corpus": 4, "get": 8, "winston": 1, "like": 5, "implement": 1, "beg": 1, "manag": 1, "select": 1, "collect": 1, "dilemma": 1, "opinion": 2, "detect": 1, "part": 4, "attempt": 2, "baffl": 2, "rare": 1, "outlin": 1, "includ": 2, "abort": 1, "tabl": 1, "straightforward": 1, "scikit": 1, "grid": 1, "phrase": 4, "this": 25, "pretti": 5, "decent": 1, "time": 6, "api": 1, "process": 3, "chang": 1, "similar": 1, "project": 13, "differ": 3, "decis": 2, "profession": 1, "mcintir": 2, "halfway": 1, "valuabl": 1, "most": 6, "between": 4, "everi": 1, "certain": 2, "excel": 1, "obvious": 1, "fail": 1, "all": 4, "top": 3, "headlin": 3, "mix": 1, "school": 1, "chemtrail": 1, "reason": 1, "countvector": 1, "proposit": 1, "combat": 2, "intercept": 1, "case": 2, "produc": 3, "hybrid": 1, "that": 33, "pair": 1, "subject": 1, "twenti": 1, "call": 2, "cycl": 1, "off": 2, "more": 10, "and": 59, "while": 1, "dedic": 1, "novel": 1, "these": 2, "stanford": 1, "jone": 1, "tzrwu": 1, "amount": 2, "made": 2, "nnumber": 1, "night": 1, "befor": 3, "cynic": 1, "point": 2, "crossvalid": 2, "detector": 1, "stori": 2, "can": 6, "make": 4, "set": 4, "kaggl": 1, "search": 1, "onli": 4, "each": 1, "promot": 1, "half": 1, "are": 13, "thing": 1, "accur": 1, "rise": 1, "unfamiliar": 1, "two": 5, "remain": 1, "common": 3, "imposs": 1, "pundit": 1, "block": 2, "qualiti": 2, "address": 1, "prevent": 1, "method": 1, "factual": 1, "murkier": 1, "repres": 1, "bio": 1, "come": 2, "abstract": 1, "exampl": 1, "chrome": 1, "learn": 5, "identifi": 1, "differenti": 1, "import": 2, "first": 4, "game": 1, "cover": 1, "tfidf": 3, "use": 18, "tool": 2, "score": 8, "social": 1, "host": 1, "often": 2, "infowar": 2, "bay": 3, "inde": 1, "same": 1, "mention": 2, "effici": 1}, "idf": {"after": 1.02070207021, "real": 2.28103448276, "understand": 2.96858638743, "unless": 5.44818119423, "scientistjournalist": 1587.6, "vector": 25.898858075, "typic": 2.2541530597799997, "magazin": 2.4312404287900002, "outlet": 11.579868709000001, "guardian": 6.58481957694, "repo": 369.209302326, "new": 1.0178880554, "vice": 5.19162851537, "fact": 1.73375559681, "addit": 1.24634950542, "would": 1.0828729281799998, "what": 1.25343439128, "markham": 121.190839695, "web": 5.17133550489, "dataset": 193.609756098, "function": 2.495441685, "class": 2.11651779763, "spectrum": 12.6401273885, "logic": 8.929133858270001, "salon": 37.3552941176, "thought": 1.9854927463699998, "viewpoint": 19.2203389831, "quandari": 369.209302326, "abov": 1.90382539873, "convinc": 4.4051054384, "assembl": 3.0011342155, "creat": 1.2492917847, "complet": 1.24021560816, "higher": 2.1218925421, "sweden": 7.50638297872, "their": 1.01547908405, "yes": 14.1876675603, "equal": 2.542193755, "data\u2014i": 1587.6, "left": 1.4398693996, "instead": 1.59461631177, "least": 1.6165359943000002, "conced": 18.102622577, "multipl": 2.74813917258, "alex": 10.655033557000001, "how": 1.60250328051, "test": 2.65707112971, "scrape": 70.56, "news": 2.08182533438, "dismiss": 5.2137931034500005, "bunch": 40.5, "truth": 5.745928338759999, "had": 1.0475750577399998, "was\u2026": 1587.6, "end": 1.10680423871, "found": 1.11387076405, "given": 1.35426085473, "word": 1.7965372864099998, "guarante": 6.57119205298, "exhibit": 3.5934812132199996, "difficult": 2.48957189901, "will": 1.22481098596, "exploit": 5.79416058394, "consid": 1.2397313759200002, "predict": 5.18484650555, "those": 1.19548192771, "null": 1587.6, "purpos": 2.23416830847, "intimaci": 71.1928251121, "otherwis": 3.72151898734, "repost": 933.882352941, "vaguelydefin": 1587.6, "next": 1.4950560316400001, "fakest": 1587.6, "claim": 1.52697893623, "perform": 1.5313977042500002, "but": 1.01632417899, "definit": 3.24, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "commit": 2.8860207235, "cost": 2.31935719503, "final": 1.34008609775, "perfect": 4.48601299802, "expect": 2.20011086475, "parti": 2.06369426752, "naiv": 50.2405063291, "review": 2.2099109131400003, "domin": 2.320713346, "organ": 1.6387283237, "pant": 41.023255814, "has": 1.0436497502, "have": 1.0148948411399998, "paramet": 17.256521739100002, "stop": 2.1783754116400003, "transform": 3.42007755278, "formul": 9.86086956522, "optim": 11.5377906977, "threshold": 23.008695652199997, "bootcamp": 1587.6, "out": 1.06016694491, "model": 2.0905978404, "treat": 3.59023066486, "good": 1.51981619759, "number": 1.10142916609, "under": 1.0781663837, "cours": 2.15092805853, "numer": 1.83325635104, "huge": 4.38927287808, "count": 3.48157894737, "around": 1.21394708671, "start": 1.26673581744, "when": 1.02076769755, "some": 1.04036697248, "not": 1.01567398119, "far": 1.71022298826, "gridsearch": 1587.6, "late": 1.31740104556, "wrong": 5.478260869570001, "someth": 3.28152128979, "disproportion": 32.33401222, "happen": 2.96359902931, "quick": 2.205, "pleas": 9.12938470385, "metric": 22.235294117600002, "handl": 3.9229058561900003, "almost": 1.53584212054, "corpura": 1587.6, "then": 1.08657860516, "complic": 5.6478121664900005, "graphic": 9.035856573710001, "anoth": 1.13643521832, "rightw": 1587.6, "adept": 55.7052631579, "turn": 1.3838912133899999, "last": 1.2117234010100002, "let": 3.48616600791, "world": 1.11340206186, "scienc": 2.31969608416, "task": 3.88641370869, "employ": 2.16530278232, "github": 1587.6, "construct": 1.9320920043799998, "passion": 8.14571575167, "polit": 1.76851954996, "internet": 4.98461538462, "journalist": 5.01136363636, "feed": 7.77853993141, "conspiracyladen": 1587.6, "simpl": 3.3981164383599998, "influenc": 1.77246846042, "stuck": 18.945107398599998, "algorithm": 27.9507042254, "theori": 3.02745995423, "respond": 3.17329602239, "sort": 5.188235294119999, "either": 1.5830092731099998, "curious": 23.381443299, "such": 1.06151377374, "accuraci": 12.7620578778, "thousand": 2.4767550702000003, "elect": 2.5228031145700003, "with": 1.0011982089899998, "lie": 3.2157180474000002, "whose": 1.73508196721, "politician": 4.7235941684, "deriv": 2.78379800105, "lot": 4.40877534018, "andor": 690.260869565, "sourc": 1.69760479042, "just": 1.33580143037, "locat": 1.59766529134, "discours": 16.468879668, "classic": 2.4087391898, "filter": 16.8893617021, "rate": 2.14048806795, "html": 71.1928251121, "arduous": 98.0, "media": 2.59369384088, "acquisit": 10.3764705882, "ani": 1.13383802314, "question": 2.20408163265, "divid": 2.3169877408099997, "talli": 31.437623762399998, "from": 1.00056721497, "answer": 4.64890190337, "allow": 1.2716059271100002, "work": 1.11520089913, "num": 1.00031504001, "veri": 1.25880114177, "churchil": 18.185567010299998, "aren": 481.09090909099996, "spam": 217.479452055, "obfusc": 182.482758621, "environ": 3.43561999567, "curv": 11.1098670399, "acquir": 3.10563380282, "for": 1.00031504001, "economi": 3.6446280991699997, "manipul": 9.145161290319999, "face": 1.80327124035, "creation": 3.0601387818, "releas": 1.8377126982299998, "sieradski": 1587.6, "competit": 3.06960556845, "zero": 8.75192943771, "determin": 2.1658935879900003, "topic": 5.457545548300001, "true": 2.55569864778, "better": 2.0065722952500002, "result": 1.14611608432, "frequent": 2.10501193317, "sheepl": 1587.6, "look": 1.9086318826599997, "spread": 2.8344938403900004, "bag": 15.8601398601, "kevin": 7.82068965517, "chanc": 4.2449197861000005, "fake": 18.290322580599998, "bar": 3.8854625550699997, "ratio": 7.21308496138, "think": 2.90715986083, "writer": 2.75816539263, "center": 1.7423178226499998, "combin": 1.69760479042, "percentag": 6.08275862069, "util": 4.65981802172, "reput": 4.06451612903, "column": 7.078020508250001, "though": 1.36076112111, "toward": 1.6303142329, "remov": 2.0058117498400003, "fight": 2.50370604006, "websit": 2.52160101652, "doe": 1.70581282905, "lowercas": 162.0, "could": 1.2043695949, "valid": 6.61224489796, "three": 1.06621893889, "probabl": 2.64555907349, "side": 1.5989525632, "train": 1.9365698950999999, "they": 1.03017325287, "bodi": 1.8618505922400002, "assumpt": 9.21951219512, "step": 2.8279301745599996, "error": 6.04109589041, "chart": 8.45367412141, "big": 2.7400759406299997, "type": 2.0281042411900003, "matter": 2.44773358002, "fals": 6.21613155834, "row": 5.549108703250001, "presid": 1.9842519685, "scientist": 4.69426374926, "machin": 4.02433460076, "action": 1.81855670103, "bias": 13.7335640138, "bloomberg": 42.563002681, "came": 1.46013059873, "sinc": 1.08368600683, "download": 14.6457564576, "presidenti": 6.325099601590001, "flag": 5.95275590551, "figur": 2.0343413634, "gave": 1.85121268657, "earlier": 1.86776470588, "choos": 4.17899447223, "meti": 352.8, "opportun": 3.0119521912400002, "clear": 1.85423966363, "find": 1.7294117647099998, "trump": 62.015625, "overlap": 12.0913937548, "borrow": 8.02223345124, "consider": 2.29920347574, "conclus": 4.84615384615, "even": 1.16461267606, "nor": 3.3479544496, "base": 1.14628158845, "relat": 1.23750876919, "label": 4.47715736041, "blather": 1587.6, "drawn": 4.6030733546, "who": 1.06279287723, "decid": 1.9257641921400002, "univers": 1.24889867841, "hot": 4.6178010471199995, "permiss": 6.280063291139999, "post": 2.23826307627, "here": 2.42307692308, "dispos": 10.4378698225, "lower": 2.10055570257, "upper": 3.41052631579, "were": 1.02458857696, "long": 1.2657259028899999, "realest": 1587.6, "surpris": 4.36633663366, "counter": 6.77592829706, "evalu": 6.9509632224199995, "than": 1.03278688525, "struggl": 3.36, "plus": 4.6914893617, "about": 1.06486015159, "problem": 1.76674827509, "intuit": 27.7068062827, "communiti": 1.96121062384, "francisco": 5.2937645882, "distinct": 2.2836593786000003, "daniel": 4.36994219653, "context": 4.25972632144, "kagglestyl": 1587.6, "entir": 1.59365589239, "lean": 16.729188619600002, "deeplearn": 1587.6, "conspiraci": 12.928338762200001, "correct": 3.6631287494199998, "standard": 1.8915763135900003, "dure": 1.0503473370799998, "posit": 1.37252528746, "classifi": 5.2937645882, "should": 1.6643254009900001, "contribut": 1.9255306246200001, "led": 1.33782758911, "across": 1.7318642958400001, "complex": 2.34021226415, "notion": 7.356811862839999, "categor": 15.0198675497, "reconfigur": 70.2477876106, "conclud": 3.02284843869, "articl": 2.01805008262, "deliber": 6.280063291139999, "singl": 1.60948905109, "them": 1.09876115994, "insight": 11.8037174721, "studi": 1.53184098804, "whi": 3.2566153846200003, "explain": 2.60049140049, "execut": 2.2363713199, "anyth": 4.58843930636, "georg": 1.8779276082299998, "quit": 2.8849718335500003, "abl": 1.8208510150200001, "mani": 1.04426757877, "data": 3.37643555934, "the": 1.0, "build": 1.6341739578, "wit": 4.386847195360001, "provid": 1.21552714187, "total": 1.5460122699399999, "journal": 2.36884512086, "freelanc": 61.0615384615, "tactic": 6.432739059969999, "order": 1.24625166811, "throughout": 1.5217099587799998, "show": 1.26703910615, "exact": 3.46864758575, "there": 1.04091266719, "surpass": 10.1185468451, "valu": 2.2777618364400003, "wide": 1.5598349381, "matrix": 22.6153846154, "cross": 2.33127753304, "possibl": 1.4173734488, "way": 1.2190739461, "nonetheless": 7.875, "best": 1.5828514456600002, "origin": 1.13724928367, "right": 1.4054532577899999, "trade": 2.37522441652, "recal": 5.30614973262, "appear": 1.3214582986499999, "mislead": 22.6153846154, "textbas": 1587.6, "take": 1.13961668222, "now": 1.160780873, "might": 2.1561863370900003, "untru": 94.5, "name": 1.10211732037, "see": 1.27242125511, "high": 1.14777327935, "publish": 1.36885669943, "power": 1.3396337861799998, "suppos": 4.23021582734, "issu": 1.43921675279, "tutori": 59.4606741573, "coupl": 3.2572835453400004, "versa": 23.381443299, "hypothesi": 13.580838323399998, "mean": 1.44906900329, "widget": 337.787234043, "user": 7.71053909665, "seven": 1.93940874664, "compris": 3.8599562363199995, "shape": 3.20338983051, "york": 1.53361669243, "research": 1.9420183486200002, "plan": 1.5356935577500002, "signific": 1.4529147982100001, "etc\u2026": 1587.6, "wherea": 4.13868613139, "challeng": 2.55816951337, "six": 1.5552507837, "promin": 2.39746300211, "want": 1.99698113208, "propag": 18.8104265403, "text": 3.12827586207, "into": 1.01502461479, "ripe": 72.16363636359999, "gatherwrangl": 1587.6, "extens": 1.99171998495, "howev": 1.0945191313299998, "share": 1.8566249561500001, "san": 3.30131004367, "week": 1.80532181033, "which": 1.005191845, "random": 7.1902173913, "tfidfvector": 1587.6, "term": 1.39520168732, "bewar": 131.20661157, "thus": 1.6463756092500001, "falsehood": 108.739726027, "other": 1.00992366412, "techniqu": 3.7293868921800004, "twoword": 1587.6, "one": 1.00627495722, "graph": 37.7102137767, "second": 1.1130898128, "terminolog": 17.6989966555, "prefer": 3.0216977540900003, "full": 1.66729678639, "routin": 7.997984886649999, "margin": 6.16783216783, "becaus": 1.1495184997499999, "facebook": 28.5539568345, "four": 1.20950784702, "corpus": 24.091047041, "get": 1.78562591385, "winston": 16.8, "like": 1.14918566775, "implement": 3.57648118946, "beg": 21.541383989099998, "manag": 1.6448404475799998, "select": 2.02345144022, "collect": 1.64109985528, "dilemma": 27.9507042254, "opinion": 3.8044572250199997, "detect": 5.41288782816, "part": 1.04330682789, "attempt": 1.4721810088999998, "baffl": 90.2045454545, "rare": 2.7259615384599996, "outlin": 6.38102893891, "includ": 1.0190641247799999, "abort": 13.627467811199999, "tabl": 3.82093862816, "straightforward": 27.7552447552, "scikit": 1587.6, "grid": 18.1232876712, "phrase": 6.18465134398, "this": 1.00379362671, "pretti": 15.75, "decent": 35.5964125561, "time": 1.01127460348, "api": 84.44680851060001, "process": 1.69524826482, "chang": 1.1808985421, "similar": 1.37514075357, "project": 1.7534791252500002, "differ": 1.23654490225, "decis": 2.16, "profession": 2.6389627659599997, "mcintir": 661.5, "halfway": 26.862944162399998, "valuabl": 7.46754468485, "most": 1.02096463023, "between": 1.03453668708, "everi": 1.47917637194, "certain": 1.8077886586200003, "excel": 4.84467500763, "obvious": 6.44841592201, "fail": 1.9281029876099998, "all": 1.01146788991, "top": 1.8387769284200002, "headlin": 12.9705882353, "mix": 2.7852631578900002, "school": 1.64008264463, "chemtrail": 1587.6, "reason": 1.72340425532, "countvector": 1587.6, "proposit": 21.9281767956, "combat": 5.01294600568, "intercept": 15.8285144566, "case": 1.48498737256, "produc": 1.36932896326, "hybrid": 12.630071599, "that": 1.00398406375, "pair": 4.36873968079, "subject": 1.8715077213299998, "twenti": 5.1562195518000005, "call": 1.0676529926, "cycl": 5.40919931857, "off": 1.5121440137200002, "more": 1.0171706817, "and": 1.00006299213, "while": 1.0441988950299999, "dedic": 3.20533010297, "novel": 4.06555697823, "these": 1.07415426252, "stanford": 12.6, "jone": 4.97368421053, "tzrwu": 1587.6, "amount": 2.27027027027, "made": 1.07038834951, "nnumber": 1587.6, "night": 2.26670474015, "befor": 1.10036041031, "cynic": 36.3295194508, "point": 1.25990000794, "crossvalid": 1587.6, "detector": 45.6206896552, "stori": 2.02396736359, "can": 1.17626139142, "make": 1.0762660158600001, "set": 1.18707940781, "kaggl": 1587.6, "search": 3.2539454806299997, "onli": 1.0256476516600002, "each": 1.18974820144, "promot": 2.0172808132099997, "half": 1.75813953488, "are": 1.02990593578, "thing": 2.4065484311099996, "accur": 5.768895348840001, "rise": 2.02940048575, "unfamiliar": 37.7102137767, "two": 1.01379310345, "remain": 1.16598119859, "common": 1.4025974025999999, "imposs": 4.96125, "pundit": 71.8371040724, "block": 3.20274359492, "qualiti": 2.9329392204, "address": 2.86157173756, "prevent": 2.16117615029, "method": 2.5714285714300003, "factual": 37.8, "murkier": 1587.6, "repres": 1.46972782818, "bio": 42.336000000000006, "come": 1.32831325301, "abstract": 9.966101694919999, "exampl": 1.50483412322, "chrome": 65.6033057851, "learn": 2.32275054865, "identifi": 2.30187037843, "differenti": 7.759530791789999, "import": 1.3401992233700002, "first": 1.00761614623, "game": 2.57978550536, "cover": 1.69380134429, "tfidf": 1587.6, "use": 1.0296387573799999, "tool": 4.99716713881, "score": 4.2884927066500005, "social": 1.9904714142400002, "host": 2.7092150170599996, "often": 1.29452054795, "infowar": 1587.6, "bay": 4.629921259840001, "inde": 4.43092380687, "same": 1.11857958148, "mention": 2.53894130817, "effici": 5.09335899904}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Machine Learning Finds \u201cFake News\u201d with 88% Accuracy</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Machine Learning Finds \u201cFake News\u201d with 88% Accuracy Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/n14.html\" rel=\"prev\" title=\"KDnuggets\u2122 News 17:n14, Apr 12: Free Machine Learning &amp; Data Science Books; Top Machine Learning &amp; Deep Learning Papers\"/>\n<link href=\"https://www.kdnuggets.com/jobs/17/04-12-world-food-programme-data-scientist.html\" rel=\"next\" title=\"World Food Programme: Data Scientist\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=65112\" rel=\"shortlink\"/>\n<link href=\"https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-65112 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 12-Apr, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Machine Learning Finds \u201cFake News\u201d with 88% Accuracy (\u00a0<a href=\"/2017/n14.html\">17:n14</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Machine Learning Finds \u201cFake News\u201d with 88% Accuracy</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/n14.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/17/04-12-world-food-programme-data-scientist.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/data-science\" rel=\"tag\">Data Science</a>, <a href=\"https://www.kdnuggets.com/tag/fake-news\" rel=\"tag\">Fake News</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a>, <a href=\"https://www.kdnuggets.com/tag/naive-bayes\" rel=\"tag\">Naive Bayes</a>, <a href=\"https://www.kdnuggets.com/tag/politics\" rel=\"tag\">Politics</a>, <a href=\"https://www.kdnuggets.com/tag/text-analytics\" rel=\"tag\">Text Analytics</a></div>\n<br/>\n<p class=\"excerpt\">\n     In this post, the author assembles a dataset of fake and real news and employs a Naive Bayes classifier in order to create a model to classify an article as fake or real based on its words and phrases.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By George McIntire, Contributing Data Science Writer, ODSC</b></p>\n<p><img alt=\"Donald Trump\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/fakenews-trump.jpg\" width=\"90%\"/></p>\n<blockquote>\n<h3>\u201cA lie gets halfway around the world before the truth has a chance to get its pants on.\u201d</h3>\n<p>\u2013\u00a0Winston Churchill\n</p></blockquote>\n<p>Since the 2016 presidential election, one topic dominating political discourse is the issue of \u201cFake News\u201d.\u00a0A number of political pundits\u00a0claim that the rise of significantly biased and/or untrue news influenced the election, though\u00a0a\u00a0<a href=\"http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study\" target=\"_blank\">study by researchers</a> from Stanford and New York University concluded otherwise. Nonetheless,\u00a0fake news posts have exploited\u00a0Facebook users\u2019 feeds to propagate throughout the internet.</p>\n<p><b><strong>\u201cWhat is fake news?\u201d</strong></b></p>\n<p>Obviously, a deliberately misleading story is \u201cfake news\u201d but lately blathering social media discourse, \u00a0is changing\u00a0its definition. Some now use the term to dismiss facts counter to their preferred viewpoints, the most prominent example being <a href=\"https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&amp;src=typd\" target=\"_blank\">President Trump</a>. Such a vaguely-defined term is ripe for a cynical manipulation.</p>\n<p>The data science community has responded by\u00a0<a href=\"https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/\" target=\"_blank\">taking action to fight the problem</a>. There\u2019s a Kaggle-style competition called the \u201c<a href=\"http://www.fakenewschallenge.org/\" target=\"_blank\">Fake News Challenge</a>\u201d\u00a0and <a href=\"https://techcrunch.com/2016/11/14/facebook-fake-news/\" target=\"_blank\">Facebook is employing AI</a>\u00a0to filter fake news stories out of users\u2019 feeds. Combating fake news is a classic text classification project with a straight-forward proposition: <strong><em>Can you build a model that can differentiate between \u201cReal\u201d news vs \u201cFake\u201d news.</em></strong></p>\n<p>And that\u2019s exactly what\u00a0I attempted to do for this project. I assembled a dataset of fake and real news and\u00a0employed a Naive\u00a0Bayes classifier in order to create a model to classify an article as fake or real based on its words and phrases.</p>\n<h3>Data Gather/Wrangling</h3>\n<p>\u00a0<br>\nThere were two parts to the data acquisition\u00a0process, getting the \u201cfake news\u201d and getting the real news. The first part was quick,\u00a0Kaggle released a\u00a0<a href=\"https://www.kaggle.com/mrisdal/fake-news\" target=\"_blank\">fake news dataset</a> comprising of 13,000 articles published during the 2016 election cycle.</br></p>\n<p>The second part was\u2026 a lot more difficult. \u00a0To acquire the real news side of the dataset, I turned to <a href=\"http://www.allsides.com/\" target=\"_blank\">All Sides</a>, a website dedicated to hosting news and opinion articles from across the political spectrum. Articles on the website are categorized by topic (environment, economy, abortion, etc\u2026) and by political leaning (left, center, and right).\u00a0I used\u00a0All Sides because it was the best way\u00a0to web scrape thousands of articles from numerous media outlets of differing\u00a0biases. Plus, it allowed to me download the full text of an article, something you cannot do with the New York Times and NPR APIs. After a long and arduous process I ended up scraping a total of <strong>5279 articles</strong>. The articles in my real news dataset came from\u00a0media organizations such as the New York Times, WSJ, Bloomberg, NPR, and the Guardian\u00a0and\u00a0were published in\u00a02015 or\u00a02016.</p>\n<p>I decided to construct my full dataset with equal parts\u00a0fake and real articles, thus making my model\u2019s null accuracy 50%. I randomly selected 5279 articles from my fake news dataset to use in my complete dataset and left the remaining articles to be used as a testing set when my model was complete.</p>\n<p>My finalized dataset was comprised of 10558 total articles with their headlines and full body text and their labels (real vs fake). The data is located here in this <a href=\"https://github.com/GeorgeMcIntire/fake_real_news_dataset\" target=\"_blank\">github repo</a>.</p>\n<h3>Purpose and Expectations</h3>\n<p>\u00a0<br>\nWhen I first started this project, I\u00a0conceded that this would not be the perfect project. The purpose of this project was to see how far I could get in creating a fake news classification and what insights could be drawn from that, then used towards a better model. My game plan was to treat this project the same way as a routine spam detection project.</br></p>\n<p>Building a model based on a count vectorizer (using word tallies) or a tfidf matrix (word tallies relative to how often they\u2019re used in other articles in your dataset) can only get you so far. These methods\u00a0do not consider important qualities\u00a0like the word ordering\u00a0and context. It\u2019s very possible for two articles\u00a0that are similar in their word counts to be totally different in their meaning. I did not expect my model to be adept at handling\u00a0fake and real articles\u00a0whose words and phrases overlap. Nonetheless, I expect some valuable insights to come from this project.</p>\n<h3>Modeling</h3>\n<p>\u00a0<br>\nSince this is a text classification project, I only used a Naive Bayes classifier as is standard for text-based data science projects.</br></p>\n<p>The real work in formulating a model was the text transformation\u00a0(count vectorizer vs tfidf vectorizer) and choosing which type of text to use (headlines vs full text). This gave me four pairs of reconfigured datasets to work with.</p>\n<p>The next step was to determine the most optimal parameters for either a countvectorizer or tfidf-vectorizer. For those of you who are unfamiliar with text machine learning, this means using a n-number of the most common words, using\u00a0words and/or phrases, lower casing or not, removing stop words (common words such as the,\u00a0when, and there) and only using words that appear at\u00a0least a given number of times in\u00a0a\u00a0text corpus (a term for a text dataset or a collection of texts).</p>\n<p>To test the performance of multiple parameters and their numerous combinations, I utilized the Sci-kit Learn\u2019s GridSearch functionality to efficiently execute this task. To learn more about how to\u00a0perfect your algorithm parameters, please review <a href=\"http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\" target=\"_blank\">this tutorial</a>.</p>\n<p>After the grid search\u00a0cross validation process, I\u00a0found that\u00a0my model worked best with\u00a0a\u00a0count vectorizer instead of a tfidf and produced higher scores when\u00a0trained on the full text of articles instead of their headlines.\u00a0The optimal parameters for\u00a0count vectorizer are no lowercasing, two-word phrases not single words, and\u00a0to only use words that appear at least three times in the corpus.</p>\n<p>Given my expectations that I outlined earlier in this post, I was surprised and almost baffled at the high scores\u00a0my model produced.\u00a0My model\u2019s cross-validated accuracy score is 91.7%, recall (true positive rate) score is\u00a092.6%, and its AUC score is 95%.</p>\n<p>Here is the ROC Curve for my model.</p>\n<p><a href=\"https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png\" target=\"_blank\"><img alt=\"ROC Curve\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png\" width=\"90%\"/></a></p>\n<p>If I\u00a0were to decide on a threshold for a model based on this graph, I would choose one that produces a FPR at around 0.08 and a TPR at around 0.90, because at that point in the graph the trade off between false positives and true positives is equal.</p>\n<h3>Results &amp; Conclusion</h3>\n<p>\u00a0<br>\nThe true test of my model\u2019s quality would be to see how fake news articles in the test set (those not used in the creation of my model) it could accurately classify.</br></p>\n<p><strong>Out of the 5234 articles left in the other fake news datasets, my model was able to correctly identify 88.2% of them as fake.</strong> This is 3.5 percentage points lower than my cross-validated accuracy score, but in my opinion it is pretty decent evaluation of my model.</p>\n<p>It turns out that my hypothesis\u00a0predicting that model would\u00a0struggle at classifying news articles was quite wrong. I\u00a0thought that an accuracy score in the upper 60s or lower 70s would be\u00a0excellent and I managed to surpass that by a significant margin.</p>\n<p>Even though I created what appears to be a pretty good model given the complexity of the task, I am not entirely convinced that it is as good as it appears to be and here\u2019s why.</p>\n<p>To be better understand why this might have happened, let\u2019s take a look at the \u201cfakest\u201d and \u201crealest\u201d words in the data\u2014I\u2019ll explain what I mean by that.</p>\n<p>Using a technique I borrowed from Kevin Markham of Data School, here\u2019s how I derived the \u201cfakest\u201d and \u201crealest\u201d words in the corpus. First I started off with a table two columns wide\u00a0and\u00a010558 rows long (that\u2019s how many words there are in the corpus). The first column represented how many times a given word appeared in articles classified as \u201cFAKE\u201d and the second column was how many times a word\u00a0appeared in a \u201cREAL\u201d article. \u00a0Then I divided\u00a0the fake column by the total number of fake articles my model classified and\u00a0so on for the real column.\u00a0Next, I added the number one to every value in the data because I created a new column of \u201cFake:Real\u201d ratios and didn\u2019t want to get an error by dividing zero. This \u201cFake:Real\u201d is a pretty good but by no means perfect metric of just how \u201cfake\u201d or \u201creal a certain word. The\u00a0logic is pretty simple, if a word shows up a bunch in \u201cfake\u201d articles and rarely in \u201creal\u201d articles then\u00a0its fake to real ratio score will be pretty high.</p>\n<p>Here are the top 20 \u201cfakest\u201d and \u201crealest\u201d words in my dataset.</p>\n<p><a href=\"https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png\" target=\"_blank\"><img alt=\"Fakest\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png\" width=\"90%\"/></a></p>\n<p><a href=\"https://opendatascience.com/wp-content/uploads/2017/02/realwords.png\" target=\"_blank\"><img alt=\"Realest\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/realwords.png\" width=\"90%\"/></a></p>\n<p>These two graphics exhibit some baffling results. The words in the \u201cfake\u201d chart are a mixed bag that includes some\u00a0typical internet\u00a0terminology such as PLEASE, Share, Posted, html, and Widget\u00a0and words that aren\u2019t even words such as tzrwu.\u00a0However I was not surprised to see infowars mentioned nor terms like \u201cSheeple\u201d or \u201cUFO\u201d make it in the top 20 \u201cfakest\u201d words. Infowars is a right-wing conspiracy-laden outlet led by Alex Jones that promotes conspiracy theories about chemtrails and 9/11.</p>\n<p>The \u201creal\u201d chart\u00a0is dominated by names and politicians and words frequently used in political articles, comprising 60% of the bars in the chart. Seven of the twenty terms, including four of the top six,\u00a0are politician names. This begs the question,\u00a0are articles\u00a0about politicians more likely to be true? No of course not, if anything you\u2019d expect there to be numerous fake news articles\u00a0spreading falsehoods\u00a0about politicians. I would be committing a huge error if I came to the conclusion that articles mentioning\u00a0politicians are more likely to be to factual.</p>\n<p>One big assumption\u00a0underlying this project is that there is considerable overlap in the topics covered by each class of article. As we witnessed above, just because a certain word\u00a0shows up more often in \u201creal\u201d news than\u00a0\u201cfake\u201d news it doesn\u2019t mean that articles with those terms are guaranteed to be \u201creal\u201d, but instead could just mean that those words are used in topics more common in the real news dataset and vice versa for the fake news dataset.</p>\n<p>I\u00a0and another party had a considerable amount of influence in shaping\u00a0this dataset. I made the decision on which articles to use for the \u201creal\u201d dataset.\u00a0The articles in the \u201cfake\u201d\u00a0dataset were determined by a\u00a0<a href=\"https://github.com/selfagency/bs-detector\" target=\"_blank\">chrome extension called \u201cBS Detector\u201d</a>\u00a0made by Daniel Sieradski. There is a\u00a0significantly high\u00a0amount of subjectivity going into determining what is and what isn\u2019t \u201cfake news\u201d. The reason why politician names are\u00a0rated\u00a0as \u201creal\u201d so highly is\u00a0most likely because that half of the corpura\u00a0disproportionately comes\u00a0from political news. In addition, I did find a couple of articles from what I find to be reputable sources of news. One such article came from The Intercept, a news organization\u00a0with high journalism standards. And yes, my model did indeed flag this supposed \u201cfake news\u201d article as real.</p>\n<p>To make\u00a0matters even more complicated,\u00a0we have to decide how to set the threshold probability for our model. If I was a data scientist at Facebook tasked with implementing a model that sorts out real and fake news in users\u2019 feeds, I\u2019d be faced with\u00a0the dilemma between choosing a model that blocks all or most fake news and some real news or a model that allows all or most real news and some fake news. But before I make that decision, I need\u00a0to figure\u00a0what is the cost of failing to prevent fake news vs the cost of blocking real news? How does\u00a0one attempt to answer such an abstract question? Unless we can train a model with a 100% true positive rate and 0% false positive rate, we\u2019ll be stuck with this quandary.</p>\n<p>In conclusion, while I think that a standard Naive Bayes text classification model can provide insight into addressing this issue,\u00a0a more powerful deep-learning tool should be employed to combat fake news in a professional setting.</p>\n<p>Classifying \u201cfake news\u201d provides a novel challenge to the data science community. \u00a0In many machine learning projects, the distinction between the different classes you want to predict is clear, whereas it\u2019s a lot murkier in this case. This\u00a0project validates the notion in data science\u00a0that intuition and intimacy with your data is just as or more important than any model or tool at your disposal.</p>\n<p><b>Bio: <a href=\"https://opendatascience.com/author/george-mcintire/\" target=\"_blank\">George McIntire</a></b> is a journalist turned data scientist/journalist hybrid. Looking for opportunities in data science and/or journalism. Impossibly curious and passionate about learning new things. Before completing the Metis Data Science Bootcamp, he worked as a freelance journalist in San Francisco for Vice, Salon, SF Weekly, San Francisco Magazine, and more.</p>\n<p><a href=\"https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/03/getting-hot-here-data-science-vs-fake-news.html\">It\u2019s Getting Hot In Here: Data Science vs Fake News</a>\n<li><a href=\"/2017/03/last-night-sweden-data-science-vs-fake-news.html\">What Happened Last Night in Sweden: Data Science vs Fake News</a>\n<li><a href=\"/2017/04/beware-two-data-obfuscation-tactics.html\">Beware of Two Data Obfuscation Tactics</a>\n</li></li></li></ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/n14.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/17/04-12-world-food-programme-data-scientist.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Machine Learning Finds \u201cFake News\u201d with 88% Accuracy (\u00a0<a href=\"/2017/n14.html\">17:n14</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556349739\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.695 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 03:22:19 -->\n<!-- Compression = gzip -->", "content_tokenized": ["georg", "mcintir", "contribut", "data", "scienc", "writer", "lie", "get", "halfway", "around", "the", "world", "befor", "the", "truth", "has", "chanc", "get", "pant", "winston", "churchil", "sinc", "the", "num", "presidenti", "elect", "one", "topic", "domin", "polit", "discours", "the", "issu", "fake", "news", "number", "polit", "pundit", "claim", "that", "the", "rise", "signific", "bias", "andor", "untru", "news", "influenc", "the", "elect", "though", "studi", "research", "from", "stanford", "and", "new", "york", "univers", "conclud", "otherwis", "nonetheless", "fake", "news", "post", "have", "exploit", "facebook", "user", "feed", "propag", "throughout", "the", "internet", "what", "fake", "news", "obvious", "deliber", "mislead", "stori", "fake", "news", "but", "late", "blather", "social", "media", "discours", "chang", "definit", "some", "now", "use", "the", "term", "dismiss", "fact", "counter", "their", "prefer", "viewpoint", "the", "most", "promin", "exampl", "presid", "trump", "such", "vaguelydefin", "term", "ripe", "for", "cynic", "manipul", "the", "data", "scienc", "communiti", "has", "respond", "take", "action", "fight", "the", "problem", "there", "kagglestyl", "competit", "call", "the", "fake", "news", "challeng", "and", "facebook", "employ", "filter", "fake", "news", "stori", "out", "user", "feed", "combat", "fake", "news", "classic", "text", "classif", "project", "with", "straightforward", "proposit", "can", "build", "model", "that", "can", "differenti", "between", "real", "news", "fake", "news", "and", "that", "exact", "what", "attempt", "for", "this", "project", "assembl", "dataset", "fake", "and", "real", "news", "and", "employ", "naiv", "bay", "classifi", "order", "creat", "model", "classifi", "articl", "fake", "real", "base", "word", "and", "phrase", "data", "gatherwrangl", "there", "were", "two", "part", "the", "data", "acquisit", "process", "get", "the", "fake", "news", "and", "get", "the", "real", "news", "the", "first", "part", "quick", "kaggl", "releas", "fake", "news", "dataset", "compris", "num", "articl", "publish", "dure", "the", "num", "elect", "cycl", "the", "second", "part", "was\u2026", "lot", "more", "difficult", "acquir", "the", "real", "news", "side", "the", "dataset", "turn", "all", "side", "websit", "dedic", "host", "news", "and", "opinion", "articl", "from", "across", "the", "polit", "spectrum", "articl", "the", "websit", "are", "categor", "topic", "environ", "economi", "abort", "etc\u2026", "and", "polit", "lean", "left", "center", "and", "right", "use", "all", "side", "becaus", "the", "best", "way", "web", "scrape", "thousand", "articl", "from", "numer", "media", "outlet", "differ", "bias", "plus", "allow", "download", "the", "full", "text", "articl", "someth", "can", "not", "with", "the", "new", "york", "time", "and", "api", "after", "long", "and", "arduous", "process", "end", "scrape", "total", "num", "articl", "the", "articl", "real", "news", "dataset", "came", "from", "media", "organ", "such", "the", "new", "york", "time", "bloomberg", "and", "the", "guardian", "and", "were", "publish", "num", "num", "decid", "construct", "full", "dataset", "with", "equal", "part", "fake", "and", "real", "articl", "thus", "make", "model", "null", "accuraci", "num", "random", "select", "num", "articl", "from", "fake", "news", "dataset", "use", "complet", "dataset", "and", "left", "the", "remain", "articl", "use", "test", "set", "when", "model", "complet", "final", "dataset", "compris", "num", "total", "articl", "with", "their", "headlin", "and", "full", "bodi", "text", "and", "their", "label", "real", "fake", "the", "data", "locat", "here", "this", "github", "repo", "purpos", "and", "expect", "when", "first", "start", "this", "project", "conced", "that", "this", "would", "not", "the", "perfect", "project", "the", "purpos", "this", "project", "see", "how", "far", "could", "get", "creat", "fake", "news", "classif", "and", "what", "insight", "could", "drawn", "from", "that", "then", "use", "toward", "better", "model", "game", "plan", "treat", "this", "project", "the", "same", "way", "routin", "spam", "detect", "project", "build", "model", "base", "count", "vector", "use", "word", "talli", "tfidf", "matrix", "word", "talli", "relat", "how", "often", "they", "use", "other", "articl", "dataset", "can", "onli", "get", "far", "these", "method", "not", "consid", "import", "qualiti", "like", "the", "word", "order", "and", "context", "veri", "possibl", "for", "two", "articl", "that", "are", "similar", "their", "word", "count", "total", "differ", "their", "mean", "not", "expect", "model", "adept", "handl", "fake", "and", "real", "articl", "whose", "word", "and", "phrase", "overlap", "nonetheless", "expect", "some", "valuabl", "insight", "come", "from", "this", "project", "model", "sinc", "this", "text", "classif", "project", "onli", "use", "naiv", "bay", "classifi", "standard", "for", "textbas", "data", "scienc", "project", "the", "real", "work", "formul", "model", "the", "text", "transform", "count", "vector", "tfidf", "vector", "and", "choos", "which", "type", "text", "use", "headlin", "full", "text", "this", "gave", "four", "pair", "reconfigur", "dataset", "work", "with", "the", "next", "step", "determin", "the", "most", "optim", "paramet", "for", "either", "countvector", "tfidfvector", "for", "those", "who", "are", "unfamiliar", "with", "text", "machin", "learn", "this", "mean", "use", "nnumber", "the", "most", "common", "word", "use", "word", "andor", "phrase", "lower", "case", "not", "remov", "stop", "word", "common", "word", "such", "the", "when", "and", "there", "and", "onli", "use", "word", "that", "appear", "least", "given", "number", "time", "text", "corpus", "term", "for", "text", "dataset", "collect", "text", "test", "the", "perform", "multipl", "paramet", "and", "their", "numer", "combin", "util", "the", "scikit", "learn", "gridsearch", "function", "effici", "execut", "this", "task", "learn", "more", "about", "how", "perfect", "algorithm", "paramet", "pleas", "review", "this", "tutori", "after", "the", "grid", "search", "cross", "valid", "process", "found", "that", "model", "work", "best", "with", "count", "vector", "instead", "tfidf", "and", "produc", "higher", "score", "when", "train", "the", "full", "text", "articl", "instead", "their", "headlin", "the", "optim", "paramet", "for", "count", "vector", "are", "lowercas", "twoword", "phrase", "not", "singl", "word", "and", "onli", "use", "word", "that", "appear", "least", "three", "time", "the", "corpus", "given", "expect", "that", "outlin", "earlier", "this", "post", "surpris", "and", "almost", "baffl", "the", "high", "score", "model", "produc", "model", "crossvalid", "accuraci", "score", "num", "recal", "true", "posit", "rate", "score", "num", "and", "score", "num", "here", "the", "curv", "for", "model", "were", "decid", "threshold", "for", "model", "base", "this", "graph", "would", "choos", "one", "that", "produc", "around", "num", "and", "around", "num", "becaus", "that", "point", "the", "graph", "the", "trade", "off", "between", "fals", "posit", "and", "true", "posit", "equal", "result", "conclus", "the", "true", "test", "model", "qualiti", "would", "see", "how", "fake", "news", "articl", "the", "test", "set", "those", "not", "use", "the", "creation", "model", "could", "accur", "classifi", "out", "the", "num", "articl", "left", "the", "other", "fake", "news", "dataset", "model", "abl", "correct", "identifi", "num", "them", "fake", "this", "num", "percentag", "point", "lower", "than", "crossvalid", "accuraci", "score", "but", "opinion", "pretti", "decent", "evalu", "model", "turn", "out", "that", "hypothesi", "predict", "that", "model", "would", "struggl", "classifi", "news", "articl", "quit", "wrong", "thought", "that", "accuraci", "score", "the", "upper", "num", "lower", "num", "would", "excel", "and", "manag", "surpass", "that", "signific", "margin", "even", "though", "creat", "what", "appear", "pretti", "good", "model", "given", "the", "complex", "the", "task", "not", "entir", "convinc", "that", "good", "appear", "and", "here", "whi", "better", "understand", "whi", "this", "might", "have", "happen", "let", "take", "look", "the", "fakest", "and", "realest", "word", "the", "data\u2014i", "explain", "what", "mean", "that", "use", "techniqu", "borrow", "from", "kevin", "markham", "data", "school", "here", "how", "deriv", "the", "fakest", "and", "realest", "word", "the", "corpus", "first", "start", "off", "with", "tabl", "two", "column", "wide", "and", "num", "row", "long", "that", "how", "mani", "word", "there", "are", "the", "corpus", "the", "first", "column", "repres", "how", "mani", "time", "given", "word", "appear", "articl", "classifi", "and", "the", "second", "column", "how", "mani", "time", "word", "appear", "articl", "then", "divid", "the", "fake", "column", "the", "total", "number", "fake", "articl", "model", "classifi", "and", "for", "the", "real", "column", "next", "the", "number", "one", "everi", "valu", "the", "data", "becaus", "creat", "new", "column", "fake", "real", "ratio", "and", "want", "get", "error", "divid", "zero", "this", "fake", "real", "pretti", "good", "but", "mean", "perfect", "metric", "just", "how", "fake", "real", "certain", "word", "the", "logic", "pretti", "simpl", "word", "show", "bunch", "fake", "articl", "and", "rare", "real", "articl", "then", "fake", "real", "ratio", "score", "will", "pretti", "high", "here", "are", "the", "top", "num", "fakest", "and", "realest", "word", "dataset", "these", "two", "graphic", "exhibit", "some", "baffl", "result", "the", "word", "the", "fake", "chart", "are", "mix", "bag", "that", "includ", "some", "typic", "internet", "terminolog", "such", "share", "post", "html", "and", "widget", "and", "word", "that", "aren", "even", "word", "such", "tzrwu", "howev", "not", "surpris", "see", "infowar", "mention", "nor", "term", "like", "sheepl", "make", "the", "top", "num", "fakest", "word", "infowar", "rightw", "conspiracyladen", "outlet", "led", "alex", "jone", "that", "promot", "conspiraci", "theori", "about", "chemtrail", "and", "num", "the", "real", "chart", "domin", "name", "and", "politician", "and", "word", "frequent", "use", "polit", "articl", "compris", "num", "the", "bar", "the", "chart", "seven", "the", "twenti", "term", "includ", "four", "the", "top", "six", "are", "politician", "name", "this", "beg", "the", "question", "are", "articl", "about", "politician", "more", "like", "true", "cours", "not", "anyth", "expect", "there", "numer", "fake", "news", "articl", "spread", "falsehood", "about", "politician", "would", "commit", "huge", "error", "came", "the", "conclus", "that", "articl", "mention", "politician", "are", "more", "like", "factual", "one", "big", "assumpt", "under", "this", "project", "that", "there", "consider", "overlap", "the", "topic", "cover", "each", "class", "articl", "wit", "abov", "just", "becaus", "certain", "word", "show", "more", "often", "real", "news", "than", "fake", "news", "mean", "that", "articl", "with", "those", "term", "are", "guarante", "real", "but", "instead", "could", "just", "mean", "that", "those", "word", "are", "use", "topic", "more", "common", "the", "real", "news", "dataset", "and", "vice", "versa", "for", "the", "fake", "news", "dataset", "and", "anoth", "parti", "had", "consider", "amount", "influenc", "shape", "this", "dataset", "made", "the", "decis", "which", "articl", "use", "for", "the", "real", "dataset", "the", "articl", "the", "fake", "dataset", "were", "determin", "chrome", "extens", "call", "detector", "made", "daniel", "sieradski", "there", "signific", "high", "amount", "subject", "into", "determin", "what", "and", "what", "fake", "news", "the", "reason", "whi", "politician", "name", "are", "rate", "real", "high", "most", "like", "becaus", "that", "half", "the", "corpura", "disproportion", "come", "from", "polit", "news", "addit", "find", "coupl", "articl", "from", "what", "find", "reput", "sourc", "news", "one", "such", "articl", "came", "from", "the", "intercept", "news", "organ", "with", "high", "journal", "standard", "and", "yes", "model", "inde", "flag", "this", "suppos", "fake", "news", "articl", "real", "make", "matter", "even", "more", "complic", "have", "decid", "how", "set", "the", "threshold", "probabl", "for", "our", "model", "data", "scientist", "facebook", "task", "with", "implement", "model", "that", "sort", "out", "real", "and", "fake", "news", "user", "feed", "face", "with", "the", "dilemma", "between", "choos", "model", "that", "block", "all", "most", "fake", "news", "and", "some", "real", "news", "model", "that", "allow", "all", "most", "real", "news", "and", "some", "fake", "news", "but", "befor", "make", "that", "decis", "need", "figur", "what", "the", "cost", "fail", "prevent", "fake", "news", "the", "cost", "block", "real", "news", "how", "doe", "one", "attempt", "answer", "such", "abstract", "question", "unless", "can", "train", "model", "with", "num", "true", "posit", "rate", "and", "num", "fals", "posit", "rate", "stuck", "with", "this", "quandari", "conclus", "while", "think", "that", "standard", "naiv", "bay", "text", "classif", "model", "can", "provid", "insight", "into", "address", "this", "issu", "more", "power", "deeplearn", "tool", "should", "employ", "combat", "fake", "news", "profession", "set", "classifi", "fake", "news", "provid", "novel", "challeng", "the", "data", "scienc", "communiti", "mani", "machin", "learn", "project", "the", "distinct", "between", "the", "differ", "class", "want", "predict", "clear", "wherea", "lot", "murkier", "this", "case", "this", "project", "valid", "the", "notion", "data", "scienc", "that", "intuit", "and", "intimaci", "with", "data", "just", "more", "import", "than", "ani", "model", "tool", "dispos", "bio", "georg", "mcintir", "journalist", "turn", "data", "scientistjournalist", "hybrid", "look", "for", "opportun", "data", "scienc", "andor", "journal", "imposs", "curious", "and", "passion", "about", "learn", "new", "thing", "befor", "complet", "the", "meti", "data", "scienc", "bootcamp", "work", "freelanc", "journalist", "san", "francisco", "for", "vice", "salon", "week", "san", "francisco", "magazin", "and", "more", "origin", "repost", "with", "permiss", "relat", "get", "hot", "here", "data", "scienc", "fake", "news", "what", "happen", "last", "night", "sweden", "data", "scienc", "fake", "news", "bewar", "two", "data", "obfusc", "tactic"], "timestamp_scraper": 1556367431.138721, "title": "Machine Learning Finds \u201cFake News\u201d with 88% Accuracy", "read_time": 617.4, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By George McIntire, Contributing Data Science Writer, ODSC</b></p>\n<p><img alt=\"Donald Trump\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/fakenews-trump.jpg\" width=\"90%\"/></p>\n<blockquote>\n<h3>\u201cA lie gets halfway around the world before the truth has a chance to get its pants on.\u201d</h3>\n<p>\u2013\u00a0Winston Churchill\n</p></blockquote>\n<p>Since the 2016 presidential election, one topic dominating political discourse is the issue of \u201cFake News\u201d.\u00a0A number of political pundits\u00a0claim that the rise of significantly biased and/or untrue news influenced the election, though\u00a0a\u00a0<a href=\"http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study\" target=\"_blank\">study by researchers</a> from Stanford and New York University concluded otherwise. Nonetheless,\u00a0fake news posts have exploited\u00a0Facebook users\u2019 feeds to propagate throughout the internet.</p>\n<p><b><strong>\u201cWhat is fake news?\u201d</strong></b></p>\n<p>Obviously, a deliberately misleading story is \u201cfake news\u201d but lately blathering social media discourse, \u00a0is changing\u00a0its definition. Some now use the term to dismiss facts counter to their preferred viewpoints, the most prominent example being <a href=\"https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&amp;src=typd\" target=\"_blank\">President Trump</a>. Such a vaguely-defined term is ripe for a cynical manipulation.</p>\n<p>The data science community has responded by\u00a0<a href=\"https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/\" target=\"_blank\">taking action to fight the problem</a>. There\u2019s a Kaggle-style competition called the \u201c<a href=\"http://www.fakenewschallenge.org/\" target=\"_blank\">Fake News Challenge</a>\u201d\u00a0and <a href=\"https://techcrunch.com/2016/11/14/facebook-fake-news/\" target=\"_blank\">Facebook is employing AI</a>\u00a0to filter fake news stories out of users\u2019 feeds. Combating fake news is a classic text classification project with a straight-forward proposition: <strong><em>Can you build a model that can differentiate between \u201cReal\u201d news vs \u201cFake\u201d news.</em></strong></p>\n<p>And that\u2019s exactly what\u00a0I attempted to do for this project. I assembled a dataset of fake and real news and\u00a0employed a Naive\u00a0Bayes classifier in order to create a model to classify an article as fake or real based on its words and phrases.</p>\n<h3>Data Gather/Wrangling</h3>\n<p>\u00a0<br>\nThere were two parts to the data acquisition\u00a0process, getting the \u201cfake news\u201d and getting the real news. The first part was quick,\u00a0Kaggle released a\u00a0<a href=\"https://www.kaggle.com/mrisdal/fake-news\" target=\"_blank\">fake news dataset</a> comprising of 13,000 articles published during the 2016 election cycle.</br></p>\n<p>The second part was\u2026 a lot more difficult. \u00a0To acquire the real news side of the dataset, I turned to <a href=\"http://www.allsides.com/\" target=\"_blank\">All Sides</a>, a website dedicated to hosting news and opinion articles from across the political spectrum. Articles on the website are categorized by topic (environment, economy, abortion, etc\u2026) and by political leaning (left, center, and right).\u00a0I used\u00a0All Sides because it was the best way\u00a0to web scrape thousands of articles from numerous media outlets of differing\u00a0biases. Plus, it allowed to me download the full text of an article, something you cannot do with the New York Times and NPR APIs. After a long and arduous process I ended up scraping a total of <strong>5279 articles</strong>. The articles in my real news dataset came from\u00a0media organizations such as the New York Times, WSJ, Bloomberg, NPR, and the Guardian\u00a0and\u00a0were published in\u00a02015 or\u00a02016.</p>\n<p>I decided to construct my full dataset with equal parts\u00a0fake and real articles, thus making my model\u2019s null accuracy 50%. I randomly selected 5279 articles from my fake news dataset to use in my complete dataset and left the remaining articles to be used as a testing set when my model was complete.</p>\n<p>My finalized dataset was comprised of 10558 total articles with their headlines and full body text and their labels (real vs fake). The data is located here in this <a href=\"https://github.com/GeorgeMcIntire/fake_real_news_dataset\" target=\"_blank\">github repo</a>.</p>\n<h3>Purpose and Expectations</h3>\n<p>\u00a0<br>\nWhen I first started this project, I\u00a0conceded that this would not be the perfect project. The purpose of this project was to see how far I could get in creating a fake news classification and what insights could be drawn from that, then used towards a better model. My game plan was to treat this project the same way as a routine spam detection project.</br></p>\n<p>Building a model based on a count vectorizer (using word tallies) or a tfidf matrix (word tallies relative to how often they\u2019re used in other articles in your dataset) can only get you so far. These methods\u00a0do not consider important qualities\u00a0like the word ordering\u00a0and context. It\u2019s very possible for two articles\u00a0that are similar in their word counts to be totally different in their meaning. I did not expect my model to be adept at handling\u00a0fake and real articles\u00a0whose words and phrases overlap. Nonetheless, I expect some valuable insights to come from this project.</p>\n<h3>Modeling</h3>\n<p>\u00a0<br>\nSince this is a text classification project, I only used a Naive Bayes classifier as is standard for text-based data science projects.</br></p>\n<p>The real work in formulating a model was the text transformation\u00a0(count vectorizer vs tfidf vectorizer) and choosing which type of text to use (headlines vs full text). This gave me four pairs of reconfigured datasets to work with.</p>\n<p>The next step was to determine the most optimal parameters for either a countvectorizer or tfidf-vectorizer. For those of you who are unfamiliar with text machine learning, this means using a n-number of the most common words, using\u00a0words and/or phrases, lower casing or not, removing stop words (common words such as the,\u00a0when, and there) and only using words that appear at\u00a0least a given number of times in\u00a0a\u00a0text corpus (a term for a text dataset or a collection of texts).</p>\n<p>To test the performance of multiple parameters and their numerous combinations, I utilized the Sci-kit Learn\u2019s GridSearch functionality to efficiently execute this task. To learn more about how to\u00a0perfect your algorithm parameters, please review <a href=\"http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\" target=\"_blank\">this tutorial</a>.</p>\n<p>After the grid search\u00a0cross validation process, I\u00a0found that\u00a0my model worked best with\u00a0a\u00a0count vectorizer instead of a tfidf and produced higher scores when\u00a0trained on the full text of articles instead of their headlines.\u00a0The optimal parameters for\u00a0count vectorizer are no lowercasing, two-word phrases not single words, and\u00a0to only use words that appear at least three times in the corpus.</p>\n<p>Given my expectations that I outlined earlier in this post, I was surprised and almost baffled at the high scores\u00a0my model produced.\u00a0My model\u2019s cross-validated accuracy score is 91.7%, recall (true positive rate) score is\u00a092.6%, and its AUC score is 95%.</p>\n<p>Here is the ROC Curve for my model.</p>\n<p><a href=\"https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png\" target=\"_blank\"><img alt=\"ROC Curve\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png\" width=\"90%\"/></a></p>\n<p>If I\u00a0were to decide on a threshold for a model based on this graph, I would choose one that produces a FPR at around 0.08 and a TPR at around 0.90, because at that point in the graph the trade off between false positives and true positives is equal.</p>\n<h3>Results &amp; Conclusion</h3>\n<p>\u00a0<br>\nThe true test of my model\u2019s quality would be to see how fake news articles in the test set (those not used in the creation of my model) it could accurately classify.</br></p>\n<p><strong>Out of the 5234 articles left in the other fake news datasets, my model was able to correctly identify 88.2% of them as fake.</strong> This is 3.5 percentage points lower than my cross-validated accuracy score, but in my opinion it is pretty decent evaluation of my model.</p>\n<p>It turns out that my hypothesis\u00a0predicting that model would\u00a0struggle at classifying news articles was quite wrong. I\u00a0thought that an accuracy score in the upper 60s or lower 70s would be\u00a0excellent and I managed to surpass that by a significant margin.</p>\n<p>Even though I created what appears to be a pretty good model given the complexity of the task, I am not entirely convinced that it is as good as it appears to be and here\u2019s why.</p>\n<p>To be better understand why this might have happened, let\u2019s take a look at the \u201cfakest\u201d and \u201crealest\u201d words in the data\u2014I\u2019ll explain what I mean by that.</p>\n<p>Using a technique I borrowed from Kevin Markham of Data School, here\u2019s how I derived the \u201cfakest\u201d and \u201crealest\u201d words in the corpus. First I started off with a table two columns wide\u00a0and\u00a010558 rows long (that\u2019s how many words there are in the corpus). The first column represented how many times a given word appeared in articles classified as \u201cFAKE\u201d and the second column was how many times a word\u00a0appeared in a \u201cREAL\u201d article. \u00a0Then I divided\u00a0the fake column by the total number of fake articles my model classified and\u00a0so on for the real column.\u00a0Next, I added the number one to every value in the data because I created a new column of \u201cFake:Real\u201d ratios and didn\u2019t want to get an error by dividing zero. This \u201cFake:Real\u201d is a pretty good but by no means perfect metric of just how \u201cfake\u201d or \u201creal a certain word. The\u00a0logic is pretty simple, if a word shows up a bunch in \u201cfake\u201d articles and rarely in \u201creal\u201d articles then\u00a0its fake to real ratio score will be pretty high.</p>\n<p>Here are the top 20 \u201cfakest\u201d and \u201crealest\u201d words in my dataset.</p>\n<p><a href=\"https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png\" target=\"_blank\"><img alt=\"Fakest\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png\" width=\"90%\"/></a></p>\n<p><a href=\"https://opendatascience.com/wp-content/uploads/2017/02/realwords.png\" target=\"_blank\"><img alt=\"Realest\" class=\"aligncenter\" src=\"https://opendatascience.com/wp-content/uploads/2017/02/realwords.png\" width=\"90%\"/></a></p>\n<p>These two graphics exhibit some baffling results. The words in the \u201cfake\u201d chart are a mixed bag that includes some\u00a0typical internet\u00a0terminology such as PLEASE, Share, Posted, html, and Widget\u00a0and words that aren\u2019t even words such as tzrwu.\u00a0However I was not surprised to see infowars mentioned nor terms like \u201cSheeple\u201d or \u201cUFO\u201d make it in the top 20 \u201cfakest\u201d words. Infowars is a right-wing conspiracy-laden outlet led by Alex Jones that promotes conspiracy theories about chemtrails and 9/11.</p>\n<p>The \u201creal\u201d chart\u00a0is dominated by names and politicians and words frequently used in political articles, comprising 60% of the bars in the chart. Seven of the twenty terms, including four of the top six,\u00a0are politician names. This begs the question,\u00a0are articles\u00a0about politicians more likely to be true? No of course not, if anything you\u2019d expect there to be numerous fake news articles\u00a0spreading falsehoods\u00a0about politicians. I would be committing a huge error if I came to the conclusion that articles mentioning\u00a0politicians are more likely to be to factual.</p>\n<p>One big assumption\u00a0underlying this project is that there is considerable overlap in the topics covered by each class of article. As we witnessed above, just because a certain word\u00a0shows up more often in \u201creal\u201d news than\u00a0\u201cfake\u201d news it doesn\u2019t mean that articles with those terms are guaranteed to be \u201creal\u201d, but instead could just mean that those words are used in topics more common in the real news dataset and vice versa for the fake news dataset.</p>\n<p>I\u00a0and another party had a considerable amount of influence in shaping\u00a0this dataset. I made the decision on which articles to use for the \u201creal\u201d dataset.\u00a0The articles in the \u201cfake\u201d\u00a0dataset were determined by a\u00a0<a href=\"https://github.com/selfagency/bs-detector\" target=\"_blank\">chrome extension called \u201cBS Detector\u201d</a>\u00a0made by Daniel Sieradski. There is a\u00a0significantly high\u00a0amount of subjectivity going into determining what is and what isn\u2019t \u201cfake news\u201d. The reason why politician names are\u00a0rated\u00a0as \u201creal\u201d so highly is\u00a0most likely because that half of the corpura\u00a0disproportionately comes\u00a0from political news. In addition, I did find a couple of articles from what I find to be reputable sources of news. One such article came from The Intercept, a news organization\u00a0with high journalism standards. And yes, my model did indeed flag this supposed \u201cfake news\u201d article as real.</p>\n<p>To make\u00a0matters even more complicated,\u00a0we have to decide how to set the threshold probability for our model. If I was a data scientist at Facebook tasked with implementing a model that sorts out real and fake news in users\u2019 feeds, I\u2019d be faced with\u00a0the dilemma between choosing a model that blocks all or most fake news and some real news or a model that allows all or most real news and some fake news. But before I make that decision, I need\u00a0to figure\u00a0what is the cost of failing to prevent fake news vs the cost of blocking real news? How does\u00a0one attempt to answer such an abstract question? Unless we can train a model with a 100% true positive rate and 0% false positive rate, we\u2019ll be stuck with this quandary.</p>\n<p>In conclusion, while I think that a standard Naive Bayes text classification model can provide insight into addressing this issue,\u00a0a more powerful deep-learning tool should be employed to combat fake news in a professional setting.</p>\n<p>Classifying \u201cfake news\u201d provides a novel challenge to the data science community. \u00a0In many machine learning projects, the distinction between the different classes you want to predict is clear, whereas it\u2019s a lot murkier in this case. This\u00a0project validates the notion in data science\u00a0that intuition and intimacy with your data is just as or more important than any model or tool at your disposal.</p>\n<p><b>Bio: <a href=\"https://opendatascience.com/author/george-mcintire/\" target=\"_blank\">George McIntire</a></b> is a journalist turned data scientist/journalist hybrid. Looking for opportunities in data science and/or journalism. Impossibly curious and passionate about learning new things. Before completing the Metis Data Science Bootcamp, he worked as a freelance journalist in San Francisco for Vice, Salon, SF Weekly, San Francisco Magazine, and more.</p>\n<p><a href=\"https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/03/getting-hot-here-data-science-vs-fake-news.html\">It\u2019s Getting Hot In Here: Data Science vs Fake News</a>\n<li><a href=\"/2017/03/last-night-sweden-data-science-vs-fake-news.html\">What Happened Last Night in Sweden: Data Science vs Fake News</a>\n<li><a href=\"/2017/04/beware-two-data-obfuscation-tactics.html\">Beware of Two Data Obfuscation Tactics</a>\n</li></li></li></ul>\n</div> ", "website": "kdnuggets"}