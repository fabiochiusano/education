{"content": "By Thomas Cabrol, Dataiku . I was pretty excited to read that our partner HPE recently added machine learning capabilities to its Vertica database . As MPP ( massively parallel processing ) systems are fairly frequent in the retail world, it is a good occasion to try building the kind of application described above with a best-of-breed technology combined with Dataiku DSS ! So What Did I Build? Actually, a predictive application managed by Dataiku DSS and running entirely on top of Vertica . This is a end-to-end data workflow starting from acquiring raw data acquisition to training a machine learning model, aiming at predicting whether or not a customer is going to make a purchase in a specific product category : The Supporting Data The data are provided by dunnhumby , a leading customer science company providing data and insights from shoppers across the globe. These are typical datasets from the retail industry: a file storing 2 years of transactions, with information about customers, products, time, store, and amount a file storing demographics about the customers a file storing product attributes : product hierarchy, packaging\u2026 The Data Science process: 1. Data ingestion As we are going to use Vertica both for storing and processing our data, the very step is, of course, to push these data into Vertica . That\u2019s not rocket science with DSS: just create the DSS datasets from your raw data files, make them looking good using a Visual Data Preparation script if you wish, create a new output dataset stored in Vertica, and run your recipe. That\u2019s it. Your data are in Vertica. No coding, no SQL, no worries about how to move data around or how to handle schemas and data types: Dataiku DSS does it all automatically for you . Great, isn\u2019t it ? 2. Data preparation The files are disparate, have unnecessary data\u2026 With Dataiku DSS, we can easily join, filter, split datasets together using visual recipes, with no need to code . So what do we do now ? We first merge the 3 initial datasets (transactions, products, and customers) all together to get an holistic view of the purchase behavior (with the mean of a Join recipe), then we split the newly created datasets in 2, with a Split recipe: one part will be used to create the features or variables for our predictive model, based on historical transactions data; and the other one will be used to create the \u201clabels\u201d, a simple new column indicating whether or not the person will purchase specific products in coming weeks. All these data management tasks will be performed by the underlying Vertica database whenever it is possible to avoid data movement and benefit from its speed. 3. Features engineering The data are still too raw to be used by machine learning algorithms directly. We need to switch from the detailed \u201ctransactional\u201d view to an \u201canalytical\u201d view, where the data will be aggregated to form a large set of attributes (\u201cfeatures\u201d, or variables) describing each customer. This step is crucial and one of the most difficult when creating a machine learning model, known as features engineering. Technically speaking, when working with a SQL database, this will be essentially a combination of group by / pivot operations \u2026 . Fortunately enough, with Dataiku DSS you can either use \u201cvisual grouping\u201d recipes to generate your SQL statements, or programmatically create much more complex queries using helper Python functions . So let\u2019s move ahead and generate this aggregated dataset (which ends up with more than 340 columns !) by combining simple counts-based features and the money spent for each type of product: 4. Data preprocessing for machine learning We\u2019re getting closer to our machine learning model. Actually, there is one remaining step: many ML algorithm implementations expect numeric only features with no missing values . This is unfortunately very uncommon in practice as we often need to deal with not-so-clean, mixed data types. So in this step, we are going to impute missing values with a sensible value (averages) \u2013 even if this is always questionable, and transforming each categorical (text) feature into a set of \u201cdummy\u201d variables (if a feature has n possible values, we will create n-1 new columns filled with 0/1 depending on the absence/presence of the value). Again, Dataiku DSS helps automating this process by offering the ability to generate dynamically the corresponding SQL statements. 5. Model creation We can finally do ML now :) And test the new Machine Learning for Predictive Analytics functionality released with the latest 7.2.2 version of Vertica . Training, storing and getting statistics from your machine learning model is as easy as 2 queries : As we are predicting whether or not someone will buy from a specific product category, we have a classification problem (with a binary outcome), hence the choice of logistic regression , which is available out of the box for Vertica . Training the model is done entirely in-database, with no need to move data around! 6. Model assessment & deployment This is our last step. Using the statistics created by Vertica, we can easily see and analyze the coefficients and associated p-values for each feature of our model. As this is a regular DSS dataset, you are also free to keep on building your workflow from there (for instance by doing Checks / Metrics analysis). Vertica provides also with a set of handy functions to assess model performances via ROC or lift curves , which can be leveraged via DSS SQL Notebooks. Finally, the results can also be operationalized by using the model to score new records on a regular basis, done again fully in-database . Conclusion This is it, we now have a functional workflow orchestrated by DSS and running on top of Vertica to produce the purchase predictions , even if rather simplistic. Creating such predictive applications is much more than training machine learning algorithms \u2013 which is in fact just a fairly small amount of work in the entire process. Data preparation, features engineering, preprocessing\u2026 : these are some of the many things to do before being able to move to the \u201creal fun\u201d of ML. Even it may look like a sequential process through this post, it is in practice highly iterative. __Data preparation and machine learning are deeply coupled, and DSS offers the immense benefit to be able to create the entire data science workflow in an integrated environment, with no need to go back and forth between several tools. As Big Data arise, and best-of-breed technologies to manage them are made available ( this what we call Technoslavia at Dataiku ), Dataiku DSS offers integrations with third-party solutions to make sure they can be properly leveraged. A key feature is the ability to push down calculations and processing to underlying, high performance system such as HPE Vertica , which will avoid unnecessary data movements between systems and tools (one of the plagues in the Big Data world). Vertica is also perfectly suited for the kind of workloads on structured data created by DSS : data scientists can join, filter, group or pivot their data without worrying about tuning the system for performance and model tables properly, it will work fast out-of-the-box. The association is powerful: Vertica as a high performance backend to predictive applications developed in Dataiku DSS . Working with our ecosystem is key to us, but even more for our clients as they can fully leverage their technological investments by creating high value predictive applications more efficiently. Blablacar is a great example, as you may read about here (in French) or here . Did you notice? It\u2019s Vertica + Dataiku DSS , but also Tableau Tableau for data visualization and dashboarding, and a Cloudera Hadoop cluster for very large scale storage and data processing. Dataiku is also a technology partner of all of these great vendors, so we can ensure maximum value for our customers. We strive to keep on being more and more integrated with our ecosystem, but also to develop our partnerships with system integrators and consulting companies that can implement end-to-end data solutions on top of our technologies, so if you are interested to learn more, connect with me on LinkedIn or ping our team at partnerships@dataiku.com ! Original . Related: Build Your Own Audio/Video Analytics App With HPE Haven OnDemand \u2013 Part 1 HPE Haven OnDemand Text Extraction API Cheat Sheet for Developers Machine Learning at your fingertips \u2013 60+ free APIs, from HPE Haven OnDemand", "title_html": "<h1 id=\"title\">Predicting purchases at retail stores using HPE Vertica and Dataiku DSS</h1> ", "url": "https://www.kdnuggets.com/2016/06/dataiku-predicting-purchases-retail-stores-hpe-vertica.html", "tfidf": {"tfidf": {"real": 2.28103448276, "too": 1.81585268215, "ahead": 5.625797306869999, "basi": 2.42122922068, "form": 1.12755681818, "kind": 5.1612483745199995, "orchestr": 15.2214765101, "technolog": 13.017382748450002, "dataset": 1548.878048784, "function": 9.98176674, "client": 14.1371326803, "thoma": 2.39673913043, "python": 56.2978723404, "join": 5.376834499889999, "product": 12.98119378576, "done": 4.6605019814999995, "creation": 3.0601387818, "binari": 32.4, "their": 2.0309581681, "scale": 3.7469907953699995, "automat": 6.787516032490001, "absencepres": 1221.23076923, "sheet": 8.60954446855, "creat": 16.2407932011, "how": 3.20500656102, "test": 2.65707112971, "bestofbre": 2442.46153846, "fair": 6.41066020594, "than": 2.0655737705, "initi": 1.35, "vertica": 19539.69230768, "end": 1.10680423871, "lift": 6.37846524709, "uncommon": 14.0620017715, "interest": 1.60331246213, "holist": 74.5352112676, "will": 12.2481098596, "associ": 2.6526315789400003, "haven": 38.071942446, "someon": 4.9350326391, "partnership": 13.1044160132, "vendor": 27.2783505155, "new": 5.0894402770000005, "indic": 2.0826446281, "perform": 7.6569885212500015, "but": 3.04897253697, "speed": 3.8703071672400005, "need": 7.186311787049999, "our": 30.64864864867, "classif": 8.067073170730001, "final": 2.6801721955, "expect": 2.20011086475, "dunnhumbi": 1221.23076923, "record": 1.42334588488, "applic": 17.1336067343, "integr": 11.301655098760001, "immens": 12.7723250201, "has": 1.0436497502, "enough": 2.2319696330700003, "use": 10.296387573799999, "sequenti": 39.5910224439, "typic": 2.2541530597799997, "out": 1.06016694491, "model": 25.0871740848, "good": 3.03963239518, "alway": 2.06745670009, "excit": 9.818181818180001, "under": 2.1563327674, "cours": 2.15092805853, "numer": 1.83325635104, "categori": 7.96388261852, "indatabas": 2442.46153846, "togeth": 3.16191993626, "view": 4.92228193467, "not": 4.06269592476, "newli": 3.1847542627900003, "storag": 8.623574144489998, "wish": 3.67755385685, "are": 14.41868310092, "team": 2.2748244734200003, "aim": 2.8960233491400005, "logist": 14.0994671403, "specif": 5.615847187829999, "easi": 5.2937645882, "aggreg": 35.085082873000005, "metric": 22.235294117600002, "handl": 3.9229058561900003, "then": 1.08657860516, "purchas": 12.323694935, "consult": 5.21721984883, "last": 1.2117234010100002, "let": 3.48616600791, "world": 2.22680412372, "scienc": 9.27878433664, "outcom": 7.48867924528, "audiovideo": 1221.23076923, "money": 2.62283165373, "ensur": 3.4127257093700005, "practic": 3.40869565218, "technoslavia": 1221.23076923, "simpl": 6.7962328767199995, "algorithm": 83.8521126762, "valu": 15.944332855080003, "offer": 4.61690577744, "either": 1.5830092731099998, "develop": 3.5867158671600006, "such": 2.12302754748, "sever": 1.07241286139, "via": 4.595744680859999, "without": 1.29547123623, "fast": 4.8729281768, "box": 4.12685209254, "small": 1.3594793629, "both": 1.05215720061, "aris": 7.54921540656, "result": 1.14611608432, "version": 2.0083491461099996, "produc": 1.36932896326, "filter": 33.7787234042, "packaging\u2026": 1221.23076923, "miss": 7.0732902651, "helper": 79.38, "acquisit": 10.3764705882, "retail": 17.56194690266, "question": 2.20408163265, "from": 10.0056721497, "ecosystem": 52.223684210600005, "workload": 74.5352112676, "behavior": 5.52978056426, "whether": 6.62051709759, "detail": 2.26186066391, "num": 15.004725600150001, "instanc": 3.2572835453400004, "free": 3.43636363636, "environ": 3.43561999567, "curv": 11.1098670399, "acquir": 3.10563380282, "for": 16.00504064016, "difficult": 2.48957189901, "predict": 46.66361854995, "output": 7.676982591880001, "releas": 1.8377126982299998, "fulli": 5.58031634446, "with": 26.031153433739995, "handi": 102.425806452, "merg": 5.28319467554, "speak": 2.89127663449, "split": 10.41276781809, "compani": 3.1047227926, "frequent": 2.10501193317, "preprocess": 1221.23076923, "look": 3.8172637653199994, "technic": 3.1400316455699997, "histor": 1.6755672823199999, "backend": 933.882352941, "veri": 3.77640342531, "extract": 7.703056768560001, "variabl": 26.241322314059996, "work": 4.46080359652, "combin": 5.09281437126, "cloudera": 1221.23076923, "column": 21.234061524750004, "dashboard": 118.47761194, "iter": 37.4433962264, "group": 3.62990625714, "doe": 1.70581282905, "even": 4.65845070424, "proper": 6.677602523659999, "train": 7.7462795803999995, "notsoclean": 1221.23076923, "avoid": 4.91973969632, "step": 14.139650872799997, "great": 3.79778327088, "move": 5.16502643352, "big": 5.480151881259999, "type": 6.084312723570001, "switch": 4.97368421053, "key": 4.5601034037, "analyz": 9.68639414277, "scientist": 4.69426374926, "notebook": 40.1924050633, "again": 3.01767724768, "dataikucom": 1221.23076923, "abov": 1.90382539873, "blablacar": 1221.23076923, "set": 3.56123822343, "where": 1.06715063521, "coeffici": 36.4965517241, "buy": 5.12459651388, "fortun": 6.211267605630001, "latest": 7.078020508250001, "rocket": 12.403125, "help": 1.39962972759, "strive": 21.9585062241, "larg": 2.3714989917, "abil": 5.41750554512, "preprocessing\u2026": 1221.23076923, "solut": 9.4556283502, "own": 1.17844418052, "base": 1.14628158845, "relat": 1.23750876919, "deal": 2.18346857379, "fact": 1.73375559681, "massiv": 4.22571200426, "tableau": 488.492307692, "post": 2.23826307627, "here": 4.84615384616, "label": 4.47715736041, "whenev": 11.622254758399999, "maximum": 4.80072573329, "averag": 2.60390355913, "script": 8.299006795610001, "much": 2.3884459154599997, "closer": 5.5666199158500005, "henc": 5.390831918509999, "parallel": 4.57917507932, "about": 5.324300757950001, "problem": 1.76674827509, "deploy": 7.41869158879, "sensibl": 24.164383561599998, "thing": 2.4065484311099996, "occas": 3.68780487805, "sure": 7.453521126760001, "just": 2.67160286074, "entir": 6.37462356956, "french": 2.11962616822, "thirdparti": 1221.23076923, "featur": 16.79838399382, "statement": 6.84457857296, "them": 2.19752231988, "check": 6.50655737705, "pivot": 35.596412556, "dynam": 6.52527743527, "across": 1.7318642958400001, "complex": 2.34021226415, "categor": 15.0198675497, "plagu": 11.086592178800002, "start": 1.26673581744, "hierarchi": 14.3285198556, "run": 4.6707855251399995, "ping": 110.25, "insight": 11.8037174721, "globe": 8.25155925156, "they": 2.06034650574, "keep": 4.08490930142, "fill": 3.33809924306, "autom": 19.8202247191, "cheat": 31.6886227545, "support": 1.2685577307200002, "abl": 3.6417020300400003, "mani": 2.08853515754, "the": 50.0, "fun": 12.8863636364, "build": 6.5366958312, "analysi": 3.47852760736, "provid": 3.64658142561, "calcul": 6.12972972973, "schema": 111.802816901, "unfortun": 9.966101694919999, "demograph": 10.851674641099999, "recip": 214.54054054050002, "there": 2.08182533438, "imput": 178.38202247200002, "endtoend": 2442.46153846, "regular": 4.18836565096, "inform": 1.5753125620200001, "possibl": 2.8347468976, "industri": 2.02319357716, "operation": 453.6, "exampl": 1.50483412322, "forth": 8.65177111717, "spent": 3.00795755968, "linkedin": 610.615384615, "visual": 20.91010865988, "now": 3.4823426189999998, "tri": 1.8544562551099997, "dummi": 48.1090909091, "code": 7.761427523839999, "high": 4.5910931174, "regress": 51.2129032258, "power": 1.3396337861799998, "leverag": 107.2702702704, "also": 7.10335570469, "coupl": 3.2572835453400004, "person": 1.40520446097, "around": 2.42789417342, "mean": 1.44906900329, "notic": 4.36994219653, "task": 3.88641370869, "dataiku": 14654.769230760001, "may": 2.10403551786, "dispar": 22.583214793699998, "ondemand": 3663.6923076900002, "transact": 47.56853932600001, "fingertip": 226.8, "machin": 44.267680608359996, "into": 2.03004922958, "system": 6.93699204755, "nnum": 39.8894472362, "outofthebox": 1221.23076923, "partner": 8.347003154580001, "essenti": 2.9280708225700005, "cabrol": 1221.23076923, "attribut": 6.8313253012, "actual": 3.74964572508, "crucial": 7.7443902439, "week": 1.80532181033, "which": 5.025959224999999, "databas": 24.741818181809997, "other": 1.00992366412, "one": 5.031374786100001, "raw": 31.943661971699996, "known": 1.0859097127200001, "custom": 25.44230769234, "see": 1.27242125511, "some": 1.04036697248, "unnecessari": 34.9691629956, "get": 5.35687774155, "still": 1.1866357724799999, "like": 1.14918566775, "shopper": 89.19101123600001, "implement": 7.15296237892, "through": 1.07074930869, "manag": 4.934521342739999, "push": 7.50283553876, "file": 18.855106888349997, "data\u2026": 1221.23076923, "process": 13.56198611856, "invest": 4.16146788991, "transform": 3.42007755278, "analyt": 51.769565217300006, "recent": 1.54405757635, "structur": 2.0580762250499998, "tabl": 3.82093862816, "this": 13.049317147230001, "choic": 3.1319786940200003, "deepli": 7.9063745019899985, "time": 1.01127460348, "api": 84.44680851060001, "part": 2.08661365578, "back": 1.26070038911, "simplist": 72.16363636359999, "statist": 8.48530197756, "pvalu": 1221.23076923, "most": 1.02096463023, "between": 2.06907337416, "what": 3.7603031738399997, "programmat": 214.54054054099998, "all": 4.04587155964, "top": 5.516330785260001, "mix": 2.7852631578900002, "store": 24.12765957448, "have": 3.0446845234199995, "suit": 3.92873051225, "that": 4.015936255, "call": 1.0676529926, "cluster": 12.5007874016, "connect": 1.8843916913900003, "more": 8.1373654536, "and": 30.0018897639, "correspond": 3.32481675393, "these": 5.3707713126000005, "prepar": 9.72049594368, "benefit": 6.13683803634, "capabl": 3.6580645161300005, "amount": 4.54054054054, "workflow": 1476.837209304, "made": 1.07038834951, "tune": 10.4173228346, "befor": 1.10036041031, "lead": 1.2664326739, "hadoop": 1221.23076923, "can": 12.93887530562, "avail": 3.4576935642, "describ": 2.94054454528, "make": 3.2287980475800007, "queri": 112.5957446808, "depend": 2.2411067193700003, "onli": 1.0256476516600002, "each": 4.75899280576, "ingest": 42.449197861, "assess": 10.48612945838, "read": 4.629921259840001, "pretti": 15.75, "remain": 1.16598119859, "worri": 20.604802076600002, "data": 118.1752445769, "oper": 1.55479384977, "perfect": 4.48601299802, "rather": 1.55692850838, "come": 1.32831325301, "origin": 1.13724928367, "countsbas": 1221.23076923, "text": 6.25655172414, "direct": 1.22226499346, "first": 1.00761614623, "engin": 7.414072229129999, "app": 35.837471783299996, "conclus": 4.84615384615, "generat": 6.15826221876, "tool": 9.99433427762, "score": 4.2884927066500005, "movement": 4.21953488372, "year": 1.0485436893200002, "easili": 7.387622149839999, "often": 1.29452054795, "down": 1.35889754344, "learn": 27.873006583800002, "when": 2.0415353951, "effici": 5.09335899904}, "logtfidf": {"real": 0.824629060574, "too": 0.5965551547219999, "ahead": 1.7273626814900003, "basi": 0.884275353639, "form": 0.120053184191, "kind": 1.896062605434, "orchestr": 2.7227073588999997, "technolog": 4.784238431775, "dataset": 42.12675653312, "function": 3.657862966376, "client": 2.6488048591599997, "thoma": 0.874109117838, "python": 4.03065674296, "join": 1.75046258826, "product": 3.872481092288, "done": 1.691951966258, "creation": 1.11846026847, "binari": 3.4781584227999995, "their": 0.030721010245400002, "scale": 1.32095306328, "automat": 1.9150850473199998, "absencepres": 7.1076144564399995, "sheet": 2.15287140979, "creat": 2.893498640682, "how": 0.9431339138600001, "test": 0.977224437103, "bestofbre": 14.215228912879999, "fair": 2.32963016262, "than": 0.0645217244364, "initi": 0.30010459245, "vertica": 113.72183130303999, "end": 0.101476798618, "lift": 1.8529275115400001, "uncommon": 2.64347624975, "interest": 0.47207177798199995, "holist": 4.31127164819, "will": 2.0278653491500003, "associ": 0.5648100307020001, "haven": 7.622595910319999, "someon": 1.59635928666, "partnership": 3.7596041861800003, "vendor": 3.30609336617, "new": 0.08864973425549999, "indic": 0.7336385419149999, "perform": 2.1309042528999997, "but": 0.0485771162157, "speed": 1.3533338752700002, "need": 1.81370081721, "our": 11.149309784366, "classif": 2.08779073629, "final": 0.585467727896, "expect": 0.78850775216, "dunnhumbi": 7.1076144564399995, "record": 0.353010356953, "applic": 6.15801964245, "integr": 4.15461929116, "immens": 2.54728072239, "has": 0.0427239448548, "enough": 0.802884439169, "use": 0.292080197316, "sequenti": 3.6786023866, "typic": 0.812774319158, "out": 0.0584263909193, "model": 8.849400877332002, "good": 0.837178809814, "alway": 0.726319204572, "excit": 2.28423595433, "under": 0.15052361076639997, "cours": 0.765899404133, "numer": 0.606093812346, "categori": 2.76353893304, "indatabas": 14.215228912879999, "togeth": 0.916064474616, "view": 1.485479826519, "not": 0.06220965203, "newli": 1.1583751315100002, "storag": 2.1544996326700003, "wish": 1.30224781835, "are": 0.4125446301578, "team": 0.821902894886, "aim": 1.06333853704, "logist": 2.6461370052, "specif": 1.8809405026230002, "easi": 1.6665296351499999, "aggreg": 5.7292577404, "metric": 3.1016808515599994, "handl": 1.36683266903, "then": 0.08303386523089999, "purchas": 4.500917862280001, "consult": 1.6519646640099999, "last": 0.19204364461100001, "let": 1.2488025672799998, "world": 0.214840497242, "scienc": 3.365744715564, "outcom": 2.01339244624, "audiovideo": 7.1076144564399995, "money": 0.964254518011, "ensur": 1.22751130026, "practic": 1.066365061734, "technoslavia": 7.1076144564399995, "simpl": 2.4464425787799997, "algorithm": 9.99132718554, "valu": 5.7623531710360005, "offer": 1.293337340706, "either": 0.459327638815, "develop": 0.535874084739, "such": 0.119391955612, "sever": 0.06991112039689999, "via": 1.663967250828, "without": 0.258874517941, "fast": 1.5836950247400001, "box": 1.41751491115, "small": 0.307101805059, "both": 0.050842533389300004, "aris": 2.0214436382, "result": 0.136378908381, "version": 0.697313064259, "produc": 0.314320812003, "filter": 5.65336787728, "packaging\u2026": 7.1076144564399995, "miss": 2.5263571502400004, "helper": 4.37424644735, "acquisit": 2.3395407995200004, "retail": 4.3451745459, "question": 0.790310929014, "from": 0.00567054168866, "ecosystem": 6.52477786388, "workload": 4.31127164819, "behavior": 1.71014813378, "whether": 2.3746835689409997, "detail": 0.816187777173, "num": 0.004724855930955001, "instanc": 1.18089357972, "free": 1.0825332985340002, "environ": 1.2341974030299998, "curv": 2.40783363597, "acquir": 1.1332178178499999, "for": 0.005039846326352001, "difficult": 0.912110767588, "predict": 14.811662139209998, "output": 2.03822657827, "releas": 0.608521699544, "fulli": 2.05219657356, "with": 0.03113478454814, "handi": 4.62913869698, "merg": 1.66453096693, "speak": 1.06169814662, "split": 3.7332613179600003, "compani": 0.879554506194, "frequent": 0.7443211360850001, "preprocess": 7.1076144564399995, "look": 1.2927733872, "technic": 1.14423287808, "histor": 0.516151783952, "backend": 6.83935046985, "veri": 0.6904793797140001, "extract": 2.04161723301, "variabl": 6.506169201600001, "work": 0.436138269092, "combin": 1.587654932253, "cloudera": 7.1076144564399995, "column": 5.87098283814, "dashboard": 4.77472401395, "iter": 3.62283035867, "group": 0.5717836043910001, "doe": 0.5340417297169999, "even": 0.609554259336, "proper": 2.4112236778400002, "train": 2.643673251356, "notsoclean": 7.1076144564399995, "avoid": 1.800216882582, "step": 5.1977252849, "great": 0.707415774237, "move": 1.022463437012, "big": 2.01597127114, "type": 2.121304456161, "switch": 1.60416085533, "key": 1.64839623792, "analyz": 2.2707222351599996, "scientist": 1.54634128444, "notebook": 3.693678049, "again": 0.822680463224, "dataikucom": 7.1076144564399995, "abov": 0.643865229816, "blablacar": 7.1076144564399995, "set": 0.5144880338669999, "where": 0.0649921387457, "coeffici": 3.5972177828099996, "buy": 1.6340517929299998, "fortun": 1.8263649984099999, "latest": 1.95699427938, "rocket": 2.51794845699, "help": 0.336207721344, "strive": 3.0891545917400003, "larg": 0.34075012121200005, "abil": 1.992976594854, "preprocessing\u2026": 7.1076144564399995, "solut": 3.10692595254, "own": 0.164195077421, "base": 0.13652330228700002, "relat": 0.21310030165399999, "deal": 0.780914701253, "fact": 0.5502899207949999, "massiv": 1.44118776833, "tableau": 10.996353088020001, "post": 0.8057001527009999, "here": 1.7700763767400003, "label": 1.49898832727, "whenev": 2.45292177377, "maximum": 1.5687671009200002, "averag": 0.957011687995, "script": 2.1161358444599996, "much": 0.35499145860200004, "closer": 1.7167880323700002, "henc": 1.68469971782, "parallel": 1.52151886822, "about": 0.31421738737300003, "problem": 0.569140724273, "deploy": 2.00400270589, "sensibl": 3.18487979542, "thing": 0.8781935346799999, "occas": 1.30503139704, "sure": 2.0086865552, "just": 0.579062868218, "entir": 1.8641227210799998, "french": 0.751239737392, "thirdparti": 7.1076144564399995, "featur": 4.657261599562, "statement": 2.4606194183000003, "them": 0.1883666538186, "check": 1.87281049562, "pivot": 5.75819536264, "dynam": 1.8756834711200001, "across": 0.549198455941, "complex": 0.8502416364309999, "categor": 2.70937382803, "plagu": 2.4057364663799996, "start": 0.236443369291, "hierarchi": 2.6622519466, "run": 1.328144926617, "ping": 4.70275051433, "insight": 2.46841452187, "globe": 2.11040218268, "they": 0.0594539895352, "keep": 1.4283046893459999, "fill": 1.20540155609, "autom": 2.9867028668299995, "cheat": 3.4559577128199996, "support": 0.237880610037, "abl": 1.19860796495, "mani": 0.0866315162442, "the": 0.0, "fun": 2.5561696698099996, "build": 1.964549808364, "analysi": 1.2466091029200002, "provid": 0.585533532975, "calcul": 1.8131506592099997, "schema": 4.7167367562999996, "unfortun": 2.29918950399, "demograph": 2.38431941288, "recip": 18.7953040413, "there": 0.080195785851, "imput": 5.18392744417, "endtoend": 14.215228912879999, "regular": 1.478326835694, "inform": 0.454453704662, "possibl": 0.697610949782, "industri": 0.7046772417749999, "operation": 6.117215752409999, "exampl": 0.40868267499899996, "forth": 2.1577640534099998, "spent": 1.10126129684, "linkedin": 6.414467275880001, "visual": 6.6157533954400005, "now": 0.44727883506300004, "tri": 0.61759152916, "dummi": 3.87347115944, "code": 2.71203819194, "high": 0.5512951461600001, "regress": 3.9359915164199997, "power": 0.292396282715, "leverag": 10.730217754409999, "also": 0.1026001046, "coupl": 1.18089357972, "person": 0.34018281601800004, "around": 0.38775421156400003, "mean": 0.37092128352, "notic": 1.47474978168, "task": 1.35748680661, "dataiku": 85.29137347727999, "may": 0.10141999056880001, "dispar": 3.11720692209, "ondemand": 21.322843369319997, "transact": 9.903508972280001, "fingertip": 5.4240685718499995, "machin": 15.31595538682, "into": 0.0298257264574, "system": 1.637151727925, "nnum": 3.6861118086199998, "outofthebox": 7.1076144564399995, "partner": 2.8575107804799997, "essenti": 1.07434378384, "cabrol": 7.1076144564399995, "attribut": 2.4567430307400002, "actual": 1.257028363296, "crucial": 2.04696874177, "week": 0.5907388641619999, "which": 0.02589206922715, "databas": 6.329647701540001, "other": 0.00987474791976, "one": 0.0312767582275, "raw": 7.09608449742, "known": 0.0824180805992, "custom": 9.033523075359998, "see": 0.240921585492, "some": 0.0395735090645, "unnecessari": 5.722638870599999, "get": 1.739307017346, "still": 0.17112222142900002, "like": 0.139053576545, "shopper": 4.49078026361, "implement": 2.54875881814, "through": 0.0683586918849, "manag": 1.492930161474, "push": 2.64426768072, "file": 6.6367294361499996, "data\u2026": 7.1076144564399995, "process": 4.2226335922, "invest": 1.42586787018, "transform": 1.22966322707, "analyt": 8.544570431579999, "recent": 0.434413741288, "structur": 0.7217716751350001, "tabl": 1.34049610661, "this": 0.0492238376825, "choic": 1.14166497543, "deepli": 2.06766933309, "time": 0.0112115188626, "api": 4.43612185107, "part": 0.08479062196560001, "back": 0.23166743089699998, "simplist": 4.27893626755, "statist": 2.8903766141400005, "pvalu": 7.1076144564399995, "most": 0.020747896295599998, "between": 0.06790736233059999, "what": 0.677661890481, "programmat": 5.3684987207, "all": 0.04561052839119999, "top": 1.8273019133640003, "mix": 1.02434236008, "store": 8.66214113464, "have": 0.0443550070236, "suit": 1.36831634882, "that": 0.01590459351856, "call": 0.0654627744488, "cluster": 2.52579163445, "connect": 0.633605058682, "more": 0.13619945279999998, "and": 0.001889704261908, "correspond": 1.20141456099, "these": 0.357668097004, "prepar": 3.5517691162480003, "benefit": 2.24232490232, "capabl": 1.2969341868100002, "amount": 1.639797772398, "workflow": 23.64545479284, "made": 0.0680215260973, "tune": 2.3434700776599997, "befor": 0.0956377718795, "lead": 0.23620402986699998, "hadoop": 7.1076144564399995, "can": 1.7857520603339998, "avail": 1.094909172578, "describ": 0.77089520625, "make": 0.22049297346869998, "queri": 8.06131348592, "depend": 0.806969815, "onli": 0.025324268329099998, "each": 0.694966757216, "ingest": 3.74830801649, "assess": 3.3138123987, "read": 1.67878536176, "pretti": 2.75684036527, "remain": 0.15356296309, "worri": 4.664753957159999, "data": 42.588720468, "oper": 0.441342964347, "perfect": 1.50096433356, "rather": 0.442714975539, "come": 0.28390990653000003, "origin": 0.128612437587, "countsbas": 7.1076144564399995, "text": 2.28096401998, "direct": 0.200705689496, "first": 0.0075872898121599995, "engin": 2.7143026748279997, "app": 3.57899404386, "conclus": 1.57818536893, "generat": 2.1575470252080002, "tool": 3.21774235926, "score": 1.4559353207700003, "movement": 1.493155448572, "year": 0.047402238894600005, "easili": 2.6133174734, "often": 0.258140393351, "down": 0.306673741186, "learn": 10.11302477694, "when": 0.0411099777168, "effici": 1.62793753414}, "logidf": {"real": 0.824629060574, "too": 0.5965551547219999, "ahead": 1.7273626814900003, "basi": 0.884275353639, "form": 0.120053184191, "kind": 0.948031302717, "orchestr": 2.7227073588999997, "technolog": 0.956847686355, "dataset": 5.26584456664, "function": 0.914465741594, "client": 2.6488048591599997, "thoma": 0.874109117838, "python": 4.03065674296, "join": 0.58348752942, "product": 0.484060136536, "done": 0.845975983129, "creation": 1.11846026847, "binari": 3.4781584227999995, "their": 0.015360505122700001, "scale": 1.32095306328, "automat": 1.9150850473199998, "absencepres": 7.1076144564399995, "sheet": 2.15287140979, "creat": 0.222576818514, "how": 0.47156695693000006, "test": 0.977224437103, "bestofbre": 7.1076144564399995, "fair": 1.16481508131, "than": 0.0322608622182, "initi": 0.30010459245, "vertica": 7.1076144564399995, "end": 0.101476798618, "lift": 1.8529275115400001, "uncommon": 2.64347624975, "interest": 0.47207177798199995, "holist": 4.31127164819, "will": 0.202786534915, "associ": 0.28240501535100004, "haven": 2.54086530344, "someon": 1.59635928666, "partnership": 1.8798020930900001, "vendor": 3.30609336617, "new": 0.0177299468511, "indic": 0.7336385419149999, "perform": 0.42618085058, "but": 0.0161923720719, "speed": 1.3533338752700002, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "final": 0.292733863948, "expect": 0.78850775216, "dunnhumbi": 7.1076144564399995, "record": 0.353010356953, "applic": 1.23160392849, "integr": 1.03865482279, "immens": 2.54728072239, "has": 0.0427239448548, "enough": 0.802884439169, "use": 0.0292080197316, "sequenti": 3.6786023866, "typic": 0.812774319158, "out": 0.0584263909193, "model": 0.7374500731110001, "good": 0.418589404907, "alway": 0.726319204572, "excit": 2.28423595433, "under": 0.07526180538319999, "cours": 0.765899404133, "numer": 0.606093812346, "categori": 1.38176946652, "indatabas": 7.1076144564399995, "togeth": 0.458032237308, "view": 0.49515994217299997, "not": 0.0155524130075, "newli": 1.1583751315100002, "storag": 2.1544996326700003, "wish": 1.30224781835, "are": 0.0294674735827, "team": 0.821902894886, "aim": 1.06333853704, "logist": 2.6461370052, "specif": 0.626980167541, "easi": 1.6665296351499999, "aggreg": 2.8646288702, "metric": 3.1016808515599994, "handl": 1.36683266903, "then": 0.08303386523089999, "purchas": 1.1252294655700001, "consult": 1.6519646640099999, "last": 0.19204364461100001, "let": 1.2488025672799998, "world": 0.107420248621, "scienc": 0.841436178891, "outcom": 2.01339244624, "audiovideo": 7.1076144564399995, "money": 0.964254518011, "ensur": 1.22751130026, "practic": 0.533182530867, "technoslavia": 7.1076144564399995, "simpl": 1.2232212893899999, "algorithm": 3.33044239518, "valu": 0.823193310148, "offer": 0.431112446902, "either": 0.459327638815, "develop": 0.178624694913, "such": 0.059695977806, "sever": 0.06991112039689999, "via": 0.831983625414, "without": 0.258874517941, "fast": 1.5836950247400001, "box": 1.41751491115, "small": 0.307101805059, "both": 0.050842533389300004, "aris": 2.0214436382, "result": 0.136378908381, "version": 0.697313064259, "produc": 0.314320812003, "filter": 2.82668393864, "packaging\u2026": 7.1076144564399995, "miss": 1.2631785751200002, "helper": 4.37424644735, "acquisit": 2.3395407995200004, "retail": 2.17258727295, "question": 0.790310929014, "from": 0.000567054168866, "ecosystem": 3.26238893194, "workload": 4.31127164819, "behavior": 1.71014813378, "whether": 0.791561189647, "detail": 0.816187777173, "num": 0.00031499039539700004, "instanc": 1.18089357972, "free": 0.5412666492670001, "environ": 1.2341974030299998, "curv": 2.40783363597, "acquir": 1.1332178178499999, "for": 0.00031499039539700004, "difficult": 0.912110767588, "predict": 1.6457402376899999, "output": 2.03822657827, "releas": 0.608521699544, "fulli": 1.02609828678, "with": 0.00119749171339, "handi": 4.62913869698, "merg": 1.66453096693, "speak": 1.06169814662, "split": 1.24442043932, "compani": 0.439777253097, "frequent": 0.7443211360850001, "preprocess": 7.1076144564399995, "look": 0.6463866936, "technic": 1.14423287808, "histor": 0.516151783952, "backend": 6.83935046985, "veri": 0.230159793238, "extract": 2.04161723301, "variabl": 2.1687230672, "work": 0.109034567273, "combin": 0.529218310751, "cloudera": 7.1076144564399995, "column": 1.95699427938, "dashboard": 4.77472401395, "iter": 3.62283035867, "group": 0.190594534797, "doe": 0.5340417297169999, "even": 0.152388564834, "proper": 1.2056118389200001, "train": 0.660918312839, "notsoclean": 7.1076144564399995, "avoid": 0.900108441291, "step": 1.03954505698, "great": 0.235805258079, "move": 0.255615859253, "big": 1.00798563557, "type": 0.707101485387, "switch": 1.60416085533, "key": 0.82419811896, "analyz": 2.2707222351599996, "scientist": 1.54634128444, "notebook": 3.693678049, "again": 0.411340231612, "dataikucom": 7.1076144564399995, "abov": 0.643865229816, "blablacar": 7.1076144564399995, "set": 0.171496011289, "where": 0.0649921387457, "coeffici": 3.5972177828099996, "buy": 1.6340517929299998, "fortun": 1.8263649984099999, "latest": 1.95699427938, "rocket": 2.51794845699, "help": 0.336207721344, "strive": 3.0891545917400003, "larg": 0.17037506060600002, "abil": 0.996488297427, "preprocessing\u2026": 7.1076144564399995, "solut": 1.55346297627, "own": 0.164195077421, "base": 0.13652330228700002, "relat": 0.21310030165399999, "deal": 0.780914701253, "fact": 0.5502899207949999, "massiv": 1.44118776833, "tableau": 5.4981765440100006, "post": 0.8057001527009999, "here": 0.8850381883700001, "label": 1.49898832727, "whenev": 2.45292177377, "maximum": 1.5687671009200002, "averag": 0.957011687995, "script": 2.1161358444599996, "much": 0.17749572930100002, "closer": 1.7167880323700002, "henc": 1.68469971782, "parallel": 1.52151886822, "about": 0.0628434774746, "problem": 0.569140724273, "deploy": 2.00400270589, "sensibl": 3.18487979542, "thing": 0.8781935346799999, "occas": 1.30503139704, "sure": 2.0086865552, "just": 0.289531434109, "entir": 0.46603068026999994, "french": 0.751239737392, "thirdparti": 7.1076144564399995, "featur": 0.423387418142, "statement": 1.2303097091500002, "them": 0.0941833269093, "check": 1.87281049562, "pivot": 2.87909768132, "dynam": 1.8756834711200001, "across": 0.549198455941, "complex": 0.8502416364309999, "categor": 2.70937382803, "plagu": 2.4057364663799996, "start": 0.236443369291, "hierarchi": 2.6622519466, "run": 0.442714975539, "ping": 4.70275051433, "insight": 2.46841452187, "globe": 2.11040218268, "they": 0.0297269947676, "keep": 0.7141523446729999, "fill": 1.20540155609, "autom": 2.9867028668299995, "cheat": 3.4559577128199996, "support": 0.237880610037, "abl": 0.599303982475, "mani": 0.0433157581221, "the": 0.0, "fun": 2.5561696698099996, "build": 0.491137452091, "analysi": 1.2466091029200002, "provid": 0.19517784432500002, "calcul": 1.8131506592099997, "schema": 4.7167367562999996, "unfortun": 2.29918950399, "demograph": 2.38431941288, "recip": 3.7590608082599997, "there": 0.0400978929255, "imput": 5.18392744417, "endtoend": 7.1076144564399995, "regular": 0.739163417847, "inform": 0.454453704662, "possibl": 0.348805474891, "industri": 0.7046772417749999, "operation": 6.117215752409999, "exampl": 0.40868267499899996, "forth": 2.1577640534099998, "spent": 1.10126129684, "linkedin": 6.414467275880001, "visual": 1.6539383488600001, "now": 0.149092945021, "tri": 0.61759152916, "dummi": 3.87347115944, "code": 1.35601909597, "high": 0.13782378654000002, "regress": 3.9359915164199997, "power": 0.292396282715, "leverag": 3.5767392514699994, "also": 0.0146571578, "coupl": 1.18089357972, "person": 0.34018281601800004, "around": 0.19387710578200001, "mean": 0.37092128352, "notic": 1.47474978168, "task": 1.35748680661, "dataiku": 7.1076144564399995, "may": 0.050709995284400004, "dispar": 3.11720692209, "ondemand": 7.1076144564399995, "transact": 2.4758772430700002, "fingertip": 5.4240685718499995, "machin": 1.39235958062, "into": 0.0149128632287, "system": 0.327430345585, "nnum": 3.6861118086199998, "outofthebox": 7.1076144564399995, "partner": 1.4287553902399999, "essenti": 1.07434378384, "cabrol": 7.1076144564399995, "attribut": 1.2283715153700001, "actual": 0.628514181648, "crucial": 2.04696874177, "week": 0.5907388641619999, "which": 0.00517841384543, "databas": 2.10988256718, "other": 0.00987474791976, "one": 0.0062553516455, "raw": 2.36536149914, "known": 0.0824180805992, "custom": 1.2905032964799998, "see": 0.240921585492, "some": 0.0395735090645, "unnecessari": 2.8613194352999995, "get": 0.579769005782, "still": 0.17112222142900002, "like": 0.139053576545, "shopper": 4.49078026361, "implement": 1.27437940907, "through": 0.0683586918849, "manag": 0.497643387158, "push": 1.32213384036, "file": 1.32734588723, "data\u2026": 7.1076144564399995, "process": 0.527829199025, "invest": 1.42586787018, "transform": 1.22966322707, "analyt": 2.8481901438599997, "recent": 0.434413741288, "structur": 0.7217716751350001, "tabl": 1.34049610661, "this": 0.0037864490525, "choic": 1.14166497543, "deepli": 2.06766933309, "time": 0.0112115188626, "api": 4.43612185107, "part": 0.04239531098280001, "back": 0.23166743089699998, "simplist": 4.27893626755, "statist": 1.4451883070700002, "pvalu": 7.1076144564399995, "most": 0.020747896295599998, "between": 0.033953681165299995, "what": 0.225887296827, "programmat": 5.3684987207, "all": 0.011402632097799998, "top": 0.609100637788, "mix": 1.02434236008, "store": 1.2374487335200002, "have": 0.0147850023412, "suit": 1.36831634882, "that": 0.00397614837964, "call": 0.0654627744488, "cluster": 2.52579163445, "connect": 0.633605058682, "more": 0.017024931599999998, "and": 6.29901420636e-05, "correspond": 1.20141456099, "these": 0.0715336194008, "prepar": 0.8879422790620001, "benefit": 1.12116245116, "capabl": 1.2969341868100002, "amount": 0.819898886199, "workflow": 5.91136369821, "made": 0.0680215260973, "tune": 2.3434700776599997, "befor": 0.0956377718795, "lead": 0.23620402986699998, "hadoop": 7.1076144564399995, "can": 0.162341096394, "avail": 0.547454586289, "describ": 0.385447603125, "make": 0.07349765782289999, "queri": 4.03065674296, "depend": 0.806969815, "onli": 0.025324268329099998, "each": 0.173741689304, "ingest": 3.74830801649, "assess": 1.65690619935, "read": 0.83939268088, "pretti": 2.75684036527, "remain": 0.15356296309, "worri": 2.3323769785799997, "data": 1.2168205848, "oper": 0.441342964347, "perfect": 1.50096433356, "rather": 0.442714975539, "come": 0.28390990653000003, "origin": 0.128612437587, "countsbas": 7.1076144564399995, "text": 1.14048200999, "direct": 0.200705689496, "first": 0.0075872898121599995, "engin": 0.904767558276, "app": 3.57899404386, "conclus": 1.57818536893, "generat": 0.719182341736, "tool": 1.60887117963, "score": 1.4559353207700003, "movement": 0.746577724286, "year": 0.047402238894600005, "easili": 1.3066587367, "often": 0.258140393351, "down": 0.306673741186, "learn": 0.842752064745, "when": 0.0205549888584, "effici": 1.62793753414}, "freq": {"real": 1, "too": 1, "ahead": 1, "basi": 1, "form": 1, "kind": 2, "orchestr": 1, "technolog": 5, "dataset": 8, "function": 4, "client": 1, "thoma": 1, "python": 1, "join": 3, "product": 8, "done": 2, "creation": 1, "binari": 1, "their": 2, "scale": 1, "automat": 1, "absencepres": 1, "sheet": 1, "creat": 13, "how": 2, "test": 1, "bestofbre": 2, "fair": 2, "than": 2, "initi": 1, "vertica": 16, "end": 1, "lift": 1, "uncommon": 1, "interest": 1, "holist": 1, "will": 10, "associ": 2, "haven": 3, "someon": 1, "partnership": 2, "vendor": 1, "new": 5, "indic": 1, "perform": 5, "but": 3, "speed": 1, "need": 5, "our": 13, "classif": 1, "final": 2, "expect": 1, "dunnhumbi": 1, "record": 1, "applic": 5, "integr": 4, "immens": 1, "has": 1, "enough": 1, "use": 10, "sequenti": 1, "typic": 1, "out": 1, "model": 12, "good": 2, "alway": 1, "excit": 1, "under": 2, "cours": 1, "numer": 1, "categori": 2, "indatabas": 2, "togeth": 2, "view": 3, "not": 4, "newli": 1, "storag": 1, "wish": 1, "are": 14, "team": 1, "aim": 1, "logist": 1, "specif": 3, "easi": 1, "aggreg": 2, "metric": 1, "handl": 1, "then": 1, "purchas": 4, "consult": 1, "last": 1, "let": 1, "world": 2, "scienc": 4, "outcom": 1, "audiovideo": 1, "money": 1, "ensur": 1, "practic": 2, "technoslavia": 1, "simpl": 2, "algorithm": 3, "valu": 7, "offer": 3, "either": 1, "develop": 3, "such": 2, "sever": 1, "via": 2, "without": 1, "fast": 1, "box": 1, "small": 1, "both": 1, "aris": 1, "result": 1, "version": 1, "produc": 1, "filter": 2, "packaging\u2026": 1, "miss": 2, "helper": 1, "acquisit": 1, "retail": 2, "question": 1, "from": 10, "ecosystem": 2, "workload": 1, "behavior": 1, "whether": 3, "detail": 1, "num": 15, "instanc": 1, "free": 2, "environ": 1, "curv": 1, "acquir": 1, "for": 16, "difficult": 1, "predict": 9, "output": 1, "releas": 1, "fulli": 2, "with": 26, "handi": 1, "merg": 1, "speak": 1, "split": 3, "compani": 2, "frequent": 1, "preprocess": 1, "look": 2, "technic": 1, "histor": 1, "backend": 1, "veri": 3, "extract": 1, "variabl": 3, "work": 4, "combin": 3, "cloudera": 1, "column": 3, "dashboard": 1, "iter": 1, "group": 3, "doe": 1, "even": 4, "proper": 2, "train": 4, "notsoclean": 1, "avoid": 2, "step": 5, "great": 3, "move": 4, "big": 2, "type": 3, "switch": 1, "key": 2, "analyz": 1, "scientist": 1, "notebook": 1, "again": 2, "dataikucom": 1, "abov": 1, "blablacar": 1, "set": 3, "where": 1, "coeffici": 1, "buy": 1, "fortun": 1, "latest": 1, "rocket": 1, "help": 1, "strive": 1, "larg": 2, "abil": 2, "preprocessing\u2026": 1, "solut": 2, "own": 1, "base": 1, "relat": 1, "deal": 1, "fact": 1, "massiv": 1, "tableau": 2, "post": 1, "here": 2, "label": 1, "whenev": 1, "maximum": 1, "averag": 1, "script": 1, "much": 2, "closer": 1, "henc": 1, "parallel": 1, "about": 5, "problem": 1, "deploy": 1, "sensibl": 1, "thing": 1, "occas": 1, "sure": 1, "just": 2, "entir": 4, "french": 1, "thirdparti": 1, "featur": 11, "statement": 2, "them": 2, "check": 1, "pivot": 2, "dynam": 1, "across": 1, "complex": 1, "categor": 1, "plagu": 1, "start": 1, "hierarchi": 1, "run": 3, "ping": 1, "insight": 1, "globe": 1, "they": 2, "keep": 2, "fill": 1, "autom": 1, "cheat": 1, "support": 1, "abl": 2, "mani": 2, "the": 50, "fun": 1, "build": 4, "analysi": 1, "provid": 3, "calcul": 1, "schema": 1, "unfortun": 1, "demograph": 1, "recip": 5, "there": 2, "imput": 1, "endtoend": 2, "regular": 2, "inform": 1, "possibl": 2, "industri": 1, "operation": 1, "exampl": 1, "forth": 1, "spent": 1, "linkedin": 1, "visual": 4, "now": 3, "tri": 1, "dummi": 1, "code": 2, "high": 4, "regress": 1, "power": 1, "leverag": 3, "also": 7, "coupl": 1, "person": 1, "around": 2, "mean": 1, "notic": 1, "task": 1, "dataiku": 12, "may": 2, "dispar": 1, "ondemand": 3, "transact": 4, "fingertip": 1, "machin": 11, "into": 2, "system": 5, "nnum": 1, "outofthebox": 1, "partner": 2, "essenti": 1, "cabrol": 1, "attribut": 2, "actual": 2, "crucial": 1, "week": 1, "which": 5, "databas": 3, "other": 1, "one": 5, "raw": 3, "known": 1, "custom": 7, "see": 1, "some": 1, "unnecessari": 2, "get": 3, "still": 1, "like": 1, "shopper": 1, "implement": 2, "through": 1, "manag": 3, "push": 2, "file": 5, "data\u2026": 1, "process": 8, "invest": 1, "transform": 1, "analyt": 3, "recent": 1, "structur": 1, "tabl": 1, "this": 13, "choic": 1, "deepli": 1, "time": 1, "api": 1, "part": 2, "back": 1, "simplist": 1, "statist": 2, "pvalu": 1, "most": 1, "between": 2, "what": 3, "programmat": 1, "all": 4, "top": 3, "mix": 1, "store": 7, "have": 3, "suit": 1, "that": 4, "call": 1, "cluster": 1, "connect": 1, "more": 8, "and": 30, "correspond": 1, "these": 5, "prepar": 4, "benefit": 2, "capabl": 1, "amount": 2, "workflow": 4, "made": 1, "tune": 1, "befor": 1, "lead": 1, "hadoop": 1, "can": 11, "avail": 2, "describ": 2, "make": 3, "queri": 2, "depend": 1, "onli": 1, "each": 4, "ingest": 1, "assess": 2, "read": 2, "pretti": 1, "remain": 1, "worri": 2, "data": 35, "oper": 1, "perfect": 1, "rather": 1, "come": 1, "origin": 1, "countsbas": 1, "text": 2, "direct": 1, "first": 1, "engin": 3, "app": 1, "conclus": 1, "generat": 3, "tool": 2, "score": 1, "movement": 2, "year": 1, "easili": 2, "often": 1, "down": 1, "learn": 12, "when": 2, "effici": 1}, "idf": {"real": 2.28103448276, "too": 1.81585268215, "ahead": 5.625797306869999, "basi": 2.42122922068, "form": 1.12755681818, "kind": 2.5806241872599998, "orchestr": 15.2214765101, "technolog": 2.6034765496900003, "dataset": 193.609756098, "function": 2.495441685, "client": 14.1371326803, "thoma": 2.39673913043, "python": 56.2978723404, "join": 1.7922781666299998, "product": 1.62264922322, "done": 2.3302509907499998, "creation": 3.0601387818, "binari": 32.4, "their": 1.01547908405, "scale": 3.7469907953699995, "automat": 6.787516032490001, "absencepres": 1221.23076923, "sheet": 8.60954446855, "creat": 1.2492917847, "how": 1.60250328051, "test": 2.65707112971, "bestofbre": 1221.23076923, "fair": 3.20533010297, "than": 1.03278688525, "initi": 1.35, "vertica": 1221.23076923, "end": 1.10680423871, "lift": 6.37846524709, "uncommon": 14.0620017715, "interest": 1.60331246213, "holist": 74.5352112676, "will": 1.22481098596, "associ": 1.3263157894700002, "haven": 12.690647482000001, "someon": 4.9350326391, "partnership": 6.5522080066, "vendor": 27.2783505155, "new": 1.0178880554, "indic": 2.0826446281, "perform": 1.5313977042500002, "but": 1.01632417899, "speed": 3.8703071672400005, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "final": 1.34008609775, "expect": 2.20011086475, "dunnhumbi": 1221.23076923, "record": 1.42334588488, "applic": 3.42672134686, "integr": 2.8254137746900003, "immens": 12.7723250201, "has": 1.0436497502, "enough": 2.2319696330700003, "use": 1.0296387573799999, "sequenti": 39.5910224439, "typic": 2.2541530597799997, "out": 1.06016694491, "model": 2.0905978404, "good": 1.51981619759, "alway": 2.06745670009, "excit": 9.818181818180001, "under": 1.0781663837, "cours": 2.15092805853, "numer": 1.83325635104, "categori": 3.98194130926, "indatabas": 1221.23076923, "togeth": 1.58095996813, "view": 1.6407606448899998, "not": 1.01567398119, "newli": 3.1847542627900003, "storag": 8.623574144489998, "wish": 3.67755385685, "are": 1.02990593578, "team": 2.2748244734200003, "aim": 2.8960233491400005, "logist": 14.0994671403, "specif": 1.8719490626099997, "easi": 5.2937645882, "aggreg": 17.542541436500002, "metric": 22.235294117600002, "handl": 3.9229058561900003, "then": 1.08657860516, "purchas": 3.08092373375, "consult": 5.21721984883, "last": 1.2117234010100002, "let": 3.48616600791, "world": 1.11340206186, "scienc": 2.31969608416, "outcom": 7.48867924528, "audiovideo": 1221.23076923, "money": 2.62283165373, "ensur": 3.4127257093700005, "practic": 1.70434782609, "technoslavia": 1221.23076923, "simpl": 3.3981164383599998, "algorithm": 27.9507042254, "valu": 2.2777618364400003, "offer": 1.53896859248, "either": 1.5830092731099998, "develop": 1.1955719557200002, "such": 1.06151377374, "sever": 1.07241286139, "via": 2.2978723404299997, "without": 1.29547123623, "fast": 4.8729281768, "box": 4.12685209254, "small": 1.3594793629, "both": 1.05215720061, "aris": 7.54921540656, "result": 1.14611608432, "version": 2.0083491461099996, "produc": 1.36932896326, "filter": 16.8893617021, "packaging\u2026": 1221.23076923, "miss": 3.53664513255, "helper": 79.38, "acquisit": 10.3764705882, "retail": 8.78097345133, "question": 2.20408163265, "from": 1.00056721497, "ecosystem": 26.111842105300003, "workload": 74.5352112676, "behavior": 5.52978056426, "whether": 2.20683903253, "detail": 2.26186066391, "num": 1.00031504001, "instanc": 3.2572835453400004, "free": 1.71818181818, "environ": 3.43561999567, "curv": 11.1098670399, "acquir": 3.10563380282, "for": 1.00031504001, "difficult": 2.48957189901, "predict": 5.18484650555, "output": 7.676982591880001, "releas": 1.8377126982299998, "fulli": 2.79015817223, "with": 1.0011982089899998, "handi": 102.425806452, "merg": 5.28319467554, "speak": 2.89127663449, "split": 3.4709226060300002, "compani": 1.5523613963, "frequent": 2.10501193317, "preprocess": 1221.23076923, "look": 1.9086318826599997, "technic": 3.1400316455699997, "histor": 1.6755672823199999, "backend": 933.882352941, "veri": 1.25880114177, "extract": 7.703056768560001, "variabl": 8.747107438019999, "work": 1.11520089913, "combin": 1.69760479042, "cloudera": 1221.23076923, "column": 7.078020508250001, "dashboard": 118.47761194, "iter": 37.4433962264, "group": 1.20996875238, "doe": 1.70581282905, "even": 1.16461267606, "proper": 3.3388012618299996, "train": 1.9365698950999999, "notsoclean": 1221.23076923, "avoid": 2.45986984816, "step": 2.8279301745599996, "great": 1.26592775696, "move": 1.29125660838, "big": 2.7400759406299997, "type": 2.0281042411900003, "switch": 4.97368421053, "key": 2.28005170185, "analyz": 9.68639414277, "scientist": 4.69426374926, "notebook": 40.1924050633, "again": 1.50883862384, "dataikucom": 1221.23076923, "abov": 1.90382539873, "blablacar": 1221.23076923, "set": 1.18707940781, "where": 1.06715063521, "coeffici": 36.4965517241, "buy": 5.12459651388, "fortun": 6.211267605630001, "latest": 7.078020508250001, "rocket": 12.403125, "help": 1.39962972759, "strive": 21.9585062241, "larg": 1.18574949585, "abil": 2.70875277256, "preprocessing\u2026": 1221.23076923, "solut": 4.7278141751, "own": 1.17844418052, "base": 1.14628158845, "relat": 1.23750876919, "deal": 2.18346857379, "fact": 1.73375559681, "massiv": 4.22571200426, "tableau": 244.246153846, "post": 2.23826307627, "here": 2.42307692308, "label": 4.47715736041, "whenev": 11.622254758399999, "maximum": 4.80072573329, "averag": 2.60390355913, "script": 8.299006795610001, "much": 1.1942229577299999, "closer": 5.5666199158500005, "henc": 5.390831918509999, "parallel": 4.57917507932, "about": 1.06486015159, "problem": 1.76674827509, "deploy": 7.41869158879, "sensibl": 24.164383561599998, "thing": 2.4065484311099996, "occas": 3.68780487805, "sure": 7.453521126760001, "just": 1.33580143037, "entir": 1.59365589239, "french": 2.11962616822, "thirdparti": 1221.23076923, "featur": 1.52712581762, "statement": 3.42228928648, "them": 1.09876115994, "check": 6.50655737705, "pivot": 17.798206278, "dynam": 6.52527743527, "across": 1.7318642958400001, "complex": 2.34021226415, "categor": 15.0198675497, "plagu": 11.086592178800002, "start": 1.26673581744, "hierarchi": 14.3285198556, "run": 1.55692850838, "ping": 110.25, "insight": 11.8037174721, "globe": 8.25155925156, "they": 1.03017325287, "keep": 2.04245465071, "fill": 3.33809924306, "autom": 19.8202247191, "cheat": 31.6886227545, "support": 1.2685577307200002, "abl": 1.8208510150200001, "mani": 1.04426757877, "the": 1.0, "fun": 12.8863636364, "build": 1.6341739578, "analysi": 3.47852760736, "provid": 1.21552714187, "calcul": 6.12972972973, "schema": 111.802816901, "unfortun": 9.966101694919999, "demograph": 10.851674641099999, "recip": 42.9081081081, "there": 1.04091266719, "imput": 178.38202247200002, "endtoend": 1221.23076923, "regular": 2.09418282548, "inform": 1.5753125620200001, "possibl": 1.4173734488, "industri": 2.02319357716, "operation": 453.6, "exampl": 1.50483412322, "forth": 8.65177111717, "spent": 3.00795755968, "linkedin": 610.615384615, "visual": 5.22752716497, "now": 1.160780873, "tri": 1.8544562551099997, "dummi": 48.1090909091, "code": 3.8807137619199996, "high": 1.14777327935, "regress": 51.2129032258, "power": 1.3396337861799998, "leverag": 35.7567567568, "also": 1.01476510067, "coupl": 3.2572835453400004, "person": 1.40520446097, "around": 1.21394708671, "mean": 1.44906900329, "notic": 4.36994219653, "task": 3.88641370869, "dataiku": 1221.23076923, "may": 1.05201775893, "dispar": 22.583214793699998, "ondemand": 1221.23076923, "transact": 11.892134831500002, "fingertip": 226.8, "machin": 4.02433460076, "into": 1.01502461479, "system": 1.38739840951, "nnum": 39.8894472362, "outofthebox": 1221.23076923, "partner": 4.173501577290001, "essenti": 2.9280708225700005, "cabrol": 1221.23076923, "attribut": 3.4156626506, "actual": 1.87482286254, "crucial": 7.7443902439, "week": 1.80532181033, "which": 1.005191845, "databas": 8.24727272727, "other": 1.00992366412, "one": 1.00627495722, "raw": 10.6478873239, "known": 1.0859097127200001, "custom": 3.6346153846199996, "see": 1.27242125511, "some": 1.04036697248, "unnecessari": 17.4845814978, "get": 1.78562591385, "still": 1.1866357724799999, "like": 1.14918566775, "shopper": 89.19101123600001, "implement": 3.57648118946, "through": 1.07074930869, "manag": 1.6448404475799998, "push": 3.75141776938, "file": 3.7710213776699995, "data\u2026": 1221.23076923, "process": 1.69524826482, "invest": 4.16146788991, "transform": 3.42007755278, "analyt": 17.256521739100002, "recent": 1.54405757635, "structur": 2.0580762250499998, "tabl": 3.82093862816, "this": 1.00379362671, "choic": 3.1319786940200003, "deepli": 7.9063745019899985, "time": 1.01127460348, "api": 84.44680851060001, "part": 1.04330682789, "back": 1.26070038911, "simplist": 72.16363636359999, "statist": 4.24265098878, "pvalu": 1221.23076923, "most": 1.02096463023, "between": 1.03453668708, "what": 1.25343439128, "programmat": 214.54054054099998, "all": 1.01146788991, "top": 1.8387769284200002, "mix": 2.7852631578900002, "store": 3.44680851064, "have": 1.0148948411399998, "suit": 3.92873051225, "that": 1.00398406375, "call": 1.0676529926, "cluster": 12.5007874016, "connect": 1.8843916913900003, "more": 1.0171706817, "and": 1.00006299213, "correspond": 3.32481675393, "these": 1.07415426252, "prepar": 2.43012398592, "benefit": 3.06841901817, "capabl": 3.6580645161300005, "amount": 2.27027027027, "workflow": 369.209302326, "made": 1.07038834951, "tune": 10.4173228346, "befor": 1.10036041031, "lead": 1.2664326739, "hadoop": 1221.23076923, "can": 1.17626139142, "avail": 1.7288467821, "describ": 1.47027227264, "make": 1.0762660158600001, "queri": 56.2978723404, "depend": 2.2411067193700003, "onli": 1.0256476516600002, "each": 1.18974820144, "ingest": 42.449197861, "assess": 5.24306472919, "read": 2.3149606299200003, "pretti": 15.75, "remain": 1.16598119859, "worri": 10.302401038300001, "data": 3.37643555934, "oper": 1.55479384977, "perfect": 4.48601299802, "rather": 1.55692850838, "come": 1.32831325301, "origin": 1.13724928367, "countsbas": 1221.23076923, "text": 3.12827586207, "direct": 1.22226499346, "first": 1.00761614623, "engin": 2.47135740971, "app": 35.837471783299996, "conclus": 4.84615384615, "generat": 2.05275407292, "tool": 4.99716713881, "score": 4.2884927066500005, "movement": 2.10976744186, "year": 1.0485436893200002, "easili": 3.6938110749199997, "often": 1.29452054795, "down": 1.35889754344, "learn": 2.32275054865, "when": 1.02076769755, "effici": 5.09335899904}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Predicting purchases at retail stores using HPE Vertica and Dataiku DSS</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/06/dataiku-predicting-purchases-retail-stores-hpe-vertica.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Predicting purchases at retail stores using HPE Vertica and Dataiku DSS Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/06/top-tweets-jun15-21.html\" rel=\"prev\" title=\"Top KDnuggets tweets, Jun 15-21: Predicting UEFA Euro2016; Visual Explanation of Backprop for Neural Nets\"/>\n<link href=\"https://www.kdnuggets.com/2016/06/achieving-security-apache-spark-databricks.html\" rel=\"next\" title=\"Achieving End-to-end Security for Apache Spark with Databricks\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/06/dataiku-predicting-purchases-retail-stores-hpe-vertica.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=51492\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/06/dataiku-predicting-purchases-retail-stores-hpe-vertica.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-51492 single-format-standard post-template post-template-fullwidth-php\">\n<div class=\"main_wrapper\"><!-- publ: 23-Jun, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/06/software.html\">Software</a> \u00bb Predicting purchases at retail stores using HPE Vertica and Dataiku DSS (\u00a0<a href=\"/2016/n23.html\">16:n23</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Predicting purchases at retail stores using HPE Vertica and Dataiku DSS</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/06/top-tweets-jun15-21.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/06/achieving-security-apache-spark-databricks.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/dataiku\" rel=\"tag\">Dataiku</a>, <a href=\"https://www.kdnuggets.com/tag/hpe\" rel=\"tag\">HPE</a>, <a href=\"https://www.kdnuggets.com/tag/retail\" rel=\"tag\">Retail</a>, <a href=\"https://www.kdnuggets.com/tag/vertica\" rel=\"tag\">Vertica</a></div>\n<br/>\n<p class=\"excerpt\">\n     The retail industry has been data centric for a while. With the rise of loyalty programs and digital touch points, retailers have been able to collect more and more data about their customers over time, opening up the ability to create better personalized marketing offers and promotions.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By Thomas Cabrol, Dataiku</b>.</p>\n<p>I was pretty excited to read that our partner <a href=\"http://community.hpe.com/t5/Big-Data/Machine-Learning-with-Vertica/ba-p/6850825#.VymnMaOLTcM\" target=\"_blank\">HPE recently added machine learning capabilities to its Vertica database</a>. As MPP (<a href=\"http://whatis.techtarget.com/definition/MPP-massively-parallel-processing\" target=\"_blank\">massively parallel processing</a>) systems are fairly frequent in the retail world, it is a good occasion to try building the kind of application described above with a best-of-breed technology combined with <a href=\"/dss/\">Dataiku DSS</a>!</p>\n<h3>So What Did I Build?</h3>\n<p>Actually, a <strong>predictive application managed by Dataiku DSS</strong> and <strong>running entirely on top of Vertica</strong>. This is a end-to-end data workflow starting from acquiring raw data acquisition to training a machine learning model, aiming at <strong>predicting whether or not a customer is going to make a purchase in a specific product category</strong>:</p>\n<p class=\"text-center zoomable\"><img alt=\"predictive application as a workflow in Dataiku DSS\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/workflow-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/workflow-original.jpg\" width=\"99%\"/></p>\n<h3>The Supporting Data</h3>\n<p>The data are <a href=\"https://www.dunnhumby.com/sourcefiles\" target=\"_blank\">provided</a> by <a href=\"https://www.linkedin.com/company/6608\" target=\"_blank\">dunnhumby</a>, a leading customer science company providing data and insights from shoppers across the globe. These are typical datasets from the retail industry:</p>\n<ul class=\"three_ul\">\n<li>a file storing 2 years of transactions, with information about customers, products, time, store, and amount</li>\n<li>a file storing demographics about the customers</li>\n<li>a file storing product attributes : product hierarchy, packaging\u2026</li>\n</ul>\n<p class=\"text-center zoomable\"><img alt=\"retail transactions dataset displayed in Dataiku DSS\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/retail-transactions-dataset-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/retail-transactions-dataset-800.jpg\" width=\"99%\"/></p>\n<h3>The Data Science process:</h3>\n<h4>1. Data ingestion</h4>\n<p>As we are going to use Vertica both for storing and processing our data, the very step is, of course, to <strong>push these data into Vertica</strong>. That\u2019s not rocket science with DSS: just create the DSS datasets from your raw data files, make them looking good using a Visual Data Preparation script if you wish, create a new output dataset stored in Vertica, and run your recipe. That\u2019s it. Your data are in Vertica. No coding, no SQL, no worries about how to move data around or how to handle schemas and data types: <strong>Dataiku DSS does it all automatically for you</strong>. Great, isn\u2019t it ?</p>\n<p class=\"text-center zoomable\"><img alt=\"loading data into HPE Vertica automatically from Dataiku DSS\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/loading-data-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/loading-data-800.jpg\" width=\"99%\"/></p>\n<h4>2. Data preparation</h4>\n<p>The files are disparate, have unnecessary data\u2026 <strong>With Dataiku DSS, we can easily join, filter, split datasets together using visual recipes, with no need to code</strong>. So what do we do now ? We first merge the 3 initial datasets (transactions, products, and customers) all together to get an holistic view of the purchase behavior (with the mean of a Join recipe), then we split the newly created datasets in 2, with a Split recipe: one part will be used to create the features or variables for our predictive model, based on historical transactions data; and the other one will be used to create the \u201clabels\u201d, a simple new column indicating whether or not the person will purchase specific products in coming weeks. <strong>All these data management tasks will be performed by the underlying Vertica database</strong> whenever it is possible to avoid data movement and benefit from its speed.</p>\n<p class=\"text-center zoomable\"><img alt=\" joining 2 Dataiku DSS datasets by leveraging HPE Vertica\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/joining-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/joining-800.jpg\" width=\"99%\"/></p>\n<h4>3. Features engineering</h4>\n<p>The <strong>data are still too raw</strong> to be used by machine learning algorithms directly. We need to switch from the detailed \u201ctransactional\u201d view to an \u201canalytical\u201d view, where the data will be aggregated to form a large set of attributes (\u201cfeatures\u201d, or variables) describing each customer. <strong>This step is crucial and one of the most difficult</strong> when creating a machine learning model, known as features engineering. Technically speaking, when working with a SQL database, this will be essentially a combination of group by / pivot operations \u2026 . Fortunately enough, with Dataiku DSS you can <strong>either use \u201cvisual grouping\u201d recipes to generate your SQL statements, or programmatically create much more complex queries using helper Python functions</strong>. So let\u2019s move ahead and generate this aggregated dataset (which ends up with more than 340 columns !) by combining simple counts-based features and the money spent for each type of product:</p>\n<p class=\"text-center zoomable\"><img alt=\"features engineering in Dataiku DSS and HPE Vertica\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/features-engineering-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/features-engineering-800.jpg\" width=\"99%\"/></p>\n<h4>4. Data preprocessing for machine learning</h4>\n<p>We\u2019re getting closer to our machine learning model. Actually, there is one remaining step: <strong>many ML algorithm implementations expect numeric only features with no missing values</strong>. This is <strong>unfortunately very uncommon in practice</strong> as we often need to deal with not-so-clean, mixed data types. So in this step, we are going to impute missing values with a sensible value (averages) \u2013 even if this is always questionable, and transforming each categorical (text) feature into a set of \u201cdummy\u201d variables (if a feature has n possible values, we will create n-1 new columns filled with 0/1 depending on the absence/presence of the value). Again, Dataiku DSS helps automating this process by offering the ability to generate dynamically the corresponding SQL statements.</p>\n<h4>5. Model creation</h4>\n<p>We can finally do ML now :) And test the new Machine Learning for Predictive Analytics functionality <a href=\"https://my.vertica.com/docs/7.2.x/HTML/index.htm#Authoring/MachineLearning/MachineLearning.htm%3FTocPath%3DAnalyzing%2520Data%7CMachine%2520Learning%2520for%2520Predictive%2520Analytics%7C_____0\" target=\"_blanc\">released with the latest 7.2.2 version of Vertica</a>. <strong>Training, storing and getting statistics from your machine learning model is as easy as 2 queries</strong>:</p>\n<p class=\"text-center\"><img alt=\"training machine learning models in HPE Vertica from Dataiku DSS\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/training-original.png\" width=\"99%\"/></p>\n<p>As we are predicting whether or not someone will buy from a specific product category, we have a classification problem (with a binary outcome), <strong>hence the choice of <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" target=\"_blank\">logistic regression</a>, which is available out of the box for Vertica</strong>. Training the model is done entirely in-database, with no need to move data around!</p>\n<h4>6. Model assessment &amp; deployment</h4>\n<p>This is our last step. Using the statistics created by Vertica, we can easily see and analyze the <strong>coefficients and associated p-values for each feature</strong> of our model. As this is a regular DSS dataset, you are also free to keep on building your workflow from there (for instance by doing <a href=\"http://doc.dataiku.com/dss/latest/scenarios/checks.html\">Checks</a> / Metrics analysis). Vertica provides also with a set of handy functions to <strong>assess model performances via ROC or lift curves</strong>, which can be leveraged via DSS SQL Notebooks. Finally, the results can also be operationalized by using the model to <strong>score new records on a regular basis, done again fully in-database</strong>.</p>\n<p class=\"text-center zoomable\"><img alt=\"in-database scoring\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/scoring-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/scoring-800.jpg\" width=\"99%\"/></p>\n<h3>Conclusion</h3>\n<p>This is it, we now have a <strong>functional workflow orchestrated by DSS and running on top of Vertica to produce the purchase predictions</strong>, even if rather simplistic.</p>\n<p>Creating such predictive applications is much more than training machine learning algorithms \u2013 which is in fact just a fairly small amount of work in the entire process. Data preparation, features engineering, preprocessing\u2026 : these are some of the many things to do before being able to move to the \u201creal fun\u201d of ML. Even it may look like a sequential process through this post, it is in practice highly iterative. __Data preparation and machine learning are deeply coupled, and DSS offers the immense benefit to be able to create the entire data science workflow in an integrated environment, with no need to go back and forth between several tools.</p>\n<p>As Big Data arise, and best-of-breed technologies to manage them are made available (<a href=\"http://www.dataiku.com/blog/2015/11/19/technoslavia.html\">this what we call Technoslavia at Dataiku</a>), <strong>Dataiku DSS offers integrations with third-party solutions</strong> to make sure they can be properly leveraged. A key feature is the ability <strong>to push down calculations and processing to underlying, high performance system such as HPE Vertica</strong>, which will avoid unnecessary data movements between systems and tools (one of the plagues in the Big Data world). Vertica is also perfectly suited for the kind of workloads on structured data created by DSS : data scientists can join, filter, group or pivot their data without worrying about tuning the system for performance and model tables properly, it will work fast out-of-the-box. <strong>The association is powerful: Vertica as a high performance backend to predictive applications developed in Dataiku DSS</strong>.</p>\n<p>Working with our ecosystem is key to us, but even more for our clients as they can fully leverage their technological investments by creating high value predictive applications more efficiently. <a href=\"https://www.blablacar.fr/\" target=\"_blank\">Blablacar</a> is a great example, as you may read about <a href=\"http://www.silicon.fr/big-data-blablacar-copilote-sa-bi-avec-hp-tableau-et-dataiku-105060.html\" target=\"_blank\">here</a> (in French) or <a href=\"http://www8.hp.com/us/en/hp-news/press-release.html?id=1837819#.Vyma7qOLTcN\" target=\"_blank\">here</a>. Did you notice? <strong>It\u2019s Vertica + Dataiku DSS</strong>, but also <a href=\"http://www.tableau.com/partners/technology\" target=\"_blank\">Tableau</a> Tableau for data visualization and dashboarding, and a <a href=\"http://www.cloudera.com/partners/partners-listing.html\" target=\"_blank\">Cloudera</a> Hadoop cluster for very large scale storage and data processing. <strong>Dataiku is also a technology partner</strong> of all of these great vendors, so we can ensure maximum value for our customers.</p>\n<p>We strive to keep on being more and more integrated with our ecosystem, but also to develop our partnerships with system integrators and consulting companies that can implement end-to-end data solutions on top of our technologies, so if you are interested to learn more, connect with me on LinkedIn or ping our team at <a href=\"mailto:partnerships@dataiku.com\">partnerships@dataiku.com</a>!</p>\n<p><a href=\"http://www.dataiku.com/blog/2016/05/17/predicting-purchases-at-retail-store-using-HPE-vertica-and-dataiku-dss.html \">Original</a>.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2016/06/build-your-own-audio-video-analytics-hpe-haven-ondemand-part-1.html\" target=\"_blank\">Build Your Own Audio/Video Analytics App With HPE Haven OnDemand \u2013 Part 1</a></li>\n<li><a href=\"/2016/06/hpe-haven-ondemand-text-extraction-cheat-sheet.html\" target=\"_blank\">HPE Haven OnDemand Text Extraction API Cheat Sheet for Developers</a></li>\n<li><a href=\"/2016/02/hpe-machine-learning-60-apis-haven-ondemand.html\" target=\"_blank\">Machine Learning at your fingertips \u2013 60+ free APIs, from HPE Haven OnDemand</a></li>\n</ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/06/top-tweets-jun15-21.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/06/achieving-security-apache-spark-databricks.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/06/software.html\">Software</a> \u00bb Predicting purchases at retail stores using HPE Vertica and Dataiku DSS (\u00a0<a href=\"/2016/n23.html\">16:n23</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556321125\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.717 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 19:25:25 -->\n<!-- Compression = gzip -->", "content_tokenized": ["thoma", "cabrol", "dataiku", "pretti", "excit", "read", "that", "our", "partner", "recent", "machin", "learn", "capabl", "vertica", "databas", "massiv", "parallel", "process", "system", "are", "fair", "frequent", "the", "retail", "world", "good", "occas", "tri", "build", "the", "kind", "applic", "describ", "abov", "with", "bestofbre", "technolog", "combin", "with", "dataiku", "what", "build", "actual", "predict", "applic", "manag", "dataiku", "and", "run", "entir", "top", "vertica", "this", "endtoend", "data", "workflow", "start", "from", "acquir", "raw", "data", "acquisit", "train", "machin", "learn", "model", "aim", "predict", "whether", "not", "custom", "make", "purchas", "specif", "product", "categori", "the", "support", "data", "the", "data", "are", "provid", "dunnhumbi", "lead", "custom", "scienc", "compani", "provid", "data", "and", "insight", "from", "shopper", "across", "the", "globe", "these", "are", "typic", "dataset", "from", "the", "retail", "industri", "file", "store", "num", "year", "transact", "with", "inform", "about", "custom", "product", "time", "store", "and", "amount", "file", "store", "demograph", "about", "the", "custom", "file", "store", "product", "attribut", "product", "hierarchi", "packaging\u2026", "the", "data", "scienc", "process", "num", "data", "ingest", "are", "use", "vertica", "both", "for", "store", "and", "process", "our", "data", "the", "veri", "step", "cours", "push", "these", "data", "into", "vertica", "that", "not", "rocket", "scienc", "with", "just", "creat", "the", "dataset", "from", "raw", "data", "file", "make", "them", "look", "good", "use", "visual", "data", "prepar", "script", "wish", "creat", "new", "output", "dataset", "store", "vertica", "and", "run", "recip", "that", "data", "are", "vertica", "code", "worri", "about", "how", "move", "data", "around", "how", "handl", "schema", "and", "data", "type", "dataiku", "doe", "all", "automat", "for", "great", "num", "data", "prepar", "the", "file", "are", "dispar", "have", "unnecessari", "data\u2026", "with", "dataiku", "can", "easili", "join", "filter", "split", "dataset", "togeth", "use", "visual", "recip", "with", "need", "code", "what", "now", "first", "merg", "the", "num", "initi", "dataset", "transact", "product", "and", "custom", "all", "togeth", "get", "holist", "view", "the", "purchas", "behavior", "with", "the", "mean", "join", "recip", "then", "split", "the", "newli", "creat", "dataset", "num", "with", "split", "recip", "one", "part", "will", "use", "creat", "the", "featur", "variabl", "for", "our", "predict", "model", "base", "histor", "transact", "data", "and", "the", "other", "one", "will", "use", "creat", "the", "label", "simpl", "new", "column", "indic", "whether", "not", "the", "person", "will", "purchas", "specif", "product", "come", "week", "all", "these", "data", "manag", "task", "will", "perform", "the", "under", "vertica", "databas", "whenev", "possibl", "avoid", "data", "movement", "and", "benefit", "from", "speed", "num", "featur", "engin", "the", "data", "are", "still", "too", "raw", "use", "machin", "learn", "algorithm", "direct", "need", "switch", "from", "the", "detail", "transact", "view", "analyt", "view", "where", "the", "data", "will", "aggreg", "form", "larg", "set", "attribut", "featur", "variabl", "describ", "each", "custom", "this", "step", "crucial", "and", "one", "the", "most", "difficult", "when", "creat", "machin", "learn", "model", "known", "featur", "engin", "technic", "speak", "when", "work", "with", "databas", "this", "will", "essenti", "combin", "group", "pivot", "oper", "fortun", "enough", "with", "dataiku", "can", "either", "use", "visual", "group", "recip", "generat", "statement", "programmat", "creat", "much", "more", "complex", "queri", "use", "helper", "python", "function", "let", "move", "ahead", "and", "generat", "this", "aggreg", "dataset", "which", "end", "with", "more", "than", "num", "column", "combin", "simpl", "countsbas", "featur", "and", "the", "money", "spent", "for", "each", "type", "product", "num", "data", "preprocess", "for", "machin", "learn", "get", "closer", "our", "machin", "learn", "model", "actual", "there", "one", "remain", "step", "mani", "algorithm", "implement", "expect", "numer", "onli", "featur", "with", "miss", "valu", "this", "unfortun", "veri", "uncommon", "practic", "often", "need", "deal", "with", "notsoclean", "mix", "data", "type", "this", "step", "are", "imput", "miss", "valu", "with", "sensibl", "valu", "averag", "even", "this", "alway", "question", "and", "transform", "each", "categor", "text", "featur", "into", "set", "dummi", "variabl", "featur", "has", "possibl", "valu", "will", "creat", "nnum", "new", "column", "fill", "with", "num", "depend", "the", "absencepres", "the", "valu", "again", "dataiku", "help", "autom", "this", "process", "offer", "the", "abil", "generat", "dynam", "the", "correspond", "statement", "num", "model", "creation", "can", "final", "now", "and", "test", "the", "new", "machin", "learn", "for", "predict", "analyt", "function", "releas", "with", "the", "latest", "num", "version", "vertica", "train", "store", "and", "get", "statist", "from", "machin", "learn", "model", "easi", "num", "queri", "are", "predict", "whether", "not", "someon", "will", "buy", "from", "specif", "product", "categori", "have", "classif", "problem", "with", "binari", "outcom", "henc", "the", "choic", "logist", "regress", "which", "avail", "out", "the", "box", "for", "vertica", "train", "the", "model", "done", "entir", "indatabas", "with", "need", "move", "data", "around", "num", "model", "assess", "deploy", "this", "our", "last", "step", "use", "the", "statist", "creat", "vertica", "can", "easili", "see", "and", "analyz", "the", "coeffici", "and", "associ", "pvalu", "for", "each", "featur", "our", "model", "this", "regular", "dataset", "are", "also", "free", "keep", "build", "workflow", "from", "there", "for", "instanc", "check", "metric", "analysi", "vertica", "provid", "also", "with", "set", "handi", "function", "assess", "model", "perform", "via", "lift", "curv", "which", "can", "leverag", "via", "notebook", "final", "the", "result", "can", "also", "operation", "use", "the", "model", "score", "new", "record", "regular", "basi", "done", "again", "fulli", "indatabas", "conclus", "this", "now", "have", "function", "workflow", "orchestr", "and", "run", "top", "vertica", "produc", "the", "purchas", "predict", "even", "rather", "simplist", "creat", "such", "predict", "applic", "much", "more", "than", "train", "machin", "learn", "algorithm", "which", "fact", "just", "fair", "small", "amount", "work", "the", "entir", "process", "data", "prepar", "featur", "engin", "preprocessing\u2026", "these", "are", "some", "the", "mani", "thing", "befor", "abl", "move", "the", "real", "fun", "even", "may", "look", "like", "sequenti", "process", "through", "this", "post", "practic", "high", "iter", "data", "prepar", "and", "machin", "learn", "are", "deepli", "coupl", "and", "offer", "the", "immens", "benefit", "abl", "creat", "the", "entir", "data", "scienc", "workflow", "integr", "environ", "with", "need", "back", "and", "forth", "between", "sever", "tool", "big", "data", "aris", "and", "bestofbre", "technolog", "manag", "them", "are", "made", "avail", "this", "what", "call", "technoslavia", "dataiku", "dataiku", "offer", "integr", "with", "thirdparti", "solut", "make", "sure", "they", "can", "proper", "leverag", "key", "featur", "the", "abil", "push", "down", "calcul", "and", "process", "under", "high", "perform", "system", "such", "vertica", "which", "will", "avoid", "unnecessari", "data", "movement", "between", "system", "and", "tool", "one", "the", "plagu", "the", "big", "data", "world", "vertica", "also", "perfect", "suit", "for", "the", "kind", "workload", "structur", "data", "creat", "data", "scientist", "can", "join", "filter", "group", "pivot", "their", "data", "without", "worri", "about", "tune", "the", "system", "for", "perform", "and", "model", "tabl", "proper", "will", "work", "fast", "outofthebox", "the", "associ", "power", "vertica", "high", "perform", "backend", "predict", "applic", "develop", "dataiku", "work", "with", "our", "ecosystem", "key", "but", "even", "more", "for", "our", "client", "they", "can", "fulli", "leverag", "their", "technolog", "invest", "creat", "high", "valu", "predict", "applic", "more", "effici", "blablacar", "great", "exampl", "may", "read", "about", "here", "french", "here", "notic", "vertica", "dataiku", "but", "also", "tableau", "tableau", "for", "data", "visual", "and", "dashboard", "and", "cloudera", "hadoop", "cluster", "for", "veri", "larg", "scale", "storag", "and", "data", "process", "dataiku", "also", "technolog", "partner", "all", "these", "great", "vendor", "can", "ensur", "maximum", "valu", "for", "our", "custom", "strive", "keep", "more", "and", "more", "integr", "with", "our", "ecosystem", "but", "also", "develop", "our", "partnership", "with", "system", "integr", "and", "consult", "compani", "that", "can", "implement", "endtoend", "data", "solut", "top", "our", "technolog", "are", "interest", "learn", "more", "connect", "with", "linkedin", "ping", "our", "team", "partnership", "dataikucom", "origin", "relat", "build", "own", "audiovideo", "analyt", "app", "with", "haven", "ondemand", "part", "num", "haven", "ondemand", "text", "extract", "cheat", "sheet", "for", "develop", "machin", "learn", "fingertip", "num", "free", "api", "from", "haven", "ondemand"], "timestamp_scraper": 1556367979.518949, "title": "Predicting purchases at retail stores using HPE Vertica and Dataiku DSS", "read_time": 425.09999999999997, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By Thomas Cabrol, Dataiku</b>.</p>\n<p>I was pretty excited to read that our partner <a href=\"http://community.hpe.com/t5/Big-Data/Machine-Learning-with-Vertica/ba-p/6850825#.VymnMaOLTcM\" target=\"_blank\">HPE recently added machine learning capabilities to its Vertica database</a>. As MPP (<a href=\"http://whatis.techtarget.com/definition/MPP-massively-parallel-processing\" target=\"_blank\">massively parallel processing</a>) systems are fairly frequent in the retail world, it is a good occasion to try building the kind of application described above with a best-of-breed technology combined with <a href=\"/dss/\">Dataiku DSS</a>!</p>\n<h3>So What Did I Build?</h3>\n<p>Actually, a <strong>predictive application managed by Dataiku DSS</strong> and <strong>running entirely on top of Vertica</strong>. This is a end-to-end data workflow starting from acquiring raw data acquisition to training a machine learning model, aiming at <strong>predicting whether or not a customer is going to make a purchase in a specific product category</strong>:</p>\n<p class=\"text-center zoomable\"><img alt=\"predictive application as a workflow in Dataiku DSS\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/workflow-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/workflow-original.jpg\" width=\"99%\"/></p>\n<h3>The Supporting Data</h3>\n<p>The data are <a href=\"https://www.dunnhumby.com/sourcefiles\" target=\"_blank\">provided</a> by <a href=\"https://www.linkedin.com/company/6608\" target=\"_blank\">dunnhumby</a>, a leading customer science company providing data and insights from shoppers across the globe. These are typical datasets from the retail industry:</p>\n<ul class=\"three_ul\">\n<li>a file storing 2 years of transactions, with information about customers, products, time, store, and amount</li>\n<li>a file storing demographics about the customers</li>\n<li>a file storing product attributes : product hierarchy, packaging\u2026</li>\n</ul>\n<p class=\"text-center zoomable\"><img alt=\"retail transactions dataset displayed in Dataiku DSS\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/retail-transactions-dataset-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/retail-transactions-dataset-800.jpg\" width=\"99%\"/></p>\n<h3>The Data Science process:</h3>\n<h4>1. Data ingestion</h4>\n<p>As we are going to use Vertica both for storing and processing our data, the very step is, of course, to <strong>push these data into Vertica</strong>. That\u2019s not rocket science with DSS: just create the DSS datasets from your raw data files, make them looking good using a Visual Data Preparation script if you wish, create a new output dataset stored in Vertica, and run your recipe. That\u2019s it. Your data are in Vertica. No coding, no SQL, no worries about how to move data around or how to handle schemas and data types: <strong>Dataiku DSS does it all automatically for you</strong>. Great, isn\u2019t it ?</p>\n<p class=\"text-center zoomable\"><img alt=\"loading data into HPE Vertica automatically from Dataiku DSS\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/loading-data-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/loading-data-800.jpg\" width=\"99%\"/></p>\n<h4>2. Data preparation</h4>\n<p>The files are disparate, have unnecessary data\u2026 <strong>With Dataiku DSS, we can easily join, filter, split datasets together using visual recipes, with no need to code</strong>. So what do we do now ? We first merge the 3 initial datasets (transactions, products, and customers) all together to get an holistic view of the purchase behavior (with the mean of a Join recipe), then we split the newly created datasets in 2, with a Split recipe: one part will be used to create the features or variables for our predictive model, based on historical transactions data; and the other one will be used to create the \u201clabels\u201d, a simple new column indicating whether or not the person will purchase specific products in coming weeks. <strong>All these data management tasks will be performed by the underlying Vertica database</strong> whenever it is possible to avoid data movement and benefit from its speed.</p>\n<p class=\"text-center zoomable\"><img alt=\" joining 2 Dataiku DSS datasets by leveraging HPE Vertica\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/joining-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/joining-800.jpg\" width=\"99%\"/></p>\n<h4>3. Features engineering</h4>\n<p>The <strong>data are still too raw</strong> to be used by machine learning algorithms directly. We need to switch from the detailed \u201ctransactional\u201d view to an \u201canalytical\u201d view, where the data will be aggregated to form a large set of attributes (\u201cfeatures\u201d, or variables) describing each customer. <strong>This step is crucial and one of the most difficult</strong> when creating a machine learning model, known as features engineering. Technically speaking, when working with a SQL database, this will be essentially a combination of group by / pivot operations \u2026 . Fortunately enough, with Dataiku DSS you can <strong>either use \u201cvisual grouping\u201d recipes to generate your SQL statements, or programmatically create much more complex queries using helper Python functions</strong>. So let\u2019s move ahead and generate this aggregated dataset (which ends up with more than 340 columns !) by combining simple counts-based features and the money spent for each type of product:</p>\n<p class=\"text-center zoomable\"><img alt=\"features engineering in Dataiku DSS and HPE Vertica\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/features-engineering-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/features-engineering-800.jpg\" width=\"99%\"/></p>\n<h4>4. Data preprocessing for machine learning</h4>\n<p>We\u2019re getting closer to our machine learning model. Actually, there is one remaining step: <strong>many ML algorithm implementations expect numeric only features with no missing values</strong>. This is <strong>unfortunately very uncommon in practice</strong> as we often need to deal with not-so-clean, mixed data types. So in this step, we are going to impute missing values with a sensible value (averages) \u2013 even if this is always questionable, and transforming each categorical (text) feature into a set of \u201cdummy\u201d variables (if a feature has n possible values, we will create n-1 new columns filled with 0/1 depending on the absence/presence of the value). Again, Dataiku DSS helps automating this process by offering the ability to generate dynamically the corresponding SQL statements.</p>\n<h4>5. Model creation</h4>\n<p>We can finally do ML now :) And test the new Machine Learning for Predictive Analytics functionality <a href=\"https://my.vertica.com/docs/7.2.x/HTML/index.htm#Authoring/MachineLearning/MachineLearning.htm%3FTocPath%3DAnalyzing%2520Data%7CMachine%2520Learning%2520for%2520Predictive%2520Analytics%7C_____0\" target=\"_blanc\">released with the latest 7.2.2 version of Vertica</a>. <strong>Training, storing and getting statistics from your machine learning model is as easy as 2 queries</strong>:</p>\n<p class=\"text-center\"><img alt=\"training machine learning models in HPE Vertica from Dataiku DSS\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/training-original.png\" width=\"99%\"/></p>\n<p>As we are predicting whether or not someone will buy from a specific product category, we have a classification problem (with a binary outcome), <strong>hence the choice of <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" target=\"_blank\">logistic regression</a>, which is available out of the box for Vertica</strong>. Training the model is done entirely in-database, with no need to move data around!</p>\n<h4>6. Model assessment &amp; deployment</h4>\n<p>This is our last step. Using the statistics created by Vertica, we can easily see and analyze the <strong>coefficients and associated p-values for each feature</strong> of our model. As this is a regular DSS dataset, you are also free to keep on building your workflow from there (for instance by doing <a href=\"http://doc.dataiku.com/dss/latest/scenarios/checks.html\">Checks</a> / Metrics analysis). Vertica provides also with a set of handy functions to <strong>assess model performances via ROC or lift curves</strong>, which can be leveraged via DSS SQL Notebooks. Finally, the results can also be operationalized by using the model to <strong>score new records on a regular basis, done again fully in-database</strong>.</p>\n<p class=\"text-center zoomable\"><img alt=\"in-database scoring\" data-original=\"http://www.dataiku.com/static/img/blog/predicting_purchases_at_retail_stores/scoring-original.jpg\" src=\"http://www.dataiku.com//static/img/blog/predicting_purchases_at_retail_stores/scoring-800.jpg\" width=\"99%\"/></p>\n<h3>Conclusion</h3>\n<p>This is it, we now have a <strong>functional workflow orchestrated by DSS and running on top of Vertica to produce the purchase predictions</strong>, even if rather simplistic.</p>\n<p>Creating such predictive applications is much more than training machine learning algorithms \u2013 which is in fact just a fairly small amount of work in the entire process. Data preparation, features engineering, preprocessing\u2026 : these are some of the many things to do before being able to move to the \u201creal fun\u201d of ML. Even it may look like a sequential process through this post, it is in practice highly iterative. __Data preparation and machine learning are deeply coupled, and DSS offers the immense benefit to be able to create the entire data science workflow in an integrated environment, with no need to go back and forth between several tools.</p>\n<p>As Big Data arise, and best-of-breed technologies to manage them are made available (<a href=\"http://www.dataiku.com/blog/2015/11/19/technoslavia.html\">this what we call Technoslavia at Dataiku</a>), <strong>Dataiku DSS offers integrations with third-party solutions</strong> to make sure they can be properly leveraged. A key feature is the ability <strong>to push down calculations and processing to underlying, high performance system such as HPE Vertica</strong>, which will avoid unnecessary data movements between systems and tools (one of the plagues in the Big Data world). Vertica is also perfectly suited for the kind of workloads on structured data created by DSS : data scientists can join, filter, group or pivot their data without worrying about tuning the system for performance and model tables properly, it will work fast out-of-the-box. <strong>The association is powerful: Vertica as a high performance backend to predictive applications developed in Dataiku DSS</strong>.</p>\n<p>Working with our ecosystem is key to us, but even more for our clients as they can fully leverage their technological investments by creating high value predictive applications more efficiently. <a href=\"https://www.blablacar.fr/\" target=\"_blank\">Blablacar</a> is a great example, as you may read about <a href=\"http://www.silicon.fr/big-data-blablacar-copilote-sa-bi-avec-hp-tableau-et-dataiku-105060.html\" target=\"_blank\">here</a> (in French) or <a href=\"http://www8.hp.com/us/en/hp-news/press-release.html?id=1837819#.Vyma7qOLTcN\" target=\"_blank\">here</a>. Did you notice? <strong>It\u2019s Vertica + Dataiku DSS</strong>, but also <a href=\"http://www.tableau.com/partners/technology\" target=\"_blank\">Tableau</a> Tableau for data visualization and dashboarding, and a <a href=\"http://www.cloudera.com/partners/partners-listing.html\" target=\"_blank\">Cloudera</a> Hadoop cluster for very large scale storage and data processing. <strong>Dataiku is also a technology partner</strong> of all of these great vendors, so we can ensure maximum value for our customers.</p>\n<p>We strive to keep on being more and more integrated with our ecosystem, but also to develop our partnerships with system integrators and consulting companies that can implement end-to-end data solutions on top of our technologies, so if you are interested to learn more, connect with me on LinkedIn or ping our team at <a href=\"mailto:partnerships@dataiku.com\">partnerships@dataiku.com</a>!</p>\n<p><a href=\"http://www.dataiku.com/blog/2016/05/17/predicting-purchases-at-retail-store-using-HPE-vertica-and-dataiku-dss.html \">Original</a>.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2016/06/build-your-own-audio-video-analytics-hpe-haven-ondemand-part-1.html\" target=\"_blank\">Build Your Own Audio/Video Analytics App With HPE Haven OnDemand \u2013 Part 1</a></li>\n<li><a href=\"/2016/06/hpe-haven-ondemand-text-extraction-cheat-sheet.html\" target=\"_blank\">HPE Haven OnDemand Text Extraction API Cheat Sheet for Developers</a></li>\n<li><a href=\"/2016/02/hpe-machine-learning-60-apis-haven-ondemand.html\" target=\"_blank\">Machine Learning at your fingertips \u2013 60+ free APIs, from HPE Haven OnDemand</a></li>\n</ul>\n</div> ", "website": "kdnuggets"}