{"content": "By Necati Demir . Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble methods usually produces more accurate solutions than a single model would. This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods. In the popular Netflix Competition, the winner used an ensemble method to implement a powerful collaborative filtering algorithm. Another example is KDD 2009 where the winner also used ensemble methods . You can also find winners who used these methods in Kaggle competitions, for example here is the interview with the winner of CrowdFlower competition . It is important that we understand a few terminologies before we continue with this article. Throughout the article I used the term \u201cmodel\u201d to describe the output of the algorithm that trained with data. This model is then used for making predictions. This algorithm can be any machine learning algorithm such as logistic regression, decision tree, etc. These models, when used as inputs of ensemble methods, are called \u201dbase models\u201d. In this blog post I will cover ensemble methods for classification and describe some widely known methods of ensemble: voting, stacking, bagging and boosting. Voting and Averaging Based Ensemble Methods Voting and averaging are two of the easiest ensemble methods. They are both easy to understand and implement. Voting is used for classification and averaging is used for regression. In both methods, the first step is to create multiple classification/regression models using some training dataset. Each base model can be created using different splits of the same training dataset and same algorithm, or using the same dataset with different algorithms, or any other method. The following Python-esque pseudocode shows the use of same training dataset with different algorithms. train = load_csv ( \"train.csv\" ) \r target = train [ \"target\" ] \r train = train . drop ( \"target\" ) \r test = load_csv ( \"test.csv\" ) \r \r algorithms = [ logistic_regression , decision_tree_classification , . . . ] #for classification \r algorithms = [ linear_regression , decision_tree_regressor , . . . ] #for regression \r \r predictions = matrix ( row_length = len ( target ) , column_length = len ( algorithms ) ) \r \r for i , algorithm in enumerate ( algorithms ) : \r predictions [ , i ] = algorithm . fit ( train , target ) . predict ( test ) \r According to the above pseudocode, we created predictions for each model and saved them in a matrix called predictions where each column contains predictions from one model. Majority Voting Every model makes a prediction (votes) for each test instance and the final output prediction is the one that receives more than half of the votes. If none of the predictions get more than half of the votes, we may say that the ensemble method could not make a stable prediction for this instance. Although this is a widely used technique, you may try the most voted prediction (even if that is less than half of the votes) as the final prediction. In some articles, you may see this method being called \u201cplurality voting\u201d. Weighted Voting Unlike majority voting, where each model has the same rights, we can increase the importance of one or more models. In weighted voting you count the prediction of the better models multiple times. Finding a reasonable set of weights is up to you. Simple Averaging In simple averaging method, for every instance of test dataset, the average predictions are calculated. This method often reduces overfit and creates a smoother regression model. The following pseudocode code shows this simple averaging method: final_predictions = [ ] \r for row_number in len ( predictions ) : \r final_predictions . append ( \r mean ( prediction [ row_number , ] ) \r ) \r Weighted Averaging Weighted averaging is a slightly modified version of simple averaging, where the prediction of each model is multiplied by the weight and then their average is calculated. The following pseudocode code shows the weighted averaging: weights = [ . . . , . . . , . . . ] #length is equal to  \r final_predictions = [ ] \r for row_number in len ( predictions ) : \r final_predictions . append ( \r mean ( prediction [ row_number , ] * weights ) \r ) \r Stacking Multiple Machine Learning Models Stacking, also known as stacked generalization, is an ensemble method where the models are combined using another machine learning algorithm. The basic idea is to train machine learning algorithms with training dataset and then generate a new dataset with these models. Then this new dataset is used as input for the combiner machine learning algorithm. The pseudocode of a stacking procedure is summarized as below: base_algorithms = [ logistic_regression , decision_tree_classification , . . . ] #for classification \r \r stacking_train_dataset = matrix ( row_length = len ( target ) , column_length = len ( algorithms ) ) \r stacking_test_dataset = matrix ( row_length = len ( test ) , column_length = len ( algorithms ) ) \r \r \r for i , base_algorithm in enumerate ( base_algorithms ) : \r stacking_train_dataset [ , i ] = base_algorithm . fit ( train , target ) . predict ( train ) \r stacking_test_dataset [ , i ] = base_algorithm . predict ( test ) \r \r final_predictions = combiner_algorithm . fit ( stacking_train_dataset , target ) . predict ( stacking_test_dataset ) \r As you can see in the above pseudocode, the training dataset for combiner algorithm is generated using the outputs of the base algorithms. In the pseudocode, the base algorithm is generated using training dataset and then the same dataset is used again to make predictions. But as we know, in the real world we do not use the same training dataset for prediction, so to overcome this problem you may see some implementations of stacking where training dataset is splitted. Below you can see a pseudocode where the training dataset is split before training the base algorithms: base_algorithms = [ logistic_regression , decision_tree_classification , . . . ] #for classification \r \r stacking_train_dataset = matrix ( row_length = len ( target ) , column_length = len ( algorithms ) ) \r stacking_test_dataset = matrix ( row_length = len ( test ) , column_length = len ( algorithms ) ) \r \r for i , base_algorithm in enumerate ( base_algorithms ) : \r for trainix , testix in split ( train , k = 10 ) : #you may use sklearn.cross_validation.KFold of sklearn library \r stacking_train_dataset [ testcv , i ] = base_algorithm . fit ( train [ trainix ] , target [ trainix ] ) . predict ( train [ testix ] ) \r stacking_test_dataset [ , i ] = base_algorithm . fit ( train ) . predict ( test ) \r \r \r final_predictions = combiner_algorithm . fit ( stacking_train_dataset , target ) . predict ( stacking_test_dataset )", "title_html": "<h1 id=\"title\">Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results</h1> ", "url": "https://www.kdnuggets.com/2016/02/ensemble-methods-techniques-produce-improved-machine-learning.html", "tfidf": {"tfidf": {"base": 6.8776895307, "real": 2.28103448276, "boost": 9.16099249856, "who": 1.06279287723, "win": 2.75290445639, "collabor": 4.45454545455, "easiest": 64.8, "fit": 20.22420382164, "here": 2.42307692308, "testix": 2442.46153846, "wide": 3.1196698762, "new": 2.0357761108, "columnlength": 6106.15384615, "averag": 31.24684270956, "would": 1.0828729281799998, "number": 1.10142916609, "contain": 1.59814777532, "etc": 4.2066772655, "dataset": 2710.536585372, "problem": 1.76674827509, "finalpredict": 7327.3846153800005, "stackingtestdataset": 7327.3846153800005, "unlik": 2.42529789184, "tree": 4.127925117, "know": 2.59327017315, "idea": 2.0930784443, "their": 1.01547908405, "but": 1.01632417899, "testcsv": 1221.23076923, "term": 1.39520168732, "equal": 2.542193755, "ensembl": 200.962025316, "save": 2.8178913737999998, "post": 2.23826307627, "summar": 15.1056137012, "multipl": 10.99255669032, "instanc": 9.771850636020002, "articl": 6.054150247859999, "test": 21.25656903768, "them": 2.19752231988, "been": 1.0239277652399998, "singl": 1.60948905109, "usual": 1.72508964468, "target": 35.408759124090004, "will": 1.22481098596, "the": 52.0, "accur": 5.768895348840001, "increas": 1.32024948025, "procedur": 5.8691312384500005, "below": 4.51215006394, "same": 7.83005707036, "sklearn": 1221.23076923, "decisiontreeregressor": 1221.23076923, "classif": 40.33536585365, "final": 2.6801721955, "crowdflow": 1221.23076923, "linearregress": 1221.23076923, "matrix": 135.6923076924, "num": 2.00063008002, "modifi": 4.45329593268, "say": 1.7544480053, "exampl": 3.00966824644, "right": 1.4054532577899999, "has": 2.0872995004, "generat": 6.15826221876, "slight": 3.25327868852, "use": 21.622413904979997, "follow": 3.1392037964699995, "pseudocod": 9769.84615384, "tri": 1.8544562551099997, "code": 7.761427523839999, "model": 39.721358967600004, "rownumb": 4884.92307692, "than": 4.131147541, "basic": 2.7301805675, "regress": 204.8516129032, "power": 1.3396337861799998, "also": 3.04429530201, "count": 3.48157894737, "demir": 1134.0, "mean": 2.89813800658, "necati": 1221.23076923, "not": 2.03134796238, "major": 2.29704116328, "classificationregress": 1221.23076923, "length": 3.69123459661, "kaggl": 1221.23076923, "may": 5.26008879465, "less": 1.46904783936, "logist": 14.0994671403, "easi": 5.2937645882, "netflix": 163.670103093, "then": 6.51947163096, "they": 1.03017325287, "decisiontreeclassif": 3663.6923076900002, "anoth": 2.27287043664, "techniqu": 7.458773784360001, "although": 1.14968498805, "logisticregress": 3663.6923076900002, "calcul": 12.25945945946, "blog": 14.1876675603, "plural": 14.2898289829, "simpl": 13.592465753439999, "other": 1.00992366412, "algorithm": 670.8169014096, "one": 3.01882487166, "show": 3.80111731845, "known": 2.1718194254400003, "terminolog": 17.6989966555, "loadcsv": 2442.46153846, "accord": 1.27589809531, "see": 5.08968502044, "len": 249.03529411800002, "some": 4.16146788992, "such": 1.06151377374, "get": 1.78562591385, "basealgorithm": 12212.3076923, "implement": 10.729443568379999, "sklearncrossvalidationkfold": 1221.23076923, "drop": 2.4594887684, "both": 2.10431440122, "smoother": 95.6385542169, "result": 1.14611608432, "append": 110.25, "throughout": 1.5217099587799998, "version": 2.0083491461099996, "produc": 2.73865792652, "filter": 16.8893617021, "winner": 20.80733944956, "rowlength": 6106.15384615, "receiv": 1.3054847463200001, "set": 1.18707940781, "ani": 2.26767604628, "two": 1.01379310345, "and": 14.000881889819999, "from": 1.00056721497, "stabl": 6.70156184044, "train": 44.5411075873, "differ": 3.7096347067499997, "multipli": 20.4061696658, "stackingtraindataset": 7327.3846153800005, "first": 1.00761614623, "most": 1.02096463023, "traincsv": 1221.23076923, "for": 22.00693088022, "predict": 145.17570215540002, "output": 23.03094777564, "with": 7.008387462929998, "competit": 12.2784222738, "reason": 1.72340425532, "are": 6.17943561468, "solut": 9.4556283502, "split": 13.883690424120001, "better": 2.0065722952500002, "trainix": 3663.6923076900002, "case": 1.48498737256, "that": 6.0239043825, "weight": 43.91026429013999, "popular": 1.50769230769, "call": 3.2029589778, "bag": 15.8601398601, "more": 4.0686827268, "improv": 2.04376930999, "pythonesqu": 1221.23076923, "these": 3.22246278756, "combin": 6.79041916168, "general": 1.1218202374200001, "could": 1.2043695949, "column": 7.078020508250001, "librari": 2.68266306185, "again": 1.50883862384, "none": 4.06555697823, "can": 7.05756834852, "describ": 2.94054454528, "make": 4.305064063440001, "vote": 42.015879017, "each": 7.13848920864, "enumer": 123.3886010364, "few": 1.31729173581, "testcv": 1221.23076923, "this": 12.04552352052, "step": 2.8279301745599996, "befor": 2.20072082062, "continu": 1.13928955867, "data": 3.37643555934, "overcom": 8.38668779715, "reduc": 1.98698372966, "method": 48.857142857170004, "machin": 24.146007604559998, "combineralgorithm": 2442.46153846, "time": 1.01127460348, "abov": 3.80765079746, "understand": 5.93717277486, "stack": 117.891089109, "import": 2.6803984467400004, "decis": 2.16, "everi": 2.95835274388, "input": 24.4058416602, "when": 1.02076769755, "interview": 3.3981164383599998, "overfit": 1221.23076923, "world": 1.11340206186, "half": 5.27441860464, "where": 8.53720508168, "often": 1.29452054795, "find": 3.4588235294199996, "learn": 13.936503291900001, "cover": 1.69380134429, "even": 1.16461267606, "creat": 6.2464589235000005}, "logtfidf": {"base": 0.8191398137220001, "real": 0.824629060574, "boost": 2.2149545241900004, "who": 0.0609002329859, "win": 1.01265652029, "collabor": 1.4939250253100003, "easiest": 4.17130560336, "fit": 7.290723761339999, "here": 0.8850381883700001, "testix": 14.215228912879999, "wide": 0.8891600135079999, "new": 0.0354598937022, "columnlength": 35.5380722822, "averag": 11.48414025594, "would": 0.0796176279647, "number": 0.0966085784186, "contain": 0.468845318236, "etc": 1.4366730879700003, "dataset": 73.72182393296, "problem": 0.569140724273, "finalpredict": 42.645686738639995, "stackingtestdataset": 42.645686738639995, "unlik": 0.885954358842, "tree": 1.41777488775, "know": 0.952919694398, "idea": 0.73863592212, "their": 0.015360505122700001, "but": 0.0161923720719, "testcsv": 7.1076144564399995, "term": 0.33303898354600003, "equal": 0.933027391343, "ensembl": 33.8185117398, "save": 1.03598886547, "post": 0.8057001527009999, "summar": 2.7150664430299996, "multipl": 4.04369607248, "instanc": 3.5426807391599997, "articl": 2.106395218722, "test": 7.817795496824, "them": 0.1883666538186, "been": 0.023645982368400004, "singl": 0.475916769059, "usual": 0.545279017064, "target": 12.859703445820001, "will": 0.202786534915, "the": 0.0, "accur": 1.75248061485, "increas": 0.277820718929, "procedur": 1.76970662262, "below": 1.627253183872, "same": 0.784417547228, "sklearn": 7.1076144564399995, "decisiontreeregressor": 7.1076144564399995, "classif": 10.43895368145, "final": 0.585467727896, "crowdflow": 7.1076144564399995, "linearregress": 7.1076144564399995, "matrix": 18.71178245928, "num": 0.0006299807907940001, "modifi": 1.4936444810499998, "say": 0.562154280552, "exampl": 0.8173653499979999, "right": 0.34035985417, "has": 0.0854478897096, "generat": 2.1575470252080002, "slight": 1.17966331506, "use": 0.6133684143636, "follow": 0.1360707332826, "pseudocod": 56.860915651519996, "tri": 0.61759152916, "code": 2.71203819194, "model": 14.011551389109002, "rownumb": 28.430457825759998, "than": 0.1290434488728, "basic": 1.00436774895, "regress": 15.743966065679999, "power": 0.292396282715, "also": 0.0439714734, "count": 1.24748591139, "demir": 7.033506484289999, "mean": 0.74184256704, "necati": 7.1076144564399995, "not": 0.031104826015, "major": 0.276949326878, "classificationregress": 7.1076144564399995, "length": 1.3059609811200001, "kaggl": 7.1076144564399995, "may": 0.253549976422, "less": 0.3846144626, "logist": 2.6461370052, "easi": 1.6665296351499999, "netflix": 5.0978528354, "then": 0.4982031913853999, "they": 0.0297269947676, "decisiontreeclassif": 21.322843369319997, "anoth": 0.255792723304, "techniqu": 2.63248769614, "although": 0.139487981418, "logisticregress": 21.322843369319997, "calcul": 3.6263013184199995, "blog": 2.65237310559, "plural": 2.65954802426, "simpl": 4.892885157559999, "other": 0.00987474791976, "algorithm": 79.93061748432, "one": 0.0187660549365, "show": 0.710048298039, "known": 0.1648361611984, "terminolog": 2.87350795184, "loadcsv": 14.215228912879999, "accord": 0.243650319127, "see": 0.963686341968, "len": 36.39225576096, "some": 0.158294036258, "such": 0.059695977806, "get": 0.579769005782, "basealgorithm": 71.0761445644, "implement": 3.8231382272100003, "sklearncrossvalidationkfold": 7.1076144564399995, "drop": 0.8999535106219999, "both": 0.10168506677860001, "smoother": 4.56057602555, "result": 0.136378908381, "append": 8.019206667539999, "throughout": 0.41983467543499997, "version": 0.697313064259, "produc": 0.628641624006, "filter": 2.82668393864, "winner": 6.596045686, "rowlength": 35.5380722822, "receiv": 0.266574424922, "set": 0.171496011289, "ani": 0.251216716732, "two": 0.0136988443582, "and": 0.0008818619888904, "from": 0.000567054168866, "stabl": 1.90234060974, "train": 15.201121195297, "differ": 0.6369633639360001, "multipli": 3.01583728972, "stackingtraindataset": 42.645686738639995, "first": 0.0075872898121599995, "most": 0.020747896295599998, "traincsv": 7.1076144564399995, "for": 0.006929788698734001, "predict": 46.08072665532, "output": 6.11467973481, "with": 0.00838244199373, "competit": 4.48619629604, "reason": 0.544301552962, "are": 0.17680484149620002, "solut": 3.10692595254, "split": 4.97768175728, "better": 0.6964279406, "trainix": 21.322843369319997, "case": 0.395406268889, "that": 0.02385689027784, "weight": 14.264311735080001, "popular": 0.41058020877499996, "call": 0.1963883233464, "bag": 2.76380903459, "more": 0.06809972639999999, "improv": 0.7147958039319999, "pythonesqu": 7.1076144564399995, "these": 0.2146008582024, "combin": 2.116873243004, "general": 0.114952578063, "could": 0.18595627229000003, "column": 1.95699427938, "librari": 0.986809980943, "again": 0.411340231612, "none": 1.40255075163, "can": 0.974046578364, "describ": 0.77089520625, "make": 0.29399063129159997, "vote": 15.3858640467, "each": 1.042450135824, "enumer": 11.15017933332, "few": 0.275577913653, "testcv": 7.1076144564399995, "this": 0.04543738863, "step": 1.03954505698, "befor": 0.191275543759, "continu": 0.13040487398700001, "data": 1.2168205848, "overcom": 2.12664566269, "reduc": 0.686617775143, "method": 17.944770567979003, "machin": 8.35415748372, "combineralgorithm": 14.215228912879999, "time": 0.0112115188626, "abov": 1.287730459632, "understand": 2.1761717513599996, "stack": 17.86801053228, "import": 0.585636554132, "decis": 0.7701082216959999, "everi": 0.782970854842, "input": 5.00335067078, "when": 0.0205549888584, "interview": 1.2232212893899999, "overfit": 7.1076144564399995, "world": 0.107420248621, "half": 1.692768502476, "where": 0.5199371099656, "often": 0.258140393351, "find": 1.095562660576, "learn": 5.05651238847, "cover": 0.526975319156, "even": 0.152388564834, "creat": 1.1128840925699999}, "logidf": {"base": 0.13652330228700002, "real": 0.824629060574, "boost": 2.2149545241900004, "who": 0.0609002329859, "win": 1.01265652029, "collabor": 1.4939250253100003, "easiest": 4.17130560336, "fit": 1.2151206268899999, "here": 0.8850381883700001, "testix": 7.1076144564399995, "wide": 0.44458000675399995, "new": 0.0177299468511, "columnlength": 7.1076144564399995, "averag": 0.957011687995, "would": 0.0796176279647, "number": 0.0966085784186, "contain": 0.468845318236, "etc": 1.4366730879700003, "dataset": 5.26584456664, "problem": 0.569140724273, "finalpredict": 7.1076144564399995, "stackingtestdataset": 7.1076144564399995, "unlik": 0.885954358842, "tree": 1.41777488775, "know": 0.952919694398, "idea": 0.73863592212, "their": 0.015360505122700001, "but": 0.0161923720719, "testcsv": 7.1076144564399995, "term": 0.33303898354600003, "equal": 0.933027391343, "ensembl": 2.81820931165, "save": 1.03598886547, "post": 0.8057001527009999, "summar": 2.7150664430299996, "multipl": 1.01092401812, "instanc": 1.18089357972, "articl": 0.702131739574, "test": 0.977224437103, "them": 0.0941833269093, "been": 0.023645982368400004, "singl": 0.475916769059, "usual": 0.545279017064, "target": 1.1690639496200002, "will": 0.202786534915, "the": 0.0, "accur": 1.75248061485, "increas": 0.277820718929, "procedur": 1.76970662262, "below": 0.813626591936, "same": 0.112059649604, "sklearn": 7.1076144564399995, "decisiontreeregressor": 7.1076144564399995, "classif": 2.08779073629, "final": 0.292733863948, "crowdflow": 7.1076144564399995, "linearregress": 7.1076144564399995, "matrix": 3.1186304098799997, "num": 0.00031499039539700004, "modifi": 1.4936444810499998, "say": 0.562154280552, "exampl": 0.40868267499899996, "right": 0.34035985417, "has": 0.0427239448548, "generat": 0.719182341736, "slight": 1.17966331506, "use": 0.0292080197316, "follow": 0.045356911094199995, "pseudocod": 7.1076144564399995, "tri": 0.61759152916, "code": 1.35601909597, "model": 0.7374500731110001, "rownumb": 7.1076144564399995, "than": 0.0322608622182, "basic": 1.00436774895, "regress": 3.9359915164199997, "power": 0.292396282715, "also": 0.0146571578, "count": 1.24748591139, "demir": 7.033506484289999, "mean": 0.37092128352, "necati": 7.1076144564399995, "not": 0.0155524130075, "major": 0.138474663439, "classificationregress": 7.1076144564399995, "length": 1.3059609811200001, "kaggl": 7.1076144564399995, "may": 0.050709995284400004, "less": 0.3846144626, "logist": 2.6461370052, "easi": 1.6665296351499999, "netflix": 5.0978528354, "then": 0.08303386523089999, "they": 0.0297269947676, "decisiontreeclassif": 7.1076144564399995, "anoth": 0.127896361652, "techniqu": 1.31624384807, "although": 0.139487981418, "logisticregress": 7.1076144564399995, "calcul": 1.8131506592099997, "blog": 2.65237310559, "plural": 2.65954802426, "simpl": 1.2232212893899999, "other": 0.00987474791976, "algorithm": 3.33044239518, "one": 0.0062553516455, "show": 0.236682766013, "known": 0.0824180805992, "terminolog": 2.87350795184, "loadcsv": 7.1076144564399995, "accord": 0.243650319127, "see": 0.240921585492, "len": 3.03268798008, "some": 0.0395735090645, "such": 0.059695977806, "get": 0.579769005782, "basealgorithm": 7.1076144564399995, "implement": 1.27437940907, "sklearncrossvalidationkfold": 7.1076144564399995, "drop": 0.8999535106219999, "both": 0.050842533389300004, "smoother": 4.56057602555, "result": 0.136378908381, "append": 4.0096033337699994, "throughout": 0.41983467543499997, "version": 0.697313064259, "produc": 0.314320812003, "filter": 2.82668393864, "winner": 1.6490114215, "rowlength": 7.1076144564399995, "receiv": 0.266574424922, "set": 0.171496011289, "ani": 0.125608358366, "two": 0.0136988443582, "and": 6.29901420636e-05, "from": 0.000567054168866, "stabl": 1.90234060974, "train": 0.660918312839, "differ": 0.212321121312, "multipli": 3.01583728972, "stackingtraindataset": 7.1076144564399995, "first": 0.0075872898121599995, "most": 0.020747896295599998, "traincsv": 7.1076144564399995, "for": 0.00031499039539700004, "predict": 1.6457402376899999, "output": 2.03822657827, "with": 0.00119749171339, "competit": 1.12154907401, "reason": 0.544301552962, "are": 0.0294674735827, "solut": 1.55346297627, "split": 1.24442043932, "better": 0.6964279406, "trainix": 7.1076144564399995, "case": 0.395406268889, "that": 0.00397614837964, "weight": 1.58492352612, "popular": 0.41058020877499996, "call": 0.0654627744488, "bag": 2.76380903459, "more": 0.017024931599999998, "improv": 0.7147958039319999, "pythonesqu": 7.1076144564399995, "these": 0.0715336194008, "combin": 0.529218310751, "general": 0.114952578063, "could": 0.18595627229000003, "column": 1.95699427938, "librari": 0.986809980943, "again": 0.411340231612, "none": 1.40255075163, "can": 0.162341096394, "describ": 0.385447603125, "make": 0.07349765782289999, "vote": 1.09899028905, "each": 0.173741689304, "enumer": 3.71672644444, "few": 0.275577913653, "testcv": 7.1076144564399995, "this": 0.0037864490525, "step": 1.03954505698, "befor": 0.0956377718795, "continu": 0.13040487398700001, "data": 1.2168205848, "overcom": 2.12664566269, "reduc": 0.686617775143, "method": 0.944461608841, "machin": 1.39235958062, "combineralgorithm": 7.1076144564399995, "time": 0.0112115188626, "abov": 0.643865229816, "understand": 1.0880858756799998, "stack": 2.97800175538, "import": 0.292818277066, "decis": 0.7701082216959999, "everi": 0.391485427421, "input": 2.50167533539, "when": 0.0205549888584, "interview": 1.2232212893899999, "overfit": 7.1076144564399995, "world": 0.107420248621, "half": 0.564256167492, "where": 0.0649921387457, "often": 0.258140393351, "find": 0.547781330288, "learn": 0.842752064745, "cover": 0.526975319156, "even": 0.152388564834, "creat": 0.222576818514}, "freq": {"base": 6, "real": 1, "boost": 1, "who": 1, "win": 1, "collabor": 1, "easiest": 1, "fit": 6, "here": 1, "testix": 2, "wide": 2, "new": 2, "columnlength": 5, "averag": 12, "would": 1, "number": 1, "contain": 1, "etc": 1, "dataset": 14, "problem": 1, "finalpredict": 6, "stackingtestdataset": 6, "unlik": 1, "tree": 1, "know": 1, "idea": 1, "their": 1, "but": 1, "testcsv": 1, "term": 1, "equal": 1, "ensembl": 12, "save": 1, "post": 1, "summar": 1, "multipl": 4, "instanc": 3, "articl": 3, "test": 8, "them": 2, "been": 1, "singl": 1, "usual": 1, "target": 11, "will": 1, "the": 52, "accur": 1, "increas": 1, "procedur": 1, "below": 2, "same": 7, "sklearn": 1, "decisiontreeregressor": 1, "classif": 5, "final": 2, "crowdflow": 1, "linearregress": 1, "matrix": 6, "num": 2, "modifi": 1, "say": 1, "exampl": 2, "right": 1, "has": 2, "generat": 3, "slight": 1, "use": 21, "follow": 3, "pseudocod": 8, "tri": 1, "code": 2, "model": 19, "rownumb": 4, "than": 4, "basic": 1, "regress": 4, "power": 1, "also": 3, "count": 1, "demir": 1, "mean": 2, "necati": 1, "not": 2, "major": 2, "classificationregress": 1, "length": 1, "kaggl": 1, "may": 5, "less": 1, "logist": 1, "easi": 1, "netflix": 1, "then": 6, "they": 1, "decisiontreeclassif": 3, "anoth": 2, "techniqu": 2, "although": 1, "logisticregress": 3, "calcul": 2, "blog": 1, "plural": 1, "simpl": 4, "other": 1, "algorithm": 24, "one": 3, "show": 3, "known": 2, "terminolog": 1, "loadcsv": 2, "accord": 1, "see": 4, "len": 12, "some": 4, "such": 1, "get": 1, "basealgorithm": 10, "implement": 3, "sklearncrossvalidationkfold": 1, "drop": 1, "both": 2, "smoother": 1, "result": 1, "append": 2, "throughout": 1, "version": 1, "produc": 2, "filter": 1, "winner": 4, "rowlength": 5, "receiv": 1, "set": 1, "ani": 2, "two": 1, "and": 14, "from": 1, "stabl": 1, "train": 23, "differ": 3, "multipli": 1, "stackingtraindataset": 6, "first": 1, "most": 1, "traincsv": 1, "for": 22, "predict": 28, "output": 3, "with": 7, "competit": 4, "reason": 1, "are": 6, "solut": 2, "split": 4, "better": 1, "trainix": 3, "case": 1, "that": 6, "weight": 9, "popular": 1, "call": 3, "bag": 1, "more": 4, "improv": 1, "pythonesqu": 1, "these": 3, "combin": 4, "general": 1, "could": 1, "column": 1, "librari": 1, "again": 1, "none": 1, "can": 6, "describ": 2, "make": 4, "vote": 14, "each": 6, "enumer": 3, "few": 1, "testcv": 1, "this": 12, "step": 1, "befor": 2, "continu": 1, "data": 1, "overcom": 1, "reduc": 1, "method": 19, "machin": 6, "combineralgorithm": 2, "time": 1, "abov": 2, "understand": 2, "stack": 6, "import": 2, "decis": 1, "everi": 2, "input": 2, "when": 1, "interview": 1, "overfit": 1, "world": 1, "half": 3, "where": 8, "often": 1, "find": 2, "learn": 6, "cover": 1, "even": 1, "creat": 5}, "idf": {"base": 1.14628158845, "real": 2.28103448276, "boost": 9.16099249856, "who": 1.06279287723, "win": 2.75290445639, "collabor": 4.45454545455, "easiest": 64.8, "fit": 3.37070063694, "here": 2.42307692308, "testix": 1221.23076923, "wide": 1.5598349381, "new": 1.0178880554, "columnlength": 1221.23076923, "averag": 2.60390355913, "would": 1.0828729281799998, "number": 1.10142916609, "contain": 1.59814777532, "etc": 4.2066772655, "dataset": 193.609756098, "problem": 1.76674827509, "finalpredict": 1221.23076923, "stackingtestdataset": 1221.23076923, "unlik": 2.42529789184, "tree": 4.127925117, "know": 2.59327017315, "idea": 2.0930784443, "their": 1.01547908405, "but": 1.01632417899, "testcsv": 1221.23076923, "term": 1.39520168732, "equal": 2.542193755, "ensembl": 16.746835443, "save": 2.8178913737999998, "post": 2.23826307627, "summar": 15.1056137012, "multipl": 2.74813917258, "instanc": 3.2572835453400004, "articl": 2.01805008262, "test": 2.65707112971, "them": 1.09876115994, "been": 1.0239277652399998, "singl": 1.60948905109, "usual": 1.72508964468, "target": 3.2189781021900004, "will": 1.22481098596, "the": 1.0, "accur": 5.768895348840001, "increas": 1.32024948025, "procedur": 5.8691312384500005, "below": 2.25607503197, "same": 1.11857958148, "sklearn": 1221.23076923, "decisiontreeregressor": 1221.23076923, "classif": 8.067073170730001, "final": 1.34008609775, "crowdflow": 1221.23076923, "linearregress": 1221.23076923, "matrix": 22.6153846154, "num": 1.00031504001, "modifi": 4.45329593268, "say": 1.7544480053, "exampl": 1.50483412322, "right": 1.4054532577899999, "has": 1.0436497502, "generat": 2.05275407292, "slight": 3.25327868852, "use": 1.0296387573799999, "follow": 1.04640126549, "pseudocod": 1221.23076923, "tri": 1.8544562551099997, "code": 3.8807137619199996, "model": 2.0905978404, "rownumb": 1221.23076923, "than": 1.03278688525, "basic": 2.7301805675, "regress": 51.2129032258, "power": 1.3396337861799998, "also": 1.01476510067, "count": 3.48157894737, "demir": 1134.0, "mean": 1.44906900329, "necati": 1221.23076923, "not": 1.01567398119, "major": 1.14852058164, "classificationregress": 1221.23076923, "length": 3.69123459661, "kaggl": 1221.23076923, "may": 1.05201775893, "less": 1.46904783936, "logist": 14.0994671403, "easi": 5.2937645882, "netflix": 163.670103093, "then": 1.08657860516, "they": 1.03017325287, "decisiontreeclassif": 1221.23076923, "anoth": 1.13643521832, "techniqu": 3.7293868921800004, "although": 1.14968498805, "logisticregress": 1221.23076923, "calcul": 6.12972972973, "blog": 14.1876675603, "plural": 14.2898289829, "simpl": 3.3981164383599998, "other": 1.00992366412, "algorithm": 27.9507042254, "one": 1.00627495722, "show": 1.26703910615, "known": 1.0859097127200001, "terminolog": 17.6989966555, "loadcsv": 1221.23076923, "accord": 1.27589809531, "see": 1.27242125511, "len": 20.752941176500002, "some": 1.04036697248, "such": 1.06151377374, "get": 1.78562591385, "basealgorithm": 1221.23076923, "implement": 3.57648118946, "sklearncrossvalidationkfold": 1221.23076923, "drop": 2.4594887684, "both": 1.05215720061, "smoother": 95.6385542169, "result": 1.14611608432, "append": 55.125, "throughout": 1.5217099587799998, "version": 2.0083491461099996, "produc": 1.36932896326, "filter": 16.8893617021, "winner": 5.20183486239, "rowlength": 1221.23076923, "receiv": 1.3054847463200001, "set": 1.18707940781, "ani": 1.13383802314, "two": 1.01379310345, "and": 1.00006299213, "from": 1.00056721497, "stabl": 6.70156184044, "train": 1.9365698950999999, "differ": 1.23654490225, "multipli": 20.4061696658, "stackingtraindataset": 1221.23076923, "first": 1.00761614623, "most": 1.02096463023, "traincsv": 1221.23076923, "for": 1.00031504001, "predict": 5.18484650555, "output": 7.676982591880001, "with": 1.0011982089899998, "competit": 3.06960556845, "reason": 1.72340425532, "are": 1.02990593578, "solut": 4.7278141751, "split": 3.4709226060300002, "better": 2.0065722952500002, "trainix": 1221.23076923, "case": 1.48498737256, "that": 1.00398406375, "weight": 4.878918254459999, "popular": 1.50769230769, "call": 1.0676529926, "bag": 15.8601398601, "more": 1.0171706817, "improv": 2.04376930999, "pythonesqu": 1221.23076923, "these": 1.07415426252, "combin": 1.69760479042, "general": 1.1218202374200001, "could": 1.2043695949, "column": 7.078020508250001, "librari": 2.68266306185, "again": 1.50883862384, "none": 4.06555697823, "can": 1.17626139142, "describ": 1.47027227264, "make": 1.0762660158600001, "vote": 3.0011342155, "each": 1.18974820144, "enumer": 41.1295336788, "few": 1.31729173581, "testcv": 1221.23076923, "this": 1.00379362671, "step": 2.8279301745599996, "befor": 1.10036041031, "continu": 1.13928955867, "data": 3.37643555934, "overcom": 8.38668779715, "reduc": 1.98698372966, "method": 2.5714285714300003, "machin": 4.02433460076, "combineralgorithm": 1221.23076923, "time": 1.01127460348, "abov": 1.90382539873, "understand": 2.96858638743, "stack": 19.6485148515, "import": 1.3401992233700002, "decis": 2.16, "everi": 1.47917637194, "input": 12.2029208301, "when": 1.02076769755, "interview": 3.3981164383599998, "overfit": 1221.23076923, "world": 1.11340206186, "half": 1.75813953488, "where": 1.06715063521, "often": 1.29452054795, "find": 1.7294117647099998, "learn": 2.32275054865, "cover": 1.69380134429, "even": 1.16461267606, "creat": 1.2492917847}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/ensemble-methods-techniques-produce-improved-machine-learning.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/dato-introduction-text-analytics-sherlock-holmes.html\" rel=\"prev\" title=\"Elementary, My Dear Watson! An Introduction to Text Analytics via Sherlock Holmes\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/paw-astounding-predictive-analytics-opportunities-2016-infographic.html\" rel=\"next\" title=\"Astounding predictive analytics opportunities in 2016 [Infographic]\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/02/ensemble-methods-techniques-produce-improved-machine-learning.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=44881\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/ensemble-methods-techniques-produce-improved-machine-learning.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-44881 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 12-Feb, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/index.html\">Feb</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/tutorials.html\">Tutorials, Overviews</a> \u00bb Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results (\u00a0<a href=\"/2016/n06.html\">16:n06</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/02/dato-introduction-text-analytics-sherlock-holmes.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/02/paw-astounding-predictive-analytics-opportunities-2016-infographic.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/boosting\" rel=\"tag\">Boosting</a>, <a href=\"https://www.kdnuggets.com/tag/ensemble-methods\" rel=\"tag\">Ensemble Methods</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a>, <a href=\"https://www.kdnuggets.com/tag/python\" rel=\"tag\">Python</a></div>\n<br/>\n<p class=\"excerpt\">\n     Get a handle on ensemble methods from voting and weighting to stacking and boosting, with this well-written overview that includes numerous Python-style pseudocode examples for reinforcement.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By Necati Demir</b>.</p>\n<p>Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble methods usually produces more accurate solutions than a single model would. This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods. In the popular Netflix Competition, <a href=\"http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/\">the winner used an ensemble method</a> to implement a powerful collaborative filtering algorithm. Another example is KDD 2009 where the winner also <a href=\"http://jmlr.org/proceedings/papers/v7/niculescu09/niculescu09.pdf\">used ensemble methods</a>. You can also find winners who used these methods in Kaggle competitions, for example <a href=\"http://blog.kaggle.com/2015/07/27/crowdflower-winners-interview-1st-place-chenglong-chen/\">here</a> is the interview with the winner of <a href=\"https://www.kaggle.com/c/crowdflower-search-relevance\">CrowdFlower competition</a>.</p>\n<p>It is important that we understand a few terminologies before we continue with this article. Throughout the article I used the term \u201cmodel\u201d to describe the output of the algorithm that trained with data. This model is then used for making predictions. This algorithm can be any <a href=\"http://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer\">machine learning</a> algorithm such as logistic regression, decision tree, etc. These models, when used as inputs of ensemble methods, are called \u201dbase models\u201d.</p>\n<p>In this blog post I will cover ensemble methods for classification and describe some widely known methods of ensemble: voting, stacking, bagging and boosting.</p>\n<p><b>Voting and Averaging Based Ensemble Methods</b></p>\n<p>Voting and averaging are two of the easiest ensemble methods. They are both easy to understand and implement. Voting is used for classification and averaging is used for regression.</p>\n<p><img alt=\"Classifying animal images\" src=\"/wp-content/uploads/classify-animals-1.jpg\" width=\"99%\"/></p>\n<p>In both methods, the first step is to create multiple classification/regression models using some training dataset. Each base model can be created using different splits of the same training dataset and same algorithm, or using the same dataset with different algorithms, or any other method. The following Python-esque pseudocode shows the use of same training dataset with different algorithms.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">train <span style=\"color:#808030; \">=</span> load_csv<span style=\"color:#808030; \">(</span><span style=\"color:#0000e6; \">\"train.csv\"</span><span style=\"color:#808030; \">)</span>\r\ntarget <span style=\"color:#808030; \">=</span> train<span style=\"color:#808030; \">[</span><span style=\"color:#0000e6; \">\"target\"</span><span style=\"color:#808030; \">]</span>\r\ntrain <span style=\"color:#808030; \">=</span> train<span style=\"color:#808030; \">.</span>drop<span style=\"color:#808030; \">(</span><span style=\"color:#0000e6; \">\"target\"</span><span style=\"color:#808030; \">)</span>\r\ntest <span style=\"color:#808030; \">=</span> load_csv<span style=\"color:#808030; \">(</span><span style=\"color:#0000e6; \">\"test.csv\"</span><span style=\"color:#808030; \">)</span>\r\n\r\nalgorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>logistic_regression<span style=\"color:#808030; \">,</span> decision_tree_classification<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for classification</span>\r\nalgorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>linear_regression<span style=\"color:#808030; \">,</span> decision_tree_regressor<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for regression</span>\r\n\r\npredictions <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\n\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> i<span style=\"color:#808030; \">,</span>algorithm <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">enumerate</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    predictions<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>According to the above pseudocode, we created predictions for each model and saved them in a matrix called predictions where each column contains predictions from one model.</p>\n<p><b>Majority Voting</b></p>\n<p>Every model makes a prediction (votes) for each test instance and the final output prediction is the one that receives more than half of the votes. If none of the predictions get more than half of the votes, we may say that the ensemble method could not make a stable prediction for this instance. Although this is a widely used technique, you may try the most voted prediction (even if that is less than half of the votes) as the final prediction. In some articles, you may see this method being called \u201cplurality voting\u201d.</p>\n<p><b>Weighted Voting</b></p>\n<p>Unlike majority voting, where each model has the same rights, we can increase the importance of one or more models. In weighted voting you count the prediction of the better models multiple times. Finding a reasonable set of weights is up to you.</p>\n<p><b>Simple Averaging</b></p>\n<p>In simple averaging method, for every instance of test dataset, the average predictions are calculated. This method often reduces overfit and creates a smoother regression model. The following pseudocode code shows this simple averaging method:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">final_predictions <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> row_number <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>predictions<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    final_predictions<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span>\r\n        mean<span style=\"color:#808030; \">(</span>prediction<span style=\"color:#808030; \">[</span>row_number<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span>\r\n    <span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Weighted Averaging</b></p>\n<p>Weighted averaging is a slightly modified version of simple averaging, where the prediction of each model is multiplied by the weight and then their average is calculated. The following pseudocode code shows the weighted averaging:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">weights <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#length is equal to len(algorithms)</span>\r\nfinal_predictions <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> row_number <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>predictions<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    final_predictions<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span>\r\n        mean<span style=\"color:#808030; \">(</span>prediction<span style=\"color:#808030; \">[</span>row_number<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">]</span><span style=\"color:#44aadd; \">*</span>weights<span style=\"color:#808030; \">)</span>\r\n    <span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Stacking Multiple Machine Learning Models</b></p>\n<p>Stacking, also known as stacked generalization, is an ensemble method where the models are combined using another <a href=\"http://www.toptal.com/machine-learning\">machine learning</a> algorithm. The basic idea is to train machine learning algorithms with training dataset and then generate a new dataset with these models. Then this new dataset is used as input for the combiner machine learning algorithm.</p>\n<p><img alt=\"Classifying animal images\" src=\"/wp-content/uploads/classify-animals-2.jpg\" width=\"99%\"/></p>\n<p>The pseudocode of a stacking procedure is summarized as below:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">base_algorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>logistic_regression<span style=\"color:#808030; \">,</span> decision_tree_classification<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for classification</span>\r\n\r\nstacking_train_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\nstacking_test_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\n\r\n\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> i<span style=\"color:#808030; \">,</span>base_algorithm <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">enumerate</span><span style=\"color:#808030; \">(</span>base_algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    stacking_train_dataset<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">)</span>\r\n    stacking_test_dataset<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span>\r\n\r\nfinal_predictions <span style=\"color:#808030; \">=</span> combiner_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>stacking_train_dataset<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>stacking_test_dataset<span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>As you can see in the above pseudocode, the training dataset for combiner algorithm is generated using the outputs of the base algorithms. In the pseudocode, the base algorithm is generated using training dataset and then the same dataset is used again to make predictions. But as we know, in the real world we do not use the same training dataset for prediction, so to overcome this problem you may see some implementations of stacking where training dataset is splitted. Below you can see a pseudocode where the training dataset is split before training the base algorithms:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">base_algorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>logistic_regression<span style=\"color:#808030; \">,</span> decision_tree_classification<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for classification</span>\r\n\r\nstacking_train_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\nstacking_test_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\n\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> i<span style=\"color:#808030; \">,</span>base_algorithm <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">enumerate</span><span style=\"color:#808030; \">(</span>base_algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    <span style=\"color:#800000; font-weight:bold; \">for</span> trainix<span style=\"color:#808030; \">,</span> testix <span style=\"color:#800000; font-weight:bold; \">in</span> split<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">,</span> k<span style=\"color:#808030; \">=</span><span style=\"color:#008c00; \">10</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span> <span style=\"color:#696969; \">#you may use sklearn.cross_validation.KFold of sklearn library</span>\r\n        stacking_train_dataset<span style=\"color:#808030; \">[</span>testcv<span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">[</span>trainix<span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">[</span>trainix<span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">[</span>testix<span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span>\r\nstacking_test_dataset<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span>\r\n\r\n\r\nfinal_predictions <span style=\"color:#808030; \">=</span> combiner_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>stacking_train_dataset<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>stacking_test_dataset<span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2016/02/ensemble-methods-techniques-produce-improved-machine-learning.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/02/dato-introduction-text-analytics-sherlock-holmes.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/02/paw-astounding-predictive-analytics-opportunities-2016-infographic.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/index.html\">Feb</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/tutorials.html\">Tutorials, Overviews</a> \u00bb Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results (\u00a0<a href=\"/2016/n06.html\">16:n06</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556365479\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.744 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 07:44:39 -->\n<!-- Compression = gzip -->", "content_tokenized": ["necati", "demir", "ensembl", "method", "are", "techniqu", "that", "creat", "multipl", "model", "and", "then", "combin", "them", "produc", "improv", "result", "ensembl", "method", "usual", "produc", "more", "accur", "solut", "than", "singl", "model", "would", "this", "has", "been", "the", "case", "number", "machin", "learn", "competit", "where", "the", "win", "solut", "use", "ensembl", "method", "the", "popular", "netflix", "competit", "the", "winner", "use", "ensembl", "method", "implement", "power", "collabor", "filter", "algorithm", "anoth", "exampl", "num", "where", "the", "winner", "also", "use", "ensembl", "method", "can", "also", "find", "winner", "who", "use", "these", "method", "kaggl", "competit", "for", "exampl", "here", "the", "interview", "with", "the", "winner", "crowdflow", "competit", "import", "that", "understand", "few", "terminolog", "befor", "continu", "with", "this", "articl", "throughout", "the", "articl", "use", "the", "term", "model", "describ", "the", "output", "the", "algorithm", "that", "train", "with", "data", "this", "model", "then", "use", "for", "make", "predict", "this", "algorithm", "can", "ani", "machin", "learn", "algorithm", "such", "logist", "regress", "decis", "tree", "etc", "these", "model", "when", "use", "input", "ensembl", "method", "are", "call", "base", "model", "this", "blog", "post", "will", "cover", "ensembl", "method", "for", "classif", "and", "describ", "some", "wide", "known", "method", "ensembl", "vote", "stack", "bag", "and", "boost", "vote", "and", "averag", "base", "ensembl", "method", "vote", "and", "averag", "are", "two", "the", "easiest", "ensembl", "method", "they", "are", "both", "easi", "understand", "and", "implement", "vote", "use", "for", "classif", "and", "averag", "use", "for", "regress", "both", "method", "the", "first", "step", "creat", "multipl", "classificationregress", "model", "use", "some", "train", "dataset", "each", "base", "model", "can", "creat", "use", "differ", "split", "the", "same", "train", "dataset", "and", "same", "algorithm", "use", "the", "same", "dataset", "with", "differ", "algorithm", "ani", "other", "method", "the", "follow", "pythonesqu", "pseudocod", "show", "the", "use", "same", "train", "dataset", "with", "differ", "algorithm", "train", "loadcsv", "traincsv", "target", "train", "target", "train", "train", "drop", "target", "test", "loadcsv", "testcsv", "algorithm", "logisticregress", "decisiontreeclassif", "for", "classif", "algorithm", "linearregress", "decisiontreeregressor", "for", "regress", "predict", "matrix", "rowlength", "len", "target", "columnlength", "len", "algorithm", "for", "algorithm", "enumer", "algorithm", "predict", "algorithm", "fit", "train", "target", "predict", "test", "accord", "the", "abov", "pseudocod", "creat", "predict", "for", "each", "model", "and", "save", "them", "matrix", "call", "predict", "where", "each", "column", "contain", "predict", "from", "one", "model", "major", "vote", "everi", "model", "make", "predict", "vote", "for", "each", "test", "instanc", "and", "the", "final", "output", "predict", "the", "one", "that", "receiv", "more", "than", "half", "the", "vote", "none", "the", "predict", "get", "more", "than", "half", "the", "vote", "may", "say", "that", "the", "ensembl", "method", "could", "not", "make", "stabl", "predict", "for", "this", "instanc", "although", "this", "wide", "use", "techniqu", "may", "tri", "the", "most", "vote", "predict", "even", "that", "less", "than", "half", "the", "vote", "the", "final", "predict", "some", "articl", "may", "see", "this", "method", "call", "plural", "vote", "weight", "vote", "unlik", "major", "vote", "where", "each", "model", "has", "the", "same", "right", "can", "increas", "the", "import", "one", "more", "model", "weight", "vote", "count", "the", "predict", "the", "better", "model", "multipl", "time", "find", "reason", "set", "weight", "simpl", "averag", "simpl", "averag", "method", "for", "everi", "instanc", "test", "dataset", "the", "averag", "predict", "are", "calcul", "this", "method", "often", "reduc", "overfit", "and", "creat", "smoother", "regress", "model", "the", "follow", "pseudocod", "code", "show", "this", "simpl", "averag", "method", "finalpredict", "for", "rownumb", "len", "predict", "finalpredict", "append", "mean", "predict", "rownumb", "weight", "averag", "weight", "averag", "slight", "modifi", "version", "simpl", "averag", "where", "the", "predict", "each", "model", "multipli", "the", "weight", "and", "then", "their", "averag", "calcul", "the", "follow", "pseudocod", "code", "show", "the", "weight", "averag", "weight", "length", "equal", "finalpredict", "for", "rownumb", "len", "predict", "finalpredict", "append", "mean", "predict", "rownumb", "weight", "stack", "multipl", "machin", "learn", "model", "stack", "also", "known", "stack", "general", "ensembl", "method", "where", "the", "model", "are", "combin", "use", "anoth", "machin", "learn", "algorithm", "the", "basic", "idea", "train", "machin", "learn", "algorithm", "with", "train", "dataset", "and", "then", "generat", "new", "dataset", "with", "these", "model", "then", "this", "new", "dataset", "use", "input", "for", "the", "combin", "machin", "learn", "algorithm", "the", "pseudocod", "stack", "procedur", "summar", "below", "basealgorithm", "logisticregress", "decisiontreeclassif", "for", "classif", "stackingtraindataset", "matrix", "rowlength", "len", "target", "columnlength", "len", "algorithm", "stackingtestdataset", "matrix", "rowlength", "len", "test", "columnlength", "len", "algorithm", "for", "basealgorithm", "enumer", "basealgorithm", "stackingtraindataset", "basealgorithm", "fit", "train", "target", "predict", "train", "stackingtestdataset", "basealgorithm", "predict", "test", "finalpredict", "combineralgorithm", "fit", "stackingtraindataset", "target", "predict", "stackingtestdataset", "can", "see", "the", "abov", "pseudocod", "the", "train", "dataset", "for", "combin", "algorithm", "generat", "use", "the", "output", "the", "base", "algorithm", "the", "pseudocod", "the", "base", "algorithm", "generat", "use", "train", "dataset", "and", "then", "the", "same", "dataset", "use", "again", "make", "predict", "but", "know", "the", "real", "world", "not", "use", "the", "same", "train", "dataset", "for", "predict", "overcom", "this", "problem", "may", "see", "some", "implement", "stack", "where", "train", "dataset", "split", "below", "can", "see", "pseudocod", "where", "the", "train", "dataset", "split", "befor", "train", "the", "base", "algorithm", "basealgorithm", "logisticregress", "decisiontreeclassif", "for", "classif", "stackingtraindataset", "matrix", "rowlength", "len", "target", "columnlength", "len", "algorithm", "stackingtestdataset", "matrix", "rowlength", "len", "test", "columnlength", "len", "algorithm", "for", "basealgorithm", "enumer", "basealgorithm", "for", "trainix", "testix", "split", "train", "num", "may", "use", "sklearncrossvalidationkfold", "sklearn", "librari", "stackingtraindataset", "testcv", "basealgorithm", "fit", "train", "trainix", "target", "trainix", "predict", "train", "testix", "stackingtestdataset", "basealgorithm", "fit", "train", "predict", "test", "finalpredict", "combineralgorithm", "fit", "stackingtraindataset", "target", "predict", "stackingtestdataset"], "timestamp_scraper": 1556365479.75999, "title": "Ensemble Methods: Elegant Techniques to Produce Improved Machine Learning Results", "read_time": 349.8, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By Necati Demir</b>.</p>\n<p>Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble methods usually produces more accurate solutions than a single model would. This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods. In the popular Netflix Competition, <a href=\"http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/\">the winner used an ensemble method</a> to implement a powerful collaborative filtering algorithm. Another example is KDD 2009 where the winner also <a href=\"http://jmlr.org/proceedings/papers/v7/niculescu09/niculescu09.pdf\">used ensemble methods</a>. You can also find winners who used these methods in Kaggle competitions, for example <a href=\"http://blog.kaggle.com/2015/07/27/crowdflower-winners-interview-1st-place-chenglong-chen/\">here</a> is the interview with the winner of <a href=\"https://www.kaggle.com/c/crowdflower-search-relevance\">CrowdFlower competition</a>.</p>\n<p>It is important that we understand a few terminologies before we continue with this article. Throughout the article I used the term \u201cmodel\u201d to describe the output of the algorithm that trained with data. This model is then used for making predictions. This algorithm can be any <a href=\"http://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer\">machine learning</a> algorithm such as logistic regression, decision tree, etc. These models, when used as inputs of ensemble methods, are called \u201dbase models\u201d.</p>\n<p>In this blog post I will cover ensemble methods for classification and describe some widely known methods of ensemble: voting, stacking, bagging and boosting.</p>\n<p><b>Voting and Averaging Based Ensemble Methods</b></p>\n<p>Voting and averaging are two of the easiest ensemble methods. They are both easy to understand and implement. Voting is used for classification and averaging is used for regression.</p>\n<p><img alt=\"Classifying animal images\" src=\"/wp-content/uploads/classify-animals-1.jpg\" width=\"99%\"/></p>\n<p>In both methods, the first step is to create multiple classification/regression models using some training dataset. Each base model can be created using different splits of the same training dataset and same algorithm, or using the same dataset with different algorithms, or any other method. The following Python-esque pseudocode shows the use of same training dataset with different algorithms.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">train <span style=\"color:#808030; \">=</span> load_csv<span style=\"color:#808030; \">(</span><span style=\"color:#0000e6; \">\"train.csv\"</span><span style=\"color:#808030; \">)</span>\r\ntarget <span style=\"color:#808030; \">=</span> train<span style=\"color:#808030; \">[</span><span style=\"color:#0000e6; \">\"target\"</span><span style=\"color:#808030; \">]</span>\r\ntrain <span style=\"color:#808030; \">=</span> train<span style=\"color:#808030; \">.</span>drop<span style=\"color:#808030; \">(</span><span style=\"color:#0000e6; \">\"target\"</span><span style=\"color:#808030; \">)</span>\r\ntest <span style=\"color:#808030; \">=</span> load_csv<span style=\"color:#808030; \">(</span><span style=\"color:#0000e6; \">\"test.csv\"</span><span style=\"color:#808030; \">)</span>\r\n\r\nalgorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>logistic_regression<span style=\"color:#808030; \">,</span> decision_tree_classification<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for classification</span>\r\nalgorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>linear_regression<span style=\"color:#808030; \">,</span> decision_tree_regressor<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for regression</span>\r\n\r\npredictions <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\n\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> i<span style=\"color:#808030; \">,</span>algorithm <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">enumerate</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    predictions<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>According to the above pseudocode, we created predictions for each model and saved them in a matrix called predictions where each column contains predictions from one model.</p>\n<p><b>Majority Voting</b></p>\n<p>Every model makes a prediction (votes) for each test instance and the final output prediction is the one that receives more than half of the votes. If none of the predictions get more than half of the votes, we may say that the ensemble method could not make a stable prediction for this instance. Although this is a widely used technique, you may try the most voted prediction (even if that is less than half of the votes) as the final prediction. In some articles, you may see this method being called \u201cplurality voting\u201d.</p>\n<p><b>Weighted Voting</b></p>\n<p>Unlike majority voting, where each model has the same rights, we can increase the importance of one or more models. In weighted voting you count the prediction of the better models multiple times. Finding a reasonable set of weights is up to you.</p>\n<p><b>Simple Averaging</b></p>\n<p>In simple averaging method, for every instance of test dataset, the average predictions are calculated. This method often reduces overfit and creates a smoother regression model. The following pseudocode code shows this simple averaging method:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">final_predictions <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> row_number <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>predictions<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    final_predictions<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span>\r\n        mean<span style=\"color:#808030; \">(</span>prediction<span style=\"color:#808030; \">[</span>row_number<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span>\r\n    <span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Weighted Averaging</b></p>\n<p>Weighted averaging is a slightly modified version of simple averaging, where the prediction of each model is multiplied by the weight and then their average is calculated. The following pseudocode code shows the weighted averaging:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">weights <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#length is equal to len(algorithms)</span>\r\nfinal_predictions <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> row_number <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>predictions<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    final_predictions<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span>\r\n        mean<span style=\"color:#808030; \">(</span>prediction<span style=\"color:#808030; \">[</span>row_number<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">]</span><span style=\"color:#44aadd; \">*</span>weights<span style=\"color:#808030; \">)</span>\r\n    <span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Stacking Multiple Machine Learning Models</b></p>\n<p>Stacking, also known as stacked generalization, is an ensemble method where the models are combined using another <a href=\"http://www.toptal.com/machine-learning\">machine learning</a> algorithm. The basic idea is to train machine learning algorithms with training dataset and then generate a new dataset with these models. Then this new dataset is used as input for the combiner machine learning algorithm.</p>\n<p><img alt=\"Classifying animal images\" src=\"/wp-content/uploads/classify-animals-2.jpg\" width=\"99%\"/></p>\n<p>The pseudocode of a stacking procedure is summarized as below:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">base_algorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>logistic_regression<span style=\"color:#808030; \">,</span> decision_tree_classification<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for classification</span>\r\n\r\nstacking_train_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\nstacking_test_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\n\r\n\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> i<span style=\"color:#808030; \">,</span>base_algorithm <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">enumerate</span><span style=\"color:#808030; \">(</span>base_algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    stacking_train_dataset<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">)</span>\r\n    stacking_test_dataset<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span>\r\n\r\nfinal_predictions <span style=\"color:#808030; \">=</span> combiner_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>stacking_train_dataset<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>stacking_test_dataset<span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>As you can see in the above pseudocode, the training dataset for combiner algorithm is generated using the outputs of the base algorithms. In the pseudocode, the base algorithm is generated using training dataset and then the same dataset is used again to make predictions. But as we know, in the real world we do not use the same training dataset for prediction, so to overcome this problem you may see some implementations of stacking where training dataset is splitted. Below you can see a pseudocode where the training dataset is split before training the base algorithms:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"color:#000000;background:#ffffff;\">base_algorithms <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span>logistic_regression<span style=\"color:#808030; \">,</span> decision_tree_classification<span style=\"color:#808030; \">,</span> <span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">.</span><span style=\"color:#808030; \">]</span> <span style=\"color:#696969; \">#for classification</span>\r\n\r\nstacking_train_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\nstacking_test_dataset <span style=\"color:#808030; \">=</span> matrix<span style=\"color:#808030; \">(</span>row_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">,</span> column_length<span style=\"color:#808030; \">=</span><span style=\"color:#400000; \">len</span><span style=\"color:#808030; \">(</span>algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\r\n\r\n<span style=\"color:#800000; font-weight:bold; \">for</span> i<span style=\"color:#808030; \">,</span>base_algorithm <span style=\"color:#800000; font-weight:bold; \">in</span> <span style=\"color:#400000; \">enumerate</span><span style=\"color:#808030; \">(</span>base_algorithms<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\r\n    <span style=\"color:#800000; font-weight:bold; \">for</span> trainix<span style=\"color:#808030; \">,</span> testix <span style=\"color:#800000; font-weight:bold; \">in</span> split<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">,</span> k<span style=\"color:#808030; \">=</span><span style=\"color:#008c00; \">10</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span> <span style=\"color:#696969; \">#you may use sklearn.cross_validation.KFold of sklearn library</span>\r\n        stacking_train_dataset<span style=\"color:#808030; \">[</span>testcv<span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">[</span>trainix<span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">[</span>trainix<span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">[</span>testix<span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span>\r\nstacking_test_dataset<span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">,</span>i<span style=\"color:#808030; \">]</span> <span style=\"color:#808030; \">=</span> base_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>train<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>test<span style=\"color:#808030; \">)</span>\r\n\r\n\r\nfinal_predictions <span style=\"color:#808030; \">=</span> combiner_algorithm<span style=\"color:#808030; \">.</span>fit<span style=\"color:#808030; \">(</span>stacking_train_dataset<span style=\"color:#808030; \">,</span> target<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">.</span>predict<span style=\"color:#808030; \">(</span>stacking_test_dataset<span style=\"color:#808030; \">)</span>\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n</div> ", "website": "kdnuggets"}