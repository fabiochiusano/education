{"content": "By Favio Vazquez , Founder at Ciencia y Datos. comments Editor's note: This post covers Favio's selections for the top 7 Python libraries of 2018. Tomorrow's post will cover his top 7 R packages of the year. \u00a0 Introduction \u00a0 If you follow me, you know that this year I started a series called\u00a0 Weekly Digest for Data Science and AI: Python & R , where I highlighted the best libraries, repos, packages, and tools that help us be better data scientists for all kinds of tasks. The great folks at\u00a0 Heartbeat \u00a0sponsored a lot of these digests, and they asked me to create a list of the best of the best\u2014those libraries that really changed or improved the way we worked this year (and beyond). If you want to read the past digests, take a look here: Weekly Digest for Data Science and AI - Revue Weekly Digest for Data Science and AI - Personal newsletter of Favio V\u00e1zquez... www.getrevue.co Disclaimer: This list is based on the libraries and packages I reviewed in my personal newsletter. All of them were trending in one way or another among programmers, data scientists, and AI enthusiasts. Some of them were created before 2018, but if they were trending, they could be considered. \u00a0 Top 7 for\u00a0Python \u00a0 \u00a0 7. AdaNet\u200a\u2014\u200aFast and flexible AutoML with learning guarantees. \u00a0 /tensorflow/adanet AdaNet is a lightweight and scalable TensorFlow AutoML framework for training and deploying adaptive neural networks using the\u00a0 AdaNet \u00a0algorithm [ Cortes et al. ICML 2017 ].\u00a0 AdaNet \u00a0combines several learned subnetworks in order to mitigate the complexity inherent in designing effective neural networks. This package will help you selecting optimal neural network architectures, implementing an adaptive algorithm for learning a neural architecture as an ensemble of subnetworks. You will need to know TensorFlow to use the package because it implements a TensorFlow Estimator, but this will help you simplify your machine learning programming by encapsulating training and also evaluation, prediction and export for serving. You can build an ensemble of neural networks, and the library will help you optimize an objective that balances the trade-offs between the ensemble\u2019s performance on the training set and its ability to generalize to unseen data. Installation adanet \u00a0depends on bug fixes and enhancements not present in TensorFlow releases prior to 1.7. You must install or upgrade your TensorFlow package to at least 1.7: $ pip install \"tensorflow>=1.7.0\" Installing from\u00a0source To install from source, you\u2019ll first need to install\u00a0 bazel \u00a0following their\u00a0 installation instructions . Next clone\u00a0 adanet \u00a0and\u00a0 cd \u00a0into its root directory: $ git clone /tensorflow/adanet && cd adanet From the\u00a0 adanet \u00a0root directory run the tests: $ cd adanet\r $ bazel test -c opt //... Once you have verified that everything works well, install\u00a0 adanet \u00a0as a\u00a0 pip package\u00a0 . You\u2019re now ready to experiment with\u00a0 adanet . import adanet Usage Here you can find two examples on the usage of the package: tensorflow/adanet Fast and flexible AutoML with learning guarantees.\u200a\u2014\u200atensorflow/adanet github.com You can read more about it in the original blog post: Introducing AdaNet: Fast and Flexible AutoML with Learning Guarantees Posted by Charles Weill, Software Engineer, Google AI, NYC Ensemble learning\u00a0, the art of combining different machine\u2026 ai.googleblog.com \u00a0 6. TPOT\u2014 An automated Python machine learning tool that optimizes machine learning pipelines using genetic programming. \u00a0 /EpistasisLab/tpot Previously \u00a0I talked about Auto-Keras, a great library for AutoML in the Pythonic world. Well, I have another very interesting tool for that. The name is\u00a0 TPOT \u00a0(Tree-based Pipeline Optimization Tool), and it\u2019s an amazing library. It\u2019s basically a Python automated machine learning tool that optimizes machine learning pipelines using\u00a0 genetic programming . TPOT can automate a lot of stuff like feature selection, model selection, feature construction, and much more. Luckily, if you\u2019re a Python machine learner, TPOT is built on top of Scikit-learn, so all of the code it generates should look familiar. What it does is automate the most tedious parts of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data, and then it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there. This is how it works: For more details you can read theses great article by\u00a0 Matthew Mayo : Using AutoML to Generate Machine Learning Pipelines with TPOT Thus far in this series of posts we have: This post will take a different approach to constructing pipelines. Certainly\u2026 www.kdnuggets.com and\u00a0 Randy Olson : TPOT: A Python Tool for Automating Data Science By Randy Olson, University of Pennsylvania. Machine learning is often touted as: A field of study that gives computers\u2026 www.kdnuggets.com Installation You actually need to follow some instructions before installing TPOT. Here they are: Installation\u200a\u2014\u200aTPOT Optionally, you can install XGBoost if you would like TPOT to use the eXtreme Gradient Boosting models. XGBoost is\u2026 epistasislab.github.io After that you can just run: pip install tpot Examples: First let\u2019s start with the basic Iris dataset: So here we built a very basic TPOT pipeline that will try to look for the best ML pipeline to predict the\u00a0 iris.target .\u00a0 And then we save that pipeline. After that, what we have to do is very simple\u200a\u2014\u200aload the\u00a0 .py \u00a0file you generated and you\u2019ll see: \r import numpy as np\r \r from sklearn.kernel_approximation import RBFSampler\r from sklearn.model_selection import train_test_split\r from sklearn.pipeline import make_pipeline\r from sklearn.tree import DecisionTreeClassifier\r \r # NOTE: Make sure that the class is labeled 'class' in the data file\r tpot_data = \r features = ., , axis=1)\r training_features, testing_features, training_classes, testing_classes = \\\r \r \r exported_pipeline = ,\r \r )\r \r \r results = \r And that\u2019s it. You built a classifier for the Iris dataset in a simple but powerful way. Let\u2019s go the MNIST dataset now: As you can see, we did the same! Let\u2019s load the\u00a0 .py \u00a0file you generated again and you\u2019ll see: \r import numpy as np\r \r from sklearn.model_selection import train_test_split\r from sklearn.neighbors import KNeighborsClassifier\r \r # NOTE: Make sure that the class is labeled 'class' in the data file\r tpot_data = \r features = ., , axis=1)\r training_features, testing_features, training_classes, testing_classes = \\\r \r \r exported_pipeline = \r \r \r results = \r Super easy and fun. Check them out! Try it and please give them a star! \u00a0 5. SHAP\u200a\u2014\u200aA unified approach to explain the output of any machine learning\u00a0model \u00a0 /slundberg/shap Explaining machine learning models isn\u2019t always easy. Yet it\u2019s so important for a range of business applications. Luckily, there are some great libraries that help us with this task. In many applications, we need to know, understand, or prove how input variables are used in the model, and how they impact final model predictions. SHAP \u00a0(SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations. Installation SHAP can be installed from\u00a0 PyPI pip install shap or\u00a0 conda-forge conda install -c conda-forge shap Usage There are tons of different models and ways to use the package. Here, I\u2019ll take one example from the DeepExplainer. Deep SHAP is a high-speed approximation algorithm for SHAP values in deep learning models that builds on a connection with\u00a0 DeepLIFT , as described in the SHAP NIPS paper that you can read here: [1802.03888] Consistent Individualized Feature Attribution for Tree Ensembles Abstract: Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is\u2026 arxiv.org Here you can see how SHAP can be used to explain the result of a Keras model for the MNIST dataset: You can find more examples here: slundberg/shap A unified approach to explain the output of any machine learning model.\u200a\u2014\u200aslundberg/shap github.com Take a look. You\u2019ll be surprised\u00a0:)", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"Gold Blog\" src=\"/images/tkb-1901-g.png\" width=\"94\"/>2018\u2019s Top 7 Python Libraries for Data Science and AI</h1> ", "url": "https://www.kdnuggets.com/2019/01/vazquez-2018-top-7-python-libraries.html", "tfidf": {"tfidf": {"after": 2.04140414042, "boost": 18.32198499712, "art": 1.9994962216599999, "axisnum": 3175.2, "highspe": 1587.6, "onc": 1.4974533106999999, "adanet": 20638.8, "pip": 542.769230768, "repo": 369.209302326, "kind": 2.5806241872599998, "addit": 2.49269901084, "would": 1.0828729281799998, "encapsul": 68.72727272729999, "googl": 11.388809182200001, "testingclass": 3175.2, "cort": 88.6927374302, "dataset": 774.439024392, "class": 8.46607119052, "learner": 75.2417061611, "python": 506.68085106359996, "sklearnkernelapproxim": 1587.6, "well": 2.1311497416, "work": 3.34560269739, "tree": 8.255850234, "approach": 8.30226173356, "enthusiast": 9.39408284024, "their": 1.01547908405, "highlight": 5.83033419023, "origin": 1.13724928367, "creat": 2.4985835694, "how": 6.41001312204, "test": 5.31414225942, "instruct": 8.338235294119999, "present": 1.25551601423, "epistasislabtpot": 1587.6, "alway": 2.06745670009, "found": 1.11387076405, "upgrad": 8.88913773796, "interest": 1.60331246213, "guarante": 19.71357615894, "deep": 7.2559414990799995, "will": 8.57367690172, "exportedpipelin": 3175.2, "consid": 1.2397313759200002, "unit": 1.15394679459, "clone": 65.0655737704, "tensorflowadanet": 6350.4, "next": 1.4950560316400001, "perform": 1.5313977042500002, "but": 3.04897253697, "were": 3.07376573088, "need": 5.749049429639999, "certainly\u2026": 1587.6, "final": 1.34008609775, "expect": 2.20011086475, "amaz": 15.250720461099998, "applic": 6.85344269372, "review": 2.2099109131400003, "testingfeatur": 3175.2, "wwwkdnuggetscom": 3175.2, "opt": 12.721153846199998, "have": 4.059579364559999, "tensorflow": 9525.599999999999, "use": 9.266748816419998, "experi": 1.87062566278, "out": 1.06016694491, "model": 22.9965762444, "best\u2014thos": 1587.6, "sure": 14.907042253520002, "iri": 98.6086956522, "sklearnneighbor": 1587.6, "optim": 57.688953488500005, "field": 1.7790228597, "usag": 19.282591093109996, "not": 1.01567398119, "far": 1.71022298826, "sponsor": 5.66393150196, "weill": 244.246153846, "founder": 4.033536585369999, "subnetwork": 3175.2, "git": 360.818181818, "unseen": 40.8123393316, "unifi": 22.82127455679, "pleas": 9.12938470385, "easi": 10.5875291764, "autokera": 1587.6, "explan": 13.0184501845, "then": 2.17315721032, "they": 5.15086626435, "deepexplain": 1587.6, "deploy": 7.41869158879, "instal": 64.38263358782, "effect": 1.3963060686000002, "let": 10.45849802373, "world": 1.11340206186, "scienc": 9.27878433664, "anoth": 2.27287043664, "blog": 14.1876675603, "construct": 3.8641840087599997, "export": 6.727118644069999, "featur": 9.16275490572, "rbfsampler": 1587.6, "simpl": 6.7962328767199995, "that": 19.07569721125, "provid": 1.21552714187, "valu": 2.2777618364400003, "softwar": 10.2624434389, "such": 1.06151377374, "makepipelin": 1587.6, "sklearntre": 1587.6, "thousand": 2.4767550702000003, "talk": 3.0303493033, "kneighborsclassifi": 1587.6, "network": 10.37477536352, "lot": 8.81755068036, "some": 3.1211009174399997, "sourc": 3.39520958084, "should": 1.6643254009900001, "super": 7.380753138080001, "result": 3.43834825296, "tpot": 1587.6, "introduc": 1.7258397651900002, "set": 1.18707940781, "ani": 3.40151406942, "two": 1.01379310345, "seri": 2.93023255814, "pennsylvania": 7.27589367553, "improv": 2.04376930999, "from": 13.00737379461, "machine\u2026": 1587.6, "detail": 2.26186066391, "num": 13.00409552013, "editor": 4.33060556465, "wwwgetrevueco": 1587.6, "balanc": 4.45329593268, "for": 21.00661584021, "depend": 2.2411067193700003, "predict": 20.7393860222, "output": 23.03094777564, "releas": 1.8377126982299998, "simplifi": 12.109839816900001, "with": 11.013180298889997, "input": 12.2029208301, "are": 4.11962374312, "inher": 10.7706919946, "look": 7.634527530639999, "option": 4.04896710023, "combin": 3.39520958084, "numpi": 3175.2, "root": 7.15618661258, "veri": 3.77640342531, "trend": 10.86281217926, "is\u2026": 3175.2, "forest": 4.89546716004, "stuff": 23.3127753304, "conda": 1587.6, "familiar": 6.86381322957, "again": 1.50883862384, "know": 7.779810519450001, "doe": 1.70581282905, "give": 2.7306501548, "condaforg": 3175.2, "bug": 27.372413793099998, "train": 5.8097096853, "great": 5.06371102784, "design": 1.45825296225, "genet": 20.511627907, "framework": 8.200413223139998, "extrem": 2.36602086438, "his": 1.0943682360200002, "ask": 2.1744966443, "comment": 3.05954904606, "note": 1.42449528937, "scientist": 9.38852749852, "machin": 56.340684410639994, "into": 1.01502461479, "paper": 2.6628648104700003, "prior": 2.17807655371, "revu": 34.7396061269, "v\u00e1zquez": 1587.6, "traintestsplit": 3175.2, "what": 2.50686878256, "tpotdata": 3175.2, "local": 3.03440366972, "interpret": 3.2150668286799995, "flexibl": 29.059182428310002, "help": 6.99814863795, "favio": 4762.799999999999, "decisiontreeclassifi": 1587.6, "find": 5.188235294129999, "abil": 2.70875277256, "deeplift": 1587.6, "cover": 3.38760268858, "least": 1.6165359943000002, "approxim": 2.2132998745299997, "base": 2.2925631769, "label": 8.95431472082, "githubcom": 3175.2, "univers": 1.24889867841, "post": 13.42957845762, "here": 19.38461538464, "better": 2.0065722952500002, "randi": 43.6153846154, "surpris": 4.36633663366, "much": 1.1942229577299999, "olson": 110.6341463414, "evalu": 6.9509632224199995, "sklearnpipelin": 1587.6, "about": 2.12972030318, "run": 3.11385701676, "scikitlearn": 1587.6, "neural": 297.3033707865, "shap": 2646.0, "just": 1.33580143037, "programm": 5.181462140990001, "adapt": 6.64545835078, "xgboost": 3175.2, "sklearnmodelselect": 3175.2, "classifi": 5.2937645882, "check": 6.50655737705, "where": 1.06715063521, "ensembl": 100.481012658, "save": 2.8178913737999998, "complex": 2.34021226415, "tool": 29.983002832860002, "start": 2.53347163488, "among": 1.25670862028, "articl": 2.01805008262, "load": 13.60994427776, "them": 4.39504463976, "dato": 278.526315789, "iristarget": 1587.6, "studi": 1.53184098804, "explain": 13.00245700245, "order": 1.24625166811, "autom": 99.1011235955, "mani": 1.04426757877, "the": 53.0, "generat": 8.21101629168, "build": 3.2683479156, "algorithm": 83.8521126762, "epistasislabgithubio": 1587.6, "select": 8.09380576088, "consist": 2.9802890932999997, "same": 1.11857958148, "trainingclass": 3175.2, "there": 3.12273800157, "connect": 3.7687833827800006, "charl": 2.3075581395299998, "possibl": 2.8347468976, "best": 7.914257228300001, "repres": 1.46972782818, "star": 2.4450947173900004, "take": 4.55846672888, "follow": 3.1392037964699995, "now": 2.321561746, "tri": 3.7089125102199993, "name": 1.10211732037, "code": 7.761427523839999, "scalabl": 186.776470588, "basic": 8.190541702500001, "realli": 4.7476076555, "power": 1.3396337861799998, "fix": 4.4346368715099995, "also": 1.01476510067, "person": 2.81040892194, "everyth": 4.81967213115, "task": 7.77282741738, "theori": 3.02745995423, "vazquez": 610.615384615, "mayo": 49.7680250784, "past": 2.01702452039, "sever": 2.14482572278, "newslett": 60.136363636400006, "want": 1.99698113208, "enhanc": 5.15957101072, "explor": 3.39593582888, "individu": 1.8004082558400003, "intellig": 4.19334389857, "prove": 2.45720476706, "pypi": 1587.6, "attribut": 6.8313253012, "actual": 1.87482286254, "disclaim": 98.6086956522, "week": 5.41596543099, "like": 2.2983713355, "thus": 1.6463756092500001, "estim": 2.34991119005, "abstract": 9.966101694919999, "variabl": 8.747107438019999, "introduct": 2.7808723068799996, "one": 3.01882487166, "impact": 2.97526236882, "bazel": 3175.2, "trainingfeatur": 3175.2, "see": 5.08968502044, "tomorrow": 21.3674293405, "becaus": 1.1495184997499999, "beyond": 2.54586273252, "arxivorg": 1587.6, "random": 7.1902173913, "implement": 7.15296237892, "aigoogleblogcom": 1587.6, "file": 15.084085510679998, "part": 1.04330682789, "mitig": 22.8103448276, "digest": 95.29411764700001, "tinker": 92.8421052632, "understand": 2.96858638743, "yet": 2.1258703802900003, "kera": 835.5789473680001, "tedious": 93.3882352941, "this": 10.037936267100001, "directori": 29.536744186, "rang": 1.7848229342299997, "engin": 2.47135740971, "chang": 1.1808985421, "computers\u2026": 1587.6, "differ": 3.7096347067499997, "previous": 2.85693719632, "most": 1.02096463023, "between": 1.03453668708, "shapley": 1058.4, "all": 3.03440366973, "top": 7.355107713680001, "busi": 2.05541170378, "ton": 10.5278514589, "program": 6.06417112299, "verifi": 14.2258064516, "gradient": 83.778364116, "slundbergshap": 4762.799999999999, "architectur": 10.25581395348, "tradeoff": 208.89473684200001, "built": 5.98341708543, "object": 2.3488681757700003, "more": 4.0686827268, "and": 34.00214173242, "list": 2.72642967542, "automl": 9525.599999999999, "these": 2.14830852504, "folk": 7.6658619024600005, "general": 1.1218202374200001, "could": 1.2043695949, "befor": 2.20072082062, "librari": 21.4613044948, "year": 3.1456310679600006, "serv": 1.4668760972, "can": 16.46765947988, "describ": 1.47027227264, "make": 2.1525320317200003, "way": 4.8762957844, "onli": 1.0256476516600002, "often": 1.29452054795, "accur": 5.768895348840001, "read": 9.259842519680001, "packag": 70.45562130174001, "data": 33.7643555934, "lightweight": 32.4, "method": 7.714285714290001, "call": 1.0676529926, "fast": 14.618784530400001, "must": 1.9220338983099996, "exampl": 6.01933649288, "readi": 5.15789473684, "matthew": 6.908616187989999, "treebas": 1587.6, "import": 13.401992233700001, "first": 2.01523229246, "game": 2.57978550536, "luckili": 382.554216868, "fun": 12.8863636364, "ciencia": 236.955223881, "tout": 37.6208530806, "learn": 44.13226042435, "heartbeat": 103.090909091, "pipelin": 353.5141700409}, "logtfidf": {"after": 0.040981389296199995, "boost": 4.429909048380001, "art": 0.6928952596619999, "axisnum": 14.739957441820001, "highspe": 7.369978720910001, "onc": 0.403765872355, "adanet": 95.80972337183, "pip": 19.64155951644, "repo": 5.91136369821, "kind": 0.948031302717, "addit": 0.440437765944, "would": 0.0796176279647, "encapsul": 4.230146103380001, "googl": 2.43263122258, "testingclass": 14.739957441820001, "cort": 4.48517800806, "dataset": 21.06337826656, "class": 2.9990887597320004, "learner": 4.320705680430001, "python": 36.275910686639996, "sklearnkernelapproxim": 7.369978720910001, "well": 0.1270288766312, "work": 0.327103701819, "tree": 2.8355497755, "approach": 2.9209344583240004, "enthusiast": 2.24008000599, "their": 0.015360505122700001, "highlight": 1.76307432123, "origin": 0.128612437587, "creat": 0.445153637028, "how": 1.8862678277200002, "test": 1.954448874206, "instruct": 2.85540883598, "present": 0.227546654799, "epistasislabtpot": 7.369978720910001, "alway": 0.726319204572, "found": 0.107841124048, "upgrad": 2.18483005247, "interest": 0.47207177798199995, "guarante": 5.64808576455, "deep": 2.5773469396, "will": 1.419505744405, "exportedpipelin": 14.739957441820001, "consid": 0.214894723824, "unit": 0.143188061817, "clone": 6.9644968161000005, "tensorflowadanet": 29.479914883640003, "next": 0.402163685499, "perform": 0.42618085058, "but": 0.0485771162157, "were": 0.07287343104329999, "need": 1.450960653768, "certainly\u2026": 7.369978720910001, "final": 0.292733863948, "expect": 0.78850775216, "amaz": 2.7246267452900006, "applic": 2.46320785698, "review": 0.7929522039210001, "testingfeatur": 14.739957441820001, "wwwkdnuggetscom": 14.739957441820001, "opt": 2.54326626497, "have": 0.0591400093648, "tensorflow": 44.21987232546, "use": 0.2628721775844, "experi": 0.626272953933, "out": 0.0584263909193, "model": 8.111950804221001, "best\u2014thos": 7.369978720910001, "sure": 4.0173731104, "iri": 7.796024536719999, "sklearnneighbor": 7.369978720910001, "optim": 12.228138977049998, "field": 0.5760642583510001, "usag": 5.58177115284, "not": 0.0155524130075, "far": 0.536623764503, "sponsor": 1.7341182627400002, "weill": 5.4981765440100006, "founder": 1.3946435557299999, "subnetwork": 14.739957441820001, "git": 5.8883741799800005, "unseen": 3.708984470280001, "unifi": 6.08724272049, "pleas": 2.21149829955, "easi": 3.3330592702999997, "autokera": 7.369978720910001, "explan": 3.74644083138, "then": 0.16606773046179998, "they": 0.148634973838, "deepexplain": 7.369978720910001, "deploy": 2.00400270589, "instal": 22.637719994300003, "effect": 0.333830227158, "let": 3.7464077018399995, "world": 0.107420248621, "scienc": 3.365744715564, "anoth": 0.255792723304, "blog": 2.65237310559, "construct": 1.317206711944, "export": 1.90614691588, "featur": 2.5403245088519997, "rbfsampler": 7.369978720910001, "simpl": 2.4464425787799997, "that": 0.07554681921315999, "provid": 0.19517784432500002, "valu": 0.823193310148, "softwar": 2.32849096333, "such": 0.059695977806, "makepipelin": 7.369978720910001, "sklearntre": 7.369978720910001, "thousand": 0.906949263988, "talk": 1.10867789449, "kneighborsclassifi": 7.369978720910001, "network": 3.8123322122079997, "lot": 2.9671939005000003, "some": 0.11872052719350001, "sourc": 1.058436621502, "should": 0.509419876758, "super": 1.9988756846400002, "result": 0.40913672514300004, "tpot": 7.369978720910001, "introduc": 0.5457137524260001, "set": 0.171496011289, "ani": 0.376825075098, "two": 0.0136988443582, "seri": 0.7638692213959999, "pennsylvania": 1.98456664751, "improv": 0.7147958039319999, "from": 0.007371704195258, "machine\u2026": 7.369978720910001, "detail": 0.816187777173, "num": 0.004094875140161, "editor": 1.4657073855, "wwwgetrevueco": 7.369978720910001, "balanc": 1.4936444810499998, "for": 0.006614798303337001, "depend": 0.806969815, "predict": 6.5829609507599995, "output": 6.11467973481, "releas": 0.608521699544, "simplifi": 2.4940183301400003, "with": 0.01317240884729, "input": 2.50167533539, "are": 0.1178698943308, "inher": 2.37682874115, "look": 2.5855467744, "option": 1.39846181161, "combin": 1.058436621502, "numpi": 14.739957441820001, "root": 2.54966012504, "veri": 0.6904793797140001, "trend": 3.3843960975800003, "is\u2026": 14.739957441820001, "forest": 1.5883097076, "stuff": 3.1490015077499995, "conda": 7.369978720910001, "familiar": 1.92626315167, "again": 0.411340231612, "know": 2.8587590831939997, "doe": 0.5340417297169999, "give": 0.622785104448, "condaforg": 14.739957441820001, "bug": 3.30953571036, "train": 1.982754938517, "great": 0.943221032316, "design": 0.377239118022, "genet": 4.6556895195, "framework": 2.10418454607, "extrem": 0.8612095839370001, "his": 0.0901772433641, "ask": 0.776797209847, "comment": 1.11826753454, "note": 0.353817568083, "scientist": 3.09268256888, "machin": 19.49303412868, "into": 0.0149128632287, "paper": 0.979402539665, "prior": 0.778442172521, "revu": 3.54788042301, "v\u00e1zquez": 7.369978720910001, "traintestsplit": 14.739957441820001, "what": 0.451774593654, "tpotdata": 14.739957441820001, "local": 0.833735480412, "interpret": 1.1678481440000001, "flexibl": 6.812166705479999, "help": 1.68103860672, "favio": 22.10993616273, "decisiontreeclassifi": 7.369978720910001, "find": 1.643343990864, "abil": 0.996488297427, "deeplift": 7.369978720910001, "cover": 1.053950638312, "least": 0.480285584745, "approxim": 0.7944845577770001, "base": 0.27304660457400004, "label": 2.99797665454, "githubcom": 14.739957441820001, "univers": 0.222262105686, "post": 4.834200916205999, "here": 7.080305506960001, "better": 0.6964279406, "randi": 6.16452553142, "surpris": 1.47392435861, "much": 0.17749572930100002, "olson": 8.02616319628, "evalu": 1.9388802431299998, "sklearnpipelin": 7.369978720910001, "about": 0.1256869549492, "run": 0.885429951078, "scikitlearn": 7.369978720910001, "neural": 20.4265757775, "shap": 14.37531432822, "just": 0.289531434109, "programm": 1.6450872830399998, "adapt": 2.4015729720400003, "xgboost": 14.739957441820001, "sklearnmodelselect": 14.739957441820001, "classifi": 1.6665296351499999, "check": 1.87281049562, "where": 0.0649921387457, "ensembl": 16.9092558699, "save": 1.03598886547, "complex": 0.8502416364309999, "tool": 9.653227077779999, "start": 0.472886738582, "among": 0.228496097073, "articl": 0.702131739574, "load": 3.83530708376, "them": 0.3767333076372, "dato": 5.62951254607, "iristarget": 7.369978720910001, "studi": 0.426470272221, "explain": 4.77850213679, "order": 0.22014038079300002, "autom": 14.933514334149997, "mani": 0.0433157581221, "the": 0.0, "generat": 2.876729366944, "build": 0.982274904182, "algorithm": 9.99132718554, "epistasislabgithubio": 7.369978720910001, "select": 2.819218748532, "consist": 0.797746252852, "same": 0.112059649604, "trainingclass": 14.739957441820001, "there": 0.12029367877649999, "connect": 1.267210117364, "charl": 0.836189882976, "possibl": 0.697610949782, "best": 2.296139664735, "repres": 0.38507723275, "star": 0.8940838613940001, "take": 0.522767848788, "follow": 0.1360707332826, "now": 0.298185890042, "tri": 1.23518305832, "name": 0.09723316638430002, "code": 2.71203819194, "scalabl": 5.22991255741, "basic": 3.01310324685, "realli": 1.5576408397, "power": 0.292396282715, "fix": 1.48944573451, "also": 0.0146571578, "person": 0.6803656320360001, "everyth": 1.57270590317, "task": 2.71497361322, "theori": 1.10772396902, "vazquez": 6.414467275880001, "mayo": 3.90737271112, "past": 0.7016234157610001, "sever": 0.13982224079379998, "newslett": 6.8069350604, "want": 0.6916366062549999, "enhanc": 1.6408534385799998, "explor": 1.22257937218, "individu": 0.588013447985, "intellig": 1.43349848213, "prove": 0.899024430345, "pypi": 7.369978720910001, "attribut": 2.4567430307400002, "actual": 0.628514181648, "disclaim": 4.591159448919999, "week": 1.7722165924859998, "like": 0.27810715309, "thus": 0.49857627139300004, "estim": 0.854377535975, "abstract": 2.29918950399, "variabl": 2.1687230672, "introduct": 1.02276465794, "one": 0.0187660549365, "impact": 1.09033222631, "bazel": 14.739957441820001, "trainingfeatur": 14.739957441820001, "see": 0.963686341968, "tomorrow": 3.0618677691900005, "becaus": 0.139343158825, "beyond": 0.934469583725, "arxivorg": 7.369978720910001, "random": 1.9727214065099998, "implement": 2.54875881814, "aigoogleblogcom": 7.369978720910001, "file": 5.30938354892, "part": 0.04239531098280001, "mitig": 3.1272141535699998, "digest": 14.737650858700002, "tinker": 4.5309002574, "understand": 1.0880858756799998, "yet": 0.754181309241, "kera": 6.72812483474, "tedious": 4.53676537685, "this": 0.037864490525, "directori": 5.3849757466799995, "rang": 0.579319213803, "engin": 0.904767558276, "chang": 0.166275625058, "computers\u2026": 7.369978720910001, "differ": 0.6369633639360001, "previous": 0.713205920126, "most": 0.020747896295599998, "between": 0.033953681165299995, "shapley": 6.964513612799999, "all": 0.03420789629339999, "top": 2.436402551152, "busi": 0.720476170355, "ton": 2.35402426534, "program": 2.111356736295, "verifi": 2.65505767096, "gradient": 7.47005521764, "slundbergshap": 22.10993616273, "architectur": 3.26939515838, "tradeoff": 5.34183047362, "built": 2.0711386051950003, "object": 0.853933584803, "more": 0.06809972639999999, "and": 0.0021416648301624, "list": 0.619691523012, "automl": 44.21987232546, "these": 0.1430672388016, "folk": 2.03677695251, "general": 0.114952578063, "could": 0.18595627229000003, "befor": 0.191275543759, "librari": 7.894479847544, "year": 0.14220671668380003, "serv": 0.383135035608, "can": 2.272775349516, "describ": 0.385447603125, "make": 0.14699531564579998, "way": 0.7923660397400001, "onli": 0.025324268329099998, "often": 0.258140393351, "accur": 1.75248061485, "read": 3.35757072352, "packag": 18.519826042710005, "data": 12.168205848, "lightweight": 3.4781584227999995, "method": 2.833384826523, "call": 0.0654627744488, "fast": 4.751085074220001, "must": 0.653383947388, "exampl": 1.6347306999959998, "readi": 1.6405284994999998, "matthew": 1.9327693554900003, "treebas": 7.369978720910001, "import": 2.92818277066, "first": 0.015174579624319999, "game": 0.9477062580210001, "luckili": 10.50744641222, "fun": 2.5561696698099996, "ciencia": 5.46787119451, "tout": 3.6275584998699997, "learn": 16.012289230154998, "heartbeat": 4.63561121149, "pipelin": 38.17031126392}, "logidf": {"after": 0.020490694648099998, "boost": 2.2149545241900004, "art": 0.6928952596619999, "axisnum": 7.369978720910001, "highspe": 7.369978720910001, "onc": 0.403765872355, "adanet": 7.369978720910001, "pip": 4.91038987911, "repo": 5.91136369821, "kind": 0.948031302717, "addit": 0.220218882972, "would": 0.0796176279647, "encapsul": 4.230146103380001, "googl": 2.43263122258, "testingclass": 7.369978720910001, "cort": 4.48517800806, "dataset": 5.26584456664, "class": 0.7497721899330001, "learner": 4.320705680430001, "python": 4.03065674296, "sklearnkernelapproxim": 7.369978720910001, "well": 0.0635144383156, "work": 0.109034567273, "tree": 1.41777488775, "approach": 0.7302336145810001, "enthusiast": 2.24008000599, "their": 0.015360505122700001, "highlight": 1.76307432123, "origin": 0.128612437587, "creat": 0.222576818514, "how": 0.47156695693000006, "test": 0.977224437103, "instruct": 1.42770441799, "present": 0.227546654799, "epistasislabtpot": 7.369978720910001, "alway": 0.726319204572, "found": 0.107841124048, "upgrad": 2.18483005247, "interest": 0.47207177798199995, "guarante": 1.8826952548500002, "deep": 1.2886734698, "will": 0.202786534915, "exportedpipelin": 7.369978720910001, "consid": 0.214894723824, "unit": 0.143188061817, "clone": 3.4822484080500002, "tensorflowadanet": 7.369978720910001, "next": 0.402163685499, "perform": 0.42618085058, "but": 0.0161923720719, "were": 0.024291143681099997, "need": 0.362740163442, "certainly\u2026": 7.369978720910001, "final": 0.292733863948, "expect": 0.78850775216, "amaz": 2.7246267452900006, "applic": 1.23160392849, "review": 0.7929522039210001, "testingfeatur": 7.369978720910001, "wwwkdnuggetscom": 7.369978720910001, "opt": 2.54326626497, "have": 0.0147850023412, "tensorflow": 7.369978720910001, "use": 0.0292080197316, "experi": 0.626272953933, "out": 0.0584263909193, "model": 0.7374500731110001, "best\u2014thos": 7.369978720910001, "sure": 2.0086865552, "iri": 3.8980122683599996, "sklearnneighbor": 7.369978720910001, "optim": 2.4456277954099996, "field": 0.5760642583510001, "usag": 1.86059038428, "not": 0.0155524130075, "far": 0.536623764503, "sponsor": 1.7341182627400002, "weill": 5.4981765440100006, "founder": 1.3946435557299999, "subnetwork": 7.369978720910001, "git": 5.8883741799800005, "unseen": 3.708984470280001, "unifi": 2.02908090683, "pleas": 2.21149829955, "easi": 1.6665296351499999, "autokera": 7.369978720910001, "explan": 1.87322041569, "then": 0.08303386523089999, "they": 0.0297269947676, "deepexplain": 7.369978720910001, "deploy": 2.00400270589, "instal": 1.3316305879, "effect": 0.333830227158, "let": 1.2488025672799998, "world": 0.107420248621, "scienc": 0.841436178891, "anoth": 0.127896361652, "blog": 2.65237310559, "construct": 0.658603355972, "export": 1.90614691588, "featur": 0.423387418142, "rbfsampler": 7.369978720910001, "simpl": 1.2232212893899999, "that": 0.00397614837964, "provid": 0.19517784432500002, "valu": 0.823193310148, "softwar": 2.32849096333, "such": 0.059695977806, "makepipelin": 7.369978720910001, "sklearntre": 7.369978720910001, "thousand": 0.906949263988, "talk": 1.10867789449, "kneighborsclassifi": 7.369978720910001, "network": 0.9530830530519999, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "should": 0.509419876758, "super": 1.9988756846400002, "result": 0.136378908381, "tpot": 7.369978720910001, "introduc": 0.5457137524260001, "set": 0.171496011289, "ani": 0.125608358366, "two": 0.0136988443582, "seri": 0.38193461069799994, "pennsylvania": 1.98456664751, "improv": 0.7147958039319999, "from": 0.000567054168866, "machine\u2026": 7.369978720910001, "detail": 0.816187777173, "num": 0.00031499039539700004, "editor": 1.4657073855, "wwwgetrevueco": 7.369978720910001, "balanc": 1.4936444810499998, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "output": 2.03822657827, "releas": 0.608521699544, "simplifi": 2.4940183301400003, "with": 0.00119749171339, "input": 2.50167533539, "are": 0.0294674735827, "inher": 2.37682874115, "look": 0.6463866936, "option": 1.39846181161, "combin": 0.529218310751, "numpi": 7.369978720910001, "root": 1.27483006252, "veri": 0.230159793238, "trend": 1.6921980487900001, "is\u2026": 7.369978720910001, "forest": 1.5883097076, "stuff": 3.1490015077499995, "conda": 7.369978720910001, "familiar": 1.92626315167, "again": 0.411340231612, "know": 0.952919694398, "doe": 0.5340417297169999, "give": 0.311392552224, "condaforg": 7.369978720910001, "bug": 3.30953571036, "train": 0.660918312839, "great": 0.235805258079, "design": 0.377239118022, "genet": 2.32784475975, "framework": 2.10418454607, "extrem": 0.8612095839370001, "his": 0.0901772433641, "ask": 0.776797209847, "comment": 1.11826753454, "note": 0.353817568083, "scientist": 1.54634128444, "machin": 1.39235958062, "into": 0.0149128632287, "paper": 0.979402539665, "prior": 0.778442172521, "revu": 3.54788042301, "v\u00e1zquez": 7.369978720910001, "traintestsplit": 7.369978720910001, "what": 0.225887296827, "tpotdata": 7.369978720910001, "local": 0.416867740206, "interpret": 1.1678481440000001, "flexibl": 2.2707222351599996, "help": 0.336207721344, "favio": 7.369978720910001, "decisiontreeclassifi": 7.369978720910001, "find": 0.547781330288, "abil": 0.996488297427, "deeplift": 7.369978720910001, "cover": 0.526975319156, "least": 0.480285584745, "approxim": 0.7944845577770001, "base": 0.13652330228700002, "label": 1.49898832727, "githubcom": 7.369978720910001, "univers": 0.222262105686, "post": 0.8057001527009999, "here": 0.8850381883700001, "better": 0.6964279406, "randi": 3.08226276571, "surpris": 1.47392435861, "much": 0.17749572930100002, "olson": 4.01308159814, "evalu": 1.9388802431299998, "sklearnpipelin": 7.369978720910001, "about": 0.0628434774746, "run": 0.442714975539, "scikitlearn": 7.369978720910001, "neural": 4.0853151555, "shap": 7.18765716411, "just": 0.289531434109, "programm": 1.6450872830399998, "adapt": 1.2007864860200002, "xgboost": 7.369978720910001, "sklearnmodelselect": 7.369978720910001, "classifi": 1.6665296351499999, "check": 1.87281049562, "where": 0.0649921387457, "ensembl": 2.81820931165, "save": 1.03598886547, "complex": 0.8502416364309999, "tool": 1.60887117963, "start": 0.236443369291, "among": 0.228496097073, "articl": 0.702131739574, "load": 1.91765354188, "them": 0.0941833269093, "dato": 5.62951254607, "iristarget": 7.369978720910001, "studi": 0.426470272221, "explain": 0.955700427358, "order": 0.22014038079300002, "autom": 2.9867028668299995, "mani": 0.0433157581221, "the": 0.0, "generat": 0.719182341736, "build": 0.491137452091, "algorithm": 3.33044239518, "epistasislabgithubio": 7.369978720910001, "select": 0.704804687133, "consist": 0.398873126426, "same": 0.112059649604, "trainingclass": 7.369978720910001, "there": 0.0400978929255, "connect": 0.633605058682, "charl": 0.836189882976, "possibl": 0.348805474891, "best": 0.459227932947, "repres": 0.38507723275, "star": 0.8940838613940001, "take": 0.130691962197, "follow": 0.045356911094199995, "now": 0.149092945021, "tri": 0.61759152916, "name": 0.09723316638430002, "code": 1.35601909597, "scalabl": 5.22991255741, "basic": 1.00436774895, "realli": 1.5576408397, "power": 0.292396282715, "fix": 1.48944573451, "also": 0.0146571578, "person": 0.34018281601800004, "everyth": 1.57270590317, "task": 1.35748680661, "theori": 1.10772396902, "vazquez": 6.414467275880001, "mayo": 3.90737271112, "past": 0.7016234157610001, "sever": 0.06991112039689999, "newslett": 3.4034675302, "want": 0.6916366062549999, "enhanc": 1.6408534385799998, "explor": 1.22257937218, "individu": 0.588013447985, "intellig": 1.43349848213, "prove": 0.899024430345, "pypi": 7.369978720910001, "attribut": 1.2283715153700001, "actual": 0.628514181648, "disclaim": 4.591159448919999, "week": 0.5907388641619999, "like": 0.139053576545, "thus": 0.49857627139300004, "estim": 0.854377535975, "abstract": 2.29918950399, "variabl": 2.1687230672, "introduct": 1.02276465794, "one": 0.0062553516455, "impact": 1.09033222631, "bazel": 7.369978720910001, "trainingfeatur": 7.369978720910001, "see": 0.240921585492, "tomorrow": 3.0618677691900005, "becaus": 0.139343158825, "beyond": 0.934469583725, "arxivorg": 7.369978720910001, "random": 1.9727214065099998, "implement": 1.27437940907, "aigoogleblogcom": 7.369978720910001, "file": 1.32734588723, "part": 0.04239531098280001, "mitig": 3.1272141535699998, "digest": 2.9475301717400004, "tinker": 4.5309002574, "understand": 1.0880858756799998, "yet": 0.754181309241, "kera": 6.72812483474, "tedious": 4.53676537685, "this": 0.0037864490525, "directori": 2.6924878733399997, "rang": 0.579319213803, "engin": 0.904767558276, "chang": 0.166275625058, "computers\u2026": 7.369978720910001, "differ": 0.212321121312, "previous": 0.356602960063, "most": 0.020747896295599998, "between": 0.033953681165299995, "shapley": 6.964513612799999, "all": 0.011402632097799998, "top": 0.609100637788, "busi": 0.720476170355, "ton": 2.35402426534, "program": 0.7037855787649999, "verifi": 2.65505767096, "gradient": 3.73502760882, "slundbergshap": 7.369978720910001, "architectur": 1.63469757919, "tradeoff": 5.34183047362, "built": 0.690379535065, "object": 0.853933584803, "more": 0.017024931599999998, "and": 6.29901420636e-05, "list": 0.309845761506, "automl": 7.369978720910001, "these": 0.0715336194008, "folk": 2.03677695251, "general": 0.114952578063, "could": 0.18595627229000003, "befor": 0.0956377718795, "librari": 0.986809980943, "year": 0.047402238894600005, "serv": 0.383135035608, "can": 0.162341096394, "describ": 0.385447603125, "make": 0.07349765782289999, "way": 0.19809150993500002, "onli": 0.025324268329099998, "often": 0.258140393351, "accur": 1.75248061485, "read": 0.83939268088, "packag": 2.0577584491900005, "data": 1.2168205848, "lightweight": 3.4781584227999995, "method": 0.944461608841, "call": 0.0654627744488, "fast": 1.5836950247400001, "must": 0.653383947388, "exampl": 0.40868267499899996, "readi": 1.6405284994999998, "matthew": 1.9327693554900003, "treebas": 7.369978720910001, "import": 0.292818277066, "first": 0.0075872898121599995, "game": 0.9477062580210001, "luckili": 5.25372320611, "fun": 2.5561696698099996, "ciencia": 5.46787119451, "tout": 3.6275584998699997, "learn": 0.842752064745, "heartbeat": 4.63561121149, "pipelin": 3.47002829672}, "freq": {"after": 2, "boost": 2, "art": 1, "axisnum": 2, "highspe": 1, "onc": 1, "adanet": 13, "pip": 4, "repo": 1, "kind": 1, "addit": 2, "would": 1, "encapsul": 1, "googl": 1, "testingclass": 2, "cort": 1, "dataset": 4, "class": 4, "learner": 1, "python": 9, "sklearnkernelapproxim": 1, "well": 2, "work": 3, "tree": 2, "approach": 4, "enthusiast": 1, "their": 1, "highlight": 1, "origin": 1, "creat": 2, "how": 4, "test": 2, "instruct": 2, "present": 1, "epistasislabtpot": 1, "alway": 1, "found": 1, "upgrad": 1, "interest": 1, "guarante": 3, "deep": 2, "will": 7, "exportedpipelin": 2, "consid": 1, "unit": 1, "clone": 2, "tensorflowadanet": 4, "next": 1, "perform": 1, "but": 3, "were": 3, "need": 4, "certainly\u2026": 1, "final": 1, "expect": 1, "amaz": 1, "applic": 2, "review": 1, "testingfeatur": 2, "wwwkdnuggetscom": 2, "opt": 1, "have": 4, "tensorflow": 6, "use": 9, "experi": 1, "out": 1, "model": 11, "best\u2014thos": 1, "sure": 2, "iri": 2, "sklearnneighbor": 1, "optim": 5, "field": 1, "usag": 3, "not": 1, "far": 1, "sponsor": 1, "weill": 1, "founder": 1, "subnetwork": 2, "git": 1, "unseen": 1, "unifi": 3, "pleas": 1, "easi": 2, "autokera": 1, "explan": 2, "then": 2, "they": 5, "deepexplain": 1, "deploy": 1, "instal": 17, "effect": 1, "let": 3, "world": 1, "scienc": 4, "anoth": 2, "blog": 1, "construct": 2, "export": 1, "featur": 6, "rbfsampler": 1, "simpl": 2, "that": 19, "provid": 1, "valu": 1, "softwar": 1, "such": 1, "makepipelin": 1, "sklearntre": 1, "thousand": 1, "talk": 1, "kneighborsclassifi": 1, "network": 4, "lot": 2, "some": 3, "sourc": 2, "should": 1, "super": 1, "result": 3, "tpot": 1, "introduc": 1, "set": 1, "ani": 3, "two": 1, "seri": 2, "pennsylvania": 1, "improv": 1, "from": 13, "machine\u2026": 1, "detail": 1, "num": 13, "editor": 1, "wwwgetrevueco": 1, "balanc": 1, "for": 21, "depend": 1, "predict": 4, "output": 3, "releas": 1, "simplifi": 1, "with": 11, "input": 1, "are": 4, "inher": 1, "look": 4, "option": 1, "combin": 2, "numpi": 2, "root": 2, "veri": 3, "trend": 2, "is\u2026": 2, "forest": 1, "stuff": 1, "conda": 1, "familiar": 1, "again": 1, "know": 3, "doe": 1, "give": 2, "condaforg": 2, "bug": 1, "train": 3, "great": 4, "design": 1, "genet": 2, "framework": 1, "extrem": 1, "his": 1, "ask": 1, "comment": 1, "note": 1, "scientist": 2, "machin": 14, "into": 1, "paper": 1, "prior": 1, "revu": 1, "v\u00e1zquez": 1, "traintestsplit": 2, "what": 2, "tpotdata": 2, "local": 2, "interpret": 1, "flexibl": 3, "help": 5, "favio": 3, "decisiontreeclassifi": 1, "find": 3, "abil": 1, "deeplift": 1, "cover": 2, "least": 1, "approxim": 1, "base": 2, "label": 2, "githubcom": 2, "univers": 1, "post": 6, "here": 8, "better": 1, "randi": 2, "surpris": 1, "much": 1, "olson": 2, "evalu": 1, "sklearnpipelin": 1, "about": 2, "run": 2, "scikitlearn": 1, "neural": 5, "shap": 2, "just": 1, "programm": 1, "adapt": 2, "xgboost": 2, "sklearnmodelselect": 2, "classifi": 1, "check": 1, "where": 1, "ensembl": 6, "save": 1, "complex": 1, "tool": 6, "start": 2, "among": 1, "articl": 1, "load": 2, "them": 4, "dato": 1, "iristarget": 1, "studi": 1, "explain": 5, "order": 1, "autom": 5, "mani": 1, "the": 53, "generat": 4, "build": 2, "algorithm": 3, "epistasislabgithubio": 1, "select": 4, "consist": 2, "same": 1, "trainingclass": 2, "there": 3, "connect": 2, "charl": 1, "possibl": 2, "best": 5, "repres": 1, "star": 1, "take": 4, "follow": 3, "now": 2, "tri": 2, "name": 1, "code": 2, "scalabl": 1, "basic": 3, "realli": 1, "power": 1, "fix": 1, "also": 1, "person": 2, "everyth": 1, "task": 2, "theori": 1, "vazquez": 1, "mayo": 1, "past": 1, "sever": 2, "newslett": 2, "want": 1, "enhanc": 1, "explor": 1, "individu": 1, "intellig": 1, "prove": 1, "pypi": 1, "attribut": 2, "actual": 1, "disclaim": 1, "week": 3, "like": 2, "thus": 1, "estim": 1, "abstract": 1, "variabl": 1, "introduct": 1, "one": 3, "impact": 1, "bazel": 2, "trainingfeatur": 2, "see": 4, "tomorrow": 1, "becaus": 1, "beyond": 1, "arxivorg": 1, "random": 1, "implement": 2, "aigoogleblogcom": 1, "file": 4, "part": 1, "mitig": 1, "digest": 5, "tinker": 1, "understand": 1, "yet": 1, "kera": 1, "tedious": 1, "this": 10, "directori": 2, "rang": 1, "engin": 1, "chang": 1, "computers\u2026": 1, "differ": 3, "previous": 2, "most": 1, "between": 1, "shapley": 1, "all": 3, "top": 4, "busi": 1, "ton": 1, "program": 3, "verifi": 1, "gradient": 2, "slundbergshap": 3, "architectur": 2, "tradeoff": 1, "built": 3, "object": 1, "more": 4, "and": 34, "list": 2, "automl": 6, "these": 2, "folk": 1, "general": 1, "could": 1, "befor": 2, "librari": 8, "year": 3, "serv": 1, "can": 14, "describ": 1, "make": 2, "way": 4, "onli": 1, "often": 1, "accur": 1, "read": 4, "packag": 9, "data": 10, "lightweight": 1, "method": 3, "call": 1, "fast": 3, "must": 1, "exampl": 4, "readi": 1, "matthew": 1, "treebas": 1, "import": 10, "first": 2, "game": 1, "luckili": 2, "fun": 1, "ciencia": 1, "tout": 1, "learn": 19, "heartbeat": 1, "pipelin": 11}, "idf": {"after": 1.02070207021, "boost": 9.16099249856, "art": 1.9994962216599999, "axisnum": 1587.6, "highspe": 1587.6, "onc": 1.4974533106999999, "adanet": 1587.6, "pip": 135.692307692, "repo": 369.209302326, "kind": 2.5806241872599998, "addit": 1.24634950542, "would": 1.0828729281799998, "encapsul": 68.72727272729999, "googl": 11.388809182200001, "testingclass": 1587.6, "cort": 88.6927374302, "dataset": 193.609756098, "class": 2.11651779763, "learner": 75.2417061611, "python": 56.2978723404, "sklearnkernelapproxim": 1587.6, "well": 1.0655748708, "work": 1.11520089913, "tree": 4.127925117, "approach": 2.07556543339, "enthusiast": 9.39408284024, "their": 1.01547908405, "highlight": 5.83033419023, "origin": 1.13724928367, "creat": 1.2492917847, "how": 1.60250328051, "test": 2.65707112971, "instruct": 4.169117647059999, "present": 1.25551601423, "epistasislabtpot": 1587.6, "alway": 2.06745670009, "found": 1.11387076405, "upgrad": 8.88913773796, "interest": 1.60331246213, "guarante": 6.57119205298, "deep": 3.6279707495399998, "will": 1.22481098596, "exportedpipelin": 1587.6, "consid": 1.2397313759200002, "unit": 1.15394679459, "clone": 32.5327868852, "tensorflowadanet": 1587.6, "next": 1.4950560316400001, "perform": 1.5313977042500002, "but": 1.01632417899, "were": 1.02458857696, "need": 1.4372623574099999, "certainly\u2026": 1587.6, "final": 1.34008609775, "expect": 2.20011086475, "amaz": 15.250720461099998, "applic": 3.42672134686, "review": 2.2099109131400003, "testingfeatur": 1587.6, "wwwkdnuggetscom": 1587.6, "opt": 12.721153846199998, "have": 1.0148948411399998, "tensorflow": 1587.6, "use": 1.0296387573799999, "experi": 1.87062566278, "out": 1.06016694491, "model": 2.0905978404, "best\u2014thos": 1587.6, "sure": 7.453521126760001, "iri": 49.3043478261, "sklearnneighbor": 1587.6, "optim": 11.5377906977, "field": 1.7790228597, "usag": 6.427530364369999, "not": 1.01567398119, "far": 1.71022298826, "sponsor": 5.66393150196, "weill": 244.246153846, "founder": 4.033536585369999, "subnetwork": 1587.6, "git": 360.818181818, "unseen": 40.8123393316, "unifi": 7.60709151893, "pleas": 9.12938470385, "easi": 5.2937645882, "autokera": 1587.6, "explan": 6.50922509225, "then": 1.08657860516, "they": 1.03017325287, "deepexplain": 1587.6, "deploy": 7.41869158879, "instal": 3.78721374046, "effect": 1.3963060686000002, "let": 3.48616600791, "world": 1.11340206186, "scienc": 2.31969608416, "anoth": 1.13643521832, "blog": 14.1876675603, "construct": 1.9320920043799998, "export": 6.727118644069999, "featur": 1.52712581762, "rbfsampler": 1587.6, "simpl": 3.3981164383599998, "that": 1.00398406375, "provid": 1.21552714187, "valu": 2.2777618364400003, "softwar": 10.2624434389, "such": 1.06151377374, "makepipelin": 1587.6, "sklearntre": 1587.6, "thousand": 2.4767550702000003, "talk": 3.0303493033, "kneighborsclassifi": 1587.6, "network": 2.59369384088, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "should": 1.6643254009900001, "super": 7.380753138080001, "result": 1.14611608432, "tpot": 1587.6, "introduc": 1.7258397651900002, "set": 1.18707940781, "ani": 1.13383802314, "two": 1.01379310345, "seri": 1.46511627907, "pennsylvania": 7.27589367553, "improv": 2.04376930999, "from": 1.00056721497, "machine\u2026": 1587.6, "detail": 2.26186066391, "num": 1.00031504001, "editor": 4.33060556465, "wwwgetrevueco": 1587.6, "balanc": 4.45329593268, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "output": 7.676982591880001, "releas": 1.8377126982299998, "simplifi": 12.109839816900001, "with": 1.0011982089899998, "input": 12.2029208301, "are": 1.02990593578, "inher": 10.7706919946, "look": 1.9086318826599997, "option": 4.04896710023, "combin": 1.69760479042, "numpi": 1587.6, "root": 3.57809330629, "veri": 1.25880114177, "trend": 5.43140608963, "is\u2026": 1587.6, "forest": 4.89546716004, "stuff": 23.3127753304, "conda": 1587.6, "familiar": 6.86381322957, "again": 1.50883862384, "know": 2.59327017315, "doe": 1.70581282905, "give": 1.3653250774, "condaforg": 1587.6, "bug": 27.372413793099998, "train": 1.9365698950999999, "great": 1.26592775696, "design": 1.45825296225, "genet": 10.2558139535, "framework": 8.200413223139998, "extrem": 2.36602086438, "his": 1.0943682360200002, "ask": 2.1744966443, "comment": 3.05954904606, "note": 1.42449528937, "scientist": 4.69426374926, "machin": 4.02433460076, "into": 1.01502461479, "paper": 2.6628648104700003, "prior": 2.17807655371, "revu": 34.7396061269, "v\u00e1zquez": 1587.6, "traintestsplit": 1587.6, "what": 1.25343439128, "tpotdata": 1587.6, "local": 1.51720183486, "interpret": 3.2150668286799995, "flexibl": 9.68639414277, "help": 1.39962972759, "favio": 1587.6, "decisiontreeclassifi": 1587.6, "find": 1.7294117647099998, "abil": 2.70875277256, "deeplift": 1587.6, "cover": 1.69380134429, "least": 1.6165359943000002, "approxim": 2.2132998745299997, "base": 1.14628158845, "label": 4.47715736041, "githubcom": 1587.6, "univers": 1.24889867841, "post": 2.23826307627, "here": 2.42307692308, "better": 2.0065722952500002, "randi": 21.8076923077, "surpris": 4.36633663366, "much": 1.1942229577299999, "olson": 55.3170731707, "evalu": 6.9509632224199995, "sklearnpipelin": 1587.6, "about": 1.06486015159, "run": 1.55692850838, "scikitlearn": 1587.6, "neural": 59.4606741573, "shap": 1323.0, "just": 1.33580143037, "programm": 5.181462140990001, "adapt": 3.32272917539, "xgboost": 1587.6, "sklearnmodelselect": 1587.6, "classifi": 5.2937645882, "check": 6.50655737705, "where": 1.06715063521, "ensembl": 16.746835443, "save": 2.8178913737999998, "complex": 2.34021226415, "tool": 4.99716713881, "start": 1.26673581744, "among": 1.25670862028, "articl": 2.01805008262, "load": 6.80497213888, "them": 1.09876115994, "dato": 278.526315789, "iristarget": 1587.6, "studi": 1.53184098804, "explain": 2.60049140049, "order": 1.24625166811, "autom": 19.8202247191, "mani": 1.04426757877, "the": 1.0, "generat": 2.05275407292, "build": 1.6341739578, "algorithm": 27.9507042254, "epistasislabgithubio": 1587.6, "select": 2.02345144022, "consist": 1.4901445466499998, "same": 1.11857958148, "trainingclass": 1587.6, "there": 1.04091266719, "connect": 1.8843916913900003, "charl": 2.3075581395299998, "possibl": 1.4173734488, "best": 1.5828514456600002, "repres": 1.46972782818, "star": 2.4450947173900004, "take": 1.13961668222, "follow": 1.04640126549, "now": 1.160780873, "tri": 1.8544562551099997, "name": 1.10211732037, "code": 3.8807137619199996, "scalabl": 186.776470588, "basic": 2.7301805675, "realli": 4.7476076555, "power": 1.3396337861799998, "fix": 4.4346368715099995, "also": 1.01476510067, "person": 1.40520446097, "everyth": 4.81967213115, "task": 3.88641370869, "theori": 3.02745995423, "vazquez": 610.615384615, "mayo": 49.7680250784, "past": 2.01702452039, "sever": 1.07241286139, "newslett": 30.068181818200003, "want": 1.99698113208, "enhanc": 5.15957101072, "explor": 3.39593582888, "individu": 1.8004082558400003, "intellig": 4.19334389857, "prove": 2.45720476706, "pypi": 1587.6, "attribut": 3.4156626506, "actual": 1.87482286254, "disclaim": 98.6086956522, "week": 1.80532181033, "like": 1.14918566775, "thus": 1.6463756092500001, "estim": 2.34991119005, "abstract": 9.966101694919999, "variabl": 8.747107438019999, "introduct": 2.7808723068799996, "one": 1.00627495722, "impact": 2.97526236882, "bazel": 1587.6, "trainingfeatur": 1587.6, "see": 1.27242125511, "tomorrow": 21.3674293405, "becaus": 1.1495184997499999, "beyond": 2.54586273252, "arxivorg": 1587.6, "random": 7.1902173913, "implement": 3.57648118946, "aigoogleblogcom": 1587.6, "file": 3.7710213776699995, "part": 1.04330682789, "mitig": 22.8103448276, "digest": 19.0588235294, "tinker": 92.8421052632, "understand": 2.96858638743, "yet": 2.1258703802900003, "kera": 835.5789473680001, "tedious": 93.3882352941, "this": 1.00379362671, "directori": 14.768372093, "rang": 1.7848229342299997, "engin": 2.47135740971, "chang": 1.1808985421, "computers\u2026": 1587.6, "differ": 1.23654490225, "previous": 1.42846859816, "most": 1.02096463023, "between": 1.03453668708, "shapley": 1058.4, "all": 1.01146788991, "top": 1.8387769284200002, "busi": 2.05541170378, "ton": 10.5278514589, "program": 2.02139037433, "verifi": 14.2258064516, "gradient": 41.889182058, "slundbergshap": 1587.6, "architectur": 5.12790697674, "tradeoff": 208.89473684200001, "built": 1.99447236181, "object": 2.3488681757700003, "more": 1.0171706817, "and": 1.00006299213, "list": 1.36321483771, "automl": 1587.6, "these": 1.07415426252, "folk": 7.6658619024600005, "general": 1.1218202374200001, "could": 1.2043695949, "befor": 1.10036041031, "librari": 2.68266306185, "year": 1.0485436893200002, "serv": 1.4668760972, "can": 1.17626139142, "describ": 1.47027227264, "make": 1.0762660158600001, "way": 1.2190739461, "onli": 1.0256476516600002, "often": 1.29452054795, "accur": 5.768895348840001, "read": 2.3149606299200003, "packag": 7.828402366860001, "data": 3.37643555934, "lightweight": 32.4, "method": 2.5714285714300003, "call": 1.0676529926, "fast": 4.8729281768, "must": 1.9220338983099996, "exampl": 1.50483412322, "readi": 5.15789473684, "matthew": 6.908616187989999, "treebas": 1587.6, "import": 1.3401992233700002, "first": 1.00761614623, "game": 2.57978550536, "luckili": 191.277108434, "fun": 12.8863636364, "ciencia": 236.955223881, "tout": 37.6208530806, "learn": 2.32275054865, "heartbeat": 103.090909091, "pipelin": 32.1376518219}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  2018\u2019s Top 7 Python Libraries for Data Science and AI</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/vazquez-2018-top-7-python-libraries.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb 2018\u2019s Top 7 Python Libraries for Data Science and AI Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/cartoon-blockchain.html\" rel=\"prev\" title=\"Cartoon: Is this how you do the blockchain thing?\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/kdd-2019-call-research-applied-data-science.html\" rel=\"next\" title=\"KDD 2019 Call for Research, Applied Data Science Papers\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/01/vazquez-2018-top-7-python-libraries.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=89647\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/vazquez-2018-top-7-python-libraries.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-89647 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 21-Jan, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/index.html\">Jan</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/tutorials.html\">Tutorials, Overviews</a> \u00bb 2018\u2019s Top 7 Python Libraries for Data Science and AI (\u00a0<a href=\"/2019/n04.html\">19:n04</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"Gold Blog\" src=\"/images/tkb-1901-g.png\" width=\"94\"/>2018\u2019s Top 7 Python Libraries for Data Science and AI</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/01/cartoon-blockchain.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/01/kdd-2019-call-research-applied-data-science.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/ai\" rel=\"tag\">AI</a>, <a href=\"https://www.kdnuggets.com/tag/data-science\" rel=\"tag\">Data Science</a>, <a href=\"https://www.kdnuggets.com/tag/python\" rel=\"tag\">Python</a></div>\n<br/>\n<p class=\"excerpt\">\n     This is a list of the best libraries that changed our lives this year, compiled from my weekly digests.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/favio-vazquez\" rel=\"author\" title=\"Posts by Favio Vazquez\">Favio Vazquez</a>, Founder at Ciencia y Datos.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2019/01/vazquez-2018-top-7-python-libraries.html?page=2#comments\">comments</a></div>\n<blockquote><p>\n<strong>Editor's note:</strong> This post covers Favio's selections for the top 7 Python libraries of 2018. Tomorrow's post will cover his top 7 R packages of the year.\n</p></blockquote>\n<p><img alt=\"Header image\" class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/2560/1*hDzdIAiZXu_d_xQpAeMIxg@2x.jpeg\" width=\"99%\"/></p>\n<p>\u00a0</p>\n<h3>Introduction</h3>\n<p>\u00a0<br>\nIf you follow me, you know that this year I started a series called\u00a0<em>Weekly Digest for Data Science and AI: Python &amp; R</em>, where I highlighted the best libraries, repos, packages, and tools that help us be better data scientists for all kinds of tasks.</br></p>\n<p>The great folks at\u00a0<a href=\"http://heartbeat.fritz.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Heartbeat</a>\u00a0sponsored a lot of these digests, and they asked me to create a list of the best of the best\u2014those libraries that really changed or improved the way we worked this year (and beyond).</p>\n<p>If you want to read the past digests, take a look here:</p>\n<p><a href=\"https://www.getrevue.co/profile/favio\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Weekly Digest for Data Science and AI - Revue</strong><br>\n<em>Weekly Digest for Data Science and AI - Personal newsletter of Favio V\u00e1zquez...</em>www.getrevue.co</br></a></p>\n<blockquote><p>Disclaimer: This list is based on the libraries and packages I reviewed in my personal newsletter. All of them were trending in one way or another among programmers, data scientists, and AI enthusiasts. Some of them were created before 2018, but if they were trending, they could be considered.</p></blockquote>\n<p>\u00a0</p>\n<h3>Top 7 for\u00a0Python</h3>\n<p>\u00a0<br>\n<img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/1*m9QfnOyrKGa6i9tS0TKVhA.gif\" width=\"99%\"/></br></p>\n<p>\u00a0</p>\n<h3><b>7. AdaNet\u200a\u2014\u200aFast and flexible AutoML with learning guarantees.</b></h3>\n<p>\u00a0<br>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/0*ZPLMGasPVMFyCyiG.png\" width=\"65%\"/><br/>\n<font size=\"-1\"><a href=\"https://github.com/tensorflow/adanet\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/tensorflow/adanet</a></font></center></br></p>\n<p>AdaNet is a lightweight and scalable TensorFlow AutoML framework for training and deploying adaptive neural networks using the\u00a0<em>AdaNet</em>\u00a0algorithm [<a href=\"https://arxiv.org/abs/1607.01097\" rel=\"noopener noreferrer\" target=\"_blank\">Cortes et al. ICML 2017</a>].\u00a0<em>AdaNet</em>\u00a0combines several learned subnetworks in order to mitigate the complexity inherent in designing effective neural networks.</p>\n<p>This package will help you selecting optimal neural network architectures, implementing an adaptive algorithm for learning a neural architecture as an ensemble of subnetworks.</p>\n<p>You will need to know TensorFlow to use the package because it implements a TensorFlow Estimator, but this will help you simplify your machine learning programming by encapsulating training and also evaluation, prediction and export for serving.</p>\n<p>You can build an ensemble of neural networks, and the library will help you optimize an objective that balances the trade-offs between the ensemble\u2019s performance on the training set and its ability to generalize to unseen data.</p>\n<p><b>Installation</b></p>\n<p><code>adanet</code>\u00a0depends on bug fixes and enhancements not present in TensorFlow releases prior to 1.7. You must install or upgrade your TensorFlow package to at least 1.7:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ pip install \"tensorflow&gt;=1.7.0\"</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Installing from\u00a0source</b></p>\n<p>To install from source, you\u2019ll first need to install\u00a0<code>bazel</code>\u00a0following their\u00a0<a href=\"https://docs.bazel.build/versions/master/install.html\" rel=\"noopener noreferrer\" target=\"_blank\">installation instructions</a>.</p>\n<p>Next clone\u00a0<code>adanet</code>\u00a0and\u00a0<code>cd</code>\u00a0into its root directory:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ git clone <a href=\"https://github.com/tensorflow/adanet\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/tensorflow/adanet</a> &amp;&amp; cd adanet</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>From the\u00a0<code>adanet</code>\u00a0root directory run the tests:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ cd adanet\r\n$ bazel test -c opt //...</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Once you have verified that everything works well, install\u00a0<code>adanet</code>\u00a0as a\u00a0<a href=\"https://github.com/tensorflow/adanet/blob/master/adanet/pip_package/PIP.md\" rel=\"noopener noreferrer\" target=\"_blank\">pip package\u00a0</a>.</p>\n<p>You\u2019re now ready to experiment with\u00a0<code>adanet</code>.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import adanet</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Usage</b></p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/0*YcvUdmZdv4NWjKF9.gif\" width=\"75%\"/></p>\n<p>Here you can find two examples on the usage of the package:</p>\n<p><a href=\"https://github.com/tensorflow/adanet/tree/master/adanet/examples/tutorials\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>tensorflow/adanet</strong><br/>\n<em>Fast and flexible AutoML with learning guarantees.\u200a\u2014\u200atensorflow/adanet</em>github.com</a></p>\n<p>You can read more about it in the original blog post:</p>\n<p><a href=\"https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html?m=1\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Introducing AdaNet: Fast and Flexible AutoML with Learning Guarantees</strong><br/>\n<em>Posted by Charles Weill, Software Engineer, Google AI, NYC Ensemble learning\u00a0, the art of combining different machine\u2026</em>ai.googleblog.com</a></p>\n<p>\u00a0</p>\n<h3><b>6. TPOT\u2014 An automated Python machine learning tool that optimizes machine learning pipelines using genetic programming.</b></h3>\n<p>\u00a0<br/>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/0*C5teFLKPLkW48BP5.jpg\" width=\"60%\"/><br/>\n<font size=\"-1\"><a href=\"https://github.com/EpistasisLab/tpot\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/EpistasisLab/tpot</a></font></center></p>\n<p><a href=\"https://heartbeat.fritz.ai/weekly-digest-for-data-science-and-ai-python-and-r-volume-6-830ed997cf07\" rel=\"noopener noreferrer\" target=\"_blank\">Previously</a>\u00a0I talked about Auto-Keras, a great library for AutoML in the Pythonic world. Well, I have another very interesting tool for that.</p>\n<p>The name is\u00a0<strong>TPOT</strong>\u00a0(Tree-based Pipeline Optimization Tool), and it\u2019s an amazing library. It\u2019s basically a Python automated machine learning tool that optimizes machine learning pipelines using\u00a0<strong>genetic programming</strong>.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/1000/0*nDQABCJuEPhds4el.png\" width=\"99%\"/></p>\n<p>TPOT can automate a lot of stuff like feature selection, model selection, feature construction, and much more. Luckily, if you\u2019re a Python machine learner, TPOT is built on top of Scikit-learn, so all of the code it generates should look familiar.</p>\n<p>What it does is automate the most tedious parts of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data, and then it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there.</p>\n<p>This is how it works:</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/1000/0*Y1E0P1CbeV0yQoUL.png\" width=\"99%\"/></p>\n<p>For more details you can read theses great article by\u00a0<a href=\"https://medium.com/@mattmayo13\" rel=\"noopener noreferrer\" target=\"_blank\">Matthew Mayo</a>:</p>\n<p><a href=\"/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-4.html\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Using AutoML to Generate Machine Learning Pipelines with TPOT</strong><br/>\n<em>Thus far in this series of posts we have: This post will take a different approach to constructing pipelines. Certainly\u2026</em>www.kdnuggets.com</a></p>\n<p>and\u00a0<a href=\"https://medium.com/@randal_olson\" rel=\"noopener noreferrer\" target=\"_blank\">Randy Olson</a>:</p>\n<p><a href=\"/2016/05/tpot-python-automating-data-science.html\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>TPOT: A Python Tool for Automating Data Science</strong><br/>\n<em>By Randy Olson, University of Pennsylvania. Machine learning is often touted as: A field of study that gives computers\u2026</em>www.kdnuggets.com</a></p>\n<p><b>Installation</b></p>\n<p>You actually need to follow some instructions before installing TPOT. Here they are:</p>\n<p><a href=\"http://epistasislab.github.io/tpot/installing/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Installation\u200a\u2014\u200aTPOT</strong><br/>\n<em>Optionally, you can install XGBoost if you would like TPOT to use the eXtreme Gradient Boosting models. XGBoost is\u2026</em>epistasislab.github.io</a></p>\n<p>After that you can just run:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>pip install tpot</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Examples:</b></p>\n<p>First let\u2019s start with the basic Iris dataset:</p>\n<p><script src=\"https://gist.github.com/FavioVazquez/5128d051c180584d12859c7a2fd93baa.js\"></script></p>\n<p>So here we built a very basic TPOT pipeline that will try to look for the best ML pipeline to predict the\u00a0<code>iris.target</code><em>.\u00a0</em>And then we save that pipeline. After that, what we have to do is very simple\u200a\u2014\u200aload the\u00a0<code>.py</code>\u00a0file you generated and you\u2019ll see:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nimport numpy as np\r\n\r\nfrom sklearn.kernel_approximation import RBFSampler\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.pipeline import make_pipeline\r\nfrom sklearn.tree import DecisionTreeClassifier\r\n\r\n# NOTE: Make sure that the class is labeled 'class' in the data file\r\ntpot_data = np.recfromcsv('PATH/TO/DATA/FILE', delimiter='COLUMN_SEPARATOR', dtype=np.float64)\r\nfeatures = np.delete(tpot_data.view(np.float64).reshape(tpot_data.size, -1), tpot_data.dtype.names.index('class'), axis=1)\r\ntraining_features, testing_features, training_classes, testing_classes = \\\r\n    train_test_split(features, tpot_data['class'], random_state=42)\r\n\r\nexported_pipeline = make_pipeline(\r\n    RBFSampler(gamma=0.8500000000000001),\r\n    DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_leaf=4, min_samples_split=9)\r\n)\r\n\r\nexported_pipeline.fit(training_features, training_classes)\r\nresults = exported_pipeline.predict(testing_features)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>And that\u2019s it. You built a classifier for the Iris dataset in a simple but powerful way.</p>\n<p>Let\u2019s go the MNIST dataset now:</p>\n<p><script src=\"https://gist.github.com/FavioVazquez/3786580b03e16c16848d8939b3aeaae5.js\"></script></p>\n<p>As you can see, we did the same! Let\u2019s load the\u00a0<code>.py</code>\u00a0file you generated again and you\u2019ll see:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nimport numpy as np\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\n# NOTE: Make sure that the class is labeled 'class' in the data file\r\ntpot_data = np.recfromcsv('PATH/TO/DATA/FILE', delimiter='COLUMN_SEPARATOR', dtype=np.float64)\r\nfeatures = np.delete(tpot_data.view(np.float64).reshape(tpot_data.size, -1), tpot_data.dtype.names.index('class'), axis=1)\r\ntraining_features, testing_features, training_classes, testing_classes = \\\r\n    train_test_split(features, tpot_data['class'], random_state=42)\r\n\r\nexported_pipeline = KNeighborsClassifier(n_neighbors=4, p=2, weights=\"distance\")\r\n\r\nexported_pipeline.fit(training_features, training_classes)\r\nresults = exported_pipeline.predict(testing_features)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Super easy and fun. Check them out! Try it and please give them a star!</p>\n<p>\u00a0</p>\n<h3><b>5. SHAP\u200a\u2014\u200aA unified approach to explain the output of any machine learning\u00a0model</b></h3>\n<p>\u00a0<br/>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/0*ngrNi7J-wpcwXXyO.png\" width=\"99%\"/><br/>\n<font size=\"-1\"><a href=\"https://github.com/slundberg/shap\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/slundberg/shap</a></font></center></p>\n<p>Explaining machine learning models isn\u2019t always easy. Yet it\u2019s so important for a range of business applications. Luckily, there are some great libraries that help us with this task. In many applications, we need to know, understand, or prove how input variables are used in the model, and how they impact final model predictions.</p>\n<p><strong>SHAP</strong>\u00a0(SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.</p>\n<p><b>Installation</b></p>\n<p>SHAP can be installed from\u00a0<a href=\"https://pypi.org/project/shap\" rel=\"noopener noreferrer\" target=\"_blank\">PyPI</a></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>pip install shap</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>or\u00a0<a href=\"https://anaconda.org/conda-forge/shap\" rel=\"noopener noreferrer\" target=\"_blank\">conda-forge</a></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>conda install -c conda-forge shap</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Usage</b></p>\n<p>There are tons of different models and ways to use the package. Here, I\u2019ll take one example from the DeepExplainer.</p>\n<p>Deep SHAP is a high-speed approximation algorithm for SHAP values in deep learning models that builds on a connection with\u00a0<a href=\"https://arxiv.org/abs/1704.02685\" rel=\"noopener noreferrer\" target=\"_blank\">DeepLIFT</a>, as described in the SHAP NIPS paper that you can read here:</p>\n<p><a href=\"https://arxiv.org/abs/1802.03888\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>[1802.03888] Consistent Individualized Feature Attribution for Tree Ensembles</strong><br/>\n<em>Abstract: Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is\u2026</em>arxiv.org</a></p>\n<p>Here you can see how SHAP can be used to explain the result of a Keras model for the MNIST dataset:</p>\n<p><script src=\"https://gist.github.com/FavioVazquez/4257dd4e0c10495e49d53f1b75e92f5f.js\"></script></p>\n<p>You can find more examples here:</p>\n<p><a href=\"https://github.com/slundberg/shap#sample-notebooks\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>slundberg/shap</strong><br/>\n<em>A unified approach to explain the output of any machine learning model.\u200a\u2014\u200aslundberg/shap</em>github.com</a></p>\n<p>Take a look. You\u2019ll be surprised\u00a0:)</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2019/01/vazquez-2018-top-7-python-libraries.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/01/cartoon-blockchain.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/01/kdd-2019-call-research-applied-data-science.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/index.html\">Jan</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/tutorials.html\">Tutorials, Overviews</a> \u00bb 2018\u2019s Top 7 Python Libraries for Data Science and AI (\u00a0<a href=\"/2019/n04.html\">19:n04</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556419079\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.728 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 22:37:59 -->\n<!-- Compression = gzip -->", "content_tokenized": ["favio", "vazquez", "founder", "ciencia", "dato", "comment", "editor", "note", "this", "post", "cover", "favio", "select", "for", "the", "top", "num", "python", "librari", "num", "tomorrow", "post", "will", "cover", "his", "top", "num", "packag", "the", "year", "introduct", "follow", "know", "that", "this", "year", "start", "seri", "call", "week", "digest", "for", "data", "scienc", "and", "python", "where", "highlight", "the", "best", "librari", "repo", "packag", "and", "tool", "that", "help", "better", "data", "scientist", "for", "all", "kind", "task", "the", "great", "folk", "heartbeat", "sponsor", "lot", "these", "digest", "and", "they", "ask", "creat", "list", "the", "best", "the", "best\u2014thos", "librari", "that", "realli", "chang", "improv", "the", "way", "work", "this", "year", "and", "beyond", "want", "read", "the", "past", "digest", "take", "look", "here", "week", "digest", "for", "data", "scienc", "and", "revu", "week", "digest", "for", "data", "scienc", "and", "person", "newslett", "favio", "v\u00e1zquez", "wwwgetrevueco", "disclaim", "this", "list", "base", "the", "librari", "and", "packag", "review", "person", "newslett", "all", "them", "were", "trend", "one", "way", "anoth", "among", "programm", "data", "scientist", "and", "enthusiast", "some", "them", "were", "creat", "befor", "num", "but", "they", "were", "trend", "they", "could", "consid", "top", "num", "for", "python", "num", "adanet", "fast", "and", "flexibl", "automl", "with", "learn", "guarante", "tensorflowadanet", "adanet", "lightweight", "and", "scalabl", "tensorflow", "automl", "framework", "for", "train", "and", "deploy", "adapt", "neural", "network", "use", "the", "adanet", "algorithm", "cort", "num", "adanet", "combin", "sever", "learn", "subnetwork", "order", "mitig", "the", "complex", "inher", "design", "effect", "neural", "network", "this", "packag", "will", "help", "select", "optim", "neural", "network", "architectur", "implement", "adapt", "algorithm", "for", "learn", "neural", "architectur", "ensembl", "subnetwork", "will", "need", "know", "tensorflow", "use", "the", "packag", "becaus", "implement", "tensorflow", "estim", "but", "this", "will", "help", "simplifi", "machin", "learn", "program", "encapsul", "train", "and", "also", "evalu", "predict", "and", "export", "for", "serv", "can", "build", "ensembl", "neural", "network", "and", "the", "librari", "will", "help", "optim", "object", "that", "balanc", "the", "tradeoff", "between", "the", "ensembl", "perform", "the", "train", "set", "and", "abil", "general", "unseen", "data", "instal", "adanet", "depend", "bug", "fix", "and", "enhanc", "not", "present", "tensorflow", "releas", "prior", "num", "must", "instal", "upgrad", "tensorflow", "packag", "least", "num", "pip", "instal", "tensorflow", "num", "instal", "from", "sourc", "instal", "from", "sourc", "first", "need", "instal", "bazel", "follow", "their", "instal", "instruct", "next", "clone", "adanet", "and", "into", "root", "directori", "git", "clone", "tensorflowadanet", "adanet", "from", "the", "adanet", "root", "directori", "run", "the", "test", "adanet", "bazel", "test", "opt", "onc", "have", "verifi", "that", "everyth", "work", "well", "instal", "adanet", "pip", "packag", "now", "readi", "experi", "with", "adanet", "import", "adanet", "usag", "here", "can", "find", "two", "exampl", "the", "usag", "the", "packag", "tensorflowadanet", "fast", "and", "flexibl", "automl", "with", "learn", "guarante", "tensorflowadanet", "githubcom", "can", "read", "more", "about", "the", "origin", "blog", "post", "introduc", "adanet", "fast", "and", "flexibl", "automl", "with", "learn", "guarante", "post", "charl", "weill", "softwar", "engin", "googl", "ensembl", "learn", "the", "art", "combin", "differ", "machine\u2026", "aigoogleblogcom", "num", "autom", "python", "machin", "learn", "tool", "that", "optim", "machin", "learn", "pipelin", "use", "genet", "program", "epistasislabtpot", "previous", "talk", "about", "autokera", "great", "librari", "for", "automl", "the", "python", "world", "well", "have", "anoth", "veri", "interest", "tool", "for", "that", "the", "name", "treebas", "pipelin", "optim", "tool", "and", "amaz", "librari", "basic", "python", "autom", "machin", "learn", "tool", "that", "optim", "machin", "learn", "pipelin", "use", "genet", "program", "can", "autom", "lot", "stuff", "like", "featur", "select", "model", "select", "featur", "construct", "and", "much", "more", "luckili", "python", "machin", "learner", "built", "top", "scikitlearn", "all", "the", "code", "generat", "should", "look", "familiar", "what", "doe", "autom", "the", "most", "tedious", "part", "machin", "learn", "intellig", "explor", "thousand", "possibl", "pipelin", "find", "the", "best", "one", "for", "data", "and", "then", "provid", "with", "the", "python", "code", "for", "the", "best", "pipelin", "found", "can", "tinker", "with", "the", "pipelin", "from", "there", "this", "how", "work", "for", "more", "detail", "can", "read", "these", "great", "articl", "matthew", "mayo", "use", "automl", "generat", "machin", "learn", "pipelin", "with", "thus", "far", "this", "seri", "post", "have", "this", "post", "will", "take", "differ", "approach", "construct", "pipelin", "certainly\u2026", "wwwkdnuggetscom", "and", "randi", "olson", "python", "tool", "for", "autom", "data", "scienc", "randi", "olson", "univers", "pennsylvania", "machin", "learn", "often", "tout", "field", "studi", "that", "give", "computers\u2026", "wwwkdnuggetscom", "instal", "actual", "need", "follow", "some", "instruct", "befor", "instal", "here", "they", "are", "instal", "option", "can", "instal", "xgboost", "would", "like", "use", "the", "extrem", "gradient", "boost", "model", "xgboost", "is\u2026", "epistasislabgithubio", "after", "that", "can", "just", "run", "pip", "instal", "tpot", "exampl", "first", "let", "start", "with", "the", "basic", "iri", "dataset", "here", "built", "veri", "basic", "pipelin", "that", "will", "tri", "look", "for", "the", "best", "pipelin", "predict", "the", "iristarget", "and", "then", "save", "that", "pipelin", "after", "that", "what", "have", "veri", "simpl", "load", "the", "file", "generat", "and", "see", "import", "numpi", "from", "sklearnkernelapproxim", "import", "rbfsampler", "from", "sklearnmodelselect", "import", "traintestsplit", "from", "sklearnpipelin", "import", "makepipelin", "from", "sklearntre", "import", "decisiontreeclassifi", "make", "sure", "that", "the", "class", "label", "class", "the", "data", "file", "tpotdata", "featur", "axisnum", "trainingfeatur", "testingfeatur", "trainingclass", "testingclass", "exportedpipelin", "result", "and", "that", "built", "classifi", "for", "the", "iri", "dataset", "simpl", "but", "power", "way", "let", "the", "dataset", "now", "can", "see", "the", "same", "let", "load", "the", "file", "generat", "again", "and", "see", "import", "numpi", "from", "sklearnmodelselect", "import", "traintestsplit", "from", "sklearnneighbor", "import", "kneighborsclassifi", "make", "sure", "that", "the", "class", "label", "class", "the", "data", "file", "tpotdata", "featur", "axisnum", "trainingfeatur", "testingfeatur", "trainingclass", "testingclass", "exportedpipelin", "result", "super", "easi", "and", "fun", "check", "them", "out", "tri", "and", "pleas", "give", "them", "star", "num", "unifi", "approach", "explain", "the", "output", "ani", "machin", "learn", "model", "slundbergshap", "explain", "machin", "learn", "model", "alway", "easi", "yet", "import", "for", "rang", "busi", "applic", "luckili", "there", "are", "some", "great", "librari", "that", "help", "with", "this", "task", "mani", "applic", "need", "know", "understand", "prove", "how", "input", "variabl", "are", "use", "the", "model", "and", "how", "they", "impact", "final", "model", "predict", "shapley", "addit", "explan", "unifi", "approach", "explain", "the", "output", "ani", "machin", "learn", "model", "connect", "game", "theori", "with", "local", "explan", "unit", "sever", "previous", "method", "and", "repres", "the", "onli", "possibl", "consist", "and", "local", "accur", "addit", "featur", "attribut", "method", "base", "expect", "instal", "can", "instal", "from", "pypi", "pip", "instal", "shap", "condaforg", "conda", "instal", "condaforg", "shap", "usag", "there", "are", "ton", "differ", "model", "and", "way", "use", "the", "packag", "here", "take", "one", "exampl", "from", "the", "deepexplain", "deep", "highspe", "approxim", "algorithm", "for", "valu", "deep", "learn", "model", "that", "build", "connect", "with", "deeplift", "describ", "the", "paper", "that", "can", "read", "here", "num", "consist", "individu", "featur", "attribut", "for", "tree", "ensembl", "abstract", "interpret", "predict", "from", "tree", "ensembl", "method", "such", "gradient", "boost", "machin", "and", "random", "forest", "is\u2026", "arxivorg", "here", "can", "see", "how", "can", "use", "explain", "the", "result", "kera", "model", "for", "the", "dataset", "can", "find", "more", "exampl", "here", "slundbergshap", "unifi", "approach", "explain", "the", "output", "ani", "machin", "learn", "model", "slundbergshap", "githubcom", "take", "look", "surpris"], "timestamp_scraper": 1556480838.43183, "title": "2018\u2019s Top 7 Python Libraries for Data Science and AI", "read_time": 393.0, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/favio-vazquez\" rel=\"author\" title=\"Posts by Favio Vazquez\">Favio Vazquez</a>, Founder at Ciencia y Datos.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2019/01/vazquez-2018-top-7-python-libraries.html?page=2#comments\">comments</a></div>\n<blockquote><p>\n<strong>Editor's note:</strong> This post covers Favio's selections for the top 7 Python libraries of 2018. Tomorrow's post will cover his top 7 R packages of the year.\n</p></blockquote>\n<p><img alt=\"Header image\" class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/2560/1*hDzdIAiZXu_d_xQpAeMIxg@2x.jpeg\" width=\"99%\"/></p>\n<p>\u00a0</p>\n<h3>Introduction</h3>\n<p>\u00a0<br>\nIf you follow me, you know that this year I started a series called\u00a0<em>Weekly Digest for Data Science and AI: Python &amp; R</em>, where I highlighted the best libraries, repos, packages, and tools that help us be better data scientists for all kinds of tasks.</br></p>\n<p>The great folks at\u00a0<a href=\"http://heartbeat.fritz.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Heartbeat</a>\u00a0sponsored a lot of these digests, and they asked me to create a list of the best of the best\u2014those libraries that really changed or improved the way we worked this year (and beyond).</p>\n<p>If you want to read the past digests, take a look here:</p>\n<p><a href=\"https://www.getrevue.co/profile/favio\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Weekly Digest for Data Science and AI - Revue</strong><br>\n<em>Weekly Digest for Data Science and AI - Personal newsletter of Favio V\u00e1zquez...</em>www.getrevue.co</br></a></p>\n<blockquote><p>Disclaimer: This list is based on the libraries and packages I reviewed in my personal newsletter. All of them were trending in one way or another among programmers, data scientists, and AI enthusiasts. Some of them were created before 2018, but if they were trending, they could be considered.</p></blockquote>\n<p>\u00a0</p>\n<h3>Top 7 for\u00a0Python</h3>\n<p>\u00a0<br>\n<img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/1*m9QfnOyrKGa6i9tS0TKVhA.gif\" width=\"99%\"/></br></p>\n<p>\u00a0</p>\n<h3><b>7. AdaNet\u200a\u2014\u200aFast and flexible AutoML with learning guarantees.</b></h3>\n<p>\u00a0<br>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/0*ZPLMGasPVMFyCyiG.png\" width=\"65%\"/><br/>\n<font size=\"-1\"><a href=\"https://github.com/tensorflow/adanet\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/tensorflow/adanet</a></font></center></br></p>\n<p>AdaNet is a lightweight and scalable TensorFlow AutoML framework for training and deploying adaptive neural networks using the\u00a0<em>AdaNet</em>\u00a0algorithm [<a href=\"https://arxiv.org/abs/1607.01097\" rel=\"noopener noreferrer\" target=\"_blank\">Cortes et al. ICML 2017</a>].\u00a0<em>AdaNet</em>\u00a0combines several learned subnetworks in order to mitigate the complexity inherent in designing effective neural networks.</p>\n<p>This package will help you selecting optimal neural network architectures, implementing an adaptive algorithm for learning a neural architecture as an ensemble of subnetworks.</p>\n<p>You will need to know TensorFlow to use the package because it implements a TensorFlow Estimator, but this will help you simplify your machine learning programming by encapsulating training and also evaluation, prediction and export for serving.</p>\n<p>You can build an ensemble of neural networks, and the library will help you optimize an objective that balances the trade-offs between the ensemble\u2019s performance on the training set and its ability to generalize to unseen data.</p>\n<p><b>Installation</b></p>\n<p><code>adanet</code>\u00a0depends on bug fixes and enhancements not present in TensorFlow releases prior to 1.7. You must install or upgrade your TensorFlow package to at least 1.7:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ pip install \"tensorflow&gt;=1.7.0\"</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Installing from\u00a0source</b></p>\n<p>To install from source, you\u2019ll first need to install\u00a0<code>bazel</code>\u00a0following their\u00a0<a href=\"https://docs.bazel.build/versions/master/install.html\" rel=\"noopener noreferrer\" target=\"_blank\">installation instructions</a>.</p>\n<p>Next clone\u00a0<code>adanet</code>\u00a0and\u00a0<code>cd</code>\u00a0into its root directory:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ git clone <a href=\"https://github.com/tensorflow/adanet\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/tensorflow/adanet</a> &amp;&amp; cd adanet</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>From the\u00a0<code>adanet</code>\u00a0root directory run the tests:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ cd adanet\r\n$ bazel test -c opt //...</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Once you have verified that everything works well, install\u00a0<code>adanet</code>\u00a0as a\u00a0<a href=\"https://github.com/tensorflow/adanet/blob/master/adanet/pip_package/PIP.md\" rel=\"noopener noreferrer\" target=\"_blank\">pip package\u00a0</a>.</p>\n<p>You\u2019re now ready to experiment with\u00a0<code>adanet</code>.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import adanet</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Usage</b></p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/0*YcvUdmZdv4NWjKF9.gif\" width=\"75%\"/></p>\n<p>Here you can find two examples on the usage of the package:</p>\n<p><a href=\"https://github.com/tensorflow/adanet/tree/master/adanet/examples/tutorials\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>tensorflow/adanet</strong><br/>\n<em>Fast and flexible AutoML with learning guarantees.\u200a\u2014\u200atensorflow/adanet</em>github.com</a></p>\n<p>You can read more about it in the original blog post:</p>\n<p><a href=\"https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html?m=1\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Introducing AdaNet: Fast and Flexible AutoML with Learning Guarantees</strong><br/>\n<em>Posted by Charles Weill, Software Engineer, Google AI, NYC Ensemble learning\u00a0, the art of combining different machine\u2026</em>ai.googleblog.com</a></p>\n<p>\u00a0</p>\n<h3><b>6. TPOT\u2014 An automated Python machine learning tool that optimizes machine learning pipelines using genetic programming.</b></h3>\n<p>\u00a0<br/>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/0*C5teFLKPLkW48BP5.jpg\" width=\"60%\"/><br/>\n<font size=\"-1\"><a href=\"https://github.com/EpistasisLab/tpot\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/EpistasisLab/tpot</a></font></center></p>\n<p><a href=\"https://heartbeat.fritz.ai/weekly-digest-for-data-science-and-ai-python-and-r-volume-6-830ed997cf07\" rel=\"noopener noreferrer\" target=\"_blank\">Previously</a>\u00a0I talked about Auto-Keras, a great library for AutoML in the Pythonic world. Well, I have another very interesting tool for that.</p>\n<p>The name is\u00a0<strong>TPOT</strong>\u00a0(Tree-based Pipeline Optimization Tool), and it\u2019s an amazing library. It\u2019s basically a Python automated machine learning tool that optimizes machine learning pipelines using\u00a0<strong>genetic programming</strong>.</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/1000/0*nDQABCJuEPhds4el.png\" width=\"99%\"/></p>\n<p>TPOT can automate a lot of stuff like feature selection, model selection, feature construction, and much more. Luckily, if you\u2019re a Python machine learner, TPOT is built on top of Scikit-learn, so all of the code it generates should look familiar.</p>\n<p>What it does is automate the most tedious parts of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data, and then it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there.</p>\n<p>This is how it works:</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/1000/0*Y1E0P1CbeV0yQoUL.png\" width=\"99%\"/></p>\n<p>For more details you can read theses great article by\u00a0<a href=\"https://medium.com/@mattmayo13\" rel=\"noopener noreferrer\" target=\"_blank\">Matthew Mayo</a>:</p>\n<p><a href=\"/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-4.html\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Using AutoML to Generate Machine Learning Pipelines with TPOT</strong><br/>\n<em>Thus far in this series of posts we have: This post will take a different approach to constructing pipelines. Certainly\u2026</em>www.kdnuggets.com</a></p>\n<p>and\u00a0<a href=\"https://medium.com/@randal_olson\" rel=\"noopener noreferrer\" target=\"_blank\">Randy Olson</a>:</p>\n<p><a href=\"/2016/05/tpot-python-automating-data-science.html\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>TPOT: A Python Tool for Automating Data Science</strong><br/>\n<em>By Randy Olson, University of Pennsylvania. Machine learning is often touted as: A field of study that gives computers\u2026</em>www.kdnuggets.com</a></p>\n<p><b>Installation</b></p>\n<p>You actually need to follow some instructions before installing TPOT. Here they are:</p>\n<p><a href=\"http://epistasislab.github.io/tpot/installing/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Installation\u200a\u2014\u200aTPOT</strong><br/>\n<em>Optionally, you can install XGBoost if you would like TPOT to use the eXtreme Gradient Boosting models. XGBoost is\u2026</em>epistasislab.github.io</a></p>\n<p>After that you can just run:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>pip install tpot</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Examples:</b></p>\n<p>First let\u2019s start with the basic Iris dataset:</p>\n<p><script src=\"https://gist.github.com/FavioVazquez/5128d051c180584d12859c7a2fd93baa.js\"></script></p>\n<p>So here we built a very basic TPOT pipeline that will try to look for the best ML pipeline to predict the\u00a0<code>iris.target</code><em>.\u00a0</em>And then we save that pipeline. After that, what we have to do is very simple\u200a\u2014\u200aload the\u00a0<code>.py</code>\u00a0file you generated and you\u2019ll see:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nimport numpy as np\r\n\r\nfrom sklearn.kernel_approximation import RBFSampler\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.pipeline import make_pipeline\r\nfrom sklearn.tree import DecisionTreeClassifier\r\n\r\n# NOTE: Make sure that the class is labeled 'class' in the data file\r\ntpot_data = np.recfromcsv('PATH/TO/DATA/FILE', delimiter='COLUMN_SEPARATOR', dtype=np.float64)\r\nfeatures = np.delete(tpot_data.view(np.float64).reshape(tpot_data.size, -1), tpot_data.dtype.names.index('class'), axis=1)\r\ntraining_features, testing_features, training_classes, testing_classes = \\\r\n    train_test_split(features, tpot_data['class'], random_state=42)\r\n\r\nexported_pipeline = make_pipeline(\r\n    RBFSampler(gamma=0.8500000000000001),\r\n    DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_leaf=4, min_samples_split=9)\r\n)\r\n\r\nexported_pipeline.fit(training_features, training_classes)\r\nresults = exported_pipeline.predict(testing_features)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>And that\u2019s it. You built a classifier for the Iris dataset in a simple but powerful way.</p>\n<p>Let\u2019s go the MNIST dataset now:</p>\n<p><script src=\"https://gist.github.com/FavioVazquez/3786580b03e16c16848d8939b3aeaae5.js\"></script></p>\n<p>As you can see, we did the same! Let\u2019s load the\u00a0<code>.py</code>\u00a0file you generated again and you\u2019ll see:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nimport numpy as np\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\n# NOTE: Make sure that the class is labeled 'class' in the data file\r\ntpot_data = np.recfromcsv('PATH/TO/DATA/FILE', delimiter='COLUMN_SEPARATOR', dtype=np.float64)\r\nfeatures = np.delete(tpot_data.view(np.float64).reshape(tpot_data.size, -1), tpot_data.dtype.names.index('class'), axis=1)\r\ntraining_features, testing_features, training_classes, testing_classes = \\\r\n    train_test_split(features, tpot_data['class'], random_state=42)\r\n\r\nexported_pipeline = KNeighborsClassifier(n_neighbors=4, p=2, weights=\"distance\")\r\n\r\nexported_pipeline.fit(training_features, training_classes)\r\nresults = exported_pipeline.predict(testing_features)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Super easy and fun. Check them out! Try it and please give them a star!</p>\n<p>\u00a0</p>\n<h3><b>5. SHAP\u200a\u2014\u200aA unified approach to explain the output of any machine learning\u00a0model</b></h3>\n<p>\u00a0<br/>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/0*ngrNi7J-wpcwXXyO.png\" width=\"99%\"/><br/>\n<font size=\"-1\"><a href=\"https://github.com/slundberg/shap\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/slundberg/shap</a></font></center></p>\n<p>Explaining machine learning models isn\u2019t always easy. Yet it\u2019s so important for a range of business applications. Luckily, there are some great libraries that help us with this task. In many applications, we need to know, understand, or prove how input variables are used in the model, and how they impact final model predictions.</p>\n<p><strong>SHAP</strong>\u00a0(SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.</p>\n<p><b>Installation</b></p>\n<p>SHAP can be installed from\u00a0<a href=\"https://pypi.org/project/shap\" rel=\"noopener noreferrer\" target=\"_blank\">PyPI</a></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>pip install shap</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>or\u00a0<a href=\"https://anaconda.org/conda-forge/shap\" rel=\"noopener noreferrer\" target=\"_blank\">conda-forge</a></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>conda install -c conda-forge shap</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><b>Usage</b></p>\n<p>There are tons of different models and ways to use the package. Here, I\u2019ll take one example from the DeepExplainer.</p>\n<p>Deep SHAP is a high-speed approximation algorithm for SHAP values in deep learning models that builds on a connection with\u00a0<a href=\"https://arxiv.org/abs/1704.02685\" rel=\"noopener noreferrer\" target=\"_blank\">DeepLIFT</a>, as described in the SHAP NIPS paper that you can read here:</p>\n<p><a href=\"https://arxiv.org/abs/1802.03888\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>[1802.03888] Consistent Individualized Feature Attribution for Tree Ensembles</strong><br/>\n<em>Abstract: Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is\u2026</em>arxiv.org</a></p>\n<p>Here you can see how SHAP can be used to explain the result of a Keras model for the MNIST dataset:</p>\n<p><script src=\"https://gist.github.com/FavioVazquez/4257dd4e0c10495e49d53f1b75e92f5f.js\"></script></p>\n<p>You can find more examples here:</p>\n<p><a href=\"https://github.com/slundberg/shap#sample-notebooks\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>slundberg/shap</strong><br/>\n<em>A unified approach to explain the output of any machine learning model.\u200a\u2014\u200aslundberg/shap</em>github.com</a></p>\n<p>Take a look. You\u2019ll be surprised\u00a0:)</p>\n</div> ", "website": "kdnuggets"}