{"content": "By Kritika Jalan , India. comments WordCloud using less than 40 lines of R\u00a0Code Guess whose twitter handle gives this word cloud? Enough hints present in there. You are right, that is Andrew Ng tweeting about his new Deep Learning course on Coursera! It\u2019s always fun to see data in action; isn\u2019t it? Let\u2019s try and create a similar word cloud for three world leaders, viz. American President Donald Trump, Indian Prime Minister Narendra Modi, and Russian President Vladimir Putin. Fig. 1: R Word Cloud from Andrew Ng\u2019s Tweets A word cloud is a data visualisation technique in which the size of each word indicates its frequency or importance in the associated text (i.e., the more times a word appears in the corpus, the bigger the word) Since you are interested in creating a word cloud from twitter handles using R, I will safely assume you have both, a Twitter account to your name, and RStudio installed on your machine. If not, now is the time to do it. You must also have a Twitter Developer Account set up as a medium to extract the tweets. If you need help with it, here\u2019s a\u00a0 quick guide . Let\u2019s get started. Following are the steps we will be taking to get this task done: Get Twitter data using handles (2 lines of code!) Prepare it for visualisation (Real fun part) And finally, create a word cloud (Single line of code!) Extract Tweets Let us load necessary libraries and establish a connection with Twitter #Getting tweets from twitter\r \r #Twitter-R Authentication\r \r #Text processing\r \r #Text mining\r \r #Wordcloud creation\r \r \r #Connect to twitter API using the saved credentials\r \r \r \r Let\u2019s go collect some data now. A couple things to note here \u2013 One can only get access to data from users who \u2018 follow\u2019 the Twitter account associated with the API. Or, from the accounts that are public (vs. private) Twitter\u00a0 API limits the number of tweets a user can get from a particular timeline to be 3200, including RTs even if it is set to FALSE. There are, although, a\u00a0 few tools \u00a0available that lets you bypass this limit. We will stick to the limits in this post Twitter API also has a\u00a0 rate limit on how many tweets can be collected at once. If you try to collect too many of them at once, it may fail or return partial results. The best way to work around this is by introducing lag between API calls so that you don\u2019t have to be around when the code runs Get twitter handles of the personalities you want to look up. Make sure these are real twitter accounts or you\u2019ll get an error. screenName <- \r \r Collect information about these handles using twitteR.\r checkHandles <- \r Get user data for each of the handles and create a data frame for easy access. Check for number of tweets and private accounts using this. Remove private accounts, if any. UserData <-  )\r UserData <- \r \r \r #Check tweet count\r \r \r #Check Private Accounts\r usernames <- \r \r #Public Accounts\r usernames <- \r Next we get the list of tweets from the user timelines, covert them to a dataframe and wait for 5 minutes before making another API call. Combine all the dataframes into one to pre-process the tweets. Note, we will only be getting 3200 most recent tweets for these handles. Trump and Modi have tweeted a lot more than that. x <- \r \r #Convert tweets list to dataframe\r TrumpData <- \r \r #Wait 5 minutes\r \r \r x <- \r PutinData <- \r \r \r x <- \r ModiData <- \r \r Trump.df <- \r Putin.df <- \r Modi.df <- \r \r #Now create a dataframe that combines all of the collected tweets\r tweets <- \r tweets <- Trump.df\r tweets <- \r tweets <- \r Pre-Process Tweets Now that we have all the relevant tweets in one place, it is time to pre-process them. What I mean here is, let\u2019s remove unwanted characters, symbols and words. You do not want graphic characters, articles, symbols, and numbers to appear in the word cloud. You can skip any of these pre-processing steps based on your need. #Convert tweets to ASCII to avoid reading strange characters\r \r \r #Clean text by removing graphic characters\u00a0\u00a0\r tweets$text=\r \r #Remove Junk Values and replacement words like fffd which appear \r because of encoding differences\r tweets$text <- \r \r #Convert all text to lower case\r tweets$text <- \r \r #Remove retweet keyword\r tweets$text <- \r \r #Remove Punctuations\r tweets$text <- \r \r #Remove links\r tweets$text <- \r \r #Remove tabs\r tweets$text <- \r \r #Remove blankspaces at begining\r tweets$text <- \r \r #Remove blankspaces at the end\r tweets$text <- \r \r #Remove usernames\r tweets$text <- \r Once we have pre-processed tweets, let us now create a corpus for each handle and remove stopwords like \u2018my\u2019, \u2018do\u2019, \u2018today\u2019 etc. #After preprocessing the data, subset for tweets for each handle\r Trump <- \r Putin <- \r Modi <- \r \r #Create corpus of individual twitter handles\r Trump <- )\r Putin <- )\r Modi <- )\r \r #Remove English Stopwords from the tweets\r Trump <- )\r Putin <- )\r Modi <- )\r Create Word Cloud If you survived through all these steps to reach here, you deserve a poetic treat! Here goes.. Now that we have everything we need, Let\u2019s feed upon our greed Make a cloud of what they tweet, Like in the beginning we\u00a0agreed A function\u00a0\u00a0lets you define parameters for word cloud creation viz. input corpus, minimum frequency of the words to be displayed, size and shape of the cloud, color and order of the words, maximum words displayed, etc. Tweak these and have a little play. ,colors=,\r random.color= FALSE, random.order = FALSE, max.words = 110)\r \r ,colors=,\r random.color= FALSE, random.order = FALSE, max.words = 100)\r \r ,colors=,\r random.color= FALSE, random.order = FALSE, max.words = 110)\r \r Syntax and Explanation ( source ):\r \r words: Words to be plotted in the cloud freq: Frequency of these words in the text min.freq: Words with frequency below min.freq will not be plotted scale: A vector of length 2 indicating the range of the size of the words max.words: Maximum number of words to be plotted; least frequent terms dropped random.order: Plot words in random order. If false, they will be plotted in decreasing frequency random.color: Choose colors randomly from the colors. If false, the color is chosen based on the frequency rot.per: Proportion words with 90 degree rotation colors: Color words from least to most frequent ordered.colors: If true, then colors are assigned to words in order use.r.layout: If false, then C++ code is used for collision detection, otherwise R is used \u2026: \u00a0Additional parameters to be passed to text (and strheight,strwidth). You can add more information to your word cloud based on the order and color you choose. You can specify non-random color assignment (random.color = FALSE) which will make it based on frequency then choose a value of colors using a palette (brewer.pal from RColorBrewer package) that goes in the order you prefer. You can also have words color-coded based on their sentiments, say for example positive and negative emotions. This can be accomplished by having an additional column in the database that define this property and then using it to define color as follows \u2013 ,random.color= FALSE, ordered.colors=TRUE,colors=[],random.order = FALSE, max.words = 110) After you have created the cloud, you might see some of the words or numbers that are irrelevant and give no additional information. In such cases, you need to tweak your cloud a bit again. For Example, when I created these clouds, I saw the words \u2018amp\u2019 and \u2018will\u2019 as the most frequent words in Trump\u2019s and Modi\u2019s cloud. I used the following code lines and removed them. Below are the word clouds I got after making these changes. #Remove numbers if necessary\r #Putin <- \r \r #Remove specific words if needed\r #Trump <- )\r #Modi <- )\r Fig. 2: R Word Cloud from President Putin\u2019s Tweets Fig. 3: R Word Cloud using President Trump\u2019s most recent Tweets Fig. 4: R Word Cloud from Prime Minister Modi\u2019s most recent Tweets I have also created a\u00a0 GitHub repository \u00a0with all the codes in one place. That one creates word clouds for Amitabh Bacchan, Sundar Pichai, Virat Kohli, and Andrew Ng. Closing Note Apart from getting a sense of what is being tweeted about the most by a particular Twitter handle, we can use word clouds to do a lot of other cool stuff. One such example is sentiment analysis for a product. Use hashtag to get all the tweets about the product, process them to get meaningful words and build a cloud, bang! You know your product is doing well if the most frequent words are positive. Bio: Kritika Jalan is an experienced business analyst working in management consulting. She is skilled in R, Python, SQL, and other data analysis tools and machine learning techniques. Related: What makes a data visualization successful? Must-Know: How to determine the influence of a Twitter user? What Americans Really Think About Trump\u2019s Immigration Ban and Why", "title_html": "<h1 id=\"title\">Find Out What Celebrities Tweet About the Most</h1> ", "url": "https://www.kdnuggets.com/2017/10/what-celebrities-tweet-about-most.html", "tfidf": {"tfidf": {"after": 3.06210621063, "real": 4.56206896552, "nonrandom": 1587.6, "sundar": 1443.27272727, "limit": 6.074612588480001, "donald": 7.0970049173000005, "onc": 4.492359932099999, "too": 1.81585268215, "analyst": 14.8373831776, "plot": 26.917599186150003, "differ": 1.23654490225, "assign": 7.67327211214, "addit": 3.73904851626, "datafram": 6350.4, "number": 6.60857499654, "decreas": 4.5230769230800005, "specif": 1.8719490626099997, "function": 2.495441685, "python": 56.2978723404, "trumpdf": 3175.2, "product": 4.86794766966, "done": 2.3302509907499998, "creation": 6.1202775636, "know": 2.59327017315, "collis": 18.3325635104, "irrelev": 29.7861163227, "collect": 8.2054992764, "scale": 3.7469907953699995, "particular": 2.7629655412400003, "creat": 14.9915014164, "their": 1.01547908405, "hashtag": 496.125, "vector": 25.898858075, "how": 3.20500656102, "present": 1.25551601423, "immigr": 5.32751677852, "authent": 11.504347826099998, "surviv": 2.2576791808900003, "minist": 6.2064112588, "end": 1.10680423871, "frame": 6.280063291139999, "alway": 2.06745670009, "word": 73.65802874280999, "interest": 1.60331246213, "deep": 3.6279707495399998, "color": 57.38313253005, "will": 9.79848788768, "associ": 2.6526315789400003, "rotat": 8.53548387097, "otherwis": 3.72151898734, "new": 1.0178880554, "lag": 33.3529411765, "similar": 1.37514075357, "need": 7.186311787049999, "our": 2.35758835759, "final": 1.34008609775, "junk": 69.327510917, "charact": 10.06881243064, "success": 1.32002993265, "fun": 25.7727272728, "replac": 1.5602948402899999, "also": 4.05906040268, "today": 1.74961428257, "pass": 1.61818367139, "use": 14.414942603319998, "establish": 1.34622233528, "bacchan": 1587.6, "treat": 3.59023066486, "sure": 7.453521126760001, "cours": 2.15092805853, "count": 3.48157894737, "everyth": 4.81967213115, "tri": 3.7089125102199993, "not": 3.04702194357, "like": 3.44755700325, "rcolorbrew": 1587.6, "length": 3.69123459661, "are": 10.299059357800001, "deserv": 15.236084453, "etc": 8.413354531, "less": 1.46904783936, "experienc": 3.5564516129, "wordcloud": 3175.2, "quick": 2.205, "easi": 5.2937645882, "tweak": 226.8, "userdata": 3175.2, "handl": 43.15196441809, "english": 1.7432744043000001, "then": 4.34631442064, "usernam": 1221.2307692309998, "graphic": 18.071713147420002, "anoth": 1.13643521832, "instal": 3.78721374046, "consult": 5.21721984883, "choos": 12.536983416690001, "world": 1.11340206186, "minimum": 6.02962400304, "chosen": 3.59266802444, "github": 1587.6, "strheight": 1587.6, "feed": 7.77853993141, "randomcolor": 9525.599999999999, "influenc": 1.77246846042, "meaning": 21.8076923077, "mine": 4.875921375919999, "twitter": 564.6276150621001, "poetic": 20.0707964602, "valu": 4.555523672880001, "kritika": 3175.2, "got": 3.61969904241, "develop": 1.1955719557200002, "bang": 24.728971962600003, "such": 2.12302754748, "agre": 2.22946215419, "whose": 1.73508196721, "amp": 72.8256880734, "lot": 8.81755068036, "some": 2.08073394496, "sourc": 1.69760479042, "drop": 2.4594887684, "add": 4.61243463103, "result": 1.14611608432, "subset": 27.3253012048, "repositori": 44.974504249300004, "india": 3.92387543253, "twitterr": 1587.6, "well": 1.0655748708, "introduc": 1.7258397651900002, "set": 2.37415881562, "wait": 9.10843373494, "ani": 2.26767604628, "credenti": 39.5910224439, "from": 14.00794100958, "account": 17.50171484565, "privat": 8.09586945436, "work": 2.23040179826, "num": 16.00504064016, "partial": 3.6131087847099996, "safe": 5.02723242559, "for": 16.00504064016, "sentiment": 19.845, "american": 2.6328358209, "orderedcolor": 1587.6, "colorcod": 1587.6, "with": 6.007189253939998, "assum": 2.9575260804799997, "determin": 2.1658935879900003, "true": 2.55569864778, "explan": 6.50922509225, "frequent": 8.42004773268, "sens": 2.8365195640499996, "preprocess": 7327.3846153800005, "look": 1.9086318826599997, "mustknow": 1587.6, "combin": 3.39520958084, "extract": 15.406113537120001, "think": 2.90715986083, "timelin": 21.822680412399997, "negat": 3.75852272727, "public": 2.4484885873, "posit": 2.74505057492, "stuff": 23.3127753304, "column": 7.078020508250001, "tab": 54.1843003413, "medium": 7.00617828773, "remov": 32.092987997440005, "even": 1.16461267606, "modi": 1764.0, "give": 2.7306501548, "reach": 1.49801849406, "ban": 4.32, "help": 1.39962972759, "check": 19.51967213115, "putindata": 1587.6, "they": 2.06034650574, "avoid": 2.45986984816, "step": 8.48379052368, "error": 6.04109589041, "stick": 11.5377906977, "his": 1.0943682360200002, "librari": 2.68266306185, "maxword": 7938.0, "randomord": 7938.0, "fals": 18.64839467502, "thing": 2.4065484311099996, "presid": 7.937007874, "machin": 8.04866920152, "again": 1.50883862384, "freq": 1587.6, "relev": 6.938811188810001, "bypass": 13.7216940363, "through": 1.07074930869, "rts": 299.547169811, "what": 6.2671719563999995, "techniqu": 7.458773784360001, "russian": 4.08228336333, "palett": 81.83505154640001, "putindf": 1587.6, "trump": 558.140625, "line": 5.673039128119999, "prime": 6.9969149405, "amitabh": 588.0, "least": 3.2330719886000003, "base": 5.73140794225, "relat": 1.23750876919, "rotper": 1587.6, "who": 1.06279287723, "between": 1.03453668708, "bigger": 13.23, "post": 2.23826307627, "here": 12.1153846154, "lower": 2.10055570257, "littl": 1.5499365420299998, "punctuat": 42.1114058355, "maximum": 9.60145146658, "clean": 6.86975335353, "paramet": 34.513043478200004, "apart": 3.1032056294, "modidata": 1587.6, "encod": 29.0237659963, "about": 5.324300757950001, "articl": 2.01805008262, "fffd": 1587.6, "pichai": 1587.6, "tweet": 3806.5263157912, "she": 2.16, "frequenc": 61.671476137599996, "upon": 1.60331246213, "them": 5.4938057997000005, "defin": 8.184911496809999, "size": 7.48162111215, "vladimir": 16.5547445255, "emot": 6.01819560273, "place": 2.2008733624400003, "save": 2.8178913737999998, "narendra": 236.955223881, "let": 31.37549407119, "tool": 9.99433427762, "start": 1.26673581744, "orderedcolorstru": 1587.6, "run": 1.55692850838, "guid": 2.49113447356, "load": 6.80497213888, "whi": 3.2566153846200003, "singl": 1.60948905109, "guess": 25.0410094637, "indian": 3.5046357615900003, "koh": 203.53846153799998, "coursera": 1587.6, "the": 56.0, "build": 1.6341739578, "analysi": 6.95705521472, "display": 5.86913123844, "order": 6.23125834055, "blankspac": 3175.2, "there": 2.08182533438, "connect": 3.7687833827800006, "inform": 4.72593768606, "unwant": 37.980861244, "say": 1.7544480053, "best": 1.5828514456600002, "exampl": 4.51450236966, "right": 1.4054532577899999, "appear": 3.96437489595, "take": 1.13961668222, "visual": 5.22752716497, "follow": 4.18560506196, "now": 6.9646852379999995, "checkhandl": 1587.6, "name": 1.10211732037, "code": 27.164996333439998, "hint": 15.2068965517, "than": 2.0655737705, "play": 1.46390041494, "realli": 4.7476076555, "goe": 8.503481521160001, "indic": 4.1652892562, "note": 4.27348586811, "cloud": 254.8655518392, "specifi": 6.920662598080001, "coupl": 3.2572835453400004, "person": 1.40520446097, "mani": 2.08853515754, "around": 2.42789417342, "mean": 1.44906900329, "symbol": 6.835737352000001, "task": 3.88641370869, "accomplish": 5.17302052786, "may": 1.05201775893, "minfreq": 3175.2, "want": 3.99396226416, "convert": 9.82223138793, "into": 1.01502461479, "screennam": 1587.6, "individu": 1.8004082558400003, "strang": 10.150895140700001, "although": 1.14968498805, "bio": 42.336000000000006, "trumpdata": 1587.6, "minut": 6.22466183102, "which": 3.015575535, "databas": 8.24727272727, "saw": 1.94845360825, "skill": 3.6989748369099997, "term": 1.39520168732, "other": 2.01984732824, "three": 1.06621893889, "one": 6.03764974332, "brewerp": 1587.6, "prefer": 3.0216977540900003, "begin": 2.6610794502200004, "see": 2.54484251022, "becaus": 1.1495184997499999, "corpus": 96.364188164, "get": 24.9987627939, "random": 14.3804347826, "manag": 1.6448404475799998, "stopword": 3175.2, "detect": 5.41288782816, "part": 1.04330682789, "both": 1.05215720061, "import": 1.3401992233700002, "includ": 1.0190641247799999, "cool": 6.8578833693300005, "strwidth": 1587.6, "next": 1.4950560316400001, "below": 4.51215006394, "this": 8.03034901368, "rang": 1.7848229342299997, "proport": 5.26741871267, "time": 3.03382381044, "process": 3.39049652964, "chang": 1.1808985421, "bit": 8.33385826772, "covert": 26.154859967100002, "most": 7.14675241161, "rstudio": 1587.6, "return": 1.39532431007, "modidf": 1587.6, "fail": 1.9281029876099998, "all": 7.080275229370001, "syntax": 45.6206896552, "input": 12.2029208301, "action": 1.81855670103, "greed": 51.2129032258, "recent": 4.63217272905, "have": 12.178738093679998, "degre": 2.4852849092, "case": 2.96997474512, "that": 12.047808765, "viz": 231.766423358, "call": 2.1353059852, "rate": 2.14048806795, "more": 3.0515120451, "and": 30.0018897639, "access": 3.7469907953800003, "list": 2.72642967542, "these": 9.66738836268, "prepar": 2.43012398592, "keyword": 139.263157895, "befor": 1.10036041031, "comment": 3.05954904606, "close": 1.2848818387799998, "can": 10.58635252278, "avail": 1.7288467821, "make": 6.457596095160001, "way": 1.2190739461, "onli": 2.0512953033200003, "each": 4.75899280576, "andrew": 11.473861720079999, "few": 1.31729173581, "necessari": 5.684210526319999, "skip": 26.111842105300003, "read": 2.3149606299200003, "packag": 7.828402366860001, "link": 2.15151104486, "data": 33.7643555934, "shape": 3.20338983051, "sinc": 1.08368600683, "virat": 1443.27272727, "jalan": 1323.0, "must": 1.9220338983099996, "might": 2.1561863370900003, "text": 53.18068965519, "leader": 2.0994445913799997, "putin": 567.0, "has": 1.0436497502, "busi": 2.05541170378, "enough": 2.2319696330700003, "fig": 218.2268041236, "properti": 2.5949656750599996, "userlayout": 1587.6, "user": 38.55269548325, "learn": 4.6455010973, "when": 2.0415353951, "retweet": 1587.6, "visualis": 360.818181818}, "logtfidf": {"after": 0.061472083944299996, "real": 1.649258121148, "nonrandom": 7.369978720910001, "sundar": 7.2746685411000005, "limit": 1.67129541852, "donald": 1.95967285241, "onc": 1.211297617065, "too": 0.5965551547219999, "analyst": 2.6971498864499996, "plot": 8.41671202545, "differ": 0.212321121312, "assign": 2.6891919112, "addit": 0.6606566489160001, "datafram": 29.479914883640003, "number": 0.5796514705116, "decreas": 1.50919249744, "specif": 0.626980167541, "function": 0.914465741594, "python": 4.03065674296, "trumpdf": 14.739957441820001, "product": 1.452180409608, "done": 0.845975983129, "creation": 2.23692053694, "know": 0.952919694398, "collis": 2.9086789053400004, "irrelev": 3.3940423897400005, "collect": 2.4768333026000002, "scale": 1.32095306328, "particular": 0.646314787608, "creat": 2.670921822168, "their": 0.015360505122700001, "hashtag": 6.2068279111, "vector": 3.25419887797, "how": 0.9431339138600001, "present": 0.227546654799, "immigr": 1.6728852344, "authent": 2.4427250357499997, "surviv": 0.8143373745379999, "minist": 2.2648713024, "end": 0.101476798618, "frame": 1.8373800586400002, "alway": 0.726319204572, "word": 24.020304377785, "interest": 0.47207177798199995, "deep": 1.2886734698, "color": 20.1255030102, "will": 1.62229227932, "associ": 0.5648100307020001, "rotat": 2.1442320472, "otherwis": 1.3141319148700001, "new": 0.0177299468511, "lag": 3.5071459596699994, "similar": 0.318556092114, "need": 1.81370081721, "our": 0.8576392141820001, "final": 0.292733863948, "junk": 4.23884181035, "charact": 3.692593628956, "success": 0.27765441259199997, "fun": 5.112339339619999, "replac": 0.444874803592, "also": 0.0586286312, "today": 0.559395353679, "pass": 0.48130432974, "use": 0.4089122762424, "establish": 0.297302399813, "bacchan": 7.369978720910001, "treat": 1.27821645249, "sure": 2.0086865552, "cours": 0.765899404133, "count": 1.24748591139, "everyth": 1.57270590317, "tri": 1.23518305832, "not": 0.0466572390225, "like": 0.417160729635, "rcolorbrew": 7.369978720910001, "length": 1.3059609811200001, "are": 0.294674735827, "deserv": 2.7236665915900002, "etc": 2.8733461759400005, "less": 0.3846144626, "experienc": 1.26876330984, "wordcloud": 14.739957441820001, "quick": 0.790727508899, "easi": 1.6665296351499999, "tweak": 9.46184278258, "userdata": 14.739957441820001, "handl": 15.035159359329999, "english": 0.555765186335, "then": 0.33213546092359997, "usernam": 18.027006503309998, "graphic": 4.40240145144, "anoth": 0.127896361652, "instal": 1.3316305879, "consult": 1.6519646640099999, "choos": 4.29021198216, "world": 0.107420248621, "minimum": 1.79668465441, "chosen": 1.27889510877, "github": 7.369978720910001, "strheight": 7.369978720910001, "feed": 2.05136865109, "randomcolor": 44.21987232546, "influenc": 0.572373185428, "meaning": 3.08226276571, "mine": 1.58430908678, "twitter": 59.550202383969996, "poetic": 2.99926584614, "valu": 1.646386620296, "kritika": 14.739957441820001, "got": 1.2863908849299999, "develop": 0.178624694913, "bang": 3.20797551021, "such": 0.119391955612, "agre": 0.801760369921, "whose": 0.5510546556329999, "amp": 4.28806875111, "lot": 2.9671939005000003, "some": 0.079147018129, "sourc": 0.529218310751, "drop": 0.8999535106219999, "add": 1.52875583713, "result": 0.136378908381, "subset": 3.3078130570499997, "repositori": 3.8060957569699996, "india": 1.36707979618, "twitterr": 7.369978720910001, "well": 0.0635144383156, "introduc": 0.5457137524260001, "set": 0.342992022578, "wait": 3.03210717564, "ani": 0.251216716732, "credenti": 3.6786023866, "from": 0.007938758364123999, "account": 5.985668609757, "privat": 2.820238506348, "work": 0.218069134546, "num": 0.005039846326352001, "partial": 1.28456856096, "safe": 1.61486961909, "for": 0.005039846326352001, "sentiment": 4.58960981136, "american": 0.549828687244, "orderedcolor": 7.369978720910001, "colorcod": 7.369978720910001, "with": 0.00718495028034, "assum": 1.08435313525, "determin": 0.772833019022, "true": 0.938325629634, "explan": 1.87322041569, "frequent": 2.9772845443400002, "sens": 1.04257779501, "preprocess": 42.645686738639995, "look": 0.6463866936, "mustknow": 7.369978720910001, "combin": 1.058436621502, "extract": 4.08323446602, "think": 1.06717661175, "timelin": 4.7796052686, "negat": 1.32402598852, "public": 0.40464750097400004, "posit": 0.633304637216, "stuff": 3.1490015077499995, "column": 1.95699427938, "tab": 3.99239120489, "medium": 1.94679237232, "remov": 11.136781465408001, "even": 0.152388564834, "modi": 43.167181559119996, "give": 0.622785104448, "reach": 0.40414323085000003, "ban": 1.4632554022600002, "help": 0.336207721344, "check": 5.6184314868600005, "putindata": 7.369978720910001, "they": 0.0594539895352, "avoid": 0.900108441291, "step": 3.11863517094, "error": 1.7985854343, "stick": 2.4456277954099996, "his": 0.0901772433641, "librari": 0.986809980943, "maxword": 36.849893604550005, "randomord": 36.849893604550005, "fals": 5.4814433319299996, "thing": 0.8781935346799999, "presid": 2.7409680042119997, "machin": 2.78471916124, "again": 0.411340231612, "freq": 7.369978720910001, "relev": 1.9371304613999998, "bypass": 2.61897808671, "through": 0.0683586918849, "rts": 5.7022719003499995, "what": 1.129436484135, "techniqu": 2.63248769614, "russian": 1.4066564797499999, "palett": 4.40470565484, "putindf": 7.369978720910001, "trump": 37.14647732478, "line": 1.397722457808, "prime": 2.50464429712, "amitabh": 6.3767269479, "least": 0.96057116949, "base": 0.6826165114350001, "relat": 0.21310030165399999, "rotper": 7.369978720910001, "who": 0.0609002329859, "between": 0.033953681165299995, "bigger": 2.58248697813, "post": 0.8057001527009999, "here": 4.42519094185, "lower": 0.742201929994, "littl": 0.438213989466, "punctuat": 3.7403186264499997, "maximum": 3.1375342018400003, "clean": 1.9271282036300001, "paramet": 5.696380287719999, "apart": 1.1324356512, "modidata": 7.369978720910001, "encod": 3.36811501148, "about": 0.31421738737300003, "articl": 0.702131739574, "fffd": 7.369978720910001, "pichai": 7.369978720910001, "tweet": 185.7669105534, "she": 0.7701082216959999, "frequenc": 15.231379630109998, "upon": 0.47207177798199995, "them": 0.47091663454649996, "defin": 3.01104032775, "size": 2.741511618183, "vladimir": 2.80667273902, "emot": 1.79478748063, "place": 0.1914141679144, "save": 1.03598886547, "narendra": 5.46787119451, "let": 11.239223105519999, "tool": 3.21774235926, "start": 0.236443369291, "orderedcolorstru": 7.369978720910001, "run": 0.442714975539, "guid": 0.912738218589, "load": 1.91765354188, "whi": 1.18068843047, "singl": 0.475916769059, "guess": 3.22051485947, "indian": 1.25408659543, "koh": 5.31585498721, "coursera": 7.369978720910001, "the": 0.0, "build": 0.491137452091, "analysi": 2.4932182058400003, "display": 2.15311888412, "order": 1.1007019039650001, "blankspac": 14.739957441820001, "there": 0.080195785851, "connect": 1.267210117364, "inform": 1.363361113986, "unwant": 3.63708238138, "say": 0.562154280552, "best": 0.459227932947, "exampl": 1.2260480249969998, "right": 0.34035985417, "appear": 0.8362076954790001, "take": 0.130691962197, "visual": 1.6539383488600001, "follow": 0.18142764437679998, "now": 0.8945576701260001, "checkhandl": 7.369978720910001, "name": 0.09723316638430002, "code": 9.49213367179, "hint": 2.72174904546, "than": 0.0645217244364, "play": 0.38110439064199997, "realli": 1.5576408397, "goe": 2.8946569795999997, "indic": 1.4672770838299998, "note": 1.061452704249, "cloud": 56.70437587392, "specifi": 1.93451151621, "coupl": 1.18089357972, "person": 0.34018281601800004, "mani": 0.0866315162442, "around": 0.38775421156400003, "mean": 0.37092128352, "symbol": 2.45803432532, "task": 1.35748680661, "accomplish": 1.64345675928, "may": 0.050709995284400004, "minfreq": 14.739957441820001, "want": 1.3832732125099998, "convert": 3.5581081104, "into": 0.0149128632287, "screennam": 7.369978720910001, "individu": 0.588013447985, "strang": 2.3175618928, "although": 0.139487981418, "bio": 3.7456377879300002, "trumpdata": 7.369978720910001, "minut": 2.2707438719599997, "which": 0.01553524153629, "databas": 2.10988256718, "saw": 0.667036036556, "skill": 1.30805571015, "term": 0.33303898354600003, "other": 0.01974949583952, "three": 0.06411868822490001, "one": 0.037532109873, "brewerp": 7.369978720910001, "prefer": 1.10581884366, "begin": 0.571169336536, "see": 0.481843170984, "becaus": 0.139343158825, "corpus": 12.7273611176, "get": 8.116766080948, "random": 3.9454428130199997, "manag": 0.497643387158, "stopword": 14.739957441820001, "detect": 1.68878274493, "part": 0.04239531098280001, "both": 0.050842533389300004, "import": 0.292818277066, "includ": 0.0188846813905, "cool": 1.9253988473800001, "strwidth": 7.369978720910001, "next": 0.402163685499, "below": 1.627253183872, "this": 0.03029159242, "rang": 0.579319213803, "proport": 1.66154043472, "time": 0.0336345565878, "process": 1.05565839805, "chang": 0.166275625058, "bit": 2.12032652634, "covert": 3.2640350228400004, "most": 0.14523527406919998, "rstudio": 7.369978720910001, "return": 0.333126868592, "modidf": 7.369978720910001, "fail": 0.656536611573, "all": 0.07981842468459999, "syntax": 3.8203613341300007, "input": 2.50167533539, "action": 0.598043165069, "greed": 3.9359915164199997, "recent": 1.3032412238639999, "have": 0.1774200280944, "degre": 0.910387304568, "case": 0.790812537778, "that": 0.04771378055568, "viz": 9.50516577614, "call": 0.1309255488976, "rate": 0.761033872166, "more": 0.05107479479999999, "and": 0.001889704261908, "access": 1.255611765432, "list": 0.619691523012, "these": 0.6438025746072, "prepar": 0.8879422790620001, "keyword": 4.93636536551, "befor": 0.0956377718795, "comment": 1.11826753454, "close": 0.250666759864, "can": 1.4610698675459999, "avail": 0.547454586289, "make": 0.44098594693739995, "way": 0.19809150993500002, "onli": 0.050648536658199995, "each": 0.694966757216, "andrew": 4.02437779755, "few": 0.275577913653, "necessari": 2.0890901347999997, "skip": 3.26238893194, "read": 0.83939268088, "packag": 2.0577584491900005, "link": 0.7661704068449999, "data": 12.168205848, "shape": 1.16420957115, "sinc": 0.0803681994577, "virat": 7.2746685411000005, "jalan": 12.989019967119999, "must": 0.653383947388, "might": 0.7683410765340001, "text": 19.388194169829998, "leader": 0.741672829452, "putin": 27.291599007000002, "has": 0.0427239448548, "busi": 0.720476170355, "enough": 0.802884439169, "fig": 15.996962186920001, "properti": 0.953573289192, "userlayout": 7.369978720910001, "user": 10.2129405344, "learn": 1.68550412949, "when": 0.0411099777168, "retweet": 7.369978720910001, "visualis": 10.39045399884}, "logidf": {"after": 0.020490694648099998, "real": 0.824629060574, "nonrandom": 7.369978720910001, "sundar": 7.2746685411000005, "limit": 0.41782385463, "donald": 1.95967285241, "onc": 0.403765872355, "too": 0.5965551547219999, "analyst": 2.6971498864499996, "plot": 1.68334240509, "differ": 0.212321121312, "assign": 1.3445959556, "addit": 0.220218882972, "datafram": 7.369978720910001, "number": 0.0966085784186, "decreas": 1.50919249744, "specif": 0.626980167541, "function": 0.914465741594, "python": 4.03065674296, "trumpdf": 7.369978720910001, "product": 0.484060136536, "done": 0.845975983129, "creation": 1.11846026847, "know": 0.952919694398, "collis": 2.9086789053400004, "irrelev": 3.3940423897400005, "collect": 0.49536666052, "scale": 1.32095306328, "particular": 0.323157393804, "creat": 0.222576818514, "their": 0.015360505122700001, "hashtag": 6.2068279111, "vector": 3.25419887797, "how": 0.47156695693000006, "present": 0.227546654799, "immigr": 1.6728852344, "authent": 2.4427250357499997, "surviv": 0.8143373745379999, "minist": 1.1324356512, "end": 0.101476798618, "frame": 1.8373800586400002, "alway": 0.726319204572, "word": 0.585861082385, "interest": 0.47207177798199995, "deep": 1.2886734698, "color": 1.3417002006799998, "will": 0.202786534915, "associ": 0.28240501535100004, "rotat": 2.1442320472, "otherwis": 1.3141319148700001, "new": 0.0177299468511, "lag": 3.5071459596699994, "similar": 0.318556092114, "need": 0.362740163442, "our": 0.8576392141820001, "final": 0.292733863948, "junk": 4.23884181035, "charact": 0.923148407239, "success": 0.27765441259199997, "fun": 2.5561696698099996, "replac": 0.444874803592, "also": 0.0146571578, "today": 0.559395353679, "pass": 0.48130432974, "use": 0.0292080197316, "establish": 0.297302399813, "bacchan": 7.369978720910001, "treat": 1.27821645249, "sure": 2.0086865552, "cours": 0.765899404133, "count": 1.24748591139, "everyth": 1.57270590317, "tri": 0.61759152916, "not": 0.0155524130075, "like": 0.139053576545, "rcolorbrew": 7.369978720910001, "length": 1.3059609811200001, "are": 0.0294674735827, "deserv": 2.7236665915900002, "etc": 1.4366730879700003, "less": 0.3846144626, "experienc": 1.26876330984, "wordcloud": 7.369978720910001, "quick": 0.790727508899, "easi": 1.6665296351499999, "tweak": 4.73092139129, "userdata": 7.369978720910001, "handl": 1.36683266903, "english": 0.555765186335, "then": 0.08303386523089999, "usernam": 6.009002167769999, "graphic": 2.20120072572, "anoth": 0.127896361652, "instal": 1.3316305879, "consult": 1.6519646640099999, "choos": 1.43007066072, "world": 0.107420248621, "minimum": 1.79668465441, "chosen": 1.27889510877, "github": 7.369978720910001, "strheight": 7.369978720910001, "feed": 2.05136865109, "randomcolor": 7.369978720910001, "influenc": 0.572373185428, "meaning": 3.08226276571, "mine": 1.58430908678, "twitter": 3.50295308141, "poetic": 2.99926584614, "valu": 0.823193310148, "kritika": 7.369978720910001, "got": 1.2863908849299999, "develop": 0.178624694913, "bang": 3.20797551021, "such": 0.059695977806, "agre": 0.801760369921, "whose": 0.5510546556329999, "amp": 4.28806875111, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "drop": 0.8999535106219999, "add": 1.52875583713, "result": 0.136378908381, "subset": 3.3078130570499997, "repositori": 3.8060957569699996, "india": 1.36707979618, "twitterr": 7.369978720910001, "well": 0.0635144383156, "introduc": 0.5457137524260001, "set": 0.171496011289, "wait": 1.51605358782, "ani": 0.125608358366, "credenti": 3.6786023866, "from": 0.000567054168866, "account": 0.665074289973, "privat": 0.705059626587, "work": 0.109034567273, "num": 0.00031499039539700004, "partial": 1.28456856096, "safe": 1.61486961909, "for": 0.00031499039539700004, "sentiment": 2.29480490568, "american": 0.274914343622, "orderedcolor": 7.369978720910001, "colorcod": 7.369978720910001, "with": 0.00119749171339, "assum": 1.08435313525, "determin": 0.772833019022, "true": 0.938325629634, "explan": 1.87322041569, "frequent": 0.7443211360850001, "sens": 1.04257779501, "preprocess": 7.1076144564399995, "look": 0.6463866936, "mustknow": 7.369978720910001, "combin": 0.529218310751, "extract": 2.04161723301, "think": 1.06717661175, "timelin": 2.3898026343, "negat": 1.32402598852, "public": 0.20232375048700002, "posit": 0.316652318608, "stuff": 3.1490015077499995, "column": 1.95699427938, "tab": 3.99239120489, "medium": 1.94679237232, "remov": 0.6960488415880001, "even": 0.152388564834, "modi": 5.3958976948899995, "give": 0.311392552224, "reach": 0.40414323085000003, "ban": 1.4632554022600002, "help": 0.336207721344, "check": 1.87281049562, "putindata": 7.369978720910001, "they": 0.0297269947676, "avoid": 0.900108441291, "step": 1.03954505698, "error": 1.7985854343, "stick": 2.4456277954099996, "his": 0.0901772433641, "librari": 0.986809980943, "maxword": 7.369978720910001, "randomord": 7.369978720910001, "fals": 1.8271477773099998, "thing": 0.8781935346799999, "presid": 0.6852420010529999, "machin": 1.39235958062, "again": 0.411340231612, "freq": 7.369978720910001, "relev": 1.9371304613999998, "bypass": 2.61897808671, "through": 0.0683586918849, "rts": 5.7022719003499995, "what": 0.225887296827, "techniqu": 1.31624384807, "russian": 1.4066564797499999, "palett": 4.40470565484, "putindf": 7.369978720910001, "trump": 4.12738636942, "line": 0.349430614452, "prime": 1.25232214856, "amitabh": 6.3767269479, "least": 0.480285584745, "base": 0.13652330228700002, "relat": 0.21310030165399999, "rotper": 7.369978720910001, "who": 0.0609002329859, "between": 0.033953681165299995, "bigger": 2.58248697813, "post": 0.8057001527009999, "here": 0.8850381883700001, "lower": 0.742201929994, "littl": 0.438213989466, "punctuat": 3.7403186264499997, "maximum": 1.5687671009200002, "clean": 1.9271282036300001, "paramet": 2.8481901438599997, "apart": 1.1324356512, "modidata": 7.369978720910001, "encod": 3.36811501148, "about": 0.0628434774746, "articl": 0.702131739574, "fffd": 7.369978720910001, "pichai": 7.369978720910001, "tweet": 4.5309002574, "she": 0.7701082216959999, "frequenc": 2.1759113757299997, "upon": 0.47207177798199995, "them": 0.0941833269093, "defin": 1.00368010925, "size": 0.9138372060609999, "vladimir": 2.80667273902, "emot": 1.79478748063, "place": 0.0957070839572, "save": 1.03598886547, "narendra": 5.46787119451, "let": 1.2488025672799998, "tool": 1.60887117963, "start": 0.236443369291, "orderedcolorstru": 7.369978720910001, "run": 0.442714975539, "guid": 0.912738218589, "load": 1.91765354188, "whi": 1.18068843047, "singl": 0.475916769059, "guess": 3.22051485947, "indian": 1.25408659543, "koh": 5.31585498721, "coursera": 7.369978720910001, "the": 0.0, "build": 0.491137452091, "analysi": 1.2466091029200002, "display": 1.07655944206, "order": 0.22014038079300002, "blankspac": 7.369978720910001, "there": 0.0400978929255, "connect": 0.633605058682, "inform": 0.454453704662, "unwant": 3.63708238138, "say": 0.562154280552, "best": 0.459227932947, "exampl": 0.40868267499899996, "right": 0.34035985417, "appear": 0.278735898493, "take": 0.130691962197, "visual": 1.6539383488600001, "follow": 0.045356911094199995, "now": 0.149092945021, "checkhandl": 7.369978720910001, "name": 0.09723316638430002, "code": 1.35601909597, "hint": 2.72174904546, "than": 0.0322608622182, "play": 0.38110439064199997, "realli": 1.5576408397, "goe": 1.4473284897999998, "indic": 0.7336385419149999, "note": 0.353817568083, "cloud": 2.36268232808, "specifi": 1.93451151621, "coupl": 1.18089357972, "person": 0.34018281601800004, "mani": 0.0433157581221, "around": 0.19387710578200001, "mean": 0.37092128352, "symbol": 1.22901716266, "task": 1.35748680661, "accomplish": 1.64345675928, "may": 0.050709995284400004, "minfreq": 7.369978720910001, "want": 0.6916366062549999, "convert": 1.1860360368, "into": 0.0149128632287, "screennam": 7.369978720910001, "individu": 0.588013447985, "strang": 2.3175618928, "although": 0.139487981418, "bio": 3.7456377879300002, "trumpdata": 7.369978720910001, "minut": 1.1353719359799999, "which": 0.00517841384543, "databas": 2.10988256718, "saw": 0.667036036556, "skill": 1.30805571015, "term": 0.33303898354600003, "other": 0.00987474791976, "three": 0.06411868822490001, "one": 0.0062553516455, "brewerp": 7.369978720910001, "prefer": 1.10581884366, "begin": 0.285584668268, "see": 0.240921585492, "becaus": 0.139343158825, "corpus": 3.1818402794, "get": 0.579769005782, "random": 1.9727214065099998, "manag": 0.497643387158, "stopword": 7.369978720910001, "detect": 1.68878274493, "part": 0.04239531098280001, "both": 0.050842533389300004, "import": 0.292818277066, "includ": 0.0188846813905, "cool": 1.9253988473800001, "strwidth": 7.369978720910001, "next": 0.402163685499, "below": 0.813626591936, "this": 0.0037864490525, "rang": 0.579319213803, "proport": 1.66154043472, "time": 0.0112115188626, "process": 0.527829199025, "chang": 0.166275625058, "bit": 2.12032652634, "covert": 3.2640350228400004, "most": 0.020747896295599998, "rstudio": 7.369978720910001, "return": 0.333126868592, "modidf": 7.369978720910001, "fail": 0.656536611573, "all": 0.011402632097799998, "syntax": 3.8203613341300007, "input": 2.50167533539, "action": 0.598043165069, "greed": 3.9359915164199997, "recent": 0.434413741288, "have": 0.0147850023412, "degre": 0.910387304568, "case": 0.395406268889, "that": 0.00397614837964, "viz": 4.75258288807, "call": 0.0654627744488, "rate": 0.761033872166, "more": 0.017024931599999998, "and": 6.29901420636e-05, "access": 0.627805882716, "list": 0.309845761506, "these": 0.0715336194008, "prepar": 0.8879422790620001, "keyword": 4.93636536551, "befor": 0.0956377718795, "comment": 1.11826753454, "close": 0.250666759864, "can": 0.162341096394, "avail": 0.547454586289, "make": 0.07349765782289999, "way": 0.19809150993500002, "onli": 0.025324268329099998, "each": 0.173741689304, "andrew": 1.34145926585, "few": 0.275577913653, "necessari": 1.0445450673999999, "skip": 3.26238893194, "read": 0.83939268088, "packag": 2.0577584491900005, "link": 0.7661704068449999, "data": 1.2168205848, "shape": 1.16420957115, "sinc": 0.0803681994577, "virat": 7.2746685411000005, "jalan": 6.4945099835599995, "must": 0.653383947388, "might": 0.7683410765340001, "text": 1.14048200999, "leader": 0.741672829452, "putin": 4.5485998345, "has": 0.0427239448548, "busi": 0.720476170355, "enough": 0.802884439169, "fig": 3.9992405467300003, "properti": 0.953573289192, "userlayout": 7.369978720910001, "user": 2.04258810688, "learn": 0.842752064745, "when": 0.0205549888584, "retweet": 7.369978720910001, "visualis": 5.19522699942}, "freq": {"after": 3, "real": 2, "nonrandom": 1, "sundar": 1, "limit": 4, "donald": 1, "onc": 3, "too": 1, "analyst": 1, "plot": 5, "differ": 1, "assign": 2, "addit": 3, "datafram": 4, "number": 6, "decreas": 1, "specif": 1, "function": 1, "python": 1, "trumpdf": 2, "product": 3, "done": 1, "creation": 2, "know": 1, "collis": 1, "irrelev": 1, "collect": 5, "scale": 1, "particular": 2, "creat": 12, "their": 1, "hashtag": 1, "vector": 1, "how": 2, "present": 1, "immigr": 1, "authent": 1, "surviv": 1, "minist": 2, "end": 1, "frame": 1, "alway": 1, "word": 41, "interest": 1, "deep": 1, "color": 15, "will": 8, "associ": 2, "rotat": 1, "otherwis": 1, "new": 1, "lag": 1, "similar": 1, "need": 5, "our": 1, "final": 1, "junk": 1, "charact": 4, "success": 1, "fun": 2, "replac": 1, "also": 4, "today": 1, "pass": 1, "use": 14, "establish": 1, "bacchan": 1, "treat": 1, "sure": 1, "cours": 1, "count": 1, "everyth": 1, "tri": 2, "not": 3, "like": 3, "rcolorbrew": 1, "length": 1, "are": 10, "deserv": 1, "etc": 2, "less": 1, "experienc": 1, "wordcloud": 2, "quick": 1, "easi": 1, "tweak": 2, "userdata": 2, "handl": 11, "english": 1, "then": 4, "usernam": 3, "graphic": 2, "anoth": 1, "instal": 1, "consult": 1, "choos": 3, "world": 1, "minimum": 1, "chosen": 1, "github": 1, "strheight": 1, "feed": 1, "randomcolor": 6, "influenc": 1, "meaning": 1, "mine": 1, "twitter": 17, "poetic": 1, "valu": 2, "kritika": 2, "got": 1, "develop": 1, "bang": 1, "such": 2, "agre": 1, "whose": 1, "amp": 1, "lot": 2, "some": 2, "sourc": 1, "drop": 1, "add": 1, "result": 1, "subset": 1, "repositori": 1, "india": 1, "twitterr": 1, "well": 1, "introduc": 1, "set": 2, "wait": 2, "ani": 2, "credenti": 1, "from": 14, "account": 9, "privat": 4, "work": 2, "num": 16, "partial": 1, "safe": 1, "for": 16, "sentiment": 2, "american": 2, "orderedcolor": 1, "colorcod": 1, "with": 6, "assum": 1, "determin": 1, "true": 1, "explan": 1, "frequent": 4, "sens": 1, "preprocess": 6, "look": 1, "mustknow": 1, "combin": 2, "extract": 2, "think": 1, "timelin": 2, "negat": 1, "public": 2, "posit": 2, "stuff": 1, "column": 1, "tab": 1, "medium": 1, "remov": 16, "even": 1, "modi": 8, "give": 2, "reach": 1, "ban": 1, "help": 1, "check": 3, "putindata": 1, "they": 2, "avoid": 1, "step": 3, "error": 1, "stick": 1, "his": 1, "librari": 1, "maxword": 5, "randomord": 5, "fals": 3, "thing": 1, "presid": 4, "machin": 2, "again": 1, "freq": 1, "relev": 1, "bypass": 1, "through": 1, "rts": 1, "what": 5, "techniqu": 2, "russian": 1, "palett": 1, "putindf": 1, "trump": 9, "line": 4, "prime": 2, "amitabh": 1, "least": 2, "base": 5, "relat": 1, "rotper": 1, "who": 1, "between": 1, "bigger": 1, "post": 1, "here": 5, "lower": 1, "littl": 1, "punctuat": 1, "maximum": 2, "clean": 1, "paramet": 2, "apart": 1, "modidata": 1, "encod": 1, "about": 5, "articl": 1, "fffd": 1, "pichai": 1, "tweet": 41, "she": 1, "frequenc": 7, "upon": 1, "them": 5, "defin": 3, "size": 3, "vladimir": 1, "emot": 1, "place": 2, "save": 1, "narendra": 1, "let": 9, "tool": 2, "start": 1, "orderedcolorstru": 1, "run": 1, "guid": 1, "load": 1, "whi": 1, "singl": 1, "guess": 1, "indian": 1, "koh": 1, "coursera": 1, "the": 56, "build": 1, "analysi": 2, "display": 2, "order": 5, "blankspac": 2, "there": 2, "connect": 2, "inform": 3, "unwant": 1, "say": 1, "best": 1, "exampl": 3, "right": 1, "appear": 3, "take": 1, "visual": 1, "follow": 4, "now": 6, "checkhandl": 1, "name": 1, "code": 7, "hint": 1, "than": 2, "play": 1, "realli": 1, "goe": 2, "indic": 2, "note": 3, "cloud": 24, "specifi": 1, "coupl": 1, "person": 1, "mani": 2, "around": 2, "mean": 1, "symbol": 2, "task": 1, "accomplish": 1, "may": 1, "minfreq": 2, "want": 2, "convert": 3, "into": 1, "screennam": 1, "individu": 1, "strang": 1, "although": 1, "bio": 1, "trumpdata": 1, "minut": 2, "which": 3, "databas": 1, "saw": 1, "skill": 1, "term": 1, "other": 2, "three": 1, "one": 6, "brewerp": 1, "prefer": 1, "begin": 2, "see": 2, "becaus": 1, "corpus": 4, "get": 14, "random": 2, "manag": 1, "stopword": 2, "detect": 1, "part": 1, "both": 1, "import": 1, "includ": 1, "cool": 1, "strwidth": 1, "next": 1, "below": 2, "this": 8, "rang": 1, "proport": 1, "time": 3, "process": 2, "chang": 1, "bit": 1, "covert": 1, "most": 7, "rstudio": 1, "return": 1, "modidf": 1, "fail": 1, "all": 7, "syntax": 1, "input": 1, "action": 1, "greed": 1, "recent": 3, "have": 12, "degre": 1, "case": 2, "that": 12, "viz": 2, "call": 2, "rate": 1, "more": 3, "and": 30, "access": 2, "list": 2, "these": 9, "prepar": 1, "keyword": 1, "befor": 1, "comment": 1, "close": 1, "can": 9, "avail": 1, "make": 6, "way": 1, "onli": 2, "each": 4, "andrew": 3, "few": 1, "necessari": 2, "skip": 1, "read": 1, "packag": 1, "link": 1, "data": 10, "shape": 1, "sinc": 1, "virat": 1, "jalan": 2, "must": 1, "might": 1, "text": 17, "leader": 1, "putin": 6, "has": 1, "busi": 1, "enough": 1, "fig": 4, "properti": 1, "userlayout": 1, "user": 5, "learn": 2, "when": 2, "retweet": 1, "visualis": 2}, "idf": {"after": 1.02070207021, "real": 2.28103448276, "nonrandom": 1587.6, "sundar": 1443.27272727, "limit": 1.5186531471200002, "donald": 7.0970049173000005, "onc": 1.4974533106999999, "too": 1.81585268215, "analyst": 14.8373831776, "plot": 5.383519837230001, "differ": 1.23654490225, "assign": 3.83663605607, "addit": 1.24634950542, "datafram": 1587.6, "number": 1.10142916609, "decreas": 4.5230769230800005, "specif": 1.8719490626099997, "function": 2.495441685, "python": 56.2978723404, "trumpdf": 1587.6, "product": 1.62264922322, "done": 2.3302509907499998, "creation": 3.0601387818, "know": 2.59327017315, "collis": 18.3325635104, "irrelev": 29.7861163227, "collect": 1.64109985528, "scale": 3.7469907953699995, "particular": 1.3814827706200001, "creat": 1.2492917847, "their": 1.01547908405, "hashtag": 496.125, "vector": 25.898858075, "how": 1.60250328051, "present": 1.25551601423, "immigr": 5.32751677852, "authent": 11.504347826099998, "surviv": 2.2576791808900003, "minist": 3.1032056294, "end": 1.10680423871, "frame": 6.280063291139999, "alway": 2.06745670009, "word": 1.7965372864099998, "interest": 1.60331246213, "deep": 3.6279707495399998, "color": 3.8255421686699997, "will": 1.22481098596, "associ": 1.3263157894700002, "rotat": 8.53548387097, "otherwis": 3.72151898734, "new": 1.0178880554, "lag": 33.3529411765, "similar": 1.37514075357, "need": 1.4372623574099999, "our": 2.35758835759, "final": 1.34008609775, "junk": 69.327510917, "charact": 2.51720310766, "success": 1.32002993265, "fun": 12.8863636364, "replac": 1.5602948402899999, "also": 1.01476510067, "today": 1.74961428257, "pass": 1.61818367139, "use": 1.0296387573799999, "establish": 1.34622233528, "bacchan": 1587.6, "treat": 3.59023066486, "sure": 7.453521126760001, "cours": 2.15092805853, "count": 3.48157894737, "everyth": 4.81967213115, "tri": 1.8544562551099997, "not": 1.01567398119, "like": 1.14918566775, "rcolorbrew": 1587.6, "length": 3.69123459661, "are": 1.02990593578, "deserv": 15.236084453, "etc": 4.2066772655, "less": 1.46904783936, "experienc": 3.5564516129, "wordcloud": 1587.6, "quick": 2.205, "easi": 5.2937645882, "tweak": 113.4, "userdata": 1587.6, "handl": 3.9229058561900003, "english": 1.7432744043000001, "then": 1.08657860516, "usernam": 407.07692307699995, "graphic": 9.035856573710001, "anoth": 1.13643521832, "instal": 3.78721374046, "consult": 5.21721984883, "choos": 4.17899447223, "world": 1.11340206186, "minimum": 6.02962400304, "chosen": 3.59266802444, "github": 1587.6, "strheight": 1587.6, "feed": 7.77853993141, "randomcolor": 1587.6, "influenc": 1.77246846042, "meaning": 21.8076923077, "mine": 4.875921375919999, "twitter": 33.213389121300004, "poetic": 20.0707964602, "valu": 2.2777618364400003, "kritika": 1587.6, "got": 3.61969904241, "develop": 1.1955719557200002, "bang": 24.728971962600003, "such": 1.06151377374, "agre": 2.22946215419, "whose": 1.73508196721, "amp": 72.8256880734, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "drop": 2.4594887684, "add": 4.61243463103, "result": 1.14611608432, "subset": 27.3253012048, "repositori": 44.974504249300004, "india": 3.92387543253, "twitterr": 1587.6, "well": 1.0655748708, "introduc": 1.7258397651900002, "set": 1.18707940781, "wait": 4.55421686747, "ani": 1.13383802314, "credenti": 39.5910224439, "from": 1.00056721497, "account": 1.94463498285, "privat": 2.02396736359, "work": 1.11520089913, "num": 1.00031504001, "partial": 3.6131087847099996, "safe": 5.02723242559, "for": 1.00031504001, "sentiment": 9.9225, "american": 1.31641791045, "orderedcolor": 1587.6, "colorcod": 1587.6, "with": 1.0011982089899998, "assum": 2.9575260804799997, "determin": 2.1658935879900003, "true": 2.55569864778, "explan": 6.50922509225, "frequent": 2.10501193317, "sens": 2.8365195640499996, "preprocess": 1221.23076923, "look": 1.9086318826599997, "mustknow": 1587.6, "combin": 1.69760479042, "extract": 7.703056768560001, "think": 2.90715986083, "timelin": 10.911340206199998, "negat": 3.75852272727, "public": 1.22424429365, "posit": 1.37252528746, "stuff": 23.3127753304, "column": 7.078020508250001, "tab": 54.1843003413, "medium": 7.00617828773, "remov": 2.0058117498400003, "even": 1.16461267606, "modi": 220.5, "give": 1.3653250774, "reach": 1.49801849406, "ban": 4.32, "help": 1.39962972759, "check": 6.50655737705, "putindata": 1587.6, "they": 1.03017325287, "avoid": 2.45986984816, "step": 2.8279301745599996, "error": 6.04109589041, "stick": 11.5377906977, "his": 1.0943682360200002, "librari": 2.68266306185, "maxword": 1587.6, "randomord": 1587.6, "fals": 6.21613155834, "thing": 2.4065484311099996, "presid": 1.9842519685, "machin": 4.02433460076, "again": 1.50883862384, "freq": 1587.6, "relev": 6.938811188810001, "bypass": 13.7216940363, "through": 1.07074930869, "rts": 299.547169811, "what": 1.25343439128, "techniqu": 3.7293868921800004, "russian": 4.08228336333, "palett": 81.83505154640001, "putindf": 1587.6, "trump": 62.015625, "line": 1.4182597820299998, "prime": 3.49845747025, "amitabh": 588.0, "least": 1.6165359943000002, "base": 1.14628158845, "relat": 1.23750876919, "rotper": 1587.6, "who": 1.06279287723, "between": 1.03453668708, "bigger": 13.23, "post": 2.23826307627, "here": 2.42307692308, "lower": 2.10055570257, "littl": 1.5499365420299998, "punctuat": 42.1114058355, "maximum": 4.80072573329, "clean": 6.86975335353, "paramet": 17.256521739100002, "apart": 3.1032056294, "modidata": 1587.6, "encod": 29.0237659963, "about": 1.06486015159, "articl": 2.01805008262, "fffd": 1587.6, "pichai": 1587.6, "tweet": 92.8421052632, "she": 2.16, "frequenc": 8.8102108768, "upon": 1.60331246213, "them": 1.09876115994, "defin": 2.72830383227, "size": 2.49387370405, "vladimir": 16.5547445255, "emot": 6.01819560273, "place": 1.1004366812200002, "save": 2.8178913737999998, "narendra": 236.955223881, "let": 3.48616600791, "tool": 4.99716713881, "start": 1.26673581744, "orderedcolorstru": 1587.6, "run": 1.55692850838, "guid": 2.49113447356, "load": 6.80497213888, "whi": 3.2566153846200003, "singl": 1.60948905109, "guess": 25.0410094637, "indian": 3.5046357615900003, "koh": 203.53846153799998, "coursera": 1587.6, "the": 1.0, "build": 1.6341739578, "analysi": 3.47852760736, "display": 2.93456561922, "order": 1.24625166811, "blankspac": 1587.6, "there": 1.04091266719, "connect": 1.8843916913900003, "inform": 1.5753125620200001, "unwant": 37.980861244, "say": 1.7544480053, "best": 1.5828514456600002, "exampl": 1.50483412322, "right": 1.4054532577899999, "appear": 1.3214582986499999, "take": 1.13961668222, "visual": 5.22752716497, "follow": 1.04640126549, "now": 1.160780873, "checkhandl": 1587.6, "name": 1.10211732037, "code": 3.8807137619199996, "hint": 15.2068965517, "than": 1.03278688525, "play": 1.46390041494, "realli": 4.7476076555, "goe": 4.251740760580001, "indic": 2.0826446281, "note": 1.42449528937, "cloud": 10.6193979933, "specifi": 6.920662598080001, "coupl": 3.2572835453400004, "person": 1.40520446097, "mani": 1.04426757877, "around": 1.21394708671, "mean": 1.44906900329, "symbol": 3.4178686760000003, "task": 3.88641370869, "accomplish": 5.17302052786, "may": 1.05201775893, "minfreq": 1587.6, "want": 1.99698113208, "convert": 3.2740771293099997, "into": 1.01502461479, "screennam": 1587.6, "individu": 1.8004082558400003, "strang": 10.150895140700001, "although": 1.14968498805, "bio": 42.336000000000006, "trumpdata": 1587.6, "minut": 3.11233091551, "which": 1.005191845, "databas": 8.24727272727, "saw": 1.94845360825, "skill": 3.6989748369099997, "term": 1.39520168732, "other": 1.00992366412, "three": 1.06621893889, "one": 1.00627495722, "brewerp": 1587.6, "prefer": 3.0216977540900003, "begin": 1.3305397251100002, "see": 1.27242125511, "becaus": 1.1495184997499999, "corpus": 24.091047041, "get": 1.78562591385, "random": 7.1902173913, "manag": 1.6448404475799998, "stopword": 1587.6, "detect": 5.41288782816, "part": 1.04330682789, "both": 1.05215720061, "import": 1.3401992233700002, "includ": 1.0190641247799999, "cool": 6.8578833693300005, "strwidth": 1587.6, "next": 1.4950560316400001, "below": 2.25607503197, "this": 1.00379362671, "rang": 1.7848229342299997, "proport": 5.26741871267, "time": 1.01127460348, "process": 1.69524826482, "chang": 1.1808985421, "bit": 8.33385826772, "covert": 26.154859967100002, "most": 1.02096463023, "rstudio": 1587.6, "return": 1.39532431007, "modidf": 1587.6, "fail": 1.9281029876099998, "all": 1.01146788991, "syntax": 45.6206896552, "input": 12.2029208301, "action": 1.81855670103, "greed": 51.2129032258, "recent": 1.54405757635, "have": 1.0148948411399998, "degre": 2.4852849092, "case": 1.48498737256, "that": 1.00398406375, "viz": 115.883211679, "call": 1.0676529926, "rate": 2.14048806795, "more": 1.0171706817, "and": 1.00006299213, "access": 1.8734953976900002, "list": 1.36321483771, "these": 1.07415426252, "prepar": 2.43012398592, "keyword": 139.263157895, "befor": 1.10036041031, "comment": 3.05954904606, "close": 1.2848818387799998, "can": 1.17626139142, "avail": 1.7288467821, "make": 1.0762660158600001, "way": 1.2190739461, "onli": 1.0256476516600002, "each": 1.18974820144, "andrew": 3.82462057336, "few": 1.31729173581, "necessari": 2.8421052631599997, "skip": 26.111842105300003, "read": 2.3149606299200003, "packag": 7.828402366860001, "link": 2.15151104486, "data": 3.37643555934, "shape": 3.20338983051, "sinc": 1.08368600683, "virat": 1443.27272727, "jalan": 661.5, "must": 1.9220338983099996, "might": 2.1561863370900003, "text": 3.12827586207, "leader": 2.0994445913799997, "putin": 94.5, "has": 1.0436497502, "busi": 2.05541170378, "enough": 2.2319696330700003, "fig": 54.5567010309, "properti": 2.5949656750599996, "userlayout": 1587.6, "user": 7.71053909665, "learn": 2.32275054865, "when": 1.02076769755, "retweet": 1587.6, "visualis": 180.409090909}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Find Out What Celebrities Tweet About the Most</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/what-celebrities-tweet-about-most.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Find Out What Celebrities Tweet About the Most Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/guide-time-series-prediction-recurrent-neural-networks-lstms.html\" rel=\"prev\" title=\"A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs)\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/data-science-systems-engineering-approach.html\" rel=\"next\" title=\"Data Science \u2013The need for a Systems Engineering approach\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/10/what-celebrities-tweet-about-most.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=72485\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/what-celebrities-tweet-about-most.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-72485 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 5-Oct, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/index.html\">Oct</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/opinions-interviews.html\">Opinions, Interviews</a> \u00bb Find Out What Celebrities Tweet About the Most (\u00a0<a href=\"/2017/n39.html\">17:n39</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Find Out What Celebrities Tweet About the Most</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/10/guide-time-series-prediction-recurrent-neural-networks-lstms.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/10/data-science-systems-engineering-approach.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/andrew-ng\" rel=\"tag\">Andrew Ng</a>, <a href=\"https://www.kdnuggets.com/tag/data-visualization\" rel=\"tag\">Data Visualization</a>, <a href=\"https://www.kdnuggets.com/tag/donald-trump\" rel=\"tag\">Donald Trump</a>, <a href=\"https://www.kdnuggets.com/tag/r\" rel=\"tag\">R</a>, <a href=\"https://www.kdnuggets.com/tag/twitter\" rel=\"tag\">Twitter</a>, <a href=\"https://www.kdnuggets.com/tag/word-cloud\" rel=\"tag\">Word Cloud</a></div>\n<br/>\n<p class=\"excerpt\">\n     Word cloud is a popular data visualisation method. Here we show how to use R to create twitter word cloud of celebrities and politicians.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/kritika-jalan\" rel=\"author\" title=\"Posts by Kritika Jalan\">Kritika Jalan</a>, India.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"#comments\">comments</a></div>\n<p><strong>WordCloud using less than 40 lines of R\u00a0Code</strong></p>\n<p>Guess whose twitter handle gives this word cloud? Enough hints present in there. You are right, that is Andrew Ng tweeting about his new Deep Learning course on Coursera! It\u2019s always fun to see data in action; isn\u2019t it? Let\u2019s try and create a similar word cloud for three world leaders, viz. American President Donald Trump, Indian Prime Minister Narendra Modi, and Russian President Vladimir Putin.<br>\n<img alt=\"\" class=\"aligncenter size-full wp-image-72491\" height=\"385\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-andrew-ng-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-andrew-ng-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-andrew-ng-tweets-300x289.jpg 300w\" width=\"400\"/></br></p>\n<p style=\"text-align: center;\"><strong>Fig. 1: R Word Cloud from Andrew Ng\u2019s Tweets</strong></p>\n<p><em>A word cloud is a data visualisation technique in which the size of each word indicates its frequency or importance in the associated text (i.e., the more times a word appears in the corpus, the bigger the word)</em></p>\n<p>Since you are interested in creating a word cloud from twitter handles using R, I will safely assume you have both, a Twitter account to your name, and RStudio installed on your machine. If not, now is the time to do it.</p>\n<p>You must also have a Twitter Developer Account set up as a medium to extract the tweets. If you need help with it, here\u2019s a\u00a0<a href=\"https://medium.com/@Kritika_Jalan/quick-guide-to-extract-tweets-using-r-c5382d3e257a\" rel=\"noopener noreferrer\" target=\"_blank\">quick guide</a>.</p>\n<p>Let\u2019s get started. Following are the steps we will be taking to get this task done:</p>\n<ol>\n<li>Get Twitter data using handles (2 lines of code!)</li>\n<li>Prepare it for visualisation (Real fun part)</li>\n<li>And finally, create a word cloud (Single line of code!)</li>\n</ol>\n<p><strong>Extract Tweets</strong></p>\n<p>Let us load necessary libraries and establish a connection with Twitter</p>\n<pre>#Getting tweets from twitter\r\nlibrary(twitteR)\r\n#Twitter-R Authentication\r\nlibrary(ROAuth)\r\n#Text processing\r\nlibrary(stringr)\r\n#Text mining\r\nlibrary(tm)\r\n#Wordcloud creation\r\nlibrary(wordcloud)\r\n\r\n#Connect to twitter API using the saved credentials\r\nload(\"twitter authentication.Rdata\")\r\nsetup_twitter_oauth(credentials$consumerKey, credentials$consumerSecret, \r\ncredentials$oauthKey, credentials$oauthSecret)\r\n\r\n</pre>\n<p>Let\u2019s go collect some data now. A couple things to note here \u2013</p>\n<ol>\n<li>One can only get access to data from users who \u2018<em>follow\u2019</em>the Twitter account associated with the API. Or, from the accounts that are public (vs. private)</li>\n<li>Twitter\u00a0<a href=\"https://dev.twitter.com/rest/reference/get/statuses/user_timeline\" rel=\"noopener noreferrer\" target=\"_blank\">API limits</a>the number of tweets a user can get from a particular timeline to be 3200, including RTs even if it is set to FALSE. There are, although, a\u00a0<a href=\"https://www.quora.com/Is-there-a-way-to-get-more-than-3200-tweets-from-a-Twitter-user-using-Twitters-API-or-scraping\" rel=\"noopener noreferrer\" target=\"_blank\">few tools</a>\u00a0available that lets you bypass this limit. We will stick to the limits in this post</li>\n<li>Twitter API also has a\u00a0<a href=\"https://dev.twitter.com/rest/public/rate-limits\" rel=\"noopener noreferrer\" target=\"_blank\">rate limit</a>on how many tweets can be collected at once. If you try to collect too many of them at once, it may fail or return partial results. The best way to work around this is by introducing lag between API calls so that you don\u2019t have to be around when the code runs</li>\n</ol>\n<p>Get twitter handles of the personalities you want to look up. Make sure these are real twitter accounts or you\u2019ll get an error.</p>\n<pre>screenName &lt;- c(\u2018realDonaldTrump\u2019, \u2018PutinRF_Eng\u2019, \u2018narendramodi\u2019)\r\n\r\nCollect information about these handles using twitteR.\r\ncheckHandles &lt;- lookupUsers(screenName)\r\n</pre>\n<p>Get user data for each of the handles and create a data frame for easy access.<br>\nCheck for number of tweets and private accounts using this. Remove private accounts, if any.</br></p>\n<pre>UserData &lt;- lapply(checkHandles, function(x) getUser(x))\r\nUserData &lt;- twListToDF(UserData)\r\ntable(UserData$name, UserData$statusesCount)\r\n\r\n#Check tweet count\r\ntable(UserData$name, UserData$protected)\r\n\r\n#Check Private Accounts\r\nusernames &lt;- subset(UserData, protected == FALSE)\r\n\r\n#Public Accounts\r\nusernames &lt;- as.list(usernames$screenName)\r\n</pre>\n<p>Next we get the list of tweets from the user timelines, covert them to a dataframe and wait for 5 minutes before making another API call. Combine all the dataframes into one to pre-process the tweets. Note, we will only be getting 3200 most recent tweets for these handles. Trump and Modi have tweeted a lot more than that.</p>\n<pre>x &lt;- userTimeline(\u2018realDonaldTrump\u2019,n=3200,includeRts = FALSE)\r\n\r\n#Convert tweets list to dataframe\r\nTrumpData &lt;- twListToDF(x)\r\n\r\n#Wait 5 minutes\r\nSys.sleep(300)\r\n\r\nx &lt;- userTimeline(\u2018PutinRF_Eng\u2019,n=3200,includeRts = FALSE)\r\nPutinData &lt;- twListToDF(x)\r\nSys.sleep(300)\r\n\r\nx &lt;- userTimeline(\u2018narendramodi\u2019,n=3200,includeRts = TRUE)\r\nModiData &lt;- twListToDF(x)\r\n\r\nTrump.df &lt;- data.frame(TrumpData)\r\nPutin.df &lt;- data.frame(PutinData)\r\nModi.df &lt;- data.frame(ModiData)\r\n\r\n#Now create a dataframe that combines all of the collected tweets\r\ntweets &lt;- data.frame()\r\ntweets &lt;- Trump.df\r\ntweets &lt;- rbind(tweets,Putin.df)\r\ntweets &lt;- rbind(tweets,Modi.df)\r\n</pre>\n<p><strong>Pre-Process Tweets</strong></p>\n<p>Now that we have all the relevant tweets in one place, it is time to pre-process them. What I mean here is, let\u2019s remove unwanted characters, symbols and words. You do not want graphic characters, articles, symbols, and numbers to appear in the word cloud. You can skip any of these pre-processing steps based on your need.</p>\n<pre>#Convert tweets to ASCII to avoid reading strange characters\r\niconv(tweets$text, from=\u201dUTF-8\", to=\u201dASCII\u201d, sub=\u201d\u201d)\r\n\r\n#Clean text by removing graphic characters\u00a0\u00a0\r\ntweets$text=str_replace_all(tweets$text,\"[^[:graph:]]\", \" \")\r\n\r\n#Remove Junk Values and replacement words like fffd which appear \r\nbecause of encoding differences\r\ntweets$text &lt;- gsub(\"[^[:alnum:]///' ]\", \"\", tweets$text)\r\n\r\n#Convert all text to lower case\r\ntweets$text &lt;- tolower(tweets$text)\r\n\r\n#Remove retweet keyword\r\ntweets$text &lt;- gsub(\"rt\", \"\", tweets$text)\r\n\r\n#Remove Punctuations\r\ntweets$text &lt;- gsub(\"[[:punct:]]\", \"\", tweets$text)\r\n\r\n#Remove links\r\ntweets$text &lt;- gsub(\"http\\\\w+\", \"\", tweets$text)\r\n\r\n#Remove tabs\r\ntweets$text &lt;- gsub(\"[ |\\t]{2,}\", \"\", tweets$text)\r\n\r\n#Remove blankspaces at begining\r\ntweets$text &lt;- gsub(\"^ \", \"\", tweets$text)\r\n\r\n#Remove blankspaces at the end\r\ntweets$text &lt;- gsub(\" $\", \"\", tweets$text)\r\n\r\n#Remove usernames\r\ntweets$text &lt;- gsub(\"@\\\\w+\", \"\", tweets$text)\r\n</pre>\n<p>Once we have pre-processed tweets, let us now create a corpus for each handle and remove stopwords like \u2018my\u2019, \u2018do\u2019, \u2018today\u2019 etc.</p>\n<pre>#After preprocessing the data, subset for tweets for each handle\r\nTrump &lt;- subset(tweets, screenName==\u201crealDonaldTrump\u201d, select= text)\r\nPutin &lt;- subset(tweets, screenName== \u201cPutinRF_Eng\u201d, select= text)\r\nModi &lt;- subset(tweets, screenName== \u201cnarendramodi\u201d, select= text)\r\n\r\n#Create corpus of individual twitter handles\r\nTrump &lt;- Corpus(VectorSource(Trump))\r\nPutin &lt;- Corpus(VectorSource(Putin))\r\nModi &lt;- Corpus(VectorSource(Modi))\r\n\r\n#Remove English Stopwords from the tweets\r\nTrump &lt;- tm_map(Trump, removeWords, stopwords(\u201cen\u201d))\r\nPutin &lt;- tm_map(Putin, removeWords, stopwords(\u201cen\u201d))\r\nModi &lt;- tm_map(Modi, removeWords, stopwords(\u201cen\u201d))\r\n</pre>\n<p><strong>Create Word Cloud</strong></p>\n<p>If you survived through all these steps to reach here, you deserve a poetic treat! Here goes..</p>\n<p>Now that we have everything we need,<br>\nLet\u2019s feed upon our greed<br>\nMake a cloud of what they tweet,<br/>\nLike in the beginning we\u00a0agreed</br></br></p>\n<p>A function\u00a0wordcloud()\u00a0lets you define parameters for word cloud creation viz. input corpus, minimum frequency of the words to be displayed, size and shape of the cloud, color and order of the words, maximum words displayed, etc. Tweak these and have a little play.</p>\n<pre>wordcloud(Trump,min.freq = 3, scale=c(6,0.5),colors=brewer.pal(8, \u201cDark2\u201d),\r\nrandom.color= FALSE, random.order = FALSE, max.words = 110)\r\n\r\nwordcloud(Putin,min.freq = 4, scale=c(7,0.8),colors=brewer.pal(8, \u201cDark2\u201d),\r\nrandom.color= FALSE, random.order = FALSE, max.words = 100)\r\n\r\nwordcloud(Modi,min.freq = 3, scale=c(6,0.5),colors=brewer.pal(8, \u201cDark2\u201d),\r\nrandom.color= FALSE, random.order = FALSE, max.words = 110)\r\n\r\nSyntax and Explanation (<a href=\"https://cran.r-project.org/web/packages/wordcloud/wordcloud.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">source</a>):\r\nwordcloud(words,freq, min.freq,scale, max.words, random.order, \r\nrandom.color, rot.per,colors, ordered.colors, use.r.layout...)\r\n</pre>\n<p>words: Words to be plotted in the cloud<br/>\nfreq: Frequency of these words in the text<br/>\nmin.freq: Words with frequency below min.freq will not be plotted<br/>\nscale: A vector of length 2 indicating the range of the size of the words<br/>\nmax.words: Maximum number of words to be plotted; least frequent terms dropped<br/>\nrandom.order: Plot words in random order. If false, they will be plotted in decreasing frequency<br/>\nrandom.color: Choose colors randomly from the colors. If false, the color is chosen based on the frequency<br/>\nrot.per: Proportion words with 90 degree rotation<br/>\ncolors: Color words from least to most frequent<br/>\nordered.colors: If true, then colors are assigned to words in order<br/>\nuse.r.layout: If false, then C++ code is used for collision detection, otherwise R is used<br/>\n\u2026: \u00a0Additional parameters to be passed to text (and strheight,strwidth).</p>\n<p>You can add more information to your word cloud based on the order and color you choose. You can specify non-random color assignment (random.color = FALSE) which will make it based on frequency then choose a value of colors using a palette (brewer.pal from <a href=\"http://www.cse.unsw.edu.au/~mike/myrlibrary.old/RColorBrewer/html/ColorBrewer.html\" rel=\"noopener noreferrer\" target=\"_blank\">RColorBrewer</a> package) that goes in the order you prefer.</p>\n<p>You can also have words color-coded based on their sentiments, say for example positive and negative emotions. This can be accomplished by having an additional column in the database that define this property and then using it to define color as follows \u2013<br/>\nwordcloud(df$words,df$freq, min.freq = 3, scale=c(6,0.5),random.color= FALSE, ordered.colors=TRUE,colors=brewer.pal(8, \u201cDark2\u201d)[factor(df$sentiment)],random.order = FALSE, max.words = 110)</p>\n<p>After you have created the cloud, you might see some of the words or numbers that are irrelevant and give no additional information. In such cases, you need to tweak your cloud a bit again. For Example, when I created these clouds, I saw the words \u2018amp\u2019 and \u2018will\u2019 as the most frequent words in Trump\u2019s and Modi\u2019s cloud. I used the following code lines and removed them. Below are the word clouds I got after making these changes.</p>\n<pre>#Remove numbers if necessary\r\n#Putin &lt;- tm_map(Putin, removeNumbers)\r\n\r\n#Remove specific words if needed\r\n#Trump &lt;- tm_map(Trump, removeWords, c(\u2018amp\u2019,\u2019will\u2019))\r\n#Modi &lt;- tm_map(Modi, removeWords, c(\u2018amp\u2019,\u2019will\u2019))\r\n</pre>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-72492\" height=\"343\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-putin-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-putin-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-putin-tweets-300x257.jpg 300w\" width=\"400\"/></p>\n<p style=\"text-align: center;\"><strong>Fig. 2: R Word Cloud from President Putin\u2019s Tweets</strong></p>\n<p style=\"text-align: center;\"><img alt=\"\" class=\"aligncenter size-full wp-image-72493\" height=\"343\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-trumph-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-trumph-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-trumph-tweets-300x257.jpg 300w\" width=\"400\"/></p>\n<p style=\"text-align: center;\"><strong>Fig. 3: R Word Cloud using President Trump\u2019s most recent Tweets</strong></p>\n<p style=\"text-align: center;\"><img alt=\"\" class=\"aligncenter size-full wp-image-72494\" height=\"343\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-pm-modi-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-pm-modi-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-pm-modi-tweets-300x257.jpg 300w\" width=\"400\"/></p>\n<p style=\"text-align: center;\"><strong>Fig. 4: R Word Cloud from Prime Minister Modi\u2019s most recent Tweets</strong></p>\n<p>I have also created a\u00a0<a href=\"https://github.com/Krithi07/Celebrity-Twitter-WordCloud\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub repository</a>\u00a0with all the codes in one place. That one creates word clouds for Amitabh Bacchan, Sundar Pichai, Virat Kohli, and Andrew Ng.</p>\n<p><strong>Closing Note</strong></p>\n<p>Apart from getting a sense of what is being tweeted about the most by a particular Twitter handle, we can use word clouds to do a lot of other cool stuff. One such example is sentiment analysis for a product. Use hashtag to get all the tweets about the product, process them to get meaningful words and build a cloud, bang! You know your product is doing well if the most frequent words are positive.</p>\n<p dir=\"ltr\"><strong>Bio: <a href=\"https://www.linkedin.com/in/kritikajalan/\">Kritika Jalan</a></strong> is an experienced business analyst working in management consulting. She is skilled in R, Python, SQL, and other data analysis tools and machine learning techniques. </p>\n<p dir=\"ltr\"><strong>Related:</strong></p>\n<ul>\n<li><a href=\"/2017/09/what-makes-data-visualization-successful.html\" rel=\"noopener noreferrer\" target=\"_blank\">What makes a data visualization successful?</a></li>\n<li><a href=\"/2017/05/must-know-determine-influence-twitter-user.html\" rel=\"noopener noreferrer\" target=\"_blank\">Must-Know: How to determine the influence of a Twitter user?</a></li>\n<li><a href=\"/2017/02/odintext-americans-think-about-trump-immigration-ban.html\" rel=\"noopener noreferrer\" target=\"_blank\">What Americans Really Think About Trump\u2019s Immigration Ban and Why</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/10/guide-time-series-prediction-recurrent-neural-networks-lstms.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/10/data-science-systems-engineering-approach.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/index.html\">Oct</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/opinions-interviews.html\">Opinions, Interviews</a> \u00bb Find Out What Celebrities Tweet About the Most (\u00a0<a href=\"/2017/n39.html\">17:n39</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556352095\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.757 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 04:01:35 -->\n<!-- Compression = gzip -->", "content_tokenized": ["kritika", "jalan", "india", "comment", "wordcloud", "use", "less", "than", "num", "line", "code", "guess", "whose", "twitter", "handl", "give", "this", "word", "cloud", "enough", "hint", "present", "there", "are", "right", "that", "andrew", "tweet", "about", "his", "new", "deep", "learn", "cours", "coursera", "alway", "fun", "see", "data", "action", "let", "tri", "and", "creat", "similar", "word", "cloud", "for", "three", "world", "leader", "viz", "american", "presid", "donald", "trump", "indian", "prime", "minist", "narendra", "modi", "and", "russian", "presid", "vladimir", "putin", "fig", "num", "word", "cloud", "from", "andrew", "tweet", "word", "cloud", "data", "visualis", "techniqu", "which", "the", "size", "each", "word", "indic", "frequenc", "import", "the", "associ", "text", "the", "more", "time", "word", "appear", "the", "corpus", "the", "bigger", "the", "word", "sinc", "are", "interest", "creat", "word", "cloud", "from", "twitter", "handl", "use", "will", "safe", "assum", "have", "both", "twitter", "account", "name", "and", "rstudio", "instal", "machin", "not", "now", "the", "time", "must", "also", "have", "twitter", "develop", "account", "set", "medium", "extract", "the", "tweet", "need", "help", "with", "here", "quick", "guid", "let", "get", "start", "follow", "are", "the", "step", "will", "take", "get", "this", "task", "done", "get", "twitter", "data", "use", "handl", "num", "line", "code", "prepar", "for", "visualis", "real", "fun", "part", "and", "final", "creat", "word", "cloud", "singl", "line", "code", "extract", "tweet", "let", "load", "necessari", "librari", "and", "establish", "connect", "with", "twitter", "get", "tweet", "from", "twitter", "twitterr", "authent", "text", "process", "text", "mine", "wordcloud", "creation", "connect", "twitter", "use", "the", "save", "credenti", "let", "collect", "some", "data", "now", "coupl", "thing", "note", "here", "one", "can", "onli", "get", "access", "data", "from", "user", "who", "follow", "the", "twitter", "account", "associ", "with", "the", "from", "the", "account", "that", "are", "public", "privat", "twitter", "limit", "the", "number", "tweet", "user", "can", "get", "from", "particular", "timelin", "num", "includ", "rts", "even", "set", "there", "are", "although", "few", "tool", "avail", "that", "let", "bypass", "this", "limit", "will", "stick", "the", "limit", "this", "post", "twitter", "also", "has", "rate", "limit", "how", "mani", "tweet", "can", "collect", "onc", "tri", "collect", "too", "mani", "them", "onc", "may", "fail", "return", "partial", "result", "the", "best", "way", "work", "around", "this", "introduc", "lag", "between", "call", "that", "have", "around", "when", "the", "code", "run", "get", "twitter", "handl", "the", "person", "want", "look", "make", "sure", "these", "are", "real", "twitter", "account", "get", "error", "screennam", "collect", "inform", "about", "these", "handl", "use", "twitter", "checkhandl", "get", "user", "data", "for", "each", "the", "handl", "and", "creat", "data", "frame", "for", "easi", "access", "check", "for", "number", "tweet", "and", "privat", "account", "use", "this", "remov", "privat", "account", "ani", "userdata", "userdata", "check", "tweet", "count", "check", "privat", "account", "usernam", "public", "account", "usernam", "next", "get", "the", "list", "tweet", "from", "the", "user", "timelin", "covert", "them", "datafram", "and", "wait", "for", "num", "minut", "befor", "make", "anoth", "call", "combin", "all", "the", "datafram", "into", "one", "preprocess", "the", "tweet", "note", "will", "onli", "get", "num", "most", "recent", "tweet", "for", "these", "handl", "trump", "and", "modi", "have", "tweet", "lot", "more", "than", "that", "convert", "tweet", "list", "datafram", "trumpdata", "wait", "num", "minut", "putindata", "modidata", "trumpdf", "putindf", "modidf", "now", "creat", "datafram", "that", "combin", "all", "the", "collect", "tweet", "tweet", "tweet", "trumpdf", "tweet", "tweet", "preprocess", "tweet", "now", "that", "have", "all", "the", "relev", "tweet", "one", "place", "time", "preprocess", "them", "what", "mean", "here", "let", "remov", "unwant", "charact", "symbol", "and", "word", "not", "want", "graphic", "charact", "articl", "symbol", "and", "number", "appear", "the", "word", "cloud", "can", "skip", "ani", "these", "preprocess", "step", "base", "need", "convert", "tweet", "avoid", "read", "strang", "charact", "clean", "text", "remov", "graphic", "charact", "tweet", "text", "remov", "junk", "valu", "and", "replac", "word", "like", "fffd", "which", "appear", "becaus", "encod", "differ", "tweet", "text", "convert", "all", "text", "lower", "case", "tweet", "text", "remov", "retweet", "keyword", "tweet", "text", "remov", "punctuat", "tweet", "text", "remov", "link", "tweet", "text", "remov", "tab", "tweet", "text", "remov", "blankspac", "begin", "tweet", "text", "remov", "blankspac", "the", "end", "tweet", "text", "remov", "usernam", "tweet", "text", "onc", "have", "preprocess", "tweet", "let", "now", "creat", "corpus", "for", "each", "handl", "and", "remov", "stopword", "like", "today", "etc", "after", "preprocess", "the", "data", "subset", "for", "tweet", "for", "each", "handl", "trump", "putin", "modi", "creat", "corpus", "individu", "twitter", "handl", "trump", "putin", "modi", "remov", "english", "stopword", "from", "the", "tweet", "trump", "putin", "modi", "creat", "word", "cloud", "surviv", "through", "all", "these", "step", "reach", "here", "deserv", "poetic", "treat", "here", "goe", "now", "that", "have", "everyth", "need", "let", "feed", "upon", "our", "greed", "make", "cloud", "what", "they", "tweet", "like", "the", "begin", "agre", "function", "let", "defin", "paramet", "for", "word", "cloud", "creation", "viz", "input", "corpus", "minimum", "frequenc", "the", "word", "display", "size", "and", "shape", "the", "cloud", "color", "and", "order", "the", "word", "maximum", "word", "display", "etc", "tweak", "these", "and", "have", "littl", "play", "color", "randomcolor", "randomord", "maxword", "num", "color", "randomcolor", "randomord", "maxword", "num", "color", "randomcolor", "randomord", "maxword", "num", "syntax", "and", "explan", "sourc", "word", "word", "plot", "the", "cloud", "freq", "frequenc", "these", "word", "the", "text", "minfreq", "word", "with", "frequenc", "below", "minfreq", "will", "not", "plot", "scale", "vector", "length", "num", "indic", "the", "rang", "the", "size", "the", "word", "maxword", "maximum", "number", "word", "plot", "least", "frequent", "term", "drop", "randomord", "plot", "word", "random", "order", "fals", "they", "will", "plot", "decreas", "frequenc", "randomcolor", "choos", "color", "random", "from", "the", "color", "fals", "the", "color", "chosen", "base", "the", "frequenc", "rotper", "proport", "word", "with", "num", "degre", "rotat", "color", "color", "word", "from", "least", "most", "frequent", "orderedcolor", "true", "then", "color", "are", "assign", "word", "order", "userlayout", "fals", "then", "code", "use", "for", "collis", "detect", "otherwis", "use", "addit", "paramet", "pass", "text", "and", "strheight", "strwidth", "can", "add", "more", "inform", "word", "cloud", "base", "the", "order", "and", "color", "choos", "can", "specifi", "nonrandom", "color", "assign", "randomcolor", "which", "will", "make", "base", "frequenc", "then", "choos", "valu", "color", "use", "palett", "brewerp", "from", "rcolorbrew", "packag", "that", "goe", "the", "order", "prefer", "can", "also", "have", "word", "colorcod", "base", "their", "sentiment", "say", "for", "exampl", "posit", "and", "negat", "emot", "this", "can", "accomplish", "have", "addit", "column", "the", "databas", "that", "defin", "this", "properti", "and", "then", "use", "defin", "color", "follow", "randomcolor", "orderedcolorstru", "color", "randomord", "maxword", "num", "after", "have", "creat", "the", "cloud", "might", "see", "some", "the", "word", "number", "that", "are", "irrelev", "and", "give", "addit", "inform", "such", "case", "need", "tweak", "cloud", "bit", "again", "for", "exampl", "when", "creat", "these", "cloud", "saw", "the", "word", "amp", "and", "will", "the", "most", "frequent", "word", "trump", "and", "modi", "cloud", "use", "the", "follow", "code", "line", "and", "remov", "them", "below", "are", "the", "word", "cloud", "got", "after", "make", "these", "chang", "remov", "number", "necessari", "putin", "remov", "specif", "word", "need", "trump", "modi", "fig", "num", "word", "cloud", "from", "presid", "putin", "tweet", "fig", "num", "word", "cloud", "use", "presid", "trump", "most", "recent", "tweet", "fig", "num", "word", "cloud", "from", "prime", "minist", "modi", "most", "recent", "tweet", "have", "also", "creat", "github", "repositori", "with", "all", "the", "code", "one", "place", "that", "one", "creat", "word", "cloud", "for", "amitabh", "bacchan", "sundar", "pichai", "virat", "koh", "and", "andrew", "close", "note", "apart", "from", "get", "sens", "what", "tweet", "about", "the", "most", "particular", "twitter", "handl", "can", "use", "word", "cloud", "lot", "other", "cool", "stuff", "one", "such", "exampl", "sentiment", "analysi", "for", "product", "use", "hashtag", "get", "all", "the", "tweet", "about", "the", "product", "process", "them", "get", "meaning", "word", "and", "build", "cloud", "bang", "know", "product", "well", "the", "most", "frequent", "word", "are", "posit", "bio", "kritika", "jalan", "experienc", "busi", "analyst", "work", "manag", "consult", "she", "skill", "python", "and", "other", "data", "analysi", "tool", "and", "machin", "learn", "techniqu", "relat", "what", "make", "data", "visual", "success", "mustknow", "how", "determin", "the", "influenc", "twitter", "user", "what", "american", "realli", "think", "about", "trump", "immigr", "ban", "and", "whi"], "timestamp_scraper": 1556367930.844727, "title": "Find Out What Celebrities Tweet About the Most", "read_time": 459.59999999999997, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/kritika-jalan\" rel=\"author\" title=\"Posts by Kritika Jalan\">Kritika Jalan</a>, India.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"#comments\">comments</a></div>\n<p><strong>WordCloud using less than 40 lines of R\u00a0Code</strong></p>\n<p>Guess whose twitter handle gives this word cloud? Enough hints present in there. You are right, that is Andrew Ng tweeting about his new Deep Learning course on Coursera! It\u2019s always fun to see data in action; isn\u2019t it? Let\u2019s try and create a similar word cloud for three world leaders, viz. American President Donald Trump, Indian Prime Minister Narendra Modi, and Russian President Vladimir Putin.<br>\n<img alt=\"\" class=\"aligncenter size-full wp-image-72491\" height=\"385\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-andrew-ng-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-andrew-ng-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-andrew-ng-tweets-300x289.jpg 300w\" width=\"400\"/></br></p>\n<p style=\"text-align: center;\"><strong>Fig. 1: R Word Cloud from Andrew Ng\u2019s Tweets</strong></p>\n<p><em>A word cloud is a data visualisation technique in which the size of each word indicates its frequency or importance in the associated text (i.e., the more times a word appears in the corpus, the bigger the word)</em></p>\n<p>Since you are interested in creating a word cloud from twitter handles using R, I will safely assume you have both, a Twitter account to your name, and RStudio installed on your machine. If not, now is the time to do it.</p>\n<p>You must also have a Twitter Developer Account set up as a medium to extract the tweets. If you need help with it, here\u2019s a\u00a0<a href=\"https://medium.com/@Kritika_Jalan/quick-guide-to-extract-tweets-using-r-c5382d3e257a\" rel=\"noopener noreferrer\" target=\"_blank\">quick guide</a>.</p>\n<p>Let\u2019s get started. Following are the steps we will be taking to get this task done:</p>\n<ol>\n<li>Get Twitter data using handles (2 lines of code!)</li>\n<li>Prepare it for visualisation (Real fun part)</li>\n<li>And finally, create a word cloud (Single line of code!)</li>\n</ol>\n<p><strong>Extract Tweets</strong></p>\n<p>Let us load necessary libraries and establish a connection with Twitter</p>\n<pre>#Getting tweets from twitter\r\nlibrary(twitteR)\r\n#Twitter-R Authentication\r\nlibrary(ROAuth)\r\n#Text processing\r\nlibrary(stringr)\r\n#Text mining\r\nlibrary(tm)\r\n#Wordcloud creation\r\nlibrary(wordcloud)\r\n\r\n#Connect to twitter API using the saved credentials\r\nload(\"twitter authentication.Rdata\")\r\nsetup_twitter_oauth(credentials$consumerKey, credentials$consumerSecret, \r\ncredentials$oauthKey, credentials$oauthSecret)\r\n\r\n</pre>\n<p>Let\u2019s go collect some data now. A couple things to note here \u2013</p>\n<ol>\n<li>One can only get access to data from users who \u2018<em>follow\u2019</em>the Twitter account associated with the API. Or, from the accounts that are public (vs. private)</li>\n<li>Twitter\u00a0<a href=\"https://dev.twitter.com/rest/reference/get/statuses/user_timeline\" rel=\"noopener noreferrer\" target=\"_blank\">API limits</a>the number of tweets a user can get from a particular timeline to be 3200, including RTs even if it is set to FALSE. There are, although, a\u00a0<a href=\"https://www.quora.com/Is-there-a-way-to-get-more-than-3200-tweets-from-a-Twitter-user-using-Twitters-API-or-scraping\" rel=\"noopener noreferrer\" target=\"_blank\">few tools</a>\u00a0available that lets you bypass this limit. We will stick to the limits in this post</li>\n<li>Twitter API also has a\u00a0<a href=\"https://dev.twitter.com/rest/public/rate-limits\" rel=\"noopener noreferrer\" target=\"_blank\">rate limit</a>on how many tweets can be collected at once. If you try to collect too many of them at once, it may fail or return partial results. The best way to work around this is by introducing lag between API calls so that you don\u2019t have to be around when the code runs</li>\n</ol>\n<p>Get twitter handles of the personalities you want to look up. Make sure these are real twitter accounts or you\u2019ll get an error.</p>\n<pre>screenName &lt;- c(\u2018realDonaldTrump\u2019, \u2018PutinRF_Eng\u2019, \u2018narendramodi\u2019)\r\n\r\nCollect information about these handles using twitteR.\r\ncheckHandles &lt;- lookupUsers(screenName)\r\n</pre>\n<p>Get user data for each of the handles and create a data frame for easy access.<br>\nCheck for number of tweets and private accounts using this. Remove private accounts, if any.</br></p>\n<pre>UserData &lt;- lapply(checkHandles, function(x) getUser(x))\r\nUserData &lt;- twListToDF(UserData)\r\ntable(UserData$name, UserData$statusesCount)\r\n\r\n#Check tweet count\r\ntable(UserData$name, UserData$protected)\r\n\r\n#Check Private Accounts\r\nusernames &lt;- subset(UserData, protected == FALSE)\r\n\r\n#Public Accounts\r\nusernames &lt;- as.list(usernames$screenName)\r\n</pre>\n<p>Next we get the list of tweets from the user timelines, covert them to a dataframe and wait for 5 minutes before making another API call. Combine all the dataframes into one to pre-process the tweets. Note, we will only be getting 3200 most recent tweets for these handles. Trump and Modi have tweeted a lot more than that.</p>\n<pre>x &lt;- userTimeline(\u2018realDonaldTrump\u2019,n=3200,includeRts = FALSE)\r\n\r\n#Convert tweets list to dataframe\r\nTrumpData &lt;- twListToDF(x)\r\n\r\n#Wait 5 minutes\r\nSys.sleep(300)\r\n\r\nx &lt;- userTimeline(\u2018PutinRF_Eng\u2019,n=3200,includeRts = FALSE)\r\nPutinData &lt;- twListToDF(x)\r\nSys.sleep(300)\r\n\r\nx &lt;- userTimeline(\u2018narendramodi\u2019,n=3200,includeRts = TRUE)\r\nModiData &lt;- twListToDF(x)\r\n\r\nTrump.df &lt;- data.frame(TrumpData)\r\nPutin.df &lt;- data.frame(PutinData)\r\nModi.df &lt;- data.frame(ModiData)\r\n\r\n#Now create a dataframe that combines all of the collected tweets\r\ntweets &lt;- data.frame()\r\ntweets &lt;- Trump.df\r\ntweets &lt;- rbind(tweets,Putin.df)\r\ntweets &lt;- rbind(tweets,Modi.df)\r\n</pre>\n<p><strong>Pre-Process Tweets</strong></p>\n<p>Now that we have all the relevant tweets in one place, it is time to pre-process them. What I mean here is, let\u2019s remove unwanted characters, symbols and words. You do not want graphic characters, articles, symbols, and numbers to appear in the word cloud. You can skip any of these pre-processing steps based on your need.</p>\n<pre>#Convert tweets to ASCII to avoid reading strange characters\r\niconv(tweets$text, from=\u201dUTF-8\", to=\u201dASCII\u201d, sub=\u201d\u201d)\r\n\r\n#Clean text by removing graphic characters\u00a0\u00a0\r\ntweets$text=str_replace_all(tweets$text,\"[^[:graph:]]\", \" \")\r\n\r\n#Remove Junk Values and replacement words like fffd which appear \r\nbecause of encoding differences\r\ntweets$text &lt;- gsub(\"[^[:alnum:]///' ]\", \"\", tweets$text)\r\n\r\n#Convert all text to lower case\r\ntweets$text &lt;- tolower(tweets$text)\r\n\r\n#Remove retweet keyword\r\ntweets$text &lt;- gsub(\"rt\", \"\", tweets$text)\r\n\r\n#Remove Punctuations\r\ntweets$text &lt;- gsub(\"[[:punct:]]\", \"\", tweets$text)\r\n\r\n#Remove links\r\ntweets$text &lt;- gsub(\"http\\\\w+\", \"\", tweets$text)\r\n\r\n#Remove tabs\r\ntweets$text &lt;- gsub(\"[ |\\t]{2,}\", \"\", tweets$text)\r\n\r\n#Remove blankspaces at begining\r\ntweets$text &lt;- gsub(\"^ \", \"\", tweets$text)\r\n\r\n#Remove blankspaces at the end\r\ntweets$text &lt;- gsub(\" $\", \"\", tweets$text)\r\n\r\n#Remove usernames\r\ntweets$text &lt;- gsub(\"@\\\\w+\", \"\", tweets$text)\r\n</pre>\n<p>Once we have pre-processed tweets, let us now create a corpus for each handle and remove stopwords like \u2018my\u2019, \u2018do\u2019, \u2018today\u2019 etc.</p>\n<pre>#After preprocessing the data, subset for tweets for each handle\r\nTrump &lt;- subset(tweets, screenName==\u201crealDonaldTrump\u201d, select= text)\r\nPutin &lt;- subset(tweets, screenName== \u201cPutinRF_Eng\u201d, select= text)\r\nModi &lt;- subset(tweets, screenName== \u201cnarendramodi\u201d, select= text)\r\n\r\n#Create corpus of individual twitter handles\r\nTrump &lt;- Corpus(VectorSource(Trump))\r\nPutin &lt;- Corpus(VectorSource(Putin))\r\nModi &lt;- Corpus(VectorSource(Modi))\r\n\r\n#Remove English Stopwords from the tweets\r\nTrump &lt;- tm_map(Trump, removeWords, stopwords(\u201cen\u201d))\r\nPutin &lt;- tm_map(Putin, removeWords, stopwords(\u201cen\u201d))\r\nModi &lt;- tm_map(Modi, removeWords, stopwords(\u201cen\u201d))\r\n</pre>\n<p><strong>Create Word Cloud</strong></p>\n<p>If you survived through all these steps to reach here, you deserve a poetic treat! Here goes..</p>\n<p>Now that we have everything we need,<br>\nLet\u2019s feed upon our greed<br>\nMake a cloud of what they tweet,<br/>\nLike in the beginning we\u00a0agreed</br></br></p>\n<p>A function\u00a0wordcloud()\u00a0lets you define parameters for word cloud creation viz. input corpus, minimum frequency of the words to be displayed, size and shape of the cloud, color and order of the words, maximum words displayed, etc. Tweak these and have a little play.</p>\n<pre>wordcloud(Trump,min.freq = 3, scale=c(6,0.5),colors=brewer.pal(8, \u201cDark2\u201d),\r\nrandom.color= FALSE, random.order = FALSE, max.words = 110)\r\n\r\nwordcloud(Putin,min.freq = 4, scale=c(7,0.8),colors=brewer.pal(8, \u201cDark2\u201d),\r\nrandom.color= FALSE, random.order = FALSE, max.words = 100)\r\n\r\nwordcloud(Modi,min.freq = 3, scale=c(6,0.5),colors=brewer.pal(8, \u201cDark2\u201d),\r\nrandom.color= FALSE, random.order = FALSE, max.words = 110)\r\n\r\nSyntax and Explanation (<a href=\"https://cran.r-project.org/web/packages/wordcloud/wordcloud.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">source</a>):\r\nwordcloud(words,freq, min.freq,scale, max.words, random.order, \r\nrandom.color, rot.per,colors, ordered.colors, use.r.layout...)\r\n</pre>\n<p>words: Words to be plotted in the cloud<br/>\nfreq: Frequency of these words in the text<br/>\nmin.freq: Words with frequency below min.freq will not be plotted<br/>\nscale: A vector of length 2 indicating the range of the size of the words<br/>\nmax.words: Maximum number of words to be plotted; least frequent terms dropped<br/>\nrandom.order: Plot words in random order. If false, they will be plotted in decreasing frequency<br/>\nrandom.color: Choose colors randomly from the colors. If false, the color is chosen based on the frequency<br/>\nrot.per: Proportion words with 90 degree rotation<br/>\ncolors: Color words from least to most frequent<br/>\nordered.colors: If true, then colors are assigned to words in order<br/>\nuse.r.layout: If false, then C++ code is used for collision detection, otherwise R is used<br/>\n\u2026: \u00a0Additional parameters to be passed to text (and strheight,strwidth).</p>\n<p>You can add more information to your word cloud based on the order and color you choose. You can specify non-random color assignment (random.color = FALSE) which will make it based on frequency then choose a value of colors using a palette (brewer.pal from <a href=\"http://www.cse.unsw.edu.au/~mike/myrlibrary.old/RColorBrewer/html/ColorBrewer.html\" rel=\"noopener noreferrer\" target=\"_blank\">RColorBrewer</a> package) that goes in the order you prefer.</p>\n<p>You can also have words color-coded based on their sentiments, say for example positive and negative emotions. This can be accomplished by having an additional column in the database that define this property and then using it to define color as follows \u2013<br/>\nwordcloud(df$words,df$freq, min.freq = 3, scale=c(6,0.5),random.color= FALSE, ordered.colors=TRUE,colors=brewer.pal(8, \u201cDark2\u201d)[factor(df$sentiment)],random.order = FALSE, max.words = 110)</p>\n<p>After you have created the cloud, you might see some of the words or numbers that are irrelevant and give no additional information. In such cases, you need to tweak your cloud a bit again. For Example, when I created these clouds, I saw the words \u2018amp\u2019 and \u2018will\u2019 as the most frequent words in Trump\u2019s and Modi\u2019s cloud. I used the following code lines and removed them. Below are the word clouds I got after making these changes.</p>\n<pre>#Remove numbers if necessary\r\n#Putin &lt;- tm_map(Putin, removeNumbers)\r\n\r\n#Remove specific words if needed\r\n#Trump &lt;- tm_map(Trump, removeWords, c(\u2018amp\u2019,\u2019will\u2019))\r\n#Modi &lt;- tm_map(Modi, removeWords, c(\u2018amp\u2019,\u2019will\u2019))\r\n</pre>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-72492\" height=\"343\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-putin-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-putin-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-putin-tweets-300x257.jpg 300w\" width=\"400\"/></p>\n<p style=\"text-align: center;\"><strong>Fig. 2: R Word Cloud from President Putin\u2019s Tweets</strong></p>\n<p style=\"text-align: center;\"><img alt=\"\" class=\"aligncenter size-full wp-image-72493\" height=\"343\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-trumph-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-trumph-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-trumph-tweets-300x257.jpg 300w\" width=\"400\"/></p>\n<p style=\"text-align: center;\"><strong>Fig. 3: R Word Cloud using President Trump\u2019s most recent Tweets</strong></p>\n<p style=\"text-align: center;\"><img alt=\"\" class=\"aligncenter size-full wp-image-72494\" height=\"343\" sizes=\"(max-width: 400px) 100vw, 400px\" src=\"/wp-content/uploads/r-cloud-pm-modi-tweets.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/r-cloud-pm-modi-tweets.jpg 400w, https://www.kdnuggets.com/wp-content/uploads/r-cloud-pm-modi-tweets-300x257.jpg 300w\" width=\"400\"/></p>\n<p style=\"text-align: center;\"><strong>Fig. 4: R Word Cloud from Prime Minister Modi\u2019s most recent Tweets</strong></p>\n<p>I have also created a\u00a0<a href=\"https://github.com/Krithi07/Celebrity-Twitter-WordCloud\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub repository</a>\u00a0with all the codes in one place. That one creates word clouds for Amitabh Bacchan, Sundar Pichai, Virat Kohli, and Andrew Ng.</p>\n<p><strong>Closing Note</strong></p>\n<p>Apart from getting a sense of what is being tweeted about the most by a particular Twitter handle, we can use word clouds to do a lot of other cool stuff. One such example is sentiment analysis for a product. Use hashtag to get all the tweets about the product, process them to get meaningful words and build a cloud, bang! You know your product is doing well if the most frequent words are positive.</p>\n<p dir=\"ltr\"><strong>Bio: <a href=\"https://www.linkedin.com/in/kritikajalan/\">Kritika Jalan</a></strong> is an experienced business analyst working in management consulting. She is skilled in R, Python, SQL, and other data analysis tools and machine learning techniques. </p>\n<p dir=\"ltr\"><strong>Related:</strong></p>\n<ul>\n<li><a href=\"/2017/09/what-makes-data-visualization-successful.html\" rel=\"noopener noreferrer\" target=\"_blank\">What makes a data visualization successful?</a></li>\n<li><a href=\"/2017/05/must-know-determine-influence-twitter-user.html\" rel=\"noopener noreferrer\" target=\"_blank\">Must-Know: How to determine the influence of a Twitter user?</a></li>\n<li><a href=\"/2017/02/odintext-americans-think-about-trump-immigration-ban.html\" rel=\"noopener noreferrer\" target=\"_blank\">What Americans Really Think About Trump\u2019s Immigration Ban and Why</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}