{"content": "comments By Abhay Pawar , Instacart . Competing in kaggle competitions is fun and addictive! And over the last couple of years, I developed some standard ways to explore features and build better machine learning models. These simple, but powerful techniques helped me get a top 2% rank in\u00a0 Instacart Market Basket Analysis \u00a0competition and I use them outside of kaggle as well. So, let\u2019s get right into it! One of the most important aspects of building any supervised learning model on numeric data is to understand the features well.\u00a0Looking at partial dependence plots of a model helps you understand how the model\u2019s output changes with any feature. source But, the problem with these plots is that they are created using a trained model. If we could create these plots from train data directly, it could help us understand the underlying data better. In fact, it can help you with all the following things: Feature understanding Identifying noisy features ( the most interesting part! ) Feature engineering Feature importance Feature debugging Leakage detection and understanding Model monitoring In order to make it easily accessible, I decided to put these techniques into a python package\u00a0 featexp \u00a0and in this article, we\u2019ll see how it can be used for feature exploration. We\u2019ll use the application dataset from\u00a0 Home Credit Default Risk \u00a0competition on Kaggle. The task of the competition is to predict defaulters using the data given about them. Feature Understanding \u00a0 Scatter plot of feature vs. target doesn\u2019t\u00a0help If dependent variable (target) is binary, scatter plots don\u2019t work because all points lie either at 0 or 1. For continuous target, too many data points make it difficult to understand the target vs. feature trend. Featexp creates better plots which help with this problem. Let\u2019s try it out! Feature vs. target plot of DAYS_BIRTH (age) Featexp creates equal population bins (X-axis) of a numeric feature. It then calculates target\u2019s mean in each bin and plots it in the left-hand side plot above. In our case, target\u2019s mean is nothing but default rate. The plot tells us that customers with high negative values for DAYS_BIRTH (higher age) have lower default rates. This makes sense since younger people are usually more likely to default. These plots help us understand what the feature is telling about customers and how it will affect the model. The plot on the right shows number of customers in each bin. Identifying noisy features Noisy features lead to overfitting and identifying them isn\u2019t easy. In featexp, you can pass a test set and compare feature trends in train/test to identify noisy ones. This test set is not the actual test set. Its your local test set/validation set for which you know target. Comparison of feature trends in train and\u00a0test Featexp calculates two metrics to display on these plots which help with gauging noisiness: Trend correlation (seen in test plot): If a feature doesn\u2019t hold same trend w.r.t. target across train and evaluation sets, it can lead to overfitting. This happens because the model is learning something which is not applicable in test data. Trend correlation helps understand how similar train/test trends are and mean target values for bins in train & test are used to calculate it. Feature above has 99% correlation. Doesn\u2019t seem noisy! Trend changes : Sudden and repeated changes in trend direction could imply noisiness. But, such trend change can also happen because that bin has a very different population in terms of other features and hence, its default rate can\u2019t really be compared with other bins. Feature below is not holding the same trend and hence, has a low trend correlation of 85%. These two metrics can be used to drop noisy features. Example of noisy\u00a0feature Dropping low trend-correlation features works well when there are a lot of features and they are correlated with each other. It leads to less overfitting and other correlated features avoid information loss. It\u2019s also important to not drop too many important features as it might lead to a drop in performance.\u00a0 Also, you can\u2019t identify these noisy features using feature importance because they could be fairly important and still be very noisy! Using test data from a different time period works better because then you would be making sure if feature trend holds over time.  \u00a0 function in featexp returns a dataframe with trend correlation and changes for each feature. Dataframe returned by\u00a0 Let\u2019s actually try dropping features with low trend-correlation in our data and see how results improve. AUC for different feature selections using trend-correlation We can see that higher the trend-correlation threshold to drop features, higher is the leaderboard (LB) AUC. \u00a0Not dropping important features further improves LB AUC to 0.74. It\u2019s also interesting and concerning that test AUC doesn\u2019t change as much as LB AUC. Getting your validation strategy right such that local test AUC follows LB AUC is also important. Whole code can be found in\u00a0 featexp_demo \u00a0notebook. Feature Engineering The insights that you get by looking at these plots help with creating better features. Just having a better understanding of data can lead to better feature engineering. But, in addition to this, it can also help you in improving the existing features. Let\u2019s look at another feature EXT_SOURCE_1: Feature vs. target plot of EXT_SOURCE_1 Customers having a high value of EXT_SOURCE_1 have low default rates. But, the first bin (~8% default rate) isn\u2019t following the feature trend (goes up and then down). It has only negative values around -99.985 and a large population. This probably implies that these are special values and hence, don\u2019t follow the feature trend. Fortunately, non-linear models won\u2019t have a problem learning this relationship. But, for linear models like logistic regression, such special values and nulls (which will be shown as a separate bin) should be imputed with a value from a bin with similar default rate instead of simply imputing with feature mean. Feature importance Featexp also helps you with gauging feature importance. DAYS_BIRTH and EXT_SOURCE_1 both have a good trend. But, population for EXT_SOURCE_1 is concentrated in special value bin implying that feature has the same information for most of the customers and hence, can\u2019t differentiate them well. This tells that it might not be as important as DAYS_BIRTH. Based on XGBoost model\u2019s feature importance, DAYS_BIRTH is actually more important than EXT_SOURCE_1. Feature debugging Looking at Featexp\u2019s plots helps you in capturing bugs in complex feature engineering codes by doing these two things: Zero variation features show only a single\u00a0bin Checking if the feature\u2019s population distribution looks right. I\u2019ve personally encountered extreme cases like above numerous times due to minor bugs. Always hypothesize what the feature trend will look like before looking at these plots. Feature trend not looking like what you expected might hint towards some problem.\u00a0 And frankly, this process of hypothesizing trends makes building ML models much more fun! Leakage Detection Data leakage from target to features leads to overfitting. Leaky features have high feature importance. But, understanding why leakage is happening in a feature is difficult. Looking at featexp plots can help you with that. The feature below has 0% default rate in \u2018Nulls\u2019 bin and 100% in all other bins. Clearly, this is an extreme case of leakage. This feature has a value only when the customer has defaulted. Based on what the feature is, this could be because of a bug or the feature is actually populated only for defaulters (in which case it should be dropped).\u00a0 Knowing what the problem is with leaky feature leads to quicker debugging. Understanding why a feature is\u00a0leaky Model Monitoring Since featexp calculates trend correlation between two data sets, it can be easily used for model monitoring. Every time the model is re-trained, the new train data can be compared with a well-tested train data (typically train data from the first time you built the model). Trend correlation can help you monitor if anything has changed in feature w.r.t. its relationship with target. Doing these simple things have always helped me in building better models in real life and on kaggle. With featexp it takes 15 minutes to look at these plots and it\u2019s definitely worth it as you won\u2019t be flying blind after that. Bio :\u00a0 Abhay Pawar currently works as a Senior Machine Learning Engineer at Instacart, in their Search & Discovery team. He works on large scale machine learning problems which help Instacart in improving the quality of their service. Original . Reposted with permission. Resources: on-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education Software for Analytics, Data Science, Data Mining, and Machine Learning Related: How many data scientists are there and is there a shortage? An Introduction to Deep Learning for Tabular Data To Kaggle Or Not", "title_html": "<h1 id=\"title\">My secret sauce to be in top 2% of a Kaggle competition</h1> ", "url": "https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html", "tfidf": {"tfidf": {"after": 1.02070207021, "real": 2.28103448276, "case": 5.93994949024, "too": 3.6317053643, "plot": 107.67039674460001, "new": 1.0178880554, "addit": 1.24634950542, "would": 1.0828729281799998, "addict": 20.0454545455, "number": 1.10142916609, "impli": 16.5375, "dataset": 193.609756098, "function": 2.495441685, "python": 56.2978723404, "well": 4.2622994832, "tri": 3.7089125102199993, "basket": 36.4128440367, "higher": 6.3656776263, "know": 5.1865403463, "their": 2.0309581681, "scale": 3.7469907953699995, "won": 4.63465187564, "equal": 2.542193755, "compet": 3.26465144972, "instead": 1.59461631177, "creat": 6.2464589235000005, "traintest": 2646.0, "thing": 7.219645293329998, "test": 29.22778242681, "repost": 933.882352941, "fair": 3.20533010297, "than": 1.03278688525, "special": 4.464566929139999, "distribut": 2.7396031061299997, "due": 1.23789473684, "alway": 4.13491340018, "found": 1.11387076405, "given": 1.35426085473, "interest": 3.20662492426, "deep": 3.6279707495399998, "difficult": 4.97914379802, "will": 3.67443295788, "see": 3.81726376533, "goe": 4.251740760580001, "coupl": 3.2572835453400004, "below": 4.51215006394, "perform": 1.5313977042500002, "but": 9.14691761091, "definit": 3.24, "our": 4.71517671518, "expect": 2.20011086475, "point": 2.51980001588, "applic": 6.85344269372, "has": 9.3928477518, "have": 8.119158729119999, "pass": 1.61818367139, "default": 253.6777629828, "resourc": 2.9487369985100003, "out": 1.06016694491, "model": 35.5401632868, "datafram": 2646.0, "good": 1.51981619759, "sure": 7.453521126760001, "under": 1.0781663837, "numer": 5.49976905312, "loss": 2.42529789184, "process": 1.69524826482, "not": 8.12539184952, "kaggl": 6615.0, "whole": 2.29488291414, "less": 1.46904783936, "logist": 14.0994671403, "happen": 8.89079708793, "easi": 5.2937645882, "shown": 2.76923076923, "then": 3.25973581548, "separ": 1.6012102874399998, "they": 3.09051975861, "anoth": 1.13643521832, "last": 1.2117234010100002, "let": 13.94466403164, "scienc": 4.63939216832, "pawar": 2116.8, "featur": 102.31742978054, "simpl": 6.7962328767199995, "trendcorrel": 5292.0, "mine": 9.751842751839998, "valu": 20.499856527960002, "softwar": 10.2624434389, "develop": 1.1955719557200002, "such": 3.18454132122, "senior": 4.00706713781, "tabular": 294.0, "explor": 6.79187165776, "lie": 3.2157180474000002, "quicker": 55.5104895105, "some": 2.08073394496, "sourc": 1.69760479042, "should": 3.3286508019800003, "put": 1.65806788512, "result": 1.14611608432, "concern": 1.8852867830400002, "supervis": 7.74061433447, "set": 7.12247644686, "ani": 2.26767604628, "two": 4.0551724138, "improv": 8.17507723996, "from": 6.00340328982, "work": 5.57600449565, "num": 11.00346544011, "abhay": 2646.0, "partial": 3.6131087847099996, "market": 2.36602086438, "for": 14.00441056014, "depend": 4.4822134387400006, "predict": 5.18484650555, "null": 2646.0, "output": 7.676982591880001, "seen": 1.61079545455, "with": 21.025162388789994, "competit": 12.2784222738, "home": 1.4599963215, "are": 8.23924748624, "better": 16.052578362000002, "current": 1.5325803649, "sens": 2.8365195640499996, "debug": 541.227272727, "look": 19.086318826599996, "metric": 44.470588235200005, "featexpdemo": 1323.0, "veri": 2.51760228354, "toward": 1.6303142329, "trend": 119.49093397186, "negat": 7.51704545454, "educ": 2.00733341763, "compar": 5.598683437170001, "shortag": 11.388809182200001, "valid": 6.61224489796, "bug": 82.1172413793, "retrain": 180.409090909, "side": 1.5989525632, "train": 15.492559160799999, "avoid": 2.45986984816, "gaug": 41.076326002600005, "extrem": 4.73204172876, "continu": 1.13928955867, "lead": 8.8650287173, "period": 1.3430335843, "probabl": 2.64555907349, "scientist": 4.69426374926, "notebook": 40.1924050633, "into": 2.03004922958, "discoveri": 4.74902781932, "younger": 4.16802310318, "abov": 5.7114761961900005, "servic": 1.51300867245, "what": 6.2671719563999995, "local": 3.03440366972, "techniqu": 7.458773784360001, "relationship": 4.78264798916, "overfit": 5292.0, "popul": 13.06845932226, "help": 23.79370536903, "affect": 2.4794627518400003, "clear": 1.85423966363, "xaxi": 1323.0, "base": 2.2925631769, "relat": 1.23750876919, "fact": 1.73375559681, "decid": 1.9257641921400002, "hold": 4.9653878231999995, "larg": 2.3714989917, "lower": 2.10055570257, "wrt": 2646.0, "leaki": 793.8000000000001, "onlin": 2.6051854282900004, "anyth": 4.58843930636, "much": 2.3884459154599997, "evalu": 6.9509632224199995, "henc": 21.563327674039996, "noisi": 684.8470588234, "about": 2.12972030318, "problem": 10.60048965054, "how": 9.61501968306, "sudden": 5.78993435449, "just": 1.33580143037, "xgboost": 1323.0, "simpli": 2.5192002538900002, "person": 1.40520446097, "check": 6.50655737705, "across": 1.7318642958400001, "complex": 2.34021226415, "noth": 3.46410648047, "articl": 2.01805008262, "them": 4.39504463976, "insight": 11.8037174721, "whi": 6.513230769240001, "frank": 3.4520547945199995, "singl": 1.60948905109, "setvalid": 1323.0, "blind": 8.849498327760001, "scatter": 18.77705499704, "usual": 1.72508964468, "comparison": 4.9597000937199995, "mani": 3.13280273631, "the": 43.0, "age": 2.97247706422, "fun": 25.7727272728, "build": 6.5366958312, "analysi": 3.47852760736, "monitor": 24.22892025944, "display": 2.93456561922, "linear": 13.8776223776, "team": 2.2748244734200003, "hypothes": 41.289986995999996, "order": 1.24625166811, "leaderboard": 1323.0, "there": 3.12273800157, "exist": 1.4647107666799999, "inform": 3.1506251240400003, "origin": 1.13724928367, "right": 5.621813031159999, "welltest": 1323.0, "correl": 118.6744186044, "either": 1.5830092731099998, "take": 1.13961668222, "follow": 4.18560506196, "might": 6.468559011270001, "strategi": 4.44208170118, "further": 1.3618116315, "code": 7.761427523839999, "hint": 15.2068965517, "high": 3.44331983805, "regress": 51.2129032258, "realli": 4.7476076555, "power": 1.3396337861799998, "also": 7.10335570469, "typic": 2.2541530597799997, "risk": 4.095975232200001, "target": 41.846715328470005, "around": 1.21394708671, "mean": 5.79627601316, "fli": 4.35555555556, "becaus": 6.897110998499999, "task": 3.88641370869, "minor": 2.23071518898, "encount": 4.13976531943, "over": 2.05050048434, "peopl": 1.21320495186, "zero": 8.75192943771, "machin": 20.121673003799998, "captur": 2.88026124819, "rank": 2.52480916031, "threshold": 23.008695652199997, "variabl": 8.747107438019999, "actual": 7.49929145016, "calcul": 24.51891891892, "minut": 3.11233091551, "which": 7.036342915, "term": 1.39520168732, "other": 5.0496183206000005, "introduct": 2.7808723068799996, "one": 2.01254991444, "show": 2.5340782123, "lot": 4.40877534018, "custom": 21.807692307719996, "seem": 2.29123971713, "bin": 290.2784810133, "outsid": 1.67450690855, "webbas": 1323.0, "get": 7.1425036554, "still": 1.1866357724799999, "like": 5.745928338750001, "select": 2.02345144022, "drop": 19.6759101472, "tell": 10.08426847344, "detect": 10.82577565632, "part": 1.04330682789, "both": 1.05215720061, "analyt": 34.513043478200004, "identifi": 11.509351892149999, "repeat": 2.8771293947099994, "access": 1.8734953976900002, "this": 13.049317147230001, "time": 5.0563730174, "variat": 4.704, "engin": 12.35678704855, "chang": 8.2662897947, "similar": 2.75028150714, "differ": 3.7096347067499997, "same": 3.35573874444, "binari": 32.4, "most": 3.06289389069, "between": 1.03453668708, "low": 8.52288283452, "return": 2.79064862014, "instacart": 5292.0, "credit": 3.04312823462, "all": 3.03440366973, "top": 1.8387769284200002, "fortun": 6.211267605630001, "someth": 3.28152128979, "imput": 356.76404494400003, "that": 12.047808765, "built": 1.99447236181, "rate": 14.98341647565, "more": 3.0515120451, "and": 35.00220472455, "leakag": 429.08108108100004, "these": 15.03815967528, "life": 1.37051104972, "could": 6.0218479745, "befor": 1.10036041031, "comment": 3.05954904606, "standard": 1.8915763135900003, "can": 19.99644365414, "make": 5.3813300793000005, "way": 1.2190739461, "search": 3.2539454806299997, "onli": 4.102590606640001, "each": 4.75899280576, "concentr": 3.16066095959, "permiss": 6.280063291139999, "packag": 7.828402366860001, "data": 67.5287111868, "qualiti": 2.9329392204, "featexp": 14553.0, "sinc": 2.16737201366, "bio": 42.336000000000006, "exampl": 1.50483412322, "aspect": 3.0893169877399997, "worth": 5.210370856580001, "understand": 35.62303664916, "differenti": 7.759530791789999, "direct": 2.44452998692, "import": 18.762789127180003, "first": 2.01523229246, "everi": 1.47917637194, "nonlinear": 99.225, "use": 11.32602633118, "year": 1.0485436893200002, "lefthand": 1221.23076923, "easili": 7.387622149839999, "down": 1.35889754344, "learn": 20.90475493785, "when": 2.0415353951}, "logtfidf": {"after": 0.020490694648099998, "real": 0.824629060574, "case": 1.581625075556, "too": 1.1931103094439999, "plot": 33.6668481018, "new": 0.0177299468511, "addit": 0.220218882972, "would": 0.0796176279647, "addict": 2.99800242209, "number": 0.0966085784186, "impli": 5.121054722310001, "dataset": 5.26584456664, "function": 0.914465741594, "python": 4.03065674296, "well": 0.2540577532624, "tri": 1.23518305832, "basket": 3.59492157055, "higher": 2.256925196985, "know": 1.905839388796, "their": 0.030721010245400002, "scale": 1.32095306328, "won": 1.6808278158, "equal": 0.933027391343, "compet": 1.1831530035, "instead": 0.46663315041500003, "creat": 1.1128840925699999, "traintest": 14.37531432822, "thing": 2.63458060404, "test": 10.749468808133, "repost": 6.83935046985, "fair": 1.16481508131, "than": 0.0322608622182, "special": 1.192679785803, "distribut": 1.00781305813, "due": 0.21341214386399998, "alway": 1.452638409144, "found": 0.107841124048, "given": 0.303255810831, "interest": 0.9441435559639999, "deep": 1.2886734698, "difficult": 1.824221535176, "will": 0.6083596047450001, "see": 0.722764756476, "goe": 1.4473284897999998, "coupl": 1.18089357972, "below": 1.627253183872, "perform": 0.42618085058, "but": 0.1457313486471, "definit": 1.1755733298, "our": 1.7152784283640001, "expect": 0.78850775216, "point": 0.46206471806599997, "applic": 2.46320785698, "has": 0.38451550369320003, "have": 0.1182800187296, "pass": 0.48130432974, "default": 36.613897945679994, "resourc": 1.08137694258, "out": 0.0584263909193, "model": 12.536651242887002, "datafram": 14.37531432822, "good": 0.418589404907, "sure": 2.0086865552, "under": 0.07526180538319999, "numer": 1.818281437038, "loss": 0.885954358842, "process": 0.527829199025, "not": 0.12441930406, "kaggl": 35.93828582055, "whole": 0.8306818244059999, "less": 0.3846144626, "logist": 2.6461370052, "happen": 3.2592132540600005, "easi": 1.6665296351499999, "shown": 1.01856958099, "then": 0.24910159569269996, "separ": 0.470759772949, "they": 0.0891809843028, "anoth": 0.127896361652, "last": 0.19204364461100001, "let": 4.995210269119999, "scienc": 1.682872357782, "pawar": 13.929027225599999, "featur": 28.366957015514, "simpl": 2.4464425787799997, "trendcorrel": 28.75062865644, "mine": 3.16861817356, "valu": 7.408739791332, "softwar": 2.32849096333, "develop": 0.178624694913, "such": 0.179087933418, "senior": 1.38805958664, "tabular": 5.6835797673399995, "explor": 2.44515874436, "lie": 1.16805067564, "quicker": 4.01657200308, "some": 0.079147018129, "sourc": 0.529218310751, "should": 1.018839753516, "put": 0.505652999854, "result": 0.136378908381, "concern": 0.634079948873, "supervis": 2.04648105583, "set": 1.0289760677339999, "ani": 0.251216716732, "two": 0.0547953774328, "improv": 2.8591832157279997, "from": 0.0034023250131959997, "work": 0.545172836365, "num": 0.0034648943493670007, "abhay": 14.37531432822, "partial": 1.28456856096, "market": 0.8612095839370001, "for": 0.0044098655355580005, "depend": 1.61393963, "predict": 1.6457402376899999, "null": 14.37531432822, "output": 2.03822657827, "seen": 0.47672812813, "with": 0.025147325981190002, "competit": 4.48619629604, "home": 0.378433916197, "are": 0.2357397886616, "better": 5.5714235248, "current": 0.42695282784500005, "sens": 1.04257779501, "debug": 15.585680998259999, "look": 6.4638669360000005, "metric": 6.203361703119999, "featexpdemo": 7.18765716411, "veri": 0.460319586476, "toward": 0.48877277716000006, "trend": 37.22835707338, "negat": 2.64805197704, "educ": 0.696807183384, "compar": 1.8717575427809998, "shortag": 2.43263122258, "valid": 1.8889232176800002, "bug": 9.92860713108, "retrain": 5.19522699942, "side": 0.46934876686899996, "train": 5.287346502712, "avoid": 0.900108441291, "gaug": 6.0445695306400005, "extrem": 1.7224191678740002, "continu": 0.13040487398700001, "lead": 1.6534282090689998, "period": 0.294930924153, "probabl": 0.972882412913, "scientist": 1.54634128444, "notebook": 3.693678049, "into": 0.0298257264574, "discoveri": 1.5579399274799999, "younger": 1.4274418474200001, "abov": 1.9315956894480002, "servic": 0.41410016674500005, "what": 1.129436484135, "local": 0.833735480412, "techniqu": 2.63248769614, "relationship": 1.743694370368, "overfit": 28.75062865644, "popul": 4.670653035126, "help": 5.715531262848, "affect": 0.908041904384, "clear": 0.617474727198, "xaxi": 7.18765716411, "base": 0.27304660457400004, "relat": 0.21310030165399999, "fact": 0.5502899207949999, "decid": 0.655322871893, "hold": 1.511637351588, "larg": 0.34075012121200005, "lower": 0.742201929994, "wrt": 14.37531432822, "leaki": 16.73465775504, "onlin": 0.957503854357, "anyth": 1.52353994585, "much": 0.35499145860200004, "evalu": 1.9388802431299998, "henc": 6.73879887128, "noisi": 45.44430295614001, "about": 0.1256869549492, "problem": 3.414844345638, "how": 2.8294017415800004, "sudden": 1.75612095378, "just": 0.289531434109, "xgboost": 7.18765716411, "simpli": 0.923941491586, "person": 0.34018281601800004, "check": 1.87281049562, "across": 0.549198455941, "complex": 0.8502416364309999, "noth": 1.24245472939, "articl": 0.702131739574, "them": 0.3767333076372, "insight": 2.46841452187, "whi": 2.36137686094, "frank": 1.2389696463600002, "singl": 0.475916769059, "setvalid": 7.18765716411, "blind": 2.1803607712799997, "scatter": 4.47897693, "usual": 0.545279017064, "comparison": 1.60134527393, "mani": 0.1299472743663, "the": 0.0, "age": 0.7924969060060001, "fun": 5.112339339619999, "build": 1.964549808364, "analysi": 1.2466091029200002, "monitor": 7.20501044232, "display": 1.07655944206, "linear": 2.63027764196, "team": 0.821902894886, "hypothes": 6.0549456888, "order": 0.22014038079300002, "leaderboard": 7.18765716411, "there": 0.12029367877649999, "exist": 0.38165779408699996, "inform": 0.908907409324, "origin": 0.128612437587, "right": 1.36143941668, "welltest": 7.18765716411, "correl": 23.212432692270003, "either": 0.459327638815, "take": 0.130691962197, "follow": 0.18142764437679998, "might": 2.3050232296020003, "strategi": 1.49112311818, "further": 0.308815895297, "code": 2.71203819194, "hint": 2.72174904546, "high": 0.41347135962000003, "regress": 3.9359915164199997, "realli": 1.5576408397, "power": 0.292396282715, "also": 0.1026001046, "typic": 0.812774319158, "risk": 1.4100048408899999, "target": 15.197831345060003, "around": 0.19387710578200001, "mean": 1.48368513408, "fli": 1.47145216946, "becaus": 0.83605895295, "task": 1.35748680661, "minor": 0.802322246604, "encount": 1.4206391000999998, "over": 0.0498734429914, "peopl": 0.193265578473, "zero": 2.1692741832299998, "machin": 6.9617979031, "captur": 1.0578810012100002, "rank": 0.926165479794, "threshold": 3.1358722163099997, "variabl": 2.1687230672, "actual": 2.514056726592, "calcul": 7.252602636839999, "minut": 1.1353719359799999, "which": 0.036248896918010004, "term": 0.33303898354600003, "other": 0.0493737395988, "introduct": 1.02276465794, "one": 0.012510703291, "show": 0.473365532026, "lot": 1.4835969502500002, "custom": 7.743019778879999, "seem": 0.829093032276, "bin": 40.37658799330001, "outsid": 0.515518738985, "webbas": 7.18765716411, "get": 2.319076023128, "still": 0.17112222142900002, "like": 0.6952678827250001, "select": 0.704804687133, "drop": 7.199628084975999, "tell": 3.63709303203, "detect": 3.37756548986, "part": 0.04239531098280001, "both": 0.050842533389300004, "analyt": 5.696380287719999, "identifi": 4.1686100023599995, "repeat": 1.0567930591299999, "access": 0.627805882716, "this": 0.0492238376825, "time": 0.056057594313, "variat": 1.5484132106, "engin": 4.52383779138, "chang": 1.163929375406, "similar": 0.637112184228, "differ": 0.6369633639360001, "same": 0.336178948812, "binari": 3.4781584227999995, "most": 0.06224368888679999, "between": 0.033953681165299995, "low": 3.0258411333960002, "return": 0.666253737184, "instacart": 28.75062865644, "credit": 1.11288601088, "all": 0.03420789629339999, "top": 0.609100637788, "fortun": 1.8263649984099999, "someth": 1.18830712273, "imput": 10.36785488834, "that": 0.04771378055568, "built": 0.690379535065, "rate": 5.327237105162, "more": 0.05107479479999999, "and": 0.0022046549722259997, "leakag": 22.2610399441, "these": 1.0014706716111998, "life": 0.315183699277, "could": 0.9297813614500001, "befor": 0.0956377718795, "comment": 1.11826753454, "standard": 0.63741050982, "can": 2.759798638698, "make": 0.36748828911449993, "way": 0.19809150993500002, "search": 1.1798682540899998, "onli": 0.10129707331639999, "each": 0.694966757216, "concentr": 1.15078117015, "permiss": 1.8373800586400002, "packag": 2.0577584491900005, "data": 24.336411696, "qualiti": 1.07600506711, "featexp": 79.06422880521, "sinc": 0.1607363989154, "bio": 3.7456377879300002, "exampl": 0.40868267499899996, "aspect": 1.12795002691, "worth": 1.65065103492, "understand": 13.057030508159997, "differenti": 2.0489218673900003, "direct": 0.401411378992, "import": 4.099455878924, "first": 0.015174579624319999, "everi": 0.391485427421, "nonlinear": 4.59738999867, "use": 0.3212882170476, "year": 0.047402238894600005, "lefthand": 7.1076144564399995, "easili": 2.6133174734, "down": 0.306673741186, "learn": 7.584768582704999, "when": 0.0411099777168}, "logidf": {"after": 0.020490694648099998, "real": 0.824629060574, "case": 0.395406268889, "too": 0.5965551547219999, "plot": 1.68334240509, "new": 0.0177299468511, "addit": 0.220218882972, "would": 0.0796176279647, "addict": 2.99800242209, "number": 0.0966085784186, "impli": 1.7070182407700003, "dataset": 5.26584456664, "function": 0.914465741594, "python": 4.03065674296, "well": 0.0635144383156, "tri": 0.61759152916, "basket": 3.59492157055, "higher": 0.752308398995, "know": 0.952919694398, "their": 0.015360505122700001, "scale": 1.32095306328, "won": 0.8404139079, "equal": 0.933027391343, "compet": 1.1831530035, "instead": 0.46663315041500003, "creat": 0.222576818514, "traintest": 7.18765716411, "thing": 0.8781935346799999, "test": 0.977224437103, "repost": 6.83935046985, "fair": 1.16481508131, "than": 0.0322608622182, "special": 0.39755992860100003, "distribut": 1.00781305813, "due": 0.21341214386399998, "alway": 0.726319204572, "found": 0.107841124048, "given": 0.303255810831, "interest": 0.47207177798199995, "deep": 1.2886734698, "difficult": 0.912110767588, "will": 0.202786534915, "see": 0.240921585492, "goe": 1.4473284897999998, "coupl": 1.18089357972, "below": 0.813626591936, "perform": 0.42618085058, "but": 0.0161923720719, "definit": 1.1755733298, "our": 0.8576392141820001, "expect": 0.78850775216, "point": 0.23103235903299998, "applic": 1.23160392849, "has": 0.0427239448548, "have": 0.0147850023412, "pass": 0.48130432974, "default": 3.0511581621399997, "resourc": 1.08137694258, "out": 0.0584263909193, "model": 0.7374500731110001, "datafram": 7.18765716411, "good": 0.418589404907, "sure": 2.0086865552, "under": 0.07526180538319999, "numer": 0.606093812346, "loss": 0.885954358842, "process": 0.527829199025, "not": 0.0155524130075, "kaggl": 7.18765716411, "whole": 0.8306818244059999, "less": 0.3846144626, "logist": 2.6461370052, "happen": 1.08640441802, "easi": 1.6665296351499999, "shown": 1.01856958099, "then": 0.08303386523089999, "separ": 0.470759772949, "they": 0.0297269947676, "anoth": 0.127896361652, "last": 0.19204364461100001, "let": 1.2488025672799998, "scienc": 0.841436178891, "pawar": 6.964513612799999, "featur": 0.423387418142, "simpl": 1.2232212893899999, "trendcorrel": 7.18765716411, "mine": 1.58430908678, "valu": 0.823193310148, "softwar": 2.32849096333, "develop": 0.178624694913, "such": 0.059695977806, "senior": 1.38805958664, "tabular": 5.6835797673399995, "explor": 1.22257937218, "lie": 1.16805067564, "quicker": 4.01657200308, "some": 0.0395735090645, "sourc": 0.529218310751, "should": 0.509419876758, "put": 0.505652999854, "result": 0.136378908381, "concern": 0.634079948873, "supervis": 2.04648105583, "set": 0.171496011289, "ani": 0.125608358366, "two": 0.0136988443582, "improv": 0.7147958039319999, "from": 0.000567054168866, "work": 0.109034567273, "num": 0.00031499039539700004, "abhay": 7.18765716411, "partial": 1.28456856096, "market": 0.8612095839370001, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "null": 7.18765716411, "output": 2.03822657827, "seen": 0.47672812813, "with": 0.00119749171339, "competit": 1.12154907401, "home": 0.378433916197, "are": 0.0294674735827, "better": 0.6964279406, "current": 0.42695282784500005, "sens": 1.04257779501, "debug": 5.19522699942, "look": 0.6463866936, "metric": 3.1016808515599994, "featexpdemo": 7.18765716411, "veri": 0.230159793238, "toward": 0.48877277716000006, "trend": 1.6921980487900001, "negat": 1.32402598852, "educ": 0.696807183384, "compar": 0.6239191809269999, "shortag": 2.43263122258, "valid": 1.8889232176800002, "bug": 3.30953571036, "retrain": 5.19522699942, "side": 0.46934876686899996, "train": 0.660918312839, "avoid": 0.900108441291, "gaug": 3.0222847653200002, "extrem": 0.8612095839370001, "continu": 0.13040487398700001, "lead": 0.23620402986699998, "period": 0.294930924153, "probabl": 0.972882412913, "scientist": 1.54634128444, "notebook": 3.693678049, "into": 0.0149128632287, "discoveri": 1.5579399274799999, "younger": 1.4274418474200001, "abov": 0.643865229816, "servic": 0.41410016674500005, "what": 0.225887296827, "local": 0.416867740206, "techniqu": 1.31624384807, "relationship": 0.871847185184, "overfit": 7.18765716411, "popul": 0.778442172521, "help": 0.336207721344, "affect": 0.908041904384, "clear": 0.617474727198, "xaxi": 7.18765716411, "base": 0.13652330228700002, "relat": 0.21310030165399999, "fact": 0.5502899207949999, "decid": 0.655322871893, "hold": 0.503879117196, "larg": 0.17037506060600002, "lower": 0.742201929994, "wrt": 7.18765716411, "leaki": 5.57821925168, "onlin": 0.957503854357, "anyth": 1.52353994585, "much": 0.17749572930100002, "evalu": 1.9388802431299998, "henc": 1.68469971782, "noisi": 4.1313002687400004, "about": 0.0628434774746, "problem": 0.569140724273, "how": 0.47156695693000006, "sudden": 1.75612095378, "just": 0.289531434109, "xgboost": 7.18765716411, "simpli": 0.923941491586, "person": 0.34018281601800004, "check": 1.87281049562, "across": 0.549198455941, "complex": 0.8502416364309999, "noth": 1.24245472939, "articl": 0.702131739574, "them": 0.0941833269093, "insight": 2.46841452187, "whi": 1.18068843047, "frank": 1.2389696463600002, "singl": 0.475916769059, "setvalid": 7.18765716411, "blind": 2.1803607712799997, "scatter": 2.239488465, "usual": 0.545279017064, "comparison": 1.60134527393, "mani": 0.0433157581221, "the": 0.0, "age": 0.39624845300300005, "fun": 2.5561696698099996, "build": 0.491137452091, "analysi": 1.2466091029200002, "monitor": 1.80125261058, "display": 1.07655944206, "linear": 2.63027764196, "team": 0.821902894886, "hypothes": 3.0274728444, "order": 0.22014038079300002, "leaderboard": 7.18765716411, "there": 0.0400978929255, "exist": 0.38165779408699996, "inform": 0.454453704662, "origin": 0.128612437587, "right": 0.34035985417, "welltest": 7.18765716411, "correl": 2.57915918803, "either": 0.459327638815, "take": 0.130691962197, "follow": 0.045356911094199995, "might": 0.7683410765340001, "strategi": 1.49112311818, "further": 0.308815895297, "code": 1.35601909597, "hint": 2.72174904546, "high": 0.13782378654000002, "regress": 3.9359915164199997, "realli": 1.5576408397, "power": 0.292396282715, "also": 0.0146571578, "typic": 0.812774319158, "risk": 1.4100048408899999, "target": 1.1690639496200002, "around": 0.19387710578200001, "mean": 0.37092128352, "fli": 1.47145216946, "becaus": 0.139343158825, "task": 1.35748680661, "minor": 0.802322246604, "encount": 1.4206391000999998, "over": 0.0249367214957, "peopl": 0.193265578473, "zero": 2.1692741832299998, "machin": 1.39235958062, "captur": 1.0578810012100002, "rank": 0.926165479794, "threshold": 3.1358722163099997, "variabl": 2.1687230672, "actual": 0.628514181648, "calcul": 1.8131506592099997, "minut": 1.1353719359799999, "which": 0.00517841384543, "term": 0.33303898354600003, "other": 0.00987474791976, "introduct": 1.02276465794, "one": 0.0062553516455, "show": 0.236682766013, "lot": 1.4835969502500002, "custom": 1.2905032964799998, "seem": 0.829093032276, "bin": 3.1058913841000004, "outsid": 0.515518738985, "webbas": 7.18765716411, "get": 0.579769005782, "still": 0.17112222142900002, "like": 0.139053576545, "select": 0.704804687133, "drop": 0.8999535106219999, "tell": 1.21236434401, "detect": 1.68878274493, "part": 0.04239531098280001, "both": 0.050842533389300004, "analyt": 2.8481901438599997, "identifi": 0.833722000472, "repeat": 1.0567930591299999, "access": 0.627805882716, "this": 0.0037864490525, "time": 0.0112115188626, "variat": 1.5484132106, "engin": 0.904767558276, "chang": 0.166275625058, "similar": 0.318556092114, "differ": 0.212321121312, "same": 0.112059649604, "binari": 3.4781584227999995, "most": 0.020747896295599998, "between": 0.033953681165299995, "low": 0.7564602833490001, "return": 0.333126868592, "instacart": 7.18765716411, "credit": 1.11288601088, "all": 0.011402632097799998, "top": 0.609100637788, "fortun": 1.8263649984099999, "someth": 1.18830712273, "imput": 5.18392744417, "that": 0.00397614837964, "built": 0.690379535065, "rate": 0.761033872166, "more": 0.017024931599999998, "and": 6.29901420636e-05, "leakag": 4.45220798882, "these": 0.0715336194008, "life": 0.315183699277, "could": 0.18595627229000003, "befor": 0.0956377718795, "comment": 1.11826753454, "standard": 0.63741050982, "can": 0.162341096394, "make": 0.07349765782289999, "way": 0.19809150993500002, "search": 1.1798682540899998, "onli": 0.025324268329099998, "each": 0.173741689304, "concentr": 1.15078117015, "permiss": 1.8373800586400002, "packag": 2.0577584491900005, "data": 1.2168205848, "qualiti": 1.07600506711, "featexp": 7.18765716411, "sinc": 0.0803681994577, "bio": 3.7456377879300002, "exampl": 0.40868267499899996, "aspect": 1.12795002691, "worth": 1.65065103492, "understand": 1.0880858756799998, "differenti": 2.0489218673900003, "direct": 0.200705689496, "import": 0.292818277066, "first": 0.0075872898121599995, "everi": 0.391485427421, "nonlinear": 4.59738999867, "use": 0.0292080197316, "year": 0.047402238894600005, "lefthand": 7.1076144564399995, "easili": 1.3066587367, "down": 0.306673741186, "learn": 0.842752064745, "when": 0.0205549888584}, "freq": {"after": 1, "real": 1, "case": 4, "too": 2, "plot": 20, "new": 1, "addit": 1, "would": 1, "addict": 1, "number": 1, "impli": 3, "dataset": 1, "function": 1, "python": 1, "well": 4, "tri": 2, "basket": 1, "higher": 3, "know": 2, "their": 2, "scale": 1, "won": 2, "equal": 1, "compet": 1, "instead": 1, "creat": 5, "traintest": 2, "thing": 3, "test": 11, "repost": 1, "fair": 1, "than": 1, "special": 3, "distribut": 1, "due": 1, "alway": 2, "found": 1, "given": 1, "interest": 2, "deep": 1, "difficult": 2, "will": 3, "see": 3, "goe": 1, "coupl": 1, "below": 2, "perform": 1, "but": 9, "definit": 1, "our": 2, "expect": 1, "point": 2, "applic": 2, "has": 9, "have": 8, "pass": 1, "default": 12, "resourc": 1, "out": 1, "model": 17, "datafram": 2, "good": 1, "sure": 1, "under": 1, "numer": 3, "loss": 1, "process": 1, "not": 8, "kaggl": 5, "whole": 1, "less": 1, "logist": 1, "happen": 3, "easi": 1, "shown": 1, "then": 3, "separ": 1, "they": 3, "anoth": 1, "last": 1, "let": 4, "scienc": 2, "pawar": 2, "featur": 67, "simpl": 2, "trendcorrel": 4, "mine": 2, "valu": 9, "softwar": 1, "develop": 1, "such": 3, "senior": 1, "tabular": 1, "explor": 2, "lie": 1, "quicker": 1, "some": 2, "sourc": 1, "should": 2, "put": 1, "result": 1, "concern": 1, "supervis": 1, "set": 6, "ani": 2, "two": 4, "improv": 4, "from": 6, "work": 5, "num": 11, "abhay": 2, "partial": 1, "market": 1, "for": 14, "depend": 2, "predict": 1, "null": 2, "output": 1, "seen": 1, "with": 21, "competit": 4, "home": 1, "are": 8, "better": 8, "current": 1, "sens": 1, "debug": 3, "look": 10, "metric": 2, "featexpdemo": 1, "veri": 2, "toward": 1, "trend": 22, "negat": 2, "educ": 1, "compar": 3, "shortag": 1, "valid": 1, "bug": 3, "retrain": 1, "side": 1, "train": 8, "avoid": 1, "gaug": 2, "extrem": 2, "continu": 1, "lead": 7, "period": 1, "probabl": 1, "scientist": 1, "notebook": 1, "into": 2, "discoveri": 1, "younger": 1, "abov": 3, "servic": 1, "what": 5, "local": 2, "techniqu": 2, "relationship": 2, "overfit": 4, "popul": 6, "help": 17, "affect": 1, "clear": 1, "xaxi": 1, "base": 2, "relat": 1, "fact": 1, "decid": 1, "hold": 3, "larg": 2, "lower": 1, "wrt": 2, "leaki": 3, "onlin": 1, "anyth": 1, "much": 2, "evalu": 1, "henc": 4, "noisi": 11, "about": 2, "problem": 6, "how": 6, "sudden": 1, "just": 1, "xgboost": 1, "simpli": 1, "person": 1, "check": 1, "across": 1, "complex": 1, "noth": 1, "articl": 1, "them": 4, "insight": 1, "whi": 2, "frank": 1, "singl": 1, "setvalid": 1, "blind": 1, "scatter": 2, "usual": 1, "comparison": 1, "mani": 3, "the": 43, "age": 2, "fun": 2, "build": 4, "analysi": 1, "monitor": 4, "display": 1, "linear": 1, "team": 1, "hypothes": 2, "order": 1, "leaderboard": 1, "there": 3, "exist": 1, "inform": 2, "origin": 1, "right": 4, "welltest": 1, "correl": 9, "either": 1, "take": 1, "follow": 4, "might": 3, "strategi": 1, "further": 1, "code": 2, "hint": 1, "high": 3, "regress": 1, "realli": 1, "power": 1, "also": 7, "typic": 1, "risk": 1, "target": 13, "around": 1, "mean": 4, "fli": 1, "becaus": 6, "task": 1, "minor": 1, "encount": 1, "over": 2, "peopl": 1, "zero": 1, "machin": 5, "captur": 1, "rank": 1, "threshold": 1, "variabl": 1, "actual": 4, "calcul": 4, "minut": 1, "which": 7, "term": 1, "other": 5, "introduct": 1, "one": 2, "show": 2, "lot": 1, "custom": 6, "seem": 1, "bin": 13, "outsid": 1, "webbas": 1, "get": 4, "still": 1, "like": 5, "select": 1, "drop": 8, "tell": 3, "detect": 2, "part": 1, "both": 1, "analyt": 2, "identifi": 5, "repeat": 1, "access": 1, "this": 13, "time": 5, "variat": 1, "engin": 5, "chang": 7, "similar": 2, "differ": 3, "same": 3, "binari": 1, "most": 3, "between": 1, "low": 4, "return": 2, "instacart": 4, "credit": 1, "all": 3, "top": 1, "fortun": 1, "someth": 1, "imput": 2, "that": 12, "built": 1, "rate": 7, "more": 3, "and": 35, "leakag": 5, "these": 14, "life": 1, "could": 5, "befor": 1, "comment": 1, "standard": 1, "can": 17, "make": 5, "way": 1, "search": 1, "onli": 4, "each": 4, "concentr": 1, "permiss": 1, "packag": 1, "data": 20, "qualiti": 1, "featexp": 11, "sinc": 2, "bio": 1, "exampl": 1, "aspect": 1, "worth": 1, "understand": 12, "differenti": 1, "direct": 2, "import": 14, "first": 2, "everi": 1, "nonlinear": 1, "use": 11, "year": 1, "lefthand": 1, "easili": 2, "down": 1, "learn": 9, "when": 2}, "idf": {"after": 1.02070207021, "real": 2.28103448276, "case": 1.48498737256, "too": 1.81585268215, "plot": 5.383519837230001, "new": 1.0178880554, "addit": 1.24634950542, "would": 1.0828729281799998, "addict": 20.0454545455, "number": 1.10142916609, "impli": 5.5125, "dataset": 193.609756098, "function": 2.495441685, "python": 56.2978723404, "well": 1.0655748708, "tri": 1.8544562551099997, "basket": 36.4128440367, "higher": 2.1218925421, "know": 2.59327017315, "their": 1.01547908405, "scale": 3.7469907953699995, "won": 2.31732593782, "equal": 2.542193755, "compet": 3.26465144972, "instead": 1.59461631177, "creat": 1.2492917847, "traintest": 1323.0, "thing": 2.4065484311099996, "test": 2.65707112971, "repost": 933.882352941, "fair": 3.20533010297, "than": 1.03278688525, "special": 1.4881889763799998, "distribut": 2.7396031061299997, "due": 1.23789473684, "alway": 2.06745670009, "found": 1.11387076405, "given": 1.35426085473, "interest": 1.60331246213, "deep": 3.6279707495399998, "difficult": 2.48957189901, "will": 1.22481098596, "see": 1.27242125511, "goe": 4.251740760580001, "coupl": 3.2572835453400004, "below": 2.25607503197, "perform": 1.5313977042500002, "but": 1.01632417899, "definit": 3.24, "our": 2.35758835759, "expect": 2.20011086475, "point": 1.25990000794, "applic": 3.42672134686, "has": 1.0436497502, "have": 1.0148948411399998, "pass": 1.61818367139, "default": 21.1398135819, "resourc": 2.9487369985100003, "out": 1.06016694491, "model": 2.0905978404, "datafram": 1323.0, "good": 1.51981619759, "sure": 7.453521126760001, "under": 1.0781663837, "numer": 1.83325635104, "loss": 2.42529789184, "process": 1.69524826482, "not": 1.01567398119, "kaggl": 1323.0, "whole": 2.29488291414, "less": 1.46904783936, "logist": 14.0994671403, "happen": 2.96359902931, "easi": 5.2937645882, "shown": 2.76923076923, "then": 1.08657860516, "separ": 1.6012102874399998, "they": 1.03017325287, "anoth": 1.13643521832, "last": 1.2117234010100002, "let": 3.48616600791, "scienc": 2.31969608416, "pawar": 1058.4, "featur": 1.52712581762, "simpl": 3.3981164383599998, "trendcorrel": 1323.0, "mine": 4.875921375919999, "valu": 2.2777618364400003, "softwar": 10.2624434389, "develop": 1.1955719557200002, "such": 1.06151377374, "senior": 4.00706713781, "tabular": 294.0, "explor": 3.39593582888, "lie": 3.2157180474000002, "quicker": 55.5104895105, "some": 1.04036697248, "sourc": 1.69760479042, "should": 1.6643254009900001, "put": 1.65806788512, "result": 1.14611608432, "concern": 1.8852867830400002, "supervis": 7.74061433447, "set": 1.18707940781, "ani": 1.13383802314, "two": 1.01379310345, "improv": 2.04376930999, "from": 1.00056721497, "work": 1.11520089913, "num": 1.00031504001, "abhay": 1323.0, "partial": 3.6131087847099996, "market": 2.36602086438, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "null": 1323.0, "output": 7.676982591880001, "seen": 1.61079545455, "with": 1.0011982089899998, "competit": 3.06960556845, "home": 1.4599963215, "are": 1.02990593578, "better": 2.0065722952500002, "current": 1.5325803649, "sens": 2.8365195640499996, "debug": 180.409090909, "look": 1.9086318826599997, "metric": 22.235294117600002, "featexpdemo": 1323.0, "veri": 1.25880114177, "toward": 1.6303142329, "trend": 5.43140608963, "negat": 3.75852272727, "educ": 2.00733341763, "compar": 1.8662278123900002, "shortag": 11.388809182200001, "valid": 6.61224489796, "bug": 27.372413793099998, "retrain": 180.409090909, "side": 1.5989525632, "train": 1.9365698950999999, "avoid": 2.45986984816, "gaug": 20.538163001300003, "extrem": 2.36602086438, "continu": 1.13928955867, "lead": 1.2664326739, "period": 1.3430335843, "probabl": 2.64555907349, "scientist": 4.69426374926, "notebook": 40.1924050633, "into": 1.01502461479, "discoveri": 4.74902781932, "younger": 4.16802310318, "abov": 1.90382539873, "servic": 1.51300867245, "what": 1.25343439128, "local": 1.51720183486, "techniqu": 3.7293868921800004, "relationship": 2.39132399458, "overfit": 1323.0, "popul": 2.17807655371, "help": 1.39962972759, "affect": 2.4794627518400003, "clear": 1.85423966363, "xaxi": 1323.0, "base": 1.14628158845, "relat": 1.23750876919, "fact": 1.73375559681, "decid": 1.9257641921400002, "hold": 1.6551292744, "larg": 1.18574949585, "lower": 2.10055570257, "wrt": 1323.0, "leaki": 264.6, "onlin": 2.6051854282900004, "anyth": 4.58843930636, "much": 1.1942229577299999, "evalu": 6.9509632224199995, "henc": 5.390831918509999, "noisi": 62.2588235294, "about": 1.06486015159, "problem": 1.76674827509, "how": 1.60250328051, "sudden": 5.78993435449, "just": 1.33580143037, "xgboost": 1323.0, "simpli": 2.5192002538900002, "person": 1.40520446097, "check": 6.50655737705, "across": 1.7318642958400001, "complex": 2.34021226415, "noth": 3.46410648047, "articl": 2.01805008262, "them": 1.09876115994, "insight": 11.8037174721, "whi": 3.2566153846200003, "frank": 3.4520547945199995, "singl": 1.60948905109, "setvalid": 1323.0, "blind": 8.849498327760001, "scatter": 9.38852749852, "usual": 1.72508964468, "comparison": 4.9597000937199995, "mani": 1.04426757877, "the": 1.0, "age": 1.48623853211, "fun": 12.8863636364, "build": 1.6341739578, "analysi": 3.47852760736, "monitor": 6.05723006486, "display": 2.93456561922, "linear": 13.8776223776, "team": 2.2748244734200003, "hypothes": 20.644993497999998, "order": 1.24625166811, "leaderboard": 1323.0, "there": 1.04091266719, "exist": 1.4647107666799999, "inform": 1.5753125620200001, "origin": 1.13724928367, "right": 1.4054532577899999, "welltest": 1323.0, "correl": 13.1860465116, "either": 1.5830092731099998, "take": 1.13961668222, "follow": 1.04640126549, "might": 2.1561863370900003, "strategi": 4.44208170118, "further": 1.3618116315, "code": 3.8807137619199996, "hint": 15.2068965517, "high": 1.14777327935, "regress": 51.2129032258, "realli": 4.7476076555, "power": 1.3396337861799998, "also": 1.01476510067, "typic": 2.2541530597799997, "risk": 4.095975232200001, "target": 3.2189781021900004, "around": 1.21394708671, "mean": 1.44906900329, "fli": 4.35555555556, "becaus": 1.1495184997499999, "task": 3.88641370869, "minor": 2.23071518898, "encount": 4.13976531943, "over": 1.02525024217, "peopl": 1.21320495186, "zero": 8.75192943771, "machin": 4.02433460076, "captur": 2.88026124819, "rank": 2.52480916031, "threshold": 23.008695652199997, "variabl": 8.747107438019999, "actual": 1.87482286254, "calcul": 6.12972972973, "minut": 3.11233091551, "which": 1.005191845, "term": 1.39520168732, "other": 1.00992366412, "introduct": 2.7808723068799996, "one": 1.00627495722, "show": 1.26703910615, "lot": 4.40877534018, "custom": 3.6346153846199996, "seem": 2.29123971713, "bin": 22.3291139241, "outsid": 1.67450690855, "webbas": 1323.0, "get": 1.78562591385, "still": 1.1866357724799999, "like": 1.14918566775, "select": 2.02345144022, "drop": 2.4594887684, "tell": 3.36142282448, "detect": 5.41288782816, "part": 1.04330682789, "both": 1.05215720061, "analyt": 17.256521739100002, "identifi": 2.30187037843, "repeat": 2.8771293947099994, "access": 1.8734953976900002, "this": 1.00379362671, "time": 1.01127460348, "variat": 4.704, "engin": 2.47135740971, "chang": 1.1808985421, "similar": 1.37514075357, "differ": 1.23654490225, "same": 1.11857958148, "binari": 32.4, "most": 1.02096463023, "between": 1.03453668708, "low": 2.13072070863, "return": 1.39532431007, "instacart": 1323.0, "credit": 3.04312823462, "all": 1.01146788991, "top": 1.8387769284200002, "fortun": 6.211267605630001, "someth": 3.28152128979, "imput": 178.38202247200002, "that": 1.00398406375, "built": 1.99447236181, "rate": 2.14048806795, "more": 1.0171706817, "and": 1.00006299213, "leakag": 85.8162162162, "these": 1.07415426252, "life": 1.37051104972, "could": 1.2043695949, "befor": 1.10036041031, "comment": 3.05954904606, "standard": 1.8915763135900003, "can": 1.17626139142, "make": 1.0762660158600001, "way": 1.2190739461, "search": 3.2539454806299997, "onli": 1.0256476516600002, "each": 1.18974820144, "concentr": 3.16066095959, "permiss": 6.280063291139999, "packag": 7.828402366860001, "data": 3.37643555934, "qualiti": 2.9329392204, "featexp": 1323.0, "sinc": 1.08368600683, "bio": 42.336000000000006, "exampl": 1.50483412322, "aspect": 3.0893169877399997, "worth": 5.210370856580001, "understand": 2.96858638743, "differenti": 7.759530791789999, "direct": 1.22226499346, "import": 1.3401992233700002, "first": 1.00761614623, "everi": 1.47917637194, "nonlinear": 99.225, "use": 1.0296387573799999, "year": 1.0485436893200002, "lefthand": 1221.23076923, "easili": 3.6938110749199997, "down": 1.35889754344, "learn": 2.32275054865, "when": 1.02076769755}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  My secret sauce to be in top 2% of a Kaggle competition</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb My secret sauce to be in top 2% of a Kaggle competition Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/18/11-26-gleif-data-analyst.html\" rel=\"prev\" title=\"Global Legal Entity Identifier Foundation (GLEIF): Data Analyst [Frankfurt, Germany]\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/mathworks-3-challenges-companies-data-science.html\" rel=\"next\" title=\"3 Challenges for Companies Tackling Data Science\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=87753\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-87753 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 26-Nov, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/opinions.html\">Opinions</a> \u00bb My secret sauce to be in top 2% of a Kaggle competition (\u00a0<a href=\"/2018/n45.html\">18:n45</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">My secret sauce to be in top 2% of a Kaggle competition</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/18/11-26-gleif-data-analyst.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/11/mathworks-3-challenges-companies-data-science.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/competition\" rel=\"tag\">Competition</a>, <a href=\"https://www.kdnuggets.com/tag/data-science\" rel=\"tag\">Data Science</a>, <a href=\"https://www.kdnuggets.com/tag/kaggle\" rel=\"tag\">Kaggle</a></div>\n<br/>\n<p class=\"excerpt\">\n     A collection of top tips on ways to explore features and build better machine learning models, including feature engineering, identifying noisy features, leakage detection, model monitoring, and more.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/abhayspawar/\">Abhay Pawar</a>, Instacart</b>.</p>\n<p>Competing in kaggle competitions is fun and addictive! And over the last couple of years, I developed some standard ways to explore features and build better machine learning models. These simple, but powerful techniques helped me get a top 2% rank in\u00a0<a data-href=\"https://www.kaggle.com/c/instacart-market-basket-analysis\" href=\"https://www.kaggle.com/c/instacart-market-basket-analysis\">Instacart Market Basket Analysis</a>\u00a0competition and I use them outside of kaggle as well. So, let\u2019s get right into it!</p>\n<p>One of the most important aspects of building any supervised learning model on numeric data is to understand the features well.\u00a0Looking at partial dependence plots of a model helps you understand how the model\u2019s output changes with any feature.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/0*qC-ilcSNCHu-vCHK.png\" width=\"100%\"/></p>\n<p><strong><a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_partial_dependence.html\">source</a></strong></p>\n<p>But, the problem with these plots is that they are created using a trained model. If we could create these plots from train data directly, it could help us understand the underlying data better. In fact, it can help you with all the following things:</p>\n<ol>\n<li>Feature understanding</li>\n<li>Identifying noisy features (<strong>the most interesting part!</strong>)</li>\n<li>Feature engineering</li>\n<li>Feature importance</li>\n<li>Feature debugging</li>\n<li>Leakage detection and understanding</li>\n<li>Model monitoring</li>\n</ol>\n<p>In order to make it easily accessible, I decided to put these techniques into a python package\u00a0<a href=\"https://github.com/abhayspawar/featexp\">featexp</a>\u00a0and in this article, we\u2019ll see how it can be used for feature exploration. We\u2019ll use the application dataset from\u00a0<a href=\"https://www.kaggle.com/c/home-credit-default-risk/\">Home Credit Default Risk</a>\u00a0competition on Kaggle. The task of the competition is to predict defaulters using the data given about them.</p>\n<ol>\n<li><strong>Feature Understanding</strong></li>\n</ol>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*Y0SsQz-n2rt_XxkC7y0zdg.png\" width=\"60%\"/></center>\u00a0</p>\n<p><strong>Scatter plot of feature vs. target doesn\u2019t\u00a0help</strong></p>\n<p>If dependent variable (target) is binary, scatter plots don\u2019t work because all points lie either at 0 or 1. For continuous target, too many data points make it difficult to understand the target vs. feature trend. Featexp creates better plots which help with this problem. Let\u2019s try it out!</p>\n<p><script src=\"https://gist.github.com/abhayspawar/67e2e7e56a3c33515002985fd1ed9c33.js\"></script></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*_FqsA9_SdUca5_0s9Uua4Q.png\" width=\"100%\"/></p>\n<p><strong>Feature vs. target plot of DAYS_BIRTH (age)</strong></p>\n<p>Featexp creates equal population bins (X-axis) of a numeric feature. It then calculates target\u2019s mean in each bin and plots it in the left-hand side plot above. In our case, target\u2019s mean is nothing but default rate. The plot tells us that customers with high negative values for DAYS_BIRTH (higher age) have lower default rates. This makes sense since younger people are usually more likely to default. These plots help us understand what the feature is telling about customers and how it will affect the model. The plot on the right shows number of customers in each bin.</p>\n<ol start=\"2\">\n<li><strong> Identifying noisy features</strong></li>\n</ol>\n<p>Noisy features lead to overfitting and identifying them isn\u2019t easy. In featexp, you can pass a test set and compare feature trends in train/test to identify noisy ones. This test set is not the actual test set. Its your local test set/validation set for which you know target.</p>\n<p><script src=\"https://gist.github.com/abhayspawar/6caf7f31021ca21cda041b9b1987202b.js\"></script></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*tpjxrjbxhH-lJo0hbRerfg.png\" width=\"100%\"/></p>\n<p><strong>Comparison of feature trends in train and\u00a0test</strong></p>\n<p>Featexp calculates two metrics to display on these plots which help with gauging noisiness:</p>\n<ol>\n<li><strong>Trend correlation</strong>(seen in test plot): If a feature doesn\u2019t hold same trend w.r.t. target across train and evaluation sets, it can lead to overfitting. This happens because the model is learning something which is not applicable in test data. Trend correlation helps understand how similar train/test trends are and mean target values for bins in train &amp; test are used to calculate it. Feature above has 99% correlation. Doesn\u2019t seem noisy!</li>\n<li><strong>Trend changes</strong>: Sudden and repeated changes in trend direction could imply noisiness. But, such trend change can also happen because that bin has a very different population in terms of other features and hence, its default rate can\u2019t really be compared with other bins.</li>\n</ol>\n<p>Feature below is not holding the same trend and hence, has a low trend correlation of 85%. These two metrics can be used to drop noisy features.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*6lSWurF_qOzm1cMEJFuRmA.png\" width=\"100%\"/></p>\n<p>Example of noisy\u00a0feature</p>\n<p>Dropping low trend-correlation features works well when there are a lot of features and they are correlated with each other. It leads to less overfitting and other correlated features avoid information loss. It\u2019s also important to not drop too many important features as it might lead to a drop in performance.\u00a0<strong>Also, you can\u2019t identify these noisy features using feature importance because they could be fairly important and still be very noisy!</strong></p>\n<p>Using test data from a different time period works better because then you would be making sure if feature trend holds over time.</p>\n<p><strong><em>get_trend_stats()</em></strong><em>\u00a0</em>function in featexp returns a dataframe with trend correlation and changes for each feature.</p>\n<p><script src=\"https://gist.github.com/abhayspawar/45b0489c88476e6908b2679781ae5997.js\"></script></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*RuxmJA0iWrMRCVxNGlBidw.png\" width=\"100%\"/></p>\n<p><strong>Dataframe returned by\u00a0get_trend_stats()</strong></p>\n<p>Let\u2019s actually try dropping features with low trend-correlation in our data and see how results improve.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*UR-SlR1rZOjp0sjTIaPZ_A.png\" width=\"100%\"/></p>\n<p><strong>AUC for different feature selections using trend-correlation</strong></p>\n<p><strong>We can see that higher the trend-correlation threshold to drop features, higher is the leaderboard (LB) AUC.</strong>\u00a0Not dropping important features further improves LB AUC to 0.74. It\u2019s also interesting and concerning that test AUC doesn\u2019t change as much as LB AUC. Getting your validation strategy right such that local test AUC follows LB AUC is also important. Whole code can be found in\u00a0<a href=\"https://github.com/abhayspawar/featexp/blob/master/featexp_demo.ipynb\">featexp_demo</a>\u00a0notebook.</p>\n<ol start=\"3\">\n<li><strong> Feature Engineering</strong></li>\n</ol>\n<p>The insights that you get by looking at these plots help with creating better features. Just having a better understanding of data can lead to better feature engineering. But, in addition to this, it can also help you in improving the existing features. Let\u2019s look at another feature EXT_SOURCE_1:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*MQQrhVy5NjtD-7mrKT8jOA.png\" width=\"100%\"/></p>\n<p><strong>Feature vs. target plot of EXT_SOURCE_1</strong></p>\n<p>Customers having a high value of EXT_SOURCE_1 have low default rates. But, the first bin (~8% default rate) isn\u2019t following the feature trend (goes up and then down). It has only negative values around -99.985 and a large population. This probably implies that these are special values and hence, don\u2019t follow the feature trend. Fortunately, non-linear models won\u2019t have a problem learning this relationship. But, for linear models like logistic regression, such special values and nulls (which will be shown as a separate bin) should be imputed with a value from a bin with similar default rate instead of simply imputing with feature mean.</p>\n<ol start=\"4\">\n<li><strong> Feature importance</strong></li>\n</ol>\n<p>Featexp also helps you with gauging feature importance. DAYS_BIRTH and EXT_SOURCE_1 both have a good trend. But, population for EXT_SOURCE_1 is concentrated in special value bin implying that feature has the same information for most of the customers and hence, can\u2019t differentiate them well. This tells that it might not be as important as DAYS_BIRTH. Based on XGBoost model\u2019s feature importance, DAYS_BIRTH is actually more important than EXT_SOURCE_1.</p>\n<ol start=\"5\">\n<li><strong> Feature debugging</strong></li>\n</ol>\n<p>Looking at Featexp\u2019s plots helps you in capturing bugs in complex feature engineering codes by doing these two things:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*-NA-fc1LR1yo0JoHp8IFOw.png\" width=\"100%\"/></p>\n<p><strong>Zero variation features show only a single\u00a0bin</strong></p>\n<ol>\n<li>Checking if the feature\u2019s population distribution looks right. I\u2019ve personally encountered extreme cases like above numerous times due to minor bugs.</li>\n<li>Always hypothesize what the feature trend will look like before looking at these plots. Feature trend not looking like what you expected might hint towards some problem.\u00a0<strong>And frankly, this process of hypothesizing trends makes building ML models much more fun!</strong></li>\n<li><strong> Leakage Detection</strong></li>\n</ol>\n<p>Data leakage from target to features leads to overfitting. Leaky features have high feature importance. But, understanding why leakage is happening in a feature is difficult. Looking at featexp plots can help you with that.</p>\n<p>The feature below has 0% default rate in \u2018Nulls\u2019 bin and 100% in all other bins. Clearly, this is an extreme case of leakage. This feature has a value only when the customer has defaulted. Based on what the feature is, this could be because of a bug or the feature is actually populated only for defaulters (in which case it should be dropped).\u00a0<strong>Knowing what the problem is with leaky feature leads to quicker debugging.</strong></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*muwhOmAYJTjSZetBv1UOaA.png\" width=\"100%\"/></p>\n<p><strong>Understanding why a feature is\u00a0leaky</strong></p>\n<ol start=\"7\">\n<li><strong> Model Monitoring</strong></li>\n</ol>\n<p>Since featexp calculates trend correlation between two data sets, it can be easily used for model monitoring. Every time the model is re-trained, the new train data can be compared with a well-tested train data (typically train data from the first time you built the model). Trend correlation can help you monitor if anything has changed in feature w.r.t. its relationship with target.</p>\n<p>Doing these simple things have always helped me in building better models in real life and on kaggle. With featexp it takes 15 minutes to look at these plots and it\u2019s definitely worth it as you won\u2019t be flying blind after that.</p>\n<p><strong>Bio</strong>:\u00a0<a href=\"https://www.linkedin.com/in/abhayspawar/\">Abhay Pawar</a> currently works as a Senior Machine Learning Engineer at Instacart, in their Search &amp; Discovery team. He works on large scale machine learning problems which help Instacart in improving the quality of their service.</p>\n<p><a href=\"https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c\">Original</a>. Reposted with permission.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">on-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2018/09/how-many-data-scientists-are-there.html\">How many data scientists are there and is there a shortage?</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/05/introduction-deep-learning-tabular-data.html\">An Introduction to Deep Learning for Tabular Data</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/05/to-kaggle-or-not.html\">To Kaggle Or Not</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/18/11-26-gleif-data-analyst.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/11/mathworks-3-challenges-companies-data-science.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/11/opinions.html\">Opinions</a> \u00bb My secret sauce to be in top 2% of a Kaggle competition (\u00a0<a href=\"/2018/n45.html\">18:n45</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556392303\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.690 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 15:11:43 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "abhay", "pawar", "instacart", "compet", "kaggl", "competit", "fun", "and", "addict", "and", "over", "the", "last", "coupl", "year", "develop", "some", "standard", "way", "explor", "featur", "and", "build", "better", "machin", "learn", "model", "these", "simpl", "but", "power", "techniqu", "help", "get", "top", "num", "rank", "instacart", "market", "basket", "analysi", "competit", "and", "use", "them", "outsid", "kaggl", "well", "let", "get", "right", "into", "one", "the", "most", "import", "aspect", "build", "ani", "supervis", "learn", "model", "numer", "data", "understand", "the", "featur", "well", "look", "partial", "depend", "plot", "model", "help", "understand", "how", "the", "model", "output", "chang", "with", "ani", "featur", "sourc", "but", "the", "problem", "with", "these", "plot", "that", "they", "are", "creat", "use", "train", "model", "could", "creat", "these", "plot", "from", "train", "data", "direct", "could", "help", "understand", "the", "under", "data", "better", "fact", "can", "help", "with", "all", "the", "follow", "thing", "featur", "understand", "identifi", "noisi", "featur", "the", "most", "interest", "part", "featur", "engin", "featur", "import", "featur", "debug", "leakag", "detect", "and", "understand", "model", "monitor", "order", "make", "easili", "access", "decid", "put", "these", "techniqu", "into", "python", "packag", "featexp", "and", "this", "articl", "see", "how", "can", "use", "for", "featur", "explor", "use", "the", "applic", "dataset", "from", "home", "credit", "default", "risk", "competit", "kaggl", "the", "task", "the", "competit", "predict", "default", "use", "the", "data", "given", "about", "them", "featur", "understand", "scatter", "plot", "featur", "target", "help", "depend", "variabl", "target", "binari", "scatter", "plot", "work", "becaus", "all", "point", "lie", "either", "num", "num", "for", "continu", "target", "too", "mani", "data", "point", "make", "difficult", "understand", "the", "target", "featur", "trend", "featexp", "creat", "better", "plot", "which", "help", "with", "this", "problem", "let", "tri", "out", "featur", "target", "plot", "age", "featexp", "creat", "equal", "popul", "bin", "xaxi", "numer", "featur", "then", "calcul", "target", "mean", "each", "bin", "and", "plot", "the", "lefthand", "side", "plot", "abov", "our", "case", "target", "mean", "noth", "but", "default", "rate", "the", "plot", "tell", "that", "custom", "with", "high", "negat", "valu", "for", "higher", "age", "have", "lower", "default", "rate", "this", "make", "sens", "sinc", "younger", "peopl", "are", "usual", "more", "like", "default", "these", "plot", "help", "understand", "what", "the", "featur", "tell", "about", "custom", "and", "how", "will", "affect", "the", "model", "the", "plot", "the", "right", "show", "number", "custom", "each", "bin", "identifi", "noisi", "featur", "noisi", "featur", "lead", "overfit", "and", "identifi", "them", "easi", "featexp", "can", "pass", "test", "set", "and", "compar", "featur", "trend", "traintest", "identifi", "noisi", "one", "this", "test", "set", "not", "the", "actual", "test", "set", "local", "test", "setvalid", "set", "for", "which", "know", "target", "comparison", "featur", "trend", "train", "and", "test", "featexp", "calcul", "two", "metric", "display", "these", "plot", "which", "help", "with", "gaug", "noisi", "trend", "correl", "seen", "test", "plot", "featur", "hold", "same", "trend", "wrt", "target", "across", "train", "and", "evalu", "set", "can", "lead", "overfit", "this", "happen", "becaus", "the", "model", "learn", "someth", "which", "not", "applic", "test", "data", "trend", "correl", "help", "understand", "how", "similar", "traintest", "trend", "are", "and", "mean", "target", "valu", "for", "bin", "train", "test", "are", "use", "calcul", "featur", "abov", "has", "num", "correl", "seem", "noisi", "trend", "chang", "sudden", "and", "repeat", "chang", "trend", "direct", "could", "impli", "noisi", "but", "such", "trend", "chang", "can", "also", "happen", "becaus", "that", "bin", "has", "veri", "differ", "popul", "term", "other", "featur", "and", "henc", "default", "rate", "can", "realli", "compar", "with", "other", "bin", "featur", "below", "not", "hold", "the", "same", "trend", "and", "henc", "has", "low", "trend", "correl", "num", "these", "two", "metric", "can", "use", "drop", "noisi", "featur", "exampl", "noisi", "featur", "drop", "low", "trendcorrel", "featur", "work", "well", "when", "there", "are", "lot", "featur", "and", "they", "are", "correl", "with", "each", "other", "lead", "less", "overfit", "and", "other", "correl", "featur", "avoid", "inform", "loss", "also", "import", "not", "drop", "too", "mani", "import", "featur", "might", "lead", "drop", "perform", "also", "can", "identifi", "these", "noisi", "featur", "use", "featur", "import", "becaus", "they", "could", "fair", "import", "and", "still", "veri", "noisi", "use", "test", "data", "from", "differ", "time", "period", "work", "better", "becaus", "then", "would", "make", "sure", "featur", "trend", "hold", "over", "time", "function", "featexp", "return", "datafram", "with", "trend", "correl", "and", "chang", "for", "each", "featur", "datafram", "return", "let", "actual", "tri", "drop", "featur", "with", "low", "trendcorrel", "our", "data", "and", "see", "how", "result", "improv", "for", "differ", "featur", "select", "use", "trendcorrel", "can", "see", "that", "higher", "the", "trendcorrel", "threshold", "drop", "featur", "higher", "the", "leaderboard", "not", "drop", "import", "featur", "further", "improv", "num", "also", "interest", "and", "concern", "that", "test", "chang", "much", "get", "valid", "strategi", "right", "such", "that", "local", "test", "follow", "also", "import", "whole", "code", "can", "found", "featexpdemo", "notebook", "featur", "engin", "the", "insight", "that", "get", "look", "these", "plot", "help", "with", "creat", "better", "featur", "just", "have", "better", "understand", "data", "can", "lead", "better", "featur", "engin", "but", "addit", "this", "can", "also", "help", "improv", "the", "exist", "featur", "let", "look", "anoth", "featur", "featur", "target", "plot", "custom", "have", "high", "valu", "have", "low", "default", "rate", "but", "the", "first", "bin", "num", "default", "rate", "follow", "the", "featur", "trend", "goe", "and", "then", "down", "has", "onli", "negat", "valu", "around", "num", "and", "larg", "popul", "this", "probabl", "impli", "that", "these", "are", "special", "valu", "and", "henc", "follow", "the", "featur", "trend", "fortun", "nonlinear", "model", "won", "have", "problem", "learn", "this", "relationship", "but", "for", "linear", "model", "like", "logist", "regress", "such", "special", "valu", "and", "null", "which", "will", "shown", "separ", "bin", "should", "imput", "with", "valu", "from", "bin", "with", "similar", "default", "rate", "instead", "simpli", "imput", "with", "featur", "mean", "featur", "import", "featexp", "also", "help", "with", "gaug", "featur", "import", "and", "both", "have", "good", "trend", "but", "popul", "for", "concentr", "special", "valu", "bin", "impli", "that", "featur", "has", "the", "same", "inform", "for", "most", "the", "custom", "and", "henc", "can", "differenti", "them", "well", "this", "tell", "that", "might", "not", "import", "base", "xgboost", "model", "featur", "import", "actual", "more", "import", "than", "featur", "debug", "look", "featexp", "plot", "help", "captur", "bug", "complex", "featur", "engin", "code", "these", "two", "thing", "zero", "variat", "featur", "show", "onli", "singl", "bin", "check", "the", "featur", "popul", "distribut", "look", "right", "person", "encount", "extrem", "case", "like", "abov", "numer", "time", "due", "minor", "bug", "alway", "hypothes", "what", "the", "featur", "trend", "will", "look", "like", "befor", "look", "these", "plot", "featur", "trend", "not", "look", "like", "what", "expect", "might", "hint", "toward", "some", "problem", "and", "frank", "this", "process", "hypothes", "trend", "make", "build", "model", "much", "more", "fun", "leakag", "detect", "data", "leakag", "from", "target", "featur", "lead", "overfit", "leaki", "featur", "have", "high", "featur", "import", "but", "understand", "whi", "leakag", "happen", "featur", "difficult", "look", "featexp", "plot", "can", "help", "with", "that", "the", "featur", "below", "has", "num", "default", "rate", "null", "bin", "and", "num", "all", "other", "bin", "clear", "this", "extrem", "case", "leakag", "this", "featur", "has", "valu", "onli", "when", "the", "custom", "has", "default", "base", "what", "the", "featur", "this", "could", "becaus", "bug", "the", "featur", "actual", "popul", "onli", "for", "default", "which", "case", "should", "drop", "know", "what", "the", "problem", "with", "leaki", "featur", "lead", "quicker", "debug", "understand", "whi", "featur", "leaki", "model", "monitor", "sinc", "featexp", "calcul", "trend", "correl", "between", "two", "data", "set", "can", "easili", "use", "for", "model", "monitor", "everi", "time", "the", "model", "retrain", "the", "new", "train", "data", "can", "compar", "with", "welltest", "train", "data", "typic", "train", "data", "from", "the", "first", "time", "built", "the", "model", "trend", "correl", "can", "help", "monitor", "anyth", "has", "chang", "featur", "wrt", "relationship", "with", "target", "these", "simpl", "thing", "have", "alway", "help", "build", "better", "model", "real", "life", "and", "kaggl", "with", "featexp", "take", "num", "minut", "look", "these", "plot", "and", "definit", "worth", "won", "fli", "blind", "after", "that", "bio", "abhay", "pawar", "current", "work", "senior", "machin", "learn", "engin", "instacart", "their", "search", "discoveri", "team", "work", "larg", "scale", "machin", "learn", "problem", "which", "help", "instacart", "improv", "the", "qualiti", "their", "servic", "origin", "repost", "with", "permiss", "resourc", "onlin", "and", "webbas", "analyt", "data", "mine", "data", "scienc", "machin", "learn", "educ", "softwar", "for", "analyt", "data", "scienc", "data", "mine", "and", "machin", "learn", "relat", "how", "mani", "data", "scientist", "are", "there", "and", "there", "shortag", "introduct", "deep", "learn", "for", "tabular", "data", "kaggl", "not"], "timestamp_scraper": 1556392303.431816, "title": "My secret sauce to be in top 2% of a Kaggle competition", "read_time": 437.4, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/abhayspawar/\">Abhay Pawar</a>, Instacart</b>.</p>\n<p>Competing in kaggle competitions is fun and addictive! And over the last couple of years, I developed some standard ways to explore features and build better machine learning models. These simple, but powerful techniques helped me get a top 2% rank in\u00a0<a data-href=\"https://www.kaggle.com/c/instacart-market-basket-analysis\" href=\"https://www.kaggle.com/c/instacart-market-basket-analysis\">Instacart Market Basket Analysis</a>\u00a0competition and I use them outside of kaggle as well. So, let\u2019s get right into it!</p>\n<p>One of the most important aspects of building any supervised learning model on numeric data is to understand the features well.\u00a0Looking at partial dependence plots of a model helps you understand how the model\u2019s output changes with any feature.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/0*qC-ilcSNCHu-vCHK.png\" width=\"100%\"/></p>\n<p><strong><a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_partial_dependence.html\">source</a></strong></p>\n<p>But, the problem with these plots is that they are created using a trained model. If we could create these plots from train data directly, it could help us understand the underlying data better. In fact, it can help you with all the following things:</p>\n<ol>\n<li>Feature understanding</li>\n<li>Identifying noisy features (<strong>the most interesting part!</strong>)</li>\n<li>Feature engineering</li>\n<li>Feature importance</li>\n<li>Feature debugging</li>\n<li>Leakage detection and understanding</li>\n<li>Model monitoring</li>\n</ol>\n<p>In order to make it easily accessible, I decided to put these techniques into a python package\u00a0<a href=\"https://github.com/abhayspawar/featexp\">featexp</a>\u00a0and in this article, we\u2019ll see how it can be used for feature exploration. We\u2019ll use the application dataset from\u00a0<a href=\"https://www.kaggle.com/c/home-credit-default-risk/\">Home Credit Default Risk</a>\u00a0competition on Kaggle. The task of the competition is to predict defaulters using the data given about them.</p>\n<ol>\n<li><strong>Feature Understanding</strong></li>\n</ol>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*Y0SsQz-n2rt_XxkC7y0zdg.png\" width=\"60%\"/></center>\u00a0</p>\n<p><strong>Scatter plot of feature vs. target doesn\u2019t\u00a0help</strong></p>\n<p>If dependent variable (target) is binary, scatter plots don\u2019t work because all points lie either at 0 or 1. For continuous target, too many data points make it difficult to understand the target vs. feature trend. Featexp creates better plots which help with this problem. Let\u2019s try it out!</p>\n<p><script src=\"https://gist.github.com/abhayspawar/67e2e7e56a3c33515002985fd1ed9c33.js\"></script></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*_FqsA9_SdUca5_0s9Uua4Q.png\" width=\"100%\"/></p>\n<p><strong>Feature vs. target plot of DAYS_BIRTH (age)</strong></p>\n<p>Featexp creates equal population bins (X-axis) of a numeric feature. It then calculates target\u2019s mean in each bin and plots it in the left-hand side plot above. In our case, target\u2019s mean is nothing but default rate. The plot tells us that customers with high negative values for DAYS_BIRTH (higher age) have lower default rates. This makes sense since younger people are usually more likely to default. These plots help us understand what the feature is telling about customers and how it will affect the model. The plot on the right shows number of customers in each bin.</p>\n<ol start=\"2\">\n<li><strong> Identifying noisy features</strong></li>\n</ol>\n<p>Noisy features lead to overfitting and identifying them isn\u2019t easy. In featexp, you can pass a test set and compare feature trends in train/test to identify noisy ones. This test set is not the actual test set. Its your local test set/validation set for which you know target.</p>\n<p><script src=\"https://gist.github.com/abhayspawar/6caf7f31021ca21cda041b9b1987202b.js\"></script></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*tpjxrjbxhH-lJo0hbRerfg.png\" width=\"100%\"/></p>\n<p><strong>Comparison of feature trends in train and\u00a0test</strong></p>\n<p>Featexp calculates two metrics to display on these plots which help with gauging noisiness:</p>\n<ol>\n<li><strong>Trend correlation</strong>(seen in test plot): If a feature doesn\u2019t hold same trend w.r.t. target across train and evaluation sets, it can lead to overfitting. This happens because the model is learning something which is not applicable in test data. Trend correlation helps understand how similar train/test trends are and mean target values for bins in train &amp; test are used to calculate it. Feature above has 99% correlation. Doesn\u2019t seem noisy!</li>\n<li><strong>Trend changes</strong>: Sudden and repeated changes in trend direction could imply noisiness. But, such trend change can also happen because that bin has a very different population in terms of other features and hence, its default rate can\u2019t really be compared with other bins.</li>\n</ol>\n<p>Feature below is not holding the same trend and hence, has a low trend correlation of 85%. These two metrics can be used to drop noisy features.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*6lSWurF_qOzm1cMEJFuRmA.png\" width=\"100%\"/></p>\n<p>Example of noisy\u00a0feature</p>\n<p>Dropping low trend-correlation features works well when there are a lot of features and they are correlated with each other. It leads to less overfitting and other correlated features avoid information loss. It\u2019s also important to not drop too many important features as it might lead to a drop in performance.\u00a0<strong>Also, you can\u2019t identify these noisy features using feature importance because they could be fairly important and still be very noisy!</strong></p>\n<p>Using test data from a different time period works better because then you would be making sure if feature trend holds over time.</p>\n<p><strong><em>get_trend_stats()</em></strong><em>\u00a0</em>function in featexp returns a dataframe with trend correlation and changes for each feature.</p>\n<p><script src=\"https://gist.github.com/abhayspawar/45b0489c88476e6908b2679781ae5997.js\"></script></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*RuxmJA0iWrMRCVxNGlBidw.png\" width=\"100%\"/></p>\n<p><strong>Dataframe returned by\u00a0get_trend_stats()</strong></p>\n<p>Let\u2019s actually try dropping features with low trend-correlation in our data and see how results improve.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*UR-SlR1rZOjp0sjTIaPZ_A.png\" width=\"100%\"/></p>\n<p><strong>AUC for different feature selections using trend-correlation</strong></p>\n<p><strong>We can see that higher the trend-correlation threshold to drop features, higher is the leaderboard (LB) AUC.</strong>\u00a0Not dropping important features further improves LB AUC to 0.74. It\u2019s also interesting and concerning that test AUC doesn\u2019t change as much as LB AUC. Getting your validation strategy right such that local test AUC follows LB AUC is also important. Whole code can be found in\u00a0<a href=\"https://github.com/abhayspawar/featexp/blob/master/featexp_demo.ipynb\">featexp_demo</a>\u00a0notebook.</p>\n<ol start=\"3\">\n<li><strong> Feature Engineering</strong></li>\n</ol>\n<p>The insights that you get by looking at these plots help with creating better features. Just having a better understanding of data can lead to better feature engineering. But, in addition to this, it can also help you in improving the existing features. Let\u2019s look at another feature EXT_SOURCE_1:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*MQQrhVy5NjtD-7mrKT8jOA.png\" width=\"100%\"/></p>\n<p><strong>Feature vs. target plot of EXT_SOURCE_1</strong></p>\n<p>Customers having a high value of EXT_SOURCE_1 have low default rates. But, the first bin (~8% default rate) isn\u2019t following the feature trend (goes up and then down). It has only negative values around -99.985 and a large population. This probably implies that these are special values and hence, don\u2019t follow the feature trend. Fortunately, non-linear models won\u2019t have a problem learning this relationship. But, for linear models like logistic regression, such special values and nulls (which will be shown as a separate bin) should be imputed with a value from a bin with similar default rate instead of simply imputing with feature mean.</p>\n<ol start=\"4\">\n<li><strong> Feature importance</strong></li>\n</ol>\n<p>Featexp also helps you with gauging feature importance. DAYS_BIRTH and EXT_SOURCE_1 both have a good trend. But, population for EXT_SOURCE_1 is concentrated in special value bin implying that feature has the same information for most of the customers and hence, can\u2019t differentiate them well. This tells that it might not be as important as DAYS_BIRTH. Based on XGBoost model\u2019s feature importance, DAYS_BIRTH is actually more important than EXT_SOURCE_1.</p>\n<ol start=\"5\">\n<li><strong> Feature debugging</strong></li>\n</ol>\n<p>Looking at Featexp\u2019s plots helps you in capturing bugs in complex feature engineering codes by doing these two things:</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*-NA-fc1LR1yo0JoHp8IFOw.png\" width=\"100%\"/></p>\n<p><strong>Zero variation features show only a single\u00a0bin</strong></p>\n<ol>\n<li>Checking if the feature\u2019s population distribution looks right. I\u2019ve personally encountered extreme cases like above numerous times due to minor bugs.</li>\n<li>Always hypothesize what the feature trend will look like before looking at these plots. Feature trend not looking like what you expected might hint towards some problem.\u00a0<strong>And frankly, this process of hypothesizing trends makes building ML models much more fun!</strong></li>\n<li><strong> Leakage Detection</strong></li>\n</ol>\n<p>Data leakage from target to features leads to overfitting. Leaky features have high feature importance. But, understanding why leakage is happening in a feature is difficult. Looking at featexp plots can help you with that.</p>\n<p>The feature below has 0% default rate in \u2018Nulls\u2019 bin and 100% in all other bins. Clearly, this is an extreme case of leakage. This feature has a value only when the customer has defaulted. Based on what the feature is, this could be because of a bug or the feature is actually populated only for defaulters (in which case it should be dropped).\u00a0<strong>Knowing what the problem is with leaky feature leads to quicker debugging.</strong></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/1*muwhOmAYJTjSZetBv1UOaA.png\" width=\"100%\"/></p>\n<p><strong>Understanding why a feature is\u00a0leaky</strong></p>\n<ol start=\"7\">\n<li><strong> Model Monitoring</strong></li>\n</ol>\n<p>Since featexp calculates trend correlation between two data sets, it can be easily used for model monitoring. Every time the model is re-trained, the new train data can be compared with a well-tested train data (typically train data from the first time you built the model). Trend correlation can help you monitor if anything has changed in feature w.r.t. its relationship with target.</p>\n<p>Doing these simple things have always helped me in building better models in real life and on kaggle. With featexp it takes 15 minutes to look at these plots and it\u2019s definitely worth it as you won\u2019t be flying blind after that.</p>\n<p><strong>Bio</strong>:\u00a0<a href=\"https://www.linkedin.com/in/abhayspawar/\">Abhay Pawar</a> currently works as a Senior Machine Learning Engineer at Instacart, in their Search &amp; Discovery team. He works on large scale machine learning problems which help Instacart in improving the quality of their service.</p>\n<p><a href=\"https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c\">Original</a>. Reposted with permission.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">on-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2018/09/how-many-data-scientists-are-there.html\">How many data scientists are there and is there a shortage?</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/05/introduction-deep-learning-tabular-data.html\">An Introduction to Deep Learning for Tabular Data</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/05/to-kaggle-or-not.html\">To Kaggle Or Not</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}