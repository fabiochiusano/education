{"content": "Facebook has again been criticized for failing to remove\u00a0child exploitation imagery from its platform following a BBC investigation into its\u00a0system for reporting inappropriate content. Last year \u00a0the news organization reported that\u00a0closed Facebook groups were being used by pedophiles to share images of child exploitation. At the time\u00a0Facebook\u2019s head of public policy told it he was committed to removing \u201ccontent that shouldn\u2019t be there\u201d, and Facebook has\u00a0since told the BBC\u00a0it has\u00a0improved its reporting system. However,\u00a0in a follow-up article\u00a0published today, the\u00a0BBC again\u00a0 reports \u00a0finding sexualized images of children being shared on Facebook \u2014 the vast majority of which the social networking giant failed to remove after the BBC initially reported\u00a0them. The\u00a0BBC said\u00a0it used the Facebook report button to alert the company to 100 images that\u00a0appeared to break its guidelines against obscene and/or sexually suggestive content\u00a0\u2014 including from pages that it said were explicitly for men with a sexual interest in children. Of the 100 reported images only 18 were removed by Facebook, according to the BBC. It also found\u00a0five convicted pedophiles with profiles and reported them to Facebook via its own system\u00a0but says none of the accounts were taken down\u00a0\u2014 despite Facebook\u2019s own rules forbidding convicted sex offenders from having accounts. In response to the report, the chairman of the UK House of Commons\u2019 media committee, Damian Collins, told the BBC he has\u00a0\u201cgrave doubts\u201d about the effectiveness of Facebook\u2019s\u00a0content moderation systems. \u201cI think it raises the question of how can users make effective complaints to Facebook about content that is disturbing, shouldn\u2019t be on the site, and have confidence that that will be acted upon,\u201d he said. In a further twist,\u00a0the news organization was subsequently reported to the police by Facebook after sharing some of the reported images directly with Facebook when it asked to send\u00a0examples of reported content that had not been removed. TechCrunch understands Facebook\u00a0was following CEOP guidelines at this point \u2014 although the BBC\u00a0claims it only sent images after being asked by Facebook to share examples of reported content. However viewing or sharing child exploitation images is illegal in the UK. The BBC would have to have sent Facebook links to illegal\u00a0content, rather than shared images directly to avoid being reported \u2014 so it\u2019s possible this aspect of the story boils down to a miscommunication. Facebook declined to answer our\u00a0questions \u2014 and declined to be interviewed on a flagship BBC news program about its content moderation problems \u2014 but in\u00a0an emailed statement UK policy director, Simon Milner, said: \u201cWe have carefully reviewed the content referred to us and have now removed all items that were illegal or against our standards. This content is no longer on our platform. We take this matter extremely seriously and we continue to improve our reporting and take-down measures. Facebook has been recognized as one of the best platforms on the internet for child safety.\u201d \u201cIt is against the law for anyone to distribute images of child exploitation. When the BBC sent us such images we followed our industry\u2019s standard practice and reported them to CEOP. We also reported the child exploitation images that had been shared on our own platform. This matter is now in the hands of the authorities,\u201d he added. The wider issue here is that Facebook\u2019s content moderation system remains\u00a0very clearly very far from perfect. And contextual content moderation is evidently a vast problem that requires far more resources\u00a0that are being devoted to it by Facebook. Even if the company\u00a0employs \u201cthousands\u201d of human moderators, distributed\u00a0in offices\u00a0around\u00a0the world (such as Dublin for European content) to ensure 24/7 availability, it\u2019s\u00a0still a drop in the ocean for a platform with more than a billion active users sharing multiple types of content on an ongoing basis. Technology solutions can\u00a0be part of the solution \u2014 such as Microsoft\u2019s PhotoDNA cloud service , which\u00a0can identify known child abuse images, for example \u2014 but such systems can\u2019t\u00a0help identify\u00a0unknown obscene material. It\u2019s a problem that\u00a0necessitates\u00a0human-moderation and enough human moderators to review user reports in a timely fashion so that problem content can be identified accurately and removed promptly \u2014 in other words, the opposite of what appears to have\u00a0happened in this instance. Facebook\u2019s leadership cannot be accused of being\u00a0blind to\u00a0concerns about its content moderation failures. Indeed,\u00a0CEO Mark Zuckerberg recently discussed \u00a0the issue in an open letter \u2014 conceding the company needs to \u201cdo more\u201d. He also talked about his\u00a0hope that technology will be able to take a bigger role in fixing\u00a0the problem in future, arguing that\u00a0\u201cartificial intelligence can help provide a better approach\u201d, and saying\u00a0Facebook is working on AI-powered content flagging systems to scale to the ever-growing challenge \u2014 although he also cautioned these will take \u201cmany years to fully develop\u201d. And that\u2019s really the problem in a nutshell. Facebook is not putting in the resources needed to fix the current problem it has with moderation \u2014 even as\u00a0it directs resources into trying to come up with possible future solutions where AI-moderation can be deployed at scale. But if Zuckerberg wants to do more right now, the simple fix is to employ more humans\u00a0to review and act on reports.", "title_html": "<h1 class=\"article__title\">Facebook\u2019s content moderation system under fire again for child safety failures</h1> ", "url": "https://beta.techcrunch.com/2017/03/07/facebooks-content-moderation-system-under-fire-for-child-safety-failures", "tfidf": {"tfidf": {"after": 3.06210621063, "mark": 1.5079787234, "milner": 138.052173913, "can": 9.41009113136, "failur": 3.28559602649, "understand": 2.96858638743, "unknown": 3.77281368821, "evergrow": 1058.4, "bigger": 13.23, "shouldn": 2116.8, "wider": 6.710059171599999, "here": 2.42307692308, "accus": 4.00302571861, "five": 1.37740760021, "report": 25.9055307454, "microsoft": 24.8450704225, "were": 5.1229428848000005, "alert": 13.6041131105, "would": 1.0828729281799998, "human": 5.68964281449, "photodna": 1058.4, "been": 4.095711060959999, "use": 2.0592775147599998, "care": 2.49426551453, "about": 5.324300757950001, "evid": 2.24872521246, "imageri": 19.7955112219, "say": 3.5088960106, "have": 7.104263887979998, "nutshel": 345.13043478300006, "techcrunch": 1058.4, "resourc": 8.84621099553, "internet": 4.98461538462, "zuckerberg": 2116.8, "standard": 3.7831526271800007, "approach": 2.07556543339, "world": 1.11340206186, "statement": 3.42228928648, "them": 3.29628347982, "remain": 1.16598119859, "email": 33.4936708861, "serious": 2.583984375, "scale": 7.493981590739999, "item": 5.07869481766, "flag": 5.95275590551, "realli": 4.7476076555, "measur": 2.41093394077, "point": 1.25990000794, "conced": 18.102622577, "multipl": 2.74813917258, "articl": 2.01805008262, "how": 1.60250328051, "billion": 4.8669527897, "news": 6.24547600314, "basi": 2.42122922068, "children": 3.82969484984, "had": 2.0951501154799996, "giant": 6.23566378633, "distribut": 5.479206212259999, "found": 1.11387076405, "blind": 8.849498327760001, "word": 1.7965372864099998, "interest": 1.60331246213, "abl": 1.8208510150200001, "mani": 1.04426757877, "miscommun": 299.547169811, "exploit": 28.9708029197, "open": 1.24556723678, "organ": 3.2774566474, "site": 1.9721739130400002, "forbid": 21.8376891334, "publish": 1.36885669943, "safeti": 4.4235162998, "thousand": 2.4767550702000003, "director": 2.62630272953, "will": 3.67443295788, "initi": 1.35, "claim": 1.52697893623, "damian": 114.215827338, "but": 4.06529671596, "need": 2.8745247148199997, "our": 14.14553014554, "followup": 466.941176471, "longer": 2.02319357716, "moder": 43.58544955384, "where": 1.06715063521, "devot": 5.0657306956, "takedown": 567.0, "doubt": 5.31325301205, "possibl": 2.8347468976, "industri": 2.02319357716, "review": 6.629732739420001, "best": 1.5828514456600002, "disturb": 9.08757870635, "ask": 4.3489932886, "has": 6.261898501199999, "interview": 3.3981164383599998, "pedophil": 1134.0, "cloud": 10.6193979933, "take": 3.4188500466600003, "inappropri": 21.6, "follow": 3.1392037964699995, "now": 3.4823426189999998, "subsequ": 1.7534791252500002, "further": 1.3618116315, "profil": 4.8314059647, "prompt": 4.44456886898, "ensur": 3.4127257093700005, "than": 2.0655737705, "child": 22.437310720790002, "declin": 4.8079951544599995, "recogn": 2.54954231572, "break": 2.42863698944, "issu": 2.87843350558, "deploy": 7.41869158879, "also": 4.05906040268, "offic": 1.58887109688, "that": 18.0717131475, "critic": 1.67010309278, "around": 1.21394708671, "view": 1.6407606448899998, "fashion": 4.85207823961, "far": 3.42044597652, "ocean": 5.35989196489, "materi": 2.13014893332, "major": 1.14852058164, "necessit": 23.450516986700002, "law": 1.7973508434299998, "imag": 32.41653905052, "technolog": 5.206953099380001, "caution": 21.2815013405, "the": 49.0, "polici": 5.05927342256, "not": 3.04702194357, "solut": 14.183442525299998, "stori": 2.02396736359, "happen": 2.96359902931, "challeng": 2.55816951337, "said": 6.19007700556, "contextu": 76.6956521739, "problem": 12.36723792563, "ongo": 6.04569687738, "sinc": 1.08368600683, "system": 9.71178886657, "obscen": 106.55033557040001, "act": 2.8636363636400004, "howev": 2.1890382626599996, "last": 1.2117234010100002, "share": 14.852999649200001, "although": 2.2993699761, "employ": 4.33060556464, "opposit": 2.4663663197099996, "still": 1.1866357724799999, "role": 1.55327267391, "which": 2.01038369, "chairman": 6.01135933359, "upon": 1.60331246213, "activ": 1.46403541129, "practic": 1.70434782609, "respons": 1.5066907089300001, "complaint": 10.1965317919, "simpl": 3.3981164383599998, "appear": 2.6429165972999997, "other": 1.00992366412, "refer": 1.30024570025, "offend": 14.8791002812, "provid": 1.21552714187, "one": 1.00627495722, "known": 1.0859097127200001, "hope": 2.50884955752, "accord": 1.27589809531, "rais": 1.9733996271, "develop": 1.1955719557200002, "some": 1.04036697248, "such": 4.24605509496, "facebook": 656.7410071935, "explicit": 5.819648093840001, "hand": 1.6152202665600002, "via": 2.2978723404299997, "talk": 3.0303493033, "convict": 13.39746835444, "network": 2.59369384088, "intellig": 4.19334389857, "andor": 690.260869565, "letter": 2.42715181165, "drop": 2.4594887684, "fix": 13.303910614529999, "tri": 1.8544562551099997, "part": 1.04330682789, "concern": 1.8852867830400002, "servic": 1.51300867245, "confid": 6.327620565959999, "aipow": 1058.4, "despit": 1.60606980273, "content": 63.7590361446, "recent": 1.54405757635, "anyon": 5.37440758294, "leadership": 4.03661327231, "platform": 31.166077738499997, "media": 2.59369384088, "more": 5.085853408499999, "this": 6.02276176026, "abus": 6.28503562945, "think": 2.90715986083, "and": 14.000881889819999, "from": 4.00226885988, "account": 3.8892699657, "answer": 4.64890190337, "vast": 8.11241696474, "work": 1.11520089913, "num": 4.00126016004, "common": 1.4025974025999999, "instanc": 3.2572835453400004, "put": 1.65806788512, "for": 8.00252032008, "fail": 3.8562059752199995, "all": 1.01146788991, "polic": 3.15, "fulli": 2.79015817223, "illeg": 16.84754156349, "with": 6.007189253939998, "requir": 1.52844902282, "program": 2.02139037433, "there": 1.04091266719, "are": 1.02990593578, "includ": 1.0190641247799999, "better": 2.0065722952500002, "compani": 4.6570841889, "commit": 2.8860207235, "european": 1.96290801187, "current": 1.5325803649, "author": 1.4229631621399998, "sent": 6.98050710831, "rule": 1.7415533128599998, "today": 1.74961428257, "public": 1.22424429365, "futur": 3.7154224198400003, "improv": 4.08753861998, "dublin": 18.5034965035, "veri": 2.51760228354, "discuss": 2.19676214197, "guidelin": 27.161676646799997, "these": 1.07415426252, "want": 1.99698113208, "humanmoder": 1058.4, "artifici": 8.31639601886, "question": 4.4081632653, "type": 2.0281042411900003, "boil": 23.730941704, "again": 3.01767724768, "none": 4.06555697823, "aimoder": 1058.4, "close": 1.2848818387799998, "year": 2.0970873786400004, "group": 1.20996875238, "even": 2.32922535212, "avail": 1.7288467821, "collin": 9.84863523573, "page": 2.03669018602, "make": 1.0762660158600001, "men": 1.86776470588, "onli": 2.0512953033200003, "grave": 6.75574468085, "told": 9.46314325452, "suggest": 1.7571665744299998, "avoid": 2.45986984816, "accur": 5.768895348840001, "flagship": 19.2203389831, "investig": 3.11721971333, "link": 2.15151104486, "extrem": 2.36602086438, "his": 1.0943682360200002, "continu": 1.13928955867, "hous": 1.4624170965399999, "taken": 1.6012102874399998, "matter": 4.89546716004, "time": 2.02254920696, "perfect": 4.48601299802, "rather": 1.55692850838, "into": 2.03004922958, "come": 1.32831325301, "exampl": 4.51450236966, "aspect": 3.0893169877399997, "effect": 2.7926121372000003, "send": 3.75053153792, "right": 1.4054532577899999, "identifi": 6.90561113529, "sex": 6.432739059969999, "direct": 3.66679498038, "simon": 4.94579439252, "remov": 14.040682248880003, "what": 1.25343439128, "button": 21.027814569500002, "social": 1.9904714142400002, "enough": 2.2319696330700003, "head": 1.57781753131, "committe": 3.2373572593799995, "against": 3.8706216984899995, "twist": 14.8930581614, "help": 2.79925945518, "sexual": 18.382091856419997, "clear": 1.85423966363, "find": 1.7294117647099998, "down": 2.71779508688, "inde": 4.43092380687, "when": 2.0415353951, "argu": 2.67768595041, "user": 23.13161728995, "own": 3.5353325415600003}, "logtfidf": {"after": 0.061472083944299996, "mark": 0.410770160338, "milner": 4.927631685540001, "can": 1.298728771152, "failur": 1.18954807429, "understand": 1.0880858756799998, "unknown": 1.32782105949, "evergrow": 6.964513612799999, "bigger": 2.58248697813, "shouldn": 13.929027225599999, "wider": 1.90360776936, "here": 0.8850381883700001, "accus": 1.38705050482, "five": 0.320203181906, "report": 5.890332671703001, "microsoft": 3.21265935953, "were": 0.12145571840549998, "alert": 2.61037218162, "would": 0.0796176279647, "human": 1.920105549729, "photodna": 6.964513612799999, "been": 0.09458392947360002, "use": 0.0584160394632, "care": 0.9139943029109999, "about": 0.31421738737300003, "evid": 0.8103634834160001, "imageri": 2.98545520604, "say": 1.124308561104, "have": 0.1034950163884, "nutshel": 5.843922417409999, "techcrunch": 6.964513612799999, "resourc": 3.24413082774, "internet": 1.6063562459, "zuckerberg": 13.929027225599999, "standard": 1.27482101964, "approach": 0.7302336145810001, "world": 0.107420248621, "statement": 1.2303097091500002, "them": 0.2825499807279, "remain": 0.15356296309, "email": 3.5113564922099996, "serious": 0.949332539075, "scale": 2.64190612656, "item": 1.62505430292, "flag": 1.78385428972, "realli": 1.5576408397, "measur": 0.880014199726, "point": 0.23103235903299998, "conced": 2.8960568215299998, "multipl": 1.01092401812, "articl": 0.702131739574, "how": 0.47156695693000006, "billion": 1.5824680307199999, "news": 2.199735220455, "basi": 0.884275353639, "children": 1.299275891574, "had": 0.0929560488222, "giant": 1.83028503479, "distribut": 2.01562611626, "found": 0.107841124048, "blind": 2.1803607712799997, "word": 0.585861082385, "interest": 0.47207177798199995, "abl": 0.599303982475, "mani": 0.0433157581221, "miscommun": 5.7022719003499995, "exploit": 8.784253072600002, "open": 0.219591038029, "organ": 0.9878410573399999, "site": 0.6791364434899999, "forbid": 3.0836373363700003, "publish": 0.313975865467, "safeti": 1.48693492276, "thousand": 0.906949263988, "director": 0.965577050854, "will": 0.6083596047450001, "initi": 0.30010459245, "claim": 0.423291231925, "damian": 4.73808988077, "but": 0.0647694882876, "need": 0.725480326884, "our": 5.145835285092001, "followup": 6.14620328929, "longer": 0.7046772417749999, "moder": 13.5622546172, "where": 0.0649921387457, "devot": 1.6224983909900001, "takedown": 6.340359303730001, "doubt": 1.67020426765, "possibl": 0.697610949782, "industri": 0.7046772417749999, "review": 2.378856611763, "best": 0.459227932947, "disturb": 2.2069085037700003, "ask": 1.553594419694, "has": 0.2563436691288, "interview": 1.2232212893899999, "pedophil": 12.680718607460001, "cloud": 2.36268232808, "take": 0.392075886591, "inappropri": 3.0726933146900004, "follow": 0.1360707332826, "now": 0.44727883506300004, "subsequ": 0.561601885907, "further": 0.308815895297, "profil": 1.5751375153100002, "prompt": 1.4916828719100002, "ensur": 1.22751130026, "than": 0.0645217244364, "child": 8.15370556917, "declin": 1.7542660177259999, "recogn": 0.935913859031, "break": 0.88733019029, "issu": 0.728198087868, "deploy": 2.00400270589, "also": 0.0586286312, "offic": 0.463023762098, "that": 0.07157067083351999, "critic": 0.512885356729, "around": 0.19387710578200001, "view": 0.49515994217299997, "fashion": 1.57940711618, "far": 1.073247529006, "ocean": 1.67894381908, "materi": 0.7561918990209999, "major": 0.138474663439, "necessit": 3.15489254099, "law": 0.5863138271580001, "imag": 11.92514528748, "technolog": 1.91369537271, "caution": 3.0578382137, "the": 0.0, "polici": 1.8561514001, "not": 0.0466572390225, "solut": 4.660388928810001, "stori": 0.705059626587, "happen": 1.08640441802, "challeng": 0.9392919688950001, "said": 1.74661266326, "contextu": 4.33984502064, "problem": 3.983985069911, "ongo": 1.79934675904, "sinc": 0.0803681994577, "system": 2.292012419095, "obscen": 7.9509406548, "act": 0.717890184946, "howev": 0.180630234695, "last": 0.19204364461100001, "share": 4.950082397976, "although": 0.278975962836, "employ": 1.5451204098859999, "opposit": 0.90274594185, "still": 0.17112222142900002, "role": 0.44036410757399996, "which": 0.01035682769086, "chairman": 1.7936509016099997, "upon": 0.47207177798199995, "activ": 0.381196603284, "practic": 0.533182530867, "respons": 0.40991566230300003, "complaint": 2.3220476420700003, "simpl": 1.2232212893899999, "appear": 0.557471796986, "other": 0.00987474791976, "refer": 0.262553246798, "offend": 2.6999575626, "provid": 0.19517784432500002, "one": 0.0062553516455, "known": 0.0824180805992, "hope": 0.919824304455, "accord": 0.243650319127, "rais": 0.6797577544760001, "develop": 0.178624694913, "some": 0.0395735090645, "such": 0.238783911224, "facebook": 77.09129695194999, "explicit": 1.7612397949400003, "hand": 0.479471335336, "via": 0.831983625414, "talk": 1.10867789449, "convict": 3.80383715954, "network": 0.9530830530519999, "intellig": 1.43349848213, "andor": 6.5370695979699995, "letter": 0.886718475942, "drop": 0.8999535106219999, "fix": 4.46833720353, "tri": 0.61759152916, "part": 0.04239531098280001, "concern": 0.634079948873, "servic": 0.41410016674500005, "confid": 1.8449242675400002, "aipow": 6.964513612799999, "despit": 0.473790078298, "content": 22.765304871719998, "recent": 0.434413741288, "anyon": 1.68164835081, "leadership": 1.3954060414700002, "platform": 9.149461694600001, "media": 0.9530830530519999, "more": 0.08512465799999999, "this": 0.022718694315, "abus": 1.83817151099, "think": 1.06717661175, "and": 0.0008818619888904, "from": 0.002268216675464, "account": 1.330148579946, "answer": 1.5366310419, "vast": 2.8004973319, "work": 0.109034567273, "num": 0.0012599615815880002, "common": 0.338325805271, "instanc": 1.18089357972, "put": 0.505652999854, "for": 0.0025199231631760004, "fail": 1.313073223146, "all": 0.011402632097799998, "polic": 1.14740245284, "fulli": 1.02609828678, "illeg": 5.17677736863, "with": 0.00718495028034, "requir": 0.424253510675, "program": 0.7037855787649999, "there": 0.0400978929255, "are": 0.0294674735827, "includ": 0.0188846813905, "better": 0.6964279406, "compani": 1.3193317592909999, "commit": 1.0598786410299998, "european": 0.674427053203, "current": 0.42695282784500005, "author": 0.35274143130999996, "sent": 2.533527831264, "rule": 0.554777423537, "today": 0.559395353679, "public": 0.20232375048700002, "futur": 1.238690395398, "improv": 1.4295916078639999, "dublin": 2.91795971441, "veri": 0.460319586476, "discuss": 0.78698452262, "guidelin": 5.21731970486, "these": 0.0715336194008, "want": 0.6916366062549999, "humanmoder": 6.964513612799999, "artifici": 2.11822899018, "question": 1.580621858028, "type": 0.707101485387, "boil": 3.16677975377, "again": 0.822680463224, "none": 1.40255075163, "aimoder": 6.964513612799999, "close": 0.250666759864, "year": 0.09480447778920001, "group": 0.190594534797, "even": 0.304777129668, "avail": 0.547454586289, "collin": 2.28733289084, "page": 0.711326032411, "make": 0.07349765782289999, "men": 0.624742371425, "onli": 0.050648536658199995, "grave": 1.91039320676, "told": 3.4463769213899997, "suggest": 0.563702610877, "avoid": 0.900108441291, "accur": 1.75248061485, "flagship": 2.95596904038, "investig": 1.13694148702, "link": 0.7661704068449999, "extrem": 0.8612095839370001, "his": 0.0901772433641, "continu": 0.13040487398700001, "hous": 0.38009061238799996, "taken": 0.470759772949, "matter": 1.7903250540720002, "time": 0.0224230377252, "perfect": 1.50096433356, "rather": 0.442714975539, "into": 0.0298257264574, "come": 0.28390990653000003, "exampl": 1.2260480249969998, "aspect": 1.12795002691, "effect": 0.667660454316, "send": 1.32189757338, "right": 0.34035985417, "identifi": 2.5011660014159998, "sex": 1.86140042888, "direct": 0.6021170684880001, "simon": 1.59853759778, "remov": 4.872341891116, "what": 0.225887296827, "button": 3.0458460646499996, "social": 0.688371502261, "enough": 0.802884439169, "head": 0.456042582852, "committe": 1.17475733629, "against": 0.7644085532339999, "twist": 2.70089520918, "help": 0.672415442688, "sexual": 5.438293900020001, "clear": 0.617474727198, "find": 0.547781330288, "down": 0.613347482372, "inde": 1.4886080966, "when": 0.0411099777168, "argu": 0.984952970196, "user": 6.127764320639999, "own": 0.492585232263}, "logidf": {"after": 0.020490694648099998, "mark": 0.410770160338, "milner": 4.927631685540001, "can": 0.162341096394, "failur": 1.18954807429, "understand": 1.0880858756799998, "unknown": 1.32782105949, "evergrow": 6.964513612799999, "bigger": 2.58248697813, "shouldn": 6.964513612799999, "wider": 1.90360776936, "here": 0.8850381883700001, "accus": 1.38705050482, "five": 0.320203181906, "report": 0.31001750903700004, "microsoft": 3.21265935953, "were": 0.024291143681099997, "alert": 2.61037218162, "would": 0.0796176279647, "human": 0.640035183243, "photodna": 6.964513612799999, "been": 0.023645982368400004, "use": 0.0292080197316, "care": 0.9139943029109999, "about": 0.0628434774746, "evid": 0.8103634834160001, "imageri": 2.98545520604, "say": 0.562154280552, "have": 0.0147850023412, "nutshel": 5.843922417409999, "techcrunch": 6.964513612799999, "resourc": 1.08137694258, "internet": 1.6063562459, "zuckerberg": 6.964513612799999, "standard": 0.63741050982, "approach": 0.7302336145810001, "world": 0.107420248621, "statement": 1.2303097091500002, "them": 0.0941833269093, "remain": 0.15356296309, "email": 3.5113564922099996, "serious": 0.949332539075, "scale": 1.32095306328, "item": 1.62505430292, "flag": 1.78385428972, "realli": 1.5576408397, "measur": 0.880014199726, "point": 0.23103235903299998, "conced": 2.8960568215299998, "multipl": 1.01092401812, "articl": 0.702131739574, "how": 0.47156695693000006, "billion": 1.5824680307199999, "news": 0.733245073485, "basi": 0.884275353639, "children": 0.649637945787, "had": 0.0464780244111, "giant": 1.83028503479, "distribut": 1.00781305813, "found": 0.107841124048, "blind": 2.1803607712799997, "word": 0.585861082385, "interest": 0.47207177798199995, "abl": 0.599303982475, "mani": 0.0433157581221, "miscommun": 5.7022719003499995, "exploit": 1.7568506145200002, "open": 0.219591038029, "organ": 0.49392052866999997, "site": 0.6791364434899999, "forbid": 3.0836373363700003, "publish": 0.313975865467, "safeti": 1.48693492276, "thousand": 0.906949263988, "director": 0.965577050854, "will": 0.202786534915, "initi": 0.30010459245, "claim": 0.423291231925, "damian": 4.73808988077, "but": 0.0161923720719, "need": 0.362740163442, "our": 0.8576392141820001, "followup": 6.14620328929, "longer": 0.7046772417749999, "moder": 1.69528182715, "where": 0.0649921387457, "devot": 1.6224983909900001, "takedown": 6.340359303730001, "doubt": 1.67020426765, "possibl": 0.348805474891, "industri": 0.7046772417749999, "review": 0.7929522039210001, "best": 0.459227932947, "disturb": 2.2069085037700003, "ask": 0.776797209847, "has": 0.0427239448548, "interview": 1.2232212893899999, "pedophil": 6.340359303730001, "cloud": 2.36268232808, "take": 0.130691962197, "inappropri": 3.0726933146900004, "follow": 0.045356911094199995, "now": 0.149092945021, "subsequ": 0.561601885907, "further": 0.308815895297, "profil": 1.5751375153100002, "prompt": 1.4916828719100002, "ensur": 1.22751130026, "than": 0.0322608622182, "child": 1.16481508131, "declin": 0.8771330088629999, "recogn": 0.935913859031, "break": 0.88733019029, "issu": 0.364099043934, "deploy": 2.00400270589, "also": 0.0146571578, "offic": 0.463023762098, "that": 0.00397614837964, "critic": 0.512885356729, "around": 0.19387710578200001, "view": 0.49515994217299997, "fashion": 1.57940711618, "far": 0.536623764503, "ocean": 1.67894381908, "materi": 0.7561918990209999, "major": 0.138474663439, "necessit": 3.15489254099, "law": 0.5863138271580001, "imag": 0.99376210729, "technolog": 0.956847686355, "caution": 3.0578382137, "the": 0.0, "polici": 0.92807570005, "not": 0.0155524130075, "solut": 1.55346297627, "stori": 0.705059626587, "happen": 1.08640441802, "challeng": 0.9392919688950001, "said": 0.436653165815, "contextu": 4.33984502064, "problem": 0.569140724273, "ongo": 1.79934675904, "sinc": 0.0803681994577, "system": 0.327430345585, "obscen": 3.9754703274, "act": 0.358945092473, "howev": 0.0903151173475, "last": 0.19204364461100001, "share": 0.618760299747, "although": 0.139487981418, "employ": 0.7725602049429999, "opposit": 0.90274594185, "still": 0.17112222142900002, "role": 0.44036410757399996, "which": 0.00517841384543, "chairman": 1.7936509016099997, "upon": 0.47207177798199995, "activ": 0.381196603284, "practic": 0.533182530867, "respons": 0.40991566230300003, "complaint": 2.3220476420700003, "simpl": 1.2232212893899999, "appear": 0.278735898493, "other": 0.00987474791976, "refer": 0.262553246798, "offend": 2.6999575626, "provid": 0.19517784432500002, "one": 0.0062553516455, "known": 0.0824180805992, "hope": 0.919824304455, "accord": 0.243650319127, "rais": 0.6797577544760001, "develop": 0.178624694913, "some": 0.0395735090645, "such": 0.059695977806, "facebook": 3.3517955196499996, "explicit": 1.7612397949400003, "hand": 0.479471335336, "via": 0.831983625414, "talk": 1.10867789449, "convict": 1.90191857977, "network": 0.9530830530519999, "intellig": 1.43349848213, "andor": 6.5370695979699995, "letter": 0.886718475942, "drop": 0.8999535106219999, "fix": 1.48944573451, "tri": 0.61759152916, "part": 0.04239531098280001, "concern": 0.634079948873, "servic": 0.41410016674500005, "confid": 1.8449242675400002, "aipow": 6.964513612799999, "despit": 0.473790078298, "content": 1.26473915954, "recent": 0.434413741288, "anyon": 1.68164835081, "leadership": 1.3954060414700002, "platform": 1.8298923389200001, "media": 0.9530830530519999, "more": 0.017024931599999998, "this": 0.0037864490525, "abus": 1.83817151099, "think": 1.06717661175, "and": 6.29901420636e-05, "from": 0.000567054168866, "account": 0.665074289973, "answer": 1.5366310419, "vast": 1.40024866595, "work": 0.109034567273, "num": 0.00031499039539700004, "common": 0.338325805271, "instanc": 1.18089357972, "put": 0.505652999854, "for": 0.00031499039539700004, "fail": 0.656536611573, "all": 0.011402632097799998, "polic": 1.14740245284, "fulli": 1.02609828678, "illeg": 1.72559245621, "with": 0.00119749171339, "requir": 0.424253510675, "program": 0.7037855787649999, "there": 0.0400978929255, "are": 0.0294674735827, "includ": 0.0188846813905, "better": 0.6964279406, "compani": 0.439777253097, "commit": 1.0598786410299998, "european": 0.674427053203, "current": 0.42695282784500005, "author": 0.35274143130999996, "sent": 0.844509277088, "rule": 0.554777423537, "today": 0.559395353679, "public": 0.20232375048700002, "futur": 0.619345197699, "improv": 0.7147958039319999, "dublin": 2.91795971441, "veri": 0.230159793238, "discuss": 0.78698452262, "guidelin": 2.60865985243, "these": 0.0715336194008, "want": 0.6916366062549999, "humanmoder": 6.964513612799999, "artifici": 2.11822899018, "question": 0.790310929014, "type": 0.707101485387, "boil": 3.16677975377, "again": 0.411340231612, "none": 1.40255075163, "aimoder": 6.964513612799999, "close": 0.250666759864, "year": 0.047402238894600005, "group": 0.190594534797, "even": 0.152388564834, "avail": 0.547454586289, "collin": 2.28733289084, "page": 0.711326032411, "make": 0.07349765782289999, "men": 0.624742371425, "onli": 0.025324268329099998, "grave": 1.91039320676, "told": 1.14879230713, "suggest": 0.563702610877, "avoid": 0.900108441291, "accur": 1.75248061485, "flagship": 2.95596904038, "investig": 1.13694148702, "link": 0.7661704068449999, "extrem": 0.8612095839370001, "his": 0.0901772433641, "continu": 0.13040487398700001, "hous": 0.38009061238799996, "taken": 0.470759772949, "matter": 0.8951625270360001, "time": 0.0112115188626, "perfect": 1.50096433356, "rather": 0.442714975539, "into": 0.0149128632287, "come": 0.28390990653000003, "exampl": 0.40868267499899996, "aspect": 1.12795002691, "effect": 0.333830227158, "send": 1.32189757338, "right": 0.34035985417, "identifi": 0.833722000472, "sex": 1.86140042888, "direct": 0.200705689496, "simon": 1.59853759778, "remov": 0.6960488415880001, "what": 0.225887296827, "button": 3.0458460646499996, "social": 0.688371502261, "enough": 0.802884439169, "head": 0.456042582852, "committe": 1.17475733629, "against": 0.254802851078, "twist": 2.70089520918, "help": 0.336207721344, "sexual": 1.8127646333400003, "clear": 0.617474727198, "find": 0.547781330288, "down": 0.306673741186, "inde": 1.4886080966, "when": 0.0205549888584, "argu": 0.984952970196, "user": 2.04258810688, "own": 0.164195077421}, "freq": {"after": 3, "mark": 1, "milner": 1, "can": 8, "failur": 1, "understand": 1, "unknown": 1, "evergrow": 1, "bigger": 1, "shouldn": 2, "wider": 1, "here": 1, "accus": 1, "five": 1, "report": 19, "microsoft": 1, "were": 5, "alert": 1, "would": 1, "human": 3, "photodna": 1, "been": 4, "use": 2, "care": 1, "about": 5, "evid": 1, "imageri": 1, "say": 2, "have": 7, "nutshel": 1, "techcrunch": 1, "resourc": 3, "internet": 1, "zuckerberg": 2, "standard": 2, "approach": 1, "world": 1, "statement": 1, "them": 3, "remain": 1, "email": 1, "serious": 1, "scale": 2, "item": 1, "flag": 1, "realli": 1, "measur": 1, "point": 1, "conced": 1, "multipl": 1, "articl": 1, "how": 1, "billion": 1, "news": 3, "basi": 1, "children": 2, "had": 2, "giant": 1, "distribut": 2, "found": 1, "blind": 1, "word": 1, "interest": 1, "abl": 1, "mani": 1, "miscommun": 1, "exploit": 5, "open": 1, "organ": 2, "site": 1, "forbid": 1, "publish": 1, "safeti": 1, "thousand": 1, "director": 1, "will": 3, "initi": 1, "claim": 1, "damian": 1, "but": 4, "need": 2, "our": 6, "followup": 1, "longer": 1, "moder": 8, "where": 1, "devot": 1, "takedown": 1, "doubt": 1, "possibl": 2, "industri": 1, "review": 3, "best": 1, "disturb": 1, "ask": 2, "has": 6, "interview": 1, "pedophil": 2, "cloud": 1, "take": 3, "inappropri": 1, "follow": 3, "now": 3, "subsequ": 1, "further": 1, "profil": 1, "prompt": 1, "ensur": 1, "than": 2, "child": 7, "declin": 2, "recogn": 1, "break": 1, "issu": 2, "deploy": 1, "also": 4, "offic": 1, "that": 18, "critic": 1, "around": 1, "view": 1, "fashion": 1, "far": 2, "ocean": 1, "materi": 1, "major": 1, "necessit": 1, "law": 1, "imag": 12, "technolog": 2, "caution": 1, "the": 49, "polici": 2, "not": 3, "solut": 3, "stori": 1, "happen": 1, "challeng": 1, "said": 4, "contextu": 1, "problem": 7, "ongo": 1, "sinc": 1, "system": 7, "obscen": 2, "act": 2, "howev": 2, "last": 1, "share": 8, "although": 2, "employ": 2, "opposit": 1, "still": 1, "role": 1, "which": 2, "chairman": 1, "upon": 1, "activ": 1, "practic": 1, "respons": 1, "complaint": 1, "simpl": 1, "appear": 2, "other": 1, "refer": 1, "offend": 1, "provid": 1, "one": 1, "known": 1, "hope": 1, "accord": 1, "rais": 1, "develop": 1, "some": 1, "such": 4, "facebook": 23, "explicit": 1, "hand": 1, "via": 1, "talk": 1, "convict": 2, "network": 1, "intellig": 1, "andor": 1, "letter": 1, "drop": 1, "fix": 3, "tri": 1, "part": 1, "concern": 1, "servic": 1, "confid": 1, "aipow": 1, "despit": 1, "content": 18, "recent": 1, "anyon": 1, "leadership": 1, "platform": 5, "media": 1, "more": 5, "this": 6, "abus": 1, "think": 1, "and": 14, "from": 4, "account": 2, "answer": 1, "vast": 2, "work": 1, "num": 4, "common": 1, "instanc": 1, "put": 1, "for": 8, "fail": 2, "all": 1, "polic": 1, "fulli": 1, "illeg": 3, "with": 6, "requir": 1, "program": 1, "there": 1, "are": 1, "includ": 1, "better": 1, "compani": 3, "commit": 1, "european": 1, "current": 1, "author": 1, "sent": 3, "rule": 1, "today": 1, "public": 1, "futur": 2, "improv": 2, "dublin": 1, "veri": 2, "discuss": 1, "guidelin": 2, "these": 1, "want": 1, "humanmoder": 1, "artifici": 1, "question": 2, "type": 1, "boil": 1, "again": 2, "none": 1, "aimoder": 1, "close": 1, "year": 2, "group": 1, "even": 2, "avail": 1, "collin": 1, "page": 1, "make": 1, "men": 1, "onli": 2, "grave": 1, "told": 3, "suggest": 1, "avoid": 1, "accur": 1, "flagship": 1, "investig": 1, "link": 1, "extrem": 1, "his": 1, "continu": 1, "hous": 1, "taken": 1, "matter": 2, "time": 2, "perfect": 1, "rather": 1, "into": 2, "come": 1, "exampl": 3, "aspect": 1, "effect": 2, "send": 1, "right": 1, "identifi": 3, "sex": 1, "direct": 3, "simon": 1, "remov": 7, "what": 1, "button": 1, "social": 1, "enough": 1, "head": 1, "committe": 1, "against": 3, "twist": 1, "help": 2, "sexual": 3, "clear": 1, "find": 1, "down": 2, "inde": 1, "when": 2, "argu": 1, "user": 3, "own": 3}, "idf": {"after": 1.02070207021, "mark": 1.5079787234, "milner": 138.052173913, "can": 1.17626139142, "failur": 3.28559602649, "understand": 2.96858638743, "unknown": 3.77281368821, "evergrow": 1058.4, "bigger": 13.23, "shouldn": 1058.4, "wider": 6.710059171599999, "here": 2.42307692308, "accus": 4.00302571861, "five": 1.37740760021, "report": 1.3634489866, "microsoft": 24.8450704225, "were": 1.02458857696, "alert": 13.6041131105, "would": 1.0828729281799998, "human": 1.8965476048299998, "photodna": 1058.4, "been": 1.0239277652399998, "use": 1.0296387573799999, "care": 2.49426551453, "about": 1.06486015159, "evid": 2.24872521246, "imageri": 19.7955112219, "say": 1.7544480053, "have": 1.0148948411399998, "nutshel": 345.13043478300006, "techcrunch": 1058.4, "resourc": 2.9487369985100003, "internet": 4.98461538462, "zuckerberg": 1058.4, "standard": 1.8915763135900003, "approach": 2.07556543339, "world": 1.11340206186, "statement": 3.42228928648, "them": 1.09876115994, "remain": 1.16598119859, "email": 33.4936708861, "serious": 2.583984375, "scale": 3.7469907953699995, "item": 5.07869481766, "flag": 5.95275590551, "realli": 4.7476076555, "measur": 2.41093394077, "point": 1.25990000794, "conced": 18.102622577, "multipl": 2.74813917258, "articl": 2.01805008262, "how": 1.60250328051, "billion": 4.8669527897, "news": 2.08182533438, "basi": 2.42122922068, "children": 1.91484742492, "had": 1.0475750577399998, "giant": 6.23566378633, "distribut": 2.7396031061299997, "found": 1.11387076405, "blind": 8.849498327760001, "word": 1.7965372864099998, "interest": 1.60331246213, "abl": 1.8208510150200001, "mani": 1.04426757877, "miscommun": 299.547169811, "exploit": 5.79416058394, "open": 1.24556723678, "organ": 1.6387283237, "site": 1.9721739130400002, "forbid": 21.8376891334, "publish": 1.36885669943, "safeti": 4.4235162998, "thousand": 2.4767550702000003, "director": 2.62630272953, "will": 1.22481098596, "initi": 1.35, "claim": 1.52697893623, "damian": 114.215827338, "but": 1.01632417899, "need": 1.4372623574099999, "our": 2.35758835759, "followup": 466.941176471, "longer": 2.02319357716, "moder": 5.44818119423, "where": 1.06715063521, "devot": 5.0657306956, "takedown": 567.0, "doubt": 5.31325301205, "possibl": 1.4173734488, "industri": 2.02319357716, "review": 2.2099109131400003, "best": 1.5828514456600002, "disturb": 9.08757870635, "ask": 2.1744966443, "has": 1.0436497502, "interview": 3.3981164383599998, "pedophil": 567.0, "cloud": 10.6193979933, "take": 1.13961668222, "inappropri": 21.6, "follow": 1.04640126549, "now": 1.160780873, "subsequ": 1.7534791252500002, "further": 1.3618116315, "profil": 4.8314059647, "prompt": 4.44456886898, "ensur": 3.4127257093700005, "than": 1.03278688525, "child": 3.20533010297, "declin": 2.4039975772299997, "recogn": 2.54954231572, "break": 2.42863698944, "issu": 1.43921675279, "deploy": 7.41869158879, "also": 1.01476510067, "offic": 1.58887109688, "that": 1.00398406375, "critic": 1.67010309278, "around": 1.21394708671, "view": 1.6407606448899998, "fashion": 4.85207823961, "far": 1.71022298826, "ocean": 5.35989196489, "materi": 2.13014893332, "major": 1.14852058164, "necessit": 23.450516986700002, "law": 1.7973508434299998, "imag": 2.70137825421, "technolog": 2.6034765496900003, "caution": 21.2815013405, "the": 1.0, "polici": 2.52963671128, "not": 1.01567398119, "solut": 4.7278141751, "stori": 2.02396736359, "happen": 2.96359902931, "challeng": 2.55816951337, "said": 1.54751925139, "contextu": 76.6956521739, "problem": 1.76674827509, "ongo": 6.04569687738, "sinc": 1.08368600683, "system": 1.38739840951, "obscen": 53.275167785200004, "act": 1.4318181818200002, "howev": 1.0945191313299998, "last": 1.2117234010100002, "share": 1.8566249561500001, "although": 1.14968498805, "employ": 2.16530278232, "opposit": 2.4663663197099996, "still": 1.1866357724799999, "role": 1.55327267391, "which": 1.005191845, "chairman": 6.01135933359, "upon": 1.60331246213, "activ": 1.46403541129, "practic": 1.70434782609, "respons": 1.5066907089300001, "complaint": 10.1965317919, "simpl": 3.3981164383599998, "appear": 1.3214582986499999, "other": 1.00992366412, "refer": 1.30024570025, "offend": 14.8791002812, "provid": 1.21552714187, "one": 1.00627495722, "known": 1.0859097127200001, "hope": 2.50884955752, "accord": 1.27589809531, "rais": 1.9733996271, "develop": 1.1955719557200002, "some": 1.04036697248, "such": 1.06151377374, "facebook": 28.5539568345, "explicit": 5.819648093840001, "hand": 1.6152202665600002, "via": 2.2978723404299997, "talk": 3.0303493033, "convict": 6.69873417722, "network": 2.59369384088, "intellig": 4.19334389857, "andor": 690.260869565, "letter": 2.42715181165, "drop": 2.4594887684, "fix": 4.4346368715099995, "tri": 1.8544562551099997, "part": 1.04330682789, "concern": 1.8852867830400002, "servic": 1.51300867245, "confid": 6.327620565959999, "aipow": 1058.4, "despit": 1.60606980273, "content": 3.5421686747, "recent": 1.54405757635, "anyon": 5.37440758294, "leadership": 4.03661327231, "platform": 6.2332155476999995, "media": 2.59369384088, "more": 1.0171706817, "this": 1.00379362671, "abus": 6.28503562945, "think": 2.90715986083, "and": 1.00006299213, "from": 1.00056721497, "account": 1.94463498285, "answer": 4.64890190337, "vast": 4.05620848237, "work": 1.11520089913, "num": 1.00031504001, "common": 1.4025974025999999, "instanc": 3.2572835453400004, "put": 1.65806788512, "for": 1.00031504001, "fail": 1.9281029876099998, "all": 1.01146788991, "polic": 3.15, "fulli": 2.79015817223, "illeg": 5.61584718783, "with": 1.0011982089899998, "requir": 1.52844902282, "program": 2.02139037433, "there": 1.04091266719, "are": 1.02990593578, "includ": 1.0190641247799999, "better": 2.0065722952500002, "compani": 1.5523613963, "commit": 2.8860207235, "european": 1.96290801187, "current": 1.5325803649, "author": 1.4229631621399998, "sent": 2.32683570277, "rule": 1.7415533128599998, "today": 1.74961428257, "public": 1.22424429365, "futur": 1.8577112099200002, "improv": 2.04376930999, "dublin": 18.5034965035, "veri": 1.25880114177, "discuss": 2.19676214197, "guidelin": 13.580838323399998, "these": 1.07415426252, "want": 1.99698113208, "humanmoder": 1058.4, "artifici": 8.31639601886, "question": 2.20408163265, "type": 2.0281042411900003, "boil": 23.730941704, "again": 1.50883862384, "none": 4.06555697823, "aimoder": 1058.4, "close": 1.2848818387799998, "year": 1.0485436893200002, "group": 1.20996875238, "even": 1.16461267606, "avail": 1.7288467821, "collin": 9.84863523573, "page": 2.03669018602, "make": 1.0762660158600001, "men": 1.86776470588, "onli": 1.0256476516600002, "grave": 6.75574468085, "told": 3.1543810848400002, "suggest": 1.7571665744299998, "avoid": 2.45986984816, "accur": 5.768895348840001, "flagship": 19.2203389831, "investig": 3.11721971333, "link": 2.15151104486, "extrem": 2.36602086438, "his": 1.0943682360200002, "continu": 1.13928955867, "hous": 1.4624170965399999, "taken": 1.6012102874399998, "matter": 2.44773358002, "time": 1.01127460348, "perfect": 4.48601299802, "rather": 1.55692850838, "into": 1.01502461479, "come": 1.32831325301, "exampl": 1.50483412322, "aspect": 3.0893169877399997, "effect": 1.3963060686000002, "send": 3.75053153792, "right": 1.4054532577899999, "identifi": 2.30187037843, "sex": 6.432739059969999, "direct": 1.22226499346, "simon": 4.94579439252, "remov": 2.0058117498400003, "what": 1.25343439128, "button": 21.027814569500002, "social": 1.9904714142400002, "enough": 2.2319696330700003, "head": 1.57781753131, "committe": 3.2373572593799995, "against": 1.2902072328299998, "twist": 14.8930581614, "help": 1.39962972759, "sexual": 6.12736395214, "clear": 1.85423966363, "find": 1.7294117647099998, "down": 1.35889754344, "inde": 4.43092380687, "when": 1.02076769755, "argu": 2.67768595041, "user": 7.71053909665, "own": 1.17844418052}}, "html": "<!DOCTYPE html>\n\n<html class=\"no-js\" lang=\"en-US\">\n<head>\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"><script type=\"text/javascript\">window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var o=n[t]={exports:{}};e[t][0].call(o.exports,function(n){var o=e[t][1][n];return r(o||n)},o,o.exports)}return n[t].exports}if(\"function\"==typeof __nr_require)return __nr_require;for(var o=0;o<t.length;o++)r(t[o]);return r}({1:[function(e,n,t){function r(){}function o(e,n,t){return function(){return i(e,[c.now()].concat(u(arguments)),n?null:this,t),n?void 0:this}}var i=e(\"handle\"),a=e(3),u=e(4),f=e(\"ee\").get(\"tracer\"),c=e(\"loader\"),s=NREUM;\"undefined\"==typeof window.newrelic&&(newrelic=s);var p=[\"setPageViewName\",\"setCustomAttribute\",\"setErrorHandler\",\"finished\",\"addToTrace\",\"inlineHit\",\"addRelease\"],d=\"api-\",l=d+\"ixn-\";a(p,function(e,n){s[n]=o(d+n,!0,\"api\")}),s.addPageAction=o(d+\"addPageAction\",!0),s.setCurrentRouteName=o(d+\"routeName\",!0),n.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,n){var t={},r=this,o=\"function\"==typeof n;return i(l+\"tracer\",[c.now(),e,t],r),function(){if(f.emit((o?\"\":\"no-\")+\"fn-start\",[c.now(),r,o],t),o)try{return n.apply(this,arguments)}catch(e){throw f.emit(\"fn-err\",[arguments,this,e],t),e}finally{f.emit(\"fn-end\",[c.now()],t)}}}};a(\"actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get\".split(\",\"),function(e,n){m[n]=o(l+n)}),newrelic.noticeError=function(e,n){\"string\"==typeof e&&(e=new Error(e)),i(\"err\",[e,c.now(),!1,n])}},{}],2:[function(e,n,t){function r(e,n){if(!o)return!1;if(e!==o)return!1;if(!n)return!0;if(!i)return!1;for(var t=i.split(\".\"),r=n.split(\".\"),a=0;a<r.length;a++)if(r[a]!==t[a])return!1;return!0}var o=null,i=null,a=/Version\\/(\\S+)\\s+Safari/;if(navigator.userAgent){var u=navigator.userAgent,f=u.match(a);f&&u.indexOf(\"Chrome\")===-1&&u.indexOf(\"Chromium\")===-1&&(o=\"Safari\",i=f[1])}n.exports={agent:o,version:i,match:r}},{}],3:[function(e,n,t){function r(e,n){var t=[],r=\"\",i=0;for(r in e)o.call(e,r)&&(t[i]=n(r,e[r]),i+=1);return t}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],4:[function(e,n,t){function r(e,n,t){n||(n=0),\"undefined\"==typeof t&&(t=e?e.length:0);for(var r=-1,o=t-n||0,i=Array(o<0?0:o);++r<o;)i[r]=e[n+r];return i}n.exports=r},{}],5:[function(e,n,t){n.exports={exists:\"undefined\"!=typeof window.performance&&window.performance.timing&&\"undefined\"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,n,t){function r(){}function o(e){function n(e){return e&&e instanceof r?e:e?f(e,u,i):i()}function t(t,r,o,i){if(!d.aborted||i){e&&e(t,r,o);for(var a=n(o),u=v(t),f=u.length,c=0;c<f;c++)u[c].apply(a,r);var p=s[y[t]];return p&&p.push([b,t,r,a]),a}}function l(e,n){h[e]=v(e).concat(n)}function m(e,n){var t=h[e];if(t)for(var r=0;r<t.length;r++)t[r]===n&&t.splice(r,1)}function v(e){return h[e]||[]}function g(e){return p[e]=p[e]||o(t)}function w(e,n){c(e,function(e,t){n=n||\"feature\",y[t]=n,n in s||(s[n]=[])})}var h={},y={},b={on:l,addEventListener:l,removeEventListener:m,emit:t,get:g,listeners:v,context:n,buffer:w,abort:a,aborted:!1};return b}function i(){return new r}function a(){(s.api||s.feature)&&(d.aborted=!0,s=d.backlog={})}var u=\"nr@context\",f=e(\"gos\"),c=e(3),s={},p={},d=n.exports=o();d.backlog=s},{}],gos:[function(e,n,t){function r(e,n,t){if(o.call(e,n))return e[n];var r=t();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,n,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return e[n]=r,r}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],handle:[function(e,n,t){function r(e,n,t,r){o.buffer([e],r),o.emit(e,n,t)}var o=e(\"ee\").get(\"handle\");n.exports=r,r.ee=o},{}],id:[function(e,n,t){function r(e){var n=typeof e;return!e||\"object\"!==n&&\"function\"!==n?-1:e===window?0:a(e,i,function(){return o++})}var o=1,i=\"nr@id\",a=e(\"gos\");n.exports=r},{}],loader:[function(e,n,t){function r(){if(!E++){var e=x.info=NREUM.info,n=l.getElementsByTagName(\"script\")[0];if(setTimeout(s.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&n))return s.abort();c(y,function(n,t){e[n]||(e[n]=t)}),f(\"mark\",[\"onload\",a()+x.offset],null,\"api\");var t=l.createElement(\"script\");t.src=\"https://\"+e.agent,n.parentNode.insertBefore(t,n)}}function o(){\"complete\"===l.readyState&&i()}function i(){f(\"mark\",[\"domContent\",a()+x.offset],null,\"api\")}function a(){return O.exists&&performance.now?Math.round(performance.now()):(u=Math.max((new Date).getTime(),u))-x.offset}var u=(new Date).getTime(),f=e(\"handle\"),c=e(3),s=e(\"ee\"),p=e(2),d=window,l=d.document,m=\"addEventListener\",v=\"attachEvent\",g=d.XMLHttpRequest,w=g&&g.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:g,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var h=\"\"+location,y={beacon:\"bam.nr-data.net\",errorBeacon:\"bam.nr-data.net\",agent:\"js-agent.newrelic.com/nr-1123.min.js\"},b=g&&w&&w[m]&&!/CriOS/.test(navigator.userAgent),x=n.exports={offset:u,now:a,origin:h,features:{},xhrWrappable:b,userAgent:p};e(1),l[m]?(l[m](\"DOMContentLoaded\",i,!1),d[m](\"load\",r,!1)):(l[v](\"onreadystatechange\",o),d[v](\"onload\",r)),f(\"mark\",[\"firstbyte\",u],null,\"api\");var E=0,O=e(5)},{}]},{},[\"loader\"]);</script>\n<meta content=\"width=device-width\" name=\"viewport\"/>\n<meta content=\"initial-scale=1.0,width=device-width,user-scalable=no,minimum-scale=1.0,maximum-scale=1.0\" name=\"viewport\"/>\n<link href=\"http://gmpg.org/xfn/11\" rel=\"profile\"/>\n<link href=\"https://techcrunch.com/xmlrpc.php\" rel=\"pingback\"/>\n<title>Facebook\u2019s content moderation system under fire again for child safety failures \u2013 TechCrunch</title>\n<link href=\"//consent.cmp.oath.com\" rel=\"dns-prefetch\">\n<link href=\"//s.yimg.com\" rel=\"dns-prefetch\">\n<link href=\"//use.typekit.net\" rel=\"dns-prefetch\"/>\n<link href=\"//cdn.vidible.tv\" rel=\"dns-prefetch\"/>\n<link href=\"//plugin.mediavoice.com\" rel=\"dns-prefetch\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://techcrunch.com/feed/\" rel=\"alternate\" title=\"TechCrunch \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://techcrunch.com/comments/feed/\" rel=\"alternate\" title=\"TechCrunch \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://techcrunch.com/2017/03/07/facebooks-content-moderation-system-under-fire-for-child-safety-failures/feed/\" rel=\"alternate\" title=\"TechCrunch \u00bb Facebook\u2019s content moderation system under fire again for child safety failures Comments Feed\" type=\"application/rss+xml\"/>\n<meta content=\"false\" name=\"oath:guce:product-eu\">\n<meta content=\"guce.techcrunch.com\" name=\"oath:guce:consent-host\">\n<meta content=\"true\" name=\"oath:guce:inline-consent\"/>\n<script async=\"\" src=\"//s.yimg.com/oa/guce.js?tc_ver=190427\"></script>\n<script type=\"text/javascript\">\n\t\t\twindow._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/11.2.0\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/11.2.0\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"https:\\/\\/techcrunch.com\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=5.1.1\"}};\n\t\t\t!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline=\"top\",l.font=\"600 32px Arial\",a){case\"flag\":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case\"emoji\":return b=d([55358,56760,9792,65039],[55358,56760,8203,9792,65039]),!b}return!1}function f(a){var c=b.createElement(\"script\");c.src=a,c.defer=c.type=\"text/javascript\",b.getElementsByTagName(\"head\")[0].appendChild(c)}var g,h,i,j,k=b.createElement(\"canvas\"),l=k.getContext&&k.getContext(\"2d\");for(j=Array(\"flag\",\"emoji\"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],\"flag\"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener(\"DOMContentLoaded\",h,!1),a.addEventListener(\"load\",h,!1)):(a.attachEvent(\"onload\",h),b.attachEvent(\"onreadystatechange\",function(){\"complete\"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);\n\t\t</script>\n<style type=\"text/css\">\nimg.wp-smiley,\nimg.emoji {\n\tdisplay: inline !important;\n\tborder: none !important;\n\tbox-shadow: none !important;\n\theight: 1em !important;\n\twidth: 1em !important;\n\tmargin: 0 .07em !important;\n\tvertical-align: -0.1em !important;\n\tbackground: none !important;\n\tpadding: 0 !important;\n}\n</style>\n<link href=\"https://techcrunch.com/_static/??/wp-includes/css/dist/block-library/style.min.css,/wp-content/plugins/wp-parsely/wp-parsely.css,/wp-content/themes/techcrunch-2017/build/ec/css/main.css?m=1556300008\" id=\"all-css-0\" media=\"all\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"https://consent.cmp.oath.com/cmp.js?ver=5.1.1\" type=\"text/javascript\"></script>\n<script src=\"https://techcrunch.com/_static/??-eJzTLy/QzcxLzilNSS3WzwKiwtLUokoopZdVrKOPT4FubmZ6UWJJql5uZh5QsX2uraGpqZGJiZGhhWEWACVgIKc=\" type=\"text/javascript\"></script>\n<script src=\"https://s.yimg.com/ss/rapid3.js?ver=5.1.1\" type=\"text/javascript\"></script>\n<script src=\"//cdn.vidible.tv/prod/player/js/latest/vidible-min.js?ver=5.1.1\" type=\"text/javascript\"></script>\n<script src=\"//plugin.mediavoice.com/mediaconductor/mc.js?ver=5.1.1\" type=\"text/javascript\"></script>\n<link href=\"https://techcrunch.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://techcrunch.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://techcrunch.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<meta content=\"WordPress 5.1.1\" name=\"generator\"/>\n<link href=\"https://techcrunch.com/2017/03/07/facebooks-content-moderation-system-under-fire-for-child-safety-failures/\" rel=\"canonical\"/>\n<link href=\"https://techcrunch.com/?p=1461242\" rel=\"shortlink\"/>\n<link href=\"https://techcrunch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Ftechcrunch.com%2F2017%2F03%2F07%2Ffacebooks-content-moderation-system-under-fire-for-child-safety-failures%2F\" rel=\"alternate\" type=\"application/json+oembed\"/>\n<link href=\"https://techcrunch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Ftechcrunch.com%2F2017%2F03%2F07%2Ffacebooks-content-moderation-system-under-fire-for-child-safety-failures%2F&amp;format=xml\" rel=\"alternate\" type=\"text/xml+oembed\"/>\n<link href=\"//v0.wordpress.com\" rel=\"dns-prefetch\"/>\n<style type=\"text/css\">img#wpstats{display:none}</style>\n<!-- BEGIN Sailthru Horizon Meta Information -->\n<meta content=\"2017-03-07 06:28:28\" name=\"sailthru.date\"/>\n<meta content=\"Facebook\u2019s content moderation system under fire again for child safety failures\" name=\"sailthru.title\"/>\n<meta content=\"BBC, child safety, content moderation, Facebook, photo sharing, social media\" name=\"sailthru.tags\"/>\n<meta content=\"Natasha Lomas\" name=\"sailthru.author\"/>\n<meta content=\"Facebook has again been criticized for failing to remove child exploitation imagery from its platform following a BBC investigation into its system for reporting inappropriate content.\" name=\"sailthru.description\"/>\n<meta content=\"https://techcrunch.com/wp-content/uploads/2015/09/p1040182.jpg\" name=\"sailthru.image.full\"/>\n<meta content=\"https://techcrunch.com/wp-content/uploads/2015/09/p1040182.jpg?w=50\" name=\"sailthru.image.thumb\"/>\n<!-- END Sailthru Horizon Meta Information -->\n<!-- BEGIN wp-parsely Plugin Version 1.13.0 -->\n<meta content=\"1.13.0\" id=\"wp-parsely_version\" name=\"wp-parsely_version\"/>\n<script type=\"application/ld+json\">\n\t{\"@context\":\"http:\\/\\/schema.org\",\"@type\":\"NewsArticle\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"http:\\/\\/techcrunch.com\\/2017\\/03\\/07\\/facebooks-content-moderation-system-under-fire-for-child-safety-failures\\/\"},\"headline\":\"Facebook&#039;s content moderation system under fire again for child safety failures\",\"url\":\"http:\\/\\/techcrunch.com\\/2017\\/03\\/07\\/facebooks-content-moderation-system-under-fire-for-child-safety-failures\\/\",\"thumbnailUrl\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=150\",\"image\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=150\"},\"dateCreated\":\"2017-03-07T14:28:28Z\",\"datePublished\":\"2017-03-07T14:28:28Z\",\"dateModified\":\"2017-03-07T14:28:28Z\",\"articleSection\":\"post\",\"author\":[{\"@type\":\"Person\",\"name\":\"Natasha Lomas\"}],\"creator\":[\"Natasha Lomas\"],\"keywords\":[\"@post-id:1461242\",\"europe\",\"social\",\"tc\",\"bbc\",\"child safety\",\"content moderation\",\"facebook\",\"photo sharing\",\"social media\"],\"publisher\":{\"@type\":\"Organization\",\"name\":\"TechCrunch\",\"logo\":{\"@type\":\"imageObject\",\"url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/themes\\/techcrunch-2017\\/images\\/logo-json-ld.png\",\"width\":\"600\",\"height\":\"60\"}}}\n\t</script>\n<!-- END wp-parsely Plugin Version 1.13.0 -->\n<meta content=\"187288694643718\" property=\"fb:app_id\"/>\n<meta content=\"8062627951\" property=\"fb:pages\"/>\n<meta content=\"8803025,726995222,771265067,1550970059,1661021707,1178144075,643979435,852465367,4700188\" property=\"fb:admins\"/>\n<meta content=\"https://www.facebook.com/techcrunch\" property=\"article:publisher\"/>\n<meta content=\"TechCrunch\" property=\"og:site_name\"/>\n<meta content=\"social.techcrunch.com\" property=\"og:site\"/>\n<meta content=\"Facebook\u2019s content moderation system under fire again for child safety failures \u2013 TechCrunch\" property=\"og:title\"/>\n<meta content=\"Facebook has again been criticized for failing to remove child exploitation imagery from its platform following a BBC investigation into its system for reporting inappropriate content.\" property=\"og:description\"/>\n<meta content=\"https://techcrunch.com/wp-content/uploads/2015/09/p1040182.jpg?w=662\" property=\"og:image\"/>\n<meta content=\"http://social.techcrunch.com/2017/03/07/facebooks-content-moderation-system-under-fire-for-child-safety-failures/\" property=\"og:url\"/>\n<meta content=\"article\" property=\"og:type\"/>\n<meta content=\"Facebook has again been criticized for failing to remove child exploitation imagery from its platform following a BBC investigation into its system for reporting inappropriate content.\" name=\"description\"/>\n<meta content=\"Facebook\u2019s content moderation system under fire again for child safety failures \u2013 TechCrunch\" name=\"title\"/>\n<meta content=\"summary_large_image\" name=\"twitter:card\"/>\n<meta content=\"@techcrunch\" name=\"twitter:site\"/>\n<meta content=\"Facebook\u2019s content moderation system under fire again for child safety failures \u2013 TechCrunch\" name=\"twitter:title\"/>\n<meta content=\"Facebook has again been criticized for failing to remove child exploitation imagery from its platform following a BBC investigation into its system for reporting inappropriate content.\" name=\"twitter:description\"/>\n<meta content=\"https://techcrunch.com/wp-content/uploads/2015/09/p1040182.jpg?w=662\" name=\"twitter:image\"/>\n<script type=\"text/javascript\">var ajaxurl = \"https://techcrunch.com/wp-admin/admin-ajax.php\"</script><link href=\"https://techcrunch.com/2017/03/07/facebooks-content-moderation-system-under-fire-for-child-safety-failures/amp/\" rel=\"amphtml\"/><link href=\"https://techcrunch.com/wp-content/uploads/2015/02/cropped-cropped-favicon-gradient.png?w=32\" rel=\"icon\" sizes=\"32x32\">\n<link href=\"https://techcrunch.com/wp-content/uploads/2015/02/cropped-cropped-favicon-gradient.png?w=192\" rel=\"icon\" sizes=\"192x192\"/>\n<link href=\"https://techcrunch.com/wp-content/uploads/2015/02/cropped-cropped-favicon-gradient.png?w=180\" rel=\"apple-touch-icon-precomposed\"/>\n<meta content=\"https://techcrunch.com/wp-content/uploads/2015/02/cropped-cropped-favicon-gradient.png?w=270\" name=\"msapplication-TileImage\"/>\n<script src=\"https://s.aolcdn.com/ads/adsWrapper.js\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n\ttry{adsEnableSandbox();}catch(e){}\n</script>\n</link></meta></meta></link></link></meta></head>\n<body class=\"\">\n<div id=\"root\">\n<div><!-- duplicate React-root div for styling -->\n<div class=\"content\">\n<article class=\"article-container article--post\">\n<header class=\"article__header\">\n<div class=\"article__title-wrapper\">\n<h1 class=\"article__title\">Facebook\u2019s content moderation system under fire again for child safety failures</h1>\n</div>\n<div class=\"article__byline-wrapper\">\n<div class=\"article__byline\">\n<a href=\"https://techcrunch.com/author/natasha-lomas/\">\n\t\t\tNatasha Lomas\t\t</a>\n<span class=\"article__byline__meta\">\n<a href=\"https://twitter.com/riptari\">@riptari</a>\n<span class=\"text--green\"> / </span>\n\t\t\t\t\t\t2 years\t\t</span>\n</div>\n</div>\n<div class=\"article__featured-image-wrapper breakout\">\n<img class=\"article__featured-image\" src=\"https://techcrunch.com/wp-content/uploads/2015/09/p1040182.jpg?w=662\"/>\n</div>\n</header>\n<div class=\"article-content\">\n<p id=\"speakable-summary\"><a class=\"crunchbase-link\" data-entity=\"facebook\" data-type=\"organization\" href=\"https://crunchbase.com/organization/facebook\" target=\"_blank\">Facebook <span class=\"crunchbase-tooltip-indicator\"></span></a> has again been criticized for failing to remove\u00a0child exploitation imagery from its platform following a BBC investigation into its\u00a0system for reporting inappropriate content.</p>\n<p><a href=\"http://www.bbc.com/news/uk-35521068\" target=\"_blank\">Last year</a>\u00a0the news organization reported that\u00a0closed Facebook groups were being used by pedophiles to share images of child exploitation. At the time\u00a0Facebook\u2019s head of public policy told it he was committed to removing \u201ccontent that shouldn\u2019t be there\u201d, and Facebook has\u00a0since told the BBC\u00a0it has\u00a0improved its reporting system.</p>\n<p>However,\u00a0in a follow-up article\u00a0published today, the\u00a0BBC again\u00a0<a href=\"http://www.bbc.com/news/technology-39187929\" target=\"_blank\">reports</a>\u00a0finding sexualized images of children being shared on Facebook \u2014 the vast majority of which the social networking giant failed to remove after the BBC initially reported\u00a0them.</p>\n<p>The\u00a0BBC said\u00a0it used the Facebook report button to alert the company to 100 images that\u00a0appeared to break its guidelines against obscene and/or sexually suggestive content\u00a0\u2014 including from pages that it said were explicitly for men with a sexual interest in children.</p>\n<p>Of the 100 reported images only 18 were removed by Facebook, according to the BBC. It also found\u00a0five convicted pedophiles with profiles and reported them to Facebook via its own system\u00a0but says none of the accounts were taken down\u00a0\u2014 despite Facebook\u2019s own rules forbidding convicted sex offenders from having accounts.</p>\n<p>In response to the report, the chairman of the UK House of Commons\u2019 media committee, Damian Collins, told the <a href=\"http://www.bbc.com/news/technology-39187929\" target=\"_blank\">BBC</a> he has\u00a0\u201cgrave doubts\u201d about the effectiveness of Facebook\u2019s\u00a0content moderation systems.</p>\n<p>\u201cI think it raises the question of how can users make effective complaints to Facebook about content that is disturbing, shouldn\u2019t be on the site, and have confidence that that will be acted upon,\u201d he said.</p>\n<p>In a further twist,\u00a0the news organization was subsequently reported to the police by Facebook after sharing some of the reported images directly with Facebook when it asked to send\u00a0examples of reported content that had not been removed.</p>\n<p>TechCrunch understands Facebook\u00a0was following <a href=\"https://ceop.police.uk/safety-centre/\" target=\"_blank\">CEOP</a> guidelines at this point \u2014 although the BBC\u00a0claims it only sent images after being asked by Facebook to share examples of reported content. However viewing or sharing child exploitation images is illegal in the UK. The BBC would have to have sent Facebook links to illegal\u00a0content, rather than shared images directly to avoid being reported \u2014 so it\u2019s possible this aspect of the story boils down to a miscommunication.</p>\n<p>Facebook declined to answer our\u00a0questions \u2014 and declined to be interviewed on a flagship BBC news program about its content moderation problems \u2014 but in\u00a0an emailed statement UK policy director, Simon Milner, said: \u201cWe have carefully reviewed the content referred to us and have now removed all items that were illegal or against our standards. This content is no longer on our platform. We take this matter extremely seriously and we continue to improve our reporting and take-down measures. Facebook has been recognized as one of the best platforms on the internet for child safety.\u201d</p>\n<p>\u201cIt is against the law for anyone to distribute images of child exploitation. When the BBC sent us such images we followed our industry\u2019s standard practice and reported them to CEOP. We also reported the child exploitation images that had been shared on our own platform. This matter is now in the hands of the authorities,\u201d he added.</p>\n<p>The wider issue here is that Facebook\u2019s content moderation system remains\u00a0very clearly very far from perfect. And contextual content moderation is evidently a vast problem that requires far more resources\u00a0that are being devoted to it by Facebook. Even if the company\u00a0employs \u201cthousands\u201d of human moderators, distributed\u00a0in offices\u00a0around\u00a0the world (such as Dublin for European content) to ensure 24/7 availability, it\u2019s\u00a0still a drop in the ocean for a platform with more than a billion active users sharing multiple types of content on an ongoing basis.</p>\n<p>Technology solutions can\u00a0be part of the solution \u2014 such as <a href=\"https://www.microsoft.com/en-us/PhotoDNA\" target=\"_blank\">Microsoft\u2019s PhotoDNA cloud service</a>, which\u00a0can identify known child abuse images, for example \u2014 but such systems can\u2019t\u00a0help identify\u00a0unknown obscene material. It\u2019s a problem that\u00a0necessitates\u00a0human-moderation and enough human moderators to review user reports in a timely fashion so that problem content can be identified accurately and removed promptly \u2014 in other words, the opposite of what appears to have\u00a0happened in this instance.</p>\n<p>Facebook\u2019s leadership cannot be accused of being\u00a0blind to\u00a0concerns about its content moderation failures. Indeed,\u00a0CEO Mark Zuckerberg <a href=\"https://www.facebook.com/notes/mark-zuckerberg/building-global-community/10154544292806634/\" target=\"_blank\">recently discussed</a>\u00a0the issue in an open letter \u2014 conceding the company needs to \u201cdo more\u201d. He also talked about his\u00a0hope that technology will be able to take a bigger role in fixing\u00a0the problem in future, arguing that\u00a0\u201cartificial intelligence can help provide a better approach\u201d, and saying\u00a0Facebook is working on AI-powered content flagging systems to scale to the ever-growing challenge \u2014 although he also cautioned these will take \u201cmany years to fully develop\u201d.</p>\n<p>And that\u2019s really the problem in a nutshell. Facebook is not putting in the resources needed to fix the current problem it has with moderation \u2014 even as\u00a0it directs resources into trying to come up with possible future solutions where AI-moderation can be deployed at scale. But if Zuckerberg wants to do more right now, the simple fix is to employ more humans\u00a0to review and act on reports.</p>\n</div>\n<footer class=\"article-footer\">\n<input class=\"shortlink\" readonly=\"\" title=\"Article Shortlink\" type=\"text\" value=\"\"/>\n</footer>\n</article>\n</div>\n</div><!-- end React-root duplication div -->\n</div><!--end #root-->\n<noscript style=\"display:none;\">\n<img alt=\"\" height=\"1\" src=\"https://www.facebook.com/tr?id=1447508128842484&amp;ev=PageView&amp;noscript=1\" width=\"1\"/>\n</noscript>\n<script type=\"text/javascript\">\n\t\t// Configure the PARSELY window global to disable auto-tracking.\n\t\t// Must load before the Parse.ly script itself.\n\t\twindow.PARSELY = {\n\t\t\tautotrack: false,\n\t\t\tonload:    this.onload,\n\t\t};\n\t</script>\n<script data-parsely-site=\"techcrunch.com\" id=\"parsely-cfg\" src=\"//d1z2jf7jlzjs58.cloudfront.net/keys/techcrunch.com/p.js\"></script>\n<!-- JSON-LD -->\n<script type=\"application/ld+json\">\n\t\t{\"@context\":\"http:\\/\\/schema.org\",\"publisher\":{\"@type\":\"Organization\",\"name\":\"TechCrunch\",\"logo\":{\"@type\":\"imageObject\",\"url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/themes\\/techcrunch-2017\\/images\\/logo-json-ld.png\",\"width\":\"600\",\"height\":\"60\"}},\"@type\":\"NewsArticle\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\/\\/techcrunch.com\\/2017\\/03\\/07\\/facebooks-content-moderation-system-under-fire-for-child-safety-failures\\/\"},\"headline\":\"Facebook&#8217;s content moderation system under fire again for child safety failures\",\"image\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=680\",\"width\":680,\"height\":411},\"datePublished\":\"2017-03-07T14:28:28+00:00\",\"dateModified\":\"2017-03-07T18:59:31+00:00\",\"author\":[{\"@type\":\"Person\",\"name\":\"Natasha Lomas\"}],\"description\":\"Facebook has again been criticized for failing to remove child exploitation imagery from its platform following a BBC investigation into its system for reporting inappropriate content.\",\"speakable\":{\"@type\":\"SpeakableSpecification\",\"cssSelector\":[\".alpha\",\"#speakable-summary\"]}}\t</script>\n<!-- End JSON-LD -->\n<script src=\"https://use.typekit.net/svv7knm.js\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\ntry{Typekit.load({ async: true });}catch(e){}\n</script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar tc_app_data = {\"ads\":{\"adpage\":\"https:\\/\\/techcrunch.com\\/wp-content\\/themes\\/techcrunch-2017\\/features\\/ads\\/_uac\\/adpage.html\",\"gemini_enabled\":true,\"gemini_codes\":{\"position_4\":{\"mobile\":\"ae64471c-14c2-4457-8e9b-a5190206eafd\",\"desktop\":\"b2018d9e-dedc-4e85-8823-b06917beb892\"},\"position_8\":{\"mobile\":\"619392a1-b497-4aa9-b683-24aab7246c16\",\"desktop\":\"05c0b21d-e742-494d-ac59-474e3feaa4b8\"}},\"mns\":[{\"where\":\"*\",\"placements\":{\"native\":\"93501877\",\"mobile_native\":\"93501878\",\"leaderboard\":\"93484975\",\"rightrail\":\"93484976\",\"rightrail_on_view\":\"93484977\",\"mobile_300x250\":\"93484973\",\"mobile_dynamic\":\"93484974\",\"amp\":\"93523784\",\"inline_leaderboard\":\"93484932\",\"inline_mobile_300x250\":\"93484930\",\"inline_amp\":\"963874680\"}},{\"where\":{\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93484953\"}},{\"where\":{\"post_type\":[\"tc_sponsored_post\"]},\"placements\":{\"leaderboard\":\"963872468\",\"leaderboard_on_view\":\"963872469\",\"rightrail\":\"963872467\",\"rightrail_on_view\":\"963872467\",\"mobile_320x50\":\"963872466\",\"mobile_dynamic\":\"963872466\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"crunchbase-video-hub\"]},\"placements\":{\"mobile_300x250\":\"93487470\",\"mobile_dynamic\":\"93487469\",\"leaderboard\":\"93487468\",\"rightrail\":\"93487467\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"enterprise\"]},\"placements\":{\"mobile_300x250\":\"93484901\",\"mobile_dynamic\":\"93484902\",\"leaderboard\":\"93484903\",\"rightrail\":\"93484904\",\"rightrail_on_view\":\"93484905\",\"amp\":\"93523756\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"enterprise\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93512990\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"gadgets\"]},\"placements\":{\"mobile_300x250\":\"93484912\",\"mobile_dynamic\":\"93484913\",\"leaderboard\":\"93484914\",\"rightrail\":\"93484915\",\"rightrail_on_view\":\"93484916\",\"amp\":\"93523764\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"gadgets\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93513296\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"mobile\"]},\"placements\":{\"mobile_native\":\"93484962\",\"mobile_300x250\":\"93484960\",\"mobile_dynamic\":\"93484961\",\"leaderboard\":\"93484957\",\"rightrail\":\"93484958\",\"rightrail_on_view\":\"93484959\",\"amp\":\"93523763\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"mobile\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93510142\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"startups\"]},\"placements\":{\"gallery_300x250\":\"93511985\",\"mobile_300x250\":\"93484986\",\"mobile_dynamic\":\"93484987\",\"leaderboard\":\"93484988\",\"rightrail\":\"93484989\",\"rightrail_on_view\":\"93484990\",\"amp\":\"93523762\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"startups\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93511984\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"apps\"]},\"placements\":{\"mobile_300x250\":\"963891138\",\"mobile_dynamic\":\"963891134\",\"leaderboard\":\"963891132\",\"rightrail\":\"963891133\",\"rightrail_on_view\":\"963891136\",\"amp\":\"963891137\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"mobile\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"963891131\"}},{\"where\":{\"post_type\":[\"tc_marketing\"]},\"placements\":{\"mobile_dynamic\":\"93484859\",\"leaderboard\":\"93484860\",\"leaderboard_on_view\":\"93484861\",\"rightrail\":\"93484862\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"apple\"]},\"placements\":{\"mobile_300x250\":\"93484869\",\"mobile_dynamic\":\"93484870\",\"leaderboard\":\"93484866\",\"rightrail\":\"93484867\",\"rightrail_on_view\":\"93484868\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"back-to-school\",\"backtoschool\",\"backtoschool13\"]},\"placements\":{\"mobile_300x250\":\"93484871\",\"mobile_dynamic\":\"93484872\",\"leaderboard\":\"93484873\",\"rightrail\":\"93484874\",\"rightrail_on_view\":\"93484875\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"ces\"]},\"placements\":{\"gallery_300x250\":\"963853166\",\"mobile_300x250\":\"93484876\",\"mobile_dynamic\":\"93484877\",\"leaderboard\":\"93484878\",\"rightrail\":\"93484879\",\"rightrail_on_view\":\"93484880\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"ces\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"963853167\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"disrupt\"]},\"placements\":{\"mobile_300x250\":\"93484895\",\"mobile_dynamic\":\"93484896\",\"leaderboard\":\"93484897\",\"rightrail\":\"93484898\",\"rightrail_on_view\":\"93484899\",\"amp\":\"93523765\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"gift-guide-2018\"]},\"placements\":{\"gallery_300x250\":\"93518231\",\"mobile_300x250\":\"93484930\",\"mobile_dynamic\":\"93484931\",\"leaderboard\":\"93484932\",\"rightrail\":\"93484933\",\"rightrail_on_view\":\"93484934\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"gift-guide-2018\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93518230\"}},{\"where\":{\"url\":\"\\/pages\\/gift-guide-2018\\/\"},\"placements\":{\"gallery_300x250\":\"93518231\",\"mobile_300x250\":\"93484930\",\"mobile_dynamic\":\"93484931\",\"leaderboard\":\"93484932\",\"rightrail\":\"93484933\",\"rightrail_on_view\":\"93484934\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"sxsw\"]},\"placements\":{\"gallery_300x250\":\"963858038\",\"mobile_300x250\":\"963858040\",\"mobile_dynamic\":\"963858041\",\"leaderboard\":\"963858042\",\"rightrail\":\"963858043\",\"rightrail_on_view\":\"963858044\"}},{\"where\":{\"taxonomy\":\"post_tag\",\"terms\":[\"sxsw\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"963858039\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"tc_video\"]},\"placements\":{\"leaderboard\":\"963874666\",\"rightrail\":\"963874667\",\"rightrail_on_view\":\"963874668\",\"mobile_320x50\":\"93485001\",\"mobile_300x250\":\"93485000\",\"mobile_dynamic\":\"93484943\",\"amp\":\"93523757\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"developer\"]},\"placements\":{\"gallery_300x250\":\"93510995\",\"mobile_300x250\":\"93484890\",\"mobile_dynamic\":\"93484891\",\"leaderboard\":\"93484892\",\"rightrail\":\"93484893\",\"rightrail_on_view\":\"93484894\",\"amp\":\"93523761\"}},{\"where\":{\"taxonomy\":\"category\",\"terms\":[\"developer\"],\"post_type\":[\"tc-media-gallery\"]},\"placements\":{\"leaderboard\":\"93510992\"}},{\"where\":{\"url\":\"\\/video\\/\"},\"placements\":{\"leaderboard\":\"963874666\",\"rightrail\":\"963874667\",\"rightrail_on_view\":\"963874668\",\"mobile_320x50\":\"93485001\",\"mobile_300x250\":\"93485000\",\"mobile_dynamic\":\"93484943\",\"amp\":\"93523757\"}},{\"where\":{\"url\":\"\\/(page\\/\\\\d+)?\"},\"placements\":{\"native\":\"93484857\",\"leaderboard\":\"93484945\",\"rightrail\":\"93484946\",\"rightrail_on_view\":\"93484947\",\"amp\":\"93523758\",\"mobile_native\":\"93484858\",\"mobile_300x250\":\"93484942\",\"mobile_dynamic\":\"93484943\"}}]},\"assetURI\":\"https:\\/\\/techcrunch.com\\/wp-content\\/themes\\/techcrunch-2017\",\"breaking\":\"\",\"ec_promo\":{\"enabled\":true,\"title\":\"Extra Crunch\",\"desc\":\"Exclusive articles, conference calls, no banner ads, and more.\",\"url\":\"\\/subscribe\\/?tpcc=rightrailapril19\",\"button_text\":\"Try it free\"},\"live_event\":\"0\",\"livestream_hash\":null,\"feature_island\":[],\"isAdminBar\":\"\",\"marketoEventId\":\"1004\",\"marketoBrandStudioId\":\"1740\",\"menus\":{\"main\":[{\"id\":335981,\"order\":1,\"parent\":0,\"text\":\"Startups\",\"url\":\"https:\\/\\/techcrunch.com\\/startups\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":20429,\"object\":\"category\",\"type\":\"taxonomy\",\"type_label\":\"Category\",\"children\":[]},{\"id\":1599989,\"order\":2,\"parent\":0,\"text\":\"Apps\",\"url\":\"https:\\/\\/techcrunch.com\\/apps\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":449557102,\"object\":\"category\",\"type\":\"taxonomy\",\"type_label\":\"Category\",\"children\":[]},{\"id\":335983,\"order\":3,\"parent\":0,\"text\":\"Gadgets\",\"url\":\"https:\\/\\/techcrunch.com\\/gadgets\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":449557086,\"object\":\"category\",\"type\":\"taxonomy\",\"type_label\":\"Category\",\"children\":[]},{\"id\":335986,\"order\":4,\"parent\":0,\"text\":\"Videos\",\"url\":\"\\/video\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":335986,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1761192,\"order\":5,\"parent\":0,\"text\":\"Podcasts\",\"url\":\"https:\\/\\/techcrunch.com\\/pages\\/podcasts\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1760429,\"object\":\"page\",\"type\":\"post_type\",\"type_label\":\"Page\",\"children\":[]},{\"id\":1781882,\"order\":6,\"parent\":0,\"text\":\"Extra Crunch\",\"url\":\"\\/extracrunch\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1781882,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1599991,\"order\":7,\"parent\":0,\"text\":\"\\u2014\",\"url\":\"#\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1599991,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1599990,\"order\":8,\"parent\":0,\"text\":\"Events\",\"url\":\"\\/events\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1599990,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1752899,\"order\":9,\"parent\":0,\"text\":\"Advertise\",\"url\":\"https:\\/\\/techcrunch.com\\/pages\\/advertisement-events-calendar\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1416499,\"object\":\"page\",\"type\":\"post_type\",\"type_label\":\"Page\",\"children\":[]},{\"id\":1599992,\"order\":10,\"parent\":0,\"text\":\"Crunchbase\",\"url\":\"http:\\/\\/crunchbase.com\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1599992,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}],\"submenu\":[{\"id\":1599997,\"order\":1,\"parent\":0,\"text\":\"Topics\",\"url\":\"#\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1599997,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[{\"id\":1600003,\"order\":2,\"parent\":1599997,\"text\":\"Social\",\"url\":\"https:\\/\\/techcrunch.com\\/social\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"How technology is shaping the way we live with each other\",\"object_id\":3457,\"object\":\"category\",\"type\":\"taxonomy\",\"type_label\":\"Category\",\"children\":[]},{\"id\":1600004,\"order\":3,\"parent\":1599997,\"text\":\"Mobile\",\"url\":\"https:\\/\\/techcrunch.com\\/mobile\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"The apps, platforms and businesses redefining how we use computers\",\"object_id\":449557028,\"object\":\"category\",\"type\":\"taxonomy\",\"type_label\":\"Category\",\"children\":[]},{\"id\":1600005,\"order\":4,\"parent\":1599997,\"text\":\"Enterprise\",\"url\":\"https:\\/\\/techcrunch.com\\/enterprise\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"How cloud computing, big data and new devices are changing work\",\"object_id\":449557044,\"object\":\"category\",\"type\":\"taxonomy\",\"type_label\":\"Category\",\"children\":[]}]},{\"id\":1599998,\"order\":5,\"parent\":0,\"text\":\"About\",\"url\":\"#\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1599998,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[{\"id\":1601717,\"order\":6,\"parent\":1599998,\"text\":\"Staff\",\"url\":\"\\/pages\\/about-techcrunch\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1601717,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1600007,\"order\":7,\"parent\":1599998,\"text\":\"Contact Us\",\"url\":\"https:\\/\\/techcrunch.com\\/pages\\/contact-us\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":672,\"object\":\"page\",\"type\":\"post_type\",\"type_label\":\"Page\",\"children\":[]},{\"id\":1600006,\"order\":8,\"parent\":1599998,\"text\":\"Advertising Opportunities\",\"url\":\"https:\\/\\/techcrunch.com\\/pages\\/advertisement-events-calendar\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1416499,\"object\":\"page\",\"type\":\"post_type\",\"type_label\":\"Page\",\"children\":[]}]},{\"id\":1600000,\"order\":9,\"parent\":0,\"text\":\"More TechCrunch\",\"url\":\"#\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600000,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[{\"id\":1600009,\"order\":10,\"parent\":1600000,\"text\":\"Startup Battlefield\",\"url\":\"\\/startup-battlefield\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600009,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1795710,\"order\":11,\"parent\":1600000,\"text\":\"Sponsored Content\",\"url\":\"\\/sponsored\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1795710,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1600010,\"order\":12,\"parent\":1600000,\"text\":\"Include\",\"url\":\"\\/include\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600010,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1600012,\"order\":13,\"parent\":1600000,\"text\":\"Crunchboard\",\"url\":\"http:\\/\\/crunchboard.com\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600012,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1600011,\"order\":14,\"parent\":1600000,\"text\":\"TechCrunch Store\",\"url\":\"http:\\/\\/techcrunchstore.com\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600011,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1620756,\"order\":15,\"parent\":1600000,\"text\":\"Apply to Startup Events\",\"url\":\"https:\\/\\/techcrunch.com\\/pages\\/tc-startup-programs\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1617703,\"object\":\"page\",\"type\":\"post_type\",\"type_label\":\"Page\",\"children\":[]}]},{\"id\":1600001,\"order\":16,\"parent\":0,\"text\":\"Read Anywhere\",\"url\":\"#\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600001,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[{\"id\":1600013,\"order\":17,\"parent\":1600001,\"text\":\"App Store\",\"url\":\"https:\\/\\/itunes.apple.com\\/us\\/app\\/techcrunch\\/id526058642?mt=8\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600013,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1600014,\"order\":18,\"parent\":1600001,\"text\":\"Google Play\",\"url\":\"https:\\/\\/play.google.com\\/store\\/apps\\/details?id=com.aol.mobile.techcrunch\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600014,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}]},{\"id\":1600002,\"order\":19,\"parent\":0,\"text\":\"International\",\"url\":\"#\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600002,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[{\"id\":1600015,\"order\":20,\"parent\":1600002,\"text\":\"China\",\"url\":\"http:\\/\\/techcrunch.cn\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600015,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1600016,\"order\":21,\"parent\":1600002,\"text\":\"Japan\",\"url\":\"http:\\/\\/jp.techcrunch.com\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1600016,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}]}],\"footer\":[{\"id\":1787716,\"order\":1,\"parent\":0,\"text\":\"TechCrunch\",\"url\":\"https:\\/\\/techcrunch.com\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1787716,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1601925,\"order\":2,\"parent\":0,\"text\":\"Privacy Policy\",\"url\":\"https:\\/\\/policies.oath.com\\/xw\\/en\\/oath\\/privacy\\/intl\\/index.html\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1601925,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1601926,\"order\":3,\"parent\":0,\"text\":\"About Our Ads\",\"url\":\"http:\\/\\/adinfo.aol.com\\/about-our-ads\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1601926,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1687671,\"order\":4,\"parent\":0,\"text\":\"Code of Conduct\",\"url\":\"https:\\/\\/techcrunch.com\\/pages\\/code-of-conduct\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1678717,\"object\":\"page\",\"type\":\"post_type\",\"type_label\":\"Page\",\"children\":[]},{\"id\":1601928,\"order\":5,\"parent\":0,\"text\":\"Terms of Service\",\"url\":\"https:\\/\\/policies.oath.com\\/xw\\/en\\/oath\\/terms\\/otos\\/index.html\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1601928,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}],\"include\":[{\"id\":1601974,\"order\":1,\"parent\":0,\"text\":\"Our Mission\",\"url\":\"\\/include\\/mission-statement\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1601974,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1601975,\"order\":2,\"parent\":0,\"text\":\"Office Hours\",\"url\":\"\\/include\\/office-hours\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1601975,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}],\"startup-battlefield\":[{\"id\":1602061,\"order\":1,\"parent\":0,\"text\":\"About\",\"url\":\"\\/startup-battlefield\\/about\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1602061,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1602062,\"order\":2,\"parent\":0,\"text\":\"FAQ\",\"url\":\"\\/startup-battlefield\\/faq\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1602062,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1602063,\"order\":3,\"parent\":0,\"text\":\"Leaderboard\",\"url\":\"\\/startup-battlefield\\/leaderboard\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1602063,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1602065,\"order\":4,\"parent\":0,\"text\":\"Battlefield Home\",\"url\":\"\\/startup-battlefield\\/\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1602065,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1787197,\"order\":5,\"parent\":0,\"text\":\"Apply Now\",\"url\":\"https:\\/\\/apply.techcrunch.com\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"apply-now-link\"],\"description\":\"\",\"object_id\":1787197,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}],\"video-hub\":[{\"id\":1605165,\"order\":1,\"parent\":0,\"text\":\"News\",\"url\":\"\\/shows\\/tctv-news\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605165,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605166,\"order\":2,\"parent\":0,\"text\":\"Gadgets\",\"url\":\"\\/shows\\/gadgets\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605166,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605167,\"order\":3,\"parent\":0,\"text\":\"Features\",\"url\":\"\\/shows\\/features\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605167,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605168,\"order\":4,\"parent\":0,\"text\":\"Reviews\",\"url\":\"\\/shows\\/reviews\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605168,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605169,\"order\":5,\"parent\":0,\"text\":\"Interviews\",\"url\":\"\\/shows\\/interviews\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605169,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605170,\"order\":6,\"parent\":0,\"text\":\"Apps\",\"url\":\"\\/shows\\/apps\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605170,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605171,\"order\":7,\"parent\":0,\"text\":\"Disrupt\",\"url\":\"\\/shows\\/techcrunch-disrupt\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605171,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605172,\"order\":8,\"parent\":0,\"text\":\"Battlefield\",\"url\":\"\\/shows\\/techcrunch-battlefield\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605172,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605173,\"order\":9,\"parent\":0,\"text\":\"Sessions\",\"url\":\"\\/shows\\/tc-sessions\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605173,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605174,\"order\":10,\"parent\":0,\"text\":\"Crunch Report\",\"url\":\"\\/shows\\/crunch-report\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605174,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605175,\"order\":11,\"parent\":0,\"text\":\"Judah vs the Machines\",\"url\":\"\\/shows\\/judah-vs-the-machines\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605175,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605176,\"order\":12,\"parent\":0,\"text\":\"Down Round\",\"url\":\"\\/shows\\/down-round\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605176,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605177,\"order\":13,\"parent\":0,\"text\":\"Trust Disrupted\",\"url\":\"\\/shows\\/trust-disrupted\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605177,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605178,\"order\":14,\"parent\":0,\"text\":\"Built in Brooklyn\",\"url\":\"\\/shows\\/built-in-brooklyn\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605178,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605179,\"order\":15,\"parent\":0,\"text\":\"Inside Jobs\",\"url\":\"\\/shows\\/inside-jobs\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605179,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]},{\"id\":1605180,\"order\":16,\"parent\":0,\"text\":\"TC Cribs\",\"url\":\"\\/shows\\/tc-cribs\",\"attr\":\"\",\"target\":\"\",\"classes\":[\"\"],\"description\":\"\",\"object_id\":1605180,\"object\":\"custom\",\"type\":\"custom\",\"type_label\":\"Custom Link\",\"children\":[]}]},\"playlistData\":{\"homepage\":[],\"videohub\":[]},\"entities\":{\"posts\":[{\"id\":1461242,\"date\":\"2017-03-07T06:28:28\",\"date_gmt\":\"2017-03-07T14:28:28\",\"guid\":{\"rendered\":\"https:\\/\\/beta.techcrunch.com\\/?p=1461242\"},\"modified\":\"2017-03-07T10:59:31\",\"modified_gmt\":\"2017-03-07T18:59:31\",\"slug\":\"facebooks-content-moderation-system-under-fire-for-child-safety-failures\",\"status\":\"publish\",\"type\":\"post\",\"link\":\"https:\\/\\/techcrunch.com\\/2017\\/03\\/07\\/facebooks-content-moderation-system-under-fire-for-child-safety-failures\\/\",\"title\":{\"rendered\":\"Facebook&#8217;s content moderation system under fire again for child safety failures\"},\"content\":{\"rendered\":\"<p id=\\\"speakable-summary\\\"><a class=\\\"crunchbase-link\\\" href=\\\"https:\\/\\/crunchbase.com\\/organization\\/facebook\\\" target=\\\"_blank\\\" data-type=\\\"organization\\\" data-entity=\\\"facebook\\\">Facebook <span class=\\\"crunchbase-tooltip-indicator\\\"><\\/span><\\/a> has again been criticized for failing to remove\\u00a0child exploitation imagery from its platform following a BBC investigation into its\\u00a0system for reporting inappropriate content.<\\/p>\\n<p><a target=\\\"_blank\\\" href=\\\"http:\\/\\/www.bbc.com\\/news\\/uk-35521068\\\">Last year<\\/a>\\u00a0the news organization reported that\\u00a0closed Facebook groups were being used by pedophiles to share images of child exploitation. At the time\\u00a0Facebook&#8217;s head of public policy told it he was committed to removing &#8220;content that shouldn&#8217;t be there&#8221;, and Facebook has\\u00a0since told the BBC\\u00a0it has\\u00a0improved its reporting system.<\\/p>\\n<p>However,\\u00a0in a follow-up article\\u00a0published today, the\\u00a0BBC again\\u00a0<a target=\\\"_blank\\\" href=\\\"http:\\/\\/www.bbc.com\\/news\\/technology-39187929\\\">reports<\\/a>\\u00a0finding sexualized images of children being shared on Facebook &#8212; the vast majority of which the social networking giant failed to remove after the BBC initially reported\\u00a0them.<\\/p>\\n<p>The\\u00a0BBC said\\u00a0it used the Facebook report button to alert the company to 100 images that\\u00a0appeared to break its guidelines against obscene and\\/or sexually suggestive content\\u00a0&#8212; including from pages that it said were explicitly for men with a sexual interest in children.<\\/p>\\n<p>Of the 100 reported images only 18 were removed by Facebook, according to the BBC. It also found\\u00a0five convicted pedophiles with profiles and reported them to Facebook via its own system\\u00a0but says none of the accounts were taken down\\u00a0&#8212; despite Facebook&#8217;s own rules forbidding convicted sex offenders from having accounts.<\\/p>\\n<p>In response to the report, the chairman of the UK House of Commons&#8217; media committee, Damian Collins, told the <a target=\\\"_blank\\\" href=\\\"http:\\/\\/www.bbc.com\\/news\\/technology-39187929\\\">BBC<\\/a> he has\\u00a0&#8220;grave doubts&#8221; about the effectiveness of Facebook&#8217;s\\u00a0content moderation systems.<\\/p>\\n<p>&#8220;I think it raises the question of how can users make effective complaints to Facebook about content that is disturbing, shouldn&#8217;t be on the site, and have confidence that that will be acted upon,&#8221; he said.<\\/p>\\n<p>In a further twist,\\u00a0the news organization was subsequently reported to the police by Facebook after sharing some of the reported images directly with Facebook when it asked to send\\u00a0examples of reported content that had not been removed.<\\/p>\\n<p>TechCrunch understands Facebook\\u00a0was following <a target=\\\"_blank\\\" href=\\\"https:\\/\\/ceop.police.uk\\/safety-centre\\/\\\">CEOP<\\/a> guidelines at this point &#8212; although the BBC\\u00a0claims it only sent images after being asked by Facebook to share examples of reported content. However viewing or sharing child exploitation images is illegal in the UK. The BBC would have to have sent Facebook links to illegal\\u00a0content, rather than shared images directly to avoid being reported &#8212; so it&#8217;s possible this aspect of the story boils down to a miscommunication.<\\/p>\\n<p>Facebook declined to answer our\\u00a0questions &#8212; and declined to be interviewed on a flagship BBC news program about its content moderation problems &#8212; but in\\u00a0an emailed statement UK policy director, Simon Milner, said: &#8220;We have carefully reviewed the content referred to us and have now removed all items that were illegal or against our standards. This content is no longer on our platform. We take this matter extremely seriously and we continue to improve our reporting and take-down measures. Facebook has been recognized as one of the best platforms on the internet for child safety.&#8221;<\\/p>\\n<p>\\u201cIt is against the law for anyone to distribute images of child exploitation. When the BBC sent us such images we followed our industry\\u2019s standard practice and reported them to CEOP. We also reported the child exploitation images that had been shared on our own platform. This matter is now in the hands of the authorities,\\u201d he added.<\\/p>\\n<p>The wider issue here is that Facebook&#8217;s content moderation system remains\\u00a0very clearly very far from perfect. And contextual content moderation is evidently a vast problem that requires far more resources\\u00a0that are being devoted to it by Facebook. Even if the company\\u00a0employs &#8220;thousands&#8221; of human moderators, distributed\\u00a0in offices\\u00a0around\\u00a0the world (such as Dublin for European content) to ensure 24\\/7 availability, it&#8217;s\\u00a0still a drop in the ocean for a platform with more than a billion active users sharing multiple types of content on an ongoing basis.<\\/p>\\n<p>Technology solutions can\\u00a0be part of the solution &#8212; such as <a target=\\\"_blank\\\" href=\\\"https:\\/\\/www.microsoft.com\\/en-us\\/PhotoDNA\\\">Microsoft&#8217;s PhotoDNA cloud service<\\/a>, which\\u00a0can identify known child abuse images, for example &#8212; but such systems can&#8217;t\\u00a0help identify\\u00a0unknown obscene material. It&#8217;s a problem that\\u00a0necessitates\\u00a0human-moderation and enough human moderators to review user reports in a timely fashion so that problem content can be identified accurately and removed promptly &#8212; in other words, the opposite of what appears to have\\u00a0happened in this instance.<\\/p>\\n<p>Facebook&#8217;s leadership cannot be accused of being\\u00a0blind to\\u00a0concerns about its content moderation failures. Indeed,\\u00a0CEO Mark Zuckerberg <a target=\\\"_blank\\\" href=\\\"https:\\/\\/www.facebook.com\\/notes\\/mark-zuckerberg\\/building-global-community\\/10154544292806634\\/\\\">recently discussed<\\/a>\\u00a0the issue in an open letter &#8212; conceding the company needs to &#8220;do more&#8221;. He also talked about his\\u00a0hope that technology will be able to take a bigger role in fixing\\u00a0the problem in future, arguing that\\u00a0&#8220;artificial intelligence can help provide a better approach&#8221;, and saying\\u00a0Facebook is working on AI-powered content flagging systems to scale to the ever-growing challenge &#8212; although he also cautioned these will take &#8220;many years to fully develop&#8221;.<\\/p>\\n<p>And that&#8217;s really the problem in a nutshell. Facebook is not putting in the resources needed to fix the current problem it has with moderation &#8212; even as\\u00a0it directs resources into trying to come up with possible future solutions where AI-moderation can be deployed at scale. But if Zuckerberg wants to do more right now, the simple fix is to employ more humans\\u00a0to review and act on reports.<\\/p>\\n\",\"protected\":false},\"excerpt\":{\"rendered\":\"<p>Facebook has again been criticized for failing to remove child exploitation imagery from its platform following a BBC investigation into its system for reporting inappropriate content.<\\/p>\\n\",\"protected\":false},\"author\":39990176,\"featured_media\":1210711,\"comment_status\":\"open\",\"ping_status\":\"closed\",\"sticky\":false,\"template\":\"\",\"format\":\"standard\",\"meta\":{\"outcome\":\"\",\"status\":\"\",\"crunchbase_tag\":0,\"amp_status\":\"\",\"relegenceEntities\":[],\"relegenceSubjects\":[],\"jetpack_publicize_message\":\"\"},\"categories\":[449557100,3457,17396],\"tags\":[2988,449559371,449548756,81819,119,49818],\"crunchbase_tag\":[204332940,197883035,197264633],\"tc_stories_tax\":[],\"tc_event\":[],\"jetpack_featured_media_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg\",\"jetpack_publicize_connections\":[],\"shortlink\":\"http:\\/\\/tcrn.ch\\/2mx1kxl\",\"rapidData\":{\"pt\":\"\",\"pct\":\"\"},\"featured\":false,\"subtitle\":\"\",\"fundingRound\":false,\"seoTitle\":\"\",\"seoDescription\":\"\",\"premiumContent\":false,\"premiumCutoffPercent\":1,\"tc_cb_mapping\":[{\"slug\":\"bbc\",\"cb_name\":\"BBC (British Broadcasting Corporation)\",\"cb_slug\":\"bbc-organization\",\"cb_link\":\"https:\\/\\/crunchbase.com\\/organization\\/bbc\"},{\"slug\":\"social-media\",\"cb_name\":\"Twitter\",\"cb_slug\":\"twitter-organization\",\"cb_link\":\"https:\\/\\/crunchbase.com\\/organization\\/twitter\"},{\"slug\":\"facebook\",\"cb_name\":\"Facebook\",\"cb_slug\":\"facebook-organization\",\"cb_link\":\"https:\\/\\/crunchbase.com\\/organization\\/facebook\"}],\"associatedEvent\":null,\"event\":null,\"authors\":[39990176],\"hideFeaturedImage\":false,\"relatedArticles\":[],\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts\\/1461242\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/types\\/post\"}],\"version-history\":[{\"count\":13,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts\\/1461242\\/revisions\"}],\"predecessor-version\":[{\"id\":1461465,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts\\/1461242\\/revisions\\/1461465\"}],\"authors\":[{\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\\/39990176\"}],\"replies\":[{\"embeddable\":true,\"count\":0,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/comments?post=1461242&order=asc&tc_hierarchical=flat\"}],\"https:\\/\\/techcrunch.com\\/edit\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-admin\\/post.php?post=1461242&action=edit\"}],\"author\":[{\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\\/39990176\"}],\"wp:featuredmedia\":[{\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/media\\/1210711\"}],\"wp:attachment\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/media?parent=1461242\"}],\"wp:term\":[{\"taxonomy\":\"category\",\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories?post=1461242\"},{\"taxonomy\":\"post_tag\",\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags?post=1461242\"},{\"taxonomy\":\"_tc_cb_tag_taxonomy\",\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag?post=1461242\"},{\"taxonomy\":\"tc_stories_tax\",\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_stories_tax?post=1461242\"},{\"taxonomy\":\"tc_event\",\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_event?post=1461242\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]},\"_embedded\":{\"authors\":[{\"id\":39990176,\"name\":\"Natasha Lomas\",\"url\":\"\",\"description\":\"\",\"link\":\"https:\\/\\/techcrunch.com\\/author\\/natasha-lomas\\/\",\"slug\":\"natasha-lomas\",\"avatar_urls\":{\"24\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/68a02f90ad0a6349a7b852ddce6f93e4?s=24&d=identicon&r=g\",\"48\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/68a02f90ad0a6349a7b852ddce6f93e4?s=48&d=identicon&r=g\",\"96\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/68a02f90ad0a6349a7b852ddce6f93e4?s=96&d=identicon&r=g\"},\"links\":{\"twitter\":\"https:\\/\\/twitter.com\\/riptari\",\"linkedin\":\"http:\\/\\/www.linkedin.com\\/in\\/nlomas\",\"crunchbase\":\"https:\\/\\/www.crunchbase.com\\/person\\/natasha-lomas\"},\"position\":\"Writer\",\"cbDescription\":\"<p>Natasha is a senior reporter for TechCrunch, joining September 2012, based in Europe. She joined TC after a stint reviewing smartphones for CNET UK and, prior to that, more than five years covering business technology for silicon.com (now folded into TechRepublic), where she focused on mobile and wireless, telecoms &amp; networking, and IT skills issues. She has also freelanced for organisations including The Guardian and the BBC. Natasha holds a First Class degree in English from Cambridge University, and an MA in journalism from Goldsmiths College, University of London.<\\/p>\",\"cbAvatar\":\"https:\\/\\/crunchbase-production-res.cloudinary.com\\/image\\/upload\\/v1397184383\\/575a81841b1b431463585c830bffd373.jpg\",\"twitter\":\"riptari\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\\/39990176\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\"}]}}],\"author\":[{\"id\":39990176,\"name\":\"Natasha Lomas\",\"url\":\"\",\"description\":\"\",\"link\":\"https:\\/\\/techcrunch.com\\/author\\/natasha-lomas\\/\",\"slug\":\"natasha-lomas\",\"avatar_urls\":{\"24\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/68a02f90ad0a6349a7b852ddce6f93e4?s=24&d=identicon&r=g\",\"48\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/68a02f90ad0a6349a7b852ddce6f93e4?s=48&d=identicon&r=g\",\"96\":\"https:\\/\\/secure.gravatar.com\\/avatar\\/68a02f90ad0a6349a7b852ddce6f93e4?s=96&d=identicon&r=g\"},\"links\":{\"twitter\":\"https:\\/\\/twitter.com\\/riptari\",\"linkedin\":\"http:\\/\\/www.linkedin.com\\/in\\/nlomas\",\"crunchbase\":\"https:\\/\\/www.crunchbase.com\\/person\\/natasha-lomas\"},\"position\":\"Writer\",\"cbDescription\":\"<p>Natasha is a senior reporter for TechCrunch, joining September 2012, based in Europe. She joined TC after a stint reviewing smartphones for CNET UK and, prior to that, more than five years covering business technology for silicon.com (now folded into TechRepublic), where she focused on mobile and wireless, telecoms &amp; networking, and IT skills issues. She has also freelanced for organisations including The Guardian and the BBC. Natasha holds a First Class degree in English from Cambridge University, and an MA in journalism from Goldsmiths College, University of London.<\\/p>\",\"cbAvatar\":\"https:\\/\\/crunchbase-production-res.cloudinary.com\\/image\\/upload\\/v1397184383\\/575a81841b1b431463585c830bffd373.jpg\",\"twitter\":\"riptari\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\\/39990176\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\"}]}}],\"wp:featuredmedia\":[{\"id\":1210711,\"date\":\"2015-09-17T04:32:41\",\"slug\":\"p1040182\",\"type\":\"attachment\",\"link\":\"https:\\/\\/techcrunch.com\\/2015\\/09\\/17\\/access-vs-encryption\\/p1040182\\/\",\"title\":{\"rendered\":\"Facebook surveillance\"},\"author\":39990176,\"license\":\"\",\"authors\":[39990176],\"caption\":{\"rendered\":\"\"},\"alt_text\":\"\",\"media_type\":\"image\",\"mime_type\":\"image\\/jpeg\",\"media_details\":{\"width\":2055,\"height\":1242,\"file\":\"2015\\/09\\/p1040182.jpg\",\"sizes\":{\"thumbnail\":{\"file\":\"p1040182.jpg?resize=150,91\",\"width\":150,\"height\":91,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=150\"},\"medium\":{\"file\":\"p1040182.jpg?resize=300,181\",\"width\":300,\"height\":181,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=300\"},\"medium_large\":{\"file\":\"p1040182.jpg?resize=768,464\",\"width\":768,\"height\":464,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=1024\"},\"large\":{\"file\":\"p1040182.jpg?resize=680,411\",\"width\":680,\"height\":411,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=680\"},\"guest-author-32\":{\"file\":\"p1040182.jpg?resize=32,32\",\"width\":32,\"height\":32,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=32&h=32&crop=1\"},\"guest-author-50\":{\"file\":\"p1040182.jpg?resize=50,50\",\"width\":50,\"height\":50,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=50&h=50&crop=1\"},\"guest-author-64\":{\"file\":\"p1040182.jpg?resize=64,64\",\"width\":64,\"height\":64,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=64&h=64&crop=1\"},\"guest-author-96\":{\"file\":\"p1040182.jpg?resize=96,96\",\"width\":96,\"height\":96,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=96&h=96&crop=1\"},\"guest-author-128\":{\"file\":\"p1040182.jpg?resize=128,128\",\"width\":128,\"height\":128,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=128&h=128&crop=1\"},\"concierge-thumb\":{\"file\":\"p1040182.jpg?resize=50,30\",\"width\":50,\"height\":30,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg?w=50\"},\"full\":{\"file\":\"p1040182.jpg\",\"width\":1024,\"height\":619,\"mime_type\":\"image\\/jpeg\",\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg\"}},\"image_meta\":{\"aperture\":3.5,\"credit\":\"\",\"camera\":\"DMC-GX1\",\"caption\":\"\",\"created_timestamp\":1442490146,\"copyright\":\"\",\"focal_length\":\"14\",\"iso\":\"640\",\"shutter_speed\":\"0.016666666666667\",\"title\":\"\",\"orientation\":1},\"filesize\":663661},\"source_url\":\"https:\\/\\/techcrunch.com\\/wp-content\\/uploads\\/2015\\/09\\/p1040182.jpg\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/media\\/1210711\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/media\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/types\\/attachment\"}],\"replies\":[{\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/comments?post=1210711\"}],\"author\":[{\"embeddable\":true,\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/tc\\/v1\\/users\\/39990176\"}]}}],\"wp:term\":[[{\"id\":449557100,\"link\":\"https:\\/\\/techcrunch.com\\/europe\\/\",\"name\":\"Europe\",\"slug\":\"europe\",\"taxonomy\":\"category\",\"parent\":0,\"rapidData\":{\"pt\":\"\",\"pct\":\"\"},\"submenu_categories\":[],\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories\\/449557100\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/category\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?categories=449557100\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?categories=449557100\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?categories=449557100\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":3457,\"link\":\"https:\\/\\/techcrunch.com\\/social\\/\",\"name\":\"Social\",\"slug\":\"social\",\"taxonomy\":\"category\",\"parent\":0,\"rapidData\":{\"pt\":\"\",\"pct\":\"\"},\"submenu_categories\":[],\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories\\/3457\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/category\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?categories=3457\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?categories=3457\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?categories=3457\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":17396,\"link\":\"https:\\/\\/techcrunch.com\\/tc\\/\",\"name\":\"TC\",\"slug\":\"tc\",\"taxonomy\":\"category\",\"parent\":0,\"rapidData\":{\"pt\":\"\",\"pct\":\"\"},\"submenu_categories\":[],\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories\\/17396\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/categories\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/category\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?categories=17396\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?categories=17396\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?categories=17396\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}}],[{\"id\":2988,\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/bbc\\/\",\"name\":\"BBC\",\"slug\":\"bbc\",\"taxonomy\":\"post_tag\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\\/2988\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/post_tag\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?tags=2988\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/battlefield-companies?tags=2988\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?tags=2988\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?tags=2988\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?tags=2988\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":449559371,\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/child-safety\\/\",\"name\":\"child safety\",\"slug\":\"child-safety\",\"taxonomy\":\"post_tag\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\\/449559371\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/post_tag\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?tags=449559371\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/battlefield-companies?tags=449559371\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?tags=449559371\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?tags=449559371\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?tags=449559371\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":449548756,\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/content-moderation\\/\",\"name\":\"content moderation\",\"slug\":\"content-moderation\",\"taxonomy\":\"post_tag\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\\/449548756\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/post_tag\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?tags=449548756\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/battlefield-companies?tags=449548756\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?tags=449548756\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?tags=449548756\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?tags=449548756\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":81819,\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/facebook\\/\",\"name\":\"Facebook\",\"slug\":\"facebook\",\"taxonomy\":\"post_tag\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\\/81819\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/post_tag\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?tags=81819\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/battlefield-companies?tags=81819\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?tags=81819\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?tags=81819\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?tags=81819\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":119,\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/photo-sharing\\/\",\"name\":\"photo sharing\",\"slug\":\"photo-sharing\",\"taxonomy\":\"post_tag\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\\/119\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/post_tag\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?tags=119\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/battlefield-companies?tags=119\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?tags=119\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?tags=119\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?tags=119\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":49818,\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/social-media\\/\",\"name\":\"social media\",\"slug\":\"social-media\",\"taxonomy\":\"post_tag\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\\/49818\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tags\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/post_tag\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?tags=49818\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/battlefield-companies?tags=49818\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc-media-gallery?tags=49818\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?tags=49818\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_video?tags=49818\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}}],[{\"id\":204332940,\"link\":\"https:\\/\\/techcrunch.com\\/?taxonomy=_tc_cb_tag_taxonomy&term=bbc-organization\",\"name\":\"bbc-organization\",\"slug\":\"bbc-organization\",\"taxonomy\":\"_tc_cb_tag_taxonomy\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag\\/204332940\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/_tc_cb_tag_taxonomy\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?crunchbase_tag=204332940\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?crunchbase_tag=204332940\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":197883035,\"link\":\"https:\\/\\/techcrunch.com\\/?taxonomy=_tc_cb_tag_taxonomy&term=facebook-organization\",\"name\":\"facebook-organization\",\"slug\":\"facebook-organization\",\"taxonomy\":\"_tc_cb_tag_taxonomy\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag\\/197883035\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/_tc_cb_tag_taxonomy\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?crunchbase_tag=197883035\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?crunchbase_tag=197883035\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}},{\"id\":197264633,\"link\":\"https:\\/\\/techcrunch.com\\/?taxonomy=_tc_cb_tag_taxonomy&term=twitter-company\",\"name\":\"twitter-company\",\"slug\":\"twitter-company\",\"taxonomy\":\"_tc_cb_tag_taxonomy\",\"_links\":{\"self\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag\\/197264633\"}],\"collection\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/crunchbase_tag\"}],\"about\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/taxonomies\\/_tc_cb_tag_taxonomy\"}],\"wp:post_type\":[{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/posts?crunchbase_tag=197264633\"},{\"href\":\"https:\\/\\/techcrunch.com\\/wp-json\\/wp\\/v2\\/tc_topic?crunchbase_tag=197264633\"}],\"curies\":[{\"name\":\"wp\",\"href\":\"https:\\/\\/api.w.org\\/{rel}\",\"templated\":true}]}}],[],[]]}}],\"media\":[],\"events\":[],\"battlefieldEvents\":[],\"battlefieldCompanies\":[],\"battlefieldPages\":[]},\"current_posts\":[1461242],\"request\":\"\\/2017\\/03\\/07\\/facebooks-content-moderation-system-under-fire-for-child-safety-failures\\/\",\"siteURI\":\"https:\\/\\/techcrunch.com\\/\",\"totalPages\":\"0\",\"trending\":[{\"id\":\"429989\",\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/tesla\\/\",\"name\":\"\\nTesla\",\"type\":\"tag\"},{\"id\":\"60523764\",\"link\":\"https:\\/\\/techcrunch.com\\/fundings-exits\\/\",\"name\":\"Fundings & Exits\\n\",\"type\":\"category\"},{\"id\":\"81\",\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/google\\/\",\"name\":\"Google\\n\",\"type\":\"tag\"},{\"id\":\"576625230\",\"link\":\"https:\\/\\/techcrunch.com\\/tag\\/tc-sessions-robotics-2019\\/\",\"name\":\"\\ntc sessions robotics 2019\",\"type\":\"tag\"}],\"videoPlayerIds\":{\"no-ad-autostart\":\"56f58bbbe4b01497527036b2\",\"regular\":\"56df4e9de4b0c9c31d626c18\",\"regular-autostart\":\"56faf851e4b0d3dcac2e081a\",\"sideview-autostart\":\"57e2c53fcc52c7730882bbfe\"},\"facebookPixelId\":\"1447508128842484\",\"marketoAccountId\":\"270-WRY-762\",\"vidibleCompanyId\":\"564f313b67b6231408bc51ee\",\"recaptchaPublic\":\"6LeZyjwUAAAAABqkWH_Ct0efGn0B4pGU6ZLUeUvA\",\"googleAnalyticsID\":\"UA-991406-1\",\"googleAnalyticsDomains\":[\"techcrunch.com\"],\"googleMapsAPIKey\":\"AIzaSyCodzMYMBdZIpxThSQqm79ACyheeRXPPE4\",\"nps_survey_id\":\"386TPSJ\",\"nps_bucket_percentage\":\"0\",\"tinypass\":{\"scriptDomain\":\"https:\\/\\/dashboard.tinypass.com\",\"scriptURL\":\"https:\\/\\/cdn.tinypass.com\\/api\\/tinypass.min.js\",\"apiKey\":\"Fy7FpgyUxA\",\"apiURL\":\"https:\\/\\/api.tinypass.com\"},\"legacyPages\":{\"extra-crunch-membership\":1781464,\"sponsored\":1796357},\"apiNonce\":\"5b3dfa6ac1\",\"userCan\":{\"editPosts\":false,\"restNonce\":null},\"initialStore\":{\"events\":{\"eventTypeIDs\":[],\"eventPostIds\":[],\"featuredEventIDs\":{\"event_home\":[]},\"featuredPostIDs\":{},\"pastEventIDs\":{\"default\":[]},\"pastFilters\":{},\"pastLoading\":false,\"upcomingEventIDs\":{\"default\":null},\"upcomingFilters\":{},\"upcomingLoading\":false},\"section\":{\"allPosts\":[1461242],\"contentObject\":null,\"currentPage\":1,\"expandedPost\":\"https:\\/\\/techcrunch.com\\/2017\\/03\\/07\\/facebooks-content-moderation-system-under-fire-for-child-safety-failures\\/\",\"expandedPostIds\":[1461242],\"expandedIsland\":\"\",\"loading\":false,\"component\":\"singlePost\"}},\"extraCrunchMarketingPageURL\":\"\\/subscribe\",\"brandStudioMarketingPageURL\":\"\\/brand-studio\",\"unicornLeaderboardSlug\":\"unicorn-leaderboard\",\"newsletterURL\":\"http:\\/\\/link.techcrunch.com\\/join\\/134\\/signup-all-newsletters\"};\n/* ]]> */\n</script>\n<script src=\"https://techcrunch.com/_static/??/wp-content/themes/techcrunch-2017/build/ec/js/main.js,/wp-includes/js/wp-embed.min.js?m=1556300008j\" type=\"text/javascript\"></script>\n<script async=\"async\" defer=\"defer\" src=\"https://stats.wp.com/e-201917.js\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n\t_stq = window._stq || [];\n\t_stq.push([ 'view', {v:'ext',j:'1:7.2.1',blog:'136296444',post:'1461242',tz:'-7',srv:'techcrunch.com'} ]);\n\t_stq.push([ 'clickTrackerInit', '136296444', '1461242' ]);\n</script>\n<script type=\"text/javascript\">window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"bam.nr-data.net\",\"licenseKey\":\"4750574831\",\"applicationID\":\"71001471\",\"transactionName\":\"NlRbNkYEWERTVkVcXA8eehdHEVlaHUJBGkVTHk0BawBAUlxB\",\"queueTime\":0,\"applicationTime\":243,\"atts\":\"GhNMQA4eSxsQVBMPSBxM\",\"errorBeacon\":\"bam.nr-data.net\",\"agent\":\"\"}</script></body>\n</html>\n", "content_tokenized": ["facebook", "has", "again", "been", "critic", "for", "fail", "remov", "child", "exploit", "imageri", "from", "platform", "follow", "investig", "into", "system", "for", "report", "inappropri", "content", "last", "year", "the", "news", "organ", "report", "that", "close", "facebook", "group", "were", "use", "pedophil", "share", "imag", "child", "exploit", "the", "time", "facebook", "head", "public", "polici", "told", "commit", "remov", "content", "that", "shouldn", "there", "and", "facebook", "has", "sinc", "told", "the", "has", "improv", "report", "system", "howev", "followup", "articl", "publish", "today", "the", "again", "report", "find", "sexual", "imag", "children", "share", "facebook", "the", "vast", "major", "which", "the", "social", "network", "giant", "fail", "remov", "after", "the", "initi", "report", "them", "the", "said", "use", "the", "facebook", "report", "button", "alert", "the", "compani", "num", "imag", "that", "appear", "break", "guidelin", "against", "obscen", "andor", "sexual", "suggest", "content", "includ", "from", "page", "that", "said", "were", "explicit", "for", "men", "with", "sexual", "interest", "children", "the", "num", "report", "imag", "onli", "num", "were", "remov", "facebook", "accord", "the", "also", "found", "five", "convict", "pedophil", "with", "profil", "and", "report", "them", "facebook", "via", "own", "system", "but", "say", "none", "the", "account", "were", "taken", "down", "despit", "facebook", "own", "rule", "forbid", "convict", "sex", "offend", "from", "have", "account", "respons", "the", "report", "the", "chairman", "the", "hous", "common", "media", "committe", "damian", "collin", "told", "the", "has", "grave", "doubt", "about", "the", "effect", "facebook", "content", "moder", "system", "think", "rais", "the", "question", "how", "can", "user", "make", "effect", "complaint", "facebook", "about", "content", "that", "disturb", "shouldn", "the", "site", "and", "have", "confid", "that", "that", "will", "act", "upon", "said", "further", "twist", "the", "news", "organ", "subsequ", "report", "the", "polic", "facebook", "after", "share", "some", "the", "report", "imag", "direct", "with", "facebook", "when", "ask", "send", "exampl", "report", "content", "that", "had", "not", "been", "remov", "techcrunch", "understand", "facebook", "follow", "guidelin", "this", "point", "although", "the", "claim", "onli", "sent", "imag", "after", "ask", "facebook", "share", "exampl", "report", "content", "howev", "view", "share", "child", "exploit", "imag", "illeg", "the", "the", "would", "have", "have", "sent", "facebook", "link", "illeg", "content", "rather", "than", "share", "imag", "direct", "avoid", "report", "possibl", "this", "aspect", "the", "stori", "boil", "down", "miscommun", "facebook", "declin", "answer", "our", "question", "and", "declin", "interview", "flagship", "news", "program", "about", "content", "moder", "problem", "but", "email", "statement", "polici", "director", "simon", "milner", "said", "have", "care", "review", "the", "content", "refer", "and", "have", "now", "remov", "all", "item", "that", "were", "illeg", "against", "our", "standard", "this", "content", "longer", "our", "platform", "take", "this", "matter", "extrem", "serious", "and", "continu", "improv", "our", "report", "and", "takedown", "measur", "facebook", "has", "been", "recogn", "one", "the", "best", "platform", "the", "internet", "for", "child", "safeti", "against", "the", "law", "for", "anyon", "distribut", "imag", "child", "exploit", "when", "the", "sent", "such", "imag", "follow", "our", "industri", "standard", "practic", "and", "report", "them", "also", "report", "the", "child", "exploit", "imag", "that", "had", "been", "share", "our", "own", "platform", "this", "matter", "now", "the", "hand", "the", "author", "the", "wider", "issu", "here", "that", "facebook", "content", "moder", "system", "remain", "veri", "clear", "veri", "far", "from", "perfect", "and", "contextu", "content", "moder", "evid", "vast", "problem", "that", "requir", "far", "more", "resourc", "that", "are", "devot", "facebook", "even", "the", "compani", "employ", "thousand", "human", "moder", "distribut", "offic", "around", "the", "world", "such", "dublin", "for", "european", "content", "ensur", "num", "avail", "still", "drop", "the", "ocean", "for", "platform", "with", "more", "than", "billion", "activ", "user", "share", "multipl", "type", "content", "ongo", "basi", "technolog", "solut", "can", "part", "the", "solut", "such", "microsoft", "photodna", "cloud", "servic", "which", "can", "identifi", "known", "child", "abus", "imag", "for", "exampl", "but", "such", "system", "can", "help", "identifi", "unknown", "obscen", "materi", "problem", "that", "necessit", "humanmoder", "and", "enough", "human", "moder", "review", "user", "report", "time", "fashion", "that", "problem", "content", "can", "identifi", "accur", "and", "remov", "prompt", "other", "word", "the", "opposit", "what", "appear", "have", "happen", "this", "instanc", "facebook", "leadership", "can", "not", "accus", "blind", "concern", "about", "content", "moder", "failur", "inde", "mark", "zuckerberg", "recent", "discuss", "the", "issu", "open", "letter", "conced", "the", "compani", "need", "more", "also", "talk", "about", "his", "hope", "that", "technolog", "will", "abl", "take", "bigger", "role", "fix", "the", "problem", "futur", "argu", "that", "artifici", "intellig", "can", "help", "provid", "better", "approach", "and", "say", "facebook", "work", "aipow", "content", "flag", "system", "scale", "the", "evergrow", "challeng", "although", "also", "caution", "these", "will", "take", "mani", "year", "fulli", "develop", "and", "that", "realli", "the", "problem", "nutshel", "facebook", "not", "put", "the", "resourc", "need", "fix", "the", "current", "problem", "has", "with", "moder", "even", "direct", "resourc", "into", "tri", "come", "with", "possibl", "futur", "solut", "where", "aimoder", "can", "deploy", "scale", "but", "zuckerberg", "want", "more", "right", "now", "the", "simpl", "fix", "employ", "more", "human", "review", "and", "act", "report"], "timestamp_scraper": 1556383658.584262, "title": "Facebook\u2019s content moderation system under fire again for child safety failures", "read_time": 252.29999999999998, "content_html": "<p id=\"speakable-summary\"><a class=\"crunchbase-link\" data-entity=\"facebook\" data-type=\"organization\" href=\"https://crunchbase.com/organization/facebook\" target=\"_blank\">Facebook <span class=\"crunchbase-tooltip-indicator\"></span></a> has again been criticized for failing to remove\u00a0child exploitation imagery from its platform following a BBC investigation into its\u00a0system for reporting inappropriate content.</p> <p><a href=\"http://www.bbc.com/news/uk-35521068\" target=\"_blank\">Last year</a>\u00a0the news organization reported that\u00a0closed Facebook groups were being used by pedophiles to share images of child exploitation. At the time\u00a0Facebook\u2019s head of public policy told it he was committed to removing \u201ccontent that shouldn\u2019t be there\u201d, and Facebook has\u00a0since told the BBC\u00a0it has\u00a0improved its reporting system.</p> <p>However,\u00a0in a follow-up article\u00a0published today, the\u00a0BBC again\u00a0<a href=\"http://www.bbc.com/news/technology-39187929\" target=\"_blank\">reports</a>\u00a0finding sexualized images of children being shared on Facebook \u2014 the vast majority of which the social networking giant failed to remove after the BBC initially reported\u00a0them.</p> <p>The\u00a0BBC said\u00a0it used the Facebook report button to alert the company to 100 images that\u00a0appeared to break its guidelines against obscene and/or sexually suggestive content\u00a0\u2014 including from pages that it said were explicitly for men with a sexual interest in children.</p> <p>Of the 100 reported images only 18 were removed by Facebook, according to the BBC. It also found\u00a0five convicted pedophiles with profiles and reported them to Facebook via its own system\u00a0but says none of the accounts were taken down\u00a0\u2014 despite Facebook\u2019s own rules forbidding convicted sex offenders from having accounts.</p> <p>In response to the report, the chairman of the UK House of Commons\u2019 media committee, Damian Collins, told the <a href=\"http://www.bbc.com/news/technology-39187929\" target=\"_blank\">BBC</a> he has\u00a0\u201cgrave doubts\u201d about the effectiveness of Facebook\u2019s\u00a0content moderation systems.</p> <p>\u201cI think it raises the question of how can users make effective complaints to Facebook about content that is disturbing, shouldn\u2019t be on the site, and have confidence that that will be acted upon,\u201d he said.</p> <p>In a further twist,\u00a0the news organization was subsequently reported to the police by Facebook after sharing some of the reported images directly with Facebook when it asked to send\u00a0examples of reported content that had not been removed.</p> <p>TechCrunch understands Facebook\u00a0was following <a href=\"https://ceop.police.uk/safety-centre/\" target=\"_blank\">CEOP</a> guidelines at this point \u2014 although the BBC\u00a0claims it only sent images after being asked by Facebook to share examples of reported content. However viewing or sharing child exploitation images is illegal in the UK. The BBC would have to have sent Facebook links to illegal\u00a0content, rather than shared images directly to avoid being reported \u2014 so it\u2019s possible this aspect of the story boils down to a miscommunication.</p> <p>Facebook declined to answer our\u00a0questions \u2014 and declined to be interviewed on a flagship BBC news program about its content moderation problems \u2014 but in\u00a0an emailed statement UK policy director, Simon Milner, said: \u201cWe have carefully reviewed the content referred to us and have now removed all items that were illegal or against our standards. This content is no longer on our platform. We take this matter extremely seriously and we continue to improve our reporting and take-down measures. Facebook has been recognized as one of the best platforms on the internet for child safety.\u201d</p> <p>\u201cIt is against the law for anyone to distribute images of child exploitation. When the BBC sent us such images we followed our industry\u2019s standard practice and reported them to CEOP. We also reported the child exploitation images that had been shared on our own platform. This matter is now in the hands of the authorities,\u201d he added.</p> <p>The wider issue here is that Facebook\u2019s content moderation system remains\u00a0very clearly very far from perfect. And contextual content moderation is evidently a vast problem that requires far more resources\u00a0that are being devoted to it by Facebook. Even if the company\u00a0employs \u201cthousands\u201d of human moderators, distributed\u00a0in offices\u00a0around\u00a0the world (such as Dublin for European content) to ensure 24/7 availability, it\u2019s\u00a0still a drop in the ocean for a platform with more than a billion active users sharing multiple types of content on an ongoing basis.</p> <p>Technology solutions can\u00a0be part of the solution \u2014 such as <a href=\"https://www.microsoft.com/en-us/PhotoDNA\" target=\"_blank\">Microsoft\u2019s PhotoDNA cloud service</a>, which\u00a0can identify known child abuse images, for example \u2014 but such systems can\u2019t\u00a0help identify\u00a0unknown obscene material. It\u2019s a problem that\u00a0necessitates\u00a0human-moderation and enough human moderators to review user reports in a timely fashion so that problem content can be identified accurately and removed promptly \u2014 in other words, the opposite of what appears to have\u00a0happened in this instance.</p> <p>Facebook\u2019s leadership cannot be accused of being\u00a0blind to\u00a0concerns about its content moderation failures. Indeed,\u00a0CEO Mark Zuckerberg <a href=\"https://www.facebook.com/notes/mark-zuckerberg/building-global-community/10154544292806634/\" target=\"_blank\">recently discussed</a>\u00a0the issue in an open letter \u2014 conceding the company needs to \u201cdo more\u201d. He also talked about his\u00a0hope that technology will be able to take a bigger role in fixing\u00a0the problem in future, arguing that\u00a0\u201cartificial intelligence can help provide a better approach\u201d, and saying\u00a0Facebook is working on AI-powered content flagging systems to scale to the ever-growing challenge \u2014 although he also cautioned these will take \u201cmany years to fully develop\u201d.</p> <p>And that\u2019s really the problem in a nutshell. Facebook is not putting in the resources needed to fix the current problem it has with moderation \u2014 even as\u00a0it directs resources into trying to come up with possible future solutions where AI-moderation can be deployed at scale. But if Zuckerberg wants to do more right now, the simple fix is to employ more humans\u00a0to review and act on reports.</p> ", "website": "techcrunch"}