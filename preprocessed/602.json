{"content": "comments By Harshit Dwivedi , Android Instructor In recent years, neural networks and deep learning have sparked tremendous progress in the field of\u00a0 natural language processing \u00a0(NLP) and\u00a0 computer vision . While many of the\u00a0 face ,\u00a0 object , landmark, logo, and\u00a0 text recognition \u00a0and detection technologies are provided for Internet-connected devices, we believe that the\u00a0 ever-increasing computational power of mobile devices \u00a0can enable the delivery of these technologies into the hands of users anytime, anywhere, regardless of Internet connection. However, computer vision for on-device and embedded applications faces many challenges\u200a\u2014\u200amodels must run quickly with high accuracy in a resource-constrained environment, making use of limited computation, power, and space. TensorFlow offers various pre-trained models, such as drag-and-drop models, in order to identify approximately 1,000 default objects. When compared with other similar models, such as the\u00a0 Inception \u00a0model datasets,\u00a0 MobileNet \u00a0works better with latency, size, and accuracy. In terms of output performance, there is a significant amount of lag with a full-fledged model. However, the trade-off is acceptable when the model is deployable on a mobile device for real-time offline detection. Let\u2019s look at an example of how to use MobileNet. We will write a simple classifier to find Pikachu in an image. The following are sample pictures showing an image of Pikachu and an image without Pikachu:", "title_html": "<h1 id=\"title\">Comparing MobileNet Models in TensorFlow</h1> ", "url": "https://www.kdnuggets.com/2019/03/comparing-mobilenet-models-tensorflow.html", "tfidf": {"tfidf": {"approxim": 2.2132998745299997, "everincreas": 1058.4, "natur": 1.5392670157100001, "limit": 1.5186531471200002, "pictur": 3.4953764861300005, "draganddrop": 1058.4, "spark": 8.360189573460001, "term": 1.39520168732, "progress": 2.44697903822, "simpl": 3.3981164383599998, "other": 1.00992366412, "provid": 1.21552714187, "deliveri": 8.90409422322, "show": 1.26703910615, "space": 2.39818731118, "offer": 1.53896859248, "look": 1.9086318826599997, "follow": 1.04640126549, "such": 2.12302754748, "accuraci": 25.5241157556, "imag": 8.10413476263, "the": 9.0, "dataset": 193.609756098, "deploy": 7.41869158879, "network": 2.59369384088, "neural": 59.4606741573, "without": 1.29547123623, "harshit": 1058.4, "tradeoff": 208.89473684200001, "devic": 15.024605678219999, "detect": 10.82577565632, "instructor": 22.583214793699998, "work": 1.11520089913, "fullfledg": 1058.4, "internet": 4.98461538462, "recent": 1.54405757635, "offlin": 132.3, "classifi": 5.2937645882, "mobil": 9.79395434916, "text": 3.12827586207, "when": 2.0415353951, "sampl": 7.23280182232, "process": 1.69524826482, "similar": 1.37514075357, "anywher": 10.1638924456, "num": 1.00031504001, "embed": 16.835630965, "technolog": 5.206953099380001, "run": 1.55692850838, "how": 1.60250328051, "enabl": 3.5421686747, "landmark": 7.969879518069999, "environ": 3.43561999567, "resourceconstrain": 1058.4, "for": 3.00094512003, "regardless": 6.35294117647, "order": 1.24625166811, "output": 7.676982591880001, "with": 4.004792835959999, "vision": 9.76083615124, "incept": 16.8535031847, "mani": 2.08853515754, "will": 1.22481098596, "these": 1.07415426252, "are": 2.05981187156, "android": 57.1079136691, "better": 2.0065722952500002, "that": 1.00398406375, "internetconnect": 1058.4, "power": 2.6792675723599997, "mobilenet": 2116.8, "object": 4.697736351540001, "lag": 33.3529411765, "and": 8.00050393704, "perform": 1.5313977042500002, "recognit": 4.40022172949, "there": 1.04091266719, "connect": 1.8843916913900003, "amount": 2.27027027027, "latenc": 174.46153846200002, "applic": 3.42672134686, "comment": 3.05954904606, "exampl": 1.50483412322, "anytim": 114.215827338, "have": 1.0148948411399998, "hand": 1.6152202665600002, "tremend": 16.0363636364, "can": 1.17626139142, "tensorflow": 1058.4, "comput": 15.711034141520003, "make": 1.0762660158600001, "default": 21.1398135819, "size": 2.49387370405, "logo": 11.356223175999999, "model": 14.6341848828, "realtim": 429.081081081, "high": 1.14777327935, "pretrain": 1058.4, "languag": 2.29488291414, "deep": 3.6279707495399998, "field": 1.7790228597, "accept": 1.7377408056, "into": 1.01502461479, "must": 1.9220338983099996, "compar": 1.8662278123900002, "pikachu": 3175.2000000000003, "signific": 1.4529147982100001, "ondevic": 1058.4, "learn": 2.32275054865, "identifi": 2.30187037843, "dwivedi": 1058.4, "face": 3.6065424807, "quick": 2.205, "various": 1.3323262839899999, "challeng": 2.55816951337, "use": 2.0592775147599998, "while": 1.0441988950299999, "year": 1.0485436893200002, "write": 2.0575427682700003, "believ": 1.6450108797, "find": 1.7294117647099998, "howev": 2.1890382626599996, "let": 3.48616600791, "user": 7.71053909665}, "logtfidf": {"approxim": 0.7944845577770001, "everincreas": 6.964513612799999, "natur": 0.431306339292, "limit": 0.41782385463, "pictur": 1.25144109124, "draganddrop": 6.964513612799999, "spark": 2.12348110309, "term": 0.33303898354600003, "progress": 0.894854218108, "simpl": 1.2232212893899999, "other": 0.00987474791976, "provid": 0.19517784432500002, "deliveri": 2.18651119604, "show": 0.236682766013, "space": 0.874713164972, "offer": 0.431112446902, "look": 0.6463866936, "follow": 0.045356911094199995, "such": 0.119391955612, "accuraci": 5.0929530812, "imag": 2.98128632187, "the": 0.0, "dataset": 5.26584456664, "deploy": 2.00400270589, "network": 0.9530830530519999, "neural": 4.0853151555, "without": 0.258874517941, "harshit": 6.964513612799999, "tradeoff": 5.34183047362, "devic": 4.833230841089999, "detect": 3.37756548986, "instructor": 3.11720692209, "work": 0.109034567273, "fullfledg": 6.964513612799999, "internet": 1.6063562459, "recent": 0.434413741288, "offlin": 4.88507207112, "classifi": 1.6665296351499999, "mobil": 3.1772362232200004, "text": 1.14048200999, "when": 0.0411099777168, "sampl": 1.9786264883900002, "process": 0.527829199025, "similar": 0.318556092114, "anywher": 2.3188414835, "num": 0.00031499039539700004, "embed": 2.82349753127, "technolog": 1.91369537271, "run": 0.442714975539, "how": 0.47156695693000006, "enabl": 1.26473915954, "landmark": 2.0756693757599995, "environ": 1.2341974030299998, "resourceconstrain": 6.964513612799999, "for": 0.0009449711861910001, "regardless": 1.8489178830700002, "order": 0.22014038079300002, "output": 2.03822657827, "with": 0.00478996685356, "vision": 3.17046177486, "incept": 2.82455853933, "mani": 0.0866315162442, "will": 0.202786534915, "these": 0.0715336194008, "are": 0.0589349471654, "android": 4.04494270021, "better": 0.6964279406, "that": 0.00397614837964, "internetconnect": 6.964513612799999, "power": 0.58479256543, "mobilenet": 13.929027225599999, "object": 1.707867169606, "lag": 3.5071459596699994, "and": 0.0005039211365088, "perform": 0.42618085058, "recognit": 1.4816549327200002, "there": 0.0400978929255, "connect": 0.633605058682, "amount": 0.819898886199, "latenc": 5.16170430739, "applic": 1.23160392849, "comment": 1.11826753454, "exampl": 0.40868267499899996, "anytim": 4.73808988077, "have": 0.0147850023412, "hand": 0.479471335336, "tremend": 2.77485887077, "can": 0.162341096394, "tensorflow": 6.964513612799999, "comput": 5.47227566376, "make": 0.07349765782289999, "default": 3.0511581621399997, "size": 0.9138372060609999, "logo": 2.4297658911099997, "model": 5.162150511777001, "realtim": 6.0616459012599995, "high": 0.13782378654000002, "pretrain": 6.964513612799999, "languag": 0.8306818244059999, "deep": 1.2886734698, "field": 0.5760642583510001, "accept": 0.552585882007, "into": 0.0149128632287, "must": 0.653383947388, "compar": 0.6239191809269999, "pikachu": 20.8935408384, "signific": 0.373571744332, "ondevic": 6.964513612799999, "learn": 0.842752064745, "identifi": 0.833722000472, "dwivedi": 6.964513612799999, "face": 1.179204742514, "quick": 0.790727508899, "various": 0.28692650007, "challeng": 0.9392919688950001, "use": 0.0584160394632, "while": 0.04324998379380001, "year": 0.047402238894600005, "write": 0.721512439877, "believ": 0.497746997996, "find": 0.547781330288, "howev": 0.180630234695, "let": 1.2488025672799998, "user": 2.04258810688}, "logidf": {"approxim": 0.7944845577770001, "everincreas": 6.964513612799999, "natur": 0.431306339292, "limit": 0.41782385463, "pictur": 1.25144109124, "draganddrop": 6.964513612799999, "spark": 2.12348110309, "term": 0.33303898354600003, "progress": 0.894854218108, "simpl": 1.2232212893899999, "other": 0.00987474791976, "provid": 0.19517784432500002, "deliveri": 2.18651119604, "show": 0.236682766013, "space": 0.874713164972, "offer": 0.431112446902, "look": 0.6463866936, "follow": 0.045356911094199995, "such": 0.059695977806, "accuraci": 2.5464765406, "imag": 0.99376210729, "the": 0.0, "dataset": 5.26584456664, "deploy": 2.00400270589, "network": 0.9530830530519999, "neural": 4.0853151555, "without": 0.258874517941, "harshit": 6.964513612799999, "tradeoff": 5.34183047362, "devic": 1.6110769470299997, "detect": 1.68878274493, "instructor": 3.11720692209, "work": 0.109034567273, "fullfledg": 6.964513612799999, "internet": 1.6063562459, "recent": 0.434413741288, "offlin": 4.88507207112, "classifi": 1.6665296351499999, "mobil": 1.5886181116100002, "text": 1.14048200999, "when": 0.0205549888584, "sampl": 1.9786264883900002, "process": 0.527829199025, "similar": 0.318556092114, "anywher": 2.3188414835, "num": 0.00031499039539700004, "embed": 2.82349753127, "technolog": 0.956847686355, "run": 0.442714975539, "how": 0.47156695693000006, "enabl": 1.26473915954, "landmark": 2.0756693757599995, "environ": 1.2341974030299998, "resourceconstrain": 6.964513612799999, "for": 0.00031499039539700004, "regardless": 1.8489178830700002, "order": 0.22014038079300002, "output": 2.03822657827, "with": 0.00119749171339, "vision": 1.58523088743, "incept": 2.82455853933, "mani": 0.0433157581221, "will": 0.202786534915, "these": 0.0715336194008, "are": 0.0294674735827, "android": 4.04494270021, "better": 0.6964279406, "that": 0.00397614837964, "internetconnect": 6.964513612799999, "power": 0.292396282715, "mobilenet": 6.964513612799999, "object": 0.853933584803, "lag": 3.5071459596699994, "and": 6.29901420636e-05, "perform": 0.42618085058, "recognit": 1.4816549327200002, "there": 0.0400978929255, "connect": 0.633605058682, "amount": 0.819898886199, "latenc": 5.16170430739, "applic": 1.23160392849, "comment": 1.11826753454, "exampl": 0.40868267499899996, "anytim": 4.73808988077, "have": 0.0147850023412, "hand": 0.479471335336, "tremend": 2.77485887077, "can": 0.162341096394, "tensorflow": 6.964513612799999, "comput": 1.36806891594, "make": 0.07349765782289999, "default": 3.0511581621399997, "size": 0.9138372060609999, "logo": 2.4297658911099997, "model": 0.7374500731110001, "realtim": 6.0616459012599995, "high": 0.13782378654000002, "pretrain": 6.964513612799999, "languag": 0.8306818244059999, "deep": 1.2886734698, "field": 0.5760642583510001, "accept": 0.552585882007, "into": 0.0149128632287, "must": 0.653383947388, "compar": 0.6239191809269999, "pikachu": 6.964513612799999, "signific": 0.373571744332, "ondevic": 6.964513612799999, "learn": 0.842752064745, "identifi": 0.833722000472, "dwivedi": 6.964513612799999, "face": 0.589602371257, "quick": 0.790727508899, "various": 0.28692650007, "challeng": 0.9392919688950001, "use": 0.0292080197316, "while": 0.04324998379380001, "year": 0.047402238894600005, "write": 0.721512439877, "believ": 0.497746997996, "find": 0.547781330288, "howev": 0.0903151173475, "let": 1.2488025672799998, "user": 2.04258810688}, "freq": {"approxim": 1, "everincreas": 1, "natur": 1, "limit": 1, "pictur": 1, "draganddrop": 1, "spark": 1, "term": 1, "progress": 1, "simpl": 1, "other": 1, "provid": 1, "deliveri": 1, "show": 1, "space": 1, "offer": 1, "look": 1, "follow": 1, "such": 2, "accuraci": 2, "imag": 3, "the": 9, "dataset": 1, "deploy": 1, "network": 1, "neural": 1, "without": 1, "harshit": 1, "tradeoff": 1, "devic": 3, "detect": 2, "instructor": 1, "work": 1, "fullfledg": 1, "internet": 1, "recent": 1, "offlin": 1, "classifi": 1, "mobil": 2, "text": 1, "when": 2, "sampl": 1, "process": 1, "similar": 1, "anywher": 1, "num": 1, "embed": 1, "technolog": 2, "run": 1, "how": 1, "enabl": 1, "landmark": 1, "environ": 1, "resourceconstrain": 1, "for": 3, "regardless": 1, "order": 1, "output": 1, "with": 4, "vision": 2, "incept": 1, "mani": 2, "will": 1, "these": 1, "are": 2, "android": 1, "better": 1, "that": 1, "internetconnect": 1, "power": 2, "mobilenet": 2, "object": 2, "lag": 1, "and": 8, "perform": 1, "recognit": 1, "there": 1, "connect": 1, "amount": 1, "latenc": 1, "applic": 1, "comment": 1, "exampl": 1, "anytim": 1, "have": 1, "hand": 1, "tremend": 1, "can": 1, "tensorflow": 1, "comput": 4, "make": 1, "default": 1, "size": 1, "logo": 1, "model": 7, "realtim": 1, "high": 1, "pretrain": 1, "languag": 1, "deep": 1, "field": 1, "accept": 1, "into": 1, "must": 1, "compar": 1, "pikachu": 3, "signific": 1, "ondevic": 1, "learn": 1, "identifi": 1, "dwivedi": 1, "face": 2, "quick": 1, "various": 1, "challeng": 1, "use": 2, "while": 1, "year": 1, "write": 1, "believ": 1, "find": 1, "howev": 2, "let": 1, "user": 1}, "idf": {"approxim": 2.2132998745299997, "everincreas": 1058.4, "natur": 1.5392670157100001, "limit": 1.5186531471200002, "pictur": 3.4953764861300005, "draganddrop": 1058.4, "spark": 8.360189573460001, "term": 1.39520168732, "progress": 2.44697903822, "simpl": 3.3981164383599998, "other": 1.00992366412, "provid": 1.21552714187, "deliveri": 8.90409422322, "show": 1.26703910615, "space": 2.39818731118, "offer": 1.53896859248, "look": 1.9086318826599997, "follow": 1.04640126549, "such": 1.06151377374, "accuraci": 12.7620578778, "imag": 2.70137825421, "the": 1.0, "dataset": 193.609756098, "deploy": 7.41869158879, "network": 2.59369384088, "neural": 59.4606741573, "without": 1.29547123623, "harshit": 1058.4, "tradeoff": 208.89473684200001, "devic": 5.00820189274, "detect": 5.41288782816, "instructor": 22.583214793699998, "work": 1.11520089913, "fullfledg": 1058.4, "internet": 4.98461538462, "recent": 1.54405757635, "offlin": 132.3, "classifi": 5.2937645882, "mobil": 4.89697717458, "text": 3.12827586207, "when": 1.02076769755, "sampl": 7.23280182232, "process": 1.69524826482, "similar": 1.37514075357, "anywher": 10.1638924456, "num": 1.00031504001, "embed": 16.835630965, "technolog": 2.6034765496900003, "run": 1.55692850838, "how": 1.60250328051, "enabl": 3.5421686747, "landmark": 7.969879518069999, "environ": 3.43561999567, "resourceconstrain": 1058.4, "for": 1.00031504001, "regardless": 6.35294117647, "order": 1.24625166811, "output": 7.676982591880001, "with": 1.0011982089899998, "vision": 4.88041807562, "incept": 16.8535031847, "mani": 1.04426757877, "will": 1.22481098596, "these": 1.07415426252, "are": 1.02990593578, "android": 57.1079136691, "better": 2.0065722952500002, "that": 1.00398406375, "internetconnect": 1058.4, "power": 1.3396337861799998, "mobilenet": 1058.4, "object": 2.3488681757700003, "lag": 33.3529411765, "and": 1.00006299213, "perform": 1.5313977042500002, "recognit": 4.40022172949, "there": 1.04091266719, "connect": 1.8843916913900003, "amount": 2.27027027027, "latenc": 174.46153846200002, "applic": 3.42672134686, "comment": 3.05954904606, "exampl": 1.50483412322, "anytim": 114.215827338, "have": 1.0148948411399998, "hand": 1.6152202665600002, "tremend": 16.0363636364, "can": 1.17626139142, "tensorflow": 1058.4, "comput": 3.9277585353800006, "make": 1.0762660158600001, "default": 21.1398135819, "size": 2.49387370405, "logo": 11.356223175999999, "model": 2.0905978404, "realtim": 429.081081081, "high": 1.14777327935, "pretrain": 1058.4, "languag": 2.29488291414, "deep": 3.6279707495399998, "field": 1.7790228597, "accept": 1.7377408056, "into": 1.01502461479, "must": 1.9220338983099996, "compar": 1.8662278123900002, "pikachu": 1058.4, "signific": 1.4529147982100001, "ondevic": 1058.4, "learn": 2.32275054865, "identifi": 2.30187037843, "dwivedi": 1058.4, "face": 1.80327124035, "quick": 2.205, "various": 1.3323262839899999, "challeng": 2.55816951337, "use": 1.0296387573799999, "while": 1.0441988950299999, "year": 1.0485436893200002, "write": 2.0575427682700003, "believ": 1.6450108797, "find": 1.7294117647099998, "howev": 1.0945191313299998, "let": 3.48616600791, "user": 7.71053909665}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Comparing MobileNet Models in TensorFlow</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/comparing-mobilenet-models-tensorflow.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comparing MobileNet Models in TensorFlow Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/most-impactful-ai-trends-2018-rise-ml-engineering.html\" rel=\"prev\" title=\"Most impactful AI trends of 2018: The rise of ML Engineering\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/data-science-job-applications.html\" rel=\"next\" title=\"What no one will tell you about data science job applications\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/03/comparing-mobilenet-models-tensorflow.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=91156\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/comparing-mobilenet-models-tensorflow.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-91156 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 1-Mar, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/tutorials.html\">Tutorials, Overviews</a> \u00bb Comparing MobileNet Models in TensorFlow (\u00a0<a href=\"/2019/n10.html\">19:n10</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Comparing MobileNet Models in TensorFlow</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/most-impactful-ai-trends-2018-rise-ml-engineering.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/data-science-job-applications.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/computer-vision\" rel=\"tag\">Computer Vision</a>, <a href=\"https://www.kdnuggets.com/tag/mobile\" rel=\"tag\">Mobile</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/tensorflow\" rel=\"tag\">TensorFlow</a></div>\n<br/>\n<p class=\"excerpt\">\n     MobileNets are a family of mobile-first computer vision models for TensorFlow, designed to effectively maximize accuracy while being mindful of the restricted resources for an on-device or embedded application.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://harshit.app/\" rel=\"noopener noreferrer\" target=\"_blank\">Harshit Dwivedi</a>, Android Instructor</b></p>\n<p><img alt=\"Header image\" class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/2560/1*lhhNdja--d36Ha9z8I8w0Q.jpeg\" width=\"99%\"/></p>\n<p>In recent years, neural networks and deep learning have sparked tremendous progress in the field of\u00a0<a href=\"https://heartbeat.fritz.ai/the-7-nlp-techniques-that-will-change-how-you-communicate-in-the-future-part-i-f0114b2f0497\" rel=\"noopener noreferrer\" target=\"_blank\">natural language processing</a>\u00a0(NLP) and\u00a0<a href=\"https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b\" rel=\"noopener noreferrer\" target=\"_blank\">computer vision</a>.</p>\n<p>While many of the\u00a0<a href=\"https://heartbeat.fritz.ai/building-a-real-time-face-detector-in-android-with-ml-kit-f930eb7b36d9\" rel=\"noopener noreferrer\" target=\"_blank\">face</a>,\u00a0<a href=\"https://heartbeat.fritz.ai/counting-items-in-real-time-on-android-with-fritz-object-detection-c450d6957448\" rel=\"noopener noreferrer\" target=\"_blank\">object</a>, landmark, logo, and\u00a0<a href=\"https://heartbeat.fritz.ai/choose-the-right-on-device-text-recognition-sdk-on-android-using-deltaml-9b4b3e409b6e\" rel=\"noopener noreferrer\" target=\"_blank\">text recognition</a>\u00a0and detection technologies are provided for Internet-connected devices, we believe that the\u00a0<a href=\"https://heartbeat.fritz.ai/hardware-acceleration-for-machine-learning-on-apple-and-android-f3e6ca85bda6\" rel=\"noopener noreferrer\" target=\"_blank\">ever-increasing computational power of mobile devices</a>\u00a0can enable the delivery of these technologies into the hands of users anytime, anywhere, regardless of Internet connection.</p>\n<p>However, computer vision for on-device and embedded applications faces many challenges\u200a\u2014\u200amodels must run quickly with high accuracy in a resource-constrained environment, making use of limited computation, power, and space.</p>\n<p>TensorFlow offers various pre-trained models, such as drag-and-drop models, in order to identify approximately 1,000 default objects.</p>\n<p>When compared with other similar models, such as the\u00a0<a href=\"https://github.com/tensorflow/models/tree/master/research/inception\" rel=\"noopener noreferrer\" target=\"_blank\">Inception</a>\u00a0model datasets,\u00a0<a href=\"https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d\" rel=\"noopener noreferrer\" target=\"_blank\">MobileNet</a>\u00a0works better with latency, size, and accuracy. In terms of output performance, there is a significant amount of lag with a full-fledged model.</p>\n<p>However, the trade-off is acceptable when the model is deployable on a mobile device for real-time offline detection.</p>\n<p>Let\u2019s look at an example of how to use MobileNet. We will write a simple classifier to find Pikachu in an image. The following are sample pictures showing an image of Pikachu and an image without Pikachu:</p>\n<div style=\"text-align:center\"><img alt=\"Figure\" src=\"https://cdn-images-1.medium.com/max/800/0*_J5lRaEE701_15ly\" width=\"250\"/><br>\n<font size=\"-1\"></font></br></div></div></div></div></div></div></body></html>\n<div class=\"caption\">Pikachu</div>\n<p></p>\n<div style=\"text-align:center\"><img alt=\"Figure\" src=\"https://cdn-images-1.medium.com/max/800/0*16pszMFO6pXZAUb9\" width=\"70%\"/><br>\n<font size=\"-1\"></font></br></div>\n<div class=\"caption\">Not Pikachu, assuming there\u2019s no Pikachu to collect in Pok\u00e9mon\u00a0Go\u2026</div>\n<p></p>\n<p>\u00a0</p>\n<h3>Building the\u00a0dataset</h3>\n<p>\u00a0<br>\nTo build our own classifier, we need to have datasets that contain images with and without Pikachu.</br></p>\n<p>Let\u2019s start with 1,000 images on each database. You can pull such images here:</p>\n<p><a href=\"https://search.creativecommons.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>CC Search</strong><br>\n<em>Creative Commons licenses provide a flexible range of protections and freedoms for authors, artists, and educators.</em><br/>\nsearch.creativecommons.org</br></a></p>\n<p>Next up, let\u2019s create two folders named\u00a0<strong>pikachu</strong>\u00a0and\u00a0<strong>no-pikachu</strong>\u00a0and drop those images accordingly.</p>\n<p>Another handy dataset containing images for all the generation one Pok\u00e9mon can be found here:</p>\n<p><a href=\"https://www.kaggle.com/thedagger/pokemon-generation-one\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Pokemon Generation One</strong><br/>\n<em>Gotta train 'em all!</em><br/>\nwww.kaggle.com</a></p>\n<p>Now we have an image folder, which is structured as follows:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>/dataset/\r\n/pikachu/[image1,..]\r\n/no-pikachu/[image1,..]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0<br/>\n<b>Retraining Images</b></p>\n<p>We can now start labeling our images. With TensorFlow, this job becomes easier. Assuming that TensorFlow\u00a0<a href=\"https://www.tensorflow.org/install/\" rel=\"noopener noreferrer\" target=\"_blank\">is installed</a>\u00a0on the training machine already, download the following retraining script:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>curl https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Next up, we\u2019ll retrain the image with this Python script\u00a0:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>python retrain.py \\\r\n--image_dir ~/MLmobileapps/Chapter5/dataset/ \\\r\n--learning_rate=0.0001 \\\r\n--testing_percentage=20 \\\r\n--validation_percentage=20 \\\r\n--train_batch_size=32 \\\r\n--validation_batch_size=-1 \\\r\n--eval_step_interval=100 \\\r\n--how_many_training_steps=1000 \\\r\n--flip_left_right=True \\\r\n--random_scale=30 \\\r\n--random_brightness=30 \\\r\n--architecture mobilenet_1.0_224 \\\r\n--output_graph=output_graph.pb \\\r\n--output_labels=output_labels.txt</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<blockquote><p>Note\u00a0: If you set\u00a0<code>validation_batch_size</code>\u00a0to -1, it will validate the whole dataset.\u00a0<code>learning_rate</code>\u00a0= 0.0001 works well. You can adjust and try this for yourself.</p>\n<p>In the\u00a0<code>architecture</code>\u00a0flag, we choose which version of MobileNet to use, from versions 1.0, 0.75, 0.50, and 0.25. The suffix number 224 represents the image resolution. You can specify 224, 192, 160, or 128 as well.</p></blockquote>\n<p>\u00a0</p>\n<h3>Model conversion from GraphDef to\u00a0TFLite</h3>\n<p>\u00a0<br/>\nTOCO Converter is used to convert from a TensorFlow GraphDef file or SavedModel into either a TFLite FlatBuffer or graph visualization.</p>\n<p>(TOCO stands for\u00a0<a href=\"https://www.tensorflow.org/lite/convert/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>TensorFlow Lite Optimizing Converter</strong>.</a>)</p>\n<p>We need to pass the data through command-line arguments. There are a few command-line arguments that can be passed in while converting the model:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>--output_file OUTPUT_FILE\r\nFilepath of the output tflite model.\r\n\r\n--graph_def_file GRAPH_DEF_FILE\r\nFilepath of input TensorFlow GraphDef.\r\n\r\n--saved_model_dir\r\nFilepath of directory containing the SavedModel.\r\n\r\n--keras_model_file\r\nFilepath of HDF5 file containing tf.Keras model.\r\n\r\n--output_format {TFLITE,GRAPHVIZ_DOT}\r\nOutput file format.\r\n\r\n--inference_type {FLOAT,QUANTIZED_UINT8}\r\nTarget data type in the output\r\n\r\n--inference_input_type {FLOAT,QUANTIZED_UINT8}\r\nTarget data type of real-number input arrays.\r\n\r\n--input_arrays INPUT_ARRAYS\r\nNames of the input arrays, comma-separated.\r\n\r\n--input_shapes INPUT_SHAPES\r\nShapes corresponding to --input_arrays, colon-separated.\r\n\r\n--output_arrays OUTPUT_ARRAYS\r\nNames of the output arrays, comma-separated.</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>We can now use the TOCO tool to convert the TensorFlow model into a\u00a0<a href=\"https://heartbeat.fritz.ai/how-tensorflow-lite-optimizes-neural-networks-for-mobile-machine-learning-e6ffa7f8ee12\" rel=\"noopener noreferrer\" target=\"_blank\">TensorFlow Lite</a>\u00a0model:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>toco \\\r\n--graph_def_file=/tmp/output_graph.pb\r\n--output_file=/tmp/retrained_model.tflite\r\n--input_arrays=Mul\r\n--output_arrays=final_result\r\n--input_format=TENSORFLOW_GRAPHDEF\r\n--output_format=TFLITE\r\n--input_shape=1,${224},${224},3\r\n--inference_type=FLOAT\r\n--input_data_type=FLOAT</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Similarly, we can use the MobileNet model in similar applications; for example, in the next section, we\u2019ll be looking at a gender model and an emotion model.</p>\n<p>\u00a0</p>\n<h3>Gender Model</h3>\n<p>\u00a0<br/>\nThis model uses the\u00a0<a href=\"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\" rel=\"noopener noreferrer\" target=\"_blank\">IMDB WIKI dataset</a>, which contains 500k+ celebrity faces. It uses the MobileNet_V1_224_0.5 version of MobileNet.</p>\n<p>It is very rare to find public datasets with thousands of images. This dataset is built on top of a large collection of celebrity faces. There are two common places: one is IMDb and the other one is Wikipedia. More than 100K celebrities\u2019 details were retrieved from their profiles from both sources through scripts.</p>\n<p>Then it was organized by removing noise (irrelevant content). All the images without a timestamp were removed, assuming that images with a single photo are likely to show the person with correct birth date details. At the end, there were 460,723 faces from 20,284 celebrities from IMDb, and 62,328 from Wikipedia, for a total of 523,051.</p>\n<p>\u00a0</p>\n<h3>Emotion model</h3>\n<p>\u00a0<br/>\nThis is built on the AffectNet model with more than 1 million images. It uses the MobileNet_V2_224_1.4 version of MobileNet.</p>\n<p>The link to the data model project can be found here:</p>\n<p><a href=\"http://mohammadmahoor.com/affectnet/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>AffectNet - Mohammad H. Mahoor, PhD</strong><br/>\n<em>Currently the test set is not released. We are planning to organize a challenge on AffectNet in near future and the\u2026</em><br/>\nmohammadmahoor.com</a></p>\n<p>The AffectNet model is built by collecting and annotating facial images of more than 1 million faces from the Internet. The images were sourced from three search engines, using around 1,250 related keywords in six different languages.</p>\n<p>Among the collected images, half of the images were manually annotated for the presence of seven discrete facial expressions (categorical model) and the intensity of valence and arousal (dimensional model).</p>\n<p>\u00a0</p>\n<h3>Comparison of MobileNet Versions</h3>\n<p>\u00a0<br/>\nIn both of the above models, different versions of MobileNet models are used. MobileNet V2 is mostly an updated version of V1 that makes it even more efficient and powerful in terms of performance.</p>\n<div style=\"text-align:center\"><img alt=\"Figure\" src=\"https://cdn-images-1.medium.com/max/800/0*cD0B2GEeq7JfpLqh\" width=\"99%\"/><br/>\n<font size=\"-1\"></font></div>\n<div class=\"caption\">Note: Lower is\u00a0better</div>\n<p></p>\n<p>MACs are\u00a0<a href=\"https://www.semanticscholar.org/topic/Multiply%E2%80%93accumulate-operation/408575\" rel=\"noopener noreferrer\" target=\"_blank\">multiply-accumulate operations</a>, which measure how many calculations are needed to perform inference on a single 224\u00d7224 RGB image.</p>\n<p>From the number of MACs alone, V2 should be almost twice as fast as V1. However, it\u2019s not just about the number of calculations. On mobile devices,\u00a0<a href=\"https://heartbeat.fritz.ai/profiling-your-app-with-android-studio-7accc268cb98\" rel=\"noopener noreferrer\" target=\"_blank\">memory access</a>\u00a0is much slower than computation. V2 only has 80% of the parameter count that V1 has hence making it better than V1.</p>\n<p>By seeing the results we can assume that V2 is almost twice as fast as V1 model. On a mobile device when memory access is limited, the computational capability of V2 works very well.</p>\n<p>In terms of accuracy:</p>\n<div style=\"text-align:center\"><img alt=\"Figure\" src=\"https://cdn-images-1.medium.com/max/800/0*tIstub8xbSd0KmZe\" width=\"99%\"/><br/>\n<font size=\"-1\"></font></div>\n<div class=\"caption\">Here MobileNet V2 is slightly, if not significantly, better than V1.</div>\n<p></p>\n<p>\u00a0</p>\n<h3>Conclusion</h3>\n<p>\u00a0<br/>\nMobileNets are a family of\u00a0<em>mobile-first</em>\u00a0computer vision models for\u00a0<a href=\"https://www.tensorflow.org/\" rel=\"noopener noreferrer\" target=\"_blank\">TensorFlow</a>, designed to effectively maximize accuracy while being mindful of the restricted resources for an on-device or embedded application.</p>\n<p>MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings, and segmentation, similar to how other popular large scale models, such as\u00a0<a href=\"https://arxiv.org/pdf/1602.07261.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Inception</a>, are used.</p>\n<p>If you want to go ahead and fuel your curiosity, a bunch of pre trained models can be found here\u00a0:</p>\n<p><a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>tensorflow/models</strong><br/>\n<em>Models and examples built with TensorFlow. Contribute to tensorflow/models development by creating an account on\u2026</em><br/>\ngithub.com</a></p>\n<p>Also, here\u2019s a blog post outlining how you can build a real like Pok\u00e9mon classifier using MobileNets and TensorFlow Lite:</p>\n<p><a href=\"https://heartbeat.fritz.ai/building-pok%C3%A9dex-in-android-using-tensorflow-lite-and-firebase-cc780848395\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Building \u201cPok\u00e9dex\u201d in Android using TensorFlow Lite and Firebase\u2019s ML Kit</strong><br/>\nheartbeat.fritz.ai</a></p>\n<p><em>Thanks for reading! If you enjoyed this story, please\u00a0</em><strong><em>click the\u00a0</em></strong>\ud83d\udc4f<strong><em>\u00a0button</em></strong><em>\u00a0</em><strong><em>and share\u00a0</em></strong><em>to help others find it! Feel free to leave a comment\u00a0</em>\ud83d\udcac<em>\u00a0below. Have feedback? Let\u2019s connect\u00a0</em><a href=\"https://twitter.com/daggerdwivedi\" rel=\"noopener noreferrer\" target=\"_blank\"><em>on Twitter</em></a><em>.</em></p>\n<p><em>If you found this article interesting, you can explore\u00a0</em><a href=\"https://www.amazon.com/Machine-Learning-Projects-Mobile-Applications/dp/1788994590\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Machine Learning Projects for Mobile Applications</em></a><em>. Written by Karthikeyan MG, an ML expert,\u00a0</em><a href=\"https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-projects-mobile-applications\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Machine Learning Projects for Mobile Applications</em></a><em>\u00a0presents the implementation of 7 practical, real-world projects that will teach you how to leverage TensorFlow Lite and Core ML to perform efficient machine learning on a cross-platform mobile OS.</em></p>\n<p><strong><em>Want to start building amazing Android Apps? Check out my course on Coding Bocks:\u00a0</em></strong><a href=\"https://online.codingblocks.com/courses/android-app-training-online\" rel=\"noopener noreferrer\" target=\"_blank\">https://online.codingblocks.com/courses/android-app-training-online</a></p>\n<p>\u00a0<br/>\nReady to dive into some code? Check out <a href=\"https://github.com/fritzlabs\" rel=\"noopener\" target=\"_blank\">Fritz on GitHub</a>. You\u2019ll find open source, mobile-friendly implementations of the popular machine and deep learning models along with training scripts, project templates, and tools for building your own ML-powered iOS and Android apps.</p>\n<p>Join us on <a href=\"https://join.slack.com/t/heartbeat-by-fritz/shared_invite/enQtNTI4MDcxMzI1MzAwLWIyMjRmMGYxYjUwZmE3MzA0MWQ0NDk0YjA2NzE3M2FjM2Y5MjQxMWM2MmQ4ZTdjNjViYjM3NDE0OWQxOTBmZWI\" rel=\"noopener\" target=\"_blank\">Slack</a> for help with technical problems, to share what you\u2019re working on, or just chat with us about mobile development and machine learning. And follow us on <a href=\"https://twitter.com/fritzlabs\" rel=\"noopener\" target=\"_blank\">Twitter</a> and <a href=\"https://www.linkedin.com/company/fritz-labs-inc/\" rel=\"noopener\" target=\"_blank\">LinkedIn</a> for the all the latest content, news, and more from the mobile machine learning world.</p>\n<p>Thanks to <a href=\"https://medium.com/@austin_32493?source=post_page\" rel=\"noopener\" target=\"_blank\">Austin Kodra</a>.</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://harshit.app/\" rel=\"noopener noreferrer\" target=\"_blank\">Harshit Dwivedi</a></b> has an *approximate* knowledge of many things. He's an Android instructor at Coding Blocks, a contributing author for Heartbeat, by Fritz, public speaker, &amp; Astrophysics enthusiast.</p>\n<p><a href=\"https://heartbeat.fritz.ai/exploring-the-mobilenet-models-in-tensorflow-d9d21774cdab\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2019/02/everything-computer-vision.html\">How to do Everything in Computer Vision</a>\n<li><a href=\"/2018/10/10-best-mobile-apps-data-scientist.html\">10 Best Mobile Apps for Data Scientist / Data Analysts</a>\n<li><a href=\"/2019/02/paperswithcode-ai-machine-learning-highlights.html\">State of the art in AI and Machine Learning \u2013 highlights of papers with code</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/most-impactful-ai-trends-2018-rise-ml-engineering.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/data-science-job-applications.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end-->\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/tutorials.html\">Tutorials, Overviews</a> \u00bb Comparing MobileNet Models in TensorFlow (\u00a0<a href=\"/2019/n10.html\">19:n10</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end-->\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556412297\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper-->\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.726 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 20:44:57 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "harshit", "dwivedi", "android", "instructor", "recent", "year", "neural", "network", "and", "deep", "learn", "have", "spark", "tremend", "progress", "the", "field", "natur", "languag", "process", "and", "comput", "vision", "while", "mani", "the", "face", "object", "landmark", "logo", "and", "text", "recognit", "and", "detect", "technolog", "are", "provid", "for", "internetconnect", "devic", "believ", "that", "the", "everincreas", "comput", "power", "mobil", "devic", "can", "enabl", "the", "deliveri", "these", "technolog", "into", "the", "hand", "user", "anytim", "anywher", "regardless", "internet", "connect", "howev", "comput", "vision", "for", "ondevic", "and", "embed", "applic", "face", "mani", "challeng", "model", "must", "run", "quick", "with", "high", "accuraci", "resourceconstrain", "environ", "make", "use", "limit", "comput", "power", "and", "space", "tensorflow", "offer", "various", "pretrain", "model", "such", "draganddrop", "model", "order", "identifi", "approxim", "num", "default", "object", "when", "compar", "with", "other", "similar", "model", "such", "the", "incept", "model", "dataset", "mobilenet", "work", "better", "with", "latenc", "size", "and", "accuraci", "term", "output", "perform", "there", "signific", "amount", "lag", "with", "fullfledg", "model", "howev", "the", "tradeoff", "accept", "when", "the", "model", "deploy", "mobil", "devic", "for", "realtim", "offlin", "detect", "let", "look", "exampl", "how", "use", "mobilenet", "will", "write", "simpl", "classifi", "find", "pikachu", "imag", "the", "follow", "are", "sampl", "pictur", "show", "imag", "pikachu", "and", "imag", "without", "pikachu"], "timestamp_scraper": 1556480818.932438, "title": "Comparing MobileNet Models in TensorFlow", "read_time": 65.1, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://harshit.app/\" rel=\"noopener noreferrer\" target=\"_blank\">Harshit Dwivedi</a>, Android Instructor</b></p>\n<p><img alt=\"Header image\" class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/2560/1*lhhNdja--d36Ha9z8I8w0Q.jpeg\" width=\"99%\"/></p>\n<p>In recent years, neural networks and deep learning have sparked tremendous progress in the field of\u00a0<a href=\"https://heartbeat.fritz.ai/the-7-nlp-techniques-that-will-change-how-you-communicate-in-the-future-part-i-f0114b2f0497\" rel=\"noopener noreferrer\" target=\"_blank\">natural language processing</a>\u00a0(NLP) and\u00a0<a href=\"https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b\" rel=\"noopener noreferrer\" target=\"_blank\">computer vision</a>.</p>\n<p>While many of the\u00a0<a href=\"https://heartbeat.fritz.ai/building-a-real-time-face-detector-in-android-with-ml-kit-f930eb7b36d9\" rel=\"noopener noreferrer\" target=\"_blank\">face</a>,\u00a0<a href=\"https://heartbeat.fritz.ai/counting-items-in-real-time-on-android-with-fritz-object-detection-c450d6957448\" rel=\"noopener noreferrer\" target=\"_blank\">object</a>, landmark, logo, and\u00a0<a href=\"https://heartbeat.fritz.ai/choose-the-right-on-device-text-recognition-sdk-on-android-using-deltaml-9b4b3e409b6e\" rel=\"noopener noreferrer\" target=\"_blank\">text recognition</a>\u00a0and detection technologies are provided for Internet-connected devices, we believe that the\u00a0<a href=\"https://heartbeat.fritz.ai/hardware-acceleration-for-machine-learning-on-apple-and-android-f3e6ca85bda6\" rel=\"noopener noreferrer\" target=\"_blank\">ever-increasing computational power of mobile devices</a>\u00a0can enable the delivery of these technologies into the hands of users anytime, anywhere, regardless of Internet connection.</p>\n<p>However, computer vision for on-device and embedded applications faces many challenges\u200a\u2014\u200amodels must run quickly with high accuracy in a resource-constrained environment, making use of limited computation, power, and space.</p>\n<p>TensorFlow offers various pre-trained models, such as drag-and-drop models, in order to identify approximately 1,000 default objects.</p>\n<p>When compared with other similar models, such as the\u00a0<a href=\"https://github.com/tensorflow/models/tree/master/research/inception\" rel=\"noopener noreferrer\" target=\"_blank\">Inception</a>\u00a0model datasets,\u00a0<a href=\"https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d\" rel=\"noopener noreferrer\" target=\"_blank\">MobileNet</a>\u00a0works better with latency, size, and accuracy. In terms of output performance, there is a significant amount of lag with a full-fledged model.</p>\n<p>However, the trade-off is acceptable when the model is deployable on a mobile device for real-time offline detection.</p>\n<p>Let\u2019s look at an example of how to use MobileNet. We will write a simple classifier to find Pikachu in an image. The following are sample pictures showing an image of Pikachu and an image without Pikachu:</p>\n<div style=\"text-align:center\"><img alt=\"Figure\" src=\"https://cdn-images-1.medium.com/max/800/0*_J5lRaEE701_15ly\" width=\"250\"/><br>\n<font size=\"-1\"></font></br></div></div> ", "website": "kdnuggets"}