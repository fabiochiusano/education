{"content": "By Ryan Prenger & Tony Han, Baidu . 1.\u2002Introduction At SVAIL (Silicon Valley AI Lab), our mission is to create AI technology that lets us have a significant impact on hundreds of millions of people. When we did the original Deep Speech work [6] in English, it became clear that the shortest path to achieving our mission would be to get the system working in Mandarin Chinese. In our recent paper [1], we showed our results in Mandarin. In just a few months, we had produced a Mandarin speech recognition system with a recognition rate better than native Mandarin speakers. The biggest change we had to make for our Deep Speech system to work in Mandarin was increasing the size of our output layer to accommodate the larger number of Chinese characters (see figure 1). Here we want to discuss what we did to adapt the system to Mandarin and how the end-to-end learning approach made the whole project easier. Figure 1 . Architecture of the DS2 system used on English versus Mandarin. The only change is the larger output layer in Mandarin that accommodates the 6000 Mandarin characters, as opposed to the 29 we use in English. 2.\u2002How End-To-End Learning Made Switching to Mandarin Easier Chinese is considered one of the hardest widely spoken languages for English speakers to learn for several reasons [7]. First, unlike English, Mandarin is a tonal language. This means that changes in pitch actually convey different words, rather than just intentions as in English. Secondly, the language has more than 20,000 different characters, around 6,000 of which are commonly used [10]. Thirdly, the writing system doesn\u2019t use spaces to delimit different words. Traditional speech recognition systems have many components that are necessary to achieve good accuracy with small training data sets. But the complexity of these systems exacerbates the challenges of adapting a speech recognition system to Mandarin. The end-to-end approach used in Deep Speech allowed us to achieve state-of-the-art results quickly with a minimal amount of effort geared towards domain specific adaptation. Below we cover how our end-to-end approach helped us deal with these problems. 2.1.\u2002Input Features Traditional speech recognition systems first convert the raw audio signal into audio features such as mel-frequency cepstral coefficients (MFCCs) in order to preserve and amplify the speech related information in the audio signal while reducing the input dimension [3]. These features suppress some of the pitch information that is unimportant for recognizing words in English but essential for tonal speech recognition. Researchers adapting the system to a tonal language like Mandarin may need to add new features containing pitch information to get good performance [9, 11]. Deep Speech doesn\u2019t use specialized features like MFCCs [1]. We train directly from the spectrogram of the input audio signal. The spectrogram is a fairly general representation of an audio signal. The neural network is able to learn directly which information is relevant from the input, so we didn\u2019t need to change anything about the features to move from English speech recognition to Mandarin speech recognition. 2.2.\u2002Phoneme Lexicon and Alignment Traditional speech recognition systems use the audio input features to predict abstract units of sound known as phonemes. Before training begins, researchers come up with a mapping from each of the words in their vocabulary to sequences of phonemes. This mapping is known as a lexicon. Usually linguists build the lexicon by agreeing on the phonetic representation of a core set of words. To augment the size of the vocabulary, a statistical model or rule-based system can also be used to estimate the phonetic representation of other words [8]. These phonemes are then aligned in time with short 10 millisecond frames of audio in an iterative training process. When switching to a new language with a traditional speech recognition system, a whole new lexicon must be hand crafted. In the case of Mandarin, the phonemes will contain tone information, and word segmentation may be necessary (see section 2.3) [11]. With the Deep Speech network, constructing a new lexicon in Mandarin is unnecessary. Deep Speech uses a deep recurrent neural network that directly maps variable length speech to characters using the connectionist temporal classification loss function [4]. There is no explicit representation of phonemes anywhere in the model, and no alignment needs to be done. This saves us a great deal of work and language specific adaptation that would require knowledge of Mandarin linguistics. 2.3.\u2002Language Modeling Both traditional speech recognition systems and Deep Speech use a language model. A language model is used to estimate how probable a string of words is for a given language. The most common language model used in speech recognition is based on n-gram counts [2]. Speech recognition systems, including our Deep Speech work in English [1], typically use a large text corpus to estimate counts of word sequences. The writing system in Mandarin doesn\u2019t delimit words using spaces. In order to use language models in the same way when switching to Mandarin, an extra word segmentation step would need to be included. However, the word segmentation of a string of characters is vague and not clearly defined; there is no widely accepted word segmentation standard. To avoid these problems when switching to Mandarin, we used a character based N-gram model rather than a word based one. Because there are many characters in a word, a character based N-gram model cannot capture the same long-term dependencies as a word based model of the same size. However, because Deep Speech predicts characters directly, it is learning a language model of its own. In theory it can model the long-term dependencies of language and doesn\u2019t necessarily need a language model. We have found that adding a character based language model is still beneficial, however the network does well without any language model at all. The use of character based model saves us the segmentation step required to move to languages that do not denote words with spaces.", "title_html": "<h1 id=\"title\">Around the World in 60 Days: Getting Deep Speech to Work in Mandarin</h1> ", "url": "https://www.kdnuggets.com/2016/02/getting-deep-speech-work-mandarin-baidu.html", "tfidf": {"tfidf": {"hand": 1.6152202665600002, "base": 8.02397111915, "relat": 1.23750876919, "deal": 4.36693714758, "exacerb": 20.172808132100002, "then": 1.08657860516, "technolog": 2.6034765496900003, "preserv": 3.1062414400300002, "mandarin": 869.9178082200001, "here": 2.42307692308, "shortest": 39.789473684200004, "unimport": 74.1869158879, "signal": 20.49838605552, "wide": 3.1196698762, "new": 4.0715522216, "space": 7.19456193354, "extra": 5.33826496301, "would": 3.2486187845399996, "layer": 16.28307692308, "toni": 6.025047438330001, "audio": 63.39532230465, "contain": 3.19629555064, "pitch": 28.502692998209998, "signific": 1.4529147982100001, "about": 1.06486015159, "function": 2.495441685, "intent": 3.19372359686, "neural": 118.9213483146, "just": 2.67160286074, "adapt": 16.613645876950002, "unlik": 2.42529789184, "done": 2.3302509907499998, "craft": 8.01413427562, "each": 1.18974820144, "approach": 6.2266963001699995, "path": 4.6421052631599995, "represent": 23.71321882, "segment": 37.78200856735, "defin": 2.72830383227, "phonet": 87.2307692308, "whole": 4.58976582828, "train": 7.7462795803999995, "save": 5.6357827475999995, "complex": 2.34021226415, "creat": 1.2492917847, "their": 1.01547908405, "great": 1.26592775696, "recogn": 2.54954231572, "how": 6.41001312204, "million": 1.7279059643, "fair": 3.20533010297, "relev": 6.938811188810001, "had": 2.0951501154799996, "increas": 1.32024948025, "special": 1.4881889763799998, "hundr": 2.4698195395099996, "anyth": 4.58843930636, "rulebas": 1587.6, "found": 1.11387076405, "given": 1.35426085473, "word": 30.541133868969997, "raw": 10.6478873239, "usual": 1.72508964468, "abl": 1.8208510150200001, "deep": 36.2797074954, "mani": 2.08853515754, "will": 1.22481098596, "network": 10.37477536352, "speech": 87.92391042614001, "specif": 3.7438981252199994, "consid": 1.2397313759200002, "build": 1.6341739578, "see": 2.54484251022, "amplifi": 25.5241157556, "tone": 8.58162162162, "second": 1.1130898128, "tradit": 8.04010938925, "string": 16.75567282322, "linguist": 19.290400972060002, "below": 2.25607503197, "clear": 3.70847932726, "perform": 1.5313977042500002, "but": 2.03264835798, "valley": 4.21673306773, "need": 7.186311787049999, "our": 18.86070686072, "classif": 8.067073170730001, "output": 15.353965183760002, "endtoend": 6350.4, "inform": 7.876562810100001, "spoken": 7.06856634016, "baidu": 1134.0, "melfrequ": 1587.6, "frame": 6.280063291139999, "lab": 14.4327272727, "origin": 1.13724928367, "has": 1.0436497502, "have": 3.0446845234199995, "knowledg": 3.3981164383599998, "longterm": 1024.258064516, "sound": 3.11294117647, "typic": 2.2541530597799997, "model": 33.4495654464, "becam": 1.17347919284, "good": 3.03963239518, "accommod": 11.41337167506, "unit": 1.15394679459, "number": 1.10142916609, "prenger": 1587.6, "gear": 11.203952011300002, "also": 1.01476510067, "count": 6.96315789474, "mission": 7.1352808988800005, "third": 1.4195278969999998, "around": 1.21394708671, "mean": 1.44906900329, "short": 1.41295834817, "loss": 2.42529789184, "not": 3.04702194357, "necessarili": 7.33302540416, "becaus": 2.2990369994999997, "compon": 4.09491875161, "length": 3.69123459661, "theori": 3.02745995423, "phonem": 506.6808510636, "hardest": 58.8, "lexicon": 187.216981132, "the": 54.0, "may": 2.10403551786, "minim": 6.10850327049, "peopl": 1.21320495186, "quick": 2.205, "challeng": 2.55816951337, "unnecessari": 17.4845814978, "want": 1.99698113208, "english": 15.6894696387, "convert": 3.2740771293099997, "biggest": 5.2972972973, "system": 23.58577296167, "first": 2.01523229246, "core": 4.623179965059999, "recurr": 35.5964125561, "howev": 3.2835573939899994, "essenti": 2.9280708225700005, "let": 3.48616600791, "variabl": 8.747107438019999, "actual": 1.87482286254, "larger": 4.481580804519999, "silicon": 31.8795180723, "section": 2.1284354471099998, "construct": 1.9320920043799998, "which": 2.01038369, "featur": 10.68988072334, "connectionist": 1587.6, "estim": 7.04973357015, "abstract": 9.966101694919999, "other": 1.00992366412, "introduct": 2.7808723068799996, "tonal": 192.8259109311, "one": 2.01254991444, "show": 1.26703910615, "known": 2.1718194254400003, "impact": 2.97526236882, "begin": 1.3305397251100002, "dimens": 8.25585023401, "captur": 2.88026124819, "such": 1.06151377374, "accuraci": 12.7620578778, "explicit": 5.819648093840001, "sever": 1.07241286139, "corpus": 24.091047041, "agre": 2.22946215419, "get": 3.5712518277, "easier": 15.68, "like": 2.2983713355, "benefici": 18.269275028800003, "some": 1.04036697248, "han": 8.03848101266, "small": 1.3594793629, "both": 1.05215720061, "still": 1.1866357724799999, "process": 1.69524826482, "add": 4.61243463103, "includ": 2.0381282495599997, "produc": 1.36932896326, "vocabulari": 46.5571847508, "without": 1.29547123623, "well": 1.0655748708, "languag": 41.30789245452, "set": 2.37415881562, "stateoftheart": 1587.6, "ani": 1.13383802314, "when": 4.0830707902, "speaker": 12.70588235294, "time": 1.01127460348, "from": 4.00226885988, "result": 2.29223216864, "delimit": 198.45, "anywher": 10.1638924456, "work": 5.57600449565, "project": 1.7534791252500002, "differ": 3.7096347067499997, "recognit": 57.202882483370004, "statist": 4.24265098878, "cepstral": 1587.6, "most": 1.02096463023, "domain": 9.39408284024, "for": 6.00189024006, "depend": 4.4822134387400006, "predict": 10.3696930111, "all": 1.01146788991, "charact": 27.68923418426, "with": 9.010783880909997, "augment": 16.5202913632, "reason": 1.72340425532, "there": 3.12273800157, "are": 4.11962374312, "recent": 1.54405757635, "better": 2.0065722952500002, "nativ": 3.00738776283, "case": 1.48498737256, "effort": 1.89247824532, "month": 1.5079787234, "that": 10.0398406375, "architectur": 5.12790697674, "standard": 1.8915763135900003, "this": 3.01138088013, "num": 26.00819104026, "rate": 2.14048806795, "more": 1.0171706817, "and": 9.000566929169999, "discuss": 2.19676214197, "achiev": 5.61650943396, "these": 5.3707713126000005, "mfccs": 3175.2, "align": 24.31240428789, "amount": 2.27027027027, "general": 1.1218202374200001, "made": 2.14077669902, "problem": 3.53349655018, "befor": 1.10036041031, "toward": 1.6303142329, "iter": 37.4433962264, "spectrogram": 3175.2, "map": 12.218573627490002, "vagu": 20.353846153800003, "ryan": 12.25, "doe": 1.70581282905, "can": 3.52878417426, "make": 1.0762660158600001, "way": 1.2190739461, "write": 4.1150855365400005, "onli": 1.0256476516600002, "convey": 12.297443842, "size": 7.48162111215, "suppress": 6.46153846154, "few": 1.31729173581, "avoid": 2.45986984816, "necessari": 5.684210526319999, "step": 5.655860349119999, "millisecond": 138.052173913, "move": 2.58251321676, "common": 2.8051948051999998, "same": 3.35573874444, "data": 3.37643555934, "switch": 19.89473684212, "reduc": 1.98698372966, "research": 3.8840366972400004, "accept": 1.7377408056, "oppos": 2.51282051282, "sequenc": 12.14225621414, "probabl": 2.64555907349, "rather": 3.11385701676, "versus": 7.77473065622, "into": 1.01502461479, "paper": 2.6628648104700003, "come": 1.32831325301, "must": 1.9220338983099996, "chines": 12.810112963949997, "ngram": 4762.799999999999, "than": 4.131147541, "text": 3.12827586207, "requir": 3.05689804564, "figur": 4.0686827268, "direct": 4.88905997384, "coeffici": 36.4965517241, "what": 1.25343439128, "input": 61.0146041505, "allow": 1.2716059271100002, "use": 18.533497632839996, "while": 1.0441988950299999, "help": 1.39962972759, "order": 2.49250333622, "chang": 4.7235941684, "larg": 1.18574949585, "denot": 10.1965317919, "learn": 11.61375274325, "cover": 1.69380134429, "tempor": 21.897931034499997, "own": 1.17844418052}, "logtfidf": {"hand": 0.479471335336, "base": 0.9556631160090001, "relat": 0.21310030165399999, "deal": 1.561829402506, "exacerb": 3.0043355654900004, "then": 0.08303386523089999, "technolog": 0.956847686355, "preserv": 1.13341345513, "mandarin": 75.45332920639999, "here": 0.8850381883700001, "shortest": 3.6836023970099996, "unimport": 4.30658779888, "signal": 6.536207171719999, "wide": 0.8891600135079999, "new": 0.0709197874044, "space": 2.624139494916, "extra": 1.67490068688, "would": 0.23885288389409998, "layer": 4.1939583247000005, "toni": 1.7959253529299999, "audio": 15.424359502860002, "contain": 0.937690636472, "pitch": 6.754158855929999, "signific": 0.373571744332, "about": 0.0628434774746, "function": 0.914465741594, "intent": 1.16118750781, "neural": 8.170630311, "just": 0.579062868218, "adapt": 6.003932430100001, "unlik": 0.885954358842, "done": 0.845975983129, "craft": 2.0812067672, "each": 0.173741689304, "approach": 2.1907008437430004, "path": 1.5351679838499999, "represent": 7.1189531505999994, "segment": 10.1119755653, "defin": 1.00368010925, "phonet": 7.55081989254, "whole": 1.6613636488119998, "train": 2.643673251356, "save": 2.07197773094, "complex": 0.8502416364309999, "creat": 0.222576818514, "their": 0.015360505122700001, "great": 0.235805258079, "recogn": 0.935913859031, "how": 1.8862678277200002, "million": 0.5469102500940001, "fair": 1.16481508131, "relev": 1.9371304613999998, "had": 0.0929560488222, "increas": 0.277820718929, "special": 0.39755992860100003, "hundr": 0.904145087046, "anyth": 1.52353994585, "rulebas": 7.369978720910001, "found": 0.107841124048, "given": 0.303255810831, "word": 9.959638400545, "raw": 2.36536149914, "usual": 0.545279017064, "abl": 0.599303982475, "deep": 12.886734698, "mani": 0.0866315162442, "will": 0.202786534915, "network": 3.8123322122079997, "speech": 30.842484116210006, "specif": 1.253960335082, "consid": 0.214894723824, "build": 0.491137452091, "see": 0.481843170984, "amplifi": 3.23962372116, "tone": 2.14962289583, "second": 0.10713976337999999, "tradit": 2.3750238814599998, "string": 4.251179392780001, "linguist": 4.53292086534, "below": 0.813626591936, "clear": 1.234949454396, "perform": 0.42618085058, "but": 0.0323847441438, "valley": 1.4390606736700002, "need": 1.81370081721, "our": 6.8611137134560005, "classif": 2.08779073629, "output": 4.07645315654, "endtoend": 29.479914883640003, "inform": 2.27226852331, "spoken": 1.9556576786000002, "baidu": 7.033506484289999, "melfrequ": 7.369978720910001, "frame": 1.8373800586400002, "lab": 2.66949835512, "origin": 0.128612437587, "has": 0.0427239448548, "have": 0.0443550070236, "knowledg": 1.2232212893899999, "longterm": 12.477153218839998, "sound": 1.13556799519, "typic": 0.812774319158, "model": 11.799201169776001, "becam": 0.1599730053, "good": 0.837178809814, "accommod": 3.4832768828400003, "unit": 0.143188061817, "number": 0.0966085784186, "prenger": 7.369978720910001, "gear": 2.41626657421, "also": 0.0146571578, "count": 2.49497182278, "mission": 2.54380887748, "third": 0.35032434942900004, "around": 0.19387710578200001, "mean": 0.37092128352, "short": 0.345685625679, "loss": 0.885954358842, "not": 0.0466572390225, "necessarili": 1.99238817347, "becaus": 0.27868631765, "compon": 1.40974687623, "length": 1.3059609811200001, "theori": 1.10772396902, "phonem": 26.61673110642, "hardest": 4.0741418549, "lexicon": 18.11415179335, "the": 0.0, "may": 0.10141999056880001, "minim": 1.80968177926, "peopl": 0.193265578473, "quick": 0.790727508899, "challeng": 0.9392919688950001, "unnecessari": 2.8613194352999995, "want": 0.6916366062549999, "english": 5.001886677015, "convert": 1.1860360368, "biggest": 1.6671967465900002, "system": 5.566315874945, "first": 0.015174579624319999, "core": 1.53108277245, "recurr": 3.5722448618800002, "howev": 0.27094535204250003, "essenti": 1.07434378384, "let": 1.2488025672799998, "variabl": 2.1687230672, "actual": 0.628514181648, "larger": 1.613657323556, "silicon": 3.46196373688, "section": 0.755387177948, "construct": 0.658603355972, "which": 0.01035682769086, "featur": 2.9637119269939998, "connectionist": 7.369978720910001, "estim": 2.563132607925, "abstract": 2.29918950399, "other": 0.00987474791976, "introduct": 1.02276465794, "tonal": 12.48952643181, "one": 0.012510703291, "show": 0.236682766013, "known": 0.1648361611984, "impact": 1.09033222631, "begin": 0.285584668268, "dimens": 2.11092206831, "captur": 1.0578810012100002, "such": 0.059695977806, "accuraci": 2.5464765406, "explicit": 1.7612397949400003, "sever": 0.06991112039689999, "corpus": 3.1818402794, "agre": 0.801760369921, "get": 1.159538011564, "easier": 4.11847766872, "like": 0.27810715309, "benefici": 2.90522068864, "some": 0.0395735090645, "han": 2.08424013657, "small": 0.307101805059, "both": 0.050842533389300004, "still": 0.17112222142900002, "process": 0.527829199025, "add": 1.52875583713, "includ": 0.037769362781, "produc": 0.314320812003, "vocabulari": 6.29506831212, "without": 0.258874517941, "well": 0.0635144383156, "languag": 14.952272839307998, "set": 0.342992022578, "stateoftheart": 7.369978720910001, "ani": 0.125608358366, "when": 0.0822199554336, "speaker": 3.6978357661400003, "time": 0.0112115188626, "from": 0.002268216675464, "result": 0.272757816762, "delimit": 9.19477999734, "anywher": 2.3188414835, "work": 0.545172836365, "project": 0.561601885907, "differ": 0.6369633639360001, "recognit": 19.26151412536, "statist": 1.4451883070700002, "cepstral": 7.369978720910001, "most": 0.020747896295599998, "domain": 2.24008000599, "for": 0.0018899423723820002, "depend": 1.61393963, "predict": 3.2914804753799998, "all": 0.011402632097799998, "charact": 10.154632479629, "with": 0.01077742542051, "augment": 2.8045894049299998, "reason": 0.544301552962, "there": 0.12029367877649999, "are": 0.1178698943308, "recent": 0.434413741288, "better": 0.6964279406, "nativ": 1.10107184908, "case": 0.395406268889, "effort": 0.637887211057, "month": 0.410770160338, "that": 0.039761483796399995, "architectur": 1.63469757919, "standard": 0.63741050982, "this": 0.0113593471575, "num": 0.008189750280322, "rate": 0.761033872166, "more": 0.017024931599999998, "and": 0.0005669112785724, "discuss": 0.78698452262, "achiev": 1.881294255351, "these": 0.357668097004, "mfccs": 14.739957441820001, "align": 6.277123187879999, "amount": 0.819898886199, "general": 0.114952578063, "made": 0.1360430521946, "problem": 1.138281448546, "befor": 0.0956377718795, "toward": 0.48877277716000006, "iter": 3.62283035867, "spectrogram": 14.739957441820001, "map": 4.21303480152, "vagu": 3.01326989422, "ryan": 2.50552593699, "doe": 0.5340417297169999, "can": 0.487023289182, "make": 0.07349765782289999, "way": 0.19809150993500002, "write": 1.443024879754, "onli": 0.025324268329099998, "convey": 2.50939142306, "size": 2.741511618183, "suppress": 1.8658674413799998, "few": 0.275577913653, "avoid": 0.900108441291, "necessari": 2.0890901347999997, "step": 2.07909011396, "millisecond": 4.927631685540001, "move": 0.511231718506, "common": 0.676651610542, "same": 0.336178948812, "data": 1.2168205848, "switch": 6.41664342132, "reduc": 0.686617775143, "research": 1.327455636276, "accept": 0.552585882007, "oppos": 0.921405832541, "sequenc": 3.6070888748, "probabl": 0.972882412913, "rather": 0.885429951078, "versus": 2.05087881518, "into": 0.0149128632287, "paper": 0.979402539665, "come": 0.28390990653000003, "must": 0.653383947388, "chines": 4.35486793686, "ngram": 22.10993616273, "than": 0.1290434488728, "text": 1.14048200999, "requir": 0.84850702135, "figur": 1.4203442243200002, "direct": 0.802822757984, "coeffici": 3.5972177828099996, "what": 0.225887296827, "input": 12.50837667695, "allow": 0.24028061118900002, "use": 0.5257443551688, "while": 0.04324998379380001, "help": 0.336207721344, "order": 0.44028076158600005, "chang": 0.665102500232, "larg": 0.17037506060600002, "denot": 2.3220476420700003, "learn": 4.213760323724999, "cover": 0.526975319156, "tempor": 3.08639215905, "own": 0.164195077421}, "logidf": {"hand": 0.479471335336, "base": 0.13652330228700002, "relat": 0.21310030165399999, "deal": 0.780914701253, "exacerb": 3.0043355654900004, "then": 0.08303386523089999, "technolog": 0.956847686355, "preserv": 1.13341345513, "mandarin": 3.7726664603199995, "here": 0.8850381883700001, "shortest": 3.6836023970099996, "unimport": 4.30658779888, "signal": 1.6340517929299998, "wide": 0.44458000675399995, "new": 0.0177299468511, "space": 0.874713164972, "extra": 1.67490068688, "would": 0.0796176279647, "layer": 2.0969791623500003, "toni": 1.7959253529299999, "audio": 2.2034799289800002, "contain": 0.468845318236, "pitch": 2.2513862853099997, "signific": 0.373571744332, "about": 0.0628434774746, "function": 0.914465741594, "intent": 1.16118750781, "neural": 4.0853151555, "just": 0.289531434109, "adapt": 1.2007864860200002, "unlik": 0.885954358842, "done": 0.845975983129, "craft": 2.0812067672, "each": 0.173741689304, "approach": 0.7302336145810001, "path": 1.5351679838499999, "represent": 1.7797382876499999, "segment": 2.02239511306, "defin": 1.00368010925, "phonet": 3.77540994627, "whole": 0.8306818244059999, "train": 0.660918312839, "save": 1.03598886547, "complex": 0.8502416364309999, "creat": 0.222576818514, "their": 0.015360505122700001, "great": 0.235805258079, "recogn": 0.935913859031, "how": 0.47156695693000006, "million": 0.5469102500940001, "fair": 1.16481508131, "relev": 1.9371304613999998, "had": 0.0464780244111, "increas": 0.277820718929, "special": 0.39755992860100003, "hundr": 0.904145087046, "anyth": 1.52353994585, "rulebas": 7.369978720910001, "found": 0.107841124048, "given": 0.303255810831, "word": 0.585861082385, "raw": 2.36536149914, "usual": 0.545279017064, "abl": 0.599303982475, "deep": 1.2886734698, "mani": 0.0433157581221, "will": 0.202786534915, "network": 0.9530830530519999, "speech": 1.3409775702700002, "specif": 0.626980167541, "consid": 0.214894723824, "build": 0.491137452091, "see": 0.240921585492, "amplifi": 3.23962372116, "tone": 2.14962289583, "second": 0.10713976337999999, "tradit": 0.47500477629199994, "string": 2.1255896963900005, "linguist": 2.26646043267, "below": 0.813626591936, "clear": 0.617474727198, "perform": 0.42618085058, "but": 0.0161923720719, "valley": 1.4390606736700002, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "output": 2.03822657827, "endtoend": 7.369978720910001, "inform": 0.454453704662, "spoken": 1.9556576786000002, "baidu": 7.033506484289999, "melfrequ": 7.369978720910001, "frame": 1.8373800586400002, "lab": 2.66949835512, "origin": 0.128612437587, "has": 0.0427239448548, "have": 0.0147850023412, "knowledg": 1.2232212893899999, "longterm": 6.238576609419999, "sound": 1.13556799519, "typic": 0.812774319158, "model": 0.7374500731110001, "becam": 0.1599730053, "good": 0.418589404907, "accommod": 1.7416384414200001, "unit": 0.143188061817, "number": 0.0966085784186, "prenger": 7.369978720910001, "gear": 2.41626657421, "also": 0.0146571578, "count": 1.24748591139, "mission": 1.27190443874, "third": 0.35032434942900004, "around": 0.19387710578200001, "mean": 0.37092128352, "short": 0.345685625679, "loss": 0.885954358842, "not": 0.0155524130075, "necessarili": 1.99238817347, "becaus": 0.139343158825, "compon": 1.40974687623, "length": 1.3059609811200001, "theori": 1.10772396902, "phonem": 4.43612185107, "hardest": 4.0741418549, "lexicon": 3.62283035867, "the": 0.0, "may": 0.050709995284400004, "minim": 1.80968177926, "peopl": 0.193265578473, "quick": 0.790727508899, "challeng": 0.9392919688950001, "unnecessari": 2.8613194352999995, "want": 0.6916366062549999, "english": 0.555765186335, "convert": 1.1860360368, "biggest": 1.6671967465900002, "system": 0.327430345585, "first": 0.0075872898121599995, "core": 1.53108277245, "recurr": 3.5722448618800002, "howev": 0.0903151173475, "essenti": 1.07434378384, "let": 1.2488025672799998, "variabl": 2.1687230672, "actual": 0.628514181648, "larger": 0.806828661778, "silicon": 3.46196373688, "section": 0.755387177948, "construct": 0.658603355972, "which": 0.00517841384543, "featur": 0.423387418142, "connectionist": 7.369978720910001, "estim": 0.854377535975, "abstract": 2.29918950399, "other": 0.00987474791976, "introduct": 1.02276465794, "tonal": 4.16317547727, "one": 0.0062553516455, "show": 0.236682766013, "known": 0.0824180805992, "impact": 1.09033222631, "begin": 0.285584668268, "dimens": 2.11092206831, "captur": 1.0578810012100002, "such": 0.059695977806, "accuraci": 2.5464765406, "explicit": 1.7612397949400003, "sever": 0.06991112039689999, "corpus": 3.1818402794, "agre": 0.801760369921, "get": 0.579769005782, "easier": 2.05923883436, "like": 0.139053576545, "benefici": 2.90522068864, "some": 0.0395735090645, "han": 2.08424013657, "small": 0.307101805059, "both": 0.050842533389300004, "still": 0.17112222142900002, "process": 0.527829199025, "add": 1.52875583713, "includ": 0.0188846813905, "produc": 0.314320812003, "vocabulari": 3.14753415606, "without": 0.258874517941, "well": 0.0635144383156, "languag": 0.8306818244059999, "set": 0.171496011289, "stateoftheart": 7.369978720910001, "ani": 0.125608358366, "when": 0.0205549888584, "speaker": 1.8489178830700002, "time": 0.0112115188626, "from": 0.000567054168866, "result": 0.136378908381, "delimit": 4.59738999867, "anywher": 2.3188414835, "work": 0.109034567273, "project": 0.561601885907, "differ": 0.212321121312, "recognit": 1.4816549327200002, "statist": 1.4451883070700002, "cepstral": 7.369978720910001, "most": 0.020747896295599998, "domain": 2.24008000599, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "all": 0.011402632097799998, "charact": 0.923148407239, "with": 0.00119749171339, "augment": 2.8045894049299998, "reason": 0.544301552962, "there": 0.0400978929255, "are": 0.0294674735827, "recent": 0.434413741288, "better": 0.6964279406, "nativ": 1.10107184908, "case": 0.395406268889, "effort": 0.637887211057, "month": 0.410770160338, "that": 0.00397614837964, "architectur": 1.63469757919, "standard": 0.63741050982, "this": 0.0037864490525, "num": 0.00031499039539700004, "rate": 0.761033872166, "more": 0.017024931599999998, "and": 6.29901420636e-05, "discuss": 0.78698452262, "achiev": 0.6270980851169999, "these": 0.0715336194008, "mfccs": 7.369978720910001, "align": 2.09237439596, "amount": 0.819898886199, "general": 0.114952578063, "made": 0.0680215260973, "problem": 0.569140724273, "befor": 0.0956377718795, "toward": 0.48877277716000006, "iter": 3.62283035867, "spectrogram": 7.369978720910001, "map": 1.40434493384, "vagu": 3.01326989422, "ryan": 2.50552593699, "doe": 0.5340417297169999, "can": 0.162341096394, "make": 0.07349765782289999, "way": 0.19809150993500002, "write": 0.721512439877, "onli": 0.025324268329099998, "convey": 2.50939142306, "size": 0.9138372060609999, "suppress": 1.8658674413799998, "few": 0.275577913653, "avoid": 0.900108441291, "necessari": 1.0445450673999999, "step": 1.03954505698, "millisecond": 4.927631685540001, "move": 0.255615859253, "common": 0.338325805271, "same": 0.112059649604, "data": 1.2168205848, "switch": 1.60416085533, "reduc": 0.686617775143, "research": 0.663727818138, "accept": 0.552585882007, "oppos": 0.921405832541, "sequenc": 1.8035444374, "probabl": 0.972882412913, "rather": 0.442714975539, "versus": 2.05087881518, "into": 0.0149128632287, "paper": 0.979402539665, "come": 0.28390990653000003, "must": 0.653383947388, "chines": 1.45162264562, "ngram": 7.369978720910001, "than": 0.0322608622182, "text": 1.14048200999, "requir": 0.424253510675, "figur": 0.7101721121600001, "direct": 0.200705689496, "coeffici": 3.5972177828099996, "what": 0.225887296827, "input": 2.50167533539, "allow": 0.24028061118900002, "use": 0.0292080197316, "while": 0.04324998379380001, "help": 0.336207721344, "order": 0.22014038079300002, "chang": 0.166275625058, "larg": 0.17037506060600002, "denot": 2.3220476420700003, "learn": 0.842752064745, "cover": 0.526975319156, "tempor": 3.08639215905, "own": 0.164195077421}, "freq": {"hand": 1, "base": 7, "relat": 1, "deal": 2, "exacerb": 1, "then": 1, "technolog": 1, "preserv": 1, "mandarin": 20, "here": 1, "shortest": 1, "unimport": 1, "signal": 4, "wide": 2, "new": 4, "space": 3, "extra": 1, "would": 3, "layer": 2, "toni": 1, "audio": 7, "contain": 2, "pitch": 3, "signific": 1, "about": 1, "function": 1, "intent": 1, "neural": 2, "just": 2, "adapt": 5, "unlik": 1, "done": 1, "craft": 1, "each": 1, "approach": 3, "path": 1, "represent": 4, "segment": 5, "defin": 1, "phonet": 2, "whole": 2, "train": 4, "save": 2, "complex": 1, "creat": 1, "their": 1, "great": 1, "recogn": 1, "how": 4, "million": 1, "fair": 1, "relev": 1, "had": 2, "increas": 1, "special": 1, "hundr": 1, "anyth": 1, "rulebas": 1, "found": 1, "given": 1, "word": 17, "raw": 1, "usual": 1, "abl": 1, "deep": 10, "mani": 2, "will": 1, "network": 4, "speech": 23, "specif": 2, "consid": 1, "build": 1, "see": 2, "amplifi": 1, "tone": 1, "second": 1, "tradit": 5, "string": 2, "linguist": 2, "below": 1, "clear": 2, "perform": 1, "but": 2, "valley": 1, "need": 5, "our": 8, "classif": 1, "output": 2, "endtoend": 4, "inform": 5, "spoken": 1, "baidu": 1, "melfrequ": 1, "frame": 1, "lab": 1, "origin": 1, "has": 1, "have": 3, "knowledg": 1, "longterm": 2, "sound": 1, "typic": 1, "model": 16, "becam": 1, "good": 2, "accommod": 2, "unit": 1, "number": 1, "prenger": 1, "gear": 1, "also": 1, "count": 2, "mission": 2, "third": 1, "around": 1, "mean": 1, "short": 1, "loss": 1, "not": 3, "necessarili": 1, "becaus": 2, "compon": 1, "length": 1, "theori": 1, "phonem": 6, "hardest": 1, "lexicon": 5, "the": 54, "may": 2, "minim": 1, "peopl": 1, "quick": 1, "challeng": 1, "unnecessari": 1, "want": 1, "english": 9, "convert": 1, "biggest": 1, "system": 17, "first": 2, "core": 1, "recurr": 1, "howev": 3, "essenti": 1, "let": 1, "variabl": 1, "actual": 1, "larger": 2, "silicon": 1, "section": 1, "construct": 1, "which": 2, "featur": 7, "connectionist": 1, "estim": 3, "abstract": 1, "other": 1, "introduct": 1, "tonal": 3, "one": 2, "show": 1, "known": 2, "impact": 1, "begin": 1, "dimens": 1, "captur": 1, "such": 1, "accuraci": 1, "explicit": 1, "sever": 1, "corpus": 1, "agre": 1, "get": 2, "easier": 2, "like": 2, "benefici": 1, "some": 1, "han": 1, "small": 1, "both": 1, "still": 1, "process": 1, "add": 1, "includ": 2, "produc": 1, "vocabulari": 2, "without": 1, "well": 1, "languag": 18, "set": 2, "stateoftheart": 1, "ani": 1, "when": 4, "speaker": 2, "time": 1, "from": 4, "result": 2, "delimit": 2, "anywher": 1, "work": 5, "project": 1, "differ": 3, "recognit": 13, "statist": 1, "cepstral": 1, "most": 1, "domain": 1, "for": 6, "depend": 2, "predict": 2, "all": 1, "charact": 11, "with": 9, "augment": 1, "reason": 1, "there": 3, "are": 4, "recent": 1, "better": 1, "nativ": 1, "case": 1, "effort": 1, "month": 1, "that": 10, "architectur": 1, "standard": 1, "this": 3, "num": 26, "rate": 1, "more": 1, "and": 9, "discuss": 1, "achiev": 3, "these": 5, "mfccs": 2, "align": 3, "amount": 1, "general": 1, "made": 2, "problem": 2, "befor": 1, "toward": 1, "iter": 1, "spectrogram": 2, "map": 3, "vagu": 1, "ryan": 1, "doe": 1, "can": 3, "make": 1, "way": 1, "write": 2, "onli": 1, "convey": 1, "size": 3, "suppress": 1, "few": 1, "avoid": 1, "necessari": 2, "step": 2, "millisecond": 1, "move": 2, "common": 2, "same": 3, "data": 1, "switch": 4, "reduc": 1, "research": 2, "accept": 1, "oppos": 1, "sequenc": 2, "probabl": 1, "rather": 2, "versus": 1, "into": 1, "paper": 1, "come": 1, "must": 1, "chines": 3, "ngram": 3, "than": 4, "text": 1, "requir": 2, "figur": 2, "direct": 4, "coeffici": 1, "what": 1, "input": 5, "allow": 1, "use": 18, "while": 1, "help": 1, "order": 2, "chang": 4, "larg": 1, "denot": 1, "learn": 5, "cover": 1, "tempor": 1, "own": 1}, "idf": {"hand": 1.6152202665600002, "base": 1.14628158845, "relat": 1.23750876919, "deal": 2.18346857379, "exacerb": 20.172808132100002, "then": 1.08657860516, "technolog": 2.6034765496900003, "preserv": 3.1062414400300002, "mandarin": 43.495890411000005, "here": 2.42307692308, "shortest": 39.789473684200004, "unimport": 74.1869158879, "signal": 5.12459651388, "wide": 1.5598349381, "new": 1.0178880554, "space": 2.39818731118, "extra": 5.33826496301, "would": 1.0828729281799998, "layer": 8.14153846154, "toni": 6.025047438330001, "audio": 9.05647461495, "contain": 1.59814777532, "pitch": 9.50089766607, "signific": 1.4529147982100001, "about": 1.06486015159, "function": 2.495441685, "intent": 3.19372359686, "neural": 59.4606741573, "just": 1.33580143037, "adapt": 3.32272917539, "unlik": 2.42529789184, "done": 2.3302509907499998, "craft": 8.01413427562, "each": 1.18974820144, "approach": 2.07556543339, "path": 4.6421052631599995, "represent": 5.928304705, "segment": 7.55640171347, "defin": 2.72830383227, "phonet": 43.6153846154, "whole": 2.29488291414, "train": 1.9365698950999999, "save": 2.8178913737999998, "complex": 2.34021226415, "creat": 1.2492917847, "their": 1.01547908405, "great": 1.26592775696, "recogn": 2.54954231572, "how": 1.60250328051, "million": 1.7279059643, "fair": 3.20533010297, "relev": 6.938811188810001, "had": 1.0475750577399998, "increas": 1.32024948025, "special": 1.4881889763799998, "hundr": 2.4698195395099996, "anyth": 4.58843930636, "rulebas": 1587.6, "found": 1.11387076405, "given": 1.35426085473, "word": 1.7965372864099998, "raw": 10.6478873239, "usual": 1.72508964468, "abl": 1.8208510150200001, "deep": 3.6279707495399998, "mani": 1.04426757877, "will": 1.22481098596, "network": 2.59369384088, "speech": 3.8227787141800005, "specif": 1.8719490626099997, "consid": 1.2397313759200002, "build": 1.6341739578, "see": 1.27242125511, "amplifi": 25.5241157556, "tone": 8.58162162162, "second": 1.1130898128, "tradit": 1.60802187785, "string": 8.37783641161, "linguist": 9.645200486030001, "below": 2.25607503197, "clear": 1.85423966363, "perform": 1.5313977042500002, "but": 1.01632417899, "valley": 4.21673306773, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "output": 7.676982591880001, "endtoend": 1587.6, "inform": 1.5753125620200001, "spoken": 7.06856634016, "baidu": 1134.0, "melfrequ": 1587.6, "frame": 6.280063291139999, "lab": 14.4327272727, "origin": 1.13724928367, "has": 1.0436497502, "have": 1.0148948411399998, "knowledg": 3.3981164383599998, "longterm": 512.129032258, "sound": 3.11294117647, "typic": 2.2541530597799997, "model": 2.0905978404, "becam": 1.17347919284, "good": 1.51981619759, "accommod": 5.70668583753, "unit": 1.15394679459, "number": 1.10142916609, "prenger": 1587.6, "gear": 11.203952011300002, "also": 1.01476510067, "count": 3.48157894737, "mission": 3.5676404494400002, "third": 1.4195278969999998, "around": 1.21394708671, "mean": 1.44906900329, "short": 1.41295834817, "loss": 2.42529789184, "not": 1.01567398119, "necessarili": 7.33302540416, "becaus": 1.1495184997499999, "compon": 4.09491875161, "length": 3.69123459661, "theori": 3.02745995423, "phonem": 84.44680851060001, "hardest": 58.8, "lexicon": 37.4433962264, "the": 1.0, "may": 1.05201775893, "minim": 6.10850327049, "peopl": 1.21320495186, "quick": 2.205, "challeng": 2.55816951337, "unnecessari": 17.4845814978, "want": 1.99698113208, "english": 1.7432744043000001, "convert": 3.2740771293099997, "biggest": 5.2972972973, "system": 1.38739840951, "first": 1.00761614623, "core": 4.623179965059999, "recurr": 35.5964125561, "howev": 1.0945191313299998, "essenti": 2.9280708225700005, "let": 3.48616600791, "variabl": 8.747107438019999, "actual": 1.87482286254, "larger": 2.2407904022599996, "silicon": 31.8795180723, "section": 2.1284354471099998, "construct": 1.9320920043799998, "which": 1.005191845, "featur": 1.52712581762, "connectionist": 1587.6, "estim": 2.34991119005, "abstract": 9.966101694919999, "other": 1.00992366412, "introduct": 2.7808723068799996, "tonal": 64.2753036437, "one": 1.00627495722, "show": 1.26703910615, "known": 1.0859097127200001, "impact": 2.97526236882, "begin": 1.3305397251100002, "dimens": 8.25585023401, "captur": 2.88026124819, "such": 1.06151377374, "accuraci": 12.7620578778, "explicit": 5.819648093840001, "sever": 1.07241286139, "corpus": 24.091047041, "agre": 2.22946215419, "get": 1.78562591385, "easier": 7.84, "like": 1.14918566775, "benefici": 18.269275028800003, "some": 1.04036697248, "han": 8.03848101266, "small": 1.3594793629, "both": 1.05215720061, "still": 1.1866357724799999, "process": 1.69524826482, "add": 4.61243463103, "includ": 1.0190641247799999, "produc": 1.36932896326, "vocabulari": 23.2785923754, "without": 1.29547123623, "well": 1.0655748708, "languag": 2.29488291414, "set": 1.18707940781, "stateoftheart": 1587.6, "ani": 1.13383802314, "when": 1.02076769755, "speaker": 6.35294117647, "time": 1.01127460348, "from": 1.00056721497, "result": 1.14611608432, "delimit": 99.225, "anywher": 10.1638924456, "work": 1.11520089913, "project": 1.7534791252500002, "differ": 1.23654490225, "recognit": 4.40022172949, "statist": 4.24265098878, "cepstral": 1587.6, "most": 1.02096463023, "domain": 9.39408284024, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "all": 1.01146788991, "charact": 2.51720310766, "with": 1.0011982089899998, "augment": 16.5202913632, "reason": 1.72340425532, "there": 1.04091266719, "are": 1.02990593578, "recent": 1.54405757635, "better": 2.0065722952500002, "nativ": 3.00738776283, "case": 1.48498737256, "effort": 1.89247824532, "month": 1.5079787234, "that": 1.00398406375, "architectur": 5.12790697674, "standard": 1.8915763135900003, "this": 1.00379362671, "num": 1.00031504001, "rate": 2.14048806795, "more": 1.0171706817, "and": 1.00006299213, "discuss": 2.19676214197, "achiev": 1.87216981132, "these": 1.07415426252, "mfccs": 1587.6, "align": 8.10413476263, "amount": 2.27027027027, "general": 1.1218202374200001, "made": 1.07038834951, "problem": 1.76674827509, "befor": 1.10036041031, "toward": 1.6303142329, "iter": 37.4433962264, "spectrogram": 1587.6, "map": 4.0728578758300005, "vagu": 20.353846153800003, "ryan": 12.25, "doe": 1.70581282905, "can": 1.17626139142, "make": 1.0762660158600001, "way": 1.2190739461, "write": 2.0575427682700003, "onli": 1.0256476516600002, "convey": 12.297443842, "size": 2.49387370405, "suppress": 6.46153846154, "few": 1.31729173581, "avoid": 2.45986984816, "necessari": 2.8421052631599997, "step": 2.8279301745599996, "millisecond": 138.052173913, "move": 1.29125660838, "common": 1.4025974025999999, "same": 1.11857958148, "data": 3.37643555934, "switch": 4.97368421053, "reduc": 1.98698372966, "research": 1.9420183486200002, "accept": 1.7377408056, "oppos": 2.51282051282, "sequenc": 6.07112810707, "probabl": 2.64555907349, "rather": 1.55692850838, "versus": 7.77473065622, "into": 1.01502461479, "paper": 2.6628648104700003, "come": 1.32831325301, "must": 1.9220338983099996, "chines": 4.270037654649999, "ngram": 1587.6, "than": 1.03278688525, "text": 3.12827586207, "requir": 1.52844902282, "figur": 2.0343413634, "direct": 1.22226499346, "coeffici": 36.4965517241, "what": 1.25343439128, "input": 12.2029208301, "allow": 1.2716059271100002, "use": 1.0296387573799999, "while": 1.0441988950299999, "help": 1.39962972759, "order": 1.24625166811, "chang": 1.1808985421, "larg": 1.18574949585, "denot": 10.1965317919, "learn": 2.32275054865, "cover": 1.69380134429, "tempor": 21.897931034499997, "own": 1.17844418052}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Around the World in 60 Days: Getting Deep Speech to Work in Mandarin</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/getting-deep-speech-work-mandarin-baidu.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Around the World in 60 Days: Getting Deep Speech to Work in Mandarin Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/n07.html\" rel=\"prev\" title=\"KDnuggets\u2122 News 16:n07, Feb 24: Deep Learning For Everyone; 21 Must-Know Data Science Q&amp;A, part 2; Amazon Machine Learning\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/conversation-data-scientist-sebastian-raschka-podcast.html\" rel=\"next\" title=\"Conversation with data scientist Sebastian Raschka: A New Podcast Episode\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/02/getting-deep-speech-work-mandarin-baidu.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=45580\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/02/getting-deep-speech-work-mandarin-baidu.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-45580 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 24-Feb, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/index.html\">Feb</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/news-features.html\">News, Features</a> \u00bb Around the World in 60 Days: Getting Deep Speech to Work in Mandarin (\u00a0<a href=\"/2016/n08.html\">16:n08</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Around the World in 60 Days: Getting Deep Speech to Work in Mandarin</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/n07.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/02/conversation-data-scientist-sebastian-raschka-podcast.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/baidu\" rel=\"tag\">Baidu</a>, <a href=\"https://www.kdnuggets.com/tag/convolutional-neural-networks\" rel=\"tag\">Convolutional Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/speech-recognition\" rel=\"tag\">Speech Recognition</a></div>\n<br/>\n<p class=\"excerpt\">\n     Baidu continues to make impressive gains with deep learning. Their latest achievement centers on Mandarin speech recognition, which you can read about here from the researchers involved in the project.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By Ryan Prenger &amp; Tony Han, Baidu</b>.</p>\n<p><b>1.\u2002Introduction</b></p>\n<p>At SVAIL (Silicon Valley AI Lab), our mission is to create AI technology that lets us have a significant impact on hundreds of millions of people. When we did the original Deep Speech work [6] in English, it became clear that the shortest path to achieving our mission would be to get the system working in Mandarin Chinese. In our recent paper [1], we showed our results in Mandarin. In just a few months, we had produced a Mandarin speech recognition system with a recognition rate better than native Mandarin speakers. The biggest change we had to make for our Deep Speech system to work in Mandarin was increasing the size of our output layer to accommodate the larger number of Chinese characters (see figure  1). Here we want to discuss what we did to adapt the system to Mandarin and how the end-to-end learning approach made the whole project easier.</p>\n<p><img alt=\"English vs Mandarin architectures\" src=\"/wp-content/uploads/english-mandarin-architectures-baidu.jpg\" width=\"99%\"/><br>\n<center><b>Figure 1</b>. Architecture of the DS2 system used on English versus Mandarin. The only change is the larger output layer in Mandarin that accommodates the  6000 Mandarin characters, as opposed to the 29 we use in English.</center></br></p>\n<p><b>2.\u2002How End-To-End Learning Made Switching to Mandarin Easier</b></p>\n<p>Chinese is considered one of the hardest widely spoken languages for English speakers to learn for several reasons [7]. First, unlike English, Mandarin is a tonal language. This means that changes in pitch actually convey different words, rather than just intentions as in English. Secondly, the language has more than 20,000 different characters, around 6,000 of which are commonly used [10]. Thirdly, the writing system doesn\u2019t use spaces to delimit different words.</p>\n<p>Traditional speech recognition systems have many components that are necessary to achieve good accuracy with small training data sets. But the complexity of these systems exacerbates the challenges of adapting a speech recognition system to Mandarin. The end-to-end approach used in Deep Speech allowed us to achieve state-of-the-art results quickly with a minimal amount of effort geared towards domain specific adaptation. Below we cover how our end-to-end approach helped us deal with these problems.</p>\n<p><b>2.1.\u2002Input Features</b></p>\n<p>Traditional speech recognition systems first convert the raw audio signal into audio features such as mel-frequency cepstral coefficients (MFCCs) in order to preserve and amplify the speech related information in the audio signal while reducing the input dimension [3]. These features suppress some of the pitch information that is unimportant for recognizing words in English but essential for tonal speech recognition. Researchers adapting the system to a tonal language like Mandarin may need to add new features containing pitch information to get good performance [9, 11].</p>\n<p>Deep Speech doesn\u2019t use specialized features like MFCCs [1]. We train directly from the spectrogram of the input audio signal. The spectrogram is a fairly general representation of an audio signal. The neural network is able to learn directly which information is relevant from the input, so we didn\u2019t need to change anything about the features to move from English speech recognition to Mandarin speech recognition.</p>\n<p><b>2.2.\u2002Phoneme Lexicon and Alignment</b></p>\n<p>Traditional speech recognition systems use the audio input features to predict abstract units of sound known as phonemes. Before training begins, researchers come up with a mapping from each of the words in their vocabulary to sequences of phonemes. This mapping is known as a lexicon. Usually linguists build the lexicon by agreeing on the phonetic representation of a core set of words. To augment the size of the vocabulary, a statistical model or rule-based system can also be used to estimate the phonetic representation of other words [8]. These phonemes are then aligned in time with short 10 millisecond frames of audio in an iterative training process. When switching to a new language with a traditional speech recognition system, a whole new lexicon must be hand crafted. In the case of Mandarin, the phonemes will contain tone information, and word segmentation may be necessary (see section 2.3) [11].</p>\n<p>With the Deep Speech network, constructing a new lexicon in Mandarin is unnecessary. Deep Speech uses a deep recurrent neural network that directly maps variable length speech to characters using the connectionist temporal classification loss function [4]. There is no explicit representation of phonemes anywhere in the model, and no alignment needs to be done. This saves us a great deal of work and language specific adaptation that would require knowledge of Mandarin linguistics.</p>\n<p><b>2.3.\u2002Language Modeling</b></p>\n<p>Both traditional speech recognition systems and Deep Speech use a language model. A language model is used to estimate how probable a string of words is for a given language. The most common language model used in speech recognition is based on n-gram counts [2]. Speech recognition systems, including our Deep Speech work in English [1], typically use a large text corpus to estimate counts of word sequences. The writing system in Mandarin doesn\u2019t delimit words using spaces. In order to use language models in the same way when switching to Mandarin, an extra word segmentation step would need to be included. However, the word segmentation of a string of characters is vague and not clearly defined; there is no widely accepted word segmentation standard.</p>\n<p>To avoid these problems when switching to Mandarin, we used a character based N-gram model rather than a word based one. Because there are many characters in a word, a character based N-gram model cannot capture the same long-term dependencies as a word based model of the same size. However, because Deep Speech predicts characters directly, it is learning a language model of its own. In theory it can model the long-term dependencies of language and doesn\u2019t necessarily need a language model. We have found that adding a character based language model is still beneficial, however the network does well without any language model at all. The use of character based model saves us the segmentation step required to move to languages that do not denote words with spaces.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2016/02/getting-deep-speech-work-mandarin-baidu.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/n07.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/02/conversation-data-scientist-sebastian-raschka-podcast.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/index.html\">Feb</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/02/news-features.html\">News, Features</a> \u00bb Around the World in 60 Days: Getting Deep Speech to Work in Mandarin (\u00a0<a href=\"/2016/n08.html\">16:n08</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556377839\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.755 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 11:10:39 -->\n<!-- Compression = gzip -->", "content_tokenized": ["ryan", "prenger", "toni", "han", "baidu", "num", "introduct", "silicon", "valley", "lab", "our", "mission", "creat", "technolog", "that", "let", "have", "signific", "impact", "hundr", "million", "peopl", "when", "the", "origin", "deep", "speech", "work", "num", "english", "becam", "clear", "that", "the", "shortest", "path", "achiev", "our", "mission", "would", "get", "the", "system", "work", "mandarin", "chines", "our", "recent", "paper", "num", "show", "our", "result", "mandarin", "just", "few", "month", "had", "produc", "mandarin", "speech", "recognit", "system", "with", "recognit", "rate", "better", "than", "nativ", "mandarin", "speaker", "the", "biggest", "chang", "had", "make", "for", "our", "deep", "speech", "system", "work", "mandarin", "increas", "the", "size", "our", "output", "layer", "accommod", "the", "larger", "number", "chines", "charact", "see", "figur", "num", "here", "want", "discuss", "what", "adapt", "the", "system", "mandarin", "and", "how", "the", "endtoend", "learn", "approach", "made", "the", "whole", "project", "easier", "figur", "num", "architectur", "the", "system", "use", "english", "versus", "mandarin", "the", "onli", "chang", "the", "larger", "output", "layer", "mandarin", "that", "accommod", "the", "num", "mandarin", "charact", "oppos", "the", "num", "use", "english", "num", "how", "endtoend", "learn", "made", "switch", "mandarin", "easier", "chines", "consid", "one", "the", "hardest", "wide", "spoken", "languag", "for", "english", "speaker", "learn", "for", "sever", "reason", "num", "first", "unlik", "english", "mandarin", "tonal", "languag", "this", "mean", "that", "chang", "pitch", "actual", "convey", "differ", "word", "rather", "than", "just", "intent", "english", "second", "the", "languag", "has", "more", "than", "num", "differ", "charact", "around", "num", "which", "are", "common", "use", "num", "third", "the", "write", "system", "use", "space", "delimit", "differ", "word", "tradit", "speech", "recognit", "system", "have", "mani", "compon", "that", "are", "necessari", "achiev", "good", "accuraci", "with", "small", "train", "data", "set", "but", "the", "complex", "these", "system", "exacerb", "the", "challeng", "adapt", "speech", "recognit", "system", "mandarin", "the", "endtoend", "approach", "use", "deep", "speech", "allow", "achiev", "stateoftheart", "result", "quick", "with", "minim", "amount", "effort", "gear", "toward", "domain", "specif", "adapt", "below", "cover", "how", "our", "endtoend", "approach", "help", "deal", "with", "these", "problem", "num", "input", "featur", "tradit", "speech", "recognit", "system", "first", "convert", "the", "raw", "audio", "signal", "into", "audio", "featur", "such", "melfrequ", "cepstral", "coeffici", "mfccs", "order", "preserv", "and", "amplifi", "the", "speech", "relat", "inform", "the", "audio", "signal", "while", "reduc", "the", "input", "dimens", "num", "these", "featur", "suppress", "some", "the", "pitch", "inform", "that", "unimport", "for", "recogn", "word", "english", "but", "essenti", "for", "tonal", "speech", "recognit", "research", "adapt", "the", "system", "tonal", "languag", "like", "mandarin", "may", "need", "add", "new", "featur", "contain", "pitch", "inform", "get", "good", "perform", "num", "num", "deep", "speech", "use", "special", "featur", "like", "mfccs", "num", "train", "direct", "from", "the", "spectrogram", "the", "input", "audio", "signal", "the", "spectrogram", "fair", "general", "represent", "audio", "signal", "the", "neural", "network", "abl", "learn", "direct", "which", "inform", "relev", "from", "the", "input", "need", "chang", "anyth", "about", "the", "featur", "move", "from", "english", "speech", "recognit", "mandarin", "speech", "recognit", "num", "phonem", "lexicon", "and", "align", "tradit", "speech", "recognit", "system", "use", "the", "audio", "input", "featur", "predict", "abstract", "unit", "sound", "known", "phonem", "befor", "train", "begin", "research", "come", "with", "map", "from", "each", "the", "word", "their", "vocabulari", "sequenc", "phonem", "this", "map", "known", "lexicon", "usual", "linguist", "build", "the", "lexicon", "agre", "the", "phonet", "represent", "core", "set", "word", "augment", "the", "size", "the", "vocabulari", "statist", "model", "rulebas", "system", "can", "also", "use", "estim", "the", "phonet", "represent", "other", "word", "num", "these", "phonem", "are", "then", "align", "time", "with", "short", "num", "millisecond", "frame", "audio", "iter", "train", "process", "when", "switch", "new", "languag", "with", "tradit", "speech", "recognit", "system", "whole", "new", "lexicon", "must", "hand", "craft", "the", "case", "mandarin", "the", "phonem", "will", "contain", "tone", "inform", "and", "word", "segment", "may", "necessari", "see", "section", "num", "num", "with", "the", "deep", "speech", "network", "construct", "new", "lexicon", "mandarin", "unnecessari", "deep", "speech", "use", "deep", "recurr", "neural", "network", "that", "direct", "map", "variabl", "length", "speech", "charact", "use", "the", "connectionist", "tempor", "classif", "loss", "function", "num", "there", "explicit", "represent", "phonem", "anywher", "the", "model", "and", "align", "need", "done", "this", "save", "great", "deal", "work", "and", "languag", "specif", "adapt", "that", "would", "requir", "knowledg", "mandarin", "linguist", "num", "languag", "model", "both", "tradit", "speech", "recognit", "system", "and", "deep", "speech", "use", "languag", "model", "languag", "model", "use", "estim", "how", "probabl", "string", "word", "for", "given", "languag", "the", "most", "common", "languag", "model", "use", "speech", "recognit", "base", "ngram", "count", "num", "speech", "recognit", "system", "includ", "our", "deep", "speech", "work", "english", "num", "typic", "use", "larg", "text", "corpus", "estim", "count", "word", "sequenc", "the", "write", "system", "mandarin", "delimit", "word", "use", "space", "order", "use", "languag", "model", "the", "same", "way", "when", "switch", "mandarin", "extra", "word", "segment", "step", "would", "need", "includ", "howev", "the", "word", "segment", "string", "charact", "vagu", "and", "not", "clear", "defin", "there", "wide", "accept", "word", "segment", "standard", "avoid", "these", "problem", "when", "switch", "mandarin", "use", "charact", "base", "ngram", "model", "rather", "than", "word", "base", "one", "becaus", "there", "are", "mani", "charact", "word", "charact", "base", "ngram", "model", "can", "not", "captur", "the", "same", "longterm", "depend", "word", "base", "model", "the", "same", "size", "howev", "becaus", "deep", "speech", "predict", "charact", "direct", "learn", "languag", "model", "own", "theori", "can", "model", "the", "longterm", "depend", "languag", "and", "necessarili", "need", "languag", "model", "have", "found", "that", "charact", "base", "languag", "model", "still", "benefici", "howev", "the", "network", "doe", "well", "without", "ani", "languag", "model", "all", "the", "use", "charact", "base", "model", "save", "the", "segment", "step", "requir", "move", "languag", "that", "not", "denot", "word", "with", "space"], "timestamp_scraper": 1556377839.693711, "title": "Around the World in 60 Days: Getting Deep Speech to Work in Mandarin", "read_time": 296.7, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By Ryan Prenger &amp; Tony Han, Baidu</b>.</p>\n<p><b>1.\u2002Introduction</b></p>\n<p>At SVAIL (Silicon Valley AI Lab), our mission is to create AI technology that lets us have a significant impact on hundreds of millions of people. When we did the original Deep Speech work [6] in English, it became clear that the shortest path to achieving our mission would be to get the system working in Mandarin Chinese. In our recent paper [1], we showed our results in Mandarin. In just a few months, we had produced a Mandarin speech recognition system with a recognition rate better than native Mandarin speakers. The biggest change we had to make for our Deep Speech system to work in Mandarin was increasing the size of our output layer to accommodate the larger number of Chinese characters (see figure  1). Here we want to discuss what we did to adapt the system to Mandarin and how the end-to-end learning approach made the whole project easier.</p>\n<p><img alt=\"English vs Mandarin architectures\" src=\"/wp-content/uploads/english-mandarin-architectures-baidu.jpg\" width=\"99%\"/><br>\n<center><b>Figure 1</b>. Architecture of the DS2 system used on English versus Mandarin. The only change is the larger output layer in Mandarin that accommodates the  6000 Mandarin characters, as opposed to the 29 we use in English.</center></br></p>\n<p><b>2.\u2002How End-To-End Learning Made Switching to Mandarin Easier</b></p>\n<p>Chinese is considered one of the hardest widely spoken languages for English speakers to learn for several reasons [7]. First, unlike English, Mandarin is a tonal language. This means that changes in pitch actually convey different words, rather than just intentions as in English. Secondly, the language has more than 20,000 different characters, around 6,000 of which are commonly used [10]. Thirdly, the writing system doesn\u2019t use spaces to delimit different words.</p>\n<p>Traditional speech recognition systems have many components that are necessary to achieve good accuracy with small training data sets. But the complexity of these systems exacerbates the challenges of adapting a speech recognition system to Mandarin. The end-to-end approach used in Deep Speech allowed us to achieve state-of-the-art results quickly with a minimal amount of effort geared towards domain specific adaptation. Below we cover how our end-to-end approach helped us deal with these problems.</p>\n<p><b>2.1.\u2002Input Features</b></p>\n<p>Traditional speech recognition systems first convert the raw audio signal into audio features such as mel-frequency cepstral coefficients (MFCCs) in order to preserve and amplify the speech related information in the audio signal while reducing the input dimension [3]. These features suppress some of the pitch information that is unimportant for recognizing words in English but essential for tonal speech recognition. Researchers adapting the system to a tonal language like Mandarin may need to add new features containing pitch information to get good performance [9, 11].</p>\n<p>Deep Speech doesn\u2019t use specialized features like MFCCs [1]. We train directly from the spectrogram of the input audio signal. The spectrogram is a fairly general representation of an audio signal. The neural network is able to learn directly which information is relevant from the input, so we didn\u2019t need to change anything about the features to move from English speech recognition to Mandarin speech recognition.</p>\n<p><b>2.2.\u2002Phoneme Lexicon and Alignment</b></p>\n<p>Traditional speech recognition systems use the audio input features to predict abstract units of sound known as phonemes. Before training begins, researchers come up with a mapping from each of the words in their vocabulary to sequences of phonemes. This mapping is known as a lexicon. Usually linguists build the lexicon by agreeing on the phonetic representation of a core set of words. To augment the size of the vocabulary, a statistical model or rule-based system can also be used to estimate the phonetic representation of other words [8]. These phonemes are then aligned in time with short 10 millisecond frames of audio in an iterative training process. When switching to a new language with a traditional speech recognition system, a whole new lexicon must be hand crafted. In the case of Mandarin, the phonemes will contain tone information, and word segmentation may be necessary (see section 2.3) [11].</p>\n<p>With the Deep Speech network, constructing a new lexicon in Mandarin is unnecessary. Deep Speech uses a deep recurrent neural network that directly maps variable length speech to characters using the connectionist temporal classification loss function [4]. There is no explicit representation of phonemes anywhere in the model, and no alignment needs to be done. This saves us a great deal of work and language specific adaptation that would require knowledge of Mandarin linguistics.</p>\n<p><b>2.3.\u2002Language Modeling</b></p>\n<p>Both traditional speech recognition systems and Deep Speech use a language model. A language model is used to estimate how probable a string of words is for a given language. The most common language model used in speech recognition is based on n-gram counts [2]. Speech recognition systems, including our Deep Speech work in English [1], typically use a large text corpus to estimate counts of word sequences. The writing system in Mandarin doesn\u2019t delimit words using spaces. In order to use language models in the same way when switching to Mandarin, an extra word segmentation step would need to be included. However, the word segmentation of a string of characters is vague and not clearly defined; there is no widely accepted word segmentation standard.</p>\n<p>To avoid these problems when switching to Mandarin, we used a character based N-gram model rather than a word based one. Because there are many characters in a word, a character based N-gram model cannot capture the same long-term dependencies as a word based model of the same size. However, because Deep Speech predicts characters directly, it is learning a language model of its own. In theory it can model the long-term dependencies of language and doesn\u2019t necessarily need a language model. We have found that adding a character based language model is still beneficial, however the network does well without any language model at all. The use of character based model saves us the segmentation step required to move to languages that do not denote words with spaces.</p>\n</div> ", "website": "kdnuggets"}