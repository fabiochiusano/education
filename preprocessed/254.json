{"content": "By Sebastian Raschka , Michigan State University. comments editor: mattmayo If we tackle a supervised learning problem, my advice is to start with the simplest hypothesis space first. I.e., try a linear model such as logistic regression. If this doesn't work \"well\" (i.e., it doesn't meet our expectation or performance criterion that we defined earlier), I would move on to the next experiment. Random Forests vs. SVMs I would say that random forests are probably THE \"worry-free\" approach - if such a thing exists in ML: There are no real hyperparameters to tune (maybe except for the number of trees; typically, the more trees we have the better). On the contrary, there are a lot of knobs to be turned in SVMs: Choosing the \"right\" kernel, regularization penalties, the slack variable, ... Both random forests and SVMs are non-parametric models (i.e., the complexity grows as the number of training samples increases). Training a non-parametric model can thus be more expensive, computationally, compared to a generalized linear model, for example. The more trees we have, the more expensive it is to build a random forest. Also, we can end up with a lot of support vectors in SVMs; in the worst-case scenario, we have as many support vectors as we have samples in the training set. Although, there are multi-class SVMs, the typical implementation for mult-class classification is One-vs.-All; thus, we have to train an SVM for each class -- in contrast, decision trees or random forests, which can handle multiple classes out of the box. To summarize, random forests are much simpler to train for a practitioner; it's easier to find a good, robust model. The complexity of a random forest grows with the number of trees in the forest, and the number of training samples we have. In SVMs, we typically need to do a fair amount of parameter tuning, and in addition to that, the computational cost grows linearly with the number of classes as well. Deep Learning As a rule of thumb, I'd say that SVMs are great for relatively small data sets with fewer outliers. Random forests may require more data but they almost always come up with a pretty robust model. And deep learning algorithms... well, they require \"relatively\" large datasets to work well, and you also need the infrastructure to train them in reasonable time. Also, deep learning algorithms require much more experience: Setting up a neural network using deep learning algorithms is much more tedious than using an off-the-shelf classifiers such as random forests and SVMs. On the other hand, deep learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition. Another advantage is that you have to worry less about the feature engineering part. Again, in practice, the decision which classifier to choose really depends on your dataset and the general complexity of the problem -- that's where your experience as machine learning practitioner kicks in. If it comes to predictive performance, there are cases where SVMs do better than random forests and vice versa: Caruana, Rich, and Alexandru Niculescu-Mizil. \" An empirical comparison of supervised learning algorithms. \" Proceedings of the 23rd international conference on Machine learning. ACM, 2006. The same is true for deep learning algorithms if you look at the MNIST benchmarks ( /exdb/mnist/ ): The best-performing model in this set is a committee consisting of 35 ConvNets, which were reported to have a 0.23% test error; the best SVM model has a test error of 0.56%. The ConvNet ensemble may reach a better accuracy (for the sake of this ensemble, let's pretend that these are totally unbiased estimates), but without a question, I'd say that the 35 ConvNet committee is far more expensive (computationally). So, if you make that decision: Is a 0.33% improvement worth it? In some cases, it's maybe worth it (e.g., in the financial sector for non-real time predictions), in other cases it perhaps won't be worth it, though. So, my practical advice is: Define a performance metric to evaluate your model Ask yourself: What performance score is desired, what hardware is required, what is the project deadline Start with the simplest model If you don't meet your expected goal, try more complex models (if possible) Bio: Sebastian Raschka is a 'Data Scientist' and Machine Learning enthusiast with a big passion for Python & open source. Author of ' Python Machine Learning '. Michigan State University. Original . Reposted with Permission. Related : 7 Steps to Understanding Deep Learning What To Expect from Deep Learning in 2016 and Beyond Top 10 Deep Learning Projects on Github", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"2016 Silver Blog\" src=\"/images/top-kdnuggets-blog-2016-silver.png\" width=\"120\"/>When Does Deep Learning Work Better Than SVMs or Random Forests?</h1> ", "url": "https://www.kdnuggets.com/2016/04/deep-learning-vs-svm-random-forest.html", "tfidf": {"tfidf": {"hand": 1.6152202665600002, "sake": 19.9447236181, "natur": 1.5392670157100001, "understand": 2.96858638743, "univers": 2.49779735682, "permiss": 6.280063291139999, "real": 2.28103448276, "sebastian": 53.6351351352, "vector": 51.79771615, "report": 1.3634489866, "worryfre": 1587.6, "vice": 5.19162851537, "space": 2.39818731118, "addit": 1.24634950542, "paramet": 17.256521739100002, "would": 2.1657458563599996, "what": 5.01373756512, "much": 3.5826688731899994, "evalu": 6.9509632224199995, "the": 39.0, "dataset": 387.219512196, "about": 1.06486015159, "problem": 5.30024482527, "class": 6.34955339289, "say": 5.2633440159, "neural": 59.4606741573, "python": 112.5957446808, "though": 1.36076112111, "well": 4.2622994832, "tri": 3.7089125102199993, "tree": 20.639625585, "find": 1.7294117647099998, "approach": 2.07556543339, "classifi": 10.5875291764, "enthusiast": 9.39408284024, "defin": 5.45660766454, "expens": 10.635998213490002, "recognit": 4.40022172949, "alexandru": 324.0, "contrast": 2.88339992735, "where": 2.13430127042, "ensembl": 33.493670886, "complex": 11.70106132075, "deadlin": 24.9230769231, "decis": 6.48, "summar": 15.1056137012, "multipl": 2.74813917258, "thing": 2.4065484311099996, "test": 5.31414225942, "repost": 933.882352941, "them": 1.09876115994, "fair": 3.20533010297, "than": 2.0655737705, "michigan": 17.9592760181, "multiclass": 1587.6, "kernel": 70.56, "end": 1.10680423871, "mayb": 42.1114058356, "raschka": 3175.2, "support": 2.5371154614400004, "benchmark": 51.8823529412, "deep": 32.65173674586, "mani": 1.04426757877, "question": 2.20408163265, "regress": 51.2129032258, "perhap": 3.14812611541, "increas": 1.32024948025, "build": 1.6341739578, "total": 1.5460122699399999, "linear": 41.6328671328, "next": 1.4950560316400001, "perform": 6.125590817000001, "but": 2.03264835798, "caruana": 1323.0, "need": 2.8745247148199997, "our": 2.35758835759, "classif": 16.134146341460003, "exist": 1.4647107666799999, "cost": 2.31935719503, "regular": 2.09418282548, "expect": 6.60033259425, "possibl": 1.4173734488, "hardwar": 18.8104265403, "empir": 2.8395635843299996, "grow": 6.81861130995, "origin": 1.13724928367, "big": 2.7400759406299997, "has": 1.0436497502, "have": 8.119158729119999, "advantag": 3.32412060302, "experi": 5.61187698834, "robust": 39.8894472362, "out": 1.06016694491, "model": 22.9965762444, "desir": 3.00170164492, "good": 1.51981619759, "alway": 2.06745670009, "comparison": 4.9597000937199995, "realli": 9.495215311, "number": 5.50714583045, "hyperparamet": 1587.6, "also": 3.04429530201, "typic": 6.762459179339999, "start": 2.53347163488, "simplest": 56.0989399294, "hypothesi": 13.580838323399998, "when": 1.02076769755, "process": 1.69524826482, "bestperform": 1587.6, "far": 1.71022298826, "tune": 20.8346456692, "imag": 2.70137825421, "scenario": 15.3986420951, "may": 2.10403551786, "probabl": 2.64555907349, "mattmayo": 1587.6, "open": 1.24556723678, "less": 1.46904783936, "metric": 22.235294117600002, "handl": 3.9229058561900003, "better": 6.01971688575, "sector": 5.493425605540001, "tedious": 93.3882352941, "they": 2.06034650574, "numrd": 3.5485024586500002, "knob": 90.2045454545, "reach": 1.49801849406, "turn": 1.3838912133899999, "let": 3.48616600791, "niculescumizil": 1587.6, "variabl": 8.747107438019999, "step": 2.8279301745599996, "easier": 7.84, "github": 1587.6, "logist": 14.0994671403, "were": 1.02458857696, "which": 3.015575535, "passion": 8.14571575167, "random": 71.902173913, "featur": 1.52712581762, "versa": 23.381443299, "practic": 3.40869565218, "thus": 3.2927512185000003, "estim": 2.34991119005, "other": 2.01984732824, "without": 1.29547123623, "algorithm": 139.753521127, "consist": 1.4901445466499998, "onevsal": 1587.6, "financi": 2.60860992442, "criterion": 31.8156312625, "such": 4.24605509496, "accuraci": 12.7620578778, "outlier": 269.084745763, "meet": 3.3317943336799996, "with": 9.010783880909997, "network": 2.59369384088, "confer": 2.8324710080299997, "implement": 3.57648118946, "lot": 8.81755068036, "box": 4.12685209254, "beyond": 2.54586273252, "small": 1.3594793629, "both": 1.05215720061, "except": 1.71948445792, "part": 1.04330682789, "state": 2.0954266481799997, "that": 9.03585657375, "supervis": 15.48122866894, "rule": 1.7415533128599998, "languag": 2.29488291414, "set": 4.74831763124, "this": 3.01138088013, "pretti": 15.75, "sampl": 21.69840546696, "and": 12.000755905559998, "from": 1.00056721497, "proceed": 3.4333910034599997, "relat": 3.71252630757, "work": 2.23040179826, "project": 3.5069582505000003, "num": 9.00283536009, "editor": 4.33060556465, "offtheshelf": 1587.6, "advic": 14.16235504014, "kick": 13.099009900999999, "intern": 1.30355530011, "for": 10.003150400100001, "depend": 2.2411067193700003, "predict": 10.3696930111, "top": 1.8387769284200002, "practition": 37.7550535078, "reason": 1.72340425532, "there": 4.16365066876, "are": 9.26915342202, "true": 2.55569864778, "almost": 1.53584212054, "case": 4.45496211768, "author": 1.4229631621399998, "look": 1.9086318826599997, "more": 9.154536135299999, "improv": 2.04376930999, "score": 4.2884927066500005, "contrari": 8.042553191489999, "these": 1.07415426252, "rich": 3.8826118855500003, "exdbmnist": 1587.6, "slack": 92.8421052632, "sourc": 1.69760479042, "amount": 2.27027027027, "general": 2.2436404748400003, "forest": 53.85013876044, "train": 13.5559892657, "penalti": 9.95360501567, "again": 1.50883862384, "compar": 1.8662278123900002, "some": 1.04036697248, "doe": 3.4116256581, "can": 3.52878417426, "comput": 11.783275606140002, "make": 1.0762660158600001, "simpler": 17.9187358916, "each": 1.18974820144, "nonparametr": 3175.2, "great": 1.26592775696, "infrastructur": 6.825451418740001, "tackl": 19.8698372966, "speech": 3.8227787141800005, "goal": 3.28152128979, "error": 12.08219178082, "time": 2.02254920696, "multclass": 1587.6, "move": 1.29125660838, "worri": 10.302401038300001, "ask": 2.1744966443, "comment": 3.05954904606, "data": 10.12930667802, "unbias": 170.709677419, "anoth": 1.13643521832, "thumb": 33.3529411765, "pretend": 18.9677419355, "scientist": 4.69426374926, "machin": 16.09733840304, "best": 1.5828514456600002, "bio": 42.336000000000006, "come": 3.9849397590299995, "exampl": 1.50483412322, "fewer": 5.94829524166, "convnet": 4762.799999999999, "worth": 15.631112569740003, "right": 1.4054532577899999, "requir": 6.11379609128, "worstcas": 1587.6, "shine": 19.6728624535, "first": 1.00761614623, "earlier": 1.86776470588, "engin": 2.47135740971, "choos": 8.35798894446, "use": 2.0592775147599998, "committe": 6.474714518759999, "although": 1.14968498805, "yourself": 26.592964824099997, "larg": 1.18574949585, "nonreal": 1587.6, "learn": 34.841258229750004, "same": 1.11857958148, "svms": 14288.4}, "logtfidf": {"hand": 0.479471335336, "sake": 2.9929646280599997, "natur": 0.431306339292, "understand": 1.0880858756799998, "univers": 0.444524211372, "permiss": 1.8373800586400002, "real": 0.824629060574, "sebastian": 6.5781143580400006, "vector": 6.50839775594, "report": 0.31001750903700004, "worryfre": 7.369978720910001, "vice": 1.64704742741, "space": 0.874713164972, "addit": 0.220218882972, "paramet": 2.8481901438599997, "would": 0.1592352559294, "what": 0.903549187308, "much": 0.5324871879030001, "evalu": 1.9388802431299998, "the": 0.0, "dataset": 10.53168913328, "about": 0.0628434774746, "problem": 1.707422172819, "class": 2.2493165697990003, "say": 1.6864628416560001, "neural": 4.0853151555, "python": 8.06131348592, "though": 0.308044191079, "well": 0.2540577532624, "tri": 1.23518305832, "tree": 7.0888744387500005, "find": 0.547781330288, "approach": 0.7302336145810001, "classifi": 3.3330592702999997, "enthusiast": 2.24008000599, "defin": 2.0073602185, "expens": 3.79689605022, "recognit": 1.4816549327200002, "alexandru": 5.78074351579, "contrast": 1.0589701282, "where": 0.1299842774914, "ensembl": 5.6364186233, "complex": 4.251208182155, "deadlin": 3.21579415833, "decis": 2.310324665088, "summar": 2.7150664430299996, "multipl": 1.01092401812, "thing": 0.8781935346799999, "test": 1.954448874206, "repost": 6.83935046985, "them": 0.0941833269093, "fair": 1.16481508131, "than": 0.0645217244364, "michigan": 4.389919141419999, "multiclass": 7.369978720910001, "kernel": 4.2564634117, "end": 0.101476798618, "mayb": 6.094342891779999, "raschka": 14.739957441820001, "support": 0.475761220074, "benchmark": 3.9489787119499997, "deep": 11.598061228199999, "mani": 0.0433157581221, "question": 0.790310929014, "regress": 3.9359915164199997, "perhap": 1.14680739183, "increas": 0.277820718929, "build": 0.491137452091, "total": 0.43567888670500005, "linear": 7.89083292588, "next": 0.402163685499, "perform": 1.70472340232, "but": 0.0323847441438, "caruana": 7.18765716411, "need": 0.725480326884, "our": 0.8576392141820001, "classif": 4.17558147258, "exist": 0.38165779408699996, "cost": 0.84129007618, "regular": 0.739163417847, "expect": 2.36552325648, "possibl": 0.348805474891, "hardwar": 2.93441131931, "empir": 1.04365037288, "grow": 2.463130626636, "origin": 0.128612437587, "big": 1.00798563557, "has": 0.0427239448548, "have": 0.1182800187296, "advantag": 1.20120515883, "experi": 1.878818861799, "robust": 5.9859292561199995, "out": 0.0584263909193, "model": 8.111950804221001, "desir": 1.0991793428399999, "good": 0.418589404907, "alway": 0.726319204572, "comparison": 1.60134527393, "realli": 3.1152816794, "number": 0.483042892093, "hyperparamet": 7.369978720910001, "also": 0.0439714734, "typic": 2.438322957474, "start": 0.472886738582, "simplest": 6.6679394713999995, "hypothesi": 2.60865985243, "when": 0.0205549888584, "process": 0.527829199025, "bestperform": 7.369978720910001, "far": 0.536623764503, "tune": 4.686940155319999, "imag": 0.99376210729, "scenario": 2.73427932989, "may": 0.10141999056880001, "probabl": 0.972882412913, "mattmayo": 7.369978720910001, "open": 0.219591038029, "less": 0.3846144626, "metric": 3.1016808515599994, "handl": 1.36683266903, "better": 2.0892838218, "sector": 1.7035520328, "tedious": 4.53676537685, "they": 0.0594539895352, "numrd": 1.26652567185, "knob": 4.5020798188599995, "reach": 0.40414323085000003, "turn": 0.324899251064, "let": 1.2488025672799998, "niculescumizil": 7.369978720910001, "variabl": 2.1687230672, "step": 1.03954505698, "easier": 2.05923883436, "github": 7.369978720910001, "logist": 2.6461370052, "were": 0.024291143681099997, "which": 0.01553524153629, "passion": 2.0974921144, "random": 19.7272140651, "featur": 0.423387418142, "versa": 3.15194268634, "practic": 1.066365061734, "thus": 0.9971525427860001, "estim": 0.854377535975, "other": 0.01974949583952, "without": 0.258874517941, "algorithm": 16.6522119759, "consist": 0.398873126426, "onevsal": 7.369978720910001, "financi": 0.958817483446, "criterion": 3.45995771815, "such": 0.238783911224, "accuraci": 2.5464765406, "outlier": 5.59502637, "meet": 1.02072763451, "with": 0.01077742542051, "network": 0.9530830530519999, "confer": 1.0411494784, "implement": 1.27437940907, "lot": 2.9671939005000003, "box": 1.41751491115, "beyond": 0.934469583725, "small": 0.307101805059, "both": 0.050842533389300004, "except": 0.54202451213, "part": 0.04239531098280001, "state": 0.0932200055336, "that": 0.035785335416759996, "supervis": 4.09296211166, "rule": 0.554777423537, "languag": 0.8306818244059999, "set": 0.685984045156, "this": 0.0113593471575, "pretti": 2.75684036527, "sampl": 5.93587946517, "and": 0.0007558817047632, "from": 0.000567054168866, "proceed": 1.23354840355, "relat": 0.639300904962, "work": 0.218069134546, "project": 1.123203771814, "num": 0.0028349135585730005, "editor": 1.4657073855, "offtheshelf": 7.369978720910001, "advic": 3.9148804205400003, "kick": 2.57253664727, "intern": 0.265095377816, "for": 0.0031499039539700006, "depend": 0.806969815, "predict": 3.2914804753799998, "top": 0.609100637788, "practition": 5.87594430786, "reason": 0.544301552962, "there": 0.160391571702, "are": 0.2652072622443, "true": 0.938325629634, "almost": 0.42907884333400004, "case": 1.186218806667, "author": 0.35274143130999996, "look": 0.6463866936, "more": 0.15322438439999997, "improv": 0.7147958039319999, "score": 1.4559353207700003, "contrari": 2.08474659391, "these": 0.0715336194008, "rich": 1.35650809354, "exdbmnist": 7.369978720910001, "slack": 4.5309002574, "sourc": 0.529218310751, "amount": 0.819898886199, "general": 0.229905156126, "forest": 17.4714067836, "train": 4.626428189873001, "penalti": 2.29793479868, "again": 0.411340231612, "compar": 0.6239191809269999, "some": 0.0395735090645, "doe": 1.0680834594339998, "can": 0.487023289182, "comput": 4.104206747819999, "make": 0.07349765782289999, "simpler": 2.8858468633, "each": 0.173741689304, "nonparametr": 14.739957441820001, "great": 0.235805258079, "infrastructur": 1.9206584808200002, "tackl": 2.98920286814, "speech": 1.3409775702700002, "goal": 1.18830712273, "error": 3.5971708686, "time": 0.0224230377252, "multclass": 7.369978720910001, "move": 0.255615859253, "worri": 2.3323769785799997, "ask": 0.776797209847, "comment": 1.11826753454, "data": 3.6504617544, "unbias": 5.13996432075, "anoth": 0.127896361652, "thumb": 3.5071459596699994, "pretend": 2.9427397434099998, "scientist": 1.54634128444, "machin": 5.56943832248, "best": 0.459227932947, "bio": 3.7456377879300002, "come": 0.8517297195900001, "exampl": 0.40868267499899996, "fewer": 1.7831046645, "convnet": 22.10993616273, "worth": 4.95195310476, "right": 0.34035985417, "requir": 1.6970140427, "worstcas": 7.369978720910001, "shine": 2.9792401456299995, "first": 0.0075872898121599995, "earlier": 0.624742371425, "engin": 0.904767558276, "choos": 2.86014132144, "use": 0.0584160394632, "committe": 2.34951467258, "although": 0.139487981418, "yourself": 3.28064670051, "larg": 0.17037506060600002, "nonreal": 7.369978720910001, "learn": 12.641280971175, "same": 0.112059649604, "svms": 66.32980848819001}, "logidf": {"hand": 0.479471335336, "sake": 2.9929646280599997, "natur": 0.431306339292, "understand": 1.0880858756799998, "univers": 0.222262105686, "permiss": 1.8373800586400002, "real": 0.824629060574, "sebastian": 3.2890571790200003, "vector": 3.25419887797, "report": 0.31001750903700004, "worryfre": 7.369978720910001, "vice": 1.64704742741, "space": 0.874713164972, "addit": 0.220218882972, "paramet": 2.8481901438599997, "would": 0.0796176279647, "what": 0.225887296827, "much": 0.17749572930100002, "evalu": 1.9388802431299998, "the": 0.0, "dataset": 5.26584456664, "about": 0.0628434774746, "problem": 0.569140724273, "class": 0.7497721899330001, "say": 0.562154280552, "neural": 4.0853151555, "python": 4.03065674296, "though": 0.308044191079, "well": 0.0635144383156, "tri": 0.61759152916, "tree": 1.41777488775, "find": 0.547781330288, "approach": 0.7302336145810001, "classifi": 1.6665296351499999, "enthusiast": 2.24008000599, "defin": 1.00368010925, "expens": 1.26563201674, "recognit": 1.4816549327200002, "alexandru": 5.78074351579, "contrast": 1.0589701282, "where": 0.0649921387457, "ensembl": 2.81820931165, "complex": 0.8502416364309999, "deadlin": 3.21579415833, "decis": 0.7701082216959999, "summar": 2.7150664430299996, "multipl": 1.01092401812, "thing": 0.8781935346799999, "test": 0.977224437103, "repost": 6.83935046985, "them": 0.0941833269093, "fair": 1.16481508131, "than": 0.0322608622182, "michigan": 2.1949595707099996, "multiclass": 7.369978720910001, "kernel": 4.2564634117, "end": 0.101476798618, "mayb": 3.0471714458899997, "raschka": 7.369978720910001, "support": 0.237880610037, "benchmark": 3.9489787119499997, "deep": 1.2886734698, "mani": 0.0433157581221, "question": 0.790310929014, "regress": 3.9359915164199997, "perhap": 1.14680739183, "increas": 0.277820718929, "build": 0.491137452091, "total": 0.43567888670500005, "linear": 2.63027764196, "next": 0.402163685499, "perform": 0.42618085058, "but": 0.0161923720719, "caruana": 7.18765716411, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "exist": 0.38165779408699996, "cost": 0.84129007618, "regular": 0.739163417847, "expect": 0.78850775216, "possibl": 0.348805474891, "hardwar": 2.93441131931, "empir": 1.04365037288, "grow": 0.821043542212, "origin": 0.128612437587, "big": 1.00798563557, "has": 0.0427239448548, "have": 0.0147850023412, "advantag": 1.20120515883, "experi": 0.626272953933, "robust": 2.9929646280599997, "out": 0.0584263909193, "model": 0.7374500731110001, "desir": 1.0991793428399999, "good": 0.418589404907, "alway": 0.726319204572, "comparison": 1.60134527393, "realli": 1.5576408397, "number": 0.0966085784186, "hyperparamet": 7.369978720910001, "also": 0.0146571578, "typic": 0.812774319158, "start": 0.236443369291, "simplest": 3.3339697356999998, "hypothesi": 2.60865985243, "when": 0.0205549888584, "process": 0.527829199025, "bestperform": 7.369978720910001, "far": 0.536623764503, "tune": 2.3434700776599997, "imag": 0.99376210729, "scenario": 2.73427932989, "may": 0.050709995284400004, "probabl": 0.972882412913, "mattmayo": 7.369978720910001, "open": 0.219591038029, "less": 0.3846144626, "metric": 3.1016808515599994, "handl": 1.36683266903, "better": 0.6964279406, "sector": 1.7035520328, "tedious": 4.53676537685, "they": 0.0297269947676, "numrd": 1.26652567185, "knob": 4.5020798188599995, "reach": 0.40414323085000003, "turn": 0.324899251064, "let": 1.2488025672799998, "niculescumizil": 7.369978720910001, "variabl": 2.1687230672, "step": 1.03954505698, "easier": 2.05923883436, "github": 7.369978720910001, "logist": 2.6461370052, "were": 0.024291143681099997, "which": 0.00517841384543, "passion": 2.0974921144, "random": 1.9727214065099998, "featur": 0.423387418142, "versa": 3.15194268634, "practic": 0.533182530867, "thus": 0.49857627139300004, "estim": 0.854377535975, "other": 0.00987474791976, "without": 0.258874517941, "algorithm": 3.33044239518, "consist": 0.398873126426, "onevsal": 7.369978720910001, "financi": 0.958817483446, "criterion": 3.45995771815, "such": 0.059695977806, "accuraci": 2.5464765406, "outlier": 5.59502637, "meet": 0.510363817255, "with": 0.00119749171339, "network": 0.9530830530519999, "confer": 1.0411494784, "implement": 1.27437940907, "lot": 1.4835969502500002, "box": 1.41751491115, "beyond": 0.934469583725, "small": 0.307101805059, "both": 0.050842533389300004, "except": 0.54202451213, "part": 0.04239531098280001, "state": 0.0466100027668, "that": 0.00397614837964, "supervis": 2.04648105583, "rule": 0.554777423537, "languag": 0.8306818244059999, "set": 0.171496011289, "this": 0.0037864490525, "pretti": 2.75684036527, "sampl": 1.9786264883900002, "and": 6.29901420636e-05, "from": 0.000567054168866, "proceed": 1.23354840355, "relat": 0.21310030165399999, "work": 0.109034567273, "project": 0.561601885907, "num": 0.00031499039539700004, "editor": 1.4657073855, "offtheshelf": 7.369978720910001, "advic": 1.9574402102700001, "kick": 2.57253664727, "intern": 0.265095377816, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "top": 0.609100637788, "practition": 2.93797215393, "reason": 0.544301552962, "there": 0.0400978929255, "are": 0.0294674735827, "true": 0.938325629634, "almost": 0.42907884333400004, "case": 0.395406268889, "author": 0.35274143130999996, "look": 0.6463866936, "more": 0.017024931599999998, "improv": 0.7147958039319999, "score": 1.4559353207700003, "contrari": 2.08474659391, "these": 0.0715336194008, "rich": 1.35650809354, "exdbmnist": 7.369978720910001, "slack": 4.5309002574, "sourc": 0.529218310751, "amount": 0.819898886199, "general": 0.114952578063, "forest": 1.5883097076, "train": 0.660918312839, "penalti": 2.29793479868, "again": 0.411340231612, "compar": 0.6239191809269999, "some": 0.0395735090645, "doe": 0.5340417297169999, "can": 0.162341096394, "comput": 1.36806891594, "make": 0.07349765782289999, "simpler": 2.8858468633, "each": 0.173741689304, "nonparametr": 7.369978720910001, "great": 0.235805258079, "infrastructur": 1.9206584808200002, "tackl": 2.98920286814, "speech": 1.3409775702700002, "goal": 1.18830712273, "error": 1.7985854343, "time": 0.0112115188626, "multclass": 7.369978720910001, "move": 0.255615859253, "worri": 2.3323769785799997, "ask": 0.776797209847, "comment": 1.11826753454, "data": 1.2168205848, "unbias": 5.13996432075, "anoth": 0.127896361652, "thumb": 3.5071459596699994, "pretend": 2.9427397434099998, "scientist": 1.54634128444, "machin": 1.39235958062, "best": 0.459227932947, "bio": 3.7456377879300002, "come": 0.28390990653000003, "exampl": 0.40868267499899996, "fewer": 1.7831046645, "convnet": 7.369978720910001, "worth": 1.65065103492, "right": 0.34035985417, "requir": 0.424253510675, "worstcas": 7.369978720910001, "shine": 2.9792401456299995, "first": 0.0075872898121599995, "earlier": 0.624742371425, "engin": 0.904767558276, "choos": 1.43007066072, "use": 0.0292080197316, "committe": 1.17475733629, "although": 0.139487981418, "yourself": 3.28064670051, "larg": 0.17037506060600002, "nonreal": 7.369978720910001, "learn": 0.842752064745, "same": 0.112059649604, "svms": 7.369978720910001}, "freq": {"hand": 1, "sake": 1, "natur": 1, "understand": 1, "univers": 2, "permiss": 1, "real": 1, "sebastian": 2, "vector": 2, "report": 1, "worryfre": 1, "vice": 1, "space": 1, "addit": 1, "paramet": 1, "would": 2, "what": 4, "much": 3, "evalu": 1, "the": 39, "dataset": 2, "about": 1, "problem": 3, "class": 3, "say": 3, "neural": 1, "python": 2, "though": 1, "well": 4, "tri": 2, "tree": 5, "find": 1, "approach": 1, "classifi": 2, "enthusiast": 1, "defin": 2, "expens": 3, "recognit": 1, "alexandru": 1, "contrast": 1, "where": 2, "ensembl": 2, "complex": 5, "deadlin": 1, "decis": 3, "summar": 1, "multipl": 1, "thing": 1, "test": 2, "repost": 1, "them": 1, "fair": 1, "than": 2, "michigan": 2, "multiclass": 1, "kernel": 1, "end": 1, "mayb": 2, "raschka": 2, "support": 2, "benchmark": 1, "deep": 9, "mani": 1, "question": 1, "regress": 1, "perhap": 1, "increas": 1, "build": 1, "total": 1, "linear": 3, "next": 1, "perform": 4, "but": 2, "caruana": 1, "need": 2, "our": 1, "classif": 2, "exist": 1, "cost": 1, "regular": 1, "expect": 3, "possibl": 1, "hardwar": 1, "empir": 1, "grow": 3, "origin": 1, "big": 1, "has": 1, "have": 8, "advantag": 1, "experi": 3, "robust": 2, "out": 1, "model": 11, "desir": 1, "good": 1, "alway": 1, "comparison": 1, "realli": 2, "number": 5, "hyperparamet": 1, "also": 3, "typic": 3, "start": 2, "simplest": 2, "hypothesi": 1, "when": 1, "process": 1, "bestperform": 1, "far": 1, "tune": 2, "imag": 1, "scenario": 1, "may": 2, "probabl": 1, "mattmayo": 1, "open": 1, "less": 1, "metric": 1, "handl": 1, "better": 3, "sector": 1, "tedious": 1, "they": 2, "numrd": 1, "knob": 1, "reach": 1, "turn": 1, "let": 1, "niculescumizil": 1, "variabl": 1, "step": 1, "easier": 1, "github": 1, "logist": 1, "were": 1, "which": 3, "passion": 1, "random": 10, "featur": 1, "versa": 1, "practic": 2, "thus": 2, "estim": 1, "other": 2, "without": 1, "algorithm": 5, "consist": 1, "onevsal": 1, "financi": 1, "criterion": 1, "such": 4, "accuraci": 1, "outlier": 1, "meet": 2, "with": 9, "network": 1, "confer": 1, "implement": 1, "lot": 2, "box": 1, "beyond": 1, "small": 1, "both": 1, "except": 1, "part": 1, "state": 2, "that": 9, "supervis": 2, "rule": 1, "languag": 1, "set": 4, "this": 3, "pretti": 1, "sampl": 3, "and": 12, "from": 1, "proceed": 1, "relat": 3, "work": 2, "project": 2, "num": 9, "editor": 1, "offtheshelf": 1, "advic": 2, "kick": 1, "intern": 1, "for": 10, "depend": 1, "predict": 2, "top": 1, "practition": 2, "reason": 1, "there": 4, "are": 9, "true": 1, "almost": 1, "case": 3, "author": 1, "look": 1, "more": 9, "improv": 1, "score": 1, "contrari": 1, "these": 1, "rich": 1, "exdbmnist": 1, "slack": 1, "sourc": 1, "amount": 1, "general": 2, "forest": 11, "train": 7, "penalti": 1, "again": 1, "compar": 1, "some": 1, "doe": 2, "can": 3, "comput": 3, "make": 1, "simpler": 1, "each": 1, "nonparametr": 2, "great": 1, "infrastructur": 1, "tackl": 1, "speech": 1, "goal": 1, "error": 2, "time": 2, "multclass": 1, "move": 1, "worri": 1, "ask": 1, "comment": 1, "data": 3, "unbias": 1, "anoth": 1, "thumb": 1, "pretend": 1, "scientist": 1, "machin": 4, "best": 1, "bio": 1, "come": 3, "exampl": 1, "fewer": 1, "convnet": 3, "worth": 3, "right": 1, "requir": 4, "worstcas": 1, "shine": 1, "first": 1, "earlier": 1, "engin": 1, "choos": 2, "use": 2, "committe": 2, "although": 1, "yourself": 1, "larg": 1, "nonreal": 1, "learn": 15, "same": 1, "svms": 9}, "idf": {"hand": 1.6152202665600002, "sake": 19.9447236181, "natur": 1.5392670157100001, "understand": 2.96858638743, "univers": 1.24889867841, "permiss": 6.280063291139999, "real": 2.28103448276, "sebastian": 26.8175675676, "vector": 25.898858075, "report": 1.3634489866, "worryfre": 1587.6, "vice": 5.19162851537, "space": 2.39818731118, "addit": 1.24634950542, "paramet": 17.256521739100002, "would": 1.0828729281799998, "what": 1.25343439128, "much": 1.1942229577299999, "evalu": 6.9509632224199995, "the": 1.0, "dataset": 193.609756098, "about": 1.06486015159, "problem": 1.76674827509, "class": 2.11651779763, "say": 1.7544480053, "neural": 59.4606741573, "python": 56.2978723404, "though": 1.36076112111, "well": 1.0655748708, "tri": 1.8544562551099997, "tree": 4.127925117, "find": 1.7294117647099998, "approach": 2.07556543339, "classifi": 5.2937645882, "enthusiast": 9.39408284024, "defin": 2.72830383227, "expens": 3.5453327378300004, "recognit": 4.40022172949, "alexandru": 324.0, "contrast": 2.88339992735, "where": 1.06715063521, "ensembl": 16.746835443, "complex": 2.34021226415, "deadlin": 24.9230769231, "decis": 2.16, "summar": 15.1056137012, "multipl": 2.74813917258, "thing": 2.4065484311099996, "test": 2.65707112971, "repost": 933.882352941, "them": 1.09876115994, "fair": 3.20533010297, "than": 1.03278688525, "michigan": 8.97963800905, "multiclass": 1587.6, "kernel": 70.56, "end": 1.10680423871, "mayb": 21.0557029178, "raschka": 1587.6, "support": 1.2685577307200002, "benchmark": 51.8823529412, "deep": 3.6279707495399998, "mani": 1.04426757877, "question": 2.20408163265, "regress": 51.2129032258, "perhap": 3.14812611541, "increas": 1.32024948025, "build": 1.6341739578, "total": 1.5460122699399999, "linear": 13.8776223776, "next": 1.4950560316400001, "perform": 1.5313977042500002, "but": 1.01632417899, "caruana": 1323.0, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "exist": 1.4647107666799999, "cost": 2.31935719503, "regular": 2.09418282548, "expect": 2.20011086475, "possibl": 1.4173734488, "hardwar": 18.8104265403, "empir": 2.8395635843299996, "grow": 2.27287043665, "origin": 1.13724928367, "big": 2.7400759406299997, "has": 1.0436497502, "have": 1.0148948411399998, "advantag": 3.32412060302, "experi": 1.87062566278, "robust": 19.9447236181, "out": 1.06016694491, "model": 2.0905978404, "desir": 3.00170164492, "good": 1.51981619759, "alway": 2.06745670009, "comparison": 4.9597000937199995, "realli": 4.7476076555, "number": 1.10142916609, "hyperparamet": 1587.6, "also": 1.01476510067, "typic": 2.2541530597799997, "start": 1.26673581744, "simplest": 28.0494699647, "hypothesi": 13.580838323399998, "when": 1.02076769755, "process": 1.69524826482, "bestperform": 1587.6, "far": 1.71022298826, "tune": 10.4173228346, "imag": 2.70137825421, "scenario": 15.3986420951, "may": 1.05201775893, "probabl": 2.64555907349, "mattmayo": 1587.6, "open": 1.24556723678, "less": 1.46904783936, "metric": 22.235294117600002, "handl": 3.9229058561900003, "better": 2.0065722952500002, "sector": 5.493425605540001, "tedious": 93.3882352941, "they": 1.03017325287, "numrd": 3.5485024586500002, "knob": 90.2045454545, "reach": 1.49801849406, "turn": 1.3838912133899999, "let": 3.48616600791, "niculescumizil": 1587.6, "variabl": 8.747107438019999, "step": 2.8279301745599996, "easier": 7.84, "github": 1587.6, "logist": 14.0994671403, "were": 1.02458857696, "which": 1.005191845, "passion": 8.14571575167, "random": 7.1902173913, "featur": 1.52712581762, "versa": 23.381443299, "practic": 1.70434782609, "thus": 1.6463756092500001, "estim": 2.34991119005, "other": 1.00992366412, "without": 1.29547123623, "algorithm": 27.9507042254, "consist": 1.4901445466499998, "onevsal": 1587.6, "financi": 2.60860992442, "criterion": 31.8156312625, "such": 1.06151377374, "accuraci": 12.7620578778, "outlier": 269.084745763, "meet": 1.6658971668399998, "with": 1.0011982089899998, "network": 2.59369384088, "confer": 2.8324710080299997, "implement": 3.57648118946, "lot": 4.40877534018, "box": 4.12685209254, "beyond": 2.54586273252, "small": 1.3594793629, "both": 1.05215720061, "except": 1.71948445792, "part": 1.04330682789, "state": 1.0477133240899998, "that": 1.00398406375, "supervis": 7.74061433447, "rule": 1.7415533128599998, "languag": 2.29488291414, "set": 1.18707940781, "this": 1.00379362671, "pretti": 15.75, "sampl": 7.23280182232, "and": 1.00006299213, "from": 1.00056721497, "proceed": 3.4333910034599997, "relat": 1.23750876919, "work": 1.11520089913, "project": 1.7534791252500002, "num": 1.00031504001, "editor": 4.33060556465, "offtheshelf": 1587.6, "advic": 7.08117752007, "kick": 13.099009900999999, "intern": 1.30355530011, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "top": 1.8387769284200002, "practition": 18.8775267539, "reason": 1.72340425532, "there": 1.04091266719, "are": 1.02990593578, "true": 2.55569864778, "almost": 1.53584212054, "case": 1.48498737256, "author": 1.4229631621399998, "look": 1.9086318826599997, "more": 1.0171706817, "improv": 2.04376930999, "score": 4.2884927066500005, "contrari": 8.042553191489999, "these": 1.07415426252, "rich": 3.8826118855500003, "exdbmnist": 1587.6, "slack": 92.8421052632, "sourc": 1.69760479042, "amount": 2.27027027027, "general": 1.1218202374200001, "forest": 4.89546716004, "train": 1.9365698950999999, "penalti": 9.95360501567, "again": 1.50883862384, "compar": 1.8662278123900002, "some": 1.04036697248, "doe": 1.70581282905, "can": 1.17626139142, "comput": 3.9277585353800006, "make": 1.0762660158600001, "simpler": 17.9187358916, "each": 1.18974820144, "nonparametr": 1587.6, "great": 1.26592775696, "infrastructur": 6.825451418740001, "tackl": 19.8698372966, "speech": 3.8227787141800005, "goal": 3.28152128979, "error": 6.04109589041, "time": 1.01127460348, "multclass": 1587.6, "move": 1.29125660838, "worri": 10.302401038300001, "ask": 2.1744966443, "comment": 3.05954904606, "data": 3.37643555934, "unbias": 170.709677419, "anoth": 1.13643521832, "thumb": 33.3529411765, "pretend": 18.9677419355, "scientist": 4.69426374926, "machin": 4.02433460076, "best": 1.5828514456600002, "bio": 42.336000000000006, "come": 1.32831325301, "exampl": 1.50483412322, "fewer": 5.94829524166, "convnet": 1587.6, "worth": 5.210370856580001, "right": 1.4054532577899999, "requir": 1.52844902282, "worstcas": 1587.6, "shine": 19.6728624535, "first": 1.00761614623, "earlier": 1.86776470588, "engin": 2.47135740971, "choos": 4.17899447223, "use": 1.0296387573799999, "committe": 3.2373572593799995, "although": 1.14968498805, "yourself": 26.592964824099997, "larg": 1.18574949585, "nonreal": 1587.6, "learn": 2.32275054865, "same": 1.11857958148, "svms": 1587.6}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  When Does Deep Learning Work Better Than SVMs or Random Forests?</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/04/deep-learning-vs-svm-random-forest.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb When Does Deep Learning Work Better Than SVMs or Random Forests? Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/16/04-22-tju-faculty-computer-science-data-science.html\" rel=\"prev\" title=\"U. Tianjin: Faculty, Computer Science/Data Science\"/>\n<link href=\"https://www.kdnuggets.com/jobs/16/04-22-snopud-data-analytics-consultant.html\" rel=\"next\" title=\"SNOPUD: Data and Analytics Consultant\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/04/deep-learning-vs-svm-random-forest.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=48109\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/04/deep-learning-vs-svm-random-forest.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-48109 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 22-Apr, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/04/opinions-interviews.html\">Opinions, Interviews, Reports</a> \u00bb When Does Deep Learning Work Better Than SVMs or Random Forests? (\u00a0<a href=\"/2016/n15.html\">16:n15</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"2016 Silver Blog\" src=\"/images/top-kdnuggets-blog-2016-silver.png\" width=\"120\"/>When Does Deep Learning Work Better Than SVMs or Random Forests?</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/16/04-22-tju-faculty-computer-science-data-science.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/16/04-22-snopud-data-analytics-consultant.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 1186</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/advice\" rel=\"tag\">Advice</a>, <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/random-forests\" rel=\"tag\">Random Forests</a>, <a href=\"https://www.kdnuggets.com/tag/support-vector-machines\" rel=\"tag\">Support Vector Machines</a>, <a href=\"https://www.kdnuggets.com/tag/svm\" rel=\"tag\">SVM</a></div>\n<br/>\n<p class=\"excerpt\">\n     Some advice on when a deep neural network may or may not outperform Support Vector Machines or Random Forests.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/sebastian-raschka\" rel=\"author\" title=\"Posts by Sebastian Raschka\">Sebastian Raschka</a>, Michigan State University.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><!-- editor: mattmayo --></p>\n<p>If we tackle a supervised learning problem, my advice is to start with the simplest hypothesis space first. I.e., try a linear model such as logistic regression. If this doesn't work \"well\" (i.e., it doesn't meet our expectation or performance criterion that we defined earlier), I would move on to the next experiment.</p>\n<p><img alt=\"Deep learning\" src=\"/wp-content/uploads/cnn-architecture.jpg\" width=\"99%\"><br>\n<b>Random Forests vs. SVMs</b></br></img></p>\n<p>I would say that random forests are probably THE \"worry-free\" approach - if such a thing exists in ML: There are no real hyperparameters to tune (maybe except for the number of trees; typically, the more trees we have the better). On the contrary, there are a lot of knobs to be turned in SVMs: Choosing the \"right\" kernel, regularization penalties, the slack variable, ...</p>\n<p>Both random forests and SVMs are non-parametric models (i.e., the complexity grows as the number of training samples increases). Training a non-parametric model can thus be more expensive, computationally, compared to a generalized linear model, for example. The more trees we have, the more expensive it is to build a random forest. Also, we can end up with a lot of support vectors in SVMs; in the worst-case scenario, we have as many support vectors as we have samples in the training set. Although, there are multi-class SVMs, the typical implementation for mult-class classification is One-vs.-All; thus, we have to train an SVM for each class -- in contrast, decision trees or random forests, which can handle multiple classes out of the box.</p>\n<p>To summarize, random forests are much simpler to train for a practitioner; it's easier to find a good, robust model. The complexity of a random forest grows with the number of trees in the forest, and the number of training samples we have. In SVMs, we typically need to do a fair amount of parameter tuning, and in addition to that, the computational cost grows linearly with the number of classes as well.</p>\n<p><b>Deep Learning</b></p>\n<p>As a rule of thumb, I'd say that SVMs are great for relatively small data sets with fewer outliers. Random forests may require more data but they almost always come up with a pretty robust model. And deep learning algorithms... well, they require \"relatively\" large datasets to work well, and you also need the infrastructure to train them in reasonable time. Also, deep learning algorithms require much more experience: Setting up a neural network using deep learning algorithms is much more tedious than using an off-the-shelf classifiers such as random forests and SVMs. On the other hand, deep learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition. Another advantage is that you have to worry less about the feature engineering part. Again, in practice, the decision which classifier to choose really depends on your dataset and the general complexity of the problem -- that's where your experience as machine learning practitioner kicks in.</p>\n<p>If it comes to predictive performance, there are cases where SVMs do better than random forests and vice versa:</p>\n<ul>\n<li>Caruana, Rich, and Alexandru Niculescu-Mizil. \"<a href=\"https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf\">An empirical comparison of supervised learning algorithms.</a>\" Proceedings of the 23rd international conference on Machine learning. ACM, 2006.</li>\n</ul>\n<p>The same is true for deep learning algorithms if you look at the MNIST benchmarks (<a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a>): The best-performing model in this set is a committee consisting of 35 ConvNets, which were reported to have a 0.23% test error; the best SVM model has a test error of 0.56%. The ConvNet ensemble may reach a better accuracy (for the sake of this ensemble, let's pretend that these are totally unbiased estimates), but without a question, I'd say that the 35 ConvNet committee is far more expensive (computationally). So, if you make that decision: Is a 0.33% improvement worth it? In some cases, it's maybe worth it (e.g., in the financial sector for non-real time predictions), in other cases it perhaps won't be worth it, though.</p>\n<p>So, my practical advice is:</p>\n<ul>\n<li>Define a performance metric to evaluate your model</li>\n<li>Ask yourself: What performance score is desired, what hardware is required, what is the project deadline</li>\n<li>Start with the simplest model</li>\n<li>If you don't meet your expected goal, try more complex models (if possible)</li>\n</ul>\n<p><b>Bio: <a href=\"https://twitter.com/rasbt\">Sebastian Raschka</a></b> is a 'Data Scientist' and Machine Learning enthusiast with a big passion for Python &amp; open source. Author of '<a href=\"https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning\">Python Machine Learning</a>'. Michigan State University.</p>\n<p><a href=\"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md\">Original</a>. Reposted with Permission.</p>\n<p><b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2016/01/seven-steps-deep-learning.html\">7 Steps to Understanding Deep Learning</a>\n<li><a href=\"/2016/01/deep-learning-2016-beyond.html\">What To Expect from Deep Learning in 2016 and Beyond</a>\n<li><a href=\"/2016/01/top-10-deep-learning-github.html\">Top 10 Deep Learning Projects on Github</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/16/04-22-tju-faculty-computer-science-data-science.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/16/04-22-snopud-data-analytics-consultant.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/04/opinions-interviews.html\">Opinions, Interviews, Reports</a> \u00bb When Does Deep Learning Work Better Than SVMs or Random Forests? (\u00a0<a href=\"/2016/n15.html\">16:n15</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556323355\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.629 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 20:02:35 -->\n<!-- Compression = gzip -->", "content_tokenized": ["sebastian", "raschka", "michigan", "state", "univers", "comment", "editor", "mattmayo", "tackl", "supervis", "learn", "problem", "advic", "start", "with", "the", "simplest", "hypothesi", "space", "first", "tri", "linear", "model", "such", "logist", "regress", "this", "doe", "work", "well", "doe", "meet", "our", "expect", "perform", "criterion", "that", "defin", "earlier", "would", "move", "the", "next", "experi", "random", "forest", "svms", "would", "say", "that", "random", "forest", "are", "probabl", "worryfre", "approach", "such", "thing", "exist", "there", "are", "real", "hyperparamet", "tune", "mayb", "except", "for", "the", "number", "tree", "typic", "the", "more", "tree", "have", "the", "better", "the", "contrari", "there", "are", "lot", "knob", "turn", "svms", "choos", "the", "right", "kernel", "regular", "penalti", "the", "slack", "variabl", "both", "random", "forest", "and", "svms", "are", "nonparametr", "model", "the", "complex", "grow", "the", "number", "train", "sampl", "increas", "train", "nonparametr", "model", "can", "thus", "more", "expens", "comput", "compar", "general", "linear", "model", "for", "exampl", "the", "more", "tree", "have", "the", "more", "expens", "build", "random", "forest", "also", "can", "end", "with", "lot", "support", "vector", "svms", "the", "worstcas", "scenario", "have", "mani", "support", "vector", "have", "sampl", "the", "train", "set", "although", "there", "are", "multiclass", "svms", "the", "typic", "implement", "for", "multclass", "classif", "onevsal", "thus", "have", "train", "for", "each", "class", "contrast", "decis", "tree", "random", "forest", "which", "can", "handl", "multipl", "class", "out", "the", "box", "summar", "random", "forest", "are", "much", "simpler", "train", "for", "practition", "easier", "find", "good", "robust", "model", "the", "complex", "random", "forest", "grow", "with", "the", "number", "tree", "the", "forest", "and", "the", "number", "train", "sampl", "have", "svms", "typic", "need", "fair", "amount", "paramet", "tune", "and", "addit", "that", "the", "comput", "cost", "grow", "linear", "with", "the", "number", "class", "well", "deep", "learn", "rule", "thumb", "say", "that", "svms", "are", "great", "for", "relat", "small", "data", "set", "with", "fewer", "outlier", "random", "forest", "may", "requir", "more", "data", "but", "they", "almost", "alway", "come", "with", "pretti", "robust", "model", "and", "deep", "learn", "algorithm", "well", "they", "requir", "relat", "larg", "dataset", "work", "well", "and", "also", "need", "the", "infrastructur", "train", "them", "reason", "time", "also", "deep", "learn", "algorithm", "requir", "much", "more", "experi", "set", "neural", "network", "use", "deep", "learn", "algorithm", "much", "more", "tedious", "than", "use", "offtheshelf", "classifi", "such", "random", "forest", "and", "svms", "the", "other", "hand", "deep", "learn", "realli", "shine", "when", "come", "complex", "problem", "such", "imag", "classif", "natur", "languag", "process", "and", "speech", "recognit", "anoth", "advantag", "that", "have", "worri", "less", "about", "the", "featur", "engin", "part", "again", "practic", "the", "decis", "which", "classifi", "choos", "realli", "depend", "dataset", "and", "the", "general", "complex", "the", "problem", "that", "where", "experi", "machin", "learn", "practition", "kick", "come", "predict", "perform", "there", "are", "case", "where", "svms", "better", "than", "random", "forest", "and", "vice", "versa", "caruana", "rich", "and", "alexandru", "niculescumizil", "empir", "comparison", "supervis", "learn", "algorithm", "proceed", "the", "numrd", "intern", "confer", "machin", "learn", "num", "the", "same", "true", "for", "deep", "learn", "algorithm", "look", "the", "benchmark", "exdbmnist", "the", "bestperform", "model", "this", "set", "committe", "consist", "num", "convnet", "which", "were", "report", "have", "num", "test", "error", "the", "best", "model", "has", "test", "error", "num", "the", "convnet", "ensembl", "may", "reach", "better", "accuraci", "for", "the", "sake", "this", "ensembl", "let", "pretend", "that", "these", "are", "total", "unbias", "estim", "but", "without", "question", "say", "that", "the", "num", "convnet", "committe", "far", "more", "expens", "comput", "make", "that", "decis", "num", "improv", "worth", "some", "case", "mayb", "worth", "the", "financi", "sector", "for", "nonreal", "time", "predict", "other", "case", "perhap", "worth", "though", "practic", "advic", "defin", "perform", "metric", "evalu", "model", "ask", "yourself", "what", "perform", "score", "desir", "what", "hardwar", "requir", "what", "the", "project", "deadlin", "start", "with", "the", "simplest", "model", "meet", "expect", "goal", "tri", "more", "complex", "model", "possibl", "bio", "sebastian", "raschka", "data", "scientist", "and", "machin", "learn", "enthusiast", "with", "big", "passion", "for", "python", "open", "sourc", "author", "python", "machin", "learn", "michigan", "state", "univers", "origin", "repost", "with", "permiss", "relat", "num", "step", "understand", "deep", "learn", "what", "expect", "from", "deep", "learn", "num", "and", "beyond", "top", "num", "deep", "learn", "project", "github"], "timestamp_scraper": 1556366035.45738, "title": "When Does Deep Learning Work Better Than SVMs or Random Forests?", "read_time": 231.0, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/sebastian-raschka\" rel=\"author\" title=\"Posts by Sebastian Raschka\">Sebastian Raschka</a>, Michigan State University.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><!-- editor: mattmayo --></p>\n<p>If we tackle a supervised learning problem, my advice is to start with the simplest hypothesis space first. I.e., try a linear model such as logistic regression. If this doesn't work \"well\" (i.e., it doesn't meet our expectation or performance criterion that we defined earlier), I would move on to the next experiment.</p>\n<p><img alt=\"Deep learning\" src=\"/wp-content/uploads/cnn-architecture.jpg\" width=\"99%\"><br>\n<b>Random Forests vs. SVMs</b></br></img></p>\n<p>I would say that random forests are probably THE \"worry-free\" approach - if such a thing exists in ML: There are no real hyperparameters to tune (maybe except for the number of trees; typically, the more trees we have the better). On the contrary, there are a lot of knobs to be turned in SVMs: Choosing the \"right\" kernel, regularization penalties, the slack variable, ...</p>\n<p>Both random forests and SVMs are non-parametric models (i.e., the complexity grows as the number of training samples increases). Training a non-parametric model can thus be more expensive, computationally, compared to a generalized linear model, for example. The more trees we have, the more expensive it is to build a random forest. Also, we can end up with a lot of support vectors in SVMs; in the worst-case scenario, we have as many support vectors as we have samples in the training set. Although, there are multi-class SVMs, the typical implementation for mult-class classification is One-vs.-All; thus, we have to train an SVM for each class -- in contrast, decision trees or random forests, which can handle multiple classes out of the box.</p>\n<p>To summarize, random forests are much simpler to train for a practitioner; it's easier to find a good, robust model. The complexity of a random forest grows with the number of trees in the forest, and the number of training samples we have. In SVMs, we typically need to do a fair amount of parameter tuning, and in addition to that, the computational cost grows linearly with the number of classes as well.</p>\n<p><b>Deep Learning</b></p>\n<p>As a rule of thumb, I'd say that SVMs are great for relatively small data sets with fewer outliers. Random forests may require more data but they almost always come up with a pretty robust model. And deep learning algorithms... well, they require \"relatively\" large datasets to work well, and you also need the infrastructure to train them in reasonable time. Also, deep learning algorithms require much more experience: Setting up a neural network using deep learning algorithms is much more tedious than using an off-the-shelf classifiers such as random forests and SVMs. On the other hand, deep learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition. Another advantage is that you have to worry less about the feature engineering part. Again, in practice, the decision which classifier to choose really depends on your dataset and the general complexity of the problem -- that's where your experience as machine learning practitioner kicks in.</p>\n<p>If it comes to predictive performance, there are cases where SVMs do better than random forests and vice versa:</p>\n<ul>\n<li>Caruana, Rich, and Alexandru Niculescu-Mizil. \"<a href=\"https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf\">An empirical comparison of supervised learning algorithms.</a>\" Proceedings of the 23rd international conference on Machine learning. ACM, 2006.</li>\n</ul>\n<p>The same is true for deep learning algorithms if you look at the MNIST benchmarks (<a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a>): The best-performing model in this set is a committee consisting of 35 ConvNets, which were reported to have a 0.23% test error; the best SVM model has a test error of 0.56%. The ConvNet ensemble may reach a better accuracy (for the sake of this ensemble, let's pretend that these are totally unbiased estimates), but without a question, I'd say that the 35 ConvNet committee is far more expensive (computationally). So, if you make that decision: Is a 0.33% improvement worth it? In some cases, it's maybe worth it (e.g., in the financial sector for non-real time predictions), in other cases it perhaps won't be worth it, though.</p>\n<p>So, my practical advice is:</p>\n<ul>\n<li>Define a performance metric to evaluate your model</li>\n<li>Ask yourself: What performance score is desired, what hardware is required, what is the project deadline</li>\n<li>Start with the simplest model</li>\n<li>If you don't meet your expected goal, try more complex models (if possible)</li>\n</ul>\n<p><b>Bio: <a href=\"https://twitter.com/rasbt\">Sebastian Raschka</a></b> is a 'Data Scientist' and Machine Learning enthusiast with a big passion for Python &amp; open source. Author of '<a href=\"https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning\">Python Machine Learning</a>'. Michigan State University.</p>\n<p><a href=\"https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md\">Original</a>. Reposted with Permission.</p>\n<p><b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2016/01/seven-steps-deep-learning.html\">7 Steps to Understanding Deep Learning</a>\n<li><a href=\"/2016/01/deep-learning-2016-beyond.html\">What To Expect from Deep Learning in 2016 and Beyond</a>\n<li><a href=\"/2016/01/top-10-deep-learning-github.html\">Top 10 Deep Learning Projects on Github</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}