{"content": "comments By Sebastian Flennerhag , Machine Learning Researcher Stacking models in Python efficiently \u00a0 Ensembles have rapidly become one of the hottest and most popular methods in applied machine learning. Virtually\u00a0 every winning Kaggle solution \u00a0features them, and many data science pipelines have ensembles in them. Put simply, ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Ensembles give us a performance boost almost for free! Example schematics of an ensemble. An input array\u00a0 X \u00a0is fed through two preprocessing pipelines and then to a set of base learners\u00a0 f (i) . The ensemble combines all base learner predictions into a final prediction array\u00a0 P .\u00a0 Source In this post, we'll take you through the basics of ensembles \u2014 what they are and why they work so well \u2014 and provide a hands-on tutorial for building basic ensembles. By the end of this post, you will: understand the fundamentals of ensembles know how to code them understand the main pitfalls and drawbacks of ensembles \u00a0 Predicting Republican and Democratic donations \u00a0 To illustrate how ensembles work, we'll use a data set on U.S. political contributions. The\u00a0 original data set \u00a0was prepared by\u00a0 Ben Wieder \u00a0at\u00a0 FiveThirtyEight , who dug around the U.S. government's political contribution registry and found that when\u00a0 scientists donate to politician, it's usually to Democrats . This claim is based on the observation on the share of donations being made to Republicans and Democrats. However, there's plenty more that can be said: for instance, which scientific discipline is most likely to make a Republican donation, and which state is most likely to make Democratic donations? We will go one step further and\u00a0 predict \u00a0whether a donation is most likely to be a to a Republican or Democrat. The\u00a0 data \u00a0we use here is slightly adapted. We remove any donations to party affiliations other than Democrat or Republican to make our exposition a little clearer and drop some duplicate and less interesting features. The data script can be found\u00a0 here . Here's the data: import numpy as np\r import pandas as pd\r \r import matplotlib.pyplot as plt\r %matplotlib inline\r \r ### Import data\r # Always good to set a seed for reproducibility\r SEED = 222\r \r \r df = \r \r ### Training and test set\r from sklearn.model_selection import train_test_split\r from sklearn.metrics import roc_auc_score\r \r def :\r \"\"\"Split Data into train and test sets.\"\"\"\r y = 1 * (df.cand_pty_affiliation == \"REP\")\r X = \r X = \r  == 0], axis=1, inplace=True)\r return \r \r xtrain, xtest, ytrain, ytest = \r \r # A look at the data\r \r \r cand_pty_affiliation cand_office_st cand_office cand_status rpt_tp transaction_tp entity_tp state classification cycle transaction_amt 0 REP US P C Q3 15 IND NY Engineer 2016.0 500.0 1 DEM US P C M5 15E IND OR Math-Stat 2016.0 50.0 2 DEM US P C M3 15 IND TX Scientist 2008.0 250.0 3 DEM US P C Q2 15E IND IN Math-Stat 2016.0 250.0 4 REP US P C 12G 15 IND MA Engineer 2016.0 184.0 .\r \r The figure above is the data underlying Ben's claim. Indeed, between Democrats and Republicans, about 75% of all contributions are made to democrats. Let's go through the features at our disposal. We have data about the donor, the transaction, and the recipient: To measure how well our models perform, we use the\u00a0 ROC-AUC \u00a0score, which trades off having high precision and high recall (if these concepts are new to you, see the Wikipedia entry on\u00a0 precision and recall \u00a0for a quick introduction). If you haven't used this metric before, a random guess has a score of 0.5 and perfect recall and precision yields 1.0. \u00a0 What is an ensemble? \u00a0 Imagine that you are playing trivial pursuit. When you play alone, there might be some topics you are good at, and some that you know next to nothing about. If we want to maximize our trivial pursuit score, we need build a team to cover all topics. This is the basic idea of an ensemble: combining predictions from several models averages out idiosyncratic errors and yield better overall predictions. An important question is how to combine predictions. In our trivial pursuit example, it is easy to imagine that team members might make their case and majority voting decides which to pick. Machine learning is remarkably similar in classification problems: taking the most common class label prediction is equivalent to a majority voting rule. But there are many other ways to combine predictions, and more generally we can use a model to\u00a0 learn \u00a0how to best combine predictions. Basic ensemble structure. Data is fed to a set of models, and a meta learner combine model predictions.\u00a0 Source \u00a0 Understanding ensembles by combining decision trees \u00a0 To illustrate the machinery of ensembles, we'll start off with a simple interpretable model: a decision tree, which is a tree of\u00a0 if-then \u00a0rules. If you're unfamiliar with decision trees or would like to dive deeper, check out the\u00a0 decision trees course \u00a0on Dataquest. The deeper the tree, the more complex the patterns it can capture, but the more prone to overfitting it will be. Because of this, we will need an alternative way of building complex models of decision trees, and an ensemble of different decision trees is one such way. We'll use the below helper function to visualize our decision rules: import pydotplus # you can install pydotplus with: pip install pydotplus \r from IPython.display import Image\r from sklearn.metrics import roc_auc_score\r from sklearn.tree import DecisionTreeClassifier, export_graphviz\r \r def :\r \"\"\"Print decision tree.\"\"\"\r graph = \r graph =  \r return )\r Let's fit a decision tree with a single node (decision rule) on our training data and see how it perform on the test set: t1 = \r \r p = [:, 1]\r \r )\r \r Decision tree ROC-AUC score: 0.672 Each of the two leaves register their share of training samples, the class distribution within their share, and the class label prediction. Our decision tree bases its prediction on whether the the size of the contribution is above 101.5: but it makes\u00a0 the same \u00a0prediction regardless! This is not too surprising given that 75% of all donations are to Democrats. But it's not making use of the data we have. Let's use three levels of decision rules and see what we can get: t2 = \r \r p = [:, 1]\r \r )\r \r Decision tree ROC-AUC score: 0.751 This model is not much better than the simple decision tree: a measly 5% of all donations are predicted to go to Republicans\u2013far short of the 25% we would expect. A closer look tells us that the decision tree uses some dubious splitting rules. A whopping 47.3% of all observations end up in the left-most leaf, while another 35.9% end up in the leaf second to the right. The vast majority of leaves are therefore irrelevant. Making the model deeper just causes it to overfit. Fixing depth, a decision tree can be made more complex by increasing \"width\", that is, creating several decision trees and combining them. In other words, an ensemble of decision trees. To see why such a model would help, consider how we may force a decision tree to investigate other patterns than those in the above tree. The simplest solution is to remove features that appear early in the tree. Suppose for instance that we remove the transaction amount feature ( transaction_amt ), the root of the tree. Our new decision tree would look like this: drop = [\"transaction_amt\"]\r \r xtrain_slim = \r xtest_slim = \r \r t3 = \r \r p = [:, 1]\r \r \r )\r \r Decision tree ROC-AUC score: 0.740 The ROC-AUC score is similar, but the share of Republican donation increased to 7.3%. Still too low, but higher than before. Importantly, in contrast to the first tree, where most of the rules related to the transaction itself, this tree is more focused on the residency of the candidate. We now have two models that by themselves have similar predictive power, but operate on different rules. Because of this, they are likely to make different prediction errors, which we can average out with an ensemble. Interlude: why averaging predictions work Why would we expect averaging predictions to work? Consider a toy example with two observations that we want to generate predictions for. The true label for the first observation is Republican, and the true label for the second observation is Democrat. In this toy example, suppose model 1 is prone to predicting Democrat while model 2 is prone to predicting Republican, as in the below table: Model Observation 1 Observation 2 True label R D Model prediction:\u00a0  Model 1 0.4 0.2 Model 2 0.8 0.6 If we use the standard 50% cutoff rule for making a class prediction, each decision tree gets one observation right and one wrong. We create an ensemble by averaging the model's class probabilities, which is a majority vote weighted by the strength (probability) of model's prediction. In our toy example, model 2 is certain of its prediction for observation 1, while model 1 is relatively uncertain. Weighting their predictions, the ensemble favors model 2 and correctly predicts Republican. For the second observation, tables are turned and the ensemble correctly predicts Democrat: Model Observation 1 Observation 2 True label R D Ensemble 0.6 0.4 With more than two decision trees, the ensemble predicts in accordance with the majority. For that reason, an ensemble that averages classifier predictions is known as a\u00a0 majority voting classifier . When an ensembles averages based on probabilities (as above), we refer to it as\u00a0 soft voting , averaging final class label predictions is known as\u00a0 hard voting . Of course, ensembles are no silver bullet. You might have noticed in our toy example that for averaging to work, prediction errors must be\u00a0 uncorrelated . If both models made incorrect predictions, the ensemble would not be able to make any corrections. Moreover, in the soft voting scheme, if one model makes an incorrect prediction with a high probability value, the ensemble would be overwhelmed. Generally, ensembles don't get every observation right, but in expectation it will do better than the underlying models. A forest is an ensemble of trees Returning to our prediction problem, let's see if we can build an ensemble out of our two decision trees. We first check error correlation: highly correlated errors makes for poor ensembles. p1 = [:, 1]\r p2 = [:, 1]\r \r .\r full_data red_data full_data 1.000000 0.669128 red_data 0.669128 1.000000 There is some correlation, but not overly so: there's still a good deal of prediction variance to exploit. To build our first ensemble, we simply average the two model's predictions. p1 = [:, 1]\r p2 = [:, 1]\r p = \r )\r Average of decision tree ROC-AUC score: 0.783 Indeed, the ensemble procedure leads to an increased score. But maybe if we had more diverse trees, we could get an even greater gain. How should we choose which features to exclude when designing the decision trees? A fast approach that works well in practice is to randomly select a subset of features, fit one decision tree on each draw and average their predictions. This process is known as\u00a0 bootstrapped averaging \u00a0(often abbreviated\u00a0 bagging ), and when applied to decision trees, the resultant model is a\u00a0 Random Forest . Let's see what a random forest can do for us. We use the\u00a0 Scikit-learn implementation and build an ensemble of 10 decision trees, each fitted on a subset of 3 features. from sklearn.ensemble import RandomForestClassifier\r \r rf = \r \r \r p = [:, 1]\r )\r Average of decision tree ROC-AUC score: 0.844 The Random Forest yields a significant improvement upon our previous models. We're on to something! But there is only so much you can do with decision trees. It's time we expand our horizon.", "title_html": "<h1 id=\"title\">Introduction to Python Ensembles</h1> ", "url": "https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html", "tfidf": {"tfidf": {"affili": 6.0503048780499995, "xtrain": 1221.23076923, "equival": 4.09175257732, "axisnum": 1221.23076923, "too": 3.6317053643, "fit": 10.11210191082, "label": 31.340101522869997, "rocaucscor": 2442.46153846, "new": 2.0357761108, "suppos": 8.46043165468, "panda": 111.802816901, "wikipedia": 40.5, "function": 2.495441685, "class": 12.69910678578, "plenti": 17.4078947368, "draw": 2.97247706422, "learner": 225.72511848329998, "python": 56.2978723404, "entri": 3.9909502262400003, "well": 4.2622994832, "uncorrel": 529.2, "whether": 4.41367806506, "tree": 156.861154446, "boost": 9.16099249856, "wieder": 567.0, "toy": 61.534883720799996, "higher": 2.1218925421, "yield": 19.40831295843, "know": 5.1865403463, "irrelev": 29.7861163227, "pydotplus": 3663.6923076900002, "abbrevi": 12.326086956500001, "uncertain": 10.8590971272, "stack": 19.6485148515, "measur": 2.41093394077, "creat": 2.4985835694, "how": 12.82002624408, "test": 7.97121338913, "had": 1.0475750577399998, "deeper": 45.2307692307, "would": 7.580110497259999, "distribut": 2.7396031061299997, "end": 3.3204127161300003, "mayb": 21.0557029178, "correl": 39.558139534800006, "word": 1.7965372864099998, "pip": 135.692307692, "interest": 1.60331246213, "tutori": 59.4606741573, "simplest": 28.0494699647, "will": 6.1240549298, "true": 10.22279459112, "exploit": 5.79416058394, "consid": 2.4794627518400003, "work": 6.69120539478, "see": 7.63452753066, "sklearnmetr": 2442.46153846, "second": 3.3392694383999997, "strength": 4.02739726027, "horizon": 18.1232876712, "donat": 59.8642533937, "fulldata": 2442.46153846, "claim": 3.05395787246, "perform": 7.6569885212500015, "but": 11.17956596889, "certain": 1.8077886586200003, "need": 2.8745247148199997, "our": 37.72141372144, "classif": 16.134146341460003, "final": 4.02025829325, "expect": 6.60033259425, "parti": 2.06369426752, "xtestslim": 1221.23076923, "scheme": 5.18993135011, "level": 1.6544393497299998, "has": 1.0436497502, "have": 9.134053570259999, "plt": 1221.23076923, "use": 11.32602633118, "govern": 1.50941243582, "script": 8.299006795610001, "out": 4.24066777964, "model": 68.9897287332, "good": 4.55944859277, "alway": 2.06745670009, "disciplin": 6.92972501091, "concept": 2.65707112971, "structur": 2.0580762250499998, "under": 2.1563327674, "cours": 4.30185611706, "pnum": 46.6255506608, "short": 1.41295834817, "print": 3.29719626168, "not": 5.07836990595, "fivethirtyeight": 1221.23076923, "altern": 2.1390460792200003, "flennerhag": 1221.23076923, "quick": 2.205, "easi": 5.2937645882, "width": 17.294117647100002, "metric": 22.235294117600002, "sklearnmodelselect": 1221.23076923, "said": 1.54751925139, "soft": 17.552238805979997, "then": 1.08657860516, "xtest": 1221.23076923, "they": 4.12069301148, "design": 1.45825296225, "anoth": 1.13643521832, "scientif": 4.15275961287, "instal": 7.57442748092, "turn": 1.3838912133899999, "choos": 4.17899447223, "scienc": 2.31969608416, "rpttp": 1221.23076923, "exposit": 20.353846153800003, "node": 44.3463687151, "featur": 12.21700654096, "resid": 2.39457013575, "donor": 25.565217391300003, "simpl": 6.7962328767199995, "appear": 1.3214582986499999, "itself": 1.74557449148, "provid": 1.21552714187, "array": 20.2888178914, "accord": 1.27589809531, "moreov": 7.56, "pattern": 7.58347265346, "signific": 1.4529147982100001, "inlin": 100.481012658, "sever": 2.14482572278, "those": 1.19548192771, "upon": 1.60331246213, "with": 10.011982089899998, "politician": 4.7235941684, "meta": 151.2, "fast": 4.8729281768, "some": 5.2018348624, "sourc": 3.39520958084, "drop": 4.9189775368, "both": 1.05215720061, "baselin": 115.4618181818, "result": 1.14611608432, "subset": 54.6506024096, "varianc": 51.3786407767, "less": 1.46904783936, "helper": 79.38, "caus": 1.38521943984, "ani": 2.26767604628, "question": 2.20408163265, "virtual": 4.11295336788, "fed": 25.0805687204, "and": 39.002456693069995, "from": 8.00453771976, "dive": 16.085106383, "num": 69.02173776069, "sebastian": 26.8175675676, "instanc": 6.514567090680001, "dfcandptyaffili": 1221.23076923, "idea": 2.0930784443, "free": 1.71818181818, "for": 16.00504064016, "predict": 217.76355323310003, "remark": 3.8515283842800003, "closer": 5.5666199158500005, "split": 6.9418452120600005, "forc": 1.32399299475, "are": 12.35887122936, "solut": 9.4556283502, "poor": 2.42196796339, "better": 10.032861476250002, "dug": 31.3754940711, "approach": 2.07556543339, "preprocess": 1221.23076923, "look": 5.725895647979999, "popular": 1.50769230769, "bag": 15.8601398601, "combin": 16.9760479042, "numpi": 1221.23076923, "root": 3.57809330629, "transactionamt": 3663.6923076900002, "exclud": 5.31859296482, "want": 3.99396226416, "reddata": 2442.46153846, "forest": 19.58186864016, "gain": 1.84819557625, "focus": 2.01012914662, "train": 7.7462795803999995, "remov": 6.017435249520001, "wrong": 5.478260869570001, "even": 1.16461267606, "littl": 1.5499365420299998, "give": 1.3653250774, "vote": 21.0079395085, "their": 5.07739542025, "clearer": 66.7058823529, "matplotlibpyplot": 1221.23076923, "step": 2.8279301745599996, "befor": 2.20072082062, "investig": 3.11721971333, "lead": 1.2664326739, "randomforestclassifi": 1221.23076923, "handson": 1221.23076923, "probabl": 10.58223629396, "scientist": 9.38852749852, "procedur": 5.8691312384500005, "reproduc": 12.6805111821, "rapid": 2.62586834271, "interlud": 74.5352112676, "figur": 2.0343413634, "traintestsplit": 1221.23076923, "dubious": 37.006993007, "what": 5.01373756512, "let": 17.43083003955, "prone": 54.432, "overfit": 2442.46153846, "interpret": 3.2150668286799995, "help": 1.39962972759, "main": 1.25303867403, "decisiontreeclassifi": 1221.23076923, "cover": 1.69380134429, "republicans\u2013far": 1221.23076923, "least": 1.6165359943000002, "base": 5.73140794225, "relat": 2.47501753838, "deal": 2.18346857379, "who": 1.06279287723, "decid": 1.9257641921400002, "recipi": 10.0481012658, "post": 4.47652615254, "here": 7.26923076924, "dispos": 10.4378698225, "averag": 36.45464982782, "through": 3.21224792607, "dataquest": 1221.23076923, "much": 2.3884459154599997, "make": 12.915192190320003, "greater": 2.14801785956, "fundament": 5.32930513595, "about": 3.19458045477, "problem": 3.53349655018, "scikitlearn": 1221.23076923, "way": 3.6572218383, "silver": 4.89697717458, "just": 1.33580143037, "tabl": 7.64187725632, "duplic": 19.7955112219, "adapt": 3.32272917539, "correct": 10.989386248259999, "simpli": 5.0384005077800005, "than": 6.196721311499999, "classifi": 10.5875291764, "them": 4.39504463976, "check": 13.0131147541, "size": 2.49387370405, "contribut": 7.7021224984800005, "contrast": 2.88339992735, "where": 1.06715063521, "ensembl": 619.632911391, "complex": 7.0206367924499995, "practic": 1.70434782609, "start": 1.26673581744, "noth": 3.46410648047, "leftmost": 360.818181818, "democrat": 49.4579439252, "whi": 13.026461538480001, "singl": 1.60948905109, "ipythondisplay": 1221.23076923, "expand": 2.2260235558000003, "tnum": 115.8832116789, "usual": 1.72508964468, "abl": 1.8208510150200001, "mani": 2.08853515754, "refer": 1.30024570025, "over": 1.02525024217, "increas": 3.9607484407499998, "build": 9.805043746800001, "ytrain": 1221.23076923, "regist": 3.9620663838300003, "error": 30.20547945205, "select": 2.02345144022, "team": 4.5496489468400005, "transactiontp": 1221.23076923, "earli": 1.12468121281, "same": 1.11857958148, "sklearnensembl": 1221.23076923, "there": 6.24547600314, "valu": 2.2777618364400003, "entitytp": 1221.23076923, "ytest": 1221.23076923, "found": 2.2277415281, "best": 3.1657028913200005, "origin": 1.13724928367, "right": 4.21635977337, "trade": 2.37522441652, "given": 1.35426085473, "illustr": 7.3228782287800005, "slight": 3.25327868852, "take": 2.27923336444, "visual": 5.22752716497, "previous": 1.42846859816, "now": 1.160780873, "further": 1.3618116315, "code": 3.8807137619199996, "hard": 2.73253012048, "guess": 25.0410094637, "high": 4.5910931174, "basic": 10.92072227, "play": 2.92780082988, "power": 1.3396337861799998, "mathstat": 2442.46153846, "fix": 4.4346368715099995, "surpris": 4.36633663366, "seed": 10.4173228346, "member": 1.32068879461, "xtrainslim": 1221.23076923, "around": 1.21394708671, "observ": 28.91803278689, "recal": 15.91844919786, "notic": 4.36994219653, "exampl": 9.02900473932, "major": 6.89112348984, "research": 1.9420183486200002, "sklearntre": 1221.23076923, "overwhelm": 6.86381322957, "incorrect": 23.2105263158, "therefor": 2.33401940606, "the": 88.0, "may": 1.05201775893, "becom": 1.12492028626, "candid": 4.51279135873, "transact": 35.676404494500005, "polit": 3.53703909992, "machin": 12.073003802279999, "amount": 2.27027027027, "captur": 2.88026124819, "into": 2.03004922958, "bullet": 16.2997946612, "candstatus": 1221.23076923, "themselv": 2.05967825636, "bootstrap": 264.6, "share": 7.4264998246000005, "win": 2.75290445639, "def": 163.67010309280002, "maxim": 12.928338762200001, "which": 8.04153476, "like": 6.8951140065, "such": 2.12302754748, "matplotlib": 1221.23076923, "other": 4.03969465648, "introduct": 2.7808723068799996, "three": 1.06621893889, "appli": 4.5944147012, "one": 7.04392470054, "graph": 75.4204275534, "idiosyncrat": 77.443902439, "known": 3.25772913816, "drawback": 49.9245283019, "divers": 3.97197898424, "becaus": 3.4485554992499994, "imag": 2.70137825421, "cutoff": 107.27027027, "get": 7.1425036554, "still": 3.5599073174399996, "random": 35.9510869565, "implement": 3.57648118946, "abov": 7.61530159492, "imagin": 13.197007481300002, "alon": 2.99716820842, "tell": 3.36142282448, "process": 1.69524826482, "put": 1.65806788512, "includ": 1.0190641247799999, "precis": 15.966476701320001, "rule": 15.673979815739997, "next": 1.4950560316400001, "below": 4.51215006394, "howev": 1.0945191313299998, "sampl": 7.23280182232, "should": 1.6643254009900001, "ifthen": 1221.23076923, "engin": 4.94271481942, "similar": 4.12542226071, "trivial": 106.0757238306, "differ": 4.946179609, "leaf": 40.759948652199995, "whop": 882.0, "first": 4.03046458492, "most": 6.12578778138, "between": 1.03453668708, "low": 2.13072070863, "return": 4.185972930209999, "all": 6.06880733946, "hottest": 44.1, "reason": 1.72340425532, "someth": 3.28152128979, "regardless": 6.35294117647, "almost": 1.53584212054, "case": 1.48498737256, "exportgraphviz": 1221.23076923, "ben": 14.36092265944, "that": 16.06374502, "weight": 9.757836508919999, "candofficest": 1221.23076923, "cycl": 5.40919931857, "off": 3.0242880274400004, "more": 9.154536135299999, "improv": 2.04376930999, "pitfal": 178.38202247200002, "these": 1.07415426252, "prepar": 2.43012398592, "pursuit": 29.418159357630003, "general": 2.2436404748400003, "made": 4.28155339804, "could": 1.2043695949, "candoffic": 1221.23076923, "schemat": 99.225, "comment": 3.05954904606, "state": 2.0954266481799997, "standard": 1.8915763135900003, "can": 12.93887530562, "topic": 10.915091096600001, "candptyaffili": 1221.23076923, "set": 9.49663526248, "kaggl": 1221.23076923, "favor": 3.1332149200700004, "onli": 1.0256476516600002, "each": 4.75899280576, "pick": 4.939639079030001, "this": 13.049317147230001, "depth": 8.24299065421, "unfamiliar": 37.7102137767, "two": 7.09655172415, "common": 1.4025974025999999, "while": 3.1325966850899993, "data": 47.27009783076, "oper": 1.55479384977, "method": 2.5714285714300003, "perfect": 4.48601299802, "registri": 29.4545454545, "overal": 3.0442953020099996, "inplacetru": 1221.23076923, "must": 1.9220338983099996, "might": 6.468559011270001, "time": 1.01127460348, "inde": 8.86184761374, "understand": 8.90575916229, "machineri": 15.12, "import": 17.422589903810003, "decis": 69.12, "everi": 2.95835274388, "leav": 3.3230769230799995, "input": 12.2029208301, "when": 5.10383848775, "generat": 4.10550814584, "score": 42.884927066500005, "republican": 63.656776263, "measli": 1221.23076923, "often": 1.29452054795, "within": 1.2369302688, "learn": 9.2910021946, "pipelin": 64.2753036438, "effici": 5.09335899904, "vast": 4.05620848237}, "logtfidf": {"affili": 1.8001086638400001, "xtrain": 7.1076144564399995, "equival": 1.40897338129, "axisnum": 7.1076144564399995, "too": 1.1931103094439999, "fit": 3.6453618806699994, "label": 10.49291829089, "rocaucscor": 14.215228912879999, "new": 0.0354598937022, "suppos": 2.88450602954, "panda": 4.7167367562999996, "wikipedia": 3.70130197411, "function": 0.914465741594, "class": 4.498633139598001, "plenti": 2.8569238238300003, "draw": 1.0893956335600001, "learner": 12.962117041290002, "python": 4.03065674296, "entri": 1.38402935449, "well": 0.2540577532624, "uncorrel": 6.27136643224, "whether": 1.583122379294, "tree": 53.875445734500005, "boost": 2.2149545241900004, "wieder": 6.340359303730001, "toy": 10.93323947144, "higher": 0.752308398995, "yield": 5.60126756589, "know": 1.905839388796, "irrelev": 3.3940423897400005, "pydotplus": 21.322843369319997, "abbrevi": 2.51171790724, "uncertain": 2.3850031735900004, "stack": 2.97800175538, "measur": 0.880014199726, "creat": 0.445153637028, "how": 3.7725356554400005, "test": 2.931673311309, "had": 0.0464780244111, "deeper": 8.13949590531, "would": 0.5573233957529, "distribut": 1.00781305813, "end": 0.304430395854, "mayb": 3.0471714458899997, "correl": 7.737477564090001, "word": 0.585861082385, "pip": 4.91038987911, "interest": 0.47207177798199995, "tutori": 4.0853151555, "simplest": 3.3339697356999998, "will": 1.0139326745750001, "true": 3.753302518536, "exploit": 1.7568506145200002, "consid": 0.429789447648, "work": 0.654207403638, "see": 1.445529512952, "sklearnmetr": 14.215228912879999, "second": 0.32141929014, "strength": 1.3931203261899998, "horizon": 2.89719772297, "donat": 17.894944626, "fulldata": 14.215228912879999, "claim": 0.84658246385, "perform": 2.1309042528999997, "but": 0.1781160927909, "certain": 0.592104362781, "need": 0.725480326884, "our": 13.722227426912001, "classif": 4.17558147258, "final": 0.878201591844, "expect": 2.36552325648, "parti": 0.724497710444, "xtestslim": 7.1076144564399995, "scheme": 1.64672046975, "level": 0.503462189943, "has": 0.0427239448548, "have": 0.1330650210708, "plt": 7.1076144564399995, "use": 0.3212882170476, "govern": 0.411720459754, "script": 2.1161358444599996, "out": 0.2337055636772, "model": 24.335852412663, "good": 1.2557682147209999, "alway": 0.726319204572, "disciplin": 1.93582013145, "concept": 0.977224437103, "structur": 0.7217716751350001, "under": 0.15052361076639997, "cours": 1.531798808266, "pnum": 9.82341730876, "short": 0.345685625679, "print": 1.19307248967, "not": 0.0777620650375, "fivethirtyeight": 7.1076144564399995, "altern": 0.760359972282, "flennerhag": 7.1076144564399995, "quick": 0.790727508899, "easi": 1.6665296351499999, "width": 2.85036642328, "metric": 3.1016808515599994, "sklearnmodelselect": 7.1076144564399995, "said": 0.436653165815, "soft": 4.344068657019999, "then": 0.08303386523089999, "xtest": 7.1076144564399995, "they": 0.1189079790704, "design": 0.377239118022, "anoth": 0.127896361652, "scientif": 1.42377308021, "instal": 2.6632611758, "turn": 0.324899251064, "choos": 1.43007066072, "scienc": 0.841436178891, "rpttp": 7.1076144564399995, "exposit": 3.01326989422, "node": 3.7920308275, "featur": 3.387099345136, "resid": 0.8732037307230001, "donor": 3.2412327319700003, "simpl": 2.4464425787799997, "appear": 0.278735898493, "itself": 0.5570837229510001, "provid": 0.19517784432500002, "array": 4.63384542186, "accord": 0.243650319127, "moreov": 2.02287119019, "pattern": 2.66564809576, "signific": 0.373571744332, "inlin": 4.609968780880001, "sever": 0.13982224079379998, "those": 0.17854939087299998, "upon": 0.47207177798199995, "with": 0.0119749171339, "politician": 1.55256998618, "meta": 5.01860346375, "fast": 1.5836950247400001, "some": 0.1978675453225, "sourc": 1.058436621502, "drop": 1.7999070212439998, "both": 0.050842533389300004, "baselin": 8.11158543248, "result": 0.136378908381, "subset": 6.6156261140999995, "varianc": 3.9392225370099996, "less": 0.3846144626, "helper": 4.37424644735, "caus": 0.325858567406, "ani": 0.251216716732, "question": 0.790310929014, "virtual": 1.4141413514399999, "fed": 5.0578924224, "and": 0.0024566155404803997, "from": 0.004536433350928, "dive": 2.7778937744700003, "num": 0.021734337282393004, "sebastian": 3.2890571790200003, "instanc": 2.36178715944, "dfcandptyaffili": 7.1076144564399995, "idea": 0.73863592212, "free": 0.5412666492670001, "for": 0.005039846326352001, "predict": 69.12108998298, "remark": 1.34847005245, "closer": 1.7167880323700002, "split": 2.48884087864, "forc": 0.280652166524, "are": 0.35360968299240003, "solut": 3.10692595254, "poor": 0.8845804177050001, "better": 3.482139703, "dug": 3.4460271446199995, "approach": 0.7302336145810001, "preprocess": 7.1076144564399995, "look": 1.9391600808, "popular": 0.41058020877499996, "bag": 2.76380903459, "combin": 5.2921831075100005, "numpi": 7.1076144564399995, "root": 1.27483006252, "transactionamt": 21.322843369319997, "exclud": 1.67120878808, "want": 1.3832732125099998, "reddata": 14.215228912879999, "forest": 6.3532388304, "gain": 0.6142097989249999, "focus": 0.6981989720559999, "train": 2.643673251356, "remov": 2.0881465247640003, "wrong": 1.70078769102, "even": 0.152388564834, "littl": 0.438213989466, "give": 0.311392552224, "vote": 7.69293202335, "their": 0.07680252561350001, "clearer": 4.20029314023, "matplotlibpyplot": 7.1076144564399995, "step": 1.03954505698, "befor": 0.191275543759, "investig": 1.13694148702, "lead": 0.23620402986699998, "randomforestclassifi": 7.1076144564399995, "handson": 7.1076144564399995, "probabl": 3.891529651652, "scientist": 3.09268256888, "procedur": 1.76970662262, "reproduc": 2.54006626224, "rapid": 0.965411638564, "interlud": 4.31127164819, "figur": 0.7101721121600001, "traintestsplit": 7.1076144564399995, "dubious": 3.61110689497, "what": 0.903549187308, "let": 6.2440128364, "prone": 8.69501978265, "overfit": 14.215228912879999, "interpret": 1.1678481440000001, "help": 0.336207721344, "main": 0.225571540588, "decisiontreeclassifi": 7.1076144564399995, "cover": 0.526975319156, "republicans\u2013far": 7.1076144564399995, "least": 0.480285584745, "base": 0.6826165114350001, "relat": 0.42620060330799997, "deal": 0.780914701253, "who": 0.0609002329859, "decid": 0.655322871893, "recipi": 2.30738368788, "post": 1.6114003054019999, "here": 2.6551145651100003, "dispos": 2.34544052164, "averag": 13.39816363193, "through": 0.20507607565469999, "dataquest": 7.1076144564399995, "much": 0.35499145860200004, "make": 0.8819718938747999, "greater": 0.764545491118, "fundament": 1.67322086119, "about": 0.18853043242380002, "problem": 1.138281448546, "scikitlearn": 7.1076144564399995, "way": 0.5942745298050001, "silver": 1.5886181116100002, "just": 0.289531434109, "tabl": 2.68099221322, "duplic": 2.98545520604, "adapt": 1.2007864860200002, "correct": 3.8949528954300003, "simpli": 1.847882983172, "than": 0.1935651733092, "classifi": 3.3330592702999997, "them": 0.3767333076372, "check": 3.74562099124, "size": 0.9138372060609999, "contribut": 2.620806315636, "contrast": 1.0589701282, "where": 0.0649921387457, "ensembl": 104.27374453105, "complex": 2.5507249092929998, "practic": 0.533182530867, "start": 0.236443369291, "noth": 1.24245472939, "leftmost": 5.8883741799800005, "democrat": 16.99459249176, "whi": 4.72275372188, "singl": 0.475916769059, "ipythondisplay": 7.1076144564399995, "expand": 0.80021683492, "tnum": 10.96191179823, "usual": 0.545279017064, "abl": 0.599303982475, "mani": 0.0866315162442, "refer": 0.262553246798, "over": 0.0249367214957, "increas": 0.833462156787, "build": 2.9468247125460003, "ytrain": 7.1076144564399995, "regist": 1.3767657032700003, "error": 8.9929271715, "select": 0.704804687133, "team": 1.643805789772, "transactiontp": 7.1076144564399995, "earli": 0.117499629108, "same": 0.112059649604, "sklearnensembl": 7.1076144564399995, "there": 0.24058735755299998, "valu": 0.823193310148, "entitytp": 7.1076144564399995, "ytest": 7.1076144564399995, "found": 0.215682248096, "best": 0.918455865894, "origin": 0.128612437587, "right": 1.02107956251, "trade": 0.865091924188, "given": 0.303255810831, "illustr": 2.5957125415599998, "slight": 1.17966331506, "take": 0.261383924394, "visual": 1.6539383488600001, "previous": 0.356602960063, "now": 0.149092945021, "further": 0.308815895297, "code": 1.35601909597, "hard": 1.00522796406, "guess": 3.22051485947, "high": 0.5512951461600001, "basic": 4.0174709958, "play": 0.7622087812839999, "power": 0.292396282715, "mathstat": 14.215228912879999, "fix": 1.48944573451, "surpris": 1.47392435861, "seed": 2.3434700776599997, "member": 0.278153414599, "xtrainslim": 7.1076144564399995, "around": 0.19387710578200001, "observ": 10.393708194116002, "recal": 5.00659942443, "notic": 1.47474978168, "exampl": 2.4520960499939997, "major": 0.830847980634, "research": 0.663727818138, "sklearntre": 7.1076144564399995, "overwhelm": 1.92626315167, "incorrect": 4.90291743144, "therefor": 0.847591848336, "the": 0.0, "may": 0.050709995284400004, "becom": 0.11771217648900001, "candid": 1.50691588861, "transact": 7.427631729210001, "polit": 1.140285568292, "machin": 4.17707874186, "amount": 0.819898886199, "captur": 1.0578810012100002, "into": 0.0298257264574, "bullet": 2.7911525102599994, "candstatus": 7.1076144564399995, "themselv": 0.7225497843690001, "bootstrap": 5.57821925168, "share": 2.475041198988, "win": 1.01265652029, "def": 8.80941130968, "maxim": 2.5594217052, "which": 0.04142731076344, "like": 0.83432145927, "such": 0.119391955612, "matplotlib": 7.1076144564399995, "other": 0.03949899167904, "introduct": 1.02276465794, "three": 0.06411868822490001, "appli": 1.6633883796239999, "one": 0.0437874615185, "graph": 7.259861960439999, "idiosyncrat": 4.34955383476, "known": 0.2472542417976, "drawback": 3.91051243112, "divers": 1.37926445519, "becaus": 0.418029476475, "imag": 0.99376210729, "cutoff": 4.67535154014, "get": 2.319076023128, "still": 0.5133666642870001, "random": 9.86360703255, "implement": 1.27437940907, "abov": 2.575460919264, "imagin": 3.77368583474, "alon": 1.09766791236, "tell": 1.21236434401, "process": 0.527829199025, "put": 0.505652999854, "includ": 0.0188846813905, "precis": 5.01563708817, "rule": 4.992996811833, "next": 0.402163685499, "below": 1.627253183872, "howev": 0.0903151173475, "sampl": 1.9786264883900002, "should": 0.509419876758, "ifthen": 7.1076144564399995, "engin": 1.809535116552, "similar": 0.9556682763419999, "trivial": 10.69662277848, "differ": 0.849284485248, "leaf": 6.029105536059999, "whop": 6.7821920560099995, "first": 0.030349159248639998, "most": 0.12448737777359999, "between": 0.033953681165299995, "low": 0.7564602833490001, "return": 0.9993806057760001, "all": 0.06841579258679999, "hottest": 3.78645978245, "reason": 0.544301552962, "someth": 1.18830712273, "regardless": 1.8489178830700002, "almost": 0.42907884333400004, "case": 0.395406268889, "exportgraphviz": 7.1076144564399995, "ben": 3.9427272661000003, "that": 0.06361837407424, "weight": 3.16984705224, "candofficest": 7.1076144564399995, "cycl": 1.68810108164, "off": 0.8270570407760001, "more": 0.15322438439999997, "improv": 0.7147958039319999, "pitfal": 5.18392744417, "these": 0.0715336194008, "prepar": 0.8879422790620001, "pursuit": 6.84899958069, "general": 0.229905156126, "made": 0.2720861043892, "could": 0.18595627229000003, "candoffic": 7.1076144564399995, "schemat": 4.59738999867, "comment": 1.11826753454, "state": 0.0932200055336, "standard": 0.63741050982, "can": 1.7857520603339998, "topic": 3.3939983108200003, "candptyaffili": 7.1076144564399995, "set": 1.371968090312, "kaggl": 7.1076144564399995, "favor": 1.1420596084299999, "onli": 0.025324268329099998, "each": 0.694966757216, "pick": 1.59729226761, "this": 0.0492238376825, "depth": 2.10936322154, "unfamiliar": 3.6299309802199997, "two": 0.09589191050740001, "common": 0.338325805271, "while": 0.12974995138140002, "data": 17.0354881872, "oper": 0.441342964347, "method": 0.944461608841, "perfect": 1.50096433356, "registri": 3.38284824299, "overal": 1.1132694464700001, "inplacetru": 7.1076144564399995, "must": 0.653383947388, "might": 2.3050232296020003, "time": 0.0112115188626, "inde": 2.9772161932, "understand": 3.264257627039999, "machineri": 2.71601837075, "import": 3.806637601858, "decis": 24.643463094271997, "everi": 0.782970854842, "leav": 1.015487914458, "input": 2.50167533539, "when": 0.102774944292, "generat": 1.438364683472, "score": 14.559353207700003, "republican": 18.509206876599997, "measli": 7.1076144564399995, "often": 0.258140393351, "within": 0.21263272059799998, "learn": 3.37100825898, "pipelin": 6.94005659344, "effici": 1.62793753414, "vast": 1.40024866595}, "logidf": {"affili": 1.8001086638400001, "xtrain": 7.1076144564399995, "equival": 1.40897338129, "axisnum": 7.1076144564399995, "too": 0.5965551547219999, "fit": 1.2151206268899999, "label": 1.49898832727, "rocaucscor": 7.1076144564399995, "new": 0.0177299468511, "suppos": 1.44225301477, "panda": 4.7167367562999996, "wikipedia": 3.70130197411, "function": 0.914465741594, "class": 0.7497721899330001, "plenti": 2.8569238238300003, "draw": 1.0893956335600001, "learner": 4.320705680430001, "python": 4.03065674296, "entri": 1.38402935449, "well": 0.0635144383156, "uncorrel": 6.27136643224, "whether": 0.791561189647, "tree": 1.41777488775, "boost": 2.2149545241900004, "wieder": 6.340359303730001, "toy": 2.73330986786, "higher": 0.752308398995, "yield": 1.86708918863, "know": 0.952919694398, "irrelev": 3.3940423897400005, "pydotplus": 7.1076144564399995, "abbrevi": 2.51171790724, "uncertain": 2.3850031735900004, "stack": 2.97800175538, "measur": 0.880014199726, "creat": 0.222576818514, "how": 0.47156695693000006, "test": 0.977224437103, "had": 0.0464780244111, "deeper": 2.7131653017699997, "would": 0.0796176279647, "distribut": 1.00781305813, "end": 0.101476798618, "mayb": 3.0471714458899997, "correl": 2.57915918803, "word": 0.585861082385, "pip": 4.91038987911, "interest": 0.47207177798199995, "tutori": 4.0853151555, "simplest": 3.3339697356999998, "will": 0.202786534915, "true": 0.938325629634, "exploit": 1.7568506145200002, "consid": 0.214894723824, "work": 0.109034567273, "see": 0.240921585492, "sklearnmetr": 7.1076144564399995, "second": 0.10713976337999999, "strength": 1.3931203261899998, "horizon": 2.89719772297, "donat": 1.7894944626, "fulldata": 7.1076144564399995, "claim": 0.423291231925, "perform": 0.42618085058, "but": 0.0161923720719, "certain": 0.592104362781, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "final": 0.292733863948, "expect": 0.78850775216, "parti": 0.724497710444, "xtestslim": 7.1076144564399995, "scheme": 1.64672046975, "level": 0.503462189943, "has": 0.0427239448548, "have": 0.0147850023412, "plt": 7.1076144564399995, "use": 0.0292080197316, "govern": 0.411720459754, "script": 2.1161358444599996, "out": 0.0584263909193, "model": 0.7374500731110001, "good": 0.418589404907, "alway": 0.726319204572, "disciplin": 1.93582013145, "concept": 0.977224437103, "structur": 0.7217716751350001, "under": 0.07526180538319999, "cours": 0.765899404133, "pnum": 2.45585432719, "short": 0.345685625679, "print": 1.19307248967, "not": 0.0155524130075, "fivethirtyeight": 7.1076144564399995, "altern": 0.760359972282, "flennerhag": 7.1076144564399995, "quick": 0.790727508899, "easi": 1.6665296351499999, "width": 2.85036642328, "metric": 3.1016808515599994, "sklearnmodelselect": 7.1076144564399995, "said": 0.436653165815, "soft": 2.1720343285099997, "then": 0.08303386523089999, "xtest": 7.1076144564399995, "they": 0.0297269947676, "design": 0.377239118022, "anoth": 0.127896361652, "scientif": 1.42377308021, "instal": 1.3316305879, "turn": 0.324899251064, "choos": 1.43007066072, "scienc": 0.841436178891, "rpttp": 7.1076144564399995, "exposit": 3.01326989422, "node": 3.7920308275, "featur": 0.423387418142, "resid": 0.8732037307230001, "donor": 3.2412327319700003, "simpl": 1.2232212893899999, "appear": 0.278735898493, "itself": 0.5570837229510001, "provid": 0.19517784432500002, "array": 2.31692271093, "accord": 0.243650319127, "moreov": 2.02287119019, "pattern": 1.33282404788, "signific": 0.373571744332, "inlin": 4.609968780880001, "sever": 0.06991112039689999, "those": 0.17854939087299998, "upon": 0.47207177798199995, "with": 0.00119749171339, "politician": 1.55256998618, "meta": 5.01860346375, "fast": 1.5836950247400001, "some": 0.0395735090645, "sourc": 0.529218310751, "drop": 0.8999535106219999, "both": 0.050842533389300004, "baselin": 4.05579271624, "result": 0.136378908381, "subset": 3.3078130570499997, "varianc": 3.9392225370099996, "less": 0.3846144626, "helper": 4.37424644735, "caus": 0.325858567406, "ani": 0.125608358366, "question": 0.790310929014, "virtual": 1.4141413514399999, "fed": 2.5289462112, "and": 6.29901420636e-05, "from": 0.000567054168866, "dive": 2.7778937744700003, "num": 0.00031499039539700004, "sebastian": 3.2890571790200003, "instanc": 1.18089357972, "dfcandptyaffili": 7.1076144564399995, "idea": 0.73863592212, "free": 0.5412666492670001, "for": 0.00031499039539700004, "predict": 1.6457402376899999, "remark": 1.34847005245, "closer": 1.7167880323700002, "split": 1.24442043932, "forc": 0.280652166524, "are": 0.0294674735827, "solut": 1.55346297627, "poor": 0.8845804177050001, "better": 0.6964279406, "dug": 3.4460271446199995, "approach": 0.7302336145810001, "preprocess": 7.1076144564399995, "look": 0.6463866936, "popular": 0.41058020877499996, "bag": 2.76380903459, "combin": 0.529218310751, "numpi": 7.1076144564399995, "root": 1.27483006252, "transactionamt": 7.1076144564399995, "exclud": 1.67120878808, "want": 0.6916366062549999, "reddata": 7.1076144564399995, "forest": 1.5883097076, "gain": 0.6142097989249999, "focus": 0.6981989720559999, "train": 0.660918312839, "remov": 0.6960488415880001, "wrong": 1.70078769102, "even": 0.152388564834, "littl": 0.438213989466, "give": 0.311392552224, "vote": 1.09899028905, "their": 0.015360505122700001, "clearer": 4.20029314023, "matplotlibpyplot": 7.1076144564399995, "step": 1.03954505698, "befor": 0.0956377718795, "investig": 1.13694148702, "lead": 0.23620402986699998, "randomforestclassifi": 7.1076144564399995, "handson": 7.1076144564399995, "probabl": 0.972882412913, "scientist": 1.54634128444, "procedur": 1.76970662262, "reproduc": 2.54006626224, "rapid": 0.965411638564, "interlud": 4.31127164819, "figur": 0.7101721121600001, "traintestsplit": 7.1076144564399995, "dubious": 3.61110689497, "what": 0.225887296827, "let": 1.2488025672799998, "prone": 2.89833992755, "overfit": 7.1076144564399995, "interpret": 1.1678481440000001, "help": 0.336207721344, "main": 0.225571540588, "decisiontreeclassifi": 7.1076144564399995, "cover": 0.526975319156, "republicans\u2013far": 7.1076144564399995, "least": 0.480285584745, "base": 0.13652330228700002, "relat": 0.21310030165399999, "deal": 0.780914701253, "who": 0.0609002329859, "decid": 0.655322871893, "recipi": 2.30738368788, "post": 0.8057001527009999, "here": 0.8850381883700001, "dispos": 2.34544052164, "averag": 0.957011687995, "through": 0.0683586918849, "dataquest": 7.1076144564399995, "much": 0.17749572930100002, "make": 0.07349765782289999, "greater": 0.764545491118, "fundament": 1.67322086119, "about": 0.0628434774746, "problem": 0.569140724273, "scikitlearn": 7.1076144564399995, "way": 0.19809150993500002, "silver": 1.5886181116100002, "just": 0.289531434109, "tabl": 1.34049610661, "duplic": 2.98545520604, "adapt": 1.2007864860200002, "correct": 1.29831763181, "simpli": 0.923941491586, "than": 0.0322608622182, "classifi": 1.6665296351499999, "them": 0.0941833269093, "check": 1.87281049562, "size": 0.9138372060609999, "contribut": 0.655201578909, "contrast": 1.0589701282, "where": 0.0649921387457, "ensembl": 2.81820931165, "complex": 0.8502416364309999, "practic": 0.533182530867, "start": 0.236443369291, "noth": 1.24245472939, "leftmost": 5.8883741799800005, "democrat": 1.41621604098, "whi": 1.18068843047, "singl": 0.475916769059, "ipythondisplay": 7.1076144564399995, "expand": 0.80021683492, "tnum": 3.65397059941, "usual": 0.545279017064, "abl": 0.599303982475, "mani": 0.0433157581221, "refer": 0.262553246798, "over": 0.0249367214957, "increas": 0.277820718929, "build": 0.491137452091, "ytrain": 7.1076144564399995, "regist": 1.3767657032700003, "error": 1.7985854343, "select": 0.704804687133, "team": 0.821902894886, "transactiontp": 7.1076144564399995, "earli": 0.117499629108, "same": 0.112059649604, "sklearnensembl": 7.1076144564399995, "there": 0.0400978929255, "valu": 0.823193310148, "entitytp": 7.1076144564399995, "ytest": 7.1076144564399995, "found": 0.107841124048, "best": 0.459227932947, "origin": 0.128612437587, "right": 0.34035985417, "trade": 0.865091924188, "given": 0.303255810831, "illustr": 1.2978562707799999, "slight": 1.17966331506, "take": 0.130691962197, "visual": 1.6539383488600001, "previous": 0.356602960063, "now": 0.149092945021, "further": 0.308815895297, "code": 1.35601909597, "hard": 1.00522796406, "guess": 3.22051485947, "high": 0.13782378654000002, "basic": 1.00436774895, "play": 0.38110439064199997, "power": 0.292396282715, "mathstat": 7.1076144564399995, "fix": 1.48944573451, "surpris": 1.47392435861, "seed": 2.3434700776599997, "member": 0.278153414599, "xtrainslim": 7.1076144564399995, "around": 0.19387710578200001, "observ": 0.7995160149320001, "recal": 1.6688664748100002, "notic": 1.47474978168, "exampl": 0.40868267499899996, "major": 0.138474663439, "research": 0.663727818138, "sklearntre": 7.1076144564399995, "overwhelm": 1.92626315167, "incorrect": 2.45145871572, "therefor": 0.847591848336, "the": 0.0, "may": 0.050709995284400004, "becom": 0.11771217648900001, "candid": 1.50691588861, "transact": 2.4758772430700002, "polit": 0.570142784146, "machin": 1.39235958062, "amount": 0.819898886199, "captur": 1.0578810012100002, "into": 0.0149128632287, "bullet": 2.7911525102599994, "candstatus": 7.1076144564399995, "themselv": 0.7225497843690001, "bootstrap": 5.57821925168, "share": 0.618760299747, "win": 1.01265652029, "def": 4.40470565484, "maxim": 2.5594217052, "which": 0.00517841384543, "like": 0.139053576545, "such": 0.059695977806, "matplotlib": 7.1076144564399995, "other": 0.00987474791976, "introduct": 1.02276465794, "three": 0.06411868822490001, "appli": 0.8316941898119999, "one": 0.0062553516455, "graph": 3.6299309802199997, "idiosyncrat": 4.34955383476, "known": 0.0824180805992, "drawback": 3.91051243112, "divers": 1.37926445519, "becaus": 0.139343158825, "imag": 0.99376210729, "cutoff": 4.67535154014, "get": 0.579769005782, "still": 0.17112222142900002, "random": 1.9727214065099998, "implement": 1.27437940907, "abov": 0.643865229816, "imagin": 1.88684291737, "alon": 1.09766791236, "tell": 1.21236434401, "process": 0.527829199025, "put": 0.505652999854, "includ": 0.0188846813905, "precis": 1.67187902939, "rule": 0.554777423537, "next": 0.402163685499, "below": 0.813626591936, "howev": 0.0903151173475, "sampl": 1.9786264883900002, "should": 0.509419876758, "ifthen": 7.1076144564399995, "engin": 0.904767558276, "similar": 0.318556092114, "trivial": 3.56554092616, "differ": 0.212321121312, "leaf": 3.0145527680299997, "whop": 6.7821920560099995, "first": 0.0075872898121599995, "most": 0.020747896295599998, "between": 0.033953681165299995, "low": 0.7564602833490001, "return": 0.333126868592, "all": 0.011402632097799998, "hottest": 3.78645978245, "reason": 0.544301552962, "someth": 1.18830712273, "regardless": 1.8489178830700002, "almost": 0.42907884333400004, "case": 0.395406268889, "exportgraphviz": 7.1076144564399995, "ben": 1.9713636330500002, "that": 0.00397614837964, "weight": 1.58492352612, "candofficest": 7.1076144564399995, "cycl": 1.68810108164, "off": 0.41352852038800003, "more": 0.017024931599999998, "improv": 0.7147958039319999, "pitfal": 5.18392744417, "these": 0.0715336194008, "prepar": 0.8879422790620001, "pursuit": 2.28299986023, "general": 0.114952578063, "made": 0.0680215260973, "could": 0.18595627229000003, "candoffic": 7.1076144564399995, "schemat": 4.59738999867, "comment": 1.11826753454, "state": 0.0466100027668, "standard": 0.63741050982, "can": 0.162341096394, "topic": 1.6969991554100001, "candptyaffili": 7.1076144564399995, "set": 0.171496011289, "kaggl": 7.1076144564399995, "favor": 1.1420596084299999, "onli": 0.025324268329099998, "each": 0.173741689304, "pick": 1.59729226761, "this": 0.0037864490525, "depth": 2.10936322154, "unfamiliar": 3.6299309802199997, "two": 0.0136988443582, "common": 0.338325805271, "while": 0.04324998379380001, "data": 1.2168205848, "oper": 0.441342964347, "method": 0.944461608841, "perfect": 1.50096433356, "registri": 3.38284824299, "overal": 1.1132694464700001, "inplacetru": 7.1076144564399995, "must": 0.653383947388, "might": 0.7683410765340001, "time": 0.0112115188626, "inde": 1.4886080966, "understand": 1.0880858756799998, "machineri": 2.71601837075, "import": 0.292818277066, "decis": 0.7701082216959999, "everi": 0.391485427421, "leav": 0.507743957229, "input": 2.50167533539, "when": 0.0205549888584, "generat": 0.719182341736, "score": 1.4559353207700003, "republican": 1.8509206876599997, "measli": 7.1076144564399995, "often": 0.258140393351, "within": 0.21263272059799998, "learn": 0.842752064745, "pipelin": 3.47002829672, "effici": 1.62793753414, "vast": 1.40024866595}, "freq": {"affili": 1, "xtrain": 1, "equival": 1, "axisnum": 1, "too": 2, "fit": 3, "label": 7, "rocaucscor": 2, "new": 2, "suppos": 2, "panda": 1, "wikipedia": 1, "function": 1, "class": 6, "plenti": 1, "draw": 1, "learner": 3, "python": 1, "entri": 1, "well": 4, "uncorrel": 1, "whether": 2, "tree": 38, "boost": 1, "wieder": 1, "toy": 4, "higher": 1, "yield": 3, "know": 2, "irrelev": 1, "pydotplus": 3, "abbrevi": 1, "uncertain": 1, "stack": 1, "measur": 1, "creat": 2, "how": 8, "test": 3, "had": 1, "deeper": 3, "would": 7, "distribut": 1, "end": 3, "mayb": 1, "correl": 3, "word": 1, "pip": 1, "interest": 1, "tutori": 1, "simplest": 1, "will": 5, "true": 4, "exploit": 1, "consid": 2, "work": 6, "see": 6, "sklearnmetr": 2, "second": 3, "strength": 1, "horizon": 1, "donat": 10, "fulldata": 2, "claim": 2, "perform": 5, "but": 11, "certain": 1, "need": 2, "our": 16, "classif": 2, "final": 3, "expect": 3, "parti": 1, "xtestslim": 1, "scheme": 1, "level": 1, "has": 1, "have": 9, "plt": 1, "use": 11, "govern": 1, "script": 1, "out": 4, "model": 33, "good": 3, "alway": 1, "disciplin": 1, "concept": 1, "structur": 1, "under": 2, "cours": 2, "pnum": 4, "short": 1, "print": 1, "not": 5, "fivethirtyeight": 1, "altern": 1, "flennerhag": 1, "quick": 1, "easi": 1, "width": 1, "metric": 1, "sklearnmodelselect": 1, "said": 1, "soft": 2, "then": 1, "xtest": 1, "they": 4, "design": 1, "anoth": 1, "scientif": 1, "instal": 2, "turn": 1, "choos": 1, "scienc": 1, "rpttp": 1, "exposit": 1, "node": 1, "featur": 8, "resid": 1, "donor": 1, "simpl": 2, "appear": 1, "itself": 1, "provid": 1, "array": 2, "accord": 1, "moreov": 1, "pattern": 2, "signific": 1, "inlin": 1, "sever": 2, "those": 1, "upon": 1, "with": 10, "politician": 1, "meta": 1, "fast": 1, "some": 5, "sourc": 2, "drop": 2, "both": 1, "baselin": 2, "result": 1, "subset": 2, "varianc": 1, "less": 1, "helper": 1, "caus": 1, "ani": 2, "question": 1, "virtual": 1, "fed": 2, "and": 39, "from": 8, "dive": 1, "num": 69, "sebastian": 1, "instanc": 2, "dfcandptyaffili": 1, "idea": 1, "free": 1, "for": 16, "predict": 42, "remark": 1, "closer": 1, "split": 2, "forc": 1, "are": 12, "solut": 2, "poor": 1, "better": 5, "dug": 1, "approach": 1, "preprocess": 1, "look": 3, "popular": 1, "bag": 1, "combin": 10, "numpi": 1, "root": 1, "transactionamt": 3, "exclud": 1, "want": 2, "reddata": 2, "forest": 4, "gain": 1, "focus": 1, "train": 4, "remov": 3, "wrong": 1, "even": 1, "littl": 1, "give": 1, "vote": 7, "their": 5, "clearer": 1, "matplotlibpyplot": 1, "step": 1, "befor": 2, "investig": 1, "lead": 1, "randomforestclassifi": 1, "handson": 1, "probabl": 4, "scientist": 2, "procedur": 1, "reproduc": 1, "rapid": 1, "interlud": 1, "figur": 1, "traintestsplit": 1, "dubious": 1, "what": 4, "let": 5, "prone": 3, "overfit": 2, "interpret": 1, "help": 1, "main": 1, "decisiontreeclassifi": 1, "cover": 1, "republicans\u2013far": 1, "least": 1, "base": 5, "relat": 2, "deal": 1, "who": 1, "decid": 1, "recipi": 1, "post": 2, "here": 3, "dispos": 1, "averag": 14, "through": 3, "dataquest": 1, "much": 2, "make": 12, "greater": 1, "fundament": 1, "about": 3, "problem": 2, "scikitlearn": 1, "way": 3, "silver": 1, "just": 1, "tabl": 2, "duplic": 1, "adapt": 1, "correct": 3, "simpli": 2, "than": 6, "classifi": 2, "them": 4, "check": 2, "size": 1, "contribut": 4, "contrast": 1, "where": 1, "ensembl": 37, "complex": 3, "practic": 1, "start": 1, "noth": 1, "leftmost": 1, "democrat": 12, "whi": 4, "singl": 1, "ipythondisplay": 1, "expand": 1, "tnum": 3, "usual": 1, "abl": 1, "mani": 2, "refer": 1, "over": 1, "increas": 3, "build": 6, "ytrain": 1, "regist": 1, "error": 5, "select": 1, "team": 2, "transactiontp": 1, "earli": 1, "same": 1, "sklearnensembl": 1, "there": 6, "valu": 1, "entitytp": 1, "ytest": 1, "found": 2, "best": 2, "origin": 1, "right": 3, "trade": 1, "given": 1, "illustr": 2, "slight": 1, "take": 2, "visual": 1, "previous": 1, "now": 1, "further": 1, "code": 1, "hard": 1, "guess": 1, "high": 4, "basic": 4, "play": 2, "power": 1, "mathstat": 2, "fix": 1, "surpris": 1, "seed": 1, "member": 1, "xtrainslim": 1, "around": 1, "observ": 13, "recal": 3, "notic": 1, "exampl": 6, "major": 6, "research": 1, "sklearntre": 1, "overwhelm": 1, "incorrect": 2, "therefor": 1, "the": 88, "may": 1, "becom": 1, "candid": 1, "transact": 3, "polit": 2, "machin": 3, "amount": 1, "captur": 1, "into": 2, "bullet": 1, "candstatus": 1, "themselv": 1, "bootstrap": 1, "share": 4, "win": 1, "def": 2, "maxim": 1, "which": 8, "like": 6, "such": 2, "matplotlib": 1, "other": 4, "introduct": 1, "three": 1, "appli": 2, "one": 7, "graph": 2, "idiosyncrat": 1, "known": 3, "drawback": 1, "divers": 1, "becaus": 3, "imag": 1, "cutoff": 1, "get": 4, "still": 3, "random": 5, "implement": 1, "abov": 4, "imagin": 2, "alon": 1, "tell": 1, "process": 1, "put": 1, "includ": 1, "precis": 3, "rule": 9, "next": 1, "below": 2, "howev": 1, "sampl": 1, "should": 1, "ifthen": 1, "engin": 2, "similar": 3, "trivial": 3, "differ": 4, "leaf": 2, "whop": 1, "first": 4, "most": 6, "between": 1, "low": 1, "return": 3, "all": 6, "hottest": 1, "reason": 1, "someth": 1, "regardless": 1, "almost": 1, "case": 1, "exportgraphviz": 1, "ben": 2, "that": 16, "weight": 2, "candofficest": 1, "cycl": 1, "off": 2, "more": 9, "improv": 1, "pitfal": 1, "these": 1, "prepar": 1, "pursuit": 3, "general": 2, "made": 4, "could": 1, "candoffic": 1, "schemat": 1, "comment": 1, "state": 2, "standard": 1, "can": 11, "topic": 2, "candptyaffili": 1, "set": 8, "kaggl": 1, "favor": 1, "onli": 1, "each": 4, "pick": 1, "this": 13, "depth": 1, "unfamiliar": 1, "two": 7, "common": 1, "while": 3, "data": 14, "oper": 1, "method": 1, "perfect": 1, "registri": 1, "overal": 1, "inplacetru": 1, "must": 1, "might": 3, "time": 1, "inde": 2, "understand": 3, "machineri": 1, "import": 13, "decis": 32, "everi": 2, "leav": 2, "input": 1, "when": 5, "generat": 2, "score": 10, "republican": 10, "measli": 1, "often": 1, "within": 1, "learn": 4, "pipelin": 2, "effici": 1, "vast": 1}, "idf": {"affili": 6.0503048780499995, "xtrain": 1221.23076923, "equival": 4.09175257732, "axisnum": 1221.23076923, "too": 1.81585268215, "fit": 3.37070063694, "label": 4.47715736041, "rocaucscor": 1221.23076923, "new": 1.0178880554, "suppos": 4.23021582734, "panda": 111.802816901, "wikipedia": 40.5, "function": 2.495441685, "class": 2.11651779763, "plenti": 17.4078947368, "draw": 2.97247706422, "learner": 75.2417061611, "python": 56.2978723404, "entri": 3.9909502262400003, "well": 1.0655748708, "uncorrel": 529.2, "whether": 2.20683903253, "tree": 4.127925117, "boost": 9.16099249856, "wieder": 567.0, "toy": 15.383720930199999, "higher": 2.1218925421, "yield": 6.46943765281, "know": 2.59327017315, "irrelev": 29.7861163227, "pydotplus": 1221.23076923, "abbrevi": 12.326086956500001, "uncertain": 10.8590971272, "stack": 19.6485148515, "measur": 2.41093394077, "creat": 1.2492917847, "how": 1.60250328051, "test": 2.65707112971, "had": 1.0475750577399998, "deeper": 15.0769230769, "would": 1.0828729281799998, "distribut": 2.7396031061299997, "end": 1.10680423871, "mayb": 21.0557029178, "correl": 13.1860465116, "word": 1.7965372864099998, "pip": 135.692307692, "interest": 1.60331246213, "tutori": 59.4606741573, "simplest": 28.0494699647, "will": 1.22481098596, "true": 2.55569864778, "exploit": 5.79416058394, "consid": 1.2397313759200002, "work": 1.11520089913, "see": 1.27242125511, "sklearnmetr": 1221.23076923, "second": 1.1130898128, "strength": 4.02739726027, "horizon": 18.1232876712, "donat": 5.986425339369999, "fulldata": 1221.23076923, "claim": 1.52697893623, "perform": 1.5313977042500002, "but": 1.01632417899, "certain": 1.8077886586200003, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "final": 1.34008609775, "expect": 2.20011086475, "parti": 2.06369426752, "xtestslim": 1221.23076923, "scheme": 5.18993135011, "level": 1.6544393497299998, "has": 1.0436497502, "have": 1.0148948411399998, "plt": 1221.23076923, "use": 1.0296387573799999, "govern": 1.50941243582, "script": 8.299006795610001, "out": 1.06016694491, "model": 2.0905978404, "good": 1.51981619759, "alway": 2.06745670009, "disciplin": 6.92972501091, "concept": 2.65707112971, "structur": 2.0580762250499998, "under": 1.0781663837, "cours": 2.15092805853, "pnum": 11.6563876652, "short": 1.41295834817, "print": 3.29719626168, "not": 1.01567398119, "fivethirtyeight": 1221.23076923, "altern": 2.1390460792200003, "flennerhag": 1221.23076923, "quick": 2.205, "easi": 5.2937645882, "width": 17.294117647100002, "metric": 22.235294117600002, "sklearnmodelselect": 1221.23076923, "said": 1.54751925139, "soft": 8.776119402989998, "then": 1.08657860516, "xtest": 1221.23076923, "they": 1.03017325287, "design": 1.45825296225, "anoth": 1.13643521832, "scientif": 4.15275961287, "instal": 3.78721374046, "turn": 1.3838912133899999, "choos": 4.17899447223, "scienc": 2.31969608416, "rpttp": 1221.23076923, "exposit": 20.353846153800003, "node": 44.3463687151, "featur": 1.52712581762, "resid": 2.39457013575, "donor": 25.565217391300003, "simpl": 3.3981164383599998, "appear": 1.3214582986499999, "itself": 1.74557449148, "provid": 1.21552714187, "array": 10.1444089457, "accord": 1.27589809531, "moreov": 7.56, "pattern": 3.79173632673, "signific": 1.4529147982100001, "inlin": 100.481012658, "sever": 1.07241286139, "those": 1.19548192771, "upon": 1.60331246213, "with": 1.0011982089899998, "politician": 4.7235941684, "meta": 151.2, "fast": 4.8729281768, "some": 1.04036697248, "sourc": 1.69760479042, "drop": 2.4594887684, "both": 1.05215720061, "baselin": 57.7309090909, "result": 1.14611608432, "subset": 27.3253012048, "varianc": 51.3786407767, "less": 1.46904783936, "helper": 79.38, "caus": 1.38521943984, "ani": 1.13383802314, "question": 2.20408163265, "virtual": 4.11295336788, "fed": 12.5402843602, "and": 1.00006299213, "from": 1.00056721497, "dive": 16.085106383, "num": 1.00031504001, "sebastian": 26.8175675676, "instanc": 3.2572835453400004, "dfcandptyaffili": 1221.23076923, "idea": 2.0930784443, "free": 1.71818181818, "for": 1.00031504001, "predict": 5.18484650555, "remark": 3.8515283842800003, "closer": 5.5666199158500005, "split": 3.4709226060300002, "forc": 1.32399299475, "are": 1.02990593578, "solut": 4.7278141751, "poor": 2.42196796339, "better": 2.0065722952500002, "dug": 31.3754940711, "approach": 2.07556543339, "preprocess": 1221.23076923, "look": 1.9086318826599997, "popular": 1.50769230769, "bag": 15.8601398601, "combin": 1.69760479042, "numpi": 1221.23076923, "root": 3.57809330629, "transactionamt": 1221.23076923, "exclud": 5.31859296482, "want": 1.99698113208, "reddata": 1221.23076923, "forest": 4.89546716004, "gain": 1.84819557625, "focus": 2.01012914662, "train": 1.9365698950999999, "remov": 2.0058117498400003, "wrong": 5.478260869570001, "even": 1.16461267606, "littl": 1.5499365420299998, "give": 1.3653250774, "vote": 3.0011342155, "their": 1.01547908405, "clearer": 66.7058823529, "matplotlibpyplot": 1221.23076923, "step": 2.8279301745599996, "befor": 1.10036041031, "investig": 3.11721971333, "lead": 1.2664326739, "randomforestclassifi": 1221.23076923, "handson": 1221.23076923, "probabl": 2.64555907349, "scientist": 4.69426374926, "procedur": 5.8691312384500005, "reproduc": 12.6805111821, "rapid": 2.62586834271, "interlud": 74.5352112676, "figur": 2.0343413634, "traintestsplit": 1221.23076923, "dubious": 37.006993007, "what": 1.25343439128, "let": 3.48616600791, "prone": 18.144000000000002, "overfit": 1221.23076923, "interpret": 3.2150668286799995, "help": 1.39962972759, "main": 1.25303867403, "decisiontreeclassifi": 1221.23076923, "cover": 1.69380134429, "republicans\u2013far": 1221.23076923, "least": 1.6165359943000002, "base": 1.14628158845, "relat": 1.23750876919, "deal": 2.18346857379, "who": 1.06279287723, "decid": 1.9257641921400002, "recipi": 10.0481012658, "post": 2.23826307627, "here": 2.42307692308, "dispos": 10.4378698225, "averag": 2.60390355913, "through": 1.07074930869, "dataquest": 1221.23076923, "much": 1.1942229577299999, "make": 1.0762660158600001, "greater": 2.14801785956, "fundament": 5.32930513595, "about": 1.06486015159, "problem": 1.76674827509, "scikitlearn": 1221.23076923, "way": 1.2190739461, "silver": 4.89697717458, "just": 1.33580143037, "tabl": 3.82093862816, "duplic": 19.7955112219, "adapt": 3.32272917539, "correct": 3.6631287494199998, "simpli": 2.5192002538900002, "than": 1.03278688525, "classifi": 5.2937645882, "them": 1.09876115994, "check": 6.50655737705, "size": 2.49387370405, "contribut": 1.9255306246200001, "contrast": 2.88339992735, "where": 1.06715063521, "ensembl": 16.746835443, "complex": 2.34021226415, "practic": 1.70434782609, "start": 1.26673581744, "noth": 3.46410648047, "leftmost": 360.818181818, "democrat": 4.1214953271, "whi": 3.2566153846200003, "singl": 1.60948905109, "ipythondisplay": 1221.23076923, "expand": 2.2260235558000003, "tnum": 38.6277372263, "usual": 1.72508964468, "abl": 1.8208510150200001, "mani": 1.04426757877, "refer": 1.30024570025, "over": 1.02525024217, "increas": 1.32024948025, "build": 1.6341739578, "ytrain": 1221.23076923, "regist": 3.9620663838300003, "error": 6.04109589041, "select": 2.02345144022, "team": 2.2748244734200003, "transactiontp": 1221.23076923, "earli": 1.12468121281, "same": 1.11857958148, "sklearnensembl": 1221.23076923, "there": 1.04091266719, "valu": 2.2777618364400003, "entitytp": 1221.23076923, "ytest": 1221.23076923, "found": 1.11387076405, "best": 1.5828514456600002, "origin": 1.13724928367, "right": 1.4054532577899999, "trade": 2.37522441652, "given": 1.35426085473, "illustr": 3.6614391143900002, "slight": 3.25327868852, "take": 1.13961668222, "visual": 5.22752716497, "previous": 1.42846859816, "now": 1.160780873, "further": 1.3618116315, "code": 3.8807137619199996, "hard": 2.73253012048, "guess": 25.0410094637, "high": 1.14777327935, "basic": 2.7301805675, "play": 1.46390041494, "power": 1.3396337861799998, "mathstat": 1221.23076923, "fix": 4.4346368715099995, "surpris": 4.36633663366, "seed": 10.4173228346, "member": 1.32068879461, "xtrainslim": 1221.23076923, "around": 1.21394708671, "observ": 2.22446406053, "recal": 5.30614973262, "notic": 4.36994219653, "exampl": 1.50483412322, "major": 1.14852058164, "research": 1.9420183486200002, "sklearntre": 1221.23076923, "overwhelm": 6.86381322957, "incorrect": 11.6052631579, "therefor": 2.33401940606, "the": 1.0, "may": 1.05201775893, "becom": 1.12492028626, "candid": 4.51279135873, "transact": 11.892134831500002, "polit": 1.76851954996, "machin": 4.02433460076, "amount": 2.27027027027, "captur": 2.88026124819, "into": 1.01502461479, "bullet": 16.2997946612, "candstatus": 1221.23076923, "themselv": 2.05967825636, "bootstrap": 264.6, "share": 1.8566249561500001, "win": 2.75290445639, "def": 81.83505154640001, "maxim": 12.928338762200001, "which": 1.005191845, "like": 1.14918566775, "such": 1.06151377374, "matplotlib": 1221.23076923, "other": 1.00992366412, "introduct": 2.7808723068799996, "three": 1.06621893889, "appli": 2.2972073506, "one": 1.00627495722, "graph": 37.7102137767, "idiosyncrat": 77.443902439, "known": 1.0859097127200001, "drawback": 49.9245283019, "divers": 3.97197898424, "becaus": 1.1495184997499999, "imag": 2.70137825421, "cutoff": 107.27027027, "get": 1.78562591385, "still": 1.1866357724799999, "random": 7.1902173913, "implement": 3.57648118946, "abov": 1.90382539873, "imagin": 6.598503740650001, "alon": 2.99716820842, "tell": 3.36142282448, "process": 1.69524826482, "put": 1.65806788512, "includ": 1.0190641247799999, "precis": 5.322158900440001, "rule": 1.7415533128599998, "next": 1.4950560316400001, "below": 2.25607503197, "howev": 1.0945191313299998, "sampl": 7.23280182232, "should": 1.6643254009900001, "ifthen": 1221.23076923, "engin": 2.47135740971, "similar": 1.37514075357, "trivial": 35.3585746102, "differ": 1.23654490225, "leaf": 20.379974326099997, "whop": 882.0, "first": 1.00761614623, "most": 1.02096463023, "between": 1.03453668708, "low": 2.13072070863, "return": 1.39532431007, "all": 1.01146788991, "hottest": 44.1, "reason": 1.72340425532, "someth": 3.28152128979, "regardless": 6.35294117647, "almost": 1.53584212054, "case": 1.48498737256, "exportgraphviz": 1221.23076923, "ben": 7.18046132972, "that": 1.00398406375, "weight": 4.878918254459999, "candofficest": 1221.23076923, "cycl": 5.40919931857, "off": 1.5121440137200002, "more": 1.0171706817, "improv": 2.04376930999, "pitfal": 178.38202247200002, "these": 1.07415426252, "prepar": 2.43012398592, "pursuit": 9.80605311921, "general": 1.1218202374200001, "made": 1.07038834951, "could": 1.2043695949, "candoffic": 1221.23076923, "schemat": 99.225, "comment": 3.05954904606, "state": 1.0477133240899998, "standard": 1.8915763135900003, "can": 1.17626139142, "topic": 5.457545548300001, "candptyaffili": 1221.23076923, "set": 1.18707940781, "kaggl": 1221.23076923, "favor": 3.1332149200700004, "onli": 1.0256476516600002, "each": 1.18974820144, "pick": 4.939639079030001, "this": 1.00379362671, "depth": 8.24299065421, "unfamiliar": 37.7102137767, "two": 1.01379310345, "common": 1.4025974025999999, "while": 1.0441988950299999, "data": 3.37643555934, "oper": 1.55479384977, "method": 2.5714285714300003, "perfect": 4.48601299802, "registri": 29.4545454545, "overal": 3.0442953020099996, "inplacetru": 1221.23076923, "must": 1.9220338983099996, "might": 2.1561863370900003, "time": 1.01127460348, "inde": 4.43092380687, "understand": 2.96858638743, "machineri": 15.12, "import": 1.3401992233700002, "decis": 2.16, "everi": 1.47917637194, "leav": 1.6615384615399997, "input": 12.2029208301, "when": 1.02076769755, "generat": 2.05275407292, "score": 4.2884927066500005, "republican": 6.3656776263, "measli": 1221.23076923, "often": 1.29452054795, "within": 1.2369302688, "learn": 2.32275054865, "pipelin": 32.1376518219, "effici": 5.09335899904, "vast": 4.05620848237}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Introduction to Python Ensembles</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Introduction to Python Ensembles Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/02/top-15-scala-libraries-data-science-2018.html\" rel=\"prev\" title=\"Top 15 Scala Libraries for Data Science in 2018\"/>\n<link href=\"https://www.kdnuggets.com/2018/02/machine-learning-algorithm-2118.html\" rel=\"next\" title=\"Which Machine Learning Algorithm be used in year 2118?\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=77491\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-77491 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 9-Feb, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/02/index.html\">Feb</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/02/tutorials.html\">Tutorials, Overviews</a> \u00bb Introduction to Python Ensembles (\u00a0<a href=\"/2018/n06.html\">18:n06</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Introduction to Python Ensembles</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/02/top-15-scala-libraries-data-science-2018.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/02/machine-learning-algorithm-2118.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/decision-trees\" rel=\"tag\">Decision Trees</a>, <a href=\"https://www.kdnuggets.com/tag/ensemble-methods\" rel=\"tag\">Ensemble Methods</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a>, <a href=\"https://www.kdnuggets.com/tag/python\" rel=\"tag\">Python</a>, <a href=\"https://www.kdnuggets.com/tag/random-forests\" rel=\"tag\">Random Forests</a>, <a href=\"https://www.kdnuggets.com/tag/scikit-learn\" rel=\"tag\">scikit-learn</a>, <a href=\"https://www.kdnuggets.com/tag/xgboost\" rel=\"tag\">XGBoost</a></div>\n<br/>\n<p class=\"excerpt\">\n     In this post, we'll take you through the basics of ensembles \u2014 what they are and why they work so well \u2014 and provide a hands-on tutorial for building basic ensembles.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2018/02/introduction-python-ensembles.html?page=2#comments\">comments</a></div>\n<p><b>By <a href=\"\" rel=\"noopener noreferrer\" target=\"_blank\">Sebastian Flennerhag</a>, Machine Learning Researcher</b></p>\n<h3>Stacking models in Python efficiently</h3>\n<p>\u00a0<br>\nEnsembles have rapidly become one of the hottest and most popular methods in applied machine learning. Virtually\u00a0<a href=\"http://blog.kaggle.com/category/winners-interviews/\" rel=\"noopener noreferrer\" target=\"_blank\">every winning Kaggle solution</a>\u00a0features them, and many data science pipelines have ensembles in them.</br></p>\n<p>Put simply, ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Ensembles give us a performance boost almost for free!</p>\n<p><img alt=\"network\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/network-1.png\" width=\"70%\"><br>\n<em>Example schematics of an ensemble. An input array\u00a0<font size=\"+1\"><b>X</b></font>\u00a0is fed through two preprocessing pipelines and then to a set of base learners\u00a0<font size=\"+1\"><b>f<sup>(i)</sup></b></font>. The ensemble combines all base learner predictions into a final prediction array\u00a0<font size=\"+1\"><b>P</b></font>.\u00a0<a href=\"http://ml-ensemble.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Source</a></em></br></img></p>\n<p>In this post, we'll take you through the basics of ensembles \u2014 what they are and why they work so well \u2014 and provide a hands-on tutorial for building basic ensembles. By the end of this post, you will:</p>\n<ul>\n<li>understand the fundamentals of ensembles\n<li>know how to code them\n<li>understand the main pitfalls and drawbacks of ensembles\n</li></li></li></ul>\n<p>\u00a0</p>\n<h3>Predicting Republican and Democratic donations</h3>\n<p>\u00a0<br>\nTo illustrate how ensembles work, we'll use a data set on U.S. political contributions. The\u00a0<a href=\"https://github.com/fivethirtyeight/data/tree/master/science-giving\" rel=\"noopener noreferrer\" target=\"_blank\">original data set</a>\u00a0was prepared by\u00a0<a href=\"https://fivethirtyeight.com/contributors/ben-wieder/\" rel=\"noopener noreferrer\" target=\"_blank\">Ben Wieder</a>\u00a0at\u00a0<a href=\"https://fivethirtyeight.com/\" rel=\"noopener noreferrer\" target=\"_blank\">FiveThirtyEight</a>, who dug around the U.S. government's political contribution registry and found that when\u00a0<a href=\"https://fivethirtyeight.com/features/when-scientists-donate-to-politicians-its-usually-to-democrats/\" rel=\"noopener noreferrer\" target=\"_blank\">scientists donate to politician, it's usually to Democrats</a>.</br></p>\n<p>This claim is based on the observation on the share of donations being made to Republicans and Democrats. However, there's plenty more that can be said: for instance, which scientific discipline is most likely to make a Republican donation, and which state is most likely to make Democratic donations? We will go one step further and\u00a0<em>predict</em>\u00a0whether a donation is most likely to be a to a Republican or Democrat.</p>\n<p>The\u00a0<a href=\"https://www.dataquest.io/blog/large_files/input.csv\" rel=\"noopener noreferrer\" target=\"_blank\">data</a>\u00a0we use here is slightly adapted. We remove any donations to party affiliations other than Democrat or Republican to make our exposition a little clearer and drop some duplicate and less interesting features. The data script can be found\u00a0<a href=\"https://www.dataquest.io/blog/large_files/gen_data.py\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>. Here's the data:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import numpy as np\r\nimport pandas as pd\r\n\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\n### Import data\r\n# Always good to set a seed for reproducibility\r\nSEED = 222\r\nnp.random.seed(SEED)\r\n\r\ndf = pd.read_csv('input.csv')\r\n\r\n### Training and test set\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import roc_auc_score\r\n\r\ndef get_train_test(test_size=0.95):\r\n    \"\"\"Split Data into train and test sets.\"\"\"\r\n    y = 1 * (df.cand_pty_affiliation == \"REP\")\r\n    X = df.drop([\"cand_pty_affiliation\"], axis=1)\r\n    X = pd.get_dummies(X, sparse=True)\r\n    X.drop(X.columns[X.std() == 0], axis=1, inplace=True)\r\n    return train_test_split(X, y, test_size=test_size, random_state=SEED)\r\n\r\nxtrain, xtest, ytrain, ytest = get_train_test()\r\n\r\n# A look at the data\r\nprint(\"\\nExample data:\")\r\ndf.head()\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<table border=\"1\">\n<thead>\n<tr>\n<th></th>\n<th>cand_pty_affiliation</th>\n<th>cand_office_st</th>\n<th>cand_office</th>\n<th>cand_status</th>\n<th>rpt_tp</th>\n<th>transaction_tp</th>\n<th>entity_tp</th>\n<th>state</th>\n<th>classification</th>\n<th>cycle</th>\n<th>transaction_amt</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>REP</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>Q3</td>\n<td>15</td>\n<td>IND</td>\n<td>NY</td>\n<td>Engineer</td>\n<td>2016.0</td>\n<td>500.0</td>\n</tr>\n<tr>\n<th>1</th>\n<td>DEM</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>M5</td>\n<td>15E</td>\n<td>IND</td>\n<td>OR</td>\n<td>Math-Stat</td>\n<td>2016.0</td>\n<td>50.0</td>\n</tr>\n<tr>\n<th>2</th>\n<td>DEM</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>M3</td>\n<td>15</td>\n<td>IND</td>\n<td>TX</td>\n<td>Scientist</td>\n<td>2008.0</td>\n<td>250.0</td>\n</tr>\n<tr>\n<th>3</th>\n<td>DEM</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>Q2</td>\n<td>15E</td>\n<td>IND</td>\n<td>IN</td>\n<td>Math-Stat</td>\n<td>2016.0</td>\n<td>250.0</td>\n</tr>\n<tr>\n<th>4</th>\n<td>REP</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>12G</td>\n<td>15</td>\n<td>IND</td>\n<td>MA</td>\n<td>Engineer</td>\n<td>2016.0</td>\n<td>184.0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>df.cand_pty_affiliation.value_counts(normalize=True).plot(\r\n    kind=\"bar\", title=\"Share of No. donations\")\r\nplt.show()\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"donations\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_2_0.png\" width=\"60%\"/></p>\n<p>The figure above is the data underlying Ben's claim. Indeed, between Democrats and Republicans, about 75% of all contributions are made to democrats. Let's go through the features at our disposal. We have data about the donor, the transaction, and the recipient:</p>\n<p><img alt=\"features\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/features.svg\" width=\"99%\"/></p>\n<p>To measure how well our models perform, we use the\u00a0<a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\" rel=\"noopener noreferrer\" target=\"_blank\">ROC-AUC</a>\u00a0score, which trades off having high precision and high recall (if these concepts are new to you, see the Wikipedia entry on\u00a0<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\" rel=\"noopener noreferrer\" target=\"_blank\">precision and recall</a>\u00a0for a quick introduction). If you haven't used this metric before, a random guess has a score of 0.5 and perfect recall and precision yields 1.0.</p>\n<p>\u00a0</p>\n<h3>What is an ensemble?</h3>\n<p>\u00a0<br/>\nImagine that you are playing trivial pursuit. When you play alone, there might be some topics you are good at, and some that you know next to nothing about. If we want to maximize our trivial pursuit score, we need build a team to cover all topics. This is the basic idea of an ensemble: combining predictions from several models averages out idiosyncratic errors and yield better overall predictions.</p>\n<p>An important question is how to combine predictions. In our trivial pursuit example, it is easy to imagine that team members might make their case and majority voting decides which to pick. Machine learning is remarkably similar in classification problems: taking the most common class label prediction is equivalent to a majority voting rule. But there are many other ways to combine predictions, and more generally we can use a model to\u00a0<em>learn</em>\u00a0how to best combine predictions.</p>\n<p><img alt=\"ensemble network\" src=\"https://www.dataquest.io/blog/content/images/2018/01/ensemble_network.png\" width=\"99%\"/><br/>\n<em>Basic ensemble structure. Data is fed to a set of models, and a meta learner combine model predictions.\u00a0<a href=\"http://flennerhag.com/2017-04-18-introduction-to-ensembles/\" rel=\"noopener noreferrer\" target=\"_blank\">Source</a></em></p>\n<p>\u00a0</p>\n<h3>Understanding ensembles by combining decision trees</h3>\n<p>\u00a0<br/>\nTo illustrate the machinery of ensembles, we'll start off with a simple interpretable model: a decision tree, which is a tree of\u00a0<code>if-then</code>\u00a0rules. If you're unfamiliar with decision trees or would like to dive deeper, check out the\u00a0<a href=\"https://www.dataquest.io/course/decision-trees\" rel=\"noopener noreferrer\" target=\"_blank\">decision trees course</a>\u00a0on Dataquest. The deeper the tree, the more complex the patterns it can capture, but the more prone to overfitting it will be. Because of this, we will need an alternative way of building complex models of decision trees, and an ensemble of different decision trees is one such way.</p>\n<p>We'll use the below helper function to visualize our decision rules:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import pydotplus  # you can install pydotplus with: pip install pydotplus \r\nfrom IPython.display import Image\r\nfrom sklearn.metrics import roc_auc_score\r\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\r\n\r\ndef print_graph(clf, feature_names):\r\n    \"\"\"Print decision tree.\"\"\"\r\n    graph = export_graphviz(\r\n        clf,\r\n        label=\"root\",\r\n        proportion=True,\r\n        impurity=False, \r\n        out_file=None, \r\n        feature_names=feature_names,\r\n        class_names={0: \"D\", 1: \"R\"},\r\n        filled=True,\r\n        rounded=True\r\n    )\r\n    graph = pydotplus.graph_from_dot_data(graph)  \r\n    return Image(graph.create_png())\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Let's fit a decision tree with a single node (decision rule) on our training data and see how it perform on the test set:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>t1 = DecisionTreeClassifier(max_depth=1, random_state=SEED)\r\nt1.fit(xtrain, ytrain)\r\np = t1.predict_proba(xtest)[:, 1]\r\n\r\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\nprint_graph(t1, xtrain.columns)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"dc1\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_6_1.png\" width=\"50%\"/><br/>\n<em>Decision tree ROC-AUC score: 0.672</em></p>\n<p>Each of the two leaves register their share of training samples, the class distribution within their share, and the class label prediction. Our decision tree bases its prediction on whether the the size of the contribution is above 101.5: but it makes\u00a0<em>the same</em>\u00a0prediction regardless! This is not too surprising given that 75% of all donations are to Democrats. But it's not making use of the data we have. Let's use three levels of decision rules and see what we can get:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>t2 = DecisionTreeClassifier(max_depth=3, random_state=SEED)\r\nt2.fit(xtrain, ytrain)\r\np = t2.predict_proba(xtest)[:, 1]\r\n\r\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\nprint_graph(t2, xtrain.columns)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"dc2\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_8_1.png\" width=\"99%\"/><br/>\n<em>Decision tree ROC-AUC score: 0.751</em></p>\n<p>This model is not much better than the simple decision tree: a measly 5% of all donations are predicted to go to Republicans\u2013far short of the 25% we would expect. A closer look tells us that the decision tree uses some dubious splitting rules. A whopping 47.3% of all observations end up in the left-most leaf, while another 35.9% end up in the leaf second to the right. The vast majority of leaves are therefore irrelevant. Making the model deeper just causes it to overfit.</p>\n<p>Fixing depth, a decision tree can be made more complex by increasing \"width\", that is, creating several decision trees and combining them. In other words, an ensemble of decision trees. To see why such a model would help, consider how we may force a decision tree to investigate other patterns than those in the above tree. The simplest solution is to remove features that appear early in the tree. Suppose for instance that we remove the transaction amount feature (<code>transaction_amt</code>), the root of the tree. Our new decision tree would look like this:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>drop = [\"transaction_amt\"]\r\n\r\nxtrain_slim = xtrain.drop(drop, 1)\r\nxtest_slim = xtest.drop(drop, 1)\r\n\r\nt3 = DecisionTreeClassifier(max_depth=3, random_state=SEED)\r\nt3.fit(xtrain_slim, ytrain)\r\np = t3.predict_proba(xtest_slim)[:, 1]\r\n\r\n\r\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\nprint_graph(t3, xtrain_slim.columns)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"dc3\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_10_1.png\" width=\"99%\"/><br/>\n<em>Decision tree ROC-AUC score: 0.740</em></p>\n<p>The ROC-AUC score is similar, but the share of Republican donation increased to 7.3%. Still too low, but higher than before. Importantly, in contrast to the first tree, where most of the rules related to the transaction itself, this tree is more focused on the residency of the candidate. We now have two models that by themselves have similar predictive power, but operate on different rules. Because of this, they are likely to make different prediction errors, which we can average out with an ensemble.</p>\n<p><b>Interlude: why averaging predictions work</b></p>\n<p>Why would we expect averaging predictions to work? Consider a toy example with two observations that we want to generate predictions for. The true label for the first observation is Republican, and the true label for the second observation is Democrat. In this toy example, suppose model 1 is prone to predicting Democrat while model 2 is prone to predicting Republican, as in the below table:</p>\n<table border=\"1\" cellpadding=\"3\" cellspacing=\"2\" class=\"wc\" width=\"100%\">\n<thead>\n<tr>\n<th>Model</th>\n<th>Observation 1</th>\n<th>Observation 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>True label</td>\n<td>R</td>\n<td>D</td>\n</tr>\n<tr>\n<td>Model prediction:\u00a0<font size=\"+1\"><em>P(R)</em></font></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Model 1</td>\n<td>0.4</td>\n<td>0.2</td>\n</tr>\n<tr>\n<td>Model 2</td>\n<td>0.8</td>\n<td>0.6</td>\n</tr>\n</tbody>\n</table>\n<p><br class=\"blank\"/></p>\n<p>If we use the standard 50% cutoff rule for making a class prediction, each decision tree gets one observation right and one wrong. We create an ensemble by averaging the model's class probabilities, which is a majority vote weighted by the strength (probability) of model's prediction. In our toy example, model 2 is certain of its prediction for observation 1, while model 1 is relatively uncertain. Weighting their predictions, the ensemble favors model 2 and correctly predicts Republican. For the second observation, tables are turned and the ensemble correctly predicts Democrat:</p>\n<table border=\"1\" cellpadding=\"3\" cellspacing=\"2\" class=\"wc\" width=\"100%\">\n<thead>\n<tr>\n<th>Model</th>\n<th>Observation 1</th>\n<th>Observation 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>True label</td>\n<td>R</td>\n<td>D</td>\n</tr>\n<tr>\n<td>Ensemble</td>\n<td>0.6</td>\n<td>0.4</td>\n</tr>\n</tbody>\n</table>\n<p><br class=\"blank\"/></p>\n<p>With more than two decision trees, the ensemble predicts in accordance with the majority. For that reason, an ensemble that averages classifier predictions is known as a\u00a0<strong>majority voting classifier</strong>. When an ensembles averages based on probabilities (as above), we refer to it as\u00a0<strong>soft voting</strong>, averaging final class label predictions is known as\u00a0<strong>hard voting</strong>.</p>\n<p>Of course, ensembles are no silver bullet. You might have noticed in our toy example that for averaging to work, prediction errors must be\u00a0<strong>uncorrelated</strong>. If both models made incorrect predictions, the ensemble would not be able to make any corrections. Moreover, in the soft voting scheme, if one model makes an incorrect prediction with a high probability value, the ensemble would be overwhelmed. Generally, ensembles don't get every observation right, but in expectation it will do better than the underlying models.</p>\n<p><b>A forest is an ensemble of trees</b></p>\n<p>Returning to our prediction problem, let's see if we can build an ensemble out of our two decision trees. We first check error correlation: highly correlated errors makes for poor ensembles.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>p1 = t2.predict_proba(xtest)[:, 1]\r\np2 = t3.predict_proba(xtest_slim)[:, 1]\r\n\r\npd.DataFrame({\"full_data\": p1,\r\n              \"red_data\": p2}).corr()\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<table border=\"1\" cellpadding=\"3\" cellspacing=\"2\" class=\"wc\" width=\"60%\">\n<thead>\n<tr>\n<th></th>\n<th>full_data</th>\n<th>red_data</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>full_data</th>\n<td>1.000000</td>\n<td>0.669128</td>\n</tr>\n<tr>\n<th>red_data</th>\n<td>0.669128</td>\n<td>1.000000</td>\n</tr>\n</tbody>\n</table>\n<p><br class=\"blank\"/></p>\n<p>There is some correlation, but not overly so: there's still a good deal of prediction variance to exploit. To build our first ensemble, we simply average the two model's predictions.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>p1 = t2.predict_proba(xtest)[:, 1]\r\np2 = t3.predict_proba(xtest_slim)[:, 1]\r\np = np.mean([p1, p2], axis=0)\r\nprint(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><em>Average of decision tree ROC-AUC score: 0.783</em></p>\n<p>Indeed, the ensemble procedure leads to an increased score. But maybe if we had more diverse trees, we could get an even greater gain. How should we choose which features to exclude when designing the decision trees?</p>\n<p>A fast approach that works well in practice is to randomly select a subset of features, fit one decision tree on each draw and average their predictions. This process is known as\u00a0<strong>bootstrapped averaging</strong>\u00a0(often abbreviated\u00a0<em>bagging</em>), and when applied to decision trees, the resultant model is a\u00a0<strong>Random Forest</strong>. Let's see what a random forest can do for us. We use the\u00a0<a href=\"http://scikit-learn.org/stable/modules/ensemble.html#forest\" rel=\"noopener noreferrer\" target=\"_blank\">Scikit-learn</a> implementation and build an ensemble of 10 decision trees, each fitted on a subset of 3 features.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>from sklearn.ensemble import RandomForestClassifier\r\n\r\nrf = RandomForestClassifier(\r\n    n_estimators=10,\r\n    max_features=3,\r\n    random_state=SEED\r\n)\r\n\r\nrf.fit(xtrain, ytrain)\r\np = rf.predict_proba(xtest)[:, 1]\r\nprint(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><em>Average of decision tree ROC-AUC score: 0.844</em></p>\n<p>The Random Forest yields a significant improvement upon our previous models. We're on to something! But there is only so much you can do with decision trees. It's time we expand our horizon.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/02/top-15-scala-libraries-data-science-2018.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/02/machine-learning-algorithm-2118.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/02/index.html\">Feb</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/02/tutorials.html\">Tutorials, Overviews</a> \u00bb Introduction to Python Ensembles (\u00a0<a href=\"/2018/n06.html\">18:n06</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556367937\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.717 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 08:25:37 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "sebastian", "flennerhag", "machin", "learn", "research", "stack", "model", "python", "effici", "ensembl", "have", "rapid", "becom", "one", "the", "hottest", "and", "most", "popular", "method", "appli", "machin", "learn", "virtual", "everi", "win", "kaggl", "solut", "featur", "them", "and", "mani", "data", "scienc", "pipelin", "have", "ensembl", "them", "put", "simpli", "ensembl", "combin", "predict", "from", "differ", "model", "generat", "final", "predict", "and", "the", "more", "model", "includ", "the", "better", "perform", "better", "still", "becaus", "ensembl", "combin", "baselin", "predict", "they", "perform", "least", "well", "the", "best", "baselin", "model", "ensembl", "give", "perform", "boost", "almost", "for", "free", "exampl", "schemat", "ensembl", "input", "array", "fed", "through", "two", "preprocess", "pipelin", "and", "then", "set", "base", "learner", "the", "ensembl", "combin", "all", "base", "learner", "predict", "into", "final", "predict", "array", "sourc", "this", "post", "take", "through", "the", "basic", "ensembl", "what", "they", "are", "and", "whi", "they", "work", "well", "and", "provid", "handson", "tutori", "for", "build", "basic", "ensembl", "the", "end", "this", "post", "will", "understand", "the", "fundament", "ensembl", "know", "how", "code", "them", "understand", "the", "main", "pitfal", "and", "drawback", "ensembl", "predict", "republican", "and", "democrat", "donat", "illustr", "how", "ensembl", "work", "use", "data", "set", "polit", "contribut", "the", "origin", "data", "set", "prepar", "ben", "wieder", "fivethirtyeight", "who", "dug", "around", "the", "govern", "polit", "contribut", "registri", "and", "found", "that", "when", "scientist", "donat", "politician", "usual", "democrat", "this", "claim", "base", "the", "observ", "the", "share", "donat", "made", "republican", "and", "democrat", "howev", "there", "plenti", "more", "that", "can", "said", "for", "instanc", "which", "scientif", "disciplin", "most", "like", "make", "republican", "donat", "and", "which", "state", "most", "like", "make", "democrat", "donat", "will", "one", "step", "further", "and", "predict", "whether", "donat", "most", "like", "republican", "democrat", "the", "data", "use", "here", "slight", "adapt", "remov", "ani", "donat", "parti", "affili", "other", "than", "democrat", "republican", "make", "our", "exposit", "littl", "clearer", "and", "drop", "some", "duplic", "and", "less", "interest", "featur", "the", "data", "script", "can", "found", "here", "here", "the", "data", "import", "numpi", "import", "panda", "import", "matplotlibpyplot", "plt", "matplotlib", "inlin", "import", "data", "alway", "good", "set", "seed", "for", "reproduc", "num", "train", "and", "test", "set", "from", "sklearnmodelselect", "import", "traintestsplit", "from", "sklearnmetr", "import", "rocaucscor", "def", "split", "data", "into", "train", "and", "test", "set", "num", "dfcandptyaffili", "num", "axisnum", "inplacetru", "return", "xtrain", "xtest", "ytrain", "ytest", "look", "the", "data", "candptyaffili", "candofficest", "candoffic", "candstatus", "rpttp", "transactiontp", "entitytp", "state", "classif", "cycl", "transactionamt", "num", "num", "engin", "num", "num", "num", "mathstat", "num", "num", "num", "num", "scientist", "num", "num", "num", "mathstat", "num", "num", "num", "num", "engin", "num", "num", "the", "figur", "abov", "the", "data", "under", "ben", "claim", "inde", "between", "democrat", "and", "republican", "about", "num", "all", "contribut", "are", "made", "democrat", "let", "through", "the", "featur", "our", "dispos", "have", "data", "about", "the", "donor", "the", "transact", "and", "the", "recipi", "measur", "how", "well", "our", "model", "perform", "use", "the", "score", "which", "trade", "off", "have", "high", "precis", "and", "high", "recal", "these", "concept", "are", "new", "see", "the", "wikipedia", "entri", "precis", "and", "recal", "for", "quick", "introduct", "have", "use", "this", "metric", "befor", "random", "guess", "has", "score", "num", "and", "perfect", "recal", "and", "precis", "yield", "num", "what", "ensembl", "imagin", "that", "are", "play", "trivial", "pursuit", "when", "play", "alon", "there", "might", "some", "topic", "are", "good", "and", "some", "that", "know", "next", "noth", "about", "want", "maxim", "our", "trivial", "pursuit", "score", "need", "build", "team", "cover", "all", "topic", "this", "the", "basic", "idea", "ensembl", "combin", "predict", "from", "sever", "model", "averag", "out", "idiosyncrat", "error", "and", "yield", "better", "overal", "predict", "import", "question", "how", "combin", "predict", "our", "trivial", "pursuit", "exampl", "easi", "imagin", "that", "team", "member", "might", "make", "their", "case", "and", "major", "vote", "decid", "which", "pick", "machin", "learn", "remark", "similar", "classif", "problem", "take", "the", "most", "common", "class", "label", "predict", "equival", "major", "vote", "rule", "but", "there", "are", "mani", "other", "way", "combin", "predict", "and", "more", "general", "can", "use", "model", "learn", "how", "best", "combin", "predict", "basic", "ensembl", "structur", "data", "fed", "set", "model", "and", "meta", "learner", "combin", "model", "predict", "sourc", "understand", "ensembl", "combin", "decis", "tree", "illustr", "the", "machineri", "ensembl", "start", "off", "with", "simpl", "interpret", "model", "decis", "tree", "which", "tree", "ifthen", "rule", "unfamiliar", "with", "decis", "tree", "would", "like", "dive", "deeper", "check", "out", "the", "decis", "tree", "cours", "dataquest", "the", "deeper", "the", "tree", "the", "more", "complex", "the", "pattern", "can", "captur", "but", "the", "more", "prone", "overfit", "will", "becaus", "this", "will", "need", "altern", "way", "build", "complex", "model", "decis", "tree", "and", "ensembl", "differ", "decis", "tree", "one", "such", "way", "use", "the", "below", "helper", "function", "visual", "our", "decis", "rule", "import", "pydotplus", "can", "instal", "pydotplus", "with", "pip", "instal", "pydotplus", "from", "ipythondisplay", "import", "imag", "from", "sklearnmetr", "import", "rocaucscor", "from", "sklearntre", "import", "decisiontreeclassifi", "exportgraphviz", "def", "print", "decis", "tree", "graph", "graph", "return", "let", "fit", "decis", "tree", "with", "singl", "node", "decis", "rule", "our", "train", "data", "and", "see", "how", "perform", "the", "test", "set", "tnum", "num", "decis", "tree", "score", "num", "each", "the", "two", "leav", "regist", "their", "share", "train", "sampl", "the", "class", "distribut", "within", "their", "share", "and", "the", "class", "label", "predict", "our", "decis", "tree", "base", "predict", "whether", "the", "the", "size", "the", "contribut", "abov", "num", "but", "make", "the", "same", "predict", "regardless", "this", "not", "too", "surpris", "given", "that", "num", "all", "donat", "are", "democrat", "but", "not", "make", "use", "the", "data", "have", "let", "use", "three", "level", "decis", "rule", "and", "see", "what", "can", "get", "tnum", "num", "decis", "tree", "score", "num", "this", "model", "not", "much", "better", "than", "the", "simpl", "decis", "tree", "measli", "num", "all", "donat", "are", "predict", "republicans\u2013far", "short", "the", "num", "would", "expect", "closer", "look", "tell", "that", "the", "decis", "tree", "use", "some", "dubious", "split", "rule", "whop", "num", "all", "observ", "end", "the", "leftmost", "leaf", "while", "anoth", "num", "end", "the", "leaf", "second", "the", "right", "the", "vast", "major", "leav", "are", "therefor", "irrelev", "make", "the", "model", "deeper", "just", "caus", "overfit", "fix", "depth", "decis", "tree", "can", "made", "more", "complex", "increas", "width", "that", "creat", "sever", "decis", "tree", "and", "combin", "them", "other", "word", "ensembl", "decis", "tree", "see", "whi", "such", "model", "would", "help", "consid", "how", "may", "forc", "decis", "tree", "investig", "other", "pattern", "than", "those", "the", "abov", "tree", "the", "simplest", "solut", "remov", "featur", "that", "appear", "earli", "the", "tree", "suppos", "for", "instanc", "that", "remov", "the", "transact", "amount", "featur", "transactionamt", "the", "root", "the", "tree", "our", "new", "decis", "tree", "would", "look", "like", "this", "drop", "transactionamt", "xtrainslim", "xtestslim", "tnum", "num", "decis", "tree", "score", "num", "the", "score", "similar", "but", "the", "share", "republican", "donat", "increas", "num", "still", "too", "low", "but", "higher", "than", "befor", "import", "contrast", "the", "first", "tree", "where", "most", "the", "rule", "relat", "the", "transact", "itself", "this", "tree", "more", "focus", "the", "resid", "the", "candid", "now", "have", "two", "model", "that", "themselv", "have", "similar", "predict", "power", "but", "oper", "differ", "rule", "becaus", "this", "they", "are", "like", "make", "differ", "predict", "error", "which", "can", "averag", "out", "with", "ensembl", "interlud", "whi", "averag", "predict", "work", "whi", "would", "expect", "averag", "predict", "work", "consid", "toy", "exampl", "with", "two", "observ", "that", "want", "generat", "predict", "for", "the", "true", "label", "for", "the", "first", "observ", "republican", "and", "the", "true", "label", "for", "the", "second", "observ", "democrat", "this", "toy", "exampl", "suppos", "model", "num", "prone", "predict", "democrat", "while", "model", "num", "prone", "predict", "republican", "the", "below", "tabl", "model", "observ", "num", "observ", "num", "true", "label", "model", "predict", "model", "num", "num", "num", "model", "num", "num", "num", "use", "the", "standard", "num", "cutoff", "rule", "for", "make", "class", "predict", "each", "decis", "tree", "get", "one", "observ", "right", "and", "one", "wrong", "creat", "ensembl", "averag", "the", "model", "class", "probabl", "which", "major", "vote", "weight", "the", "strength", "probabl", "model", "predict", "our", "toy", "exampl", "model", "num", "certain", "predict", "for", "observ", "num", "while", "model", "num", "relat", "uncertain", "weight", "their", "predict", "the", "ensembl", "favor", "model", "num", "and", "correct", "predict", "republican", "for", "the", "second", "observ", "tabl", "are", "turn", "and", "the", "ensembl", "correct", "predict", "democrat", "model", "observ", "num", "observ", "num", "true", "label", "ensembl", "num", "num", "with", "more", "than", "two", "decis", "tree", "the", "ensembl", "predict", "accord", "with", "the", "major", "for", "that", "reason", "ensembl", "that", "averag", "classifi", "predict", "known", "major", "vote", "classifi", "when", "ensembl", "averag", "base", "probabl", "abov", "refer", "soft", "vote", "averag", "final", "class", "label", "predict", "known", "hard", "vote", "cours", "ensembl", "are", "silver", "bullet", "might", "have", "notic", "our", "toy", "exampl", "that", "for", "averag", "work", "predict", "error", "must", "uncorrel", "both", "model", "made", "incorrect", "predict", "the", "ensembl", "would", "not", "abl", "make", "ani", "correct", "moreov", "the", "soft", "vote", "scheme", "one", "model", "make", "incorrect", "predict", "with", "high", "probabl", "valu", "the", "ensembl", "would", "overwhelm", "general", "ensembl", "get", "everi", "observ", "right", "but", "expect", "will", "better", "than", "the", "under", "model", "forest", "ensembl", "tree", "return", "our", "predict", "problem", "let", "see", "can", "build", "ensembl", "out", "our", "two", "decis", "tree", "first", "check", "error", "correl", "high", "correl", "error", "make", "for", "poor", "ensembl", "pnum", "num", "pnum", "num", "fulldata", "reddata", "fulldata", "num", "num", "reddata", "num", "num", "there", "some", "correl", "but", "not", "over", "there", "still", "good", "deal", "predict", "varianc", "exploit", "build", "our", "first", "ensembl", "simpli", "averag", "the", "two", "model", "predict", "pnum", "num", "pnum", "num", "averag", "decis", "tree", "score", "num", "inde", "the", "ensembl", "procedur", "lead", "increas", "score", "but", "mayb", "had", "more", "divers", "tree", "could", "get", "even", "greater", "gain", "how", "should", "choos", "which", "featur", "exclud", "when", "design", "the", "decis", "tree", "fast", "approach", "that", "work", "well", "practic", "random", "select", "subset", "featur", "fit", "one", "decis", "tree", "each", "draw", "and", "averag", "their", "predict", "this", "process", "known", "bootstrap", "averag", "often", "abbrevi", "bag", "and", "when", "appli", "decis", "tree", "the", "result", "model", "random", "forest", "let", "see", "what", "random", "forest", "can", "for", "use", "the", "scikitlearn", "implement", "and", "build", "ensembl", "num", "decis", "tree", "each", "fit", "subset", "num", "featur", "from", "sklearnensembl", "import", "randomforestclassifi", "num", "averag", "decis", "tree", "score", "num", "the", "random", "forest", "yield", "signific", "improv", "upon", "our", "previous", "model", "someth", "but", "there", "onli", "much", "can", "with", "decis", "tree", "time", "expand", "our", "horizon"], "timestamp_scraper": 1556367938.332518, "title": "Introduction to Python Ensembles", "read_time": 603.0, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2018/02/introduction-python-ensembles.html?page=2#comments\">comments</a></div>\n<p><b>By <a href=\"\" rel=\"noopener noreferrer\" target=\"_blank\">Sebastian Flennerhag</a>, Machine Learning Researcher</b></p>\n<h3>Stacking models in Python efficiently</h3>\n<p>\u00a0<br>\nEnsembles have rapidly become one of the hottest and most popular methods in applied machine learning. Virtually\u00a0<a href=\"http://blog.kaggle.com/category/winners-interviews/\" rel=\"noopener noreferrer\" target=\"_blank\">every winning Kaggle solution</a>\u00a0features them, and many data science pipelines have ensembles in them.</br></p>\n<p>Put simply, ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Ensembles give us a performance boost almost for free!</p>\n<p><img alt=\"network\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/network-1.png\" width=\"70%\"><br>\n<em>Example schematics of an ensemble. An input array\u00a0<font size=\"+1\"><b>X</b></font>\u00a0is fed through two preprocessing pipelines and then to a set of base learners\u00a0<font size=\"+1\"><b>f<sup>(i)</sup></b></font>. The ensemble combines all base learner predictions into a final prediction array\u00a0<font size=\"+1\"><b>P</b></font>.\u00a0<a href=\"http://ml-ensemble.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Source</a></em></br></img></p>\n<p>In this post, we'll take you through the basics of ensembles \u2014 what they are and why they work so well \u2014 and provide a hands-on tutorial for building basic ensembles. By the end of this post, you will:</p>\n<ul>\n<li>understand the fundamentals of ensembles\n<li>know how to code them\n<li>understand the main pitfalls and drawbacks of ensembles\n</li></li></li></ul>\n<p>\u00a0</p>\n<h3>Predicting Republican and Democratic donations</h3>\n<p>\u00a0<br>\nTo illustrate how ensembles work, we'll use a data set on U.S. political contributions. The\u00a0<a href=\"https://github.com/fivethirtyeight/data/tree/master/science-giving\" rel=\"noopener noreferrer\" target=\"_blank\">original data set</a>\u00a0was prepared by\u00a0<a href=\"https://fivethirtyeight.com/contributors/ben-wieder/\" rel=\"noopener noreferrer\" target=\"_blank\">Ben Wieder</a>\u00a0at\u00a0<a href=\"https://fivethirtyeight.com/\" rel=\"noopener noreferrer\" target=\"_blank\">FiveThirtyEight</a>, who dug around the U.S. government's political contribution registry and found that when\u00a0<a href=\"https://fivethirtyeight.com/features/when-scientists-donate-to-politicians-its-usually-to-democrats/\" rel=\"noopener noreferrer\" target=\"_blank\">scientists donate to politician, it's usually to Democrats</a>.</br></p>\n<p>This claim is based on the observation on the share of donations being made to Republicans and Democrats. However, there's plenty more that can be said: for instance, which scientific discipline is most likely to make a Republican donation, and which state is most likely to make Democratic donations? We will go one step further and\u00a0<em>predict</em>\u00a0whether a donation is most likely to be a to a Republican or Democrat.</p>\n<p>The\u00a0<a href=\"https://www.dataquest.io/blog/large_files/input.csv\" rel=\"noopener noreferrer\" target=\"_blank\">data</a>\u00a0we use here is slightly adapted. We remove any donations to party affiliations other than Democrat or Republican to make our exposition a little clearer and drop some duplicate and less interesting features. The data script can be found\u00a0<a href=\"https://www.dataquest.io/blog/large_files/gen_data.py\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>. Here's the data:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import numpy as np\r\nimport pandas as pd\r\n\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\n### Import data\r\n# Always good to set a seed for reproducibility\r\nSEED = 222\r\nnp.random.seed(SEED)\r\n\r\ndf = pd.read_csv('input.csv')\r\n\r\n### Training and test set\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import roc_auc_score\r\n\r\ndef get_train_test(test_size=0.95):\r\n    \"\"\"Split Data into train and test sets.\"\"\"\r\n    y = 1 * (df.cand_pty_affiliation == \"REP\")\r\n    X = df.drop([\"cand_pty_affiliation\"], axis=1)\r\n    X = pd.get_dummies(X, sparse=True)\r\n    X.drop(X.columns[X.std() == 0], axis=1, inplace=True)\r\n    return train_test_split(X, y, test_size=test_size, random_state=SEED)\r\n\r\nxtrain, xtest, ytrain, ytest = get_train_test()\r\n\r\n# A look at the data\r\nprint(\"\\nExample data:\")\r\ndf.head()\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<table border=\"1\">\n<thead>\n<tr>\n<th></th>\n<th>cand_pty_affiliation</th>\n<th>cand_office_st</th>\n<th>cand_office</th>\n<th>cand_status</th>\n<th>rpt_tp</th>\n<th>transaction_tp</th>\n<th>entity_tp</th>\n<th>state</th>\n<th>classification</th>\n<th>cycle</th>\n<th>transaction_amt</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>0</th>\n<td>REP</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>Q3</td>\n<td>15</td>\n<td>IND</td>\n<td>NY</td>\n<td>Engineer</td>\n<td>2016.0</td>\n<td>500.0</td>\n</tr>\n<tr>\n<th>1</th>\n<td>DEM</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>M5</td>\n<td>15E</td>\n<td>IND</td>\n<td>OR</td>\n<td>Math-Stat</td>\n<td>2016.0</td>\n<td>50.0</td>\n</tr>\n<tr>\n<th>2</th>\n<td>DEM</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>M3</td>\n<td>15</td>\n<td>IND</td>\n<td>TX</td>\n<td>Scientist</td>\n<td>2008.0</td>\n<td>250.0</td>\n</tr>\n<tr>\n<th>3</th>\n<td>DEM</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>Q2</td>\n<td>15E</td>\n<td>IND</td>\n<td>IN</td>\n<td>Math-Stat</td>\n<td>2016.0</td>\n<td>250.0</td>\n</tr>\n<tr>\n<th>4</th>\n<td>REP</td>\n<td>US</td>\n<td>P</td>\n<td>C</td>\n<td>12G</td>\n<td>15</td>\n<td>IND</td>\n<td>MA</td>\n<td>Engineer</td>\n<td>2016.0</td>\n<td>184.0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>df.cand_pty_affiliation.value_counts(normalize=True).plot(\r\n    kind=\"bar\", title=\"Share of No. donations\")\r\nplt.show()\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"donations\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_2_0.png\" width=\"60%\"/></p>\n<p>The figure above is the data underlying Ben's claim. Indeed, between Democrats and Republicans, about 75% of all contributions are made to democrats. Let's go through the features at our disposal. We have data about the donor, the transaction, and the recipient:</p>\n<p><img alt=\"features\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/features.svg\" width=\"99%\"/></p>\n<p>To measure how well our models perform, we use the\u00a0<a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\" rel=\"noopener noreferrer\" target=\"_blank\">ROC-AUC</a>\u00a0score, which trades off having high precision and high recall (if these concepts are new to you, see the Wikipedia entry on\u00a0<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\" rel=\"noopener noreferrer\" target=\"_blank\">precision and recall</a>\u00a0for a quick introduction). If you haven't used this metric before, a random guess has a score of 0.5 and perfect recall and precision yields 1.0.</p>\n<p>\u00a0</p>\n<h3>What is an ensemble?</h3>\n<p>\u00a0<br/>\nImagine that you are playing trivial pursuit. When you play alone, there might be some topics you are good at, and some that you know next to nothing about. If we want to maximize our trivial pursuit score, we need build a team to cover all topics. This is the basic idea of an ensemble: combining predictions from several models averages out idiosyncratic errors and yield better overall predictions.</p>\n<p>An important question is how to combine predictions. In our trivial pursuit example, it is easy to imagine that team members might make their case and majority voting decides which to pick. Machine learning is remarkably similar in classification problems: taking the most common class label prediction is equivalent to a majority voting rule. But there are many other ways to combine predictions, and more generally we can use a model to\u00a0<em>learn</em>\u00a0how to best combine predictions.</p>\n<p><img alt=\"ensemble network\" src=\"https://www.dataquest.io/blog/content/images/2018/01/ensemble_network.png\" width=\"99%\"/><br/>\n<em>Basic ensemble structure. Data is fed to a set of models, and a meta learner combine model predictions.\u00a0<a href=\"http://flennerhag.com/2017-04-18-introduction-to-ensembles/\" rel=\"noopener noreferrer\" target=\"_blank\">Source</a></em></p>\n<p>\u00a0</p>\n<h3>Understanding ensembles by combining decision trees</h3>\n<p>\u00a0<br/>\nTo illustrate the machinery of ensembles, we'll start off with a simple interpretable model: a decision tree, which is a tree of\u00a0<code>if-then</code>\u00a0rules. If you're unfamiliar with decision trees or would like to dive deeper, check out the\u00a0<a href=\"https://www.dataquest.io/course/decision-trees\" rel=\"noopener noreferrer\" target=\"_blank\">decision trees course</a>\u00a0on Dataquest. The deeper the tree, the more complex the patterns it can capture, but the more prone to overfitting it will be. Because of this, we will need an alternative way of building complex models of decision trees, and an ensemble of different decision trees is one such way.</p>\n<p>We'll use the below helper function to visualize our decision rules:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import pydotplus  # you can install pydotplus with: pip install pydotplus \r\nfrom IPython.display import Image\r\nfrom sklearn.metrics import roc_auc_score\r\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\r\n\r\ndef print_graph(clf, feature_names):\r\n    \"\"\"Print decision tree.\"\"\"\r\n    graph = export_graphviz(\r\n        clf,\r\n        label=\"root\",\r\n        proportion=True,\r\n        impurity=False, \r\n        out_file=None, \r\n        feature_names=feature_names,\r\n        class_names={0: \"D\", 1: \"R\"},\r\n        filled=True,\r\n        rounded=True\r\n    )\r\n    graph = pydotplus.graph_from_dot_data(graph)  \r\n    return Image(graph.create_png())\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Let's fit a decision tree with a single node (decision rule) on our training data and see how it perform on the test set:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>t1 = DecisionTreeClassifier(max_depth=1, random_state=SEED)\r\nt1.fit(xtrain, ytrain)\r\np = t1.predict_proba(xtest)[:, 1]\r\n\r\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\nprint_graph(t1, xtrain.columns)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"dc1\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_6_1.png\" width=\"50%\"/><br/>\n<em>Decision tree ROC-AUC score: 0.672</em></p>\n<p>Each of the two leaves register their share of training samples, the class distribution within their share, and the class label prediction. Our decision tree bases its prediction on whether the the size of the contribution is above 101.5: but it makes\u00a0<em>the same</em>\u00a0prediction regardless! This is not too surprising given that 75% of all donations are to Democrats. But it's not making use of the data we have. Let's use three levels of decision rules and see what we can get:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>t2 = DecisionTreeClassifier(max_depth=3, random_state=SEED)\r\nt2.fit(xtrain, ytrain)\r\np = t2.predict_proba(xtest)[:, 1]\r\n\r\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\nprint_graph(t2, xtrain.columns)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"dc2\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_8_1.png\" width=\"99%\"/><br/>\n<em>Decision tree ROC-AUC score: 0.751</em></p>\n<p>This model is not much better than the simple decision tree: a measly 5% of all donations are predicted to go to Republicans\u2013far short of the 25% we would expect. A closer look tells us that the decision tree uses some dubious splitting rules. A whopping 47.3% of all observations end up in the left-most leaf, while another 35.9% end up in the leaf second to the right. The vast majority of leaves are therefore irrelevant. Making the model deeper just causes it to overfit.</p>\n<p>Fixing depth, a decision tree can be made more complex by increasing \"width\", that is, creating several decision trees and combining them. In other words, an ensemble of decision trees. To see why such a model would help, consider how we may force a decision tree to investigate other patterns than those in the above tree. The simplest solution is to remove features that appear early in the tree. Suppose for instance that we remove the transaction amount feature (<code>transaction_amt</code>), the root of the tree. Our new decision tree would look like this:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>drop = [\"transaction_amt\"]\r\n\r\nxtrain_slim = xtrain.drop(drop, 1)\r\nxtest_slim = xtest.drop(drop, 1)\r\n\r\nt3 = DecisionTreeClassifier(max_depth=3, random_state=SEED)\r\nt3.fit(xtrain_slim, ytrain)\r\np = t3.predict_proba(xtest_slim)[:, 1]\r\n\r\n\r\nprint(\"Decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\nprint_graph(t3, xtrain_slim.columns)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><img alt=\"dc3\" class=\"aligncenter\" src=\"https://www.dataquest.io/blog/content/images/2018/01/output_10_1.png\" width=\"99%\"/><br/>\n<em>Decision tree ROC-AUC score: 0.740</em></p>\n<p>The ROC-AUC score is similar, but the share of Republican donation increased to 7.3%. Still too low, but higher than before. Importantly, in contrast to the first tree, where most of the rules related to the transaction itself, this tree is more focused on the residency of the candidate. We now have two models that by themselves have similar predictive power, but operate on different rules. Because of this, they are likely to make different prediction errors, which we can average out with an ensemble.</p>\n<p><b>Interlude: why averaging predictions work</b></p>\n<p>Why would we expect averaging predictions to work? Consider a toy example with two observations that we want to generate predictions for. The true label for the first observation is Republican, and the true label for the second observation is Democrat. In this toy example, suppose model 1 is prone to predicting Democrat while model 2 is prone to predicting Republican, as in the below table:</p>\n<table border=\"1\" cellpadding=\"3\" cellspacing=\"2\" class=\"wc\" width=\"100%\">\n<thead>\n<tr>\n<th>Model</th>\n<th>Observation 1</th>\n<th>Observation 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>True label</td>\n<td>R</td>\n<td>D</td>\n</tr>\n<tr>\n<td>Model prediction:\u00a0<font size=\"+1\"><em>P(R)</em></font></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Model 1</td>\n<td>0.4</td>\n<td>0.2</td>\n</tr>\n<tr>\n<td>Model 2</td>\n<td>0.8</td>\n<td>0.6</td>\n</tr>\n</tbody>\n</table>\n<p><br class=\"blank\"/></p>\n<p>If we use the standard 50% cutoff rule for making a class prediction, each decision tree gets one observation right and one wrong. We create an ensemble by averaging the model's class probabilities, which is a majority vote weighted by the strength (probability) of model's prediction. In our toy example, model 2 is certain of its prediction for observation 1, while model 1 is relatively uncertain. Weighting their predictions, the ensemble favors model 2 and correctly predicts Republican. For the second observation, tables are turned and the ensemble correctly predicts Democrat:</p>\n<table border=\"1\" cellpadding=\"3\" cellspacing=\"2\" class=\"wc\" width=\"100%\">\n<thead>\n<tr>\n<th>Model</th>\n<th>Observation 1</th>\n<th>Observation 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>True label</td>\n<td>R</td>\n<td>D</td>\n</tr>\n<tr>\n<td>Ensemble</td>\n<td>0.6</td>\n<td>0.4</td>\n</tr>\n</tbody>\n</table>\n<p><br class=\"blank\"/></p>\n<p>With more than two decision trees, the ensemble predicts in accordance with the majority. For that reason, an ensemble that averages classifier predictions is known as a\u00a0<strong>majority voting classifier</strong>. When an ensembles averages based on probabilities (as above), we refer to it as\u00a0<strong>soft voting</strong>, averaging final class label predictions is known as\u00a0<strong>hard voting</strong>.</p>\n<p>Of course, ensembles are no silver bullet. You might have noticed in our toy example that for averaging to work, prediction errors must be\u00a0<strong>uncorrelated</strong>. If both models made incorrect predictions, the ensemble would not be able to make any corrections. Moreover, in the soft voting scheme, if one model makes an incorrect prediction with a high probability value, the ensemble would be overwhelmed. Generally, ensembles don't get every observation right, but in expectation it will do better than the underlying models.</p>\n<p><b>A forest is an ensemble of trees</b></p>\n<p>Returning to our prediction problem, let's see if we can build an ensemble out of our two decision trees. We first check error correlation: highly correlated errors makes for poor ensembles.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>p1 = t2.predict_proba(xtest)[:, 1]\r\np2 = t3.predict_proba(xtest_slim)[:, 1]\r\n\r\npd.DataFrame({\"full_data\": p1,\r\n              \"red_data\": p2}).corr()\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<table border=\"1\" cellpadding=\"3\" cellspacing=\"2\" class=\"wc\" width=\"60%\">\n<thead>\n<tr>\n<th></th>\n<th>full_data</th>\n<th>red_data</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<th>full_data</th>\n<td>1.000000</td>\n<td>0.669128</td>\n</tr>\n<tr>\n<th>red_data</th>\n<td>0.669128</td>\n<td>1.000000</td>\n</tr>\n</tbody>\n</table>\n<p><br class=\"blank\"/></p>\n<p>There is some correlation, but not overly so: there's still a good deal of prediction variance to exploit. To build our first ensemble, we simply average the two model's predictions.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>p1 = t2.predict_proba(xtest)[:, 1]\r\np2 = t3.predict_proba(xtest_slim)[:, 1]\r\np = np.mean([p1, p2], axis=0)\r\nprint(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><em>Average of decision tree ROC-AUC score: 0.783</em></p>\n<p>Indeed, the ensemble procedure leads to an increased score. But maybe if we had more diverse trees, we could get an even greater gain. How should we choose which features to exclude when designing the decision trees?</p>\n<p>A fast approach that works well in practice is to randomly select a subset of features, fit one decision tree on each draw and average their predictions. This process is known as\u00a0<strong>bootstrapped averaging</strong>\u00a0(often abbreviated\u00a0<em>bagging</em>), and when applied to decision trees, the resultant model is a\u00a0<strong>Random Forest</strong>. Let's see what a random forest can do for us. We use the\u00a0<a href=\"http://scikit-learn.org/stable/modules/ensemble.html#forest\" rel=\"noopener noreferrer\" target=\"_blank\">Scikit-learn</a> implementation and build an ensemble of 10 decision trees, each fitted on a subset of 3 features.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>from sklearn.ensemble import RandomForestClassifier\r\n\r\nrf = RandomForestClassifier(\r\n    n_estimators=10,\r\n    max_features=3,\r\n    random_state=SEED\r\n)\r\n\r\nrf.fit(xtrain, ytrain)\r\np = rf.predict_proba(xtest)[:, 1]\r\nprint(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(ytest, p))\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><em>Average of decision tree ROC-AUC score: 0.844</em></p>\n<p>The Random Forest yields a significant improvement upon our previous models. We're on to something! But there is only so much you can do with decision trees. It's time we expand our horizon.</p>\n</div> ", "website": "kdnuggets"}