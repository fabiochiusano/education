{"title": "Is Artificial Intelligence Racist?", "tfidf": {"tfidf": {"stereotyp": 19.3138686131, "age": 1.48623853211, "made": 2.14077669902, "but": 4.06529671596, "integr": 2.8254137746900003, "larg": 1.18574949585, "record": 4.27003765464, "incom": 3.92, "american": 5.2656716418, "leagu": 3.5821299639, "opinion": 3.8044572250199997, "suppos": 4.23021582734, "pipelin": 32.1376518219, "although": 1.14968498805, "philosophi": 5.64580369844, "name": 5.510586601850001, "should": 3.3286508019800003, "great": 1.26592775696, "piec": 3.24132298898, "amazon": 66.2881002088, "pattern": 3.79173632673, "social": 1.9904714142400002, "all": 3.03440366973, "into": 1.01502461479, "other": 4.03969465648, "african": 7.59798994974, "real": 2.28103448276, "possibl": 1.4173734488, "fire": 2.1153897401700004, "and": 34.00214173242, "want": 1.99698113208, "clean": 6.86975335353, "mani": 2.08853515754, "rachel": 22.8760806916, "absorb": 6.837209302330001, "upset": 12.8032258065, "independ": 1.58950740889, "giant": 6.23566378633, "cours": 8.60371223412, "learnt": 113.806451613, "compani": 3.1047227926, "mortgag": 40.5, "uncool": 1443.27272727, "bias": 137.335640138, "block": 3.20274359492, "artifici": 16.63279203772, "financi": 2.60860992442, "povertystricken": 1443.27272727, "tech": 76.695652174, "captur": 2.88026124819, "train": 1.9365698950999999, "scienc": 6.959088252479999, "impact": 2.97526236882, "fals": 18.64839467502, "ask": 2.1744966443, "learn": 18.5820043892, "internet": 9.96923076924, "unpleas": 167.556728232, "from": 9.00510493473, "tend": 3.3735656608599998, "comment": 3.05954904606, "first": 1.00761614623, "whilst": 8.444680851060001, "underprepar": 1443.27272727, "open": 1.24556723678, "patient": 9.54660252556, "exclus": 3.40906162766, "evalu": 6.9509632224199995, "credit": 6.08625646924, "unlik": 2.42529789184, "decisiontre": 1443.27272727, "general": 1.1218202374200001, "call": 1.0676529926, "embrac": 8.45817794353, "type": 4.056208482380001, "ani": 1.13383802314, "frequenc": 8.8102108768, "last": 2.4234468020200004, "knew": 5.134540750319999, "than": 4.131147541, "buy": 5.12459651388, "who": 5.313964386149999, "decis": 10.8, "billionair": 61.7743190661, "divers": 7.94395796848, "work": 2.23040179826, "alleg": 3.8071942445999998, "have": 7.104263887979998, "togeth": 1.58095996813, "don": 6.02733485194, "between": 1.03453668708, "properti": 2.5949656750599996, "make": 8.610128126880001, "potenti": 2.52080025405, "account": 1.94463498285, "recognit": 4.40022172949, "member": 3.9620663838300003, "conserv": 3.3199498117900004, "box": 4.12685209254, "dure": 1.0503473370799998, "appli": 2.2972073506, "institut": 5.337666704010001, "creat": 1.2492917847, "human": 11.37928562898, "valley": 4.21673306773, "peopl": 6.0660247593, "appeal": 3.6614391143900002, "data": 33.7643555934, "discrimin": 10.6981132075, "technolog": 13.017382748450002, "inclus": 17.513513513520003, "correl": 13.1860465116, "advoc": 4.4595505618, "process": 1.69524826482, "prejud": 155.647058824, "event": 1.5356935577500002, "expert": 5.36713995943, "civil": 2.10306000795, "start": 1.26673581744, "san": 3.30131004367, "mugshot": 1443.27272727, "univers": 1.24889867841, "time": 2.02254920696, "joy": 51.713355048800004, "web": 5.17133550489, "weapon": 4.57126403686, "brilliant": 14.7272727273, "way": 1.2190739461, "achiev": 1.87216981132, "itself": 1.74557449148, "silicon": 31.8795180723, "one": 2.01254991444, "were": 3.07376573088, "huge": 4.38927287808, "poor": 7.265903890170001, "machin": 24.146007604559998, "paper": 2.6628648104700003, "against": 3.8706216984899995, "someon": 4.9350326391, "that": 25.09960159375, "perform": 3.0627954085000004, "polic": 12.6, "reason": 1.72340425532, "instanc": 3.2572835453400004, "straightforward": 27.7552447552, "determin": 2.1658935879900003, "centric": 1058.4, "fit": 3.37070063694, "former": 1.36111111111, "loan": 24.780437044739998, "rate": 2.14048806795, "hard": 2.73253012048, "can": 7.05756834852, "includ": 1.0190641247799999, "million": 3.4558119286, "requir": 1.52844902282, "thoma": 2.39673913043, "africanamerican": 1221.23076923, "insuffici": 10.911340206199998, "while": 1.0441988950299999, "soar": 27.184931506799998, "regular": 2.09418282548, "same": 1.11857958148, "transpar": 15.876, "regul": 3.88736532811, "peter": 2.34090238868, "cloud": 10.6193979933, "spend": 4.15928739848, "plenti": 17.4078947368, "press": 2.82491103202, "yet": 2.1258703802900003, "result": 3.43834825296, "base": 1.14628158845, "fair": 3.20533010297, "optimist": 32.1376518219, "homogen": 26.4159733777, "has": 13.567446752599999, "fastai": 1443.27272727, "becaus": 4.5980739989999995, "approv": 5.71902017292, "faculti": 10.903846153800002, "lawyer": 6.92368076755, "agenc": 3.49922856513, "high": 1.14777327935, "secret": 3.11294117647, "depart": 1.99147014551, "serena": 152.653846154, "written": 1.9573418813999999, "blind": 8.849498327760001, "number": 1.10142916609, "uncov": 14.8097014925, "current": 1.5325803649, "founder": 4.033536585369999, "over": 1.02525024217, "outperform": 82.2590673575, "kit": 35.085082873000005, "michell": 26.111842105300003, "racist": 52.309719934200004, "take": 1.13961668222, "appear": 1.3214582986499999, "gender": 37.73262032084, "topic": 5.457545548300001, "had": 1.0475750577399998, "neutral": 6.981530343010001, "like": 8.04429967425, "world": 1.11340206186, "face": 9.01635620175, "famili": 1.48804948917, "six": 1.5552507837, "motto": 21.9281767956, "get": 1.78562591385, "york": 1.53361669243, "posit": 4.11757586238, "best": 1.5828514456600002, "autom": 19.8202247191, "neural": 59.4606741573, "better": 6.01971688575, "sure": 7.453521126760001, "what": 3.7603031738399997, "reduc": 1.98698372966, "pleasant": 43.3770491804, "final": 1.34008609775, "the": 46.0, "let": 3.48616600791, "european": 1.96290801187, "differ": 2.4730898045, "francisco": 5.2937645882, "him": 1.63434218653, "whi": 3.2566153846200003, "william": 1.75483585719, "mainstream": 7.450023463160001, "exampl": 1.50483412322, "certain": 1.8077886586200003, "mit": 33.3880126182, "taken": 1.6012102874399998, "thiel": 305.307692308, "wors": 9.58695652174, "martin": 3.07793718496, "how": 8.01251640255, "signific": 1.4529147982100001, "with": 5.005991044949999, "humancent": 1443.27272727, "ethic": 8.93918918919, "there": 1.04091266719, "task": 15.54565483476, "similar": 1.37514075357, "effort": 1.89247824532, "inspect": 11.7512953368, "most": 3.06289389069, "plan": 1.5356935577500002, "desper": 11.7687175686, "risk": 8.191950464400001, "neighborhood": 16.95248264816, "stanford": 12.6, "group": 1.20996875238, "darkerskin": 1443.27272727, "publish": 2.73771339886, "creditworthi": 882.0, "past": 2.01702452039, "extern": 5.24133377352, "crawl": 46.8318584071, "hivneg": 1443.27272727, "criteria": 11.7426035503, "through": 1.07074930869, "background": 4.02739726027, "recent": 3.0881151527, "luther": 18.375, "anoth": 1.13643521832, "penetr": 10.569906790900001, "howev": 2.1890382626599996, "address": 2.86157173756, "corpus": 24.091047041, "peek": 160.363636364, "surprir": 1443.27272727, "mirror": 7.54921540656, "king": 2.0281042411900003, "donor": 25.565217391300003, "council": 2.4744389027400002, "found": 4.4554830562, "usual": 1.72508964468, "amid": 14.5919117647, "thokozan": 1443.27272727, "benevol": 38.8166259169, "also": 2.02953020134, "use": 9.266748816419998, "far": 1.71022298826, "meantim": 22.3921015515, "signi\ufb01c": 1443.27272727, "noth": 3.46410648047, "their": 5.07739542025, "system": 9.71178886657, "chapter": 3.6147540983599997, "implicit": 42.3925233644, "teach": 3.98594024605, "leverag": 35.7567567568, "race": 2.93023255814, "will": 2.44962197192, "penal": 28.35, "statist": 8.48530197756, "sometim": 1.7126213592200001, "maurizio": 220.5, "long": 1.2657259028899999, "act": 1.4318181818200002, "right": 2.8109065155799997, "men": 1.86776470588, "gain": 1.84819557625, "they": 7.21121277009, "rapid": 2.62586834271, "alexandria": 22.68, "mustn": 1443.27272727, "flower": 8.32511798637, "build": 1.6341739578, "reject": 5.64279367336, "few": 2.63458347162, "overconfid": 220.5, "algorithm": 363.35915493019996, "sell": 3.51083591331, "combin": 1.69760479042, "not": 4.06269592476, "are": 11.32896529358, "some": 2.08073394496, "scrape": 70.56, "becom": 1.12492028626, "debias": 1443.27272727, "thinker": 21.168000000000003, "lead": 1.2664326739, "comput": 19.638792676900003, "auditor": 65.8755186722, "afford": 7.0875, "crowd": 5.4, "term": 2.79040337464, "write": 2.0575427682700003, "must": 1.9220338983099996, "thing": 4.813096862219999, "for": 11.00346544011, "compliant": 72.8256880734, "sold": 2.7935949322500004, "enabl": 3.5421686747, "say": 1.7544480053, "govern": 3.01882487164, "prison": 3.82093862816, "fail": 3.8562059752199995, "program": 2.02139037433, "scientist": 9.38852749852, "unsurpris": 128.032258065, "often": 1.29452054795, "much": 2.3884459154599997, "just": 1.33580143037, "error": 18.123287671230003, "graduat": 4.60173913043, "vulner": 17.738547486039998, "where": 1.06715063521, "day": 2.36743215032, "dispos": 10.4378698225, "today": 3.49922856514, "societi": 1.8173076923099998, "obama": 14.5251601098, "prolif": 19.1277108434, "cofound": 264.6, "male": 6.9418452120600005, "compar": 1.8662278123900002, "deep": 7.2559414990799995, "under": 1.0781663837, "abus": 6.28503562945, "bad": 3.3944836433599996, "black": 5.84751381216, "career": 2.98757997742, "racial": 29.23756906076, "enter": 1.75813953488, "substanti": 3.4777656078900003, "said": 1.54751925139, "chief": 2.41827875095, "follow": 3.1392037964699995, "problem": 5.30024482527, "histor": 1.6755672823199999, "lose": 3.0851146521599997, "corpor": 3.02284843869, "women": 4.63465187564, "communiti": 1.96121062384, "discov": 2.52160101652, "text": 3.12827586207, "show": 2.5340782123, "sophist": 10.0037807183, "new": 4.0715522216, "vocabulari": 23.2785923754, "may": 3.15605327679, "those": 1.19548192771, "more": 9.154536135299999, "grant": 2.2490437739099995, "tradit": 3.2160437557, "ensur": 3.4127257093700005, "year": 3.1456310679600006, "present": 1.25551601423, "his": 2.1887364720400004, "least": 1.6165359943000002, "run": 1.55692850838, "word": 7.186149145639999, "too": 1.81585268215, "decid": 3.8515283842800003, "fanfar": 74.8867924528, "implement": 3.57648118946, "even": 2.32922535212, "lighterskin": 1443.27272727, "easili": 7.387622149839999, "resid": 2.39457013575, "justic": 3.99697885196, "accur": 5.768895348840001, "imposs": 4.96125, "repli": 6.6593959731500005, "allow": 1.2716059271100002, "palantir": 1443.27272727, "congress": 3.86277372263, "demand": 2.34159292035, "connot": 26.862944162399998, "behavior": 5.52978056426, "this": 6.02276176026, "applic": 34.2672134686, "accord": 1.27589809531, "outspoken": 28.8654545455, "winfrey": 127.008, "launch": 2.5664403491799996, "done": 2.3302509907499998, "intent": 3.19372359686, "santamicon": 1443.27272727, "contain": 1.59814777532, "such": 3.18454132122, "test": 5.31414225942, "area": 1.3881262568900001, "citi": 1.38618702523, "these": 3.22246278756, "when": 2.0415353951, "hire": 9.91630231106, "lab": 43.2981818181, "featur": 1.52712581762, "vision": 4.88041807562, "them": 2.19752231988, "almost": 1.53584212054, "effect": 1.3963060686000002, "net": 6.96315789474, "histori": 1.20629131525, "list": 1.36321483771, "psycholog": 13.369263157899999, "common": 1.4025974025999999, "individu": 1.8004082558400003, "congresswoman": 226.8, "match": 3.5676404494400002, "well": 1.0655748708, "apr": 32.2682926829, "whose": 1.73508196721, "need": 7.186311787049999, "understand": 5.93717277486, "singl": 1.60948905109, "influenc": 1.77246846042, "pitfal": 178.38202247200002, "microsoft": 24.8450704225, "num": 7.00220528007, "disciplin": 6.92972501091, "financ": 4.255159474669999, "sift": 208.89473684200001, "surround": 2.49858356941, "research": 5.8260550458600004, "suspect": 6.363126252509999, "given": 1.35426085473, "equiti": 25.240063593000002, "orlean": 15.443579766500001, "insect": 22.5191489362, "associ": 6.63157894735, "guess": 25.0410094637, "femal": 6.3644016837, "born": 2.21762816036, "about": 5.324300757950001, "buolamwini": 5773.09090908, "layer": 8.14153846154, "trump": 62.015625, "horribl": 40.2944162437, "oprah": 113.4, "ocasiocortez": 1443.27272727, "everi": 1.47917637194, "intellig": 8.38668779714, "english": 1.7432744043000001, "identifi": 4.60374075686, "help": 1.39962972759, "student": 2.47174217655, "unblock": 635.04, "previous": 1.42846859816, "guis": 36.3295194508, "prove": 2.45720476706, "return": 2.79064862014, "googl": 11.388809182200001, "inform": 1.5753125620200001, "bank": 8.62201303404, "been": 6.143566591439999, "billion": 4.8669527897, "derid": 62.015625, "licens": 11.59678597516, "field": 1.7790228597, "assumpt": 9.21951219512, "predomin": 5.33467741935, "now": 1.160780873, "fei": 278.52631579, "classifi": 5.2937645882, "approxim": 2.2132998745299997, "soweto": 429.081081081, "predict": 10.3696930111, "good": 3.03963239518, "she": 4.32, "explan": 6.50922509225}, "idf": {"stereotyp": 19.3138686131, "age": 1.48623853211, "made": 1.07038834951, "but": 1.01632417899, "integr": 2.8254137746900003, "larg": 1.18574949585, "record": 1.42334588488, "incom": 3.92, "american": 1.31641791045, "leagu": 3.5821299639, "opinion": 3.8044572250199997, "suppos": 4.23021582734, "pipelin": 32.1376518219, "although": 1.14968498805, "philosophi": 5.64580369844, "name": 1.10211732037, "should": 1.6643254009900001, "great": 1.26592775696, "piec": 3.24132298898, "amazon": 33.1440501044, "pattern": 3.79173632673, "social": 1.9904714142400002, "all": 1.01146788991, "into": 1.01502461479, "other": 1.00992366412, "african": 3.79899497487, "real": 2.28103448276, "possibl": 1.4173734488, "fire": 2.1153897401700004, "and": 1.00006299213, "want": 1.99698113208, "clean": 6.86975335353, "mani": 1.04426757877, "rachel": 22.8760806916, "absorb": 6.837209302330001, "upset": 12.8032258065, "independ": 1.58950740889, "giant": 6.23566378633, "cours": 2.15092805853, "learnt": 56.9032258065, "compani": 1.5523613963, "mortgag": 40.5, "uncool": 1443.27272727, "bias": 13.7335640138, "block": 3.20274359492, "artifici": 8.31639601886, "financi": 2.60860992442, "povertystricken": 1443.27272727, "tech": 19.1739130435, "captur": 2.88026124819, "train": 1.9365698950999999, "scienc": 2.31969608416, "impact": 2.97526236882, "fals": 6.21613155834, "ask": 2.1744966443, "learn": 2.32275054865, "internet": 4.98461538462, "unpleas": 41.889182058, "from": 1.00056721497, "tend": 3.3735656608599998, "comment": 3.05954904606, "first": 1.00761614623, "whilst": 8.444680851060001, "underprepar": 1443.27272727, "open": 1.24556723678, "patient": 9.54660252556, "exclus": 3.40906162766, "evalu": 6.9509632224199995, "credit": 3.04312823462, "unlik": 2.42529789184, "decisiontre": 1443.27272727, "general": 1.1218202374200001, "call": 1.0676529926, "embrac": 8.45817794353, "type": 2.0281042411900003, "ani": 1.13383802314, "frequenc": 8.8102108768, "last": 1.2117234010100002, "knew": 5.134540750319999, "than": 1.03278688525, "buy": 5.12459651388, "who": 1.06279287723, "decis": 2.16, "billionair": 61.7743190661, "divers": 3.97197898424, "work": 1.11520089913, "alleg": 3.8071942445999998, "have": 1.0148948411399998, "togeth": 1.58095996813, "don": 6.02733485194, "between": 1.03453668708, "properti": 2.5949656750599996, "make": 1.0762660158600001, "potenti": 2.52080025405, "account": 1.94463498285, "recognit": 4.40022172949, "member": 1.32068879461, "conserv": 3.3199498117900004, "box": 4.12685209254, "dure": 1.0503473370799998, "appli": 2.2972073506, "institut": 1.7792222346700002, "creat": 1.2492917847, "human": 1.8965476048299998, "valley": 4.21673306773, "peopl": 1.21320495186, "appeal": 3.6614391143900002, "data": 3.37643555934, "discrimin": 10.6981132075, "technolog": 2.6034765496900003, "inclus": 8.756756756760002, "correl": 13.1860465116, "advoc": 4.4595505618, "process": 1.69524826482, "prejud": 155.647058824, "event": 1.5356935577500002, "expert": 5.36713995943, "civil": 2.10306000795, "start": 1.26673581744, "san": 3.30131004367, "mugshot": 1443.27272727, "univers": 1.24889867841, "time": 1.01127460348, "joy": 12.928338762200001, "web": 5.17133550489, "weapon": 4.57126403686, "brilliant": 14.7272727273, "way": 1.2190739461, "achiev": 1.87216981132, "itself": 1.74557449148, "silicon": 31.8795180723, "one": 1.00627495722, "were": 1.02458857696, "huge": 4.38927287808, "poor": 2.42196796339, "machin": 4.02433460076, "paper": 2.6628648104700003, "against": 1.2902072328299998, "someon": 4.9350326391, "that": 1.00398406375, "perform": 1.5313977042500002, "polic": 3.15, "reason": 1.72340425532, "instanc": 3.2572835453400004, "straightforward": 27.7552447552, "determin": 2.1658935879900003, "centric": 529.2, "fit": 3.37070063694, "former": 1.36111111111, "loan": 8.26014568158, "rate": 2.14048806795, "hard": 2.73253012048, "can": 1.17626139142, "includ": 1.0190641247799999, "million": 1.7279059643, "requir": 1.52844902282, "thoma": 2.39673913043, "africanamerican": 1221.23076923, "insuffici": 10.911340206199998, "while": 1.0441988950299999, "soar": 27.184931506799998, "regular": 2.09418282548, "same": 1.11857958148, "transpar": 15.876, "regul": 3.88736532811, "peter": 2.34090238868, "cloud": 10.6193979933, "spend": 4.15928739848, "plenti": 17.4078947368, "press": 1.41245551601, "yet": 2.1258703802900003, "result": 1.14611608432, "base": 1.14628158845, "fair": 3.20533010297, "optimist": 32.1376518219, "homogen": 26.4159733777, "has": 1.0436497502, "fastai": 1443.27272727, "becaus": 1.1495184997499999, "approv": 2.85951008646, "faculti": 10.903846153800002, "lawyer": 6.92368076755, "agenc": 3.49922856513, "high": 1.14777327935, "secret": 3.11294117647, "depart": 1.99147014551, "serena": 152.653846154, "written": 1.9573418813999999, "blind": 8.849498327760001, "number": 1.10142916609, "uncov": 14.8097014925, "current": 1.5325803649, "founder": 4.033536585369999, "over": 1.02525024217, "outperform": 82.2590673575, "kit": 17.542541436500002, "michell": 26.111842105300003, "racist": 26.154859967100002, "take": 1.13961668222, "appear": 1.3214582986499999, "gender": 9.43315508021, "topic": 5.457545548300001, "had": 1.0475750577399998, "neutral": 6.981530343010001, "like": 1.14918566775, "world": 1.11340206186, "face": 1.80327124035, "famili": 1.48804948917, "six": 1.5552507837, "motto": 21.9281767956, "get": 1.78562591385, "york": 1.53361669243, "posit": 1.37252528746, "best": 1.5828514456600002, "autom": 19.8202247191, "neural": 59.4606741573, "better": 2.0065722952500002, "sure": 7.453521126760001, "what": 1.25343439128, "reduc": 1.98698372966, "pleasant": 21.6885245902, "final": 1.34008609775, "the": 1.0, "let": 3.48616600791, "european": 1.96290801187, "differ": 1.23654490225, "francisco": 5.2937645882, "him": 1.63434218653, "whi": 3.2566153846200003, "william": 1.75483585719, "mainstream": 7.450023463160001, "exampl": 1.50483412322, "certain": 1.8077886586200003, "mit": 16.6940063091, "taken": 1.6012102874399998, "thiel": 305.307692308, "wors": 9.58695652174, "martin": 3.07793718496, "how": 1.60250328051, "signific": 1.4529147982100001, "with": 1.0011982089899998, "humancent": 1443.27272727, "ethic": 8.93918918919, "there": 1.04091266719, "task": 3.88641370869, "similar": 1.37514075357, "effort": 1.89247824532, "inspect": 11.7512953368, "most": 1.02096463023, "plan": 1.5356935577500002, "desper": 11.7687175686, "risk": 4.095975232200001, "neighborhood": 8.47624132408, "stanford": 12.6, "group": 1.20996875238, "darkerskin": 1443.27272727, "publish": 1.36885669943, "creditworthi": 882.0, "past": 2.01702452039, "extern": 5.24133377352, "crawl": 46.8318584071, "hivneg": 1443.27272727, "criteria": 11.7426035503, "through": 1.07074930869, "background": 4.02739726027, "recent": 1.54405757635, "luther": 18.375, "anoth": 1.13643521832, "penetr": 10.569906790900001, "howev": 1.0945191313299998, "address": 2.86157173756, "corpus": 24.091047041, "peek": 160.363636364, "surprir": 1443.27272727, "mirror": 7.54921540656, "king": 2.0281042411900003, "donor": 25.565217391300003, "council": 2.4744389027400002, "found": 1.11387076405, "usual": 1.72508964468, "amid": 14.5919117647, "thokozan": 1443.27272727, "benevol": 38.8166259169, "also": 1.01476510067, "use": 1.0296387573799999, "far": 1.71022298826, "meantim": 22.3921015515, "signi\ufb01c": 1443.27272727, "noth": 3.46410648047, "their": 1.01547908405, "system": 1.38739840951, "chapter": 3.6147540983599997, "implicit": 21.1962616822, "teach": 3.98594024605, "leverag": 35.7567567568, "race": 2.93023255814, "will": 1.22481098596, "penal": 28.35, "statist": 4.24265098878, "sometim": 1.7126213592200001, "maurizio": 220.5, "long": 1.2657259028899999, "act": 1.4318181818200002, "right": 1.4054532577899999, "men": 1.86776470588, "gain": 1.84819557625, "they": 1.03017325287, "rapid": 2.62586834271, "alexandria": 22.68, "mustn": 1443.27272727, "flower": 8.32511798637, "build": 1.6341739578, "reject": 2.82139683668, "few": 1.31729173581, "overconfid": 220.5, "algorithm": 27.9507042254, "sell": 3.51083591331, "combin": 1.69760479042, "not": 1.01567398119, "are": 1.02990593578, "some": 1.04036697248, "scrape": 70.56, "becom": 1.12492028626, "debias": 1443.27272727, "thinker": 21.168000000000003, "lead": 1.2664326739, "comput": 3.9277585353800006, "auditor": 65.8755186722, "afford": 7.0875, "crowd": 5.4, "term": 1.39520168732, "write": 2.0575427682700003, "must": 1.9220338983099996, "thing": 2.4065484311099996, "for": 1.00031504001, "compliant": 72.8256880734, "sold": 2.7935949322500004, "enabl": 3.5421686747, "say": 1.7544480053, "govern": 1.50941243582, "prison": 3.82093862816, "fail": 1.9281029876099998, "program": 2.02139037433, "scientist": 4.69426374926, "unsurpris": 128.032258065, "often": 1.29452054795, "much": 1.1942229577299999, "just": 1.33580143037, "error": 6.04109589041, "graduat": 4.60173913043, "vulner": 8.869273743019999, "where": 1.06715063521, "day": 1.18371607516, "dispos": 10.4378698225, "today": 1.74961428257, "societi": 1.8173076923099998, "obama": 14.5251601098, "prolif": 19.1277108434, "cofound": 264.6, "male": 3.4709226060300002, "compar": 1.8662278123900002, "deep": 3.6279707495399998, "under": 1.0781663837, "abus": 6.28503562945, "bad": 3.3944836433599996, "black": 1.94917127072, "career": 2.98757997742, "racial": 7.30939226519, "enter": 1.75813953488, "substanti": 3.4777656078900003, "said": 1.54751925139, "chief": 2.41827875095, "follow": 1.04640126549, "problem": 1.76674827509, "histor": 1.6755672823199999, "lose": 3.0851146521599997, "corpor": 3.02284843869, "women": 2.31732593782, "communiti": 1.96121062384, "discov": 2.52160101652, "text": 3.12827586207, "show": 1.26703910615, "sophist": 10.0037807183, "new": 1.0178880554, "vocabulari": 23.2785923754, "may": 1.05201775893, "those": 1.19548192771, "more": 1.0171706817, "grant": 2.2490437739099995, "tradit": 1.60802187785, "ensur": 3.4127257093700005, "year": 1.0485436893200002, "present": 1.25551601423, "his": 1.0943682360200002, "least": 1.6165359943000002, "run": 1.55692850838, "word": 1.7965372864099998, "too": 1.81585268215, "decid": 1.9257641921400002, "fanfar": 74.8867924528, "implement": 3.57648118946, "even": 1.16461267606, "lighterskin": 1443.27272727, "easili": 3.6938110749199997, "resid": 2.39457013575, "justic": 3.99697885196, "accur": 5.768895348840001, "imposs": 4.96125, "repli": 6.6593959731500005, "allow": 1.2716059271100002, "palantir": 1443.27272727, "congress": 3.86277372263, "demand": 2.34159292035, "connot": 26.862944162399998, "behavior": 5.52978056426, "this": 1.00379362671, "applic": 3.42672134686, "accord": 1.27589809531, "outspoken": 28.8654545455, "winfrey": 127.008, "launch": 2.5664403491799996, "done": 2.3302509907499998, "intent": 3.19372359686, "santamicon": 1443.27272727, "contain": 1.59814777532, "such": 1.06151377374, "test": 2.65707112971, "area": 1.3881262568900001, "citi": 1.38618702523, "these": 1.07415426252, "when": 1.02076769755, "hire": 4.95815115553, "lab": 14.4327272727, "featur": 1.52712581762, "vision": 4.88041807562, "them": 1.09876115994, "almost": 1.53584212054, "effect": 1.3963060686000002, "net": 6.96315789474, "histori": 1.20629131525, "list": 1.36321483771, "psycholog": 6.6846315789499995, "common": 1.4025974025999999, "individu": 1.8004082558400003, "congresswoman": 226.8, "match": 3.5676404494400002, "well": 1.0655748708, "apr": 32.2682926829, "whose": 1.73508196721, "need": 1.4372623574099999, "understand": 2.96858638743, "singl": 1.60948905109, "influenc": 1.77246846042, "pitfal": 178.38202247200002, "microsoft": 24.8450704225, "num": 1.00031504001, "disciplin": 6.92972501091, "financ": 4.255159474669999, "sift": 208.89473684200001, "surround": 2.49858356941, "research": 1.9420183486200002, "suspect": 6.363126252509999, "given": 1.35426085473, "equiti": 25.240063593000002, "orlean": 15.443579766500001, "insect": 22.5191489362, "associ": 1.3263157894700002, "guess": 25.0410094637, "femal": 3.18220084185, "born": 2.21762816036, "about": 1.06486015159, "buolamwini": 1443.27272727, "layer": 8.14153846154, "trump": 62.015625, "horribl": 40.2944162437, "oprah": 113.4, "ocasiocortez": 1443.27272727, "everi": 1.47917637194, "intellig": 4.19334389857, "english": 1.7432744043000001, "identifi": 2.30187037843, "help": 1.39962972759, "student": 2.47174217655, "unblock": 635.04, "previous": 1.42846859816, "guis": 36.3295194508, "prove": 2.45720476706, "return": 1.39532431007, "googl": 11.388809182200001, "inform": 1.5753125620200001, "bank": 2.87400434468, "been": 1.0239277652399998, "billion": 4.8669527897, "derid": 62.015625, "licens": 5.79839298758, "field": 1.7790228597, "assumpt": 9.21951219512, "predomin": 5.33467741935, "now": 1.160780873, "fei": 139.263157895, "classifi": 5.2937645882, "approxim": 2.2132998745299997, "soweto": 429.081081081, "predict": 5.18484650555, "good": 1.51981619759, "she": 2.16, "explan": 6.50922509225}, "logidf": {"stereotyp": 2.96082341885, "age": 0.39624845300300005, "made": 0.0680215260973, "but": 0.0161923720719, "integr": 1.03865482279, "larg": 0.17037506060600002, "record": 0.353010356953, "incom": 1.3660916537999999, "american": 0.274914343622, "leagu": 1.2759575854799998, "opinion": 1.33617333331, "suppos": 1.44225301477, "pipelin": 3.47002829672, "although": 0.139487981418, "philosophi": 1.73091256097, "name": 0.09723316638430002, "should": 0.509419876758, "great": 0.235805258079, "piec": 1.17598157639, "amazon": 3.50086321649, "pattern": 1.33282404788, "social": 0.688371502261, "all": 0.011402632097799998, "into": 0.0149128632287, "other": 0.00987474791976, "african": 1.33473655146, "real": 0.824629060574, "possibl": 0.348805474891, "fire": 0.749239069835, "and": 6.29901420636e-05, "want": 0.6916366062549999, "clean": 1.9271282036300001, "mani": 0.0433157581221, "rachel": 3.1300918533999997, "absorb": 1.92237965165, "upset": 2.5496971553, "independ": 0.463424162503, "giant": 1.83028503479, "cours": 0.765899404133, "learnt": 4.04135203208, "compani": 0.439777253097, "mortgag": 3.70130197411, "uncool": 7.2746685411000005, "bias": 2.61984276467, "block": 1.16400781588, "artifici": 2.11822899018, "financi": 0.958817483446, "povertystricken": 7.2746685411000005, "tech": 2.9535506595200003, "captur": 1.0578810012100002, "train": 0.660918312839, "scienc": 0.841436178891, "impact": 1.09033222631, "fals": 1.8271477773099998, "ask": 0.776797209847, "learn": 0.842752064745, "internet": 1.6063562459, "unpleas": 3.73502760882, "from": 0.000567054168866, "tend": 1.21597024462, "comment": 1.11826753454, "first": 0.0075872898121599995, "whilst": 2.13353675808, "underprepar": 7.2746685411000005, "open": 0.219591038029, "patient": 2.25618533471, "exclus": 1.22643707092, "evalu": 1.9388802431299998, "credit": 1.11288601088, "unlik": 0.885954358842, "decisiontre": 7.2746685411000005, "general": 0.114952578063, "call": 0.0654627744488, "embrac": 2.13513377732, "type": 0.707101485387, "ani": 0.125608358366, "frequenc": 2.1759113757299997, "last": 0.19204364461100001, "knew": 1.6359904042, "than": 0.0322608622182, "buy": 1.6340517929299998, "who": 0.0609002329859, "decis": 0.7701082216959999, "billionair": 4.12348772901, "divers": 1.37926445519, "work": 0.109034567273, "alleg": 1.33689249911, "have": 0.0147850023412, "togeth": 0.458032237308, "don": 1.7963049316, "between": 0.033953681165299995, "properti": 0.953573289192, "make": 0.07349765782289999, "potenti": 0.9245764122419999, "account": 0.665074289973, "recognit": 1.4816549327200002, "member": 0.278153414599, "conserv": 1.19994966588, "box": 1.41751491115, "dure": 0.0491209066894, "appli": 0.8316941898119999, "institut": 0.576176322003, "creat": 0.222576818514, "human": 0.640035183243, "valley": 1.4390606736700002, "peopl": 0.193265578473, "appeal": 1.2978562707799999, "data": 1.2168205848, "discrimin": 2.37006739018, "technolog": 0.956847686355, "inclus": 2.16982560315, "correl": 2.57915918803, "advoc": 1.4950479900600002, "process": 0.527829199025, "prejud": 5.04759100062, "event": 0.428982108147, "expert": 1.68029517063, "civil": 0.7433934307629999, "start": 0.236443369291, "san": 1.1943193726299999, "mugshot": 7.2746685411000005, "univers": 0.222262105686, "time": 0.0112115188626, "joy": 2.5594217052, "web": 1.6431309733200001, "weapon": 1.51978976116, "brilliant": 2.6897010624299997, "way": 0.19809150993500002, "achiev": 0.6270980851169999, "itself": 0.5570837229510001, "silicon": 3.46196373688, "one": 0.0062553516455, "were": 0.024291143681099997, "huge": 1.47916358195, "poor": 0.8845804177050001, "machin": 1.39235958062, "paper": 0.979402539665, "against": 0.254802851078, "someon": 1.59635928666, "that": 0.00397614837964, "perform": 0.42618085058, "polic": 1.14740245284, "reason": 0.544301552962, "instanc": 1.18089357972, "straightforward": 3.3234248225200003, "determin": 0.772833019022, "centric": 6.27136643224, "fit": 1.2151206268899999, "former": 0.308301359655, "loan": 2.11144222437, "rate": 0.761033872166, "hard": 1.00522796406, "can": 0.162341096394, "includ": 0.0188846813905, "million": 0.5469102500940001, "requir": 0.424253510675, "thoma": 0.874109117838, "africanamerican": 7.1076144564399995, "insuffici": 2.3898026343, "while": 0.04324998379380001, "soar": 3.30266283107, "regular": 0.739163417847, "same": 0.112059649604, "transpar": 2.76480853492, "regul": 1.3577316346200001, "peter": 0.850536491217, "cloud": 2.36268232808, "spend": 1.42534376116, "plenti": 2.8569238238300003, "press": 0.345329690455, "yet": 0.754181309241, "result": 0.136378908381, "base": 0.13652330228700002, "fair": 1.16481508131, "optimist": 3.47002829672, "homogen": 3.2739688793700004, "has": 0.0427239448548, "fastai": 7.2746685411000005, "becaus": 0.139343158825, "approv": 1.0506503117200001, "faculti": 2.38911558515, "lawyer": 1.93494753105, "agenc": 1.25254253424, "high": 0.13782378654000002, "secret": 1.13556799519, "depart": 0.68887313257, "serena": 5.02817291476, "written": 0.671587369833, "blind": 2.1803607712799997, "number": 0.0966085784186, "uncov": 2.69528247227, "current": 0.42695282784500005, "founder": 1.3946435557299999, "over": 0.0249367214957, "outperform": 4.409873625, "kit": 2.8646288702, "michell": 3.26238893194, "racist": 3.2640350228400004, "take": 0.130691962197, "appear": 0.278735898493, "gender": 2.2442306197099997, "topic": 1.6969991554100001, "had": 0.0464780244111, "neutral": 1.9432681395900002, "like": 0.139053576545, "world": 0.107420248621, "face": 0.589602371257, "famili": 0.39746619471100003, "six": 0.441636808318, "motto": 3.08777242152, "get": 0.579769005782, "york": 0.42762879716200003, "posit": 0.316652318608, "best": 0.459227932947, "autom": 2.9867028668299995, "neural": 4.0853151555, "better": 0.6964279406, "sure": 2.0086865552, "what": 0.225887296827, "reduc": 0.686617775143, "pleasant": 3.07678329994, "final": 0.292733863948, "the": 0.0, "let": 1.2488025672799998, "european": 0.674427053203, "differ": 0.212321121312, "francisco": 1.6665296351499999, "him": 0.49124039099699995, "whi": 1.18068843047, "william": 0.562375323877, "mainstream": 2.0082171818, "exampl": 0.40868267499899996, "certain": 0.592104362781, "mit": 2.8150497513599997, "taken": 0.470759772949, "thiel": 5.721320095319999, "wors": 2.26040347896, "martin": 1.12425962746, "how": 0.47156695693000006, "signific": 0.373571744332, "with": 0.00119749171339, "humancent": 7.2746685411000005, "ethic": 2.19044489035, "there": 0.0400978929255, "task": 1.35748680661, "similar": 0.318556092114, "effort": 0.637887211057, "inspect": 2.46396347594, "most": 0.020747896295599998, "plan": 0.428982108147, "desper": 2.4654449577, "risk": 1.4100048408899999, "neighborhood": 2.13726711146, "stanford": 2.53369681396, "group": 0.190594534797, "darkerskin": 7.2746685411000005, "publish": 0.313975865467, "creditworthi": 6.7821920560099995, "past": 0.7016234157610001, "extern": 1.6565760028799998, "crawl": 3.8465637065199996, "hivneg": 7.2746685411000005, "criteria": 2.4632235573, "through": 0.0683586918849, "background": 1.3931203261899998, "recent": 0.434413741288, "luther": 2.9109910451, "anoth": 0.127896361652, "penetr": 2.35801098158, "howev": 0.0903151173475, "address": 1.05137103247, "corpus": 3.1818402794, "peek": 5.0774439637699995, "surprir": 7.2746685411000005, "mirror": 2.0214436382, "king": 0.707101485387, "donor": 3.2412327319700003, "council": 0.906013664357, "found": 0.107841124048, "usual": 0.545279017064, "amid": 2.68046738649, "thokozan": 7.2746685411000005, "benevol": 3.65884865786, "also": 0.0146571578, "use": 0.0292080197316, "far": 0.536623764503, "meantim": 3.10870828737, "signi\ufb01c": 7.2746685411000005, "noth": 1.24245472939, "their": 0.015360505122700001, "system": 0.327430345585, "chapter": 1.2850238307100001, "implicit": 3.0538248303900004, "teach": 1.38277323072, "leverag": 3.5767392514699994, "race": 1.07508179126, "will": 0.202786534915, "penal": 3.3446270301700003, "statist": 1.4451883070700002, "sometim": 0.538025155343, "maurizio": 5.3958976948899995, "long": 0.235645793878, "act": 0.358945092473, "right": 0.34035985417, "men": 0.624742371425, "gain": 0.6142097989249999, "they": 0.0297269947676, "rapid": 0.965411638564, "alexandria": 3.1214834788599997, "mustn": 7.2746685411000005, "flower": 2.1192772083, "build": 0.491137452091, "reject": 1.0372320944700002, "few": 0.275577913653, "overconfid": 5.3958976948899995, "algorithm": 3.33044239518, "sell": 1.25585416107, "combin": 0.529218310751, "not": 0.0155524130075, "are": 0.0294674735827, "some": 0.0395735090645, "scrape": 4.2564634117, "becom": 0.11771217648900001, "debias": 7.2746685411000005, "thinker": 3.0524906073699998, "lead": 0.23620402986699998, "comput": 1.36806891594, "auditor": 4.18776688041, "afford": 1.95833266905, "crowd": 1.68639895357, "term": 0.33303898354600003, "write": 0.721512439877, "must": 0.653383947388, "thing": 0.8781935346799999, "for": 0.00031499039539700004, "compliant": 4.28806875111, "sold": 1.02732927261, "enabl": 1.26473915954, "say": 0.562154280552, "govern": 0.411720459754, "prison": 1.34049610661, "fail": 0.656536611573, "program": 0.7037855787649999, "scientist": 1.54634128444, "unsurpris": 4.8522822483, "often": 0.258140393351, "much": 0.17749572930100002, "just": 0.289531434109, "error": 1.7985854343, "graduat": 1.52643430388, "vulner": 2.18259291507, "where": 0.0649921387457, "day": 0.16865870631700003, "dispos": 2.34544052164, "today": 0.559395353679, "societi": 0.597356115918, "obama": 2.67588232573, "prolif": 2.95113811311, "cofound": 5.57821925168, "male": 1.24442043932, "compar": 0.6239191809269999, "deep": 1.2886734698, "under": 0.07526180538319999, "abus": 1.83817151099, "bad": 1.2221516561799999, "black": 0.667404292867, "career": 1.0944636875799998, "racial": 1.98916013285, "enter": 0.564256167492, "substanti": 1.24639002087, "said": 0.436653165815, "chief": 0.883056027166, "follow": 0.045356911094199995, "problem": 0.569140724273, "histor": 0.516151783952, "lose": 1.1265888210600001, "corpor": 1.1061995784799998, "women": 0.8404139079, "communiti": 0.673561947791, "discov": 0.924894023806, "text": 1.14048200999, "show": 0.236682766013, "sophist": 2.30296309338, "new": 0.0177299468511, "vocabulari": 3.14753415606, "may": 0.050709995284400004, "those": 0.17854939087299998, "more": 0.017024931599999998, "grant": 0.8105051365070001, "tradit": 0.47500477629199994, "ensur": 1.22751130026, "year": 0.047402238894600005, "present": 0.227546654799, "his": 0.0901772433641, "least": 0.480285584745, "run": 0.442714975539, "word": 0.585861082385, "too": 0.5965551547219999, "decid": 0.655322871893, "fanfar": 4.31597753923, "implement": 1.27437940907, "even": 0.152388564834, "lighterskin": 7.2746685411000005, "easili": 1.3066587367, "resid": 0.8732037307230001, "justic": 1.38553878874, "accur": 1.75248061485, "imposs": 1.60165772512, "repli": 1.89602878572, "allow": 0.24028061118900002, "palantir": 7.2746685411000005, "congress": 1.35138550641, "demand": 0.850831432969, "connot": 3.2907477965, "behavior": 1.71014813378, "this": 0.0037864490525, "applic": 1.23160392849, "accord": 0.243650319127, "outspoken": 3.36264553568, "winfrey": 4.8442500766, "launch": 0.942519860658, "done": 0.845975983129, "intent": 1.16118750781, "santamicon": 7.2746685411000005, "contain": 0.468845318236, "such": 0.059695977806, "test": 0.977224437103, "area": 0.327954821122, "citi": 0.326556830505, "these": 0.0715336194008, "when": 0.0205549888584, "hire": 1.60103292035, "lab": 2.66949835512, "featur": 0.423387418142, "vision": 1.58523088743, "them": 0.0941833269093, "almost": 0.42907884333400004, "effect": 0.333830227158, "net": 1.9406330919499999, "histori": 0.187550624069, "list": 0.309845761506, "psycholog": 1.89981109743, "common": 0.338325805271, "individu": 0.588013447985, "congresswoman": 5.4240685718499995, "match": 1.27190443874, "well": 0.0635144383156, "apr": 3.47408509741, "whose": 0.5510546556329999, "need": 0.362740163442, "understand": 1.0880858756799998, "singl": 0.475916769059, "influenc": 0.572373185428, "pitfal": 5.18392744417, "microsoft": 3.21265935953, "num": 0.00031499039539700004, "disciplin": 1.93582013145, "financ": 1.44813224068, "sift": 5.34183047362, "surround": 0.915723999073, "research": 0.663727818138, "suspect": 1.85051980572, "given": 0.303255810831, "equiti": 3.2284325572, "orlean": 2.7371933678900002, "insect": 3.1143660110900004, "associ": 0.28240501535100004, "guess": 3.22051485947, "femal": 1.15757304604, "born": 0.7964382285070001, "about": 0.0628434774746, "buolamwini": 7.2746685411000005, "layer": 2.0969791623500003, "trump": 4.12738636942, "horribl": 3.69621290461, "oprah": 4.73092139129, "ocasiocortez": 7.2746685411000005, "everi": 0.391485427421, "intellig": 1.43349848213, "english": 0.555765186335, "identifi": 0.833722000472, "help": 0.336207721344, "student": 0.904923236645, "unblock": 6.45368798903, "previous": 0.356602960063, "guis": 3.59263061881, "prove": 0.899024430345, "return": 0.333126868592, "googl": 2.43263122258, "inform": 0.454453704662, "bank": 1.0557062993700002, "been": 0.023645982368400004, "billion": 1.5824680307199999, "derid": 4.12738636942, "licens": 1.7575808080500002, "field": 0.5760642583510001, "assumpt": 2.2213221289200002, "predomin": 1.6742284179499998, "now": 0.149092945021, "fei": 4.93636536551, "classifi": 1.6665296351499999, "approxim": 0.7944845577770001, "soweto": 6.0616459012599995, "predict": 1.6457402376899999, "good": 0.418589404907, "she": 0.7701082216959999, "explan": 1.87322041569}, "freq": {"stereotyp": 1, "age": 1, "made": 2, "but": 4, "integr": 1, "larg": 1, "record": 3, "incom": 1, "american": 4, "leagu": 1, "opinion": 1, "suppos": 1, "pipelin": 1, "although": 1, "philosophi": 1, "name": 5, "should": 2, "great": 1, "piec": 1, "amazon": 2, "pattern": 1, "social": 1, "all": 3, "into": 1, "other": 4, "african": 2, "real": 1, "possibl": 1, "fire": 1, "and": 34, "want": 1, "clean": 1, "mani": 2, "rachel": 1, "absorb": 1, "upset": 1, "independ": 1, "giant": 1, "cours": 4, "learnt": 2, "compani": 2, "mortgag": 1, "uncool": 1, "bias": 10, "block": 1, "artifici": 2, "financi": 1, "povertystricken": 1, "tech": 4, "captur": 1, "train": 1, "scienc": 3, "impact": 1, "fals": 3, "ask": 1, "learn": 8, "internet": 2, "unpleas": 4, "from": 9, "tend": 1, "comment": 1, "first": 1, "whilst": 1, "underprepar": 1, "open": 1, "patient": 1, "exclus": 1, "evalu": 1, "credit": 2, "unlik": 1, "decisiontre": 1, "general": 1, "call": 1, "embrac": 1, "type": 2, "ani": 1, "frequenc": 1, "last": 2, "knew": 1, "than": 4, "buy": 1, "who": 5, "decis": 5, "billionair": 1, "divers": 2, "work": 2, "alleg": 1, "have": 7, "togeth": 1, "don": 1, "between": 1, "properti": 1, "make": 8, "potenti": 1, "account": 1, "recognit": 1, "member": 3, "conserv": 1, "box": 1, "dure": 1, "appli": 1, "institut": 3, "creat": 1, "human": 6, "valley": 1, "peopl": 5, "appeal": 1, "data": 10, "discrimin": 1, "technolog": 5, "inclus": 2, "correl": 1, "advoc": 1, "process": 1, "prejud": 1, "event": 1, "expert": 1, "civil": 1, "start": 1, "san": 1, "mugshot": 1, "univers": 1, "time": 2, "joy": 4, "web": 1, "weapon": 1, "brilliant": 1, "way": 1, "achiev": 1, "itself": 1, "silicon": 1, "one": 2, "were": 3, "huge": 1, "poor": 3, "machin": 6, "paper": 1, "against": 3, "someon": 1, "that": 25, "perform": 2, "polic": 4, "reason": 1, "instanc": 1, "straightforward": 1, "determin": 1, "centric": 2, "fit": 1, "former": 1, "loan": 3, "rate": 1, "hard": 1, "can": 6, "includ": 1, "million": 2, "requir": 1, "thoma": 1, "africanamerican": 1, "insuffici": 1, "while": 1, "soar": 1, "regular": 1, "same": 1, "transpar": 1, "regul": 1, "peter": 1, "cloud": 1, "spend": 1, "plenti": 1, "press": 2, "yet": 1, "result": 3, "base": 1, "fair": 1, "optimist": 1, "homogen": 1, "has": 13, "fastai": 1, "becaus": 4, "approv": 2, "faculti": 1, "lawyer": 1, "agenc": 1, "high": 1, "secret": 1, "depart": 1, "serena": 1, "written": 1, "blind": 1, "number": 1, "uncov": 1, "current": 1, "founder": 1, "over": 1, "outperform": 1, "kit": 2, "michell": 1, "racist": 2, "take": 1, "appear": 1, "gender": 4, "topic": 1, "had": 1, "neutral": 1, "like": 7, "world": 1, "face": 5, "famili": 1, "six": 1, "motto": 1, "get": 1, "york": 1, "posit": 3, "best": 1, "autom": 1, "neural": 1, "better": 3, "sure": 1, "what": 3, "reduc": 1, "pleasant": 2, "final": 1, "the": 46, "let": 1, "european": 1, "differ": 2, "francisco": 1, "him": 1, "whi": 1, "william": 1, "mainstream": 1, "exampl": 1, "certain": 1, "mit": 2, "taken": 1, "thiel": 1, "wors": 1, "martin": 1, "how": 5, "signific": 1, "with": 5, "humancent": 1, "ethic": 1, "there": 1, "task": 4, "similar": 1, "effort": 1, "inspect": 1, "most": 3, "plan": 1, "desper": 1, "risk": 2, "neighborhood": 2, "stanford": 1, "group": 1, "darkerskin": 1, "publish": 2, "creditworthi": 1, "past": 1, "extern": 1, "crawl": 1, "hivneg": 1, "criteria": 1, "through": 1, "background": 1, "recent": 2, "luther": 1, "anoth": 1, "penetr": 1, "howev": 2, "address": 1, "corpus": 1, "peek": 1, "surprir": 1, "mirror": 1, "king": 1, "donor": 1, "council": 1, "found": 4, "usual": 1, "amid": 1, "thokozan": 1, "benevol": 1, "also": 2, "use": 9, "far": 1, "meantim": 1, "signi\ufb01c": 1, "noth": 1, "their": 5, "system": 7, "chapter": 1, "implicit": 2, "teach": 1, "leverag": 1, "race": 1, "will": 2, "penal": 1, "statist": 2, "sometim": 1, "maurizio": 1, "long": 1, "act": 1, "right": 2, "men": 1, "gain": 1, "they": 7, "rapid": 1, "alexandria": 1, "mustn": 1, "flower": 1, "build": 1, "reject": 2, "few": 2, "overconfid": 1, "algorithm": 13, "sell": 1, "combin": 1, "not": 4, "are": 11, "some": 2, "scrape": 1, "becom": 1, "debias": 1, "thinker": 1, "lead": 1, "comput": 5, "auditor": 1, "afford": 1, "crowd": 1, "term": 2, "write": 1, "must": 1, "thing": 2, "for": 11, "compliant": 1, "sold": 1, "enabl": 1, "say": 1, "govern": 2, "prison": 1, "fail": 2, "program": 1, "scientist": 2, "unsurpris": 1, "often": 1, "much": 2, "just": 1, "error": 3, "graduat": 1, "vulner": 2, "where": 1, "day": 2, "dispos": 1, "today": 2, "societi": 1, "obama": 1, "prolif": 1, "cofound": 1, "male": 2, "compar": 1, "deep": 2, "under": 1, "abus": 1, "bad": 1, "black": 3, "career": 1, "racial": 4, "enter": 1, "substanti": 1, "said": 1, "chief": 1, "follow": 3, "problem": 3, "histor": 1, "lose": 1, "corpor": 1, "women": 2, "communiti": 1, "discov": 1, "text": 1, "show": 2, "sophist": 1, "new": 4, "vocabulari": 1, "may": 3, "those": 1, "more": 9, "grant": 1, "tradit": 2, "ensur": 1, "year": 3, "present": 1, "his": 2, "least": 1, "run": 1, "word": 4, "too": 1, "decid": 2, "fanfar": 1, "implement": 1, "even": 2, "lighterskin": 1, "easili": 2, "resid": 1, "justic": 1, "accur": 1, "imposs": 1, "repli": 1, "allow": 1, "palantir": 1, "congress": 1, "demand": 1, "connot": 1, "behavior": 1, "this": 6, "applic": 10, "accord": 1, "outspoken": 1, "winfrey": 1, "launch": 1, "done": 1, "intent": 1, "santamicon": 1, "contain": 1, "such": 3, "test": 2, "area": 1, "citi": 1, "these": 3, "when": 2, "hire": 2, "lab": 3, "featur": 1, "vision": 1, "them": 2, "almost": 1, "effect": 1, "net": 1, "histori": 1, "list": 1, "psycholog": 2, "common": 1, "individu": 1, "congresswoman": 1, "match": 1, "well": 1, "apr": 1, "whose": 1, "need": 5, "understand": 2, "singl": 1, "influenc": 1, "pitfal": 1, "microsoft": 1, "num": 7, "disciplin": 1, "financ": 1, "sift": 1, "surround": 1, "research": 3, "suspect": 1, "given": 1, "equiti": 1, "orlean": 1, "insect": 1, "associ": 5, "guess": 1, "femal": 2, "born": 1, "about": 5, "buolamwini": 4, "layer": 1, "trump": 1, "horribl": 1, "oprah": 1, "ocasiocortez": 1, "everi": 1, "intellig": 2, "english": 1, "identifi": 2, "help": 1, "student": 1, "unblock": 1, "previous": 1, "guis": 1, "prove": 1, "return": 2, "googl": 1, "inform": 1, "bank": 3, "been": 6, "billion": 1, "derid": 1, "licens": 2, "field": 1, "assumpt": 1, "predomin": 1, "now": 1, "fei": 2, "classifi": 1, "approxim": 1, "soweto": 1, "predict": 2, "good": 2, "she": 2, "explan": 1}, "logtfidf": {"stereotyp": 2.96082341885, "age": 0.39624845300300005, "made": 0.1360430521946, "but": 0.0647694882876, "integr": 1.03865482279, "larg": 0.17037506060600002, "record": 1.059031070859, "incom": 1.3660916537999999, "american": 1.099657374488, "leagu": 1.2759575854799998, "opinion": 1.33617333331, "suppos": 1.44225301477, "pipelin": 3.47002829672, "although": 0.139487981418, "philosophi": 1.73091256097, "name": 0.4861658319215001, "should": 1.018839753516, "great": 0.235805258079, "piec": 1.17598157639, "amazon": 7.00172643298, "pattern": 1.33282404788, "social": 0.688371502261, "all": 0.03420789629339999, "into": 0.0149128632287, "other": 0.03949899167904, "african": 2.66947310292, "real": 0.824629060574, "possibl": 0.348805474891, "fire": 0.749239069835, "and": 0.0021416648301624, "want": 0.6916366062549999, "clean": 1.9271282036300001, "mani": 0.0866315162442, "rachel": 3.1300918533999997, "absorb": 1.92237965165, "upset": 2.5496971553, "independ": 0.463424162503, "giant": 1.83028503479, "cours": 3.063597616532, "learnt": 8.08270406416, "compani": 0.879554506194, "mortgag": 3.70130197411, "uncool": 7.2746685411000005, "bias": 26.1984276467, "block": 1.16400781588, "artifici": 4.23645798036, "financi": 0.958817483446, "povertystricken": 7.2746685411000005, "tech": 11.814202638080001, "captur": 1.0578810012100002, "train": 0.660918312839, "scienc": 2.524308536673, "impact": 1.09033222631, "fals": 5.4814433319299996, "ask": 0.776797209847, "learn": 6.74201651796, "internet": 3.2127124918, "unpleas": 14.94011043528, "from": 0.005103487519794, "tend": 1.21597024462, "comment": 1.11826753454, "first": 0.0075872898121599995, "whilst": 2.13353675808, "underprepar": 7.2746685411000005, "open": 0.219591038029, "patient": 2.25618533471, "exclus": 1.22643707092, "evalu": 1.9388802431299998, "credit": 2.22577202176, "unlik": 0.885954358842, "decisiontre": 7.2746685411000005, "general": 0.114952578063, "call": 0.0654627744488, "embrac": 2.13513377732, "type": 1.414202970774, "ani": 0.125608358366, "frequenc": 2.1759113757299997, "last": 0.38408728922200003, "knew": 1.6359904042, "than": 0.1290434488728, "buy": 1.6340517929299998, "who": 0.30450116492949997, "decis": 3.8505411084799994, "billionair": 4.12348772901, "divers": 2.75852891038, "work": 0.218069134546, "alleg": 1.33689249911, "have": 0.1034950163884, "togeth": 0.458032237308, "don": 1.7963049316, "between": 0.033953681165299995, "properti": 0.953573289192, "make": 0.5879812625831999, "potenti": 0.9245764122419999, "account": 0.665074289973, "recognit": 1.4816549327200002, "member": 0.834460243797, "conserv": 1.19994966588, "box": 1.41751491115, "dure": 0.0491209066894, "appli": 0.8316941898119999, "institut": 1.7285289660089997, "creat": 0.222576818514, "human": 3.840211099458, "valley": 1.4390606736700002, "peopl": 0.9663278923649999, "appeal": 1.2978562707799999, "data": 12.168205848, "discrimin": 2.37006739018, "technolog": 4.784238431775, "inclus": 4.3396512063, "correl": 2.57915918803, "advoc": 1.4950479900600002, "process": 0.527829199025, "prejud": 5.04759100062, "event": 0.428982108147, "expert": 1.68029517063, "civil": 0.7433934307629999, "start": 0.236443369291, "san": 1.1943193726299999, "mugshot": 7.2746685411000005, "univers": 0.222262105686, "time": 0.0224230377252, "joy": 10.2376868208, "web": 1.6431309733200001, "weapon": 1.51978976116, "brilliant": 2.6897010624299997, "way": 0.19809150993500002, "achiev": 0.6270980851169999, "itself": 0.5570837229510001, "silicon": 3.46196373688, "one": 0.012510703291, "were": 0.07287343104329999, "huge": 1.47916358195, "poor": 2.653741253115, "machin": 8.35415748372, "paper": 0.979402539665, "against": 0.7644085532339999, "someon": 1.59635928666, "that": 0.099403709491, "perform": 0.85236170116, "polic": 4.58960981136, "reason": 0.544301552962, "instanc": 1.18089357972, "straightforward": 3.3234248225200003, "determin": 0.772833019022, "centric": 12.54273286448, "fit": 1.2151206268899999, "former": 0.308301359655, "loan": 6.3343266731100005, "rate": 0.761033872166, "hard": 1.00522796406, "can": 0.974046578364, "includ": 0.0188846813905, "million": 1.0938205001880001, "requir": 0.424253510675, "thoma": 0.874109117838, "africanamerican": 7.1076144564399995, "insuffici": 2.3898026343, "while": 0.04324998379380001, "soar": 3.30266283107, "regular": 0.739163417847, "same": 0.112059649604, "transpar": 2.76480853492, "regul": 1.3577316346200001, "peter": 0.850536491217, "cloud": 2.36268232808, "spend": 1.42534376116, "plenti": 2.8569238238300003, "press": 0.69065938091, "yet": 0.754181309241, "result": 0.40913672514300004, "base": 0.13652330228700002, "fair": 1.16481508131, "optimist": 3.47002829672, "homogen": 3.2739688793700004, "has": 0.5554112831124001, "fastai": 7.2746685411000005, "becaus": 0.5573726353, "approv": 2.1013006234400002, "faculti": 2.38911558515, "lawyer": 1.93494753105, "agenc": 1.25254253424, "high": 0.13782378654000002, "secret": 1.13556799519, "depart": 0.68887313257, "serena": 5.02817291476, "written": 0.671587369833, "blind": 2.1803607712799997, "number": 0.0966085784186, "uncov": 2.69528247227, "current": 0.42695282784500005, "founder": 1.3946435557299999, "over": 0.0249367214957, "outperform": 4.409873625, "kit": 5.7292577404, "michell": 3.26238893194, "racist": 6.528070045680001, "take": 0.130691962197, "appear": 0.278735898493, "gender": 8.976922478839999, "topic": 1.6969991554100001, "had": 0.0464780244111, "neutral": 1.9432681395900002, "like": 0.973375035815, "world": 0.107420248621, "face": 2.948011856285, "famili": 0.39746619471100003, "six": 0.441636808318, "motto": 3.08777242152, "get": 0.579769005782, "york": 0.42762879716200003, "posit": 0.9499569558240001, "best": 0.459227932947, "autom": 2.9867028668299995, "neural": 4.0853151555, "better": 2.0892838218, "sure": 2.0086865552, "what": 0.677661890481, "reduc": 0.686617775143, "pleasant": 6.15356659988, "final": 0.292733863948, "the": 0.0, "let": 1.2488025672799998, "european": 0.674427053203, "differ": 0.424642242624, "francisco": 1.6665296351499999, "him": 0.49124039099699995, "whi": 1.18068843047, "william": 0.562375323877, "mainstream": 2.0082171818, "exampl": 0.40868267499899996, "certain": 0.592104362781, "mit": 5.630099502719999, "taken": 0.470759772949, "thiel": 5.721320095319999, "wors": 2.26040347896, "martin": 1.12425962746, "how": 2.3578347846500005, "signific": 0.373571744332, "with": 0.00598745856695, "humancent": 7.2746685411000005, "ethic": 2.19044489035, "there": 0.0400978929255, "task": 5.42994722644, "similar": 0.318556092114, "effort": 0.637887211057, "inspect": 2.46396347594, "most": 0.06224368888679999, "plan": 0.428982108147, "desper": 2.4654449577, "risk": 2.8200096817799998, "neighborhood": 4.27453422292, "stanford": 2.53369681396, "group": 0.190594534797, "darkerskin": 7.2746685411000005, "publish": 0.627951730934, "creditworthi": 6.7821920560099995, "past": 0.7016234157610001, "extern": 1.6565760028799998, "crawl": 3.8465637065199996, "hivneg": 7.2746685411000005, "criteria": 2.4632235573, "through": 0.0683586918849, "background": 1.3931203261899998, "recent": 0.868827482576, "luther": 2.9109910451, "anoth": 0.127896361652, "penetr": 2.35801098158, "howev": 0.180630234695, "address": 1.05137103247, "corpus": 3.1818402794, "peek": 5.0774439637699995, "surprir": 7.2746685411000005, "mirror": 2.0214436382, "king": 0.707101485387, "donor": 3.2412327319700003, "council": 0.906013664357, "found": 0.431364496192, "usual": 0.545279017064, "amid": 2.68046738649, "thokozan": 7.2746685411000005, "benevol": 3.65884865786, "also": 0.0293143156, "use": 0.2628721775844, "far": 0.536623764503, "meantim": 3.10870828737, "signi\ufb01c": 7.2746685411000005, "noth": 1.24245472939, "their": 0.07680252561350001, "system": 2.292012419095, "chapter": 1.2850238307100001, "implicit": 6.107649660780001, "teach": 1.38277323072, "leverag": 3.5767392514699994, "race": 1.07508179126, "will": 0.40557306983, "penal": 3.3446270301700003, "statist": 2.8903766141400005, "sometim": 0.538025155343, "maurizio": 5.3958976948899995, "long": 0.235645793878, "act": 0.358945092473, "right": 0.68071970834, "men": 0.624742371425, "gain": 0.6142097989249999, "they": 0.20808896337320001, "rapid": 0.965411638564, "alexandria": 3.1214834788599997, "mustn": 7.2746685411000005, "flower": 2.1192772083, "build": 0.491137452091, "reject": 2.0744641889400004, "few": 0.551155827306, "overconfid": 5.3958976948899995, "algorithm": 43.29575113734, "sell": 1.25585416107, "combin": 0.529218310751, "not": 0.06220965203, "are": 0.3241422094097, "some": 0.079147018129, "scrape": 4.2564634117, "becom": 0.11771217648900001, "debias": 7.2746685411000005, "thinker": 3.0524906073699998, "lead": 0.23620402986699998, "comput": 6.8403445797, "auditor": 4.18776688041, "afford": 1.95833266905, "crowd": 1.68639895357, "term": 0.6660779670920001, "write": 0.721512439877, "must": 0.653383947388, "thing": 1.7563870693599999, "for": 0.0034648943493670007, "compliant": 4.28806875111, "sold": 1.02732927261, "enabl": 1.26473915954, "say": 0.562154280552, "govern": 0.823440919508, "prison": 1.34049610661, "fail": 1.313073223146, "program": 0.7037855787649999, "scientist": 3.09268256888, "unsurpris": 4.8522822483, "often": 0.258140393351, "much": 0.35499145860200004, "just": 0.289531434109, "error": 5.395756302900001, "graduat": 1.52643430388, "vulner": 4.36518583014, "where": 0.0649921387457, "day": 0.33731741263400006, "dispos": 2.34544052164, "today": 1.118790707358, "societi": 0.597356115918, "obama": 2.67588232573, "prolif": 2.95113811311, "cofound": 5.57821925168, "male": 2.48884087864, "compar": 0.6239191809269999, "deep": 2.5773469396, "under": 0.07526180538319999, "abus": 1.83817151099, "bad": 1.2221516561799999, "black": 2.002212878601, "career": 1.0944636875799998, "racial": 7.9566405314, "enter": 0.564256167492, "substanti": 1.24639002087, "said": 0.436653165815, "chief": 0.883056027166, "follow": 0.1360707332826, "problem": 1.707422172819, "histor": 0.516151783952, "lose": 1.1265888210600001, "corpor": 1.1061995784799998, "women": 1.6808278158, "communiti": 0.673561947791, "discov": 0.924894023806, "text": 1.14048200999, "show": 0.473365532026, "sophist": 2.30296309338, "new": 0.0709197874044, "vocabulari": 3.14753415606, "may": 0.1521299858532, "those": 0.17854939087299998, "more": 0.15322438439999997, "grant": 0.8105051365070001, "tradit": 0.9500095525839999, "ensur": 1.22751130026, "year": 0.14220671668380003, "present": 0.227546654799, "his": 0.1803544867282, "least": 0.480285584745, "run": 0.442714975539, "word": 2.34344432954, "too": 0.5965551547219999, "decid": 1.310645743786, "fanfar": 4.31597753923, "implement": 1.27437940907, "even": 0.304777129668, "lighterskin": 7.2746685411000005, "easili": 2.6133174734, "resid": 0.8732037307230001, "justic": 1.38553878874, "accur": 1.75248061485, "imposs": 1.60165772512, "repli": 1.89602878572, "allow": 0.24028061118900002, "palantir": 7.2746685411000005, "congress": 1.35138550641, "demand": 0.850831432969, "connot": 3.2907477965, "behavior": 1.71014813378, "this": 0.022718694315, "applic": 12.3160392849, "accord": 0.243650319127, "outspoken": 3.36264553568, "winfrey": 4.8442500766, "launch": 0.942519860658, "done": 0.845975983129, "intent": 1.16118750781, "santamicon": 7.2746685411000005, "contain": 0.468845318236, "such": 0.179087933418, "test": 1.954448874206, "area": 0.327954821122, "citi": 0.326556830505, "these": 0.2146008582024, "when": 0.0411099777168, "hire": 3.2020658407, "lab": 8.00849506536, "featur": 0.423387418142, "vision": 1.58523088743, "them": 0.1883666538186, "almost": 0.42907884333400004, "effect": 0.333830227158, "net": 1.9406330919499999, "histori": 0.187550624069, "list": 0.309845761506, "psycholog": 3.79962219486, "common": 0.338325805271, "individu": 0.588013447985, "congresswoman": 5.4240685718499995, "match": 1.27190443874, "well": 0.0635144383156, "apr": 3.47408509741, "whose": 0.5510546556329999, "need": 1.81370081721, "understand": 2.1761717513599996, "singl": 0.475916769059, "influenc": 0.572373185428, "pitfal": 5.18392744417, "microsoft": 3.21265935953, "num": 0.0022049327677790003, "disciplin": 1.93582013145, "financ": 1.44813224068, "sift": 5.34183047362, "surround": 0.915723999073, "research": 1.991183454414, "suspect": 1.85051980572, "given": 0.303255810831, "equiti": 3.2284325572, "orlean": 2.7371933678900002, "insect": 3.1143660110900004, "associ": 1.4120250767550002, "guess": 3.22051485947, "femal": 2.31514609208, "born": 0.7964382285070001, "about": 0.31421738737300003, "buolamwini": 29.098674164400002, "layer": 2.0969791623500003, "trump": 4.12738636942, "horribl": 3.69621290461, "oprah": 4.73092139129, "ocasiocortez": 7.2746685411000005, "everi": 0.391485427421, "intellig": 2.86699696426, "english": 0.555765186335, "identifi": 1.667444000944, "help": 0.336207721344, "student": 0.904923236645, "unblock": 6.45368798903, "previous": 0.356602960063, "guis": 3.59263061881, "prove": 0.899024430345, "return": 0.666253737184, "googl": 2.43263122258, "inform": 0.454453704662, "bank": 3.1671188981100005, "been": 0.14187589421040003, "billion": 1.5824680307199999, "derid": 4.12738636942, "licens": 3.5151616161000003, "field": 0.5760642583510001, "assumpt": 2.2213221289200002, "predomin": 1.6742284179499998, "now": 0.149092945021, "fei": 9.87273073102, "classifi": 1.6665296351499999, "approxim": 0.7944845577770001, "soweto": 6.0616459012599995, "predict": 3.2914804753799998, "good": 0.837178809814, "she": 1.5402164433919998, "explan": 1.87322041569}}, "url": "https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de", "html": "<!DOCTYPE html>\n<html xmlns:cc=\"http://creativecommons.org/ns#\"><head prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#\"><meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/><meta content=\"width=device-width, initial-scale=1.0, viewport-fit=contain\" name=\"viewport\"/><title>Is Artificial Intelligence Racist? \u2013 Towards Data Science</title><link href=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" rel=\"canonical\"/><meta content=\"Is Artificial Intelligence Racist? \u2013 Towards Data Science\" name=\"title\"/><meta content=\"origin\" name=\"referrer\"/><meta content=\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New York City. She was of course derided the following day by\u2026\" name=\"description\"/><meta content=\"#000000\" name=\"theme-color\"/><meta content=\"Is Artificial Intelligence Racist?\" property=\"og:title\"/><meta content=\"Is Artificial Intelligence Racist?\" property=\"twitter:title\"/><meta content=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" property=\"og:url\"/><meta content=\"https://cdn-images-1.medium.com/max/1200/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\" property=\"og:image\"/><meta content=\"542599432471018\" property=\"fb:app_id\"/><meta content=\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New\u2026\" property=\"og:description\"/><meta content=\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New\u2026\" name=\"twitter:description\"/><meta content=\"https://cdn-images-1.medium.com/max/1200/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\" name=\"twitter:image:src\"/><link href=\"https://plus.google.com/103654360130207659246\" rel=\"publisher\"/><link href=\"https://towardsdatascience.com/@mauriziosantamicone\" rel=\"author\"/><meta content=\"Maurizio Santamicone\" name=\"author\"/><meta content=\"article\" property=\"og:type\"/><meta content=\"summary_large_image\" name=\"twitter:card\"/><meta content=\"https://www.facebook.com/towardsdatascience\" property=\"article:publisher\"/><meta content=\"10155520971186573\" property=\"article:author\"/><meta content=\"index, follow\" name=\"robots\"/><meta content=\"2019-04-02T15:11:15.062Z\" property=\"article:published_time\"/><meta content=\"@santamm\" name=\"twitter:creator\"/><meta content=\"@TDataScience\" name=\"twitter:site\"/><meta content=\"Towards Data Science\" property=\"og:site_name\"/><meta name=\"twitter:label1\" value=\"Reading time\"/><meta name=\"twitter:data1\" value=\"6 min read\"/><meta content=\"Medium\" name=\"twitter:app:name:iphone\"/><meta content=\"828256236\" name=\"twitter:app:id:iphone\"/><meta content=\"medium://p/66ea8f67c7de\" name=\"twitter:app:url:iphone\"/><meta content=\"Medium\" property=\"al:ios:app_name\"/><meta content=\"828256236\" property=\"al:ios:app_store_id\"/><meta content=\"com.medium.reader\" property=\"al:android:package\"/><meta content=\"Medium\" property=\"al:android:app_name\"/><meta content=\"medium://p/66ea8f67c7de\" property=\"al:ios:url\"/><meta content=\"medium://p/66ea8f67c7de\" property=\"al:android:url\"/><meta content=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" property=\"al:web:url\"/><link href=\"/osd.xml\" rel=\"search\" title=\"Medium\" type=\"application/opensearchdescription+xml\"><link href=\"android-app://com.medium.reader/https/medium.com/p/66ea8f67c7de\" rel=\"alternate\"><script type=\"application/ld+json\">{\"@context\":\"http://schema.org\",\"@type\":\"NewsArticle\",\"image\":{\"@type\":\"ImageObject\",\"width\":860,\"height\":460,\"url\":\"https://cdn-images-1.medium.com/max/1720/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\"},\"url\":\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\",\"dateCreated\":\"2019-04-02T15:11:15.062Z\",\"datePublished\":\"2019-04-02T15:11:15.062Z\",\"dateModified\":\"2019-04-03T13:35:22.053Z\",\"headline\":\"Is Artificial Intelligence Racist?\",\"name\":\"Is Artificial Intelligence Racist?\",\"articleId\":\"66ea8f67c7de\",\"thumbnailUrl\":\"https://cdn-images-1.medium.com/max/1720/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\",\"keywords\":[\"Tag:Artificial Intelligence\",\"Tag:Ethical Ai\",\"Tag:Accountable Ai\",\"Tag:Racism\",\"Tag:Bias\",\"Topic:Artificial Intelligence\",\"Topic:Race\",\"Publication:towards-data-science\",\"LockedPostSource:1\",\"Elevated:false\",\"LayerCake:3\"],\"author\":{\"@type\":\"Person\",\"name\":\"Maurizio Santamicone\",\"url\":\"https://towardsdatascience.com/@mauriziosantamicone\"},\"creator\":[\"Maurizio Santamicone\"],\"publisher\":{\"@type\":\"Organization\",\"name\":\"Towards Data Science\",\"url\":\"https://towardsdatascience.com\",\"logo\":{\"@type\":\"ImageObject\",\"width\":161,\"height\":60,\"url\":\"https://cdn-images-1.medium.com/max/322/1*5EUO1kUYBthpOCPzRj_l2g.png\"}},\"mainEntityOfPage\":\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\"}</script><meta content=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" name=\"parsely-link\"/><link class=\"js-glyph-\" href=\"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css\" id=\"glyph-8\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://cdn-static-1.medium.com/_/fp/css/main-branding-base.sMRbh_65n82B91860QdvTg.css\" rel=\"stylesheet\"/><script>!function(n,e){var t,o,i,c=[],f={passive:!0,capture:!0},r=new Date,a=\"pointerup\",u=\"pointercancel\";function p(n,c){t||(t=c,o=n,i=new Date,w(e),s())}function s(){o>=0&&o<i-r&&(c.forEach(function(n){n(o,t)}),c=[])}function l(t){if(t.cancelable){var o=(t.timeStamp>1e12?new Date:performance.now())-t.timeStamp;\"pointerdown\"==t.type?function(t,o){function i(){p(t,o),r()}function c(){r()}function r(){e(a,i,f),e(u,c,f)}n(a,i,f),n(u,c,f)}(o,t):p(o,t)}}function w(n){[\"click\",\"mousedown\",\"keydown\",\"touchstart\",\"pointerdown\"].forEach(function(e){n(e,l,f)})}w(n),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){c.push(n),s()}}(addEventListener,removeEventListener);</script><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener(\"error\", _onerror, true); else if (document.attachEvent) document.attachEvent(\"onerror\", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName(\"script\")[0], s = d.createElement(\"script\"); s.type = \"text/javascript\"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName(\"script\")[0], s = d.createElement(\"link\"); s.rel = \"stylesheet\"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = \"/_/stat?event=pixel.load&origin=\" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga(\"create\", \"UA-24232453-2\", \"auto\", {\"allowLinker\": true, \"legacyCookieDomain\": window.location.hostname}); ga(\"send\", \"pageview\");ga(\"create\", \"UA-19707169-24\", \"auto\", 'tracker0'); ga(\"tracker0.send\", \"pageview\");</script><script async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><!--[if lt IE 9]><script charset=\"UTF-8\" src=\"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js\"></script><![endif]--><link class=\"js-favicon\" href=\"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico\" rel=\"icon\"/><link href=\"https://cdn-images-1.medium.com/fit/c/304/304/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\" rel=\"apple-touch-icon\" sizes=\"152x152\"/><link href=\"https://cdn-images-1.medium.com/fit/c/240/240/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\" rel=\"apple-touch-icon\" sizes=\"120x120\"/><link href=\"https://cdn-images-1.medium.com/fit/c/152/152/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\" rel=\"apple-touch-icon\" sizes=\"76x76\"/><link href=\"https://cdn-images-1.medium.com/fit/c/120/120/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\" rel=\"apple-touch-icon\" sizes=\"60x60\"/><link color=\"#171717\" href=\"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg\" rel=\"mask-icon\"/></link></link></link></head><body class=\"postShowScreen browser-chrome os-windows is-withMagicUnderlines v-glyph v-glyph--m2 is-noJs\" itemscope=\"\"><script>document.body.className = document.body.className.replace(/(^|\\s)is-noJs(\\s|$)/, \"$1is-js$2\")</script><div class=\"site-main\" id=\"container\"><div class=\"butterBar butterBar--error\"></div><div class=\"surface\"><div class=\"screenContent\" id=\"prerendered\"><canvas class=\"canvas-renderer\"></canvas><div class=\"container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer\"></div><div class=\"metabar u-clearfix u-boxShadow4px12pxBlackLighter u-textColorTransparentWhiteDarker u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth js-metabar\"><div class=\"branch-journeys-top\"></div><div class=\"js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20\"><div class=\"metabar-block u-flex1 u-flexCenter\"><div class=\"u-xs-hide js-metabarLogoLeft\"><a class=\"siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0\" data-log-event=\"home\" href=\"https://medium.com/\"><span class=\"svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0\"><svg class=\"svgIcon-use\" height=\"45\" width=\"45\"><path d=\"M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z\"></path></svg></span><span class=\"u-textScreenReader\">Homepage</span></a></div><div class=\"u-xs-show js-metabarLogoLeft\"><a class=\"siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0\" data-log-event=\"home\" href=\"https://medium.com/\"><span class=\"svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0\"><svg class=\"svgIcon-use\" height=\"45\" width=\"45\"><path d=\"M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z\"></path></svg></span><span class=\"u-textScreenReader\">Homepage</span></a></div></div><div class=\"metabar-block u-flex0 u-flexCenter\"><div class=\"u-flexCenter u-height65 u-xs-height56\"><div class=\"buttonSet buttonSet--wide u-lineHeightInherit\"><a class=\"button button--primary button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton\" data-action=\"sign-in-prompt\" data-action-source=\"--------------------------nav_reg\" data-redirect=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" href=\"https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhttps-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de&amp;source=--------------------------nav_reg&amp;operation=login\">Sign in</a><a class=\"button button--primary button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton\" data-action=\"sign-up-prompt\" data-action-source=\"--------------------------nav_reg\" data-redirect=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" href=\"https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhttps-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de&amp;source=--------------------------nav_reg&amp;operation=register\">Get started</a></div></div></div></div><div class=\"u-tintBgColor u-tintSpectrum\"><div class=\"metabar-inner u-marginAuto u-maxWidth1032 u-paddingHorizontal20 js-metabarBottom\"><nav class=\"metabar-block metabar-block--below u-flexCenter u-overflowHidden u-height54\" role=\"navigation\"><div class=\"u-flexCenter u-overflowHidden\"><div class=\"u-marginRight40\"><a class=\"u-flexCenter js-collectionLogoOrName\" href=\"https://towardsdatascience.com?source=logo-lo_6G8DpQ9xFsFp---7f60cf5620c9\"><img alt=\"Towards Data Science\" height=\"36\" src=\"https://cdn-images-1.medium.com/letterbox/194/72/50/50/1*5EUO1kUYBthpOCPzRj_l2g.png?source=logoAvatar-lo_6G8DpQ9xFsFp---7f60cf5620c9\" width=\"97\"/></a></div><div class=\"u-overflowHidden u-xs-hide\"><ul class=\"u-textAlignLeft u-noWrap u-overflowX u-height80 u-marginTop40 js-collectionNavItems\"><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/data-science/home\">Data Science</a></li><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/machine-learning/home\">Machine Learning</a></li><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/programming/home\">Programming</a></li><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/data-visualization/home\">Visualization</a></li><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/artificial-intelligence/home\">AI</a></li><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/data-journalism/home\">Journalism</a></li><li class=\"metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/editors-picks/home\">Picks</a></li><span class=\"u-borderLeft1 u-baseColor--borderLight\"></span><li class=\"metabar-navItem js-collectionNavItem is-external u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10\"><a class=\"link link--darkenOnHover u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink\" href=\"https://towardsdatascience.com/contribute/home\" rel=\"nofollow noopener\" target=\"_blank\">Contribute</a></li></ul></div></div></nav></div></div></div><div class=\"metabar metabar--spacer js-metabarSpacer u-tintBgColor u-height119 u-xs-height110\"></div><main role=\"main\"><article class=\"u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40\" lang=\"en\"><div class=\"postArticle-content js-postField js-notesSource js-trackPostScrolls\" data-collection-id=\"7f60cf5620c9\" data-post-id=\"66ea8f67c7de\" data-source=\"post_page\" data-tracking-context=\"postPage\"><section class=\"section section--body section--first section--last\" name=\"2ee2\"><div class=\"section-divider\"><hr class=\"section-divider\"/></div><div class=\"section-content\"><div class=\"section-inner sectionLayout--insetColumn\"><h1 class=\"graf graf--h3 graf--leading graf--title\" id=\"7b98\" name=\"7b98\">Is Artificial Intelligence Racist?</h1><h2 class=\"graf graf--h4 graf-after--h3 graf--subtitle\" id=\"82e6\" name=\"82e6\">Racial and Gender Bias in\u00a0AI</h2><div class=\"uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup\"><div class=\"u-flex0\"><a class=\"link u-baseColor--link avatar\" data-action=\"show-user-card\" data-action-source=\"post_header_lockup\" data-action-type=\"hover\" data-action-value=\"479cace88d58\" data-collection-slug=\"towards-data-science\" data-user-id=\"479cace88d58\" dir=\"auto\" href=\"https://towardsdatascience.com/@mauriziosantamicone?source=post_header_lockup\"><div class=\"u-relative u-inlineBlock u-flex0\"><img alt=\"Go to the profile of Maurizio Santamicone\" class=\"avatar-image u-size50x50\" src=\"https://cdn-images-1.medium.com/fit/c/100/100/1*9tRCoLMCijoqWB0ePvW6Wg.jpeg\"/><div class=\"avatar-halo u-absolute u-textColorGreenNormal svgIcon\" style=\"width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px\"><svg viewbox=\"0 0 70 70\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.53538374,19.9430227 C11.180401,8.78497536 22.6271155,1.6 35.3571429,1.6 C48.0871702,1.6 59.5338847,8.78497536 65.178902,19.9430227 L66.2496695,19.401306 C60.4023065,7.84329843 48.5440457,0.4 35.3571429,0.4 C22.17024,0.4 10.3119792,7.84329843 4.46461626,19.401306 L5.53538374,19.9430227 Z\"></path><path d=\"M65.178902,49.9077131 C59.5338847,61.0657604 48.0871702,68.2507358 35.3571429,68.2507358 C22.6271155,68.2507358 11.180401,61.0657604 5.53538374,49.9077131 L4.46461626,50.4494298 C10.3119792,62.0074373 22.17024,69.4507358 35.3571429,69.4507358 C48.5440457,69.4507358 60.4023065,62.0074373 66.2496695,50.4494298 L65.178902,49.9077131 Z\"></path></svg></div></div></a></div><div class=\"u-flex1 u-paddingLeft15 u-overflowHidden\"><div class=\"u-paddingBottom3\"><a class=\"ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker\" data-action=\"show-user-card\" data-action-type=\"hover\" data-action-value=\"479cace88d58\" data-collection-slug=\"towards-data-science\" data-user-id=\"479cace88d58\" dir=\"auto\" href=\"https://towardsdatascience.com/@mauriziosantamicone\">Maurizio Santamicone</a><span class=\"followState js-followState\" data-user-id=\"479cace88d58\"><button class=\"button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide\" data-action=\"sign-up-prompt\" data-action-source=\"post_header_lockup\" data-redirect=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"toggle-block-user\"><span class=\"button-label button-defaultState\">Blocked</span><span class=\"button-label button-hoverState\">Unblock</span></button><button class=\"button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide\" data-action=\"sign-up-prompt\" data-action-source=\"post_header_lockup-479cace88d58-------------------------follow_byline\" data-redirect=\"https://medium.com/_/subscribe/user/479cace88d58\" data-requires-token=\"true\" data-sign-in-action=\"toggle-subscribe-user\"><span class=\"button-label button-defaultState js-buttonLabel\">Follow</span><span class=\"button-label button-activeState\">Following</span></button></span></div><div class=\"ui-caption u-noWrapWithEllipsis js-testPostMetaInlineSupplemental\"><time datetime=\"2019-04-02T15:11:15.062Z\">Apr 2</time><span class=\"middotDivider u-fontSize12\"></span><span class=\"readingTime\" title=\"6 min read\"></span><span class=\"u-paddingLeft4\"><span class=\"svgIcon svgIcon--star svgIcon--15px\"><svg class=\"svgIcon-use\" height=\"15\" width=\"15\"><path d=\"M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z\"></path></svg></span></span></div></div></div><figure class=\"graf graf--figure graf-after--h4\" id=\"8e3a\" name=\"8e3a\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 700px; max-height: 374px;\"><div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 53.5%;\"></div><div class=\"progressiveMedia js-progressiveMedia graf-image\" data-action=\"zoom\" data-action-value=\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\" data-height=\"460\" data-image-id=\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\" data-width=\"860\"><img class=\"progressiveMedia-thumbnail js-progressiveMedia-thumbnail\" crossorigin=\"anonymous\" src=\"https://cdn-images-1.medium.com/freeze/max/60/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg?q=20\"/><canvas class=\"progressiveMedia-canvas js-progressiveMedia-canvas\"></canvas><img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1600/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\"/><noscript class=\"js-progressiveMedia-inner\"><img class=\"progressiveMedia-noscript js-progressiveMedia-inner\" src=\"https://cdn-images-1.medium.com/max/1600/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\"/></noscript></div></div></figure><p class=\"graf graf--p graf-after--figure\" id=\"40ed\" name=\"40ed\">Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://abcnews.go.com/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\" href=\"https://abcnews.go.com/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\" rel=\"noopener\" target=\"_blank\">Martin Luther King Jr. day event in New York City</a>. She was of course derided the following day by conservative commentators.</p><p class=\"graf graf--p graf-after--p\" id=\"8c81\" name=\"8c81\">But she is right.</p><p class=\"graf graf--p graf-after--p\" id=\"18b7\" name=\"18b7\"><a class=\"markup--anchor markup--p-anchor\" data-href=\"http://gendershades.org\" href=\"http://gendershades.org\" rel=\"noopener\" target=\"_blank\">Joy Buolamwini</a>, an MIT scientist and founder of the <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://www.ajlunited.org/gender-shades\" href=\"http://www.ajlunited.org/gender-shades\" rel=\"noopener\" target=\"_blank\">Algorithmic Justice League</a>, published a research that uncovered large gender and racial bias in AI systems sold by tech giants like IBM, Microsoft, and Amazon. Given the task of guessing the gender of a face, all companies performed substantially better on male faces than female faces. The error rates were no more than 1% for lighter-skinned men whilst for darker-skinned women, the errors soared to 35%. When tasked to classify the faces of Oprah Winfrey, Michelle Obama, and Serena Williams, the systems failed.</p><figure class=\"graf graf--figure graf-after--p\" id=\"3674\" name=\"3674\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 700px; max-height: 592px;\"><div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 84.6%;\"></div><div class=\"progressiveMedia js-progressiveMedia graf-image\" data-action=\"zoom\" data-action-value=\"1*s2hOVNc8SPNUjZufAOgHpg.png\" data-height=\"791\" data-image-id=\"1*s2hOVNc8SPNUjZufAOgHpg.png\" data-width=\"935\"><img class=\"progressiveMedia-thumbnail js-progressiveMedia-thumbnail\" crossorigin=\"anonymous\" src=\"https://cdn-images-1.medium.com/freeze/max/60/1*s2hOVNc8SPNUjZufAOgHpg.png?q=20\"/><canvas class=\"progressiveMedia-canvas js-progressiveMedia-canvas\"></canvas><img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1600/1*s2hOVNc8SPNUjZufAOgHpg.png\"/><noscript class=\"js-progressiveMedia-inner\"><img class=\"progressiveMedia-noscript js-progressiveMedia-inner\" src=\"https://cdn-images-1.medium.com/max/1600/1*s2hOVNc8SPNUjZufAOgHpg.png\"/></noscript></div></div><figcaption class=\"imageCaption\">License: Joy Buolamwini\u200a\u2014\u200a<a class=\"markup--anchor markup--figure-anchor\" data-href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" rel=\"noopener\" target=\"_blank\">Mit Lab Press\u00a0Kit</a></figcaption></figure><p class=\"graf graf--p graf-after--figure\" id=\"5323\" name=\"5323\">These technologies are today penetrating every layer of society. Decisions like determining who is hired, fired, granted a loan, or how long an individual spends in prison have traditionally been performed by humans. Today, they are rapidly made by algorithms or at least algorithms are used in the decision making process for such tasks.</p><p class=\"graf graf--p graf-after--p\" id=\"34d2\" name=\"34d2\">Machine learning algorithms sift through millions of pieces of data and make correlations and predictions about the world. Their appeal is huge: machines can use hard data to make decisions that are sometimes more accurate than a human\u2019s.</p><figure class=\"graf graf--figure graf-after--p\" id=\"e2ae\" name=\"e2ae\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 700px; max-height: 466px;\"><div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 66.60000000000001%;\"></div><div class=\"progressiveMedia js-progressiveMedia graf-image\" data-action=\"zoom\" data-action-value=\"1*1ffhogHj4damUCp7WdX5Jg.png\" data-height=\"616\" data-image-id=\"1*1ffhogHj4damUCp7WdX5Jg.png\" data-width=\"925\"><img class=\"progressiveMedia-thumbnail js-progressiveMedia-thumbnail\" crossorigin=\"anonymous\" src=\"https://cdn-images-1.medium.com/freeze/max/60/1*1ffhogHj4damUCp7WdX5Jg.png?q=20\"/><canvas class=\"progressiveMedia-canvas js-progressiveMedia-canvas\"></canvas><img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1600/1*1ffhogHj4damUCp7WdX5Jg.png\"/><noscript class=\"js-progressiveMedia-inner\"><img class=\"progressiveMedia-noscript js-progressiveMedia-inner\" src=\"https://cdn-images-1.medium.com/max/1600/1*1ffhogHj4damUCp7WdX5Jg.png\"/></noscript></div></div><figcaption class=\"imageCaption\">License: Joy Buolamwini\u200a\u2014\u200a<a class=\"markup--anchor markup--figure-anchor\" data-href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" rel=\"noopener\" target=\"_blank\">Mit Lab Press\u00a0Kit</a></figcaption></figure><p class=\"graf graf--p graf-after--figure\" id=\"5e9f\" name=\"5e9f\">Computer vision is used in policing, i.e. identifying suspects in a crowd. <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://www.palantir.com\" href=\"https://www.palantir.com\" rel=\"noopener\" target=\"_blank\">Palantir</a>, a company founded by tech billionaire and Trump donor Peter Thiel, has been using its predictive policing technologies in New Orleans for the last six years: this program was so secretive that even council members knew nothing about it. Amazon has been selling police departments a real time face recognition system that <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://www.buzzfeednews.com/article/daveyalba/amazon-rekognition-facial-recognition-congress-false\" href=\"https://www.buzzfeednews.com/article/daveyalba/amazon-rekognition-facial-recognition-congress-false\" rel=\"noopener\" target=\"_blank\">falsely matched 28 member of Congress with mugshots</a>. The problem with these systems is that although they are effective on general tasks, they usually return a high number of <em class=\"markup--em markup--p-em\">false positives </em>(in statistics, a false positive is when a statistical test returns a Type I error, like an HIV test resulting positive on an HIV-negative patient). Combine it with racial bias, and we get a racist policing system, independently from who is using it.</p><p class=\"graf graf--p graf-after--p\" id=\"66a4\" name=\"66a4\">The influence of bias is present in plenty of other types of data as well. For instance, a straightforward application of Machine Learning where computers outperform humans is loan approvals. Financial institutions leverage on historical data to train their algorithms over millions of records allowing them to capture patterns in the data that best identify the features of mortgage applicants.</p><p class=\"graf graf--p graf-after--p\" id=\"9d90\" name=\"9d90\">The problem is that algorithms can learn <em class=\"markup--em markup--p-em\">too much</em>. Suppose Thokozane is a brilliant graduate student from a poor Soweto neighborhood that has been working regularly for the past few years, has a clean credit record and has finally decided to apply for a loan to buy his first property. According to all the criteria traditionally used by banks to evaluate someone\u2019s creditworthiness, his application should be approved. The algorithm, however, has another plan. It has learnt in the meantime that applicants from the same poor neighborhood TK is from have in the last few years had most of their applications rejected because of poor credit records, insufficient disposable income ans so on. So TK\u2019s application is surpriringly rejected. In other words, the algorithm has learnt an <em class=\"markup--em markup--p-em\">implicit bias</em>.</p><p class=\"graf graf--p graf-after--p\" id=\"2fad\" name=\"2fad\">TK is of course reasonably upset about this, and decides to ask the bank for an explanation, as he alleges that the algorithm has discriminated racially against him. The bank of course replies that this is not possible, as the algorithms have been intentionally blinded to the race of the applicants (this assumption is optimistic). However, the problem is that while some algorithms like DecisionTrees may enable an auditor to discover if the address information was used in a way to penalize applicants who were born or previously resided in predominantly poverty-stricken areas, other algorithms like Deep Learning are much more sophisticated and tend to be a \u201cblack box\u201d to external inspection, and it may prove almost impossible to understand why, or even how, a certain decision has been taken.</p><p class=\"graf graf--p graf-after--p\" id=\"abc6\" name=\"abc6\">In 2017 a paper was published on <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://science.sciencemag.org/content/356/6334/183\" href=\"http://science.sciencemag.org/content/356/6334/183\" rel=\"noopener\" target=\"_blank\"><em class=\"markup--em markup--p-em\">Science</em></a><em class=\"markup--em markup--p-em\"> </em>that found that as a computer teaches itself English, it becomes prejudiced against black Americans and women. Using data \u201cscraped\u201d from the web called the \u201cCommon Crawl\u201d, a corpus containing approximately 840 billion words, it shows that machines can learn word associations from written texts and that these associations mirror those learned by humans, such as pleasantness and flowers or unpleasantness and insects. So far so good. But it also shows that machine learning absorbs stereotyped biases as easily as any other\u200a\u2014\u200afor example, associations between female names and family or male names and career. From bad to worse, the researchers found that names associated with being European American were signi\ufb01cantly more easily associated with pleasant than unpleasant terms, compared to some African American names.</p><p class=\"graf graf--p graf-after--p\" id=\"ec64\" name=\"ec64\">A computer builds its vocabulary using frequency data, or how often terms appear together. So it found that on the internet, African-American names are more likely to be surrounded by words that connote unpleasantness. Is that because African Americans are unpleasant? Of course not. It\u2019s because people on the internet write and say horrible things.</p><p class=\"graf graf--p graf-after--p\" id=\"17c1\" name=\"17c1\">The bias this time is not so implicit, is it?</p><h3 class=\"graf graf--h3 graf-after--p\" id=\"e696\" name=\"e696\">So what should be\u00a0done?</h3><p class=\"graf graf--p graf-after--h3\" id=\"5631\" name=\"5631\"><a class=\"markup--anchor markup--p-anchor\" data-href=\"https://youtu.be/LqjP7O9SxOM\" href=\"https://youtu.be/LqjP7O9SxOM\" rel=\"noopener\" target=\"_blank\">Rachel Thomas</a>, co-founder of <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://fast.ai\" href=\"http://fast.ai\" rel=\"noopener\" target=\"_blank\">fast.ai</a>, a deep learning lab based in San Francisco whose motto is \u201cmaking neural nets uncool\u201d, advocates for a more open and inclusive AI, that embraces people from different backgrounds and communities, people who don\u2019t \u201cfit in\u201d the current system, because they have a better understanding of how tech can be weaponized against the most vulnerable: \u201c<em class=\"markup--em markup--p-em\">We can\u2019t afford to have a tech that is run by an exclusive and homogenous group creating technology that impacts us all. We need more experts about people, like human psychology, behavior and history. AI needs more unlikely people.</em>\u201d</p><p class=\"graf graf--p graf-after--p\" id=\"bf53\" name=\"bf53\">Unsurprisingly, <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://gendershades.org/\" href=\"http://gendershades.org/\" rel=\"noopener\" target=\"_blank\">Joy Buolamwini</a> has a similar opinion: \u201c<em class=\"markup--em markup--p-em\">Data centric technologies are vulnerable to bias and abuse. As a result, we must demand more transparency and accountability. We have entered the age of automation overconfident yet underprepared. If we fail to make an ethical and inclusive AI, we risk losing gains made in civil rights and gender equity under the guise of machine neutrality.</em>\u201d</p><h3 class=\"graf graf--h3 graf-after--p\" id=\"69a8\" name=\"69a8\">So what is \u201cmainstream AI\u201d doing about\u00a0it?</h3><p class=\"graf graf--p graf-after--h3\" id=\"79cc\" name=\"79cc\">Let\u2019s take a peek at the Silicon Valley.</p><p class=\"graf graf--p graf-after--p\" id=\"9d69\" name=\"9d69\">Stanford University recently launched amid great fanfare the <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://hai.stanford.edu/\" href=\"https://hai.stanford.edu/\" rel=\"noopener\" target=\"_blank\">Institute for Human-Centered Artificial Intelligence</a>, or HAI, lead by <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/\" href=\"https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/\" rel=\"noopener\" target=\"_blank\">Fei Fei Li</a>, one of the most prolific researchers in the field and former Chief Scientist of AI/ML at Google Cloud. HAI will work on topics such as how to ensure algorithms make fair decisions in government or finance, and what new regulations may be required on AI applications. \u201c<em class=\"markup--em markup--p-em\">AI started as a computer science discipline, but now we are in a new chapter. This technology has the potential to do so many good things, but there are also risks and pitfalls. We have to act and make sure it is human benevolent.</em>\u201d</p><p class=\"graf graf--p graf-after--p\" id=\"84c8\" name=\"84c8\">HAI has 121 faculty member listed. Not a single one of them is black.</p><p class=\"graf graf--p graf-after--p graf--trailing\" id=\"3707\" name=\"3707\">AI desperately needs diversity. Diversity in AI will help reduce biases, and government agencies, corporates and institutions who implement data centric applications need to integrate de-biasing efforts into their data pipelines; they mustn\u2019t just hire lawyers to make their systems compliant, they need to include many different thinkers from psychology, social sciences, philosophy if they want to achieve significantly better results.</p></div></div></section></div><footer class=\"u-paddingTop10\"><div class=\"container u-maxWidth740\"><div class=\"row\"><div class=\"col u-size12of12\"><div class=\"postMetaInline postMetaInline--acknowledgments u-paddingTop5 u-paddingBottom20 js-postMetaAcknowledgments\"><a class=\"link u-baseColor--link\" data-tooltip=\"Except where otherwise noted, this work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International license by the author.\" href=\"https://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license cc:license\" target=\"_blank\">Some rights reserved</a><span class=\"postMetaInline-licenseIcons u-marginLeft5\"><span title=\"You can distribute, remix, and build upon this work as long as you credit the author.\"><span class=\"svgIcon svgIcon--creativeCommonsBy svgIcon--21px\"><svg class=\"svgIcon-use\" height=\"21\" width=\"21\"><path d=\"M10.485 2c2.387 0 4.4.82 6.04 2.46C18.175 6.107 19 8.12 19 10.5c0 2.388-.81 4.376-2.43 5.965C14.85 18.155 12.823 19 10.486 19c-2.298 0-4.29-.835-5.98-2.505C2.836 14.825 2 12.827 2 10.5s.835-4.34 2.505-6.04C6.145 2.82 8.137 2 10.485 2zm.03 1.533c-1.933 0-3.567.678-4.903 2.034-1.386 1.417-2.08 3.06-2.08 4.933 0 1.882.69 3.512 2.065 4.887 1.376 1.377 3.015 2.064 4.918 2.064 1.892 0 3.54-.69 4.948-2.07 1.336-1.28 2.004-2.91 2.004-4.87 0-1.93-.68-3.57-2.034-4.93-1.356-1.35-2.995-2.03-4.918-2.03zm2.277 4.857v3.476h-.97v4.128H9.18v-4.128h-.972V8.39a.53.53 0 0 1 .16-.387.528.528 0 0 1 .387-.16h3.49c.143 0 .27.054.38.16a.52.52 0 0 1 .167.387zM9.316 6.205c0-.8.394-1.2 1.184-1.2.79 0 1.184.4 1.184 1.2 0 .79-.395 1.183-1.184 1.183-.79 0-1.184-.394-1.184-1.183z\" fill-rule=\"evenodd\"></path></svg></span></span><span title=\"You can use this work for non-commercial purposes only.\"><span class=\"svgIcon svgIcon--creativeCommonsNc svgIcon--21px\"><svg class=\"svgIcon-use\" height=\"21\" width=\"21\"><path d=\"M10.485 2c2.388 0 4.4.82 6.04 2.46C18.175 6.097 19 8.11 19 10.5s-.81 4.376-2.43 5.965C14.85 18.155 12.823 19 10.486 19c-2.308 0-4.3-.84-5.98-2.52C2.836 14.81 2 12.82 2 10.5c0-2.327.835-4.34 2.505-6.04C6.145 2.82 8.137 2 10.485 2zM3.913 8.208a6.68 6.68 0 0 0-.38 2.292c0 1.882.688 3.512 2.064 4.888 1.386 1.366 3.026 2.05 4.918 2.05 1.912 0 3.56-.694 4.948-2.08a6.2 6.2 0 0 0 1.168-1.49l-3.2-1.425c-.11.536-.38.974-.81 1.313a2.8 2.8 0 0 1-1.52.584v1.305h-.98V14.34c-.94-.01-1.8-.35-2.58-1.017L8.7 12.14c.556.51 1.19.77 1.898.77.294 0 .545-.067.752-.2.207-.13.312-.35.312-.652a.658.658 0 0 0-.23-.516l-.82-.35-1-.455-1.353-.59-4.34-1.944zm6.602-4.69c-1.933 0-3.567.683-4.903 2.05a8.007 8.007 0 0 0-.94 1.138L7.92 8.163c.14-.446.41-.802.804-1.07a2.68 2.68 0 0 1 1.382-.448V5.34h.986v1.305c.78.04 1.488.303 2.125.79L12.11 8.57c-.477-.334-.962-.5-1.458-.5-.263 0-.498.05-.706.15-.207.103-.31.275-.31.517 0 .07.024.14.075.212l1.08.48.75.33 1.37.6 4.36 1.94c.14-.6.22-1.21.22-1.83 0-1.95-.67-3.6-2.03-4.93-1.35-1.37-2.99-2.05-4.92-2.05z\" fill-rule=\"evenodd\"></path></svg></span></span></span> </div></div></div><div class=\"row\"><div class=\"col u-size12of12 js-postTags\"><div class=\"u-paddingBottom10\"><ul class=\"tags tags--postTags tags--borderless\"><li><a class=\"link u-baseColor--link\" data-action-source=\"post\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com/tagged/artificial-intelligence?source=post\">Artificial Intelligence</a></li><li><a class=\"link u-baseColor--link\" data-action-source=\"post\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com/tagged/ethical-ai?source=post\">Ethical Ai</a></li><li><a class=\"link u-baseColor--link\" data-action-source=\"post\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com/tagged/accountable-ai?source=post\">Accountable Ai</a></li><li><a class=\"link u-baseColor--link\" data-action-source=\"post\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com/tagged/racism?source=post\">Racism</a></li><li><a class=\"link u-baseColor--link\" data-action-source=\"post\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com/tagged/bias?source=post\">Bias</a></li></ul></div></div></div><div class=\"postActions js-postActionsFooter\"><div class=\"u-flexCenter\"><div class=\"u-flex1\"><div class=\"multirecommend js-actionMultirecommend u-flexCenter\" data-clap-string-plural=\"claps\" data-clap-string-singular=\"clap\" data-has-recommend-list=\"true\" data-is-circle=\"true\" data-is-icon-29px=\"true\" data-post-id=\"66ea8f67c7de\" data-source=\"post_actions_footer-----66ea8f67c7de---------------------clap_footer\"><div class=\"u-relative u-foreground\"><button aria-label=\"Clap\" class=\"button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection\" data-action=\"sign-up-prompt\" data-action-source=\"post_actions_footer-----66ea8f67c7de---------------------clap_footer\" data-redirect=\"https://medium.com/_/vote/p/66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"multivote\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0\"><svg class=\"svgIcon-use\" height=\"33\" width=\"33\"><path d=\"M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z\" fill-rule=\"evenodd\"></path></svg></span></span><span class=\"button-activeState\"><span class=\"svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0\"><svg class=\"svgIcon-use\" height=\"33\" width=\"33\"><g fill-rule=\"evenodd\"><path d=\"M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z\"></path><path d=\"M13.285.48l-1.916.881 2.37 2.837z\"></path><path d=\"M21.719 1.361L19.79.501l-.44 3.697z\"></path><path d=\"M16.502 3.298L15.481 0h2.043z\"></path></g></svg></span></span></button><div class=\"clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Springu-backgroundGrayLighter js-clapUndo\" style=\"top: 14px; padding: 2px;\"><button class=\"button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight\" data-action=\"multivote-undo\" data-action-value=\"66ea8f67c7de\"><span class=\"svgIcon svgIcon--removeThin svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61\" fill-rule=\"evenodd\"></path></svg></span></button></div></div><span class=\"u-relative u-background js-actionMultirecommendCount u-marginLeft16\"><button class=\"button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-textColorDarker\" data-action=\"show-recommends\" data-action-value=\"66ea8f67c7de\">4 claps</button><span class=\"u-xs-hide\"></span></span></div></div><div class=\"buttonSet u-flex0\"><a aria-label=\"Share on Twitter\" class=\"button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12\" data-action-source=\"post_actions_footer\" href=\"https://medium.com/p/66ea8f67c7de/share/twitter\" target=\"_blank\" title=\"Share on Twitter\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--twitterFilled svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z\"></path></svg></span></span></a><a aria-label=\"Share on Facebook\" class=\"button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12\" data-action-source=\"post_actions_footer\" href=\"https://medium.com/p/66ea8f67c7de/share/facebook\" target=\"_blank\" title=\"Share on Facebook\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--facebookSquare svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79\"></path></svg></span></span></a><button aria-label=\"Share this story on Twitter or Facebook\" class=\"button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show u-marginRight10\" data-action=\"show-share-popover\" data-action-source=\"post_actions_footer\" title=\"Share this story on Twitter or Facebook\"><span class=\"svgIcon svgIcon--share svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706\" fill-rule=\"evenodd\"></path></svg></span></button><button class=\"button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon\" data-action=\"show-membership-respond-warning\" data-action-source=\"post_actions_footer\"><span class=\"svgIcon svgIcon--response svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z\"></path></svg></span></button><button class=\"button button--chromeless u-baseColor--buttonNormal u-marginRight12\" data-action=\"scroll-to-responses\">2</button><button aria-label=\"Bookmark this story to read later\" class=\"button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton\" data-action=\"sign-up-prompt\" data-action-source=\"post_actions_footer\" data-redirect=\"https://medium.com/_/bookmark/p/66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"add-to-bookmarks\" title=\"Bookmark this story to read later\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--bookmark svgIcon--29px u-marginRight4\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z\" fill-rule=\"evenodd\"></path></svg></span></span><span class=\"button-activeState\"><span class=\"svgIcon svgIcon--bookmarkFilled svgIcon--29px u-marginRight4\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z\" fill-rule=\"evenodd\"></path></svg></span></span></button><button aria-label=\"More actions\" class=\"button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton\" data-action=\"more-actions\" title=\"More actions\"><span class=\"svgIcon svgIcon--more svgIcon--25px\"><svg class=\"svgIcon-use\" height=\"25\" viewbox=\"-480.5 272.5 21 21\" width=\"25\"><path d=\"M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z\"></path></svg></span></button></div></div></div></div><div class=\"u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer\"><div class=\"row js-postFooterInfo\"><div class=\"col u-size6of12 u-xs-size12of12\"><li class=\"uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser\"><div class=\"u-marginLeft20 u-floatRight\"><span class=\"followState js-followState\" data-user-id=\"479cace88d58\"><button class=\"button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton\" data-action=\"sign-up-prompt\" data-action-source=\"footer_card\" data-redirect=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"toggle-block-user\"><span class=\"button-label button-defaultState\">Blocked</span><span class=\"button-label button-hoverState\">Unblock</span></button><button class=\"button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton\" data-action=\"sign-up-prompt\" data-action-source=\"footer_card-479cace88d58-------------------------follow_footer\" data-redirect=\"https://medium.com/_/subscribe/user/479cace88d58\" data-requires-token=\"true\" data-sign-in-action=\"toggle-subscribe-user\"><span class=\"button-label button-defaultState js-buttonLabel\">Follow</span><span class=\"button-label button-activeState\">Following</span></button></span></div><div class=\"u-tableCell\"><a aria-label=\"Go to the profile of Maurizio Santamicone\" class=\"link u-baseColor--link avatar\" data-action-source=\"footer_card\" data-collection-slug=\"towards-data-science\" data-user-id=\"479cace88d58\" dir=\"auto\" href=\"https://towardsdatascience.com/@mauriziosantamicone?source=footer_card\" title=\"Go to the profile of Maurizio Santamicone\"><div class=\"u-relative u-inlineBlock u-flex0\"><img alt=\"Go to the profile of Maurizio Santamicone\" class=\"avatar-image avatar-image--small\" src=\"https://cdn-images-1.medium.com/fit/c/120/120/1*9tRCoLMCijoqWB0ePvW6Wg.jpeg\"/><div class=\"avatar-halo u-absolute u-textColorGreenNormal svgIcon\" style=\"width: calc(100% + 12px); height: calc(100% + 12px); top:-6px; left:-6px\"><svg viewbox=\"0 0 114 114\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7.66922967,32.092726 C17.0070768,13.6353618 35.9421928,1.75 57,1.75 C78.0578072,1.75 96.9929232,13.6353618 106.33077,32.092726 L107.66923,31.4155801 C98.0784505,12.4582656 78.6289015,0.25 57,0.25 C35.3710985,0.25 15.9215495,12.4582656 6.33077033,31.4155801 L7.66922967,32.092726 Z\"></path><path d=\"M106.33077,81.661427 C96.9929232,100.118791 78.0578072,112.004153 57,112.004153 C35.9421928,112.004153 17.0070768,100.118791 7.66922967,81.661427 L6.33077033,82.338573 C15.9215495,101.295887 35.3710985,113.504153 57,113.504153 C78.6289015,113.504153 98.0784505,101.295887 107.66923,82.338573 L106.33077,81.661427 Z\"></path></svg></div></div></a></div><div class=\"u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15\"><h3 class=\"ui-h3 u-fontSize18 u-lineHeightTighter\"><a aria-label=\"Go to the profile of Maurizio Santamicone\" class=\"link link--primary u-accentColor--hoverTextNormal\" data-collection-slug=\"towards-data-science\" data-user-id=\"479cace88d58\" dir=\"auto\" href=\"https://towardsdatascience.com/@mauriziosantamicone\" property=\"cc:attributionName\" rel=\"author cc:attributionUrl\" title=\"Go to the profile of Maurizio Santamicone\">Maurizio Santamicone</a></h3><div class=\"ui-caption u-textColorGreenNormal u-fontSize13 u-tintSpectrum u-accentColor--textNormal u-marginBottom7\">Medium member since Jan 2019</div><p class=\"ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4\">Data Scientist. Founder at Fliptin Technologies, Soulstice Consulting. Investor. Startups. AI, Machine Learning.</p></div></li></div><div class=\"col u-size6of12 u-xs-size12of12 u-xs-marginTop30\"><li class=\"uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection\"><div class=\"u-marginLeft20 u-floatRight\"><button class=\"button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton\" data-action=\"sign-up-prompt\" data-action-source=\"footer_card----7f60cf5620c9----------------------follow_footer\" data-collection-id=\"7f60cf5620c9\" data-redirect=\"https://medium.com/_/subscribe/collection/towards-data-science\" data-requires-token=\"true\" data-sign-in-action=\"toggle-follow-collection\"><span class=\"button-label js-buttonLabel\">Follow</span></button></div><div class=\"u-tableCell\"><a aria-label=\"Go to Towards Data Science\" class=\"link u-baseColor--link avatar avatar--roundedRectangle\" data-action-source=\"footer_card\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com?source=footer_card\" title=\"Go to Towards Data Science\"><img alt=\"Towards Data Science\" class=\"avatar-image u-size60x60\" src=\"https://cdn-images-1.medium.com/fit/c/120/120/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\"/></a></div><div class=\"u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15\"><h3 class=\"ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4\"><a class=\"link link--primary u-accentColor--hoverTextNormal\" data-action-source=\"footer_card\" data-collection-slug=\"towards-data-science\" href=\"https://towardsdatascience.com?source=footer_card\" rel=\"collection\">Towards Data Science</a></h3><p class=\"ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4\">Sharing concepts, ideas, and codes.</p><div class=\"buttonSet\"></div></div></li></div></div></div><div class=\"js-postFooterPlacements\" data-collection-id=\"7f60cf5620c9\" data-post-id=\"66ea8f67c7de\"></div><div class=\"u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper\"></div><div class=\"supplementalPostContent js-heroPromo\"></div></footer></article></main><aside class=\"u-marginAuto u-maxWidth1032 js-postLeftSidebar\"><div class=\"u-foreground u-top0 u-transition--fadeOut300 u-fixed u-sm-hide js-postShareWidget\"><ul><li class=\"u-marginVertical10\"><div class=\"multirecommend js-actionMultirecommend u-flexCenter\" data-has-recommend-list=\"true\" data-is-icon-29px=\"true\" data-post-id=\"66ea8f67c7de\" data-source=\"post_share_widget-----66ea8f67c7de---------------------clap_sidebar\"><div class=\"u-relative u-foreground\"><button aria-label=\"Clap\" class=\"button button--primary button--large button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker\" data-action=\"sign-up-prompt\" data-action-source=\"post_share_widget-----66ea8f67c7de---------------------clap_sidebar\" data-redirect=\"https://medium.com/_/vote/p/66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"multivote\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--clap svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><g fill-rule=\"evenodd\"><path d=\"M13.739 1l.761 2.966L15.261 1z\"></path><path d=\"M16.815 4.776l1.84-2.551-1.43-.471z\"></path><path d=\"M10.378 2.224l1.84 2.551-.408-3.022z\"></path><path d=\"M22.382 22.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L6.11 15.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L8.43 9.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L20.628 15c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM12.99 6.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z\"></path></g></svg></span></span><span class=\"button-activeState\"><span class=\"svgIcon svgIcon--clapFilled svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><g fill-rule=\"evenodd\"><path d=\"M13.738 1l.762 2.966L15.262 1z\"></path><path d=\"M18.634 2.224l-1.432-.47-.408 3.022z\"></path><path d=\"M11.79 1.754l-1.431.47 1.84 2.552z\"></path><path d=\"M24.472 14.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914\"></path><path d=\"M14.58 10.887c-.156-.83.096-1.569.692-2.142L12.78 6.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z\"></path><path d=\"M17.812 10.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L9.2 7.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L7.046 9.54 5.802 8.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394l1.241 1.241 4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L4.89 11.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C21.74 20.8 22.271 18 20.62 14.982l-2.809-4.942z\"></path></g></svg></span></span></button></div><span class=\"u-relative u-background js-actionMultirecommendCount u-marginLeft5\"><button class=\"button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton\" data-action=\"show-recommends\" data-action-value=\"66ea8f67c7de\">4</button></span></div></li><li class=\"u-marginVertical10 u-marginLeft3\"><button aria-label=\"Bookmark this story to read later\" class=\"button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton\" data-action=\"sign-up-prompt\" data-action-source=\"post_share_widget-----66ea8f67c7de---------------------bookmark_sidebar\" data-redirect=\"https://medium.com/_/bookmark/p/66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"add-to-bookmarks\" title=\"Bookmark this story to read later\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--bookmark svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z\" fill-rule=\"evenodd\"></path></svg></span></span><span class=\"button-activeState\"><span class=\"svgIcon svgIcon--bookmarkFilled svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z\" fill-rule=\"evenodd\"></path></svg></span></span></button></li><li class=\"u-marginVertical10 u-marginLeft3\"><a aria-label=\"Share on Twitter\" class=\"button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless\" data-action-source=\"post_share_widget\" href=\"https://medium.com/p/66ea8f67c7de/share/twitter\" target=\"_blank\" title=\"Share on Twitter\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--twitterFilled svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z\"></path></svg></span></span></a></li><li class=\"u-marginVertical10 u-marginLeft3\"><a aria-label=\"Share on Facebook\" class=\"button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless\" data-action-source=\"post_share_widget\" href=\"https://medium.com/p/66ea8f67c7de/share/facebook\" target=\"_blank\" title=\"Share on Facebook\"><span class=\"button-defaultState\"><span class=\"svgIcon svgIcon--facebookSquare svgIcon--29px\"><svg class=\"svgIcon-use\" height=\"29\" width=\"29\"><path d=\"M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79\"></path></svg></span></span></a></li></ul></div></aside><style class=\"js-collectionStyle\">\n.u-accentColor--borderLight {border-color: #668AAA !important;}\n.u-accentColor--borderNormal {border-color: #668AAA !important;}\n.u-accentColor--borderDark {border-color: #5A7690 !important;}\n.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #668AAA !important;}\n.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #668AAA !important;}\n.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #5A7690 !important;}\n.u-accentColor--textNormal {color: #5A7690 !important;}\n.u-accentColor--hoverTextNormal:hover {color: #5A7690 !important;}\n.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #546C83 !important;}\n.u-accentColor--textDark {color: #546C83 !important;}\n.u-accentColor--backgroundLight {background-color: #668AAA !important;}\n.u-accentColor--backgroundNormal {background-color: #668AAA !important;}\n.u-accentColor--backgroundDark {background-color: #5A7690 !important;}\n.u-accentColor--buttonDark {border-color: #5A7690 !important; color: #546C83 !important;}\n.u-accentColor--buttonDark:hover {border-color: #546C83 !important;}\n.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #5A7690 !important; fill: #5A7690 !important;}\n.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #668AAA !important; color: #5A7690 !important;}\n.u-accentColor--buttonNormal:hover {border-color: #5A7690 !important;}\n.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #668AAA !important; fill: #668AAA !important;}\n.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #5A7690 !important; border-color: #5A7690 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #668AAA !important; border-color: #668AAA !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #5A7690 !important;}.u-tintBgColor {background-color: rgba(53, 88, 118, 1) !important;}.u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(53, 88, 118, 1) 0%, rgba(53, 88, 118, 0) 100%) !important;}.u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(53, 88, 118, 0) 0%, rgba(53, 88, 118, 1) 100%) !important;}\n.u-tintSpectrum .u-baseColor--borderLight {border-color: #9FB3C6 !important;}\n.u-tintSpectrum .u-baseColor--borderNormal {border-color: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--borderDark {border-color: #E9F1FA !important;}\n.u-tintSpectrum .u-baseColor--iconLight .svgIcon,.u-tintSpectrum .u-baseColor--iconLight.svgIcon {fill: #9FB3C6 !important;}\n.u-tintSpectrum .u-baseColor--iconNormal .svgIcon,.u-tintSpectrum .u-baseColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--iconDark .svgIcon,.u-tintSpectrum .u-baseColor--iconDark.svgIcon {fill: #E9F1FA !important;}\n.u-tintSpectrum .u-baseColor--textNormal {color: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--textDark {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--textDarker {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--backgroundLight {background-color: #9FB3C6 !important;}\n.u-tintSpectrum .u-baseColor--backgroundNormal {background-color: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--backgroundDark {background-color: #E9F1FA !important;}\n.u-tintSpectrum .u-baseColor--buttonLight {border-color: #9FB3C6 !important; color: #9FB3C6 !important;}\n.u-tintSpectrum .u-baseColor--buttonLight:hover {border-color: #9FB3C6 !important;}\n.u-tintSpectrum .u-baseColor--buttonLight .icon:before,.u-tintSpectrum .u-baseColor--buttonLight .svgIcon {color: #9FB3C6 !important; fill: #9FB3C6 !important;}\n.u-tintSpectrum .u-baseColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--buttonDark:hover {border-color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--buttonDark .icon:before,.u-tintSpectrum .u-baseColor--buttonDark .svgIcon {color: #E9F1FA !important; fill: #E9F1FA !important;}\n.u-tintSpectrum .u-baseColor--buttonNormal {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--buttonNormal:hover {border-color: #E9F1FA !important;}\n.u-tintSpectrum .u-baseColor--buttonNormal .icon:before,.u-tintSpectrum .u-baseColor--buttonNormal .svgIcon {color: #C5D2E1 !important; fill: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--buttonDark.button--filled,.u-tintSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}\n.u-tintSpectrum .u-baseColor--buttonNormal.button--filled,.u-tintSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}\n.u-tintSpectrum .u-baseColor--link {color: #C5D2E1 !important;}\n.u-tintSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--link.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--darken:active {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--link.link--dark {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:active {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--link.link--darker {color: #FBFFFF !important;}\n.u-tintSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: #9FB3C6;}\n.u-tintSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: #9FB3C6;}\n.u-tintSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: #9FB3C6;}\n.u-tintSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: #FBFFFF !important;}\n.u-tintSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: #FBFFFF !important;}\n.u-tintSpectrum  .ui-h1,.u-tintSpectrum  .ui-h2,.u-tintSpectrum  .ui-h3,.u-tintSpectrum  .ui-h4,.u-tintSpectrum  .ui-brand1,.u-tintSpectrum  .ui-brand2,.u-tintSpectrum  .ui-captionStrong {color: #FBFFFF !important; fill: #FBFFFF !important;}\n.u-tintSpectrum  .ui-body,.u-tintSpectrum  .ui-caps {color: #FBFFFF !important; fill: #FBFFFF !important;}\n.u-tintSpectrum  .ui-summary,.u-tintSpectrum  .ui-caption {color: #9FB3C6 !important; fill: #9FB3C6 !important;}\n.u-tintSpectrum .u-accentColor--borderLight {border-color: #9FB3C6 !important;}\n.u-tintSpectrum .u-accentColor--borderNormal {border-color: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--borderDark {border-color: #E9F1FA !important;}\n.u-tintSpectrum .u-accentColor--iconLight .svgIcon,.u-tintSpectrum .u-accentColor--iconLight.svgIcon {fill: #9FB3C6 !important;}\n.u-tintSpectrum .u-accentColor--iconNormal .svgIcon,.u-tintSpectrum .u-accentColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--iconDark .svgIcon,.u-tintSpectrum .u-accentColor--iconDark.svgIcon {fill: #E9F1FA !important;}\n.u-tintSpectrum .u-accentColor--textNormal {color: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--hoverTextNormal:hover {color: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #FBFFFF !important;}\n.u-tintSpectrum .u-accentColor--textDark {color: #FBFFFF !important;}\n.u-tintSpectrum .u-accentColor--backgroundLight {background-color: #9FB3C6 !important;}\n.u-tintSpectrum .u-accentColor--backgroundNormal {background-color: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--backgroundDark {background-color: #E9F1FA !important;}\n.u-tintSpectrum .u-accentColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}\n.u-tintSpectrum .u-accentColor--buttonDark:hover {border-color: #FBFFFF !important;}\n.u-tintSpectrum .u-accentColor--buttonDark .icon:before,.u-tintSpectrum .u-accentColor--buttonDark .svgIcon{color: #E9F1FA !important; fill: #E9F1FA !important;}\n.u-tintSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--buttonNormal:hover {border-color: #E9F1FA !important;}\n.u-tintSpectrum .u-accentColor--buttonNormal .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal .svgIcon{color: #C5D2E1 !important; fill: #C5D2E1 !important;}\n.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}\n.u-tintSpectrum .u-accentColor--buttonDark.button--filled,.u-tintSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-tintSpectrum .u-accentColor--fillWhenActive.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}\n.u-tintSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-tintSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}\n.u-tintSpectrum .postArticle.is-withAccentColors .markup--user,.u-tintSpectrum .postArticle.is-withAccentColors .markup--query {color: #C5D2E1 !important;}\n.u-accentColor--highlightFaint {background-color: rgba(233, 242, 253, 1) !important;}\n.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(200, 228, 255, 1) !important;}\n.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 242, 253, 1) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 242, 253, 1), rgba(233, 242, 253, 1));}\n.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(215, 235, 254, 1) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(215, 235, 254, 1), rgba(215, 235, 254, 1));}\n.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(200, 228, 255, 1) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}\n.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(200, 228, 255, 1) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}\n.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(200, 228, 255, 1) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class=\"js-collectionStyleConstant\">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}\n.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}\n.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}\n.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}\n.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}\n.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}\n.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}\n.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}\n.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}\n.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}\n.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}\n.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}\n.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}\n.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}\n.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}\n.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}\n.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}\n.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}\n.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}\n.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}\n.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}\n.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}\n.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}\n.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}\n.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}\n.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}\n.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}\n.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}\n.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}\nbody.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}\n.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}\n.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}\n.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}\n.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}\n.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}\n.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}\n.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}\n.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}\n.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}\n.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}\n.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}\n.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}\n.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}\n.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}\n.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}\n.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}\n.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}\n.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}\n.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style></div></div></div><div class=\"loadingBar\"></div><script>// <![CDATA[\nwindow[\"obvInit\"] = function (opt_embedded) {window[\"obvInit\"][\"embedded\"] = opt_embedded; window[\"obvInit\"][\"ready\"] = true;}\n// ]]></script><script>// <![CDATA[\nvar GLOBALS = {\"audioUrl\":\"https://d1fcbxp97j4nb2.cloudfront.net\",\"baseUrl\":\"https://towardsdatascience.com\",\"buildLabel\":\"37284-b92bb4c\",\"currentUser\":{\"userId\":\"lo_6G8DpQ9xFsFp\",\"isVerified\":false,\"subscriberEmail\":\"\",\"hasPastMemberships\":false,\"isEnrolledInHightower\":false,\"isEligibleForHightower\":false,\"hightowerLastLockedAt\":0,\"isWriterProgramEnrolled\":true,\"isWriterProgramInvited\":false,\"isWriterProgramOptedOut\":false,\"writerProgramVersion\":0,\"writerProgramEnrolledAt\":0,\"friendLinkOnboarding\":0,\"hasAdditionalUnlocks\":false,\"hasApiAccess\":false,\"isQuarantined\":false,\"writerProgramDistributionSettingOptedIn\":false},\"currentUserHasUnverifiedEmail\":false,\"isAuthenticated\":false,\"isCurrentUserVerified\":false,\"miroUrl\":\"https://cdn-images-1.medium.com\",\"moduleUrls\":{\"base\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.taBuz0BaPXEzQ0XY-OlDyQ.js\",\"common-async\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.A_mLXkb4Ge7UOhdBL7AHpQ.js\",\"hightower\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.cu_DvZdJVTyB3GCuIZGzjA.js\",\"home-screens\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.E8mGTqZIRt8PdKIj5rb_6Q.js\",\"misc-screens\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle._iq07U-iugyd4o0z11Ll3A.js\",\"notes\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.K3uboaPn6_SsEx2F5Tb_LA.js\",\"payments\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.bPiaCD-_HYPk52L1yyY-oQ.js\",\"posters\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.I93Nud4U0O5nGLwcgAp67Q.js\",\"power-readers\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.LOR4KdNUoWnoxzgunR034A.js\",\"pubs\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.gtUNNQd8niE3bfa7whdBwQ.js\",\"stats\":\"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.IP6BuJ1_wMVlpXqXyiyBuA.js\"},\"previewConfig\":{\"weightThreshold\":1,\"weightImageParagraph\":0.51,\"weightIframeParagraph\":0.8,\"weightTextParagraph\":0.08,\"weightEmptyParagraph\":0,\"weightP\":0.003,\"weightH\":0.005,\"weightBq\":0.003,\"minPTextLength\":60,\"truncateBoundaryChars\":20,\"detectTitle\":true,\"detectTitleLevThreshold\":0.15},\"productName\":\"Medium\",\"supportsEdit\":true,\"termsUrl\":\"//medium.com/policy/9db0094a1e0f\",\"textshotHost\":\"textshot.medium.com\",\"transactionId\":\"1555944845700:c4a97c3bb6e6\",\"useragent\":{\"browser\":\"chrome\",\"family\":\"chrome\",\"os\":\"windows\",\"version\":63,\"supportsDesktopEdit\":true,\"supportsInteract\":true,\"supportsView\":true,\"isMobile\":false,\"isTablet\":false,\"isNative\":false,\"supportsFileAPI\":true,\"isTier1\":true,\"clientVersion\":\"\",\"unknownParagraphsBad\":false,\"clientChannel\":\"\",\"supportsRealScrollEvents\":true,\"supportsVhUnits\":true,\"ruinsViewportSections\":false,\"supportsHtml5Video\":true,\"supportsMagicUnderlines\":true,\"isWebView\":false,\"isFacebookWebView\":false,\"supportsProgressiveMedia\":true,\"supportsPromotedPosts\":true,\"isBot\":false,\"isNativeIphone\":false,\"supportsCssVariables\":true,\"supportsVideoSections\":true,\"emojiSupportLevel\":1,\"isSearchBot\":false,\"isSyndicationBot\":false,\"isNativeAndroid\":false,\"isNativeIos\":false,\"supportsScrollableMetabar\":true},\"variants\":{\"allow_access\":true,\"allow_signup\":true,\"allow_test_auth\":\"disallow\",\"signin_services\":\"twitter,facebook,google,email,google-fastidv,google-one-tap\",\"signup_services\":\"twitter,facebook,google,email,google-fastidv,google-one-tap\",\"google_sign_in_android\":true,\"reengagement_notification_duration\":3,\"browsable_stream_config_bucket\":\"curated-topics\",\"enable_dedicated_series_tab_api_ios\":true,\"enable_post_import\":true,\"available_monthly_plan\":\"60e220181034\",\"available_annual_plan\":\"2c754bcc2995\",\"disable_ios_resume_reading_toast\":true,\"is_not_medium_subscriber\":true,\"glyph_font_set\":\"m2\",\"enable_branding\":true,\"enable_branding_fonts\":true,\"max_premium_content_per_user_under_metering\":3,\"enable_automated_mission_control_triggers\":true,\"enable_lite_profile\":true,\"enable_marketing_emails\":true,\"enable_topic_lifecycle_email\":true,\"enable_parsely\":true,\"enable_branch_io\":true,\"enable_ios_post_stats\":true,\"enable_lite_topics\":true,\"enable_lite_stories\":true,\"redis_read_write_splitting\":true,\"enable_tipalti_onboarding\":true,\"enable_annual_renewal_reminder_email\":true,\"enable_janky_spam_rules\":\"users,posts\",\"enable_new_collaborative_filtering_data\":true,\"android_rating_prompt_stories_read_threshold\":2,\"stripe_v3\":true,\"enable_google_one_tap\":true,\"enable_email_sign_in_captcha\":true,\"enable_rito_post_handler\":true,\"enable_rito_sequence_post_recirc_query\":true,\"editorial_push_notifications\":true,\"enable_primary_topic_for_mobile\":true,\"enable_rito_sequence_post_handler\":true,\"enable_interest_graph_with_signup_post\":true,\"enable_todays_highlights_ios\":true,\"enable_logged_out_homepage_signup\":true,\"use_new_admin_topic_backend\":true,\"enable_quarantine_rules\":true,\"enable_lite_privacy_banner\":true,\"enable_simplified_welcome_email\":true},\"xsrfToken\":\"\",\"iosAppId\":\"828256236\",\"supportEmail\":\"yourfriends@medium.com\",\"fp\":{\"/icons/monogram-mask.svg\":\"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg\",\"/icons/favicon-dev-editor.ico\":\"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico\",\"/icons/favicon-hatch-editor.ico\":\"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico\",\"/icons/favicon-medium-editor.ico\":\"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico\"},\"authBaseUrl\":\"https://medium.com\",\"imageUploadSizeMb\":25,\"isAuthDomainRequest\":false,\"domainCollectionSlug\":\"towards-data-science\",\"algoliaApiEndpoint\":\"https://MQ57UUUQZ2-dsn.algolia.net\",\"algoliaAppId\":\"MQ57UUUQZ2\",\"algoliaSearchOnlyApiKey\":\"394474ced050e3911ae2249ecc774921\",\"iosAppStoreUrl\":\"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8\",\"iosAppLinkBaseUrl\":\"medium:\",\"algoliaIndexPrefix\":\"medium_\",\"androidPlayStoreUrl\":\"https://play.google.com/store/apps/details?id=com.medium.reader\",\"googleClientId\":\"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com\",\"androidPackage\":\"com.medium.reader\",\"androidPlayStoreMarketScheme\":\"market://details?id=com.medium.reader\",\"googleAuthUri\":\"https://accounts.google.com/o/oauth2/auth\",\"androidScheme\":\"medium\",\"layoutData\":{\"useDynamicScripts\":false,\"googleAnalyticsTrackingCode\":\"UA-24232453-2\",\"jsShivUrl\":\"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js\",\"useDynamicCss\":false,\"faviconUrl\":\"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico\",\"faviconImageId\":\"1*8I-HPL0bfoIzGied-dzOvA.png\",\"fontSets\":[{\"id\":8,\"url\":\"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css\"},{\"id\":11,\"url\":\"https://glyph.medium.com/css/m2.css\"},{\"id\":9,\"url\":\"https://glyph.medium.com/css/mkt.css\"}],\"editorFaviconUrl\":\"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico\",\"glyphUrl\":\"https://glyph.medium.com\"},\"authBaseUrlRev\":\"moc.muidem//:sptth\",\"isDnt\":false,\"stripePublishableKey\":\"pk_live_7FReX44VnNIInZwrIIx6ghjl\",\"archiveUploadSizeMb\":100,\"paymentData\":{\"currencies\":{\"1\":{\"label\":\"US Dollar\",\"external\":\"usd\"}},\"countries\":{\"1\":{\"label\":\"United States of America\",\"external\":\"US\"}},\"accountTypes\":{\"1\":{\"label\":\"Individual\",\"external\":\"individual\"},\"2\":{\"label\":\"Company\",\"external\":\"company\"}}},\"previewConfig2\":{\"weightThreshold\":1,\"weightImageParagraph\":0.05,\"raiseImage\":true,\"enforceHeaderHierarchy\":true,\"isImageInsetRight\":true},\"isAmp\":false,\"iosScheme\":\"medium\",\"isSwBoot\":false,\"lightstep\":{\"accessToken\":\"ce5be895bef60919541332990ac9fef2\",\"carrier\":\"{\\\"ot-tracer-spanid\\\":\\\"16ac81b533b88bb5\\\",\\\"ot-tracer-traceid\\\":\\\"067e57ea3413efd7\\\",\\\"ot-tracer-sampled\\\":\\\"true\\\"}\",\"host\":\"collector-medium.lightstep.com\"},\"facebook\":{\"key\":\"542599432471018\",\"namespace\":\"medium-com\",\"scope\":{\"default\":[\"public_profile\",\"email\"],\"connect\":[\"public_profile\",\"email\"],\"login\":[\"public_profile\",\"email\"],\"share\":[\"public_profile\",\"email\"]}},\"editorsPicksTopicId\":\"3985d2a191c5\",\"popularOnMediumTopicId\":\"9d34e48ecf94\",\"memberContentTopicId\":\"13d7efd82fb2\",\"audioContentTopicId\":\"3792abbd134\",\"brandedSequenceId\":\"7d337ddf1941\",\"isDoNotAuth\":false,\"goldfinchUrl\":\"https://goldfinch.medium.com\",\"buggle\":{\"url\":\"https://buggle.medium.com\",\"videoUrl\":\"https://cdn-videos-1.medium.com\",\"audioUrl\":\"https://cdn-audio-1.medium.com\"},\"referrerType\":5,\"isMeteredOut\":false,\"meterConfig\":{\"maxUnlockCount\":3,\"windowLength\":\"MONTHLY\"},\"partnerProgramEmail\":\"partnerprogram@medium.com\",\"userResearchPrompts\":[{\"promptId\":\"lo_post_page_4\",\"type\":0,\"url\":\"www.calendly.com\"},{\"promptId\":\"lo_home_page\",\"type\":1,\"url\":\"www.calendly.com\"},{\"promptId\":\"lo_profile_page\",\"type\":2,\"url\":\"www.calendly.com\"}],\"recaptchaKey\":\"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ\",\"signinWallCustomDomainCollectionIds\":[\"3a8144eabfe3\",\"336d898217ee\",\"61061eb0c96b\",\"138adf9c44c\",\"819cc2aaeee0\"],\"countryCode\":\"A1\",\"bypassMeter\":false,\"branchKey\":\"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm\",\"paypal\":{\"clientMode\":\"production\",\"oneYearGift\":{\"name\":\"Medium Membership (1 Year, Digital Gift Code)\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.\",\"price\":\"50.00\",\"currency\":\"USD\",\"sku\":\"membership-gift-1-yr\"}},\"collectionConfig\":{\"mediumOwnedAndOperatedCollectionIds\":[\"544c7006046e // Human Parts\",\"bcc38c8f6edf // Matter\",\"444d13b52878 // OneZero\",\"8d6b8a439e32 // Elemental\"]}}\n// ]]></script><script async=\"\" charset=\"UTF-8\" src=\"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.taBuz0BaPXEzQ0XY-OlDyQ.js\"></script><script>// <![CDATA[\nwindow[\"obvInit\"]({\"value\":{\"id\":\"66ea8f67c7de\",\"versionId\":\"c9cc026c4817\",\"creatorId\":\"479cace88d58\",\"creator\":{\"userId\":\"479cace88d58\",\"name\":\"Maurizio Santamicone\",\"username\":\"mauriziosantamicone\",\"createdAt\":1538056636750,\"imageId\":\"1*9tRCoLMCijoqWB0ePvW6Wg.jpeg\",\"backgroundImageId\":\"\",\"bio\":\"Data Scientist. Founder at Fliptin Technologies, Soulstice Consulting. Investor. Startups. AI, Machine Learning.\",\"twitterScreenName\":\"santamm\",\"socialStats\":{\"userId\":\"479cace88d58\",\"usersFollowedCount\":2,\"usersFollowedByCount\":2,\"type\":\"SocialStats\"},\"social\":{\"userId\":\"lo_6G8DpQ9xFsFp\",\"targetUserId\":\"479cace88d58\",\"type\":\"Social\"},\"facebookAccountId\":\"10155520971186573\",\"allowNotes\":1,\"mediumMemberAt\":1548057267000,\"isNsfw\":false,\"isWriterProgramEnrolled\":true,\"isQuarantined\":false,\"type\":\"User\"},\"homeCollection\":{\"id\":\"7f60cf5620c9\",\"name\":\"Towards Data Science\",\"slug\":\"towards-data-science\",\"tags\":[\"DATA SCIENCE\",\"MACHINE LEARNING\",\"ARTIFICIAL INTELLIGENCE\",\"BIG DATA\",\"ANALYTICS\"],\"creatorId\":\"895063a310f4\",\"description\":\"Sharing concepts, ideas, and codes.\",\"shortDescription\":\"Sharing concepts, ideas, and codes.\",\"image\":{\"imageId\":\"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1275,\"originalHeight\":1275,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"metadata\":{\"followerCount\":206076,\"activeAt\":1555943821581},\"virtuals\":{\"permissions\":{\"canPublish\":false,\"canPublishAll\":false,\"canRepublish\":false,\"canRemove\":false,\"canManageAll\":false,\"canSubmit\":false,\"canEditPosts\":false,\"canAddWriters\":false,\"canViewStats\":false,\"canSendNewsletter\":false,\"canViewLockedPosts\":false,\"canViewCloaked\":false,\"canEditOwnPosts\":false,\"canBeAssignedAuthor\":false,\"canEnrollInHightower\":false,\"canLockPostsForMediumMembers\":false,\"canLockOwnPostsForMediumMembers\":false},\"isSubscribed\":false,\"isNewsletterSubscribed\":false,\"isEnrolledInHightower\":false,\"isEligibleForHightower\":false},\"logo\":{\"imageId\":\"1*5EUO1kUYBthpOCPzRj_l2g.png\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1010,\"originalHeight\":376,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"twitterUsername\":\"TDataScience\",\"facebookPageName\":\"towardsdatascience\",\"collectionMastheadId\":\"8b6aceffde6\",\"domain\":\"towardsdatascience.com\",\"sections\":[{\"type\":2,\"collectionHeaderMetadata\":{\"title\":\"Towards Data Science\",\"description\":\"Sharing concepts, ideas, and codes\",\"backgroundImage\":{},\"logoImage\":{},\"alignment\":2,\"layout\":5}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"7f2f79e10e3f\",\"8e2374e11bfb\"]}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":3,\"postIds\":[\"449f3c5f6e99\",\"3bc890dac04d\",\"4e73e55de341\"],\"sectionHeader\":\"Featured \"}},{\"type\":1,\"postListMetadata\":{\"source\":1,\"layout\":4,\"number\":6,\"postIds\":[],\"sectionHeader\":\"Latest\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"badbb1726722\",\"7e5819af339d\"],\"sectionHeader\":\"Our Letters\"}},{\"type\":3,\"promoMetadata\":{\"sectionHeader\":\"\",\"promoId\":\"126dff5b63d2\"}},{\"type\":1,\"postListMetadata\":{\"source\":2,\"layout\":4,\"number\":6,\"postIds\":[],\"sectionHeader\":\"Trending\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"3bf37f75a345\",\"3920888f831c\"],\"sectionHeader\":\"Our Readers\u2019 Guide\"}},{\"type\":1,\"postListMetadata\":{\"source\":4,\"layout\":4,\"number\":9,\"postIds\":[],\"tagSlug\":\"Towards Data Science\",\"sectionHeader\":\"Editors' Picks\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"96667b06af5\",\"f8432d67a777\"],\"sectionHeader\":\"Contribute\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"d691af11cc2f\",\"c2c8e712c971\"]}},{\"type\":1,\"postListMetadata\":{\"source\":4,\"layout\":5,\"number\":3,\"postIds\":[],\"tagSlug\":\"Towards Data Science\",\"sectionHeader\":\"Last Chance To Read\"}}],\"tintColor\":\"#FF355876\",\"lightText\":true,\"favicon\":{\"imageId\":\"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1275,\"originalHeight\":1275,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"colorPalette\":{\"defaultBackgroundSpectrum\":{\"colorPoints\":[{\"color\":\"#FF668AAA\",\"point\":0},{\"color\":\"#FF61809D\",\"point\":0.1},{\"color\":\"#FF5A7690\",\"point\":0.2},{\"color\":\"#FF546C83\",\"point\":0.3},{\"color\":\"#FF4D6275\",\"point\":0.4},{\"color\":\"#FF455768\",\"point\":0.5},{\"color\":\"#FF3D4C5A\",\"point\":0.6},{\"color\":\"#FF34414C\",\"point\":0.7},{\"color\":\"#FF2B353E\",\"point\":0.8},{\"color\":\"#FF21282F\",\"point\":0.9},{\"color\":\"#FF161B1F\",\"point\":1}],\"backgroundColor\":\"#FFFFFFFF\"},\"tintBackgroundSpectrum\":{\"colorPoints\":[{\"color\":\"#FF355876\",\"point\":0},{\"color\":\"#FF4D6C88\",\"point\":0.1},{\"color\":\"#FF637F99\",\"point\":0.2},{\"color\":\"#FF7791A8\",\"point\":0.3},{\"color\":\"#FF8CA2B7\",\"point\":0.4},{\"color\":\"#FF9FB3C6\",\"point\":0.5},{\"color\":\"#FFB2C3D4\",\"point\":0.6},{\"color\":\"#FFC5D2E1\",\"point\":0.7},{\"color\":\"#FFD7E2EE\",\"point\":0.8},{\"color\":\"#FFE9F1FA\",\"point\":0.9},{\"color\":\"#FFFBFFFF\",\"point\":1}],\"backgroundColor\":\"#FF355876\"},\"highlightSpectrum\":{\"colorPoints\":[{\"color\":\"#FFEDF4FC\",\"point\":0},{\"color\":\"#FFE9F2FD\",\"point\":0.1},{\"color\":\"#FFE6F1FD\",\"point\":0.2},{\"color\":\"#FFE2EFFD\",\"point\":0.3},{\"color\":\"#FFDFEEFD\",\"point\":0.4},{\"color\":\"#FFDBECFE\",\"point\":0.5},{\"color\":\"#FFD7EBFE\",\"point\":0.6},{\"color\":\"#FFD4E9FE\",\"point\":0.7},{\"color\":\"#FFD0E7FF\",\"point\":0.8},{\"color\":\"#FFCCE6FF\",\"point\":0.9},{\"color\":\"#FFC8E4FF\",\"point\":1}],\"backgroundColor\":\"#FFFFFFFF\"}},\"navItems\":[{\"type\":4,\"title\":\"Data Science\",\"url\":\"https://towardsdatascience.com/data-science/home\",\"topicId\":\"cf416843aadc\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Machine Learning\",\"url\":\"https://towardsdatascience.com/machine-learning/home\",\"topicId\":\"a5c9b2f1cb6b\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Programming\",\"url\":\"https://towardsdatascience.com/programming/home\",\"topicId\":\"41533a1dc73c\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Visualization\",\"url\":\"https://towardsdatascience.com/data-visualization/home\",\"topicId\":\"825e6cb8b9ce\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"AI\",\"url\":\"https://towardsdatascience.com/artificial-intelligence/home\",\"topicId\":\"7f029b17bf96\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Journalism\",\"url\":\"https://towardsdatascience.com/data-journalism/home\",\"topicId\":\"27a6ac3980c6\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Picks\",\"url\":\"https://towardsdatascience.com/editors-picks/home\",\"topicId\":\"e81f4fc5ee6b\",\"source\":\"topicId\"},{\"type\":3,\"title\":\"Contribute\",\"url\":\"https://towardsdatascience.com/contribute/home\"}],\"colorBehavior\":2,\"instantArticlesState\":0,\"acceleratedMobilePagesState\":0,\"googleAnalyticsId\":\"UA-19707169-24\",\"ampLogo\":{\"imageId\":\"\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":0,\"originalHeight\":0,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"header\":{\"title\":\"Towards Data Science\",\"description\":\"Sharing concepts, ideas, and codes\",\"backgroundImage\":{},\"logoImage\":{},\"alignment\":2,\"layout\":5},\"paidForDomainAt\":1509037374118,\"type\":\"Collection\"},\"homeCollectionId\":\"7f60cf5620c9\",\"title\":\"Is Artificial Intelligence Racist?\",\"detectedLanguage\":\"en\",\"latestVersion\":\"c9cc026c4817\",\"latestPublishedVersion\":\"c9cc026c4817\",\"hasUnpublishedEdits\":false,\"latestRev\":719,\"createdAt\":1553165512225,\"updatedAt\":1554298522053,\"acceptedAt\":0,\"firstPublishedAt\":1554217875062,\"latestPublishedAt\":1554298522053,\"vote\":false,\"experimentalCss\":\"\",\"displayAuthor\":\"\",\"content\":{\"subtitle\":\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New\u2026\",\"bodyModel\":{\"paragraphs\":[{\"name\":\"7b98\",\"type\":3,\"text\":\"Is Artificial Intelligence Racist?\",\"markups\":[]},{\"name\":\"82e6\",\"type\":13,\"text\":\"Racial and Gender Bias in AI\",\"markups\":[]},{\"name\":\"8e3a\",\"type\":4,\"text\":\"\",\"markups\":[],\"layout\":1,\"metadata\":{\"id\":\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\",\"originalWidth\":860,\"originalHeight\":460}},{\"name\":\"40ed\",\"type\":1,\"text\":\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New York City. She was of course derided the following day by conservative commentators.\",\"markups\":[{\"type\":3,\"start\":97,\"end\":146,\"href\":\"https://abcnews.go.com/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0}]},{\"name\":\"8c81\",\"type\":1,\"text\":\"But she is right.\",\"markups\":[]},{\"name\":\"18b7\",\"type\":1,\"text\":\"Joy Buolamwini, an MIT scientist and founder of the Algorithmic Justice League, published a research that uncovered large gender and racial bias in AI systems sold by tech giants like IBM, Microsoft, and Amazon. Given the task of guessing the gender of a face, all companies performed substantially better on male faces than female faces. The error rates were no more than 1% for lighter-skinned men whilst for darker-skinned women, the errors soared to 35%. When tasked to classify the faces of Oprah Winfrey, Michelle Obama, and Serena Williams, the systems failed.\",\"markups\":[{\"type\":3,\"start\":0,\"end\":14,\"href\":\"http://gendershades.org\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":3,\"start\":52,\"end\":78,\"href\":\"http://www.ajlunited.org/gender-shades\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0}]},{\"name\":\"3674\",\"type\":4,\"text\":\"License: Joy Buolamwini \u2014 Mit Lab Press Kit\",\"markups\":[{\"type\":3,\"start\":26,\"end\":43,\"href\":\"https://www.media.mit.edu/projects/gender-shades/press-kit/\",\"title\":\"\",\"rel\":\"noopener\",\"anchorType\":0}],\"layout\":1,\"metadata\":{\"id\":\"1*s2hOVNc8SPNUjZufAOgHpg.png\",\"originalWidth\":935,\"originalHeight\":791}},{\"name\":\"5323\",\"type\":1,\"text\":\"These technologies are today penetrating every layer of society. Decisions like determining who is hired, fired, granted a loan, or how long an individual spends in prison have traditionally been performed by humans. Today, they are rapidly made by algorithms or at least algorithms are used in the decision making process for such tasks.\",\"markups\":[]},{\"name\":\"34d2\",\"type\":1,\"text\":\"Machine learning algorithms sift through millions of pieces of data and make correlations and predictions about the world. Their appeal is huge: machines can use hard data to make decisions that are sometimes more accurate than a human\u2019s.\",\"markups\":[]},{\"name\":\"e2ae\",\"type\":4,\"text\":\"License: Joy Buolamwini \u2014 Mit Lab Press Kit\",\"markups\":[{\"type\":3,\"start\":26,\"end\":43,\"href\":\"https://www.media.mit.edu/projects/gender-shades/press-kit/\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0}],\"layout\":1,\"metadata\":{\"id\":\"1*1ffhogHj4damUCp7WdX5Jg.png\",\"originalWidth\":925,\"originalHeight\":616}},{\"name\":\"5e9f\",\"type\":1,\"text\":\"Computer vision is used in policing, i.e. identifying suspects in a crowd. Palantir, a company founded by tech billionaire and Trump donor Peter Thiel, has been using its predictive policing technologies in New Orleans for the last six years: this program was so secretive that even council members knew nothing about it. Amazon has been selling police departments a real time face recognition system that falsely matched 28 member of Congress with mugshots. The problem with these systems is that although they are effective on general tasks, they usually return a high number of false positives (in statistics, a false positive is when a statistical test returns a Type I error, like an HIV test resulting positive on an HIV-negative patient). Combine it with racial bias, and we get a racist policing system, independently from who is using it.\",\"markups\":[{\"type\":3,\"start\":75,\"end\":83,\"href\":\"https://www.palantir.com\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":3,\"start\":406,\"end\":457,\"href\":\"https://www.buzzfeednews.com/article/daveyalba/amazon-rekognition-facial-recognition-congress-false\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":2,\"start\":581,\"end\":597}]},{\"name\":\"66a4\",\"type\":1,\"text\":\"The influence of bias is present in plenty of other types of data as well. For instance, a straightforward application of Machine Learning where computers outperform humans is loan approvals. Financial institutions leverage on historical data to train their algorithms over millions of records allowing them to capture patterns in the data that best identify the features of mortgage applicants.\",\"markups\":[]},{\"name\":\"9d90\",\"type\":1,\"text\":\"The problem is that algorithms can learn too much. Suppose Thokozane is a brilliant graduate student from a poor Soweto neighborhood that has been working regularly for the past few years, has a clean credit record and has finally decided to apply for a loan to buy his first property. According to all the criteria traditionally used by banks to evaluate someone\u2019s creditworthiness, his application should be approved. The algorithm, however, has another plan. It has learnt in the meantime that applicants from the same poor neighborhood TK is from have in the last few years had most of their applications rejected because of poor credit records, insufficient disposable income ans so on. So TK\u2019s application is surpriringly rejected. In other words, the algorithm has learnt an implicit bias.\",\"markups\":[{\"type\":2,\"start\":41,\"end\":49},{\"type\":2,\"start\":782,\"end\":795}]},{\"name\":\"2fad\",\"type\":1,\"text\":\"TK is of course reasonably upset about this, and decides to ask the bank for an explanation, as he alleges that the algorithm has discriminated racially against him. The bank of course replies that this is not possible, as the algorithms have been intentionally blinded to the race of the applicants (this assumption is optimistic). However, the problem is that while some algorithms like DecisionTrees may enable an auditor to discover if the address information was used in a way to penalize applicants who were born or previously resided in predominantly poverty-stricken areas, other algorithms like Deep Learning are much more sophisticated and tend to be a \u201cblack box\u201d to external inspection, and it may prove almost impossible to understand why, or even how, a certain decision has been taken.\",\"markups\":[]},{\"name\":\"abc6\",\"type\":1,\"text\":\"In 2017 a paper was published on Science that found that as a computer teaches itself English, it becomes prejudiced against black Americans and women. Using data \u201cscraped\u201d from the web called the \u201cCommon Crawl\u201d, a corpus containing approximately 840 billion words, it shows that machines can learn word associations from written texts and that these associations mirror those learned by humans, such as pleasantness and flowers or unpleasantness and insects. So far so good. But it also shows that machine learning absorbs stereotyped biases as easily as any other \u2014 for example, associations between female names and family or male names and career. From bad to worse, the researchers found that names associated with being European American were signi\ufb01cantly more easily associated with pleasant than unpleasant terms, compared to some African American names.\",\"markups\":[{\"type\":3,\"start\":33,\"end\":40,\"href\":\"http://science.sciencemag.org/content/356/6334/183\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":2,\"start\":33,\"end\":41}]},{\"name\":\"ec64\",\"type\":1,\"text\":\"A computer builds its vocabulary using frequency data, or how often terms appear together. So it found that on the internet, African-American names are more likely to be surrounded by words that connote unpleasantness. Is that because African Americans are unpleasant? Of course not. It\u2019s because people on the internet write and say horrible things.\",\"markups\":[]},{\"name\":\"17c1\",\"type\":1,\"text\":\"The bias this time is not so implicit, is it?\",\"markups\":[]},{\"name\":\"e696\",\"type\":3,\"text\":\"So what should be done?\",\"markups\":[]},{\"name\":\"5631\",\"type\":1,\"text\":\"Rachel Thomas, co-founder of fast.ai, a deep learning lab based in San Francisco whose motto is \u201cmaking neural nets uncool\u201d, advocates for a more open and inclusive AI, that embraces people from different backgrounds and communities, people who don\u2019t \u201cfit in\u201d the current system, because they have a better understanding of how tech can be weaponized against the most vulnerable: \u201cWe can\u2019t afford to have a tech that is run by an exclusive and homogenous group creating technology that impacts us all. We need more experts about people, like human psychology, behavior and history. AI needs more unlikely people.\u201d\",\"markups\":[{\"type\":3,\"start\":0,\"end\":13,\"href\":\"https://youtu.be/LqjP7O9SxOM\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":3,\"start\":29,\"end\":36,\"href\":\"http://fast.ai\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":2,\"start\":381,\"end\":612}]},{\"name\":\"bf53\",\"type\":1,\"text\":\"Unsurprisingly, Joy Buolamwini has a similar opinion: \u201cData centric technologies are vulnerable to bias and abuse. As a result, we must demand more transparency and accountability. We have entered the age of automation overconfident yet underprepared. If we fail to make an ethical and inclusive AI, we risk losing gains made in civil rights and gender equity under the guise of machine neutrality.\u201d\",\"markups\":[{\"type\":3,\"start\":16,\"end\":30,\"href\":\"http://gendershades.org/\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":2,\"start\":55,\"end\":398}]},{\"name\":\"69a8\",\"type\":3,\"text\":\"So what is \u201cmainstream AI\u201d doing about it?\",\"markups\":[]},{\"name\":\"79cc\",\"type\":1,\"text\":\"Let\u2019s take a peek at the Silicon Valley.\",\"markups\":[]},{\"name\":\"9d69\",\"type\":1,\"text\":\"Stanford University recently launched amid great fanfare the Institute for Human-Centered Artificial Intelligence, or HAI, lead by Fei Fei Li, one of the most prolific researchers in the field and former Chief Scientist of AI/ML at Google Cloud. HAI will work on topics such as how to ensure algorithms make fair decisions in government or finance, and what new regulations may be required on AI applications. \u201cAI started as a computer science discipline, but now we are in a new chapter. This technology has the potential to do so many good things, but there are also risks and pitfalls. We have to act and make sure it is human benevolent.\u201d\",\"markups\":[{\"type\":3,\"start\":61,\"end\":113,\"href\":\"https://hai.stanford.edu/\",\"title\":\"\",\"rel\":\"noopener\",\"anchorType\":0},{\"type\":3,\"start\":131,\"end\":141,\"href\":\"https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/\",\"title\":\"\",\"rel\":\"\",\"anchorType\":0},{\"type\":2,\"start\":411,\"end\":641}]},{\"name\":\"84c8\",\"type\":1,\"text\":\"HAI has 121 faculty member listed. Not a single one of them is black.\",\"markups\":[]},{\"name\":\"3707\",\"type\":1,\"text\":\"AI desperately needs diversity. Diversity in AI will help reduce biases, and government agencies, corporates and institutions who implement data centric applications need to integrate de-biasing efforts into their data pipelines; they mustn\u2019t just hire lawyers to make their systems compliant, they need to include many different thinkers from psychology, social sciences, philosophy if they want to achieve significantly better results.\",\"markups\":[]}],\"sections\":[{\"name\":\"2ee2\",\"startIndex\":0}]},\"postDisplay\":{\"coverless\":true}},\"virtuals\":{\"statusForCollection\":\"APPROVED\",\"allowNotes\":true,\"previewImage\":{\"imageId\":\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":860,\"originalHeight\":460,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"wordCount\":1267,\"imageCount\":3,\"readingTime\":5.3311320754716975,\"subtitle\":\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New\u2026\",\"publishedInCount\":1,\"usersBySocialRecommends\":[],\"noIndex\":false,\"recommends\":3,\"socialRecommends\":[],\"isBookmarked\":false,\"tags\":[{\"slug\":\"artificial-intelligence\",\"name\":\"Artificial Intelligence\",\"postCount\":80842,\"metadata\":{\"postCount\":80842,\"coverImage\":{\"id\":\"1*gAn_BSffVBcwCIR6bDgK1g.jpeg\"}},\"type\":\"Tag\"},{\"slug\":\"ethical-ai\",\"name\":\"Ethical Ai\",\"postCount\":9,\"metadata\":{\"postCount\":9,\"coverImage\":{\"id\":\"1*vzzmJpN71fD6jxA5Iuh8mw.jpeg\",\"originalWidth\":800,\"originalHeight\":533,\"isFeatured\":true}},\"type\":\"Tag\"},{\"slug\":\"accountable-ai\",\"name\":\"Accountable Ai\",\"postCount\":0,\"metadata\":{\"postCount\":0,\"coverImage\":{\"id\":\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\",\"originalWidth\":860,\"originalHeight\":460}},\"type\":\"Tag\"},{\"slug\":\"racism\",\"name\":\"Racism\",\"postCount\":33477,\"metadata\":{\"postCount\":33477,\"coverImage\":{\"id\":\"1*RC7PYbHchlxQxJTcm2bw1Q.jpeg\"}},\"type\":\"Tag\"},{\"slug\":\"bias\",\"name\":\"Bias\",\"postCount\":2004,\"metadata\":{\"postCount\":2004,\"coverImage\":{\"id\":\"1*1kcoXFv-7cnKasg6ncTWzg.jpeg\",\"originalWidth\":1199,\"originalHeight\":849,\"isFeatured\":true}},\"type\":\"Tag\"}],\"socialRecommendsCount\":0,\"responsesCreatedCount\":2,\"links\":{\"entries\":[{\"url\":\"https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/\",\"alts\":[{\"type\":1,\"url\":\"https://cdn.ampproject.org/c/s/www.wired.com/story/fei-fei-li-ai-care-more-about-humans/amp\"}],\"httpStatus\":200},{\"url\":\"http://www.ajlunited.org/gender-shades\",\"alts\":[],\"httpStatus\":200},{\"url\":\"https://www.media.mit.edu/projects/gender-shades/press-kit/\",\"alts\":[],\"httpStatus\":200},{\"url\":\"http://gendershades.org\",\"alts\":[],\"httpStatus\":200},{\"url\":\"https://www.buzzfeednews.com/article/daveyalba/amazon-rekognition-facial-recognition-congress-false\",\"alts\":[{\"type\":1,\"url\":\"https://cdn.ampproject.org/c/s/www.buzzfeednews.com/amphtml/daveyalba/amazon-rekognition-facial-recognition-congress-false\"}],\"httpStatus\":200},{\"url\":\"https://abcnews.go.com/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\",\"alts\":[{\"type\":1,\"url\":\"https://cdn.ampproject.org/c/s/abcnews.go.com/amp/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\"}],\"httpStatus\":200},{\"url\":\"http://science.sciencemag.org/content/356/6334/183\",\"alts\":[],\"httpStatus\":200},{\"url\":\"http://gendershades.org/\",\"alts\":[],\"httpStatus\":200},{\"url\":\"http://fast.ai\",\"alts\":[],\"httpStatus\":200},{\"url\":\"https://hai.stanford.edu/\",\"alts\":[],\"httpStatus\":200},{\"url\":\"https://www.palantir.com\",\"alts\":[],\"httpStatus\":200},{\"url\":\"https://youtu.be/LqjP7O9SxOM\",\"alts\":[{\"type\":2,\"url\":\"vnd.youtube://www.youtube.com/watch?v=LqjP7O9SxOM&feature=applinks\"},{\"type\":3,\"url\":\"vnd.youtube://www.youtube.com/watch?v=LqjP7O9SxOM&feature=applinks\"}],\"httpStatus\":200}],\"version\":\"0.3\",\"generatedAt\":1554298522685},\"isLockedPreviewOnly\":false,\"takeoverId\":\"\",\"metaDescription\":\"\",\"totalClapCount\":4,\"sectionCount\":1,\"readingList\":0,\"topics\":[{\"topicId\":\"1af65db9c2f8\",\"slug\":\"artificial-intelligence\",\"createdAt\":1487916832419,\"deletedAt\":0,\"image\":{\"id\":\"1*A28aHchbaA8zNVXraBq0Ug@2x.jpeg\",\"originalWidth\":4866,\"originalHeight\":3244},\"name\":\"Artificial Intelligence\",\"description\":\"Born to be bot.\",\"relatedTopics\":[],\"visibility\":1,\"relatedTags\":[],\"type\":\"Topic\"},{\"topicId\":\"8e7ee9fba6e1\",\"slug\":\"race\",\"createdAt\":1525367660866,\"deletedAt\":0,\"image\":{\"id\":\"1*TXl3DuOr2aULBFIQphpPWw@2x.jpeg\",\"originalWidth\":4608,\"originalHeight\":3456},\"name\":\"Race\",\"description\":\"Insight and inclusion.\",\"relatedTopics\":[],\"visibility\":1,\"relatedTags\":[],\"type\":\"Topic\"}]},\"coverless\":true,\"slug\":\"is-artificial-intelligence-racist\",\"translationSourcePostId\":\"\",\"translationSourceCreatorId\":\"\",\"isApprovedTranslation\":false,\"inResponseToPostId\":\"\",\"inResponseToRemovedAt\":0,\"isTitleSynthesized\":false,\"allowResponses\":true,\"importedUrl\":\"\",\"importedPublishedAt\":0,\"visibility\":2,\"uniqueSlug\":\"https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\",\"previewContent\":{\"bodyModel\":{\"paragraphs\":[{\"name\":\"7b98\",\"type\":3,\"text\":\"Is Artificial Intelligence Racist?\",\"markups\":[],\"alignment\":1},{\"name\":\"82e6\",\"type\":13,\"text\":\"Racial and Gender Bias in AI\",\"markups\":[],\"alignment\":1},{\"name\":\"8e3a\",\"type\":4,\"text\":\"\",\"markups\":[],\"layout\":9,\"metadata\":{\"id\":\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\",\"originalWidth\":860,\"originalHeight\":460}}],\"sections\":[{\"startIndex\":0}]},\"isFullContent\":false,\"subtitle\":\"Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New\u2026\"},\"license\":4,\"inResponseToMediaResourceId\":\"\",\"canonicalUrl\":\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\",\"approvedHomeCollectionId\":\"7f60cf5620c9\",\"approvedHomeCollection\":{\"id\":\"7f60cf5620c9\",\"name\":\"Towards Data Science\",\"slug\":\"towards-data-science\",\"tags\":[\"DATA SCIENCE\",\"MACHINE LEARNING\",\"ARTIFICIAL INTELLIGENCE\",\"BIG DATA\",\"ANALYTICS\"],\"creatorId\":\"895063a310f4\",\"description\":\"Sharing concepts, ideas, and codes.\",\"shortDescription\":\"Sharing concepts, ideas, and codes.\",\"image\":{\"imageId\":\"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1275,\"originalHeight\":1275,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"metadata\":{\"followerCount\":206076,\"activeAt\":1555943821581},\"virtuals\":{\"permissions\":{\"canPublish\":false,\"canPublishAll\":false,\"canRepublish\":false,\"canRemove\":false,\"canManageAll\":false,\"canSubmit\":false,\"canEditPosts\":false,\"canAddWriters\":false,\"canViewStats\":false,\"canSendNewsletter\":false,\"canViewLockedPosts\":false,\"canViewCloaked\":false,\"canEditOwnPosts\":false,\"canBeAssignedAuthor\":false,\"canEnrollInHightower\":false,\"canLockPostsForMediumMembers\":false,\"canLockOwnPostsForMediumMembers\":false},\"isSubscribed\":false,\"isNewsletterSubscribed\":false,\"isEnrolledInHightower\":false,\"isEligibleForHightower\":false},\"logo\":{\"imageId\":\"1*5EUO1kUYBthpOCPzRj_l2g.png\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1010,\"originalHeight\":376,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"twitterUsername\":\"TDataScience\",\"facebookPageName\":\"towardsdatascience\",\"collectionMastheadId\":\"8b6aceffde6\",\"domain\":\"towardsdatascience.com\",\"sections\":[{\"type\":2,\"collectionHeaderMetadata\":{\"title\":\"Towards Data Science\",\"description\":\"Sharing concepts, ideas, and codes\",\"backgroundImage\":{},\"logoImage\":{},\"alignment\":2,\"layout\":5}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"7f2f79e10e3f\",\"8e2374e11bfb\"]}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":3,\"postIds\":[\"449f3c5f6e99\",\"3bc890dac04d\",\"4e73e55de341\"],\"sectionHeader\":\"Featured \"}},{\"type\":1,\"postListMetadata\":{\"source\":1,\"layout\":4,\"number\":6,\"postIds\":[],\"sectionHeader\":\"Latest\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"badbb1726722\",\"7e5819af339d\"],\"sectionHeader\":\"Our Letters\"}},{\"type\":3,\"promoMetadata\":{\"sectionHeader\":\"\",\"promoId\":\"126dff5b63d2\"}},{\"type\":1,\"postListMetadata\":{\"source\":2,\"layout\":4,\"number\":6,\"postIds\":[],\"sectionHeader\":\"Trending\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"3bf37f75a345\",\"3920888f831c\"],\"sectionHeader\":\"Our Readers\u2019 Guide\"}},{\"type\":1,\"postListMetadata\":{\"source\":4,\"layout\":4,\"number\":9,\"postIds\":[],\"tagSlug\":\"Towards Data Science\",\"sectionHeader\":\"Editors' Picks\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"96667b06af5\",\"f8432d67a777\"],\"sectionHeader\":\"Contribute\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"d691af11cc2f\",\"c2c8e712c971\"]}},{\"type\":1,\"postListMetadata\":{\"source\":4,\"layout\":5,\"number\":3,\"postIds\":[],\"tagSlug\":\"Towards Data Science\",\"sectionHeader\":\"Last Chance To Read\"}}],\"tintColor\":\"#FF355876\",\"lightText\":true,\"favicon\":{\"imageId\":\"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1275,\"originalHeight\":1275,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"colorPalette\":{\"defaultBackgroundSpectrum\":{\"colorPoints\":[{\"color\":\"#FF668AAA\",\"point\":0},{\"color\":\"#FF61809D\",\"point\":0.1},{\"color\":\"#FF5A7690\",\"point\":0.2},{\"color\":\"#FF546C83\",\"point\":0.3},{\"color\":\"#FF4D6275\",\"point\":0.4},{\"color\":\"#FF455768\",\"point\":0.5},{\"color\":\"#FF3D4C5A\",\"point\":0.6},{\"color\":\"#FF34414C\",\"point\":0.7},{\"color\":\"#FF2B353E\",\"point\":0.8},{\"color\":\"#FF21282F\",\"point\":0.9},{\"color\":\"#FF161B1F\",\"point\":1}],\"backgroundColor\":\"#FFFFFFFF\"},\"tintBackgroundSpectrum\":{\"colorPoints\":[{\"color\":\"#FF355876\",\"point\":0},{\"color\":\"#FF4D6C88\",\"point\":0.1},{\"color\":\"#FF637F99\",\"point\":0.2},{\"color\":\"#FF7791A8\",\"point\":0.3},{\"color\":\"#FF8CA2B7\",\"point\":0.4},{\"color\":\"#FF9FB3C6\",\"point\":0.5},{\"color\":\"#FFB2C3D4\",\"point\":0.6},{\"color\":\"#FFC5D2E1\",\"point\":0.7},{\"color\":\"#FFD7E2EE\",\"point\":0.8},{\"color\":\"#FFE9F1FA\",\"point\":0.9},{\"color\":\"#FFFBFFFF\",\"point\":1}],\"backgroundColor\":\"#FF355876\"},\"highlightSpectrum\":{\"colorPoints\":[{\"color\":\"#FFEDF4FC\",\"point\":0},{\"color\":\"#FFE9F2FD\",\"point\":0.1},{\"color\":\"#FFE6F1FD\",\"point\":0.2},{\"color\":\"#FFE2EFFD\",\"point\":0.3},{\"color\":\"#FFDFEEFD\",\"point\":0.4},{\"color\":\"#FFDBECFE\",\"point\":0.5},{\"color\":\"#FFD7EBFE\",\"point\":0.6},{\"color\":\"#FFD4E9FE\",\"point\":0.7},{\"color\":\"#FFD0E7FF\",\"point\":0.8},{\"color\":\"#FFCCE6FF\",\"point\":0.9},{\"color\":\"#FFC8E4FF\",\"point\":1}],\"backgroundColor\":\"#FFFFFFFF\"}},\"navItems\":[{\"type\":4,\"title\":\"Data Science\",\"url\":\"https://towardsdatascience.com/data-science/home\",\"topicId\":\"cf416843aadc\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Machine Learning\",\"url\":\"https://towardsdatascience.com/machine-learning/home\",\"topicId\":\"a5c9b2f1cb6b\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Programming\",\"url\":\"https://towardsdatascience.com/programming/home\",\"topicId\":\"41533a1dc73c\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Visualization\",\"url\":\"https://towardsdatascience.com/data-visualization/home\",\"topicId\":\"825e6cb8b9ce\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"AI\",\"url\":\"https://towardsdatascience.com/artificial-intelligence/home\",\"topicId\":\"7f029b17bf96\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Journalism\",\"url\":\"https://towardsdatascience.com/data-journalism/home\",\"topicId\":\"27a6ac3980c6\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Picks\",\"url\":\"https://towardsdatascience.com/editors-picks/home\",\"topicId\":\"e81f4fc5ee6b\",\"source\":\"topicId\"},{\"type\":3,\"title\":\"Contribute\",\"url\":\"https://towardsdatascience.com/contribute/home\"}],\"colorBehavior\":2,\"instantArticlesState\":0,\"acceleratedMobilePagesState\":0,\"googleAnalyticsId\":\"UA-19707169-24\",\"ampLogo\":{\"imageId\":\"\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":0,\"originalHeight\":0,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"header\":{\"title\":\"Towards Data Science\",\"description\":\"Sharing concepts, ideas, and codes\",\"backgroundImage\":{},\"logoImage\":{},\"alignment\":2,\"layout\":5},\"paidForDomainAt\":1509037374118,\"type\":\"Collection\"},\"newsletterId\":\"\",\"webCanonicalUrl\":\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\",\"mediumUrl\":\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\",\"migrationId\":\"\",\"notifyFollowers\":true,\"notifyTwitter\":false,\"notifyFacebook\":false,\"responseHiddenOnParentPostAt\":0,\"isSeries\":false,\"isSubscriptionLocked\":true,\"seriesLastAppendedAt\":0,\"audioVersionDurationSec\":0,\"sequenceId\":\"\",\"isNsfw\":false,\"isEligibleForRevenue\":true,\"isBlockedFromHightower\":false,\"deletedAt\":0,\"lockedPostSource\":1,\"hightowerMinimumGuaranteeStartsAt\":0,\"hightowerMinimumGuaranteeEndsAt\":0,\"featureLockRequestAcceptedAt\":0,\"mongerRequestType\":1,\"layerCake\":3,\"socialTitle\":\"\",\"socialDek\":\"\",\"editorialPreviewTitle\":\"\",\"editorialPreviewDek\":\"\",\"curationEligibleAt\":1554217874151,\"primaryTopic\":{\"topicId\":\"1af65db9c2f8\",\"slug\":\"artificial-intelligence\",\"createdAt\":1487916832419,\"deletedAt\":0,\"image\":{\"id\":\"1*A28aHchbaA8zNVXraBq0Ug@2x.jpeg\",\"originalWidth\":4866,\"originalHeight\":3244},\"name\":\"Artificial Intelligence\",\"description\":\"Born to be bot.\",\"relatedTopics\":[],\"visibility\":1,\"relatedTags\":[],\"type\":\"Topic\"},\"primaryTopicId\":\"1af65db9c2f8\",\"type\":\"Post\"},\"mentionedUsers\":[],\"collaborators\":[],\"hideMeter\":false,\"collectionUserRelations\":[],\"mode\":null,\"references\":{\"User\":{\"479cace88d58\":{\"userId\":\"479cace88d58\",\"name\":\"Maurizio Santamicone\",\"username\":\"mauriziosantamicone\",\"createdAt\":1538056636750,\"imageId\":\"1*9tRCoLMCijoqWB0ePvW6Wg.jpeg\",\"backgroundImageId\":\"\",\"bio\":\"Data Scientist. Founder at Fliptin Technologies, Soulstice Consulting. Investor. Startups. AI, Machine Learning.\",\"twitterScreenName\":\"santamm\",\"socialStats\":{\"userId\":\"479cace88d58\",\"usersFollowedCount\":2,\"usersFollowedByCount\":2,\"type\":\"SocialStats\"},\"social\":{\"userId\":\"lo_6G8DpQ9xFsFp\",\"targetUserId\":\"479cace88d58\",\"type\":\"Social\"},\"facebookAccountId\":\"10155520971186573\",\"allowNotes\":1,\"mediumMemberAt\":1548057267000,\"isNsfw\":false,\"isWriterProgramEnrolled\":true,\"isQuarantined\":false,\"type\":\"User\"}},\"Collection\":{\"7f60cf5620c9\":{\"id\":\"7f60cf5620c9\",\"name\":\"Towards Data Science\",\"slug\":\"towards-data-science\",\"tags\":[\"DATA SCIENCE\",\"MACHINE LEARNING\",\"ARTIFICIAL INTELLIGENCE\",\"BIG DATA\",\"ANALYTICS\"],\"creatorId\":\"895063a310f4\",\"description\":\"Sharing concepts, ideas, and codes.\",\"shortDescription\":\"Sharing concepts, ideas, and codes.\",\"image\":{\"imageId\":\"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1275,\"originalHeight\":1275,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"metadata\":{\"followerCount\":206076,\"activeAt\":1555943821581},\"virtuals\":{\"permissions\":{\"canPublish\":false,\"canPublishAll\":false,\"canRepublish\":false,\"canRemove\":false,\"canManageAll\":false,\"canSubmit\":false,\"canEditPosts\":false,\"canAddWriters\":false,\"canViewStats\":false,\"canSendNewsletter\":false,\"canViewLockedPosts\":false,\"canViewCloaked\":false,\"canEditOwnPosts\":false,\"canBeAssignedAuthor\":false,\"canEnrollInHightower\":false,\"canLockPostsForMediumMembers\":false,\"canLockOwnPostsForMediumMembers\":false},\"isSubscribed\":false,\"isNewsletterSubscribed\":false,\"isEnrolledInHightower\":false,\"isEligibleForHightower\":false},\"logo\":{\"imageId\":\"1*5EUO1kUYBthpOCPzRj_l2g.png\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1010,\"originalHeight\":376,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"twitterUsername\":\"TDataScience\",\"facebookPageName\":\"towardsdatascience\",\"collectionMastheadId\":\"8b6aceffde6\",\"domain\":\"towardsdatascience.com\",\"sections\":[{\"type\":2,\"collectionHeaderMetadata\":{\"title\":\"Towards Data Science\",\"description\":\"Sharing concepts, ideas, and codes\",\"backgroundImage\":{},\"logoImage\":{},\"alignment\":2,\"layout\":5}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"7f2f79e10e3f\",\"8e2374e11bfb\"]}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":3,\"postIds\":[\"449f3c5f6e99\",\"3bc890dac04d\",\"4e73e55de341\"],\"sectionHeader\":\"Featured \"}},{\"type\":1,\"postListMetadata\":{\"source\":1,\"layout\":4,\"number\":6,\"postIds\":[],\"sectionHeader\":\"Latest\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"badbb1726722\",\"7e5819af339d\"],\"sectionHeader\":\"Our Letters\"}},{\"type\":3,\"promoMetadata\":{\"sectionHeader\":\"\",\"promoId\":\"126dff5b63d2\"}},{\"type\":1,\"postListMetadata\":{\"source\":2,\"layout\":4,\"number\":6,\"postIds\":[],\"sectionHeader\":\"Trending\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"3bf37f75a345\",\"3920888f831c\"],\"sectionHeader\":\"Our Readers\u2019 Guide\"}},{\"type\":1,\"postListMetadata\":{\"source\":4,\"layout\":4,\"number\":9,\"postIds\":[],\"tagSlug\":\"Towards Data Science\",\"sectionHeader\":\"Editors' Picks\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"96667b06af5\",\"f8432d67a777\"],\"sectionHeader\":\"Contribute\"}},{\"type\":1,\"postListMetadata\":{\"source\":3,\"layout\":4,\"number\":2,\"postIds\":[\"d691af11cc2f\",\"c2c8e712c971\"]}},{\"type\":1,\"postListMetadata\":{\"source\":4,\"layout\":5,\"number\":3,\"postIds\":[],\"tagSlug\":\"Towards Data Science\",\"sectionHeader\":\"Last Chance To Read\"}}],\"tintColor\":\"#FF355876\",\"lightText\":true,\"favicon\":{\"imageId\":\"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":1275,\"originalHeight\":1275,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"colorPalette\":{\"defaultBackgroundSpectrum\":{\"colorPoints\":[{\"color\":\"#FF668AAA\",\"point\":0},{\"color\":\"#FF61809D\",\"point\":0.1},{\"color\":\"#FF5A7690\",\"point\":0.2},{\"color\":\"#FF546C83\",\"point\":0.3},{\"color\":\"#FF4D6275\",\"point\":0.4},{\"color\":\"#FF455768\",\"point\":0.5},{\"color\":\"#FF3D4C5A\",\"point\":0.6},{\"color\":\"#FF34414C\",\"point\":0.7},{\"color\":\"#FF2B353E\",\"point\":0.8},{\"color\":\"#FF21282F\",\"point\":0.9},{\"color\":\"#FF161B1F\",\"point\":1}],\"backgroundColor\":\"#FFFFFFFF\"},\"tintBackgroundSpectrum\":{\"colorPoints\":[{\"color\":\"#FF355876\",\"point\":0},{\"color\":\"#FF4D6C88\",\"point\":0.1},{\"color\":\"#FF637F99\",\"point\":0.2},{\"color\":\"#FF7791A8\",\"point\":0.3},{\"color\":\"#FF8CA2B7\",\"point\":0.4},{\"color\":\"#FF9FB3C6\",\"point\":0.5},{\"color\":\"#FFB2C3D4\",\"point\":0.6},{\"color\":\"#FFC5D2E1\",\"point\":0.7},{\"color\":\"#FFD7E2EE\",\"point\":0.8},{\"color\":\"#FFE9F1FA\",\"point\":0.9},{\"color\":\"#FFFBFFFF\",\"point\":1}],\"backgroundColor\":\"#FF355876\"},\"highlightSpectrum\":{\"colorPoints\":[{\"color\":\"#FFEDF4FC\",\"point\":0},{\"color\":\"#FFE9F2FD\",\"point\":0.1},{\"color\":\"#FFE6F1FD\",\"point\":0.2},{\"color\":\"#FFE2EFFD\",\"point\":0.3},{\"color\":\"#FFDFEEFD\",\"point\":0.4},{\"color\":\"#FFDBECFE\",\"point\":0.5},{\"color\":\"#FFD7EBFE\",\"point\":0.6},{\"color\":\"#FFD4E9FE\",\"point\":0.7},{\"color\":\"#FFD0E7FF\",\"point\":0.8},{\"color\":\"#FFCCE6FF\",\"point\":0.9},{\"color\":\"#FFC8E4FF\",\"point\":1}],\"backgroundColor\":\"#FFFFFFFF\"}},\"navItems\":[{\"type\":4,\"title\":\"Data Science\",\"url\":\"https://towardsdatascience.com/data-science/home\",\"topicId\":\"cf416843aadc\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Machine Learning\",\"url\":\"https://towardsdatascience.com/machine-learning/home\",\"topicId\":\"a5c9b2f1cb6b\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Programming\",\"url\":\"https://towardsdatascience.com/programming/home\",\"topicId\":\"41533a1dc73c\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Visualization\",\"url\":\"https://towardsdatascience.com/data-visualization/home\",\"topicId\":\"825e6cb8b9ce\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"AI\",\"url\":\"https://towardsdatascience.com/artificial-intelligence/home\",\"topicId\":\"7f029b17bf96\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Journalism\",\"url\":\"https://towardsdatascience.com/data-journalism/home\",\"topicId\":\"27a6ac3980c6\",\"source\":\"topicId\"},{\"type\":4,\"title\":\"Picks\",\"url\":\"https://towardsdatascience.com/editors-picks/home\",\"topicId\":\"e81f4fc5ee6b\",\"source\":\"topicId\"},{\"type\":3,\"title\":\"Contribute\",\"url\":\"https://towardsdatascience.com/contribute/home\"}],\"colorBehavior\":2,\"instantArticlesState\":0,\"acceleratedMobilePagesState\":0,\"googleAnalyticsId\":\"UA-19707169-24\",\"ampLogo\":{\"imageId\":\"\",\"filter\":\"\",\"backgroundSize\":\"\",\"originalWidth\":0,\"originalHeight\":0,\"strategy\":\"resample\",\"height\":0,\"width\":0},\"header\":{\"title\":\"Towards Data Science\",\"description\":\"Sharing concepts, ideas, and codes\",\"backgroundImage\":{},\"logoImage\":{},\"alignment\":2,\"layout\":5},\"paidForDomainAt\":1509037374118,\"type\":\"Collection\"}},\"Social\":{\"479cace88d58\":{\"userId\":\"lo_6G8DpQ9xFsFp\",\"targetUserId\":\"479cace88d58\",\"type\":\"Social\"}},\"SocialStats\":{\"479cace88d58\":{\"userId\":\"479cace88d58\",\"usersFollowedCount\":2,\"usersFollowedByCount\":2,\"type\":\"SocialStats\"}}}})\n// ]]></script><script id=\"parsely-cfg\" src=\"//d1z2jf7jlzjs58.cloudfront.net/keys/medium.com/p.js\"></script><script type=\"text/javascript\">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src=\"https://cdn.branch.io/branch-latest.min.js\";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,\"script\",\"branch\",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},\"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent\".split(\" \"), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled':  false }, function(err, data) {});</script></body></html>", "content_html": "<div class=\"section-content\"><div class=\"section-inner sectionLayout--insetColumn\"><h1 class=\"graf graf--h3 graf--leading graf--title\" id=\"7b98\" name=\"7b98\">Is Artificial Intelligence Racist?</h1><h2 class=\"graf graf--h4 graf-after--h3 graf--subtitle\" id=\"82e6\" name=\"82e6\">Racial and Gender Bias in\u00a0AI</h2><div class=\"uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup\"><div class=\"u-flex0\"><a class=\"link u-baseColor--link avatar\" data-action=\"show-user-card\" data-action-source=\"post_header_lockup\" data-action-type=\"hover\" data-action-value=\"479cace88d58\" data-collection-slug=\"towards-data-science\" data-user-id=\"479cace88d58\" dir=\"auto\" href=\"https://towardsdatascience.com/@mauriziosantamicone?source=post_header_lockup\"><div class=\"u-relative u-inlineBlock u-flex0\"><img alt=\"Go to the profile of Maurizio Santamicone\" class=\"avatar-image u-size50x50\" src=\"https://cdn-images-1.medium.com/fit/c/100/100/1*9tRCoLMCijoqWB0ePvW6Wg.jpeg\"/><div class=\"avatar-halo u-absolute u-textColorGreenNormal svgIcon\" style=\"width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px\"><svg viewbox=\"0 0 70 70\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M5.53538374,19.9430227 C11.180401,8.78497536 22.6271155,1.6 35.3571429,1.6 C48.0871702,1.6 59.5338847,8.78497536 65.178902,19.9430227 L66.2496695,19.401306 C60.4023065,7.84329843 48.5440457,0.4 35.3571429,0.4 C22.17024,0.4 10.3119792,7.84329843 4.46461626,19.401306 L5.53538374,19.9430227 Z\"></path><path d=\"M65.178902,49.9077131 C59.5338847,61.0657604 48.0871702,68.2507358 35.3571429,68.2507358 C22.6271155,68.2507358 11.180401,61.0657604 5.53538374,49.9077131 L4.46461626,50.4494298 C10.3119792,62.0074373 22.17024,69.4507358 35.3571429,69.4507358 C48.5440457,69.4507358 60.4023065,62.0074373 66.2496695,50.4494298 L65.178902,49.9077131 Z\"></path></svg></div></div></a></div><div class=\"u-flex1 u-paddingLeft15 u-overflowHidden\"><div class=\"u-paddingBottom3\"><a class=\"ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker\" data-action=\"show-user-card\" data-action-type=\"hover\" data-action-value=\"479cace88d58\" data-collection-slug=\"towards-data-science\" data-user-id=\"479cace88d58\" dir=\"auto\" href=\"https://towardsdatascience.com/@mauriziosantamicone\">Maurizio Santamicone</a><span class=\"followState js-followState\" data-user-id=\"479cace88d58\"><button class=\"button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide\" data-action=\"sign-up-prompt\" data-action-source=\"post_header_lockup\" data-redirect=\"https://towardsdatascience.com/https-medium-com-mauriziosantamicone-is-artificial-intelligence-racist-66ea8f67c7de\" data-requires-token=\"true\" data-sign-in-action=\"toggle-block-user\"><span class=\"button-label button-defaultState\">Blocked</span><span class=\"button-label button-hoverState\">Unblock</span></button><button class=\"button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide\" data-action=\"sign-up-prompt\" data-action-source=\"post_header_lockup-479cace88d58-------------------------follow_byline\" data-redirect=\"https://medium.com/_/subscribe/user/479cace88d58\" data-requires-token=\"true\" data-sign-in-action=\"toggle-subscribe-user\"><span class=\"button-label button-defaultState js-buttonLabel\">Follow</span><span class=\"button-label button-activeState\">Following</span></button></span></div><div class=\"ui-caption u-noWrapWithEllipsis js-testPostMetaInlineSupplemental\"><time datetime=\"2019-04-02T15:11:15.062Z\">Apr 2</time><span class=\"middotDivider u-fontSize12\"></span><span class=\"readingTime\" title=\"6 min read\"></span><span class=\"u-paddingLeft4\"><span class=\"svgIcon svgIcon--star svgIcon--15px\"><svg class=\"svgIcon-use\" height=\"15\" width=\"15\"><path d=\"M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z\"></path></svg></span></span></div></div></div><figure class=\"graf graf--figure graf-after--h4\" id=\"8e3a\" name=\"8e3a\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 700px; max-height: 374px;\"><div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 53.5%;\"></div><div class=\"progressiveMedia js-progressiveMedia graf-image\" data-action=\"zoom\" data-action-value=\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\" data-height=\"460\" data-image-id=\"1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\" data-width=\"860\"><img class=\"progressiveMedia-thumbnail js-progressiveMedia-thumbnail\" crossorigin=\"anonymous\" src=\"https://cdn-images-1.medium.com/freeze/max/60/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg?q=20\"/><canvas class=\"progressiveMedia-canvas js-progressiveMedia-canvas\"></canvas><img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1600/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\"/><noscript class=\"js-progressiveMedia-inner\"><img class=\"progressiveMedia-noscript js-progressiveMedia-inner\" src=\"https://cdn-images-1.medium.com/max/1600/1*O5EJEcF-jUkHoms_DW_4Bw.jpeg\"/></noscript></div></div></figure><p class=\"graf graf--p graf-after--figure\" id=\"40ed\" name=\"40ed\">Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://abcnews.go.com/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\" href=\"https://abcnews.go.com/Politics/ta-nehisi-coates-alexandria-ocasio-cortez-discuss-martin/story?id=60532979\" rel=\"noopener\" target=\"_blank\">Martin Luther King Jr. day event in New York City</a>. She was of course derided the following day by conservative commentators.</p><p class=\"graf graf--p graf-after--p\" id=\"8c81\" name=\"8c81\">But she is right.</p><p class=\"graf graf--p graf-after--p\" id=\"18b7\" name=\"18b7\"><a class=\"markup--anchor markup--p-anchor\" data-href=\"http://gendershades.org\" href=\"http://gendershades.org\" rel=\"noopener\" target=\"_blank\">Joy Buolamwini</a>, an MIT scientist and founder of the <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://www.ajlunited.org/gender-shades\" href=\"http://www.ajlunited.org/gender-shades\" rel=\"noopener\" target=\"_blank\">Algorithmic Justice League</a>, published a research that uncovered large gender and racial bias in AI systems sold by tech giants like IBM, Microsoft, and Amazon. Given the task of guessing the gender of a face, all companies performed substantially better on male faces than female faces. The error rates were no more than 1% for lighter-skinned men whilst for darker-skinned women, the errors soared to 35%. When tasked to classify the faces of Oprah Winfrey, Michelle Obama, and Serena Williams, the systems failed.</p><figure class=\"graf graf--figure graf-after--p\" id=\"3674\" name=\"3674\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 700px; max-height: 592px;\"><div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 84.6%;\"></div><div class=\"progressiveMedia js-progressiveMedia graf-image\" data-action=\"zoom\" data-action-value=\"1*s2hOVNc8SPNUjZufAOgHpg.png\" data-height=\"791\" data-image-id=\"1*s2hOVNc8SPNUjZufAOgHpg.png\" data-width=\"935\"><img class=\"progressiveMedia-thumbnail js-progressiveMedia-thumbnail\" crossorigin=\"anonymous\" src=\"https://cdn-images-1.medium.com/freeze/max/60/1*s2hOVNc8SPNUjZufAOgHpg.png?q=20\"/><canvas class=\"progressiveMedia-canvas js-progressiveMedia-canvas\"></canvas><img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1600/1*s2hOVNc8SPNUjZufAOgHpg.png\"/><noscript class=\"js-progressiveMedia-inner\"><img class=\"progressiveMedia-noscript js-progressiveMedia-inner\" src=\"https://cdn-images-1.medium.com/max/1600/1*s2hOVNc8SPNUjZufAOgHpg.png\"/></noscript></div></div><figcaption class=\"imageCaption\">License: Joy Buolamwini\u200a\u2014\u200a<a class=\"markup--anchor markup--figure-anchor\" data-href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" rel=\"noopener\" target=\"_blank\">Mit Lab Press\u00a0Kit</a></figcaption></figure><p class=\"graf graf--p graf-after--figure\" id=\"5323\" name=\"5323\">These technologies are today penetrating every layer of society. Decisions like determining who is hired, fired, granted a loan, or how long an individual spends in prison have traditionally been performed by humans. Today, they are rapidly made by algorithms or at least algorithms are used in the decision making process for such tasks.</p><p class=\"graf graf--p graf-after--p\" id=\"34d2\" name=\"34d2\">Machine learning algorithms sift through millions of pieces of data and make correlations and predictions about the world. Their appeal is huge: machines can use hard data to make decisions that are sometimes more accurate than a human\u2019s.</p><figure class=\"graf graf--figure graf-after--p\" id=\"e2ae\" name=\"e2ae\"><div class=\"aspectRatioPlaceholder is-locked\" style=\"max-width: 700px; max-height: 466px;\"><div class=\"aspectRatioPlaceholder-fill\" style=\"padding-bottom: 66.60000000000001%;\"></div><div class=\"progressiveMedia js-progressiveMedia graf-image\" data-action=\"zoom\" data-action-value=\"1*1ffhogHj4damUCp7WdX5Jg.png\" data-height=\"616\" data-image-id=\"1*1ffhogHj4damUCp7WdX5Jg.png\" data-width=\"925\"><img class=\"progressiveMedia-thumbnail js-progressiveMedia-thumbnail\" crossorigin=\"anonymous\" src=\"https://cdn-images-1.medium.com/freeze/max/60/1*1ffhogHj4damUCp7WdX5Jg.png?q=20\"/><canvas class=\"progressiveMedia-canvas js-progressiveMedia-canvas\"></canvas><img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1600/1*1ffhogHj4damUCp7WdX5Jg.png\"/><noscript class=\"js-progressiveMedia-inner\"><img class=\"progressiveMedia-noscript js-progressiveMedia-inner\" src=\"https://cdn-images-1.medium.com/max/1600/1*1ffhogHj4damUCp7WdX5Jg.png\"/></noscript></div></div><figcaption class=\"imageCaption\">License: Joy Buolamwini\u200a\u2014\u200a<a class=\"markup--anchor markup--figure-anchor\" data-href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" href=\"https://www.media.mit.edu/projects/gender-shades/press-kit/\" rel=\"noopener\" target=\"_blank\">Mit Lab Press\u00a0Kit</a></figcaption></figure><p class=\"graf graf--p graf-after--figure\" id=\"5e9f\" name=\"5e9f\">Computer vision is used in policing, i.e. identifying suspects in a crowd. <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://www.palantir.com\" href=\"https://www.palantir.com\" rel=\"noopener\" target=\"_blank\">Palantir</a>, a company founded by tech billionaire and Trump donor Peter Thiel, has been using its predictive policing technologies in New Orleans for the last six years: this program was so secretive that even council members knew nothing about it. Amazon has been selling police departments a real time face recognition system that <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://www.buzzfeednews.com/article/daveyalba/amazon-rekognition-facial-recognition-congress-false\" href=\"https://www.buzzfeednews.com/article/daveyalba/amazon-rekognition-facial-recognition-congress-false\" rel=\"noopener\" target=\"_blank\">falsely matched 28 member of Congress with mugshots</a>. The problem with these systems is that although they are effective on general tasks, they usually return a high number of <em class=\"markup--em markup--p-em\">false positives </em>(in statistics, a false positive is when a statistical test returns a Type I error, like an HIV test resulting positive on an HIV-negative patient). Combine it with racial bias, and we get a racist policing system, independently from who is using it.</p><p class=\"graf graf--p graf-after--p\" id=\"66a4\" name=\"66a4\">The influence of bias is present in plenty of other types of data as well. For instance, a straightforward application of Machine Learning where computers outperform humans is loan approvals. Financial institutions leverage on historical data to train their algorithms over millions of records allowing them to capture patterns in the data that best identify the features of mortgage applicants.</p><p class=\"graf graf--p graf-after--p\" id=\"9d90\" name=\"9d90\">The problem is that algorithms can learn <em class=\"markup--em markup--p-em\">too much</em>. Suppose Thokozane is a brilliant graduate student from a poor Soweto neighborhood that has been working regularly for the past few years, has a clean credit record and has finally decided to apply for a loan to buy his first property. According to all the criteria traditionally used by banks to evaluate someone\u2019s creditworthiness, his application should be approved. The algorithm, however, has another plan. It has learnt in the meantime that applicants from the same poor neighborhood TK is from have in the last few years had most of their applications rejected because of poor credit records, insufficient disposable income ans so on. So TK\u2019s application is surpriringly rejected. In other words, the algorithm has learnt an <em class=\"markup--em markup--p-em\">implicit bias</em>.</p><p class=\"graf graf--p graf-after--p\" id=\"2fad\" name=\"2fad\">TK is of course reasonably upset about this, and decides to ask the bank for an explanation, as he alleges that the algorithm has discriminated racially against him. The bank of course replies that this is not possible, as the algorithms have been intentionally blinded to the race of the applicants (this assumption is optimistic). However, the problem is that while some algorithms like DecisionTrees may enable an auditor to discover if the address information was used in a way to penalize applicants who were born or previously resided in predominantly poverty-stricken areas, other algorithms like Deep Learning are much more sophisticated and tend to be a \u201cblack box\u201d to external inspection, and it may prove almost impossible to understand why, or even how, a certain decision has been taken.</p><p class=\"graf graf--p graf-after--p\" id=\"abc6\" name=\"abc6\">In 2017 a paper was published on <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://science.sciencemag.org/content/356/6334/183\" href=\"http://science.sciencemag.org/content/356/6334/183\" rel=\"noopener\" target=\"_blank\"><em class=\"markup--em markup--p-em\">Science</em></a><em class=\"markup--em markup--p-em\"> </em>that found that as a computer teaches itself English, it becomes prejudiced against black Americans and women. Using data \u201cscraped\u201d from the web called the \u201cCommon Crawl\u201d, a corpus containing approximately 840 billion words, it shows that machines can learn word associations from written texts and that these associations mirror those learned by humans, such as pleasantness and flowers or unpleasantness and insects. So far so good. But it also shows that machine learning absorbs stereotyped biases as easily as any other\u200a\u2014\u200afor example, associations between female names and family or male names and career. From bad to worse, the researchers found that names associated with being European American were signi\ufb01cantly more easily associated with pleasant than unpleasant terms, compared to some African American names.</p><p class=\"graf graf--p graf-after--p\" id=\"ec64\" name=\"ec64\">A computer builds its vocabulary using frequency data, or how often terms appear together. So it found that on the internet, African-American names are more likely to be surrounded by words that connote unpleasantness. Is that because African Americans are unpleasant? Of course not. It\u2019s because people on the internet write and say horrible things.</p><p class=\"graf graf--p graf-after--p\" id=\"17c1\" name=\"17c1\">The bias this time is not so implicit, is it?</p><h3 class=\"graf graf--h3 graf-after--p\" id=\"e696\" name=\"e696\">So what should be\u00a0done?</h3><p class=\"graf graf--p graf-after--h3\" id=\"5631\" name=\"5631\"><a class=\"markup--anchor markup--p-anchor\" data-href=\"https://youtu.be/LqjP7O9SxOM\" href=\"https://youtu.be/LqjP7O9SxOM\" rel=\"noopener\" target=\"_blank\">Rachel Thomas</a>, co-founder of <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://fast.ai\" href=\"http://fast.ai\" rel=\"noopener\" target=\"_blank\">fast.ai</a>, a deep learning lab based in San Francisco whose motto is \u201cmaking neural nets uncool\u201d, advocates for a more open and inclusive AI, that embraces people from different backgrounds and communities, people who don\u2019t \u201cfit in\u201d the current system, because they have a better understanding of how tech can be weaponized against the most vulnerable: \u201c<em class=\"markup--em markup--p-em\">We can\u2019t afford to have a tech that is run by an exclusive and homogenous group creating technology that impacts us all. We need more experts about people, like human psychology, behavior and history. AI needs more unlikely people.</em>\u201d</p><p class=\"graf graf--p graf-after--p\" id=\"bf53\" name=\"bf53\">Unsurprisingly, <a class=\"markup--anchor markup--p-anchor\" data-href=\"http://gendershades.org/\" href=\"http://gendershades.org/\" rel=\"noopener\" target=\"_blank\">Joy Buolamwini</a> has a similar opinion: \u201c<em class=\"markup--em markup--p-em\">Data centric technologies are vulnerable to bias and abuse. As a result, we must demand more transparency and accountability. We have entered the age of automation overconfident yet underprepared. If we fail to make an ethical and inclusive AI, we risk losing gains made in civil rights and gender equity under the guise of machine neutrality.</em>\u201d</p><h3 class=\"graf graf--h3 graf-after--p\" id=\"69a8\" name=\"69a8\">So what is \u201cmainstream AI\u201d doing about\u00a0it?</h3><p class=\"graf graf--p graf-after--h3\" id=\"79cc\" name=\"79cc\">Let\u2019s take a peek at the Silicon Valley.</p><p class=\"graf graf--p graf-after--p\" id=\"9d69\" name=\"9d69\">Stanford University recently launched amid great fanfare the <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://hai.stanford.edu/\" href=\"https://hai.stanford.edu/\" rel=\"noopener\" target=\"_blank\">Institute for Human-Centered Artificial Intelligence</a>, or HAI, lead by <a class=\"markup--anchor markup--p-anchor\" data-href=\"https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/\" href=\"https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/\" rel=\"noopener\" target=\"_blank\">Fei Fei Li</a>, one of the most prolific researchers in the field and former Chief Scientist of AI/ML at Google Cloud. HAI will work on topics such as how to ensure algorithms make fair decisions in government or finance, and what new regulations may be required on AI applications. \u201c<em class=\"markup--em markup--p-em\">AI started as a computer science discipline, but now we are in a new chapter. This technology has the potential to do so many good things, but there are also risks and pitfalls. We have to act and make sure it is human benevolent.</em>\u201d</p><p class=\"graf graf--p graf-after--p\" id=\"84c8\" name=\"84c8\">HAI has 121 faculty member listed. Not a single one of them is black.</p><p class=\"graf graf--p graf-after--p graf--trailing\" id=\"3707\" name=\"3707\">AI desperately needs diversity. Diversity in AI will help reduce biases, and government agencies, corporates and institutions who implement data centric applications need to integrate de-biasing efforts into their data pipelines; they mustn\u2019t just hire lawyers to make their systems compliant, they need to include many different thinkers from psychology, social sciences, philosophy if they want to achieve significantly better results.</p></div></div> ", "content": "Is Artificial Intelligence Racist? Racial and Gender Bias in\u00a0AI Maurizio Santamicone Blocked Unblock Follow Following Apr 2 Outspoken US Congresswoman Alexandria Ocasio-Cortez recently said that AI can be biased during a Martin Luther King Jr. day event in New York City . She was of course derided the following day by conservative commentators. But she is right. Joy Buolamwini , an MIT scientist and founder of the Algorithmic Justice League , published a research that uncovered large gender and racial bias in AI systems sold by tech giants like IBM, Microsoft, and Amazon. Given the task of guessing the gender of a face, all companies performed substantially better on male faces than female faces. The error rates were no more than 1% for lighter-skinned men whilst for darker-skinned women, the errors soared to 35%. When tasked to classify the faces of Oprah Winfrey, Michelle Obama, and Serena Williams, the systems failed. License: Joy Buolamwini\u200a\u2014\u200a Mit Lab Press\u00a0Kit These technologies are today penetrating every layer of society. Decisions like determining who is hired, fired, granted a loan, or how long an individual spends in prison have traditionally been performed by humans. Today, they are rapidly made by algorithms or at least algorithms are used in the decision making process for such tasks. Machine learning algorithms sift through millions of pieces of data and make correlations and predictions about the world. Their appeal is huge: machines can use hard data to make decisions that are sometimes more accurate than a human\u2019s. License: Joy Buolamwini\u200a\u2014\u200a Mit Lab Press\u00a0Kit Computer vision is used in policing, i.e. identifying suspects in a crowd. Palantir , a company founded by tech billionaire and Trump donor Peter Thiel, has been using its predictive policing technologies in New Orleans for the last six years: this program was so secretive that even council members knew nothing about it. Amazon has been selling police departments a real time face recognition system that falsely matched 28 member of Congress with mugshots . The problem with these systems is that although they are effective on general tasks, they usually return a high number of false positives (in statistics, a false positive is when a statistical test returns a Type I error, like an HIV test resulting positive on an HIV-negative patient). Combine it with racial bias, and we get a racist policing system, independently from who is using it. The influence of bias is present in plenty of other types of data as well. For instance, a straightforward application of Machine Learning where computers outperform humans is loan approvals. Financial institutions leverage on historical data to train their algorithms over millions of records allowing them to capture patterns in the data that best identify the features of mortgage applicants. The problem is that algorithms can learn too much . Suppose Thokozane is a brilliant graduate student from a poor Soweto neighborhood that has been working regularly for the past few years, has a clean credit record and has finally decided to apply for a loan to buy his first property. According to all the criteria traditionally used by banks to evaluate someone\u2019s creditworthiness, his application should be approved. The algorithm, however, has another plan. It has learnt in the meantime that applicants from the same poor neighborhood TK is from have in the last few years had most of their applications rejected because of poor credit records, insufficient disposable income ans so on. So TK\u2019s application is surpriringly rejected. In other words, the algorithm has learnt an implicit bias . TK is of course reasonably upset about this, and decides to ask the bank for an explanation, as he alleges that the algorithm has discriminated racially against him. The bank of course replies that this is not possible, as the algorithms have been intentionally blinded to the race of the applicants (this assumption is optimistic). However, the problem is that while some algorithms like DecisionTrees may enable an auditor to discover if the address information was used in a way to penalize applicants who were born or previously resided in predominantly poverty-stricken areas, other algorithms like Deep Learning are much more sophisticated and tend to be a \u201cblack box\u201d to external inspection, and it may prove almost impossible to understand why, or even how, a certain decision has been taken. In 2017 a paper was published on Science that found that as a computer teaches itself English, it becomes prejudiced against black Americans and women. Using data \u201cscraped\u201d from the web called the \u201cCommon Crawl\u201d, a corpus containing approximately 840 billion words, it shows that machines can learn word associations from written texts and that these associations mirror those learned by humans, such as pleasantness and flowers or unpleasantness and insects. So far so good. But it also shows that machine learning absorbs stereotyped biases as easily as any other\u200a\u2014\u200afor example, associations between female names and family or male names and career. From bad to worse, the researchers found that names associated with being European American were signi\ufb01cantly more easily associated with pleasant than unpleasant terms, compared to some African American names. A computer builds its vocabulary using frequency data, or how often terms appear together. So it found that on the internet, African-American names are more likely to be surrounded by words that connote unpleasantness. Is that because African Americans are unpleasant? Of course not. It\u2019s because people on the internet write and say horrible things. The bias this time is not so implicit, is it? So what should be\u00a0done? Rachel Thomas , co-founder of fast.ai , a deep learning lab based in San Francisco whose motto is \u201cmaking neural nets uncool\u201d, advocates for a more open and inclusive AI, that embraces people from different backgrounds and communities, people who don\u2019t \u201cfit in\u201d the current system, because they have a better understanding of how tech can be weaponized against the most vulnerable: \u201c We can\u2019t afford to have a tech that is run by an exclusive and homogenous group creating technology that impacts us all. We need more experts about people, like human psychology, behavior and history. AI needs more unlikely people. \u201d Unsurprisingly, Joy Buolamwini has a similar opinion: \u201c Data centric technologies are vulnerable to bias and abuse. As a result, we must demand more transparency and accountability. We have entered the age of automation overconfident yet underprepared. If we fail to make an ethical and inclusive AI, we risk losing gains made in civil rights and gender equity under the guise of machine neutrality. \u201d So what is \u201cmainstream AI\u201d doing about\u00a0it? Let\u2019s take a peek at the Silicon Valley. Stanford University recently launched amid great fanfare the Institute for Human-Centered Artificial Intelligence , or HAI, lead by Fei Fei Li , one of the most prolific researchers in the field and former Chief Scientist of AI/ML at Google Cloud. HAI will work on topics such as how to ensure algorithms make fair decisions in government or finance, and what new regulations may be required on AI applications. \u201c AI started as a computer science discipline, but now we are in a new chapter. This technology has the potential to do so many good things, but there are also risks and pitfalls. We have to act and make sure it is human benevolent. \u201d HAI has 121 faculty member listed. Not a single one of them is black. AI desperately needs diversity. Diversity in AI will help reduce biases, and government agencies, corporates and institutions who implement data centric applications need to integrate de-biasing efforts into their data pipelines; they mustn\u2019t just hire lawyers to make their systems compliant, they need to include many different thinkers from psychology, social sciences, philosophy if they want to achieve significantly better results.", "read_time": 387.0, "title_html": "<h1 class=\"graf graf--h3 graf--leading graf--title\" id=\"7b98\" name=\"7b98\">Is Artificial Intelligence Racist?</h1> "}