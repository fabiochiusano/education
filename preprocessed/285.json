{"content": "By Ahmed Gad , KDnuggets Contributor. In this article, two basic feed-forward neural networks (FFNNs) will be created using TensorFlow deep learning library in Python. The reader should have basic understanding of how neural networks work and its concepts in order to apply them programmatically. This article will take you through all steps required to build a simple feed-forward neural network in TensorFlow by explaining each step in details. Before actual building of the neural network, some preliminary steps are recommended to be discussed. The summarized steps are as follows: Reading the training data (inputs and outputs) Building and connect the neural networks layers (this included preparing weights, biases, and activation function of each layer) Building a loss function to assess the prediction error Create a training loop for training the network and updating its parameters Applying some testing data to assess the network prediction accuracy Here is the first classification problem that we are to solve using neural network. It is a binary classification problem to classify colors into either red or blue based on the three RGB color channels. It can be solved linearly and thus we don`t have to use hidden layers. Just input and output layers are to be used. There will be a single neuron in the output layer with an activation function. The network architecture is shown in the following figure ( Figure 1 ): Where X0=1 is the bias and W0 is its weight. W1 , W2, and W3 are the weights for the three inputs R (Red), G (Green), and B (Blue). Here is the complete code of the neural network solving that problem to be discussed later. For easy access, this code is called\u00a0 CodeSample1 . 1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r 2.\u00a0 \u00a0\u00a0\r 3.\u00a0 #\u00a0Preparing\u00a0training\u00a0data\u00a0(inputs-outputs)\u00a0\u00a0\r 4.\u00a0 training_inputs\u00a0=\u00a0\u00a0\u00a0\r 5.\u00a0 training_outputs\u00a0=\u00a0\u00a0#Desired\u00a0outputs\u00a0for\u00a0each\u00a0input\u00a0\u00a0\r 6.\u00a0 \u00a0\u00a0\r 7.\u00a0 #\u00a0Preparing\u00a0neural\u00a0network\u00a0parameters\u00a0(weights\u00a0and\u00a0bias)\u00a0using\u00a0TensorFlow\u00a0Variables\u00a0\u00a0\r 8.\u00a0 weights\u00a0=\u00a0\u00a0\u00a0\r 9.\u00a0 bias\u00a0=\u00a0\u00a0\u00a0\r 10. \u00a0\u00a0\r 11. #\u00a0Preparing\u00a0inputs\u00a0of\u00a0the\u00a0activation\u00a0function\u00a0\u00a0\r 12. af_input\u00a0=\u00a0\u00a0+\u00a0bias\u00a0\u00a0\r 13. \u00a0\u00a0\r 14. #\u00a0Activation\u00a0function\u00a0of\u00a0the\u00a0output\u00a0layer\u00a0neuron\u00a0\u00a0\r 15. predictions\u00a0=\u00a0\u00a0\u00a0\r 16. \u00a0\u00a0\r 17. #\u00a0Measuring\u00a0the\u00a0prediction\u00a0error\u00a0of\u00a0the\u00a0network after being trained\u00a0\u00a0\r 18. prediction_error\u00a0=\u00a0\u00a0\u00a0\r 19. \u00a0\u00a0\r 20. #\u00a0Minimizing\u00a0the\u00a0prediction\u00a0error\u00a0using\u00a0gradient\u00a0descent\u00a0optimizer\u00a0\u00a0\r 21. train_op\u00a0=\u00a0.\u00a0\u00a0\r 22. \u00a0\u00a0\r 23. #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r 24. sess\u00a0=\u00a0\u00a0\u00a0\r 25. \u00a0\u00a0\r 26. #\u00a0Initializing\u00a0the\u00a0TensorFlow\u00a0Variables\u00a0(weights\u00a0and\u00a0bias)\u00a0\u00a0\r 27. )\u00a0\u00a0\r 28. \u00a0\u00a0\r 29. #\u00a0Training\u00a0data\u00a0inputs\u00a0\u00a0\r 30. training_inputs_data\u00a0=\u00a0[[255,\u00a00,\u00a00],\u00a0\u00a0\r 31. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[248,\u00a080,\u00a068],\u00a0\u00a0\r 32. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[0,\u00a00,\u00a0255],\u00a0\u00a0\r 33. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[67,\u00a015,\u00a0210]]\u00a0\u00a0\r 34. \u00a0\u00a0\r 35. #\u00a0Training\u00a0data\u00a0desired\u00a0outputs\u00a0\u00a0\r 36. training_outputs_data\u00a0=\u00a0[[1],\u00a0\u00a0\r 37. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [1],\u00a0\u00a0\r 38. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [0],\u00a0\u00a0\r 39. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [0]]\u00a0\u00a0\r 40. \u00a0\u00a0\r 41. #\u00a0Training\u00a0loop\u00a0of\u00a0the\u00a0neural\u00a0network\u00a0\u00a0\r 42. for\u00a0step\u00a0in\u00a0:\u00a0\u00a0\r 43. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r 46. \u00a0\u00a0\r 47. #\u00a0Class scores\u00a0of\u00a0some\u00a0testing\u00a0data\u00a0\u00a0\r 48. )\u00a0\u00a0\r 49. \u00a0\r 50. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0to\u00a0free\u00a0resources\u00a0\u00a0\r 51.  \u00a0 Reading the Training Data \u00a0 The data is read in the previous code in lines 4 and 5 using something called placeholder. But what is a placeholder? Why we have not just used a NumPy array for preparing the data? To answer these questions, we can explore a simpler example that reads some inputs and print it to the console as follows: 1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r 2.\u00a0 \u00a0\u00a0\r 3.\u00a0 #\u00a0Creating\u00a0a\u00a0NumPy\u00a0array\u00a0holding\u00a0the\u00a0input\u00a0data\u00a0\u00a0\r 4.\u00a0 numpy_inputs\u00a0=\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r 5.\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]\u00a0\u00a0\r 6.\u00a0 \u00a0\u00a0\r 7.\u00a0 #\u00a0Converting\u00a0the\u00a0NumPy\u00a0array\u00a0to\u00a0a\u00a0TensorFlow\u00a0Tensor\u00a0\u00a0\r 8.\u00a0 #\u00a0\u00a0doc:\u00a0/api_docs/python/tf/convert_to_tensor\u00a0\u00a0\r 9.\u00a0 training_inputs\u00a0=\u00a0\u00a0\u00a0\r 10. \u00a0\u00a0\r 11. #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r 12. sess\u00a0=\u00a0\u00a0\u00a0\r 13. \u00a0\u00a0\r 14. #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0the\u00a0previously\u00a0created\u00a0Tensor\u00a0\u00a0\r 15. )\u00a0\u00a0\r 16. \u00a0\u00a0\r 17. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r 18.  The input is read into a NumPy array away from TensorFlow as in line 4. But TensorFlow just know Tensors and just we have to convert the NumPy array into a Tensor. The  TensorFlow operation does that conversion as in line 9. To be able to print the contents of a Tensor, we must at first create a Session using the  class as in line 12. In line 15, the session runs in order evaluate the Tensor training_inputs and get its values printed. Finally, the session got closed in line 18. The result of printing is as follows: Output\u00a0is\u00a0:\u00a0\u00a0[[\u00a05\u00a0\u00a02\u00a013]\u00a0,\u00a0[\u00a07\u00a0\u00a09\u00a0\u00a00]] This example doesn`t use placeholders. So, what is the use of a TensorFlow placeholder? Assume that we want to run the session with another input. To do that, we have to modify the numpy_input Python variable each time a new input is applied. numpy_inputs\u00a0=\u00a0[[83,\u00a049,\u00a092],\u00a0\u00a0[31,\u00a078,\u00a060]] It is not a good way to modify the code in order to get different inputs. A better way for doing that is to just create the Tensor and then modify its value without modifying it in the code. This is the job of the TensorFlow placeholder. Placeholder in TensorFlow is a way for accepting the input data. It is created in the code and modified multiple times in the Session running time. The following code modifies the previous code to use placeholders: 1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r 2.\u00a0 \u00a0\u00a0\r 3.\u00a0 #\u00a0Create\u00a0a\u00a0placeholder\u00a0with\u00a0data\u00a0type\u00a0int8\u00a0and\u00a0shape\u00a02x3.\u00a0\u00a0\r 4.\u00a0 training_inputs\u00a0=\u00a0)\u00a0\u00a0\r 5.\u00a0 \u00a0\u00a0\r 6.\u00a0 #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r 7.\u00a0 sess\u00a0=\u00a0\u00a0\u00a0\r 8.\u00a0 \u00a0\u00a0\r 9.\u00a0 #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0assigning\u00a0a\u00a0value\u00a0to\u00a0the\u00a0placeholder\u00a0\u00a0\r 10. )\u00a0\u00a0\r 13. \u00a0\u00a0\r 14. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r 15. \u00a0\u00a0 This code prints the same outputs as before but it uses a placeholder as in line 4. The placeholder is created by specifying the data type and the shape of the data it will accept. The shape can be specified to restrict the input data to be of specific size. If no shape specified, then different inputs with different shapes can be assigned to the placeholder. The placeholder is assigned a value when running the Session using the feed_dict argument of the run operation. feed_dict is a dictionary used to initialize the placeholders. But assume there is a feature vector of 50 feature and we have a dataset of 100 samples. Assume we want to train a model two times with different number of samples, say 30 and 40. Here the size of the training set has one dimension fixed (number of features=number of columns) and another dimension (number of rows=number of training samples) of variable size. Setting its size to 30, then we restrict the input to be of size (30, 50) and thus we won`t be able to re-train the model with 40 samples. The same holds for using 40 as number of rows. The solution is to just set the number of columns but leave the number of rows unspecified by setting it to None as follows: #\u00a0Create\u00a0a\u00a0placeholder\u00a0with\u00a0data\u00a0type\u00a0int8\u00a0and\u00a0shape\u00a0Rx3.\u00a0\u00a0\r training_inputs\u00a0=\u00a0) One benefit of using placeholder is that its value is modified easily. You have not to modify the program in order the use different inputs. It is like a variable in Java, C++, or Python but it is not exactly a variable in TensorFlow. We can run the session multiple times with different values for the placeholder: #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0assigning\u00a0a\u00a0value\u00a0to\u00a0the\u00a0placeholder\u00a0\u00a0\r )\u00a0\u00a0\r )\u00a0\u00a0\r ) To do that using NumPy arrays we have to create a new Python array for each new input we are to run the program with. This is why we are using placeholders for feeding the data. For every input there should be a separate placeholder. In out neural network, there are two inputs which are training inputs and training outputs and thus there should be two placeholders one for each as in lines 4 and 5 in CodeSample1. #\u00a0Preparing\u00a0training\u00a0data\u00a0(inputs-outputs)\u00a0\u00a0\r training_inputs\u00a0=\u00a0\u00a0\u00a0\r training_outputs\u00a0=\u00a0\u00a0#Desired\u00a0outputs\u00a0for\u00a0each\u00a0input\u00a0\u00a0\r Note that the size of these placeholders is not fixed to allow variable number of training samples to be used with the code unchanged. But both placeholders of inputs and outputs training data must have the same number of rows. For example, according to our currently presented training data, training_inputs should have a shape=(4, 2) and training_outputs should be of shape=(4, 1).", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"Silver Blog\" src=\"/images/tkb-1710-s.png\" width=\"94\"/>TensorFlow: Building Feed-Forward Neural Networks Step-by-Step</h1> ", "url": "https://www.kdnuggets.com/2017/10/tensorflow-building-feed-forward-neural-networks-step-by-step.html", "tfidf": {"tfidf": {"after": 1.02070207021, "base": 1.14628158845, "hold": 3.3102585488, "here": 7.26923076924, "red": 4.44456886898, "new": 3.0536641662, "assign": 15.34654422428, "paramet": 34.513043478200004, "layer": 48.849230769239995, "follow": 6.278407592939999, "evalu": 27.803852889679998, "preliminari": 12.6501992032, "dataset": 193.609756098, "problem": 5.30024482527, "class": 4.23303559526, "job": 3.2539454806299997, "neural": 594.606741573, "descent": 8.494382022469999, "ffnns": 1443.27272727, "python": 225.1914893616, "just": 8.01480858222, "valu": 15.944332855080003, "work": 1.11520089913, "complet": 1.24021560816, "away": 1.85142857143, "type": 6.084312723570001, "classifi": 5.2937645882, "know": 2.59327017315, "should": 8.32162700495, "code": 38.8071376192, "recommend": 3.9142011834300003, "activ": 5.85614164516, "where": 1.06715063521, "run": 15.5692850838, "measur": 2.41093394077, "creat": 17.4900849858, "ahm": 30.3556405354, "summar": 15.1056137012, "multipl": 5.49627834516, "rxnum": 1443.27272727, "articl": 4.03610016524, "how": 1.60250328051, "test": 5.31414225942, "singl": 1.60948905109, "them": 1.09876115994, "present": 1.25551601423, "dictionari": 5.2292490118599995, "vector": 25.898858075, "explain": 2.60049140049, "initi": 2.7, "order": 4.98500667244, "whi": 6.513230769240001, "abl": 3.6417020300400003, "deep": 3.6279707495399998, "will": 4.89924394384, "the": 93.0, "numxnum": 52.0524590164, "build": 6.5366958312, "want": 3.99396226416, "trainop": 1443.27272727, "error": 18.123287671230003, "linear": 13.8776223776, "neuron": 128.5506072874, "but": 7.11426925293, "sess": 1764.0, "programmat": 214.54054054099998, "our": 2.35758835759, "classif": 16.134146341460003, "output": 84.44680851068001, "final": 1.34008609775, "num": 138.04347552138, "modifi": 35.62636746144, "hidden": 7.81299212598, "exampl": 4.51450236966, "has": 1.0436497502, "feeddict": 2886.54545454, "tensorflow": 30308.72727267, "take": 1.13961668222, "traininginput": 10102.90909089, "previous": 4.28540579448, "column": 14.156041016500001, "resourc": 2.9487369985100003, "green": 2.63065451533, "reader": 6.437956204380001, "feedforward": 2886.54545454, "model": 4.1811956808, "desir": 9.005104934759999, "good": 1.51981619759, "basic": 5.460361135, "concept": 2.65707112971, "number": 8.81143332872, "note": 1.42449528937, "fix": 8.869273743019999, "optim": 11.5377906977, "specifi": 20.761987794240003, "loss": 2.42529789184, "apidocspythontfconverttotensor": 1443.27272727, "print": 16.4859813084, "not": 5.07836990595, "someth": 3.28152128979, "shape": 25.62711864408, "gradient": 41.889182058, "minim": 6.10850327049, "doc": 34.8157894737, "unspecifi": 38.7219512195, "specif": 1.8719490626099997, "easi": 5.2937645882, "shown": 2.76923076923, "trainingoutputsdata": 1443.27272727, "solv": 21.80769230769, "convert": 6.5481542586199994, "function": 12.477208424999999, "numpyinput": 4329.81818181, "separ": 1.6012102874399998, "argument": 5.09335899904, "anoth": 2.27287043664, "blue": 6.14039837556, "allow": 1.2716059271100002, "out": 1.06016694491, "kdnugget": 1443.27272727, "contributor": 14.4721969006, "featur": 3.05425163524, "bias": 82.4013840828, "tensor": 1068.5769230780002, "feed": 7.77853993141, "thus": 4.93912682775, "session": 89.53683468448, "simpl": 3.3981164383599998, "appli": 6.8916220518, "three": 2.13243787778, "one": 3.01882487166, "restrict": 6.2124828800600005, "array": 71.0108626199, "two": 4.0551724138, "either": 1.5830092731099998, "accord": 1.27589809531, "got": 3.61969904241, "accuraci": 12.7620578778, "explor": 3.39593582888, "loop": 27.0229787234, "get": 3.5712518277, "network": 36.31171377232, "like": 1.14918566775, "consol": 20.275862069000002, "through": 1.07074930869, "some": 4.16146788992, "updat": 5.56466876972, "placehold": 7607.25, "both": 1.05215720061, "result": 1.14611608432, "trainingoutput": 4329.81818181, "includ": 1.0190641247799999, "content": 3.5421686747, "understand": 2.96858638743, "without": 1.29547123623, "use": 21.622413904979997, "channel": 3.6784059314199995, "set": 4.74831763124, "access": 1.8734953976900002, "this": 8.03034901368, "question": 2.20408163265, "sampl": 36.1640091116, "time": 5.0563730174, "predictionerror": 1443.27272727, "leav": 1.6615384615399997, "which": 1.005191845, "answer": 4.64890190337, "detail": 2.26186066391, "differ": 7.4192694134999995, "same": 3.35573874444, "gad": 236.955223881, "binari": 32.4, "free": 1.71818181818, "what": 2.50686878256, "for": 19.00598576019, "color": 7.6510843373399995, "predict": 25.92423252775, "java": 31.625498008, "all": 1.01146788991, "traininginputsdata": 1443.27272727, "exact": 3.46864758575, "with": 10.011982089899998, "won": 2.31732593782, "program": 4.04278074866, "assum": 8.87257824144, "there": 5.20456333595, "are": 9.26915342202, "solut": 4.7278141751, "better": 2.0065722952500002, "current": 1.5325803649, "that": 10.0398406375, "intnum": 2886.54545454, "weight": 29.273509526759995, "architectur": 5.12790697674, "afinput": 1443.27272727, "call": 2.1353059852, "connect": 1.8843916913900003, "numpi": 8659.63636362, "and": 30.0018897639, "discuss": 4.39352428394, "these": 2.14830852504, "prepar": 14.58074391552, "benefit": 3.06841901817, "unchang": 16.3165467626, "later": 1.08650424309, "befor": 2.20072082062, "librari": 2.68266306185, "none": 4.06555697823, "close": 5.139527355119999, "then": 3.25973581548, "doe": 1.70581282905, "can": 5.8813069571, "convers": 3.3486606201200004, "simpler": 17.9187358916, "way": 3.6572218383, "each": 8.32823741008, "retrain": 180.409090909, "train": 34.8582581118, "assess": 10.48612945838, "step": 14.139650872799997, "read": 11.574803149600001, "rowsnumb": 1443.27272727, "codesamplenum": 2886.54545454, "say": 1.7544480053, "data": 67.5287111868, "oper": 3.10958769954, "accept": 3.4754816112, "row": 16.647326109750004, "into": 3.04507384437, "size": 14.9632422243, "inputsoutput": 2886.54545454, "must": 3.844067796619999, "variabl": 61.229752066139994, "dimens": 16.51170046802, "learn": 2.32275054865, "featuresnumb": 1443.27272727, "requir": 1.52844902282, "from": 1.00056721497, "figur": 4.0686827268, "import": 4.020597670110001, "first": 2.01523229246, "everi": 1.47917637194, "input": 280.6671790923, "have": 10.1489484114, "score": 4.2884927066500005, "easili": 3.6938110749199997, "line": 11.346078256239998, "actual": 1.87482286254, "when": 1.02076769755}, "logtfidf": {"after": 0.020490694648099998, "base": 0.13652330228700002, "hold": 1.007758234392, "here": 2.6551145651100003, "red": 1.597071382694, "new": 0.0531898405533, "assign": 5.3783838224, "paramet": 5.696380287719999, "layer": 12.581874974100002, "follow": 0.2721414665652, "evalu": 7.755520972519999, "preliminari": 2.5376729623400003, "dataset": 5.26584456664, "problem": 1.707422172819, "class": 1.4995443798660002, "job": 1.1798682540899998, "neural": 40.853151555, "descent": 2.13940500645, "ffnns": 7.2746685411000005, "python": 16.12262697184, "just": 1.737188604654, "valu": 5.7623531710360005, "work": 0.109034567273, "complet": 0.215285242047, "away": 0.615957541869, "type": 2.121304456161, "classifi": 1.6665296351499999, "know": 0.952919694398, "should": 2.54709938379, "code": 13.5601909597, "recommend": 1.36461126863, "activ": 1.524786413136, "where": 0.0649921387457, "run": 4.42714975539, "measur": 0.880014199726, "creat": 3.116075459196, "ahm": 3.4129823498400005, "summar": 2.7150664430299996, "multipl": 2.02184803624, "rxnum": 7.2746685411000005, "articl": 1.404263479148, "how": 0.47156695693000006, "test": 1.954448874206, "singl": 0.475916769059, "them": 0.0941833269093, "present": 0.227546654799, "dictionari": 1.65426767539, "vector": 3.25419887797, "explain": 0.955700427358, "initi": 0.6002091849, "order": 0.8805615231720001, "whi": 2.36137686094, "abl": 1.19860796495, "deep": 1.2886734698, "will": 0.81114613966, "the": 0.0, "numxnum": 3.9522520373, "build": 1.964549808364, "want": 1.3832732125099998, "trainop": 7.2746685411000005, "error": 5.395756302900001, "linear": 2.63027764196, "neuron": 8.32635095454, "but": 0.1133466045033, "sess": 19.1301808437, "programmat": 5.3684987207, "our": 0.8576392141820001, "classif": 4.17558147258, "output": 22.42049236097, "final": 0.292733863948, "num": 0.04346867456478601, "modifi": 11.949155848399998, "hidden": 2.0557880052, "exampl": 1.2260480249969998, "has": 0.0427239448548, "feeddict": 14.549337082200001, "tensorflow": 152.7680393631, "take": 0.130691962197, "traininginput": 50.922679787700005, "previous": 1.069808880189, "column": 3.91398855876, "resourc": 1.08137694258, "green": 0.9672326803710001, "reader": 1.8622111301800002, "feedforward": 14.549337082200001, "model": 1.4749001462220002, "desir": 3.2975380285199996, "good": 0.418589404907, "basic": 2.0087354979, "concept": 0.977224437103, "number": 0.7728686273488, "note": 0.353817568083, "fix": 2.97889146902, "optim": 2.4456277954099996, "specifi": 5.80353454863, "loss": 0.885954358842, "apidocspythontfconverttotensor": 7.2746685411000005, "print": 5.96536244835, "not": 0.0777620650375, "someth": 1.18830712273, "shape": 9.3136765692, "gradient": 3.73502760882, "minim": 1.80968177926, "doc": 3.55007100439, "unspecifi": 3.6564066542, "specif": 0.626980167541, "easi": 1.6665296351499999, "shown": 1.01856958099, "trainingoutputsdata": 7.2746685411000005, "solv": 5.950951431120001, "convert": 2.3720720736, "function": 4.57232870797, "numpyinput": 21.824005623300003, "separ": 0.470759772949, "argument": 1.62793753414, "anoth": 0.255792723304, "blue": 2.2434848830200003, "allow": 0.24028061118900002, "out": 0.0584263909193, "kdnugget": 7.2746685411000005, "contributor": 2.67222935363, "featur": 0.846774836284, "bias": 15.719056588019999, "tensor": 35.19721040332, "feed": 2.05136865109, "thus": 1.4957288141790002, "session": 27.552982065440002, "simpl": 1.2232212893899999, "appli": 2.4950825694359997, "three": 0.12823737644980002, "one": 0.0187660549365, "restrict": 2.26682691026, "array": 16.21845897651, "two": 0.0547953774328, "either": 0.459327638815, "accord": 0.243650319127, "got": 1.2863908849299999, "accuraci": 2.5464765406, "explor": 1.22257937218, "loop": 5.20708077464, "get": 1.159538011564, "network": 13.343162742728, "like": 0.139053576545, "consol": 3.00943111791, "through": 0.0683586918849, "some": 0.158294036258, "updat": 1.7164374626899999, "placehold": 133.431344469, "both": 0.050842533389300004, "result": 0.136378908381, "trainingoutput": 21.824005623300003, "includ": 0.0188846813905, "content": 1.26473915954, "understand": 1.0880858756799998, "without": 0.258874517941, "use": 0.6133684143636, "channel": 1.30247948752, "set": 0.685984045156, "access": 0.627805882716, "this": 0.03029159242, "question": 0.790310929014, "sampl": 9.893132441950002, "time": 0.056057594313, "predictionerror": 7.2746685411000005, "leav": 0.507743957229, "which": 0.00517841384543, "answer": 1.5366310419, "detail": 0.816187777173, "differ": 1.2739267278720001, "same": 0.336178948812, "gad": 5.46787119451, "binari": 3.4781584227999995, "free": 0.5412666492670001, "what": 0.451774593654, "for": 0.005984817512543001, "color": 2.6834004013599997, "predict": 8.22870118845, "java": 3.45396369421, "all": 0.011402632097799998, "traininginputsdata": 7.2746685411000005, "exact": 1.2437647732500001, "with": 0.0119749171339, "won": 0.8404139079, "program": 1.4075711575299998, "assum": 3.25305940575, "there": 0.2004894646275, "are": 0.2652072622443, "solut": 1.55346297627, "better": 0.6964279406, "current": 0.42695282784500005, "that": 0.039761483796399995, "intnum": 14.549337082200001, "weight": 9.509541156720001, "architectur": 1.63469757919, "afinput": 7.2746685411000005, "call": 0.1309255488976, "connect": 0.633605058682, "numpi": 43.64801124660001, "and": 0.001889704261908, "discuss": 1.57396904524, "these": 0.1430672388016, "prepar": 5.327653674372001, "benefit": 1.12116245116, "unchang": 2.79217973172, "later": 0.0829654259878, "befor": 0.191275543759, "librari": 0.986809980943, "none": 1.40255075163, "close": 1.002667039456, "then": 0.24910159569269996, "doe": 0.5340417297169999, "can": 0.8117054819699999, "convers": 1.2085604509999999, "simpler": 2.8858468633, "way": 0.5942745298050001, "each": 1.216191825128, "retrain": 5.19522699942, "train": 11.896529631102, "assess": 3.3138123987, "step": 5.1977252849, "read": 4.1969634044, "rowsnumb": 7.2746685411000005, "codesamplenum": 14.549337082200001, "say": 0.562154280552, "data": 24.336411696, "oper": 0.882685928694, "accept": 1.105171764014, "row": 5.14091196255, "into": 0.0447385896861, "size": 5.483023236366, "inputsoutput": 14.549337082200001, "must": 1.306767894776, "variabl": 15.181061470400001, "dimens": 4.22184413662, "learn": 0.842752064745, "featuresnumb": 7.2746685411000005, "requir": 0.424253510675, "from": 0.000567054168866, "figur": 1.4203442243200002, "import": 0.878454831198, "first": 0.015174579624319999, "everi": 0.391485427421, "input": 57.53853271397, "have": 0.14785002341200001, "score": 1.4559353207700003, "easili": 1.3066587367, "line": 2.795444915616, "actual": 0.628514181648, "when": 0.0205549888584}, "logidf": {"after": 0.020490694648099998, "base": 0.13652330228700002, "hold": 0.503879117196, "here": 0.8850381883700001, "red": 0.798535691347, "new": 0.0177299468511, "assign": 1.3445959556, "paramet": 2.8481901438599997, "layer": 2.0969791623500003, "follow": 0.045356911094199995, "evalu": 1.9388802431299998, "preliminari": 2.5376729623400003, "dataset": 5.26584456664, "problem": 0.569140724273, "class": 0.7497721899330001, "job": 1.1798682540899998, "neural": 4.0853151555, "descent": 2.13940500645, "ffnns": 7.2746685411000005, "python": 4.03065674296, "just": 0.289531434109, "valu": 0.823193310148, "work": 0.109034567273, "complet": 0.215285242047, "away": 0.615957541869, "type": 0.707101485387, "classifi": 1.6665296351499999, "know": 0.952919694398, "should": 0.509419876758, "code": 1.35601909597, "recommend": 1.36461126863, "activ": 0.381196603284, "where": 0.0649921387457, "run": 0.442714975539, "measur": 0.880014199726, "creat": 0.222576818514, "ahm": 3.4129823498400005, "summar": 2.7150664430299996, "multipl": 1.01092401812, "rxnum": 7.2746685411000005, "articl": 0.702131739574, "how": 0.47156695693000006, "test": 0.977224437103, "singl": 0.475916769059, "them": 0.0941833269093, "present": 0.227546654799, "dictionari": 1.65426767539, "vector": 3.25419887797, "explain": 0.955700427358, "initi": 0.30010459245, "order": 0.22014038079300002, "whi": 1.18068843047, "abl": 0.599303982475, "deep": 1.2886734698, "will": 0.202786534915, "the": 0.0, "numxnum": 3.9522520373, "build": 0.491137452091, "want": 0.6916366062549999, "trainop": 7.2746685411000005, "error": 1.7985854343, "linear": 2.63027764196, "neuron": 4.16317547727, "but": 0.0161923720719, "sess": 6.3767269479, "programmat": 5.3684987207, "our": 0.8576392141820001, "classif": 2.08779073629, "output": 2.03822657827, "final": 0.292733863948, "num": 0.00031499039539700004, "modifi": 1.4936444810499998, "hidden": 2.0557880052, "exampl": 0.40868267499899996, "has": 0.0427239448548, "feeddict": 7.2746685411000005, "tensorflow": 7.2746685411000005, "take": 0.130691962197, "traininginput": 7.2746685411000005, "previous": 0.356602960063, "column": 1.95699427938, "resourc": 1.08137694258, "green": 0.9672326803710001, "reader": 1.8622111301800002, "feedforward": 7.2746685411000005, "model": 0.7374500731110001, "desir": 1.0991793428399999, "good": 0.418589404907, "basic": 1.00436774895, "concept": 0.977224437103, "number": 0.0966085784186, "note": 0.353817568083, "fix": 1.48944573451, "optim": 2.4456277954099996, "specifi": 1.93451151621, "loss": 0.885954358842, "apidocspythontfconverttotensor": 7.2746685411000005, "print": 1.19307248967, "not": 0.0155524130075, "someth": 1.18830712273, "shape": 1.16420957115, "gradient": 3.73502760882, "minim": 1.80968177926, "doc": 3.55007100439, "unspecifi": 3.6564066542, "specif": 0.626980167541, "easi": 1.6665296351499999, "shown": 1.01856958099, "trainingoutputsdata": 7.2746685411000005, "solv": 1.9836504770400003, "convert": 1.1860360368, "function": 0.914465741594, "numpyinput": 7.2746685411000005, "separ": 0.470759772949, "argument": 1.62793753414, "anoth": 0.127896361652, "blue": 1.1217424415100001, "allow": 0.24028061118900002, "out": 0.0584263909193, "kdnugget": 7.2746685411000005, "contributor": 2.67222935363, "featur": 0.423387418142, "bias": 2.61984276467, "tensor": 5.02817291476, "feed": 2.05136865109, "thus": 0.49857627139300004, "session": 1.7220613790900001, "simpl": 1.2232212893899999, "appli": 0.8316941898119999, "three": 0.06411868822490001, "one": 0.0062553516455, "restrict": 1.13341345513, "array": 2.31692271093, "two": 0.0136988443582, "either": 0.459327638815, "accord": 0.243650319127, "got": 1.2863908849299999, "accuraci": 2.5464765406, "explor": 1.22257937218, "loop": 2.60354038732, "get": 0.579769005782, "network": 0.9530830530519999, "like": 0.139053576545, "consol": 3.00943111791, "through": 0.0683586918849, "some": 0.0395735090645, "updat": 1.7164374626899999, "placehold": 5.801362803, "both": 0.050842533389300004, "result": 0.136378908381, "trainingoutput": 7.2746685411000005, "includ": 0.0188846813905, "content": 1.26473915954, "understand": 1.0880858756799998, "without": 0.258874517941, "use": 0.0292080197316, "channel": 1.30247948752, "set": 0.171496011289, "access": 0.627805882716, "this": 0.0037864490525, "question": 0.790310929014, "sampl": 1.9786264883900002, "time": 0.0112115188626, "predictionerror": 7.2746685411000005, "leav": 0.507743957229, "which": 0.00517841384543, "answer": 1.5366310419, "detail": 0.816187777173, "differ": 0.212321121312, "same": 0.112059649604, "gad": 5.46787119451, "binari": 3.4781584227999995, "free": 0.5412666492670001, "what": 0.225887296827, "for": 0.00031499039539700004, "color": 1.3417002006799998, "predict": 1.6457402376899999, "java": 3.45396369421, "all": 0.011402632097799998, "traininginputsdata": 7.2746685411000005, "exact": 1.2437647732500001, "with": 0.00119749171339, "won": 0.8404139079, "program": 0.7037855787649999, "assum": 1.08435313525, "there": 0.0400978929255, "are": 0.0294674735827, "solut": 1.55346297627, "better": 0.6964279406, "current": 0.42695282784500005, "that": 0.00397614837964, "intnum": 7.2746685411000005, "weight": 1.58492352612, "architectur": 1.63469757919, "afinput": 7.2746685411000005, "call": 0.0654627744488, "connect": 0.633605058682, "numpi": 7.2746685411000005, "and": 6.29901420636e-05, "discuss": 0.78698452262, "these": 0.0715336194008, "prepar": 0.8879422790620001, "benefit": 1.12116245116, "unchang": 2.79217973172, "later": 0.0829654259878, "befor": 0.0956377718795, "librari": 0.986809980943, "none": 1.40255075163, "close": 0.250666759864, "then": 0.08303386523089999, "doe": 0.5340417297169999, "can": 0.162341096394, "convers": 1.2085604509999999, "simpler": 2.8858468633, "way": 0.19809150993500002, "each": 0.173741689304, "retrain": 5.19522699942, "train": 0.660918312839, "assess": 1.65690619935, "step": 1.03954505698, "read": 0.83939268088, "rowsnumb": 7.2746685411000005, "codesamplenum": 7.2746685411000005, "say": 0.562154280552, "data": 1.2168205848, "oper": 0.441342964347, "accept": 0.552585882007, "row": 1.71363732085, "into": 0.0149128632287, "size": 0.9138372060609999, "inputsoutput": 7.2746685411000005, "must": 0.653383947388, "variabl": 2.1687230672, "dimens": 2.11092206831, "learn": 0.842752064745, "featuresnumb": 7.2746685411000005, "requir": 0.424253510675, "from": 0.000567054168866, "figur": 0.7101721121600001, "import": 0.292818277066, "first": 0.0075872898121599995, "everi": 0.391485427421, "input": 2.50167533539, "have": 0.0147850023412, "score": 1.4559353207700003, "easili": 1.3066587367, "line": 0.349430614452, "actual": 0.628514181648, "when": 0.0205549888584}, "freq": {"after": 1, "base": 1, "hold": 2, "here": 3, "red": 2, "new": 3, "assign": 4, "paramet": 2, "layer": 6, "follow": 6, "evalu": 4, "preliminari": 1, "dataset": 1, "problem": 3, "class": 2, "job": 1, "neural": 10, "descent": 1, "ffnns": 1, "python": 4, "just": 6, "valu": 7, "work": 1, "complet": 1, "away": 1, "type": 3, "classifi": 1, "know": 1, "should": 5, "code": 10, "recommend": 1, "activ": 4, "where": 1, "run": 10, "measur": 1, "creat": 14, "ahm": 1, "summar": 1, "multipl": 2, "rxnum": 1, "articl": 2, "how": 1, "test": 2, "singl": 1, "them": 1, "present": 1, "dictionari": 1, "vector": 1, "explain": 1, "initi": 2, "order": 4, "whi": 2, "abl": 2, "deep": 1, "will": 4, "the": 93, "numxnum": 1, "build": 4, "want": 2, "trainop": 1, "error": 3, "linear": 1, "neuron": 2, "but": 7, "sess": 3, "programmat": 1, "our": 1, "classif": 2, "output": 11, "final": 1, "num": 138, "modifi": 8, "hidden": 1, "exampl": 3, "has": 1, "feeddict": 2, "tensorflow": 21, "take": 1, "traininginput": 7, "previous": 3, "column": 2, "resourc": 1, "green": 1, "reader": 1, "feedforward": 2, "model": 2, "desir": 3, "good": 1, "basic": 2, "concept": 1, "number": 8, "note": 1, "fix": 2, "optim": 1, "specifi": 3, "loss": 1, "apidocspythontfconverttotensor": 1, "print": 5, "not": 5, "someth": 1, "shape": 8, "gradient": 1, "minim": 1, "doc": 1, "unspecifi": 1, "specif": 1, "easi": 1, "shown": 1, "trainingoutputsdata": 1, "solv": 3, "convert": 2, "function": 5, "numpyinput": 3, "separ": 1, "argument": 1, "anoth": 2, "blue": 2, "allow": 1, "out": 1, "kdnugget": 1, "contributor": 1, "featur": 2, "bias": 6, "tensor": 7, "feed": 1, "thus": 3, "session": 16, "simpl": 1, "appli": 3, "three": 2, "one": 3, "restrict": 2, "array": 7, "two": 4, "either": 1, "accord": 1, "got": 1, "accuraci": 1, "explor": 1, "loop": 2, "get": 2, "network": 14, "like": 1, "consol": 1, "through": 1, "some": 4, "updat": 1, "placehold": 23, "both": 1, "result": 1, "trainingoutput": 3, "includ": 1, "content": 1, "understand": 1, "without": 1, "use": 21, "channel": 1, "set": 4, "access": 1, "this": 8, "question": 1, "sampl": 5, "time": 5, "predictionerror": 1, "leav": 1, "which": 1, "answer": 1, "detail": 1, "differ": 6, "same": 3, "gad": 1, "binari": 1, "free": 1, "what": 2, "for": 19, "color": 2, "predict": 5, "java": 1, "all": 1, "traininginputsdata": 1, "exact": 1, "with": 10, "won": 1, "program": 2, "assum": 3, "there": 5, "are": 9, "solut": 1, "better": 1, "current": 1, "that": 10, "intnum": 2, "weight": 6, "architectur": 1, "afinput": 1, "call": 2, "connect": 1, "numpi": 6, "and": 30, "discuss": 2, "these": 2, "prepar": 6, "benefit": 1, "unchang": 1, "later": 1, "befor": 2, "librari": 1, "none": 1, "close": 4, "then": 3, "doe": 1, "can": 5, "convers": 1, "simpler": 1, "way": 3, "each": 7, "retrain": 1, "train": 18, "assess": 2, "step": 5, "read": 5, "rowsnumb": 1, "codesamplenum": 2, "say": 1, "data": 20, "oper": 2, "accept": 2, "row": 3, "into": 3, "size": 6, "inputsoutput": 2, "must": 2, "variabl": 7, "dimens": 2, "learn": 1, "featuresnumb": 1, "requir": 1, "from": 1, "figur": 2, "import": 3, "first": 2, "everi": 1, "input": 23, "have": 10, "score": 1, "easili": 1, "line": 8, "actual": 1, "when": 1}, "idf": {"after": 1.02070207021, "base": 1.14628158845, "hold": 1.6551292744, "here": 2.42307692308, "red": 2.22228443449, "new": 1.0178880554, "assign": 3.83663605607, "paramet": 17.256521739100002, "layer": 8.14153846154, "follow": 1.04640126549, "evalu": 6.9509632224199995, "preliminari": 12.6501992032, "dataset": 193.609756098, "problem": 1.76674827509, "class": 2.11651779763, "job": 3.2539454806299997, "neural": 59.4606741573, "descent": 8.494382022469999, "ffnns": 1443.27272727, "python": 56.2978723404, "just": 1.33580143037, "valu": 2.2777618364400003, "work": 1.11520089913, "complet": 1.24021560816, "away": 1.85142857143, "type": 2.0281042411900003, "classifi": 5.2937645882, "know": 2.59327017315, "should": 1.6643254009900001, "code": 3.8807137619199996, "recommend": 3.9142011834300003, "activ": 1.46403541129, "where": 1.06715063521, "run": 1.55692850838, "measur": 2.41093394077, "creat": 1.2492917847, "ahm": 30.3556405354, "summar": 15.1056137012, "multipl": 2.74813917258, "rxnum": 1443.27272727, "articl": 2.01805008262, "how": 1.60250328051, "test": 2.65707112971, "singl": 1.60948905109, "them": 1.09876115994, "present": 1.25551601423, "dictionari": 5.2292490118599995, "vector": 25.898858075, "explain": 2.60049140049, "initi": 1.35, "order": 1.24625166811, "whi": 3.2566153846200003, "abl": 1.8208510150200001, "deep": 3.6279707495399998, "will": 1.22481098596, "the": 1.0, "numxnum": 52.0524590164, "build": 1.6341739578, "want": 1.99698113208, "trainop": 1443.27272727, "error": 6.04109589041, "linear": 13.8776223776, "neuron": 64.2753036437, "but": 1.01632417899, "sess": 588.0, "programmat": 214.54054054099998, "our": 2.35758835759, "classif": 8.067073170730001, "output": 7.676982591880001, "final": 1.34008609775, "num": 1.00031504001, "modifi": 4.45329593268, "hidden": 7.81299212598, "exampl": 1.50483412322, "has": 1.0436497502, "feeddict": 1443.27272727, "tensorflow": 1443.27272727, "take": 1.13961668222, "traininginput": 1443.27272727, "previous": 1.42846859816, "column": 7.078020508250001, "resourc": 2.9487369985100003, "green": 2.63065451533, "reader": 6.437956204380001, "feedforward": 1443.27272727, "model": 2.0905978404, "desir": 3.00170164492, "good": 1.51981619759, "basic": 2.7301805675, "concept": 2.65707112971, "number": 1.10142916609, "note": 1.42449528937, "fix": 4.4346368715099995, "optim": 11.5377906977, "specifi": 6.920662598080001, "loss": 2.42529789184, "apidocspythontfconverttotensor": 1443.27272727, "print": 3.29719626168, "not": 1.01567398119, "someth": 3.28152128979, "shape": 3.20338983051, "gradient": 41.889182058, "minim": 6.10850327049, "doc": 34.8157894737, "unspecifi": 38.7219512195, "specif": 1.8719490626099997, "easi": 5.2937645882, "shown": 2.76923076923, "trainingoutputsdata": 1443.27272727, "solv": 7.26923076923, "convert": 3.2740771293099997, "function": 2.495441685, "numpyinput": 1443.27272727, "separ": 1.6012102874399998, "argument": 5.09335899904, "anoth": 1.13643521832, "blue": 3.07019918778, "allow": 1.2716059271100002, "out": 1.06016694491, "kdnugget": 1443.27272727, "contributor": 14.4721969006, "featur": 1.52712581762, "bias": 13.7335640138, "tensor": 152.653846154, "feed": 7.77853993141, "thus": 1.6463756092500001, "session": 5.59605216778, "simpl": 3.3981164383599998, "appli": 2.2972073506, "three": 1.06621893889, "one": 1.00627495722, "restrict": 3.1062414400300002, "array": 10.1444089457, "two": 1.01379310345, "either": 1.5830092731099998, "accord": 1.27589809531, "got": 3.61969904241, "accuraci": 12.7620578778, "explor": 3.39593582888, "loop": 13.5114893617, "get": 1.78562591385, "network": 2.59369384088, "like": 1.14918566775, "consol": 20.275862069000002, "through": 1.07074930869, "some": 1.04036697248, "updat": 5.56466876972, "placehold": 330.75, "both": 1.05215720061, "result": 1.14611608432, "trainingoutput": 1443.27272727, "includ": 1.0190641247799999, "content": 3.5421686747, "understand": 2.96858638743, "without": 1.29547123623, "use": 1.0296387573799999, "channel": 3.6784059314199995, "set": 1.18707940781, "access": 1.8734953976900002, "this": 1.00379362671, "question": 2.20408163265, "sampl": 7.23280182232, "time": 1.01127460348, "predictionerror": 1443.27272727, "leav": 1.6615384615399997, "which": 1.005191845, "answer": 4.64890190337, "detail": 2.26186066391, "differ": 1.23654490225, "same": 1.11857958148, "gad": 236.955223881, "binari": 32.4, "free": 1.71818181818, "what": 1.25343439128, "for": 1.00031504001, "color": 3.8255421686699997, "predict": 5.18484650555, "java": 31.625498008, "all": 1.01146788991, "traininginputsdata": 1443.27272727, "exact": 3.46864758575, "with": 1.0011982089899998, "won": 2.31732593782, "program": 2.02139037433, "assum": 2.9575260804799997, "there": 1.04091266719, "are": 1.02990593578, "solut": 4.7278141751, "better": 2.0065722952500002, "current": 1.5325803649, "that": 1.00398406375, "intnum": 1443.27272727, "weight": 4.878918254459999, "architectur": 5.12790697674, "afinput": 1443.27272727, "call": 1.0676529926, "connect": 1.8843916913900003, "numpi": 1443.27272727, "and": 1.00006299213, "discuss": 2.19676214197, "these": 1.07415426252, "prepar": 2.43012398592, "benefit": 3.06841901817, "unchang": 16.3165467626, "later": 1.08650424309, "befor": 1.10036041031, "librari": 2.68266306185, "none": 4.06555697823, "close": 1.2848818387799998, "then": 1.08657860516, "doe": 1.70581282905, "can": 1.17626139142, "convers": 3.3486606201200004, "simpler": 17.9187358916, "way": 1.2190739461, "each": 1.18974820144, "retrain": 180.409090909, "train": 1.9365698950999999, "assess": 5.24306472919, "step": 2.8279301745599996, "read": 2.3149606299200003, "rowsnumb": 1443.27272727, "codesamplenum": 1443.27272727, "say": 1.7544480053, "data": 3.37643555934, "oper": 1.55479384977, "accept": 1.7377408056, "row": 5.549108703250001, "into": 1.01502461479, "size": 2.49387370405, "inputsoutput": 1443.27272727, "must": 1.9220338983099996, "variabl": 8.747107438019999, "dimens": 8.25585023401, "learn": 2.32275054865, "featuresnumb": 1443.27272727, "requir": 1.52844902282, "from": 1.00056721497, "figur": 2.0343413634, "import": 1.3401992233700002, "first": 1.00761614623, "everi": 1.47917637194, "input": 12.2029208301, "have": 1.0148948411399998, "score": 4.2884927066500005, "easili": 3.6938110749199997, "line": 1.4182597820299998, "actual": 1.87482286254, "when": 1.02076769755}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  TensorFlow: Building Feed-Forward Neural Networks Step-by-Step</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/tensorflow-building-feed-forward-neural-networks-step-by-step.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb TensorFlow: Building Feed-Forward Neural Networks Step-by-Step Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/17/10-23-apple-manager-data-science.html\" rel=\"prev\" title=\"Apple: Manager, Data Science \u2013 Apple Media Products Commerce Engineering\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/bigcloud-data-science-salary-report-2018.html\" rel=\"next\" title=\"Data Science Salary Report 2018 \u2013 participate\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/10/tensorflow-building-feed-forward-neural-networks-step-by-step.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=73391\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/10/tensorflow-building-feed-forward-neural-networks-step-by-step.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-73391 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 23-Oct, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/index.html\">Oct</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/tutorials.html\">Tutorials, Overviews</a> \u00bb TensorFlow: Building Feed-Forward Neural Networks Step-by-Step (\u00a0<a href=\"/2017/n41.html\">17:n41</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"Silver Blog\" src=\"/images/tkb-1710-s.png\" width=\"94\"/>TensorFlow: Building Feed-Forward Neural Networks Step-by-Step</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/17/10-23-apple-manager-data-science.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/10/bigcloud-data-science-salary-report-2018.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/tensorflow\" rel=\"tag\">TensorFlow</a></div>\n<br/>\n<p class=\"excerpt\">\n     This article will take you through all steps required to build a simple feed-forward neural network in TensorFlow by explaining each step in details.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/ahmed-gad\" rel=\"author\" title=\"Posts by Ahmed Gad\">Ahmed Gad</a>, KDnuggets Contributor.</b></div>\n<p><img alt=\"\" class=\"aligncenter\" src=\"https://media.licdn.com/media/AAIA_wDGAAAAAQAAAAAAAAobAAAAJGY5NzBhMDc5LWU0NmItNDRkNS1hNzJkLTgyOWFjZDhjMjg5Mg.png\" width=\"99%\"/></p>\n<p>In this article, two basic feed-forward neural networks (FFNNs) will be created using TensorFlow deep learning library in Python. The reader should have basic understanding of how neural networks work and its concepts in order to apply them programmatically.</p>\n<p>This article will take you through all steps required to build a simple feed-forward neural network in TensorFlow by explaining each step in details. Before actual building of the neural network, some preliminary steps are recommended to be discussed.</p>\n<p>The summarized steps are as follows:</p>\n<ol>\n<li>Reading the training data (inputs and outputs)\n<li>Building and connect the neural networks layers (this included preparing weights, biases, and activation function of each layer)\n<li>Building a loss function to assess the prediction error\n<li>Create a training loop for training the network and updating its parameters\n<li>Applying some testing data to assess the network prediction accuracy\n</li></li></li></li></li></ol>\n<p>Here is the first classification problem that we are to solve using neural network.</p>\n<p><img alt=\"Image\" class=\"aligncenter\" src=\"https://media.licdn.com/mpr/mpr/AAIA_wDGAAAAAQAAAAAAAA02AAAAJDlkMTg4ODI4LWMxYzQtNDM4Zi04NmI5LTRlM2M1MTQ1OWI5Yg.png\" width=\"60%\"/></p>\n<p>It is a binary classification problem to classify colors into either red or blue based on the three RGB color channels. It can be solved linearly and thus we don`t have to use hidden layers. Just input and output layers are to be used. There will be a single neuron in the output layer with an activation function. The network architecture is shown in the following figure (<strong><u>Figure 1</u></strong>):</p>\n<p><img alt=\"Image\" class=\"aligncenter\" src=\"https://media.licdn.com/mpr/mpr/AAIA_wDGAAAAAQAAAAAAAAu0AAAAJGYyMzU4NjNkLWY0MGEtNDRkNi04OWI4LTVjZTE1ZjEwN2U1Mg.png\" width=\"99%\"/></p>\n<p>Where X0=1 is the bias and W0 is its weight. W1 , W2, and W3 are the weights for the three inputs R (Red), G (Green), and B (Blue).</p>\n<p>Here is the complete code of the neural network solving that problem to be discussed later. For easy access, this code is called\u00a0<strong><u>CodeSample1</u></strong>.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r\n2.\u00a0 \u00a0\u00a0\r\n3.\u00a0 #\u00a0Preparing\u00a0training\u00a0data\u00a0(inputs-outputs)\u00a0\u00a0\r\n4.\u00a0 training_inputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a03],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\n5.\u00a0 training_outputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a01],\u00a0dtype=tensorflow.float32)\u00a0#Desired\u00a0outputs\u00a0for\u00a0each\u00a0input\u00a0\u00a0\r\n6.\u00a0 \u00a0\u00a0\r\n7.\u00a0 #\u00a0Preparing\u00a0neural\u00a0network\u00a0parameters\u00a0(weights\u00a0and\u00a0bias)\u00a0using\u00a0TensorFlow\u00a0Variables\u00a0\u00a0\r\n8.\u00a0 weights\u00a0=\u00a0tensorflow.Variable(initial_value=[[.3],\u00a0[.1],\u00a0[.8]],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\n9.\u00a0 bias\u00a0=\u00a0tensorflow.Variable(initial_value=[[1]],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\n10. \u00a0\u00a0\r\n11. #\u00a0Preparing\u00a0inputs\u00a0of\u00a0the\u00a0activation\u00a0function\u00a0\u00a0\r\n12. af_input\u00a0=\u00a0tensorflow.matmul(training_inputs,\u00a0weights)\u00a0+\u00a0bias\u00a0\u00a0\r\n13. \u00a0\u00a0\r\n14. #\u00a0Activation\u00a0function\u00a0of\u00a0the\u00a0output\u00a0layer\u00a0neuron\u00a0\u00a0\r\n15. predictions\u00a0=\u00a0tensorflow.nn.sigmoid(af_input)\u00a0\u00a0\r\n16. \u00a0\u00a0\r\n17. #\u00a0Measuring\u00a0the\u00a0prediction\u00a0error\u00a0of\u00a0the\u00a0network after being trained\u00a0\u00a0\r\n18. prediction_error\u00a0=\u00a0tensorflow.reduce_sum(training_outputs\u00a0-\u00a0predictions)\u00a0\u00a0\r\n19. \u00a0\u00a0\r\n20. #\u00a0Minimizing\u00a0the\u00a0prediction\u00a0error\u00a0using\u00a0gradient\u00a0descent\u00a0optimizer\u00a0\u00a0\r\n21. train_op\u00a0=\u00a0tensorflow.train.GradientDescentOptimizer(learning_rate=0.05).minimize(prediction_error)\u00a0\u00a0\r\n22. \u00a0\u00a0\r\n23. #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n24. sess\u00a0=\u00a0tensorflow.Session()\u00a0\u00a0\r\n25. \u00a0\u00a0\r\n26. #\u00a0Initializing\u00a0the\u00a0TensorFlow\u00a0Variables\u00a0(weights\u00a0and\u00a0bias)\u00a0\u00a0\r\n27. sess.run(tensorflow.global_variables_initializer())\u00a0\u00a0\r\n28. \u00a0\u00a0\r\n29. #\u00a0Training\u00a0data\u00a0inputs\u00a0\u00a0\r\n30. training_inputs_data\u00a0=\u00a0[[255,\u00a00,\u00a00],\u00a0\u00a0\r\n31. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[248,\u00a080,\u00a068],\u00a0\u00a0\r\n32. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[0,\u00a00,\u00a0255],\u00a0\u00a0\r\n33. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[67,\u00a015,\u00a0210]]\u00a0\u00a0\r\n34. \u00a0\u00a0\r\n35. #\u00a0Training\u00a0data\u00a0desired\u00a0outputs\u00a0\u00a0\r\n36. training_outputs_data\u00a0=\u00a0[[1],\u00a0\u00a0\r\n37. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [1],\u00a0\u00a0\r\n38. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [0],\u00a0\u00a0\r\n39. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [0]]\u00a0\u00a0\r\n40. \u00a0\u00a0\r\n41. #\u00a0Training\u00a0loop\u00a0of\u00a0the\u00a0neural\u00a0network\u00a0\u00a0\r\n42. for\u00a0step\u00a0in\u00a0range(10000):\u00a0\u00a0\r\n43. \u00a0\u00a0\u00a0\u00a0sess.run(fetches=[train_op],\u00a0feed_dict={\r\n44. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0training_inputs:\u00a0training_inputs_data,\u00a0\u00a0\r\n45. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0training_outputs:\u00a0training_outputs_data})\u00a0\u00a0\r\n46. \u00a0\u00a0\r\n47. #\u00a0Class scores\u00a0of\u00a0some\u00a0testing\u00a0data\u00a0\u00a0\r\n48. print(\"Expected Scores\u00a0:\u00a0\",\u00a0sess.run(fetches=predictions,\u00a0feed_dict={training_inputs:\u00a0[[248,\u00a080,\u00a068],\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0[0,\u00a00,\u00a0255]]}))\u00a0\u00a0\r\n49. \u00a0\r\n50. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0to\u00a0free\u00a0resources\u00a0\u00a0\r\n51. sess.close()</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3>Reading the Training Data</h3>\n<p>\u00a0<br>\nThe data is read in the previous code in lines 4 and 5 using something called placeholder. But what is a placeholder? Why we have not just used a NumPy array for preparing the data? To answer these questions, we can explore a simpler example that reads some inputs and print it to the console as follows:</br></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r\n2.\u00a0 \u00a0\u00a0\r\n3.\u00a0 #\u00a0Creating\u00a0a\u00a0NumPy\u00a0array\u00a0holding\u00a0the\u00a0input\u00a0data\u00a0\u00a0\r\n4.\u00a0 numpy_inputs\u00a0=\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r\n5.\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]\u00a0\u00a0\r\n6.\u00a0 \u00a0\u00a0\r\n7.\u00a0 #\u00a0Converting\u00a0the\u00a0NumPy\u00a0array\u00a0to\u00a0a\u00a0TensorFlow\u00a0Tensor\u00a0\u00a0\r\n8.\u00a0 #\u00a0convert_to_tensor()\u00a0doc:\u00a0https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor\u00a0\u00a0\r\n9.\u00a0 training_inputs\u00a0=\u00a0tensorflow.convert_to_tensor(value=numpy_inputs,\u00a0dtype=tensorflow.int8)\u00a0\u00a0\r\n10. \u00a0\u00a0\r\n11. #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n12. sess\u00a0=\u00a0tensorflow.Session()\u00a0\u00a0\r\n13. \u00a0\u00a0\r\n14. #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0the\u00a0previously\u00a0created\u00a0Tensor\u00a0\u00a0\r\n15. print(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs))\u00a0\u00a0\r\n16. \u00a0\u00a0\r\n17. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n18. sess.close()</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The input is read into a NumPy array away from TensorFlow as in line 4. But TensorFlow just know Tensors and just we have to convert the NumPy array into a Tensor. The tensorflow.convert_to_tensor() TensorFlow operation does that conversion as in line 9. To be able to print the contents of a Tensor, we must at first create a Session using the tensorflow.Session() class as in line 12. In line 15, the session runs in order evaluate the Tensor training_inputs and get its values printed. Finally, the session got closed in line 18. The result of printing is as follows:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Output\u00a0is\u00a0:\u00a0\u00a0[[\u00a05\u00a0\u00a02\u00a013]\u00a0,\u00a0[\u00a07\u00a0\u00a09\u00a0\u00a00]]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>This example doesn`t use placeholders. So, what is the use of a TensorFlow placeholder? Assume that we want to run the session with another input. To do that, we have to modify the numpy_input Python variable each time a new input is applied.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>numpy_inputs\u00a0=\u00a0[[83,\u00a049,\u00a092],\u00a0\u00a0[31,\u00a078,\u00a060]]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>It is not a good way to modify the code in order to get different inputs. A better way for doing that is to just create the Tensor and then modify its value without modifying it in the code. This is the job of the TensorFlow placeholder.</p>\n<p>Placeholder in TensorFlow is a way for accepting the input data. It is created in the code and modified multiple times in the Session running time. The following code modifies the previous code to use placeholders:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r\n2.\u00a0 \u00a0\u00a0\r\n3.\u00a0 #\u00a0Create\u00a0a\u00a0placeholder\u00a0with\u00a0data\u00a0type\u00a0int8\u00a0and\u00a0shape\u00a02x3.\u00a0\u00a0\r\n4.\u00a0 training_inputs\u00a0=\u00a0tensorflow.placeholder(dtype=tensorflow.int8,\u00a0shape=(2,\u00a03))\u00a0\u00a0\r\n5.\u00a0 \u00a0\u00a0\r\n6.\u00a0 #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n7.\u00a0 sess\u00a0=\u00a0tensorflow.Session()\u00a0\u00a0\r\n8.\u00a0 \u00a0\u00a0\r\n9.\u00a0 #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0assigning\u00a0a\u00a0value\u00a0to\u00a0the\u00a0placeholder\u00a0\u00a0\r\n10. print(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n11. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r\n12. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]}))\u00a0\u00a0\r\n13. \u00a0\u00a0\r\n14. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n15. sess.close()\u00a0\u00a0</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>This code prints the same outputs as before but it uses a placeholder as in line 4. The placeholder is created by specifying the data type and the shape of the data it will accept. The shape can be specified to restrict the input data to be of specific size. If no shape specified, then different inputs with different shapes can be assigned to the placeholder. The placeholder is assigned a value when running the Session using the feed_dict argument of the run operation. feed_dict is a dictionary used to initialize the placeholders.</p>\n<p>But assume there is a feature vector of 50 feature and we have a dataset of 100 samples. Assume we want to train a model two times with different number of samples, say 30 and 40. Here the size of the training set has one dimension fixed (number of features=number of columns) and another dimension (number of rows=number of training samples) of variable size. Setting its size to 30, then we restrict the input to be of size (30, 50) and thus we won`t be able to re-train the model with 40 samples. The same holds for using 40 as number of rows. The solution is to just set the number of columns but leave the number of rows unspecified by setting it to None as follows:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>#\u00a0Create\u00a0a\u00a0placeholder\u00a0with\u00a0data\u00a0type\u00a0int8\u00a0and\u00a0shape\u00a0Rx3.\u00a0\u00a0\r\ntraining_inputs\u00a0=\u00a0tensorflow.placeholder(dtype=tensorflow.int8,\u00a0shape=(None,\u00a050))</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>One benefit of using placeholder is that its value is modified easily. You have not to modify the program in order the use different inputs. It is like a variable in Java, C++, or Python but it is not exactly a variable in TensorFlow. We can run the session multiple times with different values for the placeholder:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre spellcheck=\"false\">#\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0assigning\u00a0a\u00a0value\u00a0to\u00a0the\u00a0placeholder\u00a0\u00a0\r\nprint(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n                     \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]}))\u00a0\u00a0\r\nprint(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[1,\u00a02,\u00a03],\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[4,\u00a05,\u00a06]]}))\u00a0\u00a0\r\nprint(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[12,\u00a013,\u00a014],\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[15,\u00a016,\u00a017]]}))</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>To do that using NumPy arrays we have to create a new Python array for each new input we are to run the program with.</p>\n<p>This is why we are using placeholders for feeding the data. For every input there should be a separate placeholder. In out neural network, there are two inputs which are training inputs and training outputs and thus there should be two placeholders one for each as in lines 4 and 5 in CodeSample1.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre spellcheck=\"false\">#\u00a0Preparing\u00a0training\u00a0data\u00a0(inputs-outputs)\u00a0\u00a0\r\ntraining_inputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a03],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\ntraining_outputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a01],\u00a0dtype=tensorflow.float32)\u00a0#Desired\u00a0outputs\u00a0for\u00a0each\u00a0input\u00a0\u00a0\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Note that the size of these placeholders is not fixed to allow variable number of training samples to be used with the code unchanged. But both placeholders of inputs and outputs training data must have the same number of rows. For example, according to our currently presented training data, training_inputs should have a shape=(4, 2) and training_outputs should be of shape=(4, 1).</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2017/10/tensorflow-building-feed-forward-neural-networks-step-by-step.html/2\">2</a> <a href=\"https://www.kdnuggets.com/2017/10/tensorflow-building-feed-forward-neural-networks-step-by-step.html/3\">3</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/17/10-23-apple-manager-data-science.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/10/bigcloud-data-science-salary-report-2018.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/index.html\">Oct</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/10/tutorials.html\">Tutorials, Overviews</a> \u00bb TensorFlow: Building Feed-Forward Neural Networks Step-by-Step (\u00a0<a href=\"/2017/n41.html\">17:n41</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556325195\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.745 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 20:33:15 -->\n<!-- Compression = gzip -->", "content_tokenized": ["ahm", "gad", "kdnugget", "contributor", "this", "articl", "two", "basic", "feedforward", "neural", "network", "ffnns", "will", "creat", "use", "tensorflow", "deep", "learn", "librari", "python", "the", "reader", "should", "have", "basic", "understand", "how", "neural", "network", "work", "and", "concept", "order", "appli", "them", "programmat", "this", "articl", "will", "take", "through", "all", "step", "requir", "build", "simpl", "feedforward", "neural", "network", "tensorflow", "explain", "each", "step", "detail", "befor", "actual", "build", "the", "neural", "network", "some", "preliminari", "step", "are", "recommend", "discuss", "the", "summar", "step", "are", "follow", "read", "the", "train", "data", "input", "and", "output", "build", "and", "connect", "the", "neural", "network", "layer", "this", "includ", "prepar", "weight", "bias", "and", "activ", "function", "each", "layer", "build", "loss", "function", "assess", "the", "predict", "error", "creat", "train", "loop", "for", "train", "the", "network", "and", "updat", "paramet", "appli", "some", "test", "data", "assess", "the", "network", "predict", "accuraci", "here", "the", "first", "classif", "problem", "that", "are", "solv", "use", "neural", "network", "binari", "classif", "problem", "classifi", "color", "into", "either", "red", "blue", "base", "the", "three", "color", "channel", "can", "solv", "linear", "and", "thus", "have", "use", "hidden", "layer", "just", "input", "and", "output", "layer", "are", "use", "there", "will", "singl", "neuron", "the", "output", "layer", "with", "activ", "function", "the", "network", "architectur", "shown", "the", "follow", "figur", "figur", "num", "where", "the", "bias", "and", "weight", "and", "are", "the", "weight", "for", "the", "three", "input", "red", "green", "and", "blue", "here", "the", "complet", "code", "the", "neural", "network", "solv", "that", "problem", "discuss", "later", "for", "easi", "access", "this", "code", "call", "codesamplenum", "num", "import", "tensorflow", "num", "num", "prepar", "train", "data", "inputsoutput", "num", "traininginput", "num", "trainingoutput", "desir", "output", "for", "each", "input", "num", "num", "prepar", "neural", "network", "paramet", "weight", "and", "bias", "use", "tensorflow", "variabl", "num", "weight", "num", "bias", "num", "num", "prepar", "input", "the", "activ", "function", "num", "afinput", "bias", "num", "num", "activ", "function", "the", "output", "layer", "neuron", "num", "predict", "num", "num", "measur", "the", "predict", "error", "the", "network", "after", "train", "num", "predictionerror", "num", "num", "minim", "the", "predict", "error", "use", "gradient", "descent", "optim", "num", "trainop", "num", "num", "creat", "tensorflow", "session", "num", "sess", "num", "num", "initi", "the", "tensorflow", "variabl", "weight", "and", "bias", "num", "num", "num", "train", "data", "input", "num", "traininginputsdata", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "train", "data", "desir", "output", "num", "trainingoutputsdata", "num", "num", "num", "num", "num", "num", "num", "num", "num", "train", "loop", "the", "neural", "network", "num", "for", "step", "num", "num", "num", "class", "score", "some", "test", "data", "num", "num", "num", "close", "the", "tensorflow", "session", "free", "resourc", "num", "read", "the", "train", "data", "the", "data", "read", "the", "previous", "code", "line", "num", "and", "num", "use", "someth", "call", "placehold", "but", "what", "placehold", "whi", "have", "not", "just", "use", "numpi", "array", "for", "prepar", "the", "data", "answer", "these", "question", "can", "explor", "simpler", "exampl", "that", "read", "some", "input", "and", "print", "the", "consol", "follow", "num", "import", "tensorflow", "num", "num", "creat", "numpi", "array", "hold", "the", "input", "data", "num", "numpyinput", "num", "num", "num", "num", "num", "num", "num", "num", "num", "convert", "the", "numpi", "array", "tensorflow", "tensor", "num", "doc", "apidocspythontfconverttotensor", "num", "traininginput", "num", "num", "creat", "tensorflow", "session", "num", "sess", "num", "num", "run", "the", "session", "for", "evalu", "the", "previous", "creat", "tensor", "num", "num", "num", "close", "the", "tensorflow", "session", "num", "the", "input", "read", "into", "numpi", "array", "away", "from", "tensorflow", "line", "num", "but", "tensorflow", "just", "know", "tensor", "and", "just", "have", "convert", "the", "numpi", "array", "into", "tensor", "the", "tensorflow", "oper", "doe", "that", "convers", "line", "num", "abl", "print", "the", "content", "tensor", "must", "first", "creat", "session", "use", "the", "class", "line", "num", "line", "num", "the", "session", "run", "order", "evalu", "the", "tensor", "traininginput", "and", "get", "valu", "print", "final", "the", "session", "got", "close", "line", "num", "the", "result", "print", "follow", "output", "num", "num", "num", "num", "num", "num", "this", "exampl", "use", "placehold", "what", "the", "use", "tensorflow", "placehold", "assum", "that", "want", "run", "the", "session", "with", "anoth", "input", "that", "have", "modifi", "the", "numpyinput", "python", "variabl", "each", "time", "new", "input", "appli", "numpyinput", "num", "num", "num", "num", "num", "num", "not", "good", "way", "modifi", "the", "code", "order", "get", "differ", "input", "better", "way", "for", "that", "just", "creat", "the", "tensor", "and", "then", "modifi", "valu", "without", "modifi", "the", "code", "this", "the", "job", "the", "tensorflow", "placehold", "placehold", "tensorflow", "way", "for", "accept", "the", "input", "data", "creat", "the", "code", "and", "modifi", "multipl", "time", "the", "session", "run", "time", "the", "follow", "code", "modifi", "the", "previous", "code", "use", "placehold", "num", "import", "tensorflow", "num", "num", "creat", "placehold", "with", "data", "type", "intnum", "and", "shape", "numxnum", "num", "traininginput", "num", "num", "creat", "tensorflow", "session", "num", "sess", "num", "num", "run", "the", "session", "for", "evalu", "assign", "valu", "the", "placehold", "num", "num", "num", "close", "the", "tensorflow", "session", "num", "this", "code", "print", "the", "same", "output", "befor", "but", "use", "placehold", "line", "num", "the", "placehold", "creat", "specifi", "the", "data", "type", "and", "the", "shape", "the", "data", "will", "accept", "the", "shape", "can", "specifi", "restrict", "the", "input", "data", "specif", "size", "shape", "specifi", "then", "differ", "input", "with", "differ", "shape", "can", "assign", "the", "placehold", "the", "placehold", "assign", "valu", "when", "run", "the", "session", "use", "the", "feeddict", "argument", "the", "run", "oper", "feeddict", "dictionari", "use", "initi", "the", "placehold", "but", "assum", "there", "featur", "vector", "num", "featur", "and", "have", "dataset", "num", "sampl", "assum", "want", "train", "model", "two", "time", "with", "differ", "number", "sampl", "say", "num", "and", "num", "here", "the", "size", "the", "train", "set", "has", "one", "dimens", "fix", "number", "featuresnumb", "column", "and", "anoth", "dimens", "number", "rowsnumb", "train", "sampl", "variabl", "size", "set", "size", "num", "then", "restrict", "the", "input", "size", "num", "num", "and", "thus", "won", "abl", "retrain", "the", "model", "with", "num", "sampl", "the", "same", "hold", "for", "use", "num", "number", "row", "the", "solut", "just", "set", "the", "number", "column", "but", "leav", "the", "number", "row", "unspecifi", "set", "none", "follow", "creat", "placehold", "with", "data", "type", "intnum", "and", "shape", "rxnum", "traininginput", "one", "benefit", "use", "placehold", "that", "valu", "modifi", "easili", "have", "not", "modifi", "the", "program", "order", "the", "use", "differ", "input", "like", "variabl", "java", "python", "but", "not", "exact", "variabl", "tensorflow", "can", "run", "the", "session", "multipl", "time", "with", "differ", "valu", "for", "the", "placehold", "run", "the", "session", "for", "evalu", "assign", "valu", "the", "placehold", "that", "use", "numpi", "array", "have", "creat", "new", "python", "array", "for", "each", "new", "input", "are", "run", "the", "program", "with", "this", "whi", "are", "use", "placehold", "for", "feed", "the", "data", "for", "everi", "input", "there", "should", "separ", "placehold", "out", "neural", "network", "there", "are", "two", "input", "which", "are", "train", "input", "and", "train", "output", "and", "thus", "there", "should", "two", "placehold", "one", "for", "each", "line", "num", "and", "num", "codesamplenum", "prepar", "train", "data", "inputsoutput", "traininginput", "trainingoutput", "desir", "output", "for", "each", "input", "note", "that", "the", "size", "these", "placehold", "not", "fix", "allow", "variabl", "number", "train", "sampl", "use", "with", "the", "code", "unchang", "but", "both", "placehold", "input", "and", "output", "train", "data", "must", "have", "the", "same", "number", "row", "for", "exampl", "accord", "our", "current", "present", "train", "data", "traininginput", "should", "have", "shape", "num", "num", "and", "trainingoutput", "should", "shape", "num", "num"], "timestamp_scraper": 1556390458.087754, "title": "TensorFlow: Building Feed-Forward Neural Networks Step-by-Step", "read_time": 350.7, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/ahmed-gad\" rel=\"author\" title=\"Posts by Ahmed Gad\">Ahmed Gad</a>, KDnuggets Contributor.</b></div>\n<p><img alt=\"\" class=\"aligncenter\" src=\"https://media.licdn.com/media/AAIA_wDGAAAAAQAAAAAAAAobAAAAJGY5NzBhMDc5LWU0NmItNDRkNS1hNzJkLTgyOWFjZDhjMjg5Mg.png\" width=\"99%\"/></p>\n<p>In this article, two basic feed-forward neural networks (FFNNs) will be created using TensorFlow deep learning library in Python. The reader should have basic understanding of how neural networks work and its concepts in order to apply them programmatically.</p>\n<p>This article will take you through all steps required to build a simple feed-forward neural network in TensorFlow by explaining each step in details. Before actual building of the neural network, some preliminary steps are recommended to be discussed.</p>\n<p>The summarized steps are as follows:</p>\n<ol>\n<li>Reading the training data (inputs and outputs)\n<li>Building and connect the neural networks layers (this included preparing weights, biases, and activation function of each layer)\n<li>Building a loss function to assess the prediction error\n<li>Create a training loop for training the network and updating its parameters\n<li>Applying some testing data to assess the network prediction accuracy\n</li></li></li></li></li></ol>\n<p>Here is the first classification problem that we are to solve using neural network.</p>\n<p><img alt=\"Image\" class=\"aligncenter\" src=\"https://media.licdn.com/mpr/mpr/AAIA_wDGAAAAAQAAAAAAAA02AAAAJDlkMTg4ODI4LWMxYzQtNDM4Zi04NmI5LTRlM2M1MTQ1OWI5Yg.png\" width=\"60%\"/></p>\n<p>It is a binary classification problem to classify colors into either red or blue based on the three RGB color channels. It can be solved linearly and thus we don`t have to use hidden layers. Just input and output layers are to be used. There will be a single neuron in the output layer with an activation function. The network architecture is shown in the following figure (<strong><u>Figure 1</u></strong>):</p>\n<p><img alt=\"Image\" class=\"aligncenter\" src=\"https://media.licdn.com/mpr/mpr/AAIA_wDGAAAAAQAAAAAAAAu0AAAAJGYyMzU4NjNkLWY0MGEtNDRkNi04OWI4LTVjZTE1ZjEwN2U1Mg.png\" width=\"99%\"/></p>\n<p>Where X0=1 is the bias and W0 is its weight. W1 , W2, and W3 are the weights for the three inputs R (Red), G (Green), and B (Blue).</p>\n<p>Here is the complete code of the neural network solving that problem to be discussed later. For easy access, this code is called\u00a0<strong><u>CodeSample1</u></strong>.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r\n2.\u00a0 \u00a0\u00a0\r\n3.\u00a0 #\u00a0Preparing\u00a0training\u00a0data\u00a0(inputs-outputs)\u00a0\u00a0\r\n4.\u00a0 training_inputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a03],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\n5.\u00a0 training_outputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a01],\u00a0dtype=tensorflow.float32)\u00a0#Desired\u00a0outputs\u00a0for\u00a0each\u00a0input\u00a0\u00a0\r\n6.\u00a0 \u00a0\u00a0\r\n7.\u00a0 #\u00a0Preparing\u00a0neural\u00a0network\u00a0parameters\u00a0(weights\u00a0and\u00a0bias)\u00a0using\u00a0TensorFlow\u00a0Variables\u00a0\u00a0\r\n8.\u00a0 weights\u00a0=\u00a0tensorflow.Variable(initial_value=[[.3],\u00a0[.1],\u00a0[.8]],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\n9.\u00a0 bias\u00a0=\u00a0tensorflow.Variable(initial_value=[[1]],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\n10. \u00a0\u00a0\r\n11. #\u00a0Preparing\u00a0inputs\u00a0of\u00a0the\u00a0activation\u00a0function\u00a0\u00a0\r\n12. af_input\u00a0=\u00a0tensorflow.matmul(training_inputs,\u00a0weights)\u00a0+\u00a0bias\u00a0\u00a0\r\n13. \u00a0\u00a0\r\n14. #\u00a0Activation\u00a0function\u00a0of\u00a0the\u00a0output\u00a0layer\u00a0neuron\u00a0\u00a0\r\n15. predictions\u00a0=\u00a0tensorflow.nn.sigmoid(af_input)\u00a0\u00a0\r\n16. \u00a0\u00a0\r\n17. #\u00a0Measuring\u00a0the\u00a0prediction\u00a0error\u00a0of\u00a0the\u00a0network after being trained\u00a0\u00a0\r\n18. prediction_error\u00a0=\u00a0tensorflow.reduce_sum(training_outputs\u00a0-\u00a0predictions)\u00a0\u00a0\r\n19. \u00a0\u00a0\r\n20. #\u00a0Minimizing\u00a0the\u00a0prediction\u00a0error\u00a0using\u00a0gradient\u00a0descent\u00a0optimizer\u00a0\u00a0\r\n21. train_op\u00a0=\u00a0tensorflow.train.GradientDescentOptimizer(learning_rate=0.05).minimize(prediction_error)\u00a0\u00a0\r\n22. \u00a0\u00a0\r\n23. #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n24. sess\u00a0=\u00a0tensorflow.Session()\u00a0\u00a0\r\n25. \u00a0\u00a0\r\n26. #\u00a0Initializing\u00a0the\u00a0TensorFlow\u00a0Variables\u00a0(weights\u00a0and\u00a0bias)\u00a0\u00a0\r\n27. sess.run(tensorflow.global_variables_initializer())\u00a0\u00a0\r\n28. \u00a0\u00a0\r\n29. #\u00a0Training\u00a0data\u00a0inputs\u00a0\u00a0\r\n30. training_inputs_data\u00a0=\u00a0[[255,\u00a00,\u00a00],\u00a0\u00a0\r\n31. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[248,\u00a080,\u00a068],\u00a0\u00a0\r\n32. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[0,\u00a00,\u00a0255],\u00a0\u00a0\r\n33. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[67,\u00a015,\u00a0210]]\u00a0\u00a0\r\n34. \u00a0\u00a0\r\n35. #\u00a0Training\u00a0data\u00a0desired\u00a0outputs\u00a0\u00a0\r\n36. training_outputs_data\u00a0=\u00a0[[1],\u00a0\u00a0\r\n37. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [1],\u00a0\u00a0\r\n38. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [0],\u00a0\u00a0\r\n39. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 [0]]\u00a0\u00a0\r\n40. \u00a0\u00a0\r\n41. #\u00a0Training\u00a0loop\u00a0of\u00a0the\u00a0neural\u00a0network\u00a0\u00a0\r\n42. for\u00a0step\u00a0in\u00a0range(10000):\u00a0\u00a0\r\n43. \u00a0\u00a0\u00a0\u00a0sess.run(fetches=[train_op],\u00a0feed_dict={\r\n44. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0training_inputs:\u00a0training_inputs_data,\u00a0\u00a0\r\n45. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0training_outputs:\u00a0training_outputs_data})\u00a0\u00a0\r\n46. \u00a0\u00a0\r\n47. #\u00a0Class scores\u00a0of\u00a0some\u00a0testing\u00a0data\u00a0\u00a0\r\n48. print(\"Expected Scores\u00a0:\u00a0\",\u00a0sess.run(fetches=predictions,\u00a0feed_dict={training_inputs:\u00a0[[248,\u00a080,\u00a068],\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0[0,\u00a00,\u00a0255]]}))\u00a0\u00a0\r\n49. \u00a0\r\n50. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0to\u00a0free\u00a0resources\u00a0\u00a0\r\n51. sess.close()</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3>Reading the Training Data</h3>\n<p>\u00a0<br>\nThe data is read in the previous code in lines 4 and 5 using something called placeholder. But what is a placeholder? Why we have not just used a NumPy array for preparing the data? To answer these questions, we can explore a simpler example that reads some inputs and print it to the console as follows:</br></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r\n2.\u00a0 \u00a0\u00a0\r\n3.\u00a0 #\u00a0Creating\u00a0a\u00a0NumPy\u00a0array\u00a0holding\u00a0the\u00a0input\u00a0data\u00a0\u00a0\r\n4.\u00a0 numpy_inputs\u00a0=\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r\n5.\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]\u00a0\u00a0\r\n6.\u00a0 \u00a0\u00a0\r\n7.\u00a0 #\u00a0Converting\u00a0the\u00a0NumPy\u00a0array\u00a0to\u00a0a\u00a0TensorFlow\u00a0Tensor\u00a0\u00a0\r\n8.\u00a0 #\u00a0convert_to_tensor()\u00a0doc:\u00a0https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor\u00a0\u00a0\r\n9.\u00a0 training_inputs\u00a0=\u00a0tensorflow.convert_to_tensor(value=numpy_inputs,\u00a0dtype=tensorflow.int8)\u00a0\u00a0\r\n10. \u00a0\u00a0\r\n11. #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n12. sess\u00a0=\u00a0tensorflow.Session()\u00a0\u00a0\r\n13. \u00a0\u00a0\r\n14. #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0the\u00a0previously\u00a0created\u00a0Tensor\u00a0\u00a0\r\n15. print(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs))\u00a0\u00a0\r\n16. \u00a0\u00a0\r\n17. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n18. sess.close()</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The input is read into a NumPy array away from TensorFlow as in line 4. But TensorFlow just know Tensors and just we have to convert the NumPy array into a Tensor. The tensorflow.convert_to_tensor() TensorFlow operation does that conversion as in line 9. To be able to print the contents of a Tensor, we must at first create a Session using the tensorflow.Session() class as in line 12. In line 15, the session runs in order evaluate the Tensor training_inputs and get its values printed. Finally, the session got closed in line 18. The result of printing is as follows:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Output\u00a0is\u00a0:\u00a0\u00a0[[\u00a05\u00a0\u00a02\u00a013]\u00a0,\u00a0[\u00a07\u00a0\u00a09\u00a0\u00a00]]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>This example doesn`t use placeholders. So, what is the use of a TensorFlow placeholder? Assume that we want to run the session with another input. To do that, we have to modify the numpy_input Python variable each time a new input is applied.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>numpy_inputs\u00a0=\u00a0[[83,\u00a049,\u00a092],\u00a0\u00a0[31,\u00a078,\u00a060]]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>It is not a good way to modify the code in order to get different inputs. A better way for doing that is to just create the Tensor and then modify its value without modifying it in the code. This is the job of the TensorFlow placeholder.</p>\n<p>Placeholder in TensorFlow is a way for accepting the input data. It is created in the code and modified multiple times in the Session running time. The following code modifies the previous code to use placeholders:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>1.\u00a0 import\u00a0tensorflow\u00a0\u00a0\r\n2.\u00a0 \u00a0\u00a0\r\n3.\u00a0 #\u00a0Create\u00a0a\u00a0placeholder\u00a0with\u00a0data\u00a0type\u00a0int8\u00a0and\u00a0shape\u00a02x3.\u00a0\u00a0\r\n4.\u00a0 training_inputs\u00a0=\u00a0tensorflow.placeholder(dtype=tensorflow.int8,\u00a0shape=(2,\u00a03))\u00a0\u00a0\r\n5.\u00a0 \u00a0\u00a0\r\n6.\u00a0 #\u00a0Creating\u00a0a\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n7.\u00a0 sess\u00a0=\u00a0tensorflow.Session()\u00a0\u00a0\r\n8.\u00a0 \u00a0\u00a0\r\n9.\u00a0 #\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0assigning\u00a0a\u00a0value\u00a0to\u00a0the\u00a0placeholder\u00a0\u00a0\r\n10. print(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n11. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r\n12. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]}))\u00a0\u00a0\r\n13. \u00a0\u00a0\r\n14. #\u00a0Closing\u00a0the\u00a0TensorFlow\u00a0Session\u00a0\u00a0\r\n15. sess.close()\u00a0\u00a0</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>This code prints the same outputs as before but it uses a placeholder as in line 4. The placeholder is created by specifying the data type and the shape of the data it will accept. The shape can be specified to restrict the input data to be of specific size. If no shape specified, then different inputs with different shapes can be assigned to the placeholder. The placeholder is assigned a value when running the Session using the feed_dict argument of the run operation. feed_dict is a dictionary used to initialize the placeholders.</p>\n<p>But assume there is a feature vector of 50 feature and we have a dataset of 100 samples. Assume we want to train a model two times with different number of samples, say 30 and 40. Here the size of the training set has one dimension fixed (number of features=number of columns) and another dimension (number of rows=number of training samples) of variable size. Setting its size to 30, then we restrict the input to be of size (30, 50) and thus we won`t be able to re-train the model with 40 samples. The same holds for using 40 as number of rows. The solution is to just set the number of columns but leave the number of rows unspecified by setting it to None as follows:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>#\u00a0Create\u00a0a\u00a0placeholder\u00a0with\u00a0data\u00a0type\u00a0int8\u00a0and\u00a0shape\u00a0Rx3.\u00a0\u00a0\r\ntraining_inputs\u00a0=\u00a0tensorflow.placeholder(dtype=tensorflow.int8,\u00a0shape=(None,\u00a050))</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>One benefit of using placeholder is that its value is modified easily. You have not to modify the program in order the use different inputs. It is like a variable in Java, C++, or Python but it is not exactly a variable in TensorFlow. We can run the session multiple times with different values for the placeholder:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre spellcheck=\"false\">#\u00a0Running\u00a0the\u00a0session\u00a0for\u00a0evaluating\u00a0assigning\u00a0a\u00a0value\u00a0to\u00a0the\u00a0placeholder\u00a0\u00a0\r\nprint(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n                     \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[5,\u00a02,\u00a013],\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[7,\u00a09,\u00a00]]}))\u00a0\u00a0\r\nprint(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[1,\u00a02,\u00a03],\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[4,\u00a05,\u00a06]]}))\u00a0\u00a0\r\nprint(\"Output\u00a0is\u00a0:\u00a0\",\u00a0sess.run(fetches=training_inputs,\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0feed_dict={training_inputs:\u00a0[[12,\u00a013,\u00a014],\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[15,\u00a016,\u00a017]]}))</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>To do that using NumPy arrays we have to create a new Python array for each new input we are to run the program with.</p>\n<p>This is why we are using placeholders for feeding the data. For every input there should be a separate placeholder. In out neural network, there are two inputs which are training inputs and training outputs and thus there should be two placeholders one for each as in lines 4 and 5 in CodeSample1.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre spellcheck=\"false\">#\u00a0Preparing\u00a0training\u00a0data\u00a0(inputs-outputs)\u00a0\u00a0\r\ntraining_inputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a03],\u00a0dtype=tensorflow.float32)\u00a0\u00a0\r\ntraining_outputs\u00a0=\u00a0tensorflow.placeholder(shape=[None,\u00a01],\u00a0dtype=tensorflow.float32)\u00a0#Desired\u00a0outputs\u00a0for\u00a0each\u00a0input\u00a0\u00a0\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Note that the size of these placeholders is not fixed to allow variable number of training samples to be used with the code unchanged. But both placeholders of inputs and outputs training data must have the same number of rows. For example, according to our currently presented training data, training_inputs should have a shape=(4, 2) and training_outputs should be of shape=(4, 1).</p>\n</div> ", "website": "kdnuggets"}