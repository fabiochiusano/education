{"content": "comments By Henry H. Eckerson, Eckerson Group. From Neural Networks and Deep Learning , by Michael Nielsen. Deep learning is exploding. According to Gartner , the number of open positions for deep learning experts grew from almost zero in 2014 to 41,000 today. Much of this growth is being driven by high tech giants, such as Facebook, Apple, Netflix, Microsoft, Google, and Baidu. These big players and others have invested heavily in deep learning projects. Besides hiring experts, they have funded deep learning projects and experiments and acquired deep learning related companies. And these investments are only the beginning. Gartner predicts that 80% of data scientists will be using deep learning tools by 2018. Deep learning technology, which is meant to simulate biological neural networks in brains, arose in the 1950s, along with the first computers. So, if computers and deep learning began development together, why is deep learning only now reaching a mainstream computing audience? The increased processing power afforded by graphical processing units (GPUs), the enormous amount of available data, and the development of more advanced algorithms has led to the rise of deep learning. \u00a0 The Current State Of Deep Learning Deep learning is all around us. It\u2019s used to determine which online ads to display in real time, identify and tags friends in photos, translate your voice to text, translate text into different languages on a Web page, and drive autonomous vehicles. Deep learning is also found in less visible places. Credit card companies use deep learning for fraud detection; businesses use it to predict whether you will cancel a subscription and provide personalized customer recommendations; banks use it to predict bankruptcy and loan risk; hospitals use it for detection, diagnosis, and treatment of diseases. The range of applications is almost limitless. Other options include text analysis, image captioning, image colorization, x-ray analysis, weather forecasts, finance predictions, and more. Deep learning is already being widely used to automate processes, improve performance, detect patterns, and solve problems. What Is Deep Learning? Deep learning falls under the umbrella of machine learning which is a subset of artificial intelligence (AI). Loosely defined, artificial intelligence encompasses technology that simulates human capabilities while machine learning algorithms learn and adapt to new events. Deep learning is a term for technologies that use artificial neural network (ANNs) algorithms. Experts consider deep learning and ANNs to be the same thing and use the terms interchangeably. Just like neural networks in brains, ANNs have neurons (nodes) interconnected by synapses (links). Each node receives data, performs an operation, and passes the new data to another node via a link. The links contain weights or biases that influence the next node\u2019s operation. To illustrate the roles of nodes and links, imagine a company that wants to predict whether a customer will renew a subscription based on two predictors, gender and age. The company\u2019s neural network has two input nodes\u2013one for each predictor\u2013connected via separate links to one output node. Gender and age values are fed into the input nodes. Those values are multiplied by preset weights in the links. If age happens to be a better predictor than gender, then the link that sends age data will have a higher weight. The output node adds the weighted data from the input nodes and produces a value, which equates to a prediction. In this simplified example, the value could be between 0 and 1. The closer the value is to 1, the more likely the customer is to renew the subscription. In a real project, ANNs may contain thousands of nodes and billions of links. Each node belongs to a layer, which is a group of nodes. There are input layers, output layers, and layers in between the two, which are known as hidden layers. Adding nodes, links, and layers increases the accuracy of the ANN. \u00a0 Role of Training. Once built, ANNs require a lot of \u2018training\u2019 to work well. An untrained ANN will always fail. This is where the \u2018learning\u2019 in deep learning comes into play. Data scientists can use supervised or unsupervised training. Under supervised training, ANNs process input values from test data and produce output values (predictions), which are compared to the real output values from the test data. Then, a training algorithm, specifically designed to train ANNs, is applied. A few types of training algorithms exist, but the most widely used type is called backpropagation. The backpropagation algorithm identifies the parts of the ANN responsible for an inaccurate prediction by following the error in the output nodes back through the ANN to the hidden and input layers and changes the weights accordingly. This process is repeated over and over until the ANN produces consistent, accurate predictions with the test data. Then, the ANN is ready to process new input values and predict unknown output values. The purpose of unsupervised training is to model the structure or distribution of data, not to produce a predictor. So with unsupervised training, once an ANN processes input data, the weights do not need to be changed because there is no corresponding output data to compare the ANN\u2019s prediction to. Deep Learning Is Old Technology The best place to start the AI and deep learning story is with William McCulloch and Walter Pitts. In 1943, they published A Logical Calculus of the Ideas Immanent in Nervous Activity in which they outlined the first computational model of a neural network. This paper served as the blueprint for the first ANNs. Six years later, Donald Hebb published The Organization of Behavior , which argued that the connections between neurons strengthened with use. This concept proved fundamental to understanding human learning and how to train ANNs. In 1954, Belmont Farley and Wesley Clark, using the research done by McCulloch and Pitts, ran the first computer simulations of an artificial neural network. These networks of up to 128 neurons were trained to recognize simple patterns. In the summer of 1956, computer scientists met \u201cto act on the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\u201d This event, known as the Dartmouth Conference, is considered the birthplace of AI. Following the Dartmouth Conference, the field of artificial intelligence took off. In 1957, Frank Rosenblatt began to study a type of neural network he called the perceptron and was able to apply the training method Farley and Clark used on their two-layer networks to multi-layer ones. In 1959, Bernard Widrow and Marcian Hoff developed a single layer neural network they called ADALINE short for Adaptive Linear Elements, which could predict the next bit of information on an incoming phone call based on the prior bits. Their next development, a multilayer neural network called MADALINE, eliminated echoes on phone calls and is said to be the first practical application of an ANN. Innovations continued through the \u201860s, but funding, research, and advances slowed in the \u201870s. AI scientists\u2019 accomplishments failed to live up to media hype and government expectations. The so-called \u2018AI winter\u2019 ensued during which there was little funding and minimal research done on the topic. Starting in 1986, research resurged for a few years after Geoff Hinton published Learning Representations by Back-propagating Errors , which describes the backpropagation learning procedure. However, true resurgence did not occur until the mid 2000s. Today, deep learning and AI are in deep bloom, and some would say overhyped. So, Why Are ANNs Becoming Useful Now? Three factors have unleashed the potential of deep learning: 1. The Exponential Explosion of Available Data According to Cisco, the global Internet traffic in 1992 was 100 GB per day. In 2015, that number was 17.5 million times greater at 20,235 GB per second. Now, 90% of the world\u2019s data has been created in the last two years. Without this data, training ANNs containing millions of connections and thousands of nodes could not happen. For an ANN to recognize a face, detect credit fraud, or translate a voice to text in a noisy room it takes more than just a few bits of test data for consistent, accurate predictions. This is why ANNs flourish in the age of big data. The best and most visible example of data enabling an ANN is a project led by Google X, a somewhat secretive research and development team. Led by Andrew Ng, until recently the chief scientist at Baidu Research, and Jeff Dean, a Google Senior Fellow, the team assembled a 16,000 central processing units (CPUs) to power a ANN with over a billion connections. The ANN then underwent training, processing 10 million images from randomly selected YouTube videos. According to many sources, the ANN trained itself to recognize cats. In reality, only one node in the ANN was responsible for recognizing cat images. Other nodes could identify human bodies and faces. Two decades ago, it would have been impossible to collect 10 million images to train the ANN. Next, we look at the rise of the GPU.", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"Gold Blog, May 2017\" src=\"/images/top-kdnuggets-blog-2017-may-gold.png\" width=\"95\"/>Deep Learning \u2013 Past, Present, and Future</h1> ", "url": "https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html", "tfidf": {"tfidf": {"after": 1.02070207021, "real": 6.84310344828, "googl": 34.166427546600005, "web": 5.17133550489, "fall": 1.6945244956799999, "donald": 7.0970049173000005, "onc": 2.9949066213999997, "relat": 1.23750876919, "hebb": 1323.0, "data": 64.15227562746, "wide": 3.1196698762, "neuron": 192.8259109311, "organ": 1.6387283237, "would": 2.1657458563599996, "number": 2.20285833218, "incom": 3.92, "recogn": 10.19816926288, "specif": 1.8719490626099997, "walter": 4.81967213115, "logic": 8.929133858270001, "mcculloch": 382.554216868, "well": 1.0655748708, "unsupervis": 1035.3913043490002, "done": 4.6605019814999995, "limitless": 154.13592233, "assembl": 3.0011342155, "wesley": 29.0769230769, "higher": 2.1218925421, "umbrella": 23.1428571429, "their": 2.0309581681, "calculus": 62.2588235294, "chief": 2.41827875095, "creat": 1.2492917847, "room": 3.07674418605, "how": 1.60250328051, "billion": 9.7339055794, "million": 6.9116238572, "represent": 5.928304705, "increas": 2.6404989605, "equat": 9.76984615385, "expert": 16.101419878290002, "distribut": 2.7396031061299997, "found": 1.11387076405, "untrain": 123.06976744200001, "unleash": 34.6637554585, "began": 2.58209319346, "summer": 2.22104085059, "deep": 94.32723948804, "will": 6.1240549298, "event": 3.0713871155000003, "consid": 2.4794627518400003, "those": 1.19548192771, "purpos": 2.23416830847, "nodes\u2013on": 1323.0, "next": 5.9802241265600005, "simpl": 3.3981164383599998, "perform": 3.0627954085000004, "but": 2.03264835798, "gender": 28.29946524063, "met": 2.3614457831299998, "off": 1.5121440137200002, "expect": 2.20011086475, "applic": 6.85344269372, "hidden": 15.62598425196, "ann": 61.00288184436, "fraud": 32.937759336, "has": 3.1309492505999996, "have": 6.089369046839999, "besid": 5.1362018764199995, "enorm": 7.54921540656, "pass": 1.61818367139, "geoff": 38.7219512195, "experi": 1.87062566278, "govern": 1.50941243582, "onlin": 2.6051854282900004, "model": 4.1811956808, "unit": 2.30789358918, "alway": 2.06745670009, "slow": 4.04793472718, "concept": 2.65707112971, "mainstream": 7.450023463160001, "much": 1.1942229577299999, "under": 2.1563327674, "decad": 2.1390460792200003, "cpus": 174.46153846200002, "field": 1.7790228597, "global": 3.30612244898, "togeth": 1.58095996813, "short": 1.41295834817, "not": 4.06269592476, "growth": 3.15062512403, "are": 8.23924748624, "minim": 6.10850327049, "less": 1.46904783936, "stori": 2.02396736359, "happen": 5.92719805862, "true": 2.55569864778, "said": 1.54751925139, "solv": 7.26923076923, "than": 2.0655737705, "then": 4.34631442064, "separ": 1.6012102874399998, "graphic": 9.035856573710001, "design": 1.45825296225, "anoth": 1.13643521832, "reach": 1.49801849406, "last": 1.2117234010100002, "world": 1.11340206186, "card": 6.42492917847, "aros": 7.941970985489999, "node": 753.8882681567, "featur": 1.52712581762, "practic": 1.70434782609, "respons": 3.0133814178600002, "alreadi": 1.9551724137900002, "influenc": 1.77246846042, "phone": 18.237794371059998, "itself": 1.74557449148, "provid": 1.21552714187, "until": 3.44556174492, "valu": 22.777618364400002, "accord": 5.10359238124, "develop": 5.977859778600001, "pattern": 7.58347265346, "accuraci": 12.7620578778, "senior": 4.00706713781, "thousand": 4.953510140400001, "nervous": 17.6204217536, "network": 31.124326090559997, "confer": 5.6649420160599995, "three": 1.06621893889, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "collect": 1.64109985528, "add": 4.61243463103, "call": 6.4059179556, "subset": 27.3253012048, "fellow": 4.3639362287, "cancel": 5.23097199341, "produc": 5.47731585304, "use": 15.444581360699999, "biolog": 6.60674157303, "languag": 2.29488291414, "media": 2.59369384088, "ani": 1.13383802314, "two": 5.0689655172500006, "fed": 12.5402843602, "and": 51.00321259863, "from": 6.00340328982, "visibl": 9.37190082644, "behavior": 5.52978056426, "resurg": 42.8502024292, "num": 28.00882112028, "jeff": 9.7339055794, "multipli": 20.4061696658, "diagnosi": 28.8130671506, "idea": 2.0930784443, "william": 1.75483585719, "widrow": 1323.0, "acquir": 3.10563380282, "bloom": 25.320574162699998, "for": 12.00378048012, "color": 3.8255421686699997, "predict": 67.40300457215001, "output": 61.415860735040006, "closer": 5.5666199158500005, "vehicl": 4.6928761454300005, "simplifi": 12.109839816900001, "with": 6.007189253939998, "zero": 8.75192943771, "new": 3.0536641662, "determin": 2.1658935879900003, "topic": 5.457545548300001, "recommend": 3.9142011834300003, "better": 2.0065722952500002, "compani": 6.2094455852, "caption": 55.5104895105, "current": 1.5325803649, "team": 4.5496489468400005, "look": 1.9086318826599997, "option": 4.04896710023, "video": 3.29719626168, "predictor": 301.443037974, "ago": 6.05954198473, "work": 1.11520089913, "posit": 1.37252528746, "later": 1.08650424309, "train": 30.985118321599998, "compar": 3.7324556247800005, "strengthen": 6.247933884299999, "group": 2.41993750476, "old": 1.52844902282, "littl": 1.5499365420299998, "could": 4.8174783796, "photo": 6.41973311767, "place": 2.2008733624400003, "imman": 172.56521739099998, "bodi": 1.8618505922400002, "error": 12.08219178082, "big": 5.480151881259999, "type": 6.084312723570001, "financ": 4.255159474669999, "cisco": 133.411764706, "argu": 2.67768595041, "rosenblatt": 547.448275862, "machin": 12.073003802279999, "into": 3.04507384437, "youtub": 20.25, "paper": 2.6628648104700003, "marcian": 1221.23076923, "prior": 2.17807655371, "appl": 13.6980155306, "underw": 9.793954349169999, "hire": 4.95815115553, "realiti": 4.563380281690001, "via": 4.595744680859999, "through": 2.14149861738, "requir": 1.52844902282, "meant": 3.20597738288, "face": 3.6065424807, "what": 1.25343439128, "exponenti": 39.2, "translat": 8.57235421167, "loan": 8.26014568158, "cat": 21.0696748506, "nielsen": 33.2830188679, "forecast": 21.897931034499997, "potenti": 2.52080025405, "brain": 17.858267716540002, "tech": 19.1739130435, "base": 2.2925631769, "occur": 1.7453825857499998, "weather": 5.3944954128400004, "along": 1.2973768080399999, "twolay": 1323.0, "explod": 12.432263116700002, "renew": 9.238289205700001, "factor": 2.89127663449, "microsoft": 24.8450704225, "were": 1.02458857696, "comput": 23.566551212280004, "human": 5.68964281449, "layer": 65.13230769232, "greater": 2.14801785956, "contain": 4.79444332596, "noisi": 62.2588235294, "belong": 3.5, "problem": 1.76674827509, "voic": 6.42362937488, "neural": 594.606741573, "thing": 2.4065484311099996, "serv": 1.4668760972, "just": 2.67160286074, "test": 10.62828451884, "adapt": 6.64545835078, "understand": 2.96858638743, "interconnect": 30.297709923699998, "internet": 4.98461538462, "birthplac": 18.082004555799998, "dure": 1.0503473370799998, "random": 7.1902173913, "defin": 2.72830383227, "led": 4.01348276733, "activ": 1.46403541129, "where": 1.06715063521, "live": 1.30591428806, "echo": 10.5, "tool": 4.99716713881, "start": 2.53347163488, "took": 1.4009883515700001, "ran": 3.4915328788199997, "enabl": 3.5421686747, "they": 4.12069301148, "risk": 4.095975232200001, "whi": 9.769846153860001, "bankruptci": 18.7659574468, "studi": 1.53184098804, "giant": 6.23566378633, "singl": 1.60948905109, "autom": 19.8202247191, "central": 1.6121039805000001, "play": 1.46390041494, "mani": 1.04426757877, "diseas": 5.2120814182499995, "over": 3.07575072651, "afford": 7.0875, "netflix": 163.670103093, "analysi": 6.95705521472, "display": 2.93456561922, "linear": 13.8776223776, "hinton": 152.653846154, "consist": 2.9802890932999997, "traffic": 5.95052473763, "ensu": 8.4312267658, "synaps": 211.68, "there": 3.12273800157, "explos": 6.72142252329, "connect": 5.653175074170001, "inform": 1.5753125620200001, "bank": 2.87400434468, "baidu": 2268.0, "say": 1.7544480053, "best": 3.1657028913200005, "exampl": 3.00966824644, "continu": 1.13928955867, "unknown": 3.77281368821, "secret": 3.11294117647, "illustr": 3.6614391143900002, "loos": 7.065420560750001, "take": 1.13961668222, "follow": 2.09280253098, "now": 3.4823426189999998, "bernard": 8.540075309310001, "predictor\u2013connect": 1323.0, "per": 3.9195161091199995, "high": 1.14777327935, "winter": 3.24132298898, "driven": 5.601976005650001, "abl": 1.8208510150200001, "publish": 4.10657009829, "power": 2.6792675723599997, "audienc": 4.4784203103, "also": 1.01476510067, "person": 1.40520446097, "around": 1.21394708671, "such": 1.06151377374, "treatment": 3.87125091441, "role": 3.10654534782, "research": 11.652110091720001, "imag": 13.506891271050002, "accomplish": 5.17302052786, "repeat": 2.8771293947099994, "the": 94.0, "may": 1.05201775893, "becom": 1.12492028626, "age": 7.43119266055, "tag": 19.7462686567, "scientist": 23.4713187463, "hype": 80.5888324873, "open": 1.24556723678, "select": 2.02345144022, "six": 1.5552507837, "hospit": 3.4633507853400003, "want": 1.99698113208, "simul": 45.9175704988, "act": 1.4318181818200002, "howev": 1.0945191313299998, "prove": 2.45720476706, "elimin": 3.67670217693, "readi": 5.15789473684, "flourish": 9.89775561097, "clark": 11.508517578839998, "henri": 2.63808574277, "that": 10.0398406375, "which": 12.06230214, "intellig": 16.77337559428, "encompass": 8.02628918099, "bias": 13.7335640138, "mid": 9.727941176469999, "other": 4.03969465648, "appli": 4.5944147012, "whether": 4.41367806506, "procedur": 5.8691312384500005, "one": 3.01882487166, "second": 1.1130898128, "known": 2.1718194254400003, "custom": 10.903846153859998, "begin": 1.3305397251100002, "algorithm": 167.7042253524, "becaus": 1.1495184997499999, "facebook": 28.5539568345, "hoff": 278.526315789, "like": 2.2983713355, "overhyp": 1323.0, "belmont": 71.1928251121, "imagin": 6.598503740650001, "technolog": 10.413906198760001, "preset": 196.0, "detect": 21.65155131264, "part": 1.04330682789, "invest": 8.32293577982, "backpropag": 5292.0, "element": 2.36004162331, "outlin": 6.38102893891, "includ": 1.0190641247799999, "precis": 5.322158900440001, "gpus": 1058.4, "receiv": 1.3054847463200001, "everi": 1.47917637194, "term": 2.79040337464, "autonom": 11.086592178800002, "frank": 3.4520547945199995, "conjectur": 34.6637554585, "principl": 3.4520547945199995, "rang": 1.7848229342299997, "time": 2.02254920696, "process": 15.25723438338, "back": 1.26070038911, "chang": 2.3617970842, "bit": 25.00157480316, "project": 7.013916501000001, "differ": 1.23654490225, "been": 2.0478555304799997, "somewhat": 4.29197080292, "interchang": 13.793223284100002, "most": 2.04192926046, "between": 3.1036100612399995, "heavili": 3.24132298898, "player": 3.54375, "drive": 2.93510815308, "credit": 6.08625646924, "fail": 3.8562059752199995, "need": 1.4372623574099999, "all": 1.01146788991, "busi": 2.05541170378, "today": 3.49922856514, "supervis": 15.48122866894, "recent": 1.54405757635, "almost": 3.07168424108, "exist": 1.4647107666799999, "structur": 2.0580762250499998, "day": 1.18371607516, "xray": 1323.0, "weight": 29.273509526759995, "built": 1.99447236181, "more": 4.0686827268, "improv": 2.04376930999, "correspond": 3.32481675393, "these": 3.22246278756, "fund": 7.69061844018, "inaccur": 24.201219512199998, "capabl": 3.6580645161300005, "amount": 2.27027027027, "artifici": 41.58198009430001, "made": 1.07038834951, "blueprint": 45.6206896552, "comment": 3.05954904606, "state": 1.0477133240899998, "friend": 2.20194174757, "dartmouth": 142.3856502242, "can": 3.52878417426, "avail": 3.4576935642, "describ": 2.94054454528, "fundament": 5.32930513595, "onli": 3.0769429549800007, "each": 3.56924460432, "andrew": 3.82462057336, "few": 3.95187520743, "this": 9.03414264039, "accur": 11.537790697680002, "rise": 4.0588009715, "link": 19.36359940374, "advanc": 3.9994961582, "imposs": 4.96125, "gartner": 738.418604652, "subscript": 62.258823529500006, "oper": 3.10958769954, "method": 2.5714285714300003, "pitt": 82.2590673576, "dean": 8.27737226277, "eckerson": 2646.0, "come": 1.32831325301, "perceptron": 1323.0, "aspect": 3.0893169877399997, "text": 12.51310344828, "send": 3.75053153792, "identifi": 6.90561113529, "first": 5.03808073115, "grew": 3.06545665186, "input": 97.6233666408, "michael": 2.23259738433, "page": 2.03669018602, "while": 1.0441988950299999, "innov": 4.74051955808, "year": 3.1456310679600006, "farley": 238.73684210599998, "without": 1.29547123623, "socal": 1134.0, "learn": 76.65076810545001, "same": 1.11857958148, "multilay": 648.0}, "logtfidf": {"after": 0.020490694648099998, "real": 2.473887181722, "googl": 7.29789366774, "web": 1.6431309733200001, "fall": 0.527402167952, "donald": 1.95967285241, "onc": 0.80753174471, "relat": 0.21310030165399999, "hebb": 7.18765716411, "data": 23.1195911112, "wide": 0.8891600135079999, "neuron": 12.48952643181, "organ": 0.49392052866999997, "would": 0.1592352559294, "number": 0.1932171568372, "incom": 1.3660916537999999, "recogn": 3.743655436124, "specif": 0.626980167541, "walter": 1.57270590317, "logic": 2.18931939783, "mcculloch": 10.50744641222, "well": 0.0635144383156, "unsupervis": 17.531767252229997, "done": 1.691951966258, "limitless": 5.03783482567, "assembl": 1.09899028905, "wesley": 3.36994483816, "higher": 0.752308398995, "umbrella": 3.14168618618, "their": 0.030721010245400002, "calculus": 4.1313002687400004, "chief": 0.883056027166, "creat": 0.222576818514, "room": 1.12387195543, "how": 0.47156695693000006, "billion": 3.1649360614399997, "million": 2.1876410003760003, "represent": 1.7797382876499999, "increas": 0.555641437858, "equat": 2.27930071914, "expert": 5.04088551189, "distribut": 1.00781305813, "found": 0.107841124048, "untrain": 4.81275140954, "unleash": 3.5456946297900003, "began": 0.5109064094619999, "summer": 0.797975937624, "deep": 33.5055102148, "will": 1.0139326745750001, "event": 0.857964216294, "consid": 0.429789447648, "those": 0.17854939087299998, "purpos": 0.803869037322, "nodes\u2013on": 7.18765716411, "next": 1.608654741996, "simpl": 1.2232212893899999, "perform": 0.85236170116, "but": 0.0323847441438, "gender": 6.732691859129999, "met": 0.8592740514339999, "off": 0.41352852038800003, "expect": 0.78850775216, "applic": 2.46320785698, "hidden": 4.1115760104, "ann": 19.51217347944, "fraud": 5.602945038580001, "has": 0.1281718345644, "have": 0.0887100140472, "besid": 1.63631387177, "enorm": 2.0214436382, "pass": 0.48130432974, "geoff": 3.6564066542, "experi": 0.626272953933, "govern": 0.411720459754, "onlin": 0.957503854357, "model": 1.4749001462220002, "unit": 0.286376123634, "alway": 0.726319204572, "slow": 1.39820680715, "concept": 0.977224437103, "mainstream": 2.0082171818, "much": 0.17749572930100002, "under": 0.15052361076639997, "decad": 0.760359972282, "cpus": 5.16170430739, "field": 0.5760642583510001, "global": 1.1957760371200001, "togeth": 0.458032237308, "short": 0.345685625679, "not": 0.06220965203, "growth": 1.1476008852200001, "are": 0.2357397886616, "minim": 1.80968177926, "less": 0.3846144626, "stori": 0.705059626587, "happen": 2.17280883604, "true": 0.938325629634, "said": 0.436653165815, "solv": 1.9836504770400003, "than": 0.0645217244364, "then": 0.33213546092359997, "separ": 0.470759772949, "graphic": 2.20120072572, "design": 0.377239118022, "anoth": 0.127896361652, "reach": 0.40414323085000003, "last": 0.19204364461100001, "world": 0.107420248621, "card": 1.8601856079099999, "aros": 2.0721614794, "node": 64.46452406750001, "featur": 0.423387418142, "practic": 0.533182530867, "respons": 0.8198313246060001, "alreadi": 0.670478380747, "influenc": 0.572373185428, "phone": 4.420697748259999, "itself": 0.5570837229510001, "provid": 0.19517784432500002, "until": 0.415423990317, "valu": 8.23193310148, "accord": 0.974601276508, "develop": 0.8931234745650001, "pattern": 2.66564809576, "accuraci": 2.5464765406, "senior": 1.38805958664, "thousand": 1.813898527976, "nervous": 2.86905855629, "network": 11.436996636623999, "confer": 2.0822989568, "three": 0.06411868822490001, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "collect": 0.49536666052, "add": 1.52875583713, "call": 0.3927766466928, "subset": 3.3078130570499997, "fellow": 1.4733744548199998, "cancel": 1.6545971104100001, "produc": 1.257283248012, "use": 0.43812029597400004, "biolog": 1.88809057817, "languag": 0.8306818244059999, "media": 0.9530830530519999, "ani": 0.125608358366, "two": 0.06849422179100001, "fed": 2.5289462112, "and": 0.0032124972452435997, "from": 0.0034023250131959997, "visibl": 3.0891375162599997, "behavior": 1.71014813378, "resurg": 6.12912637722, "num": 0.008819731071116001, "jeff": 2.27561521128, "multipli": 3.01583728972, "diagnosi": 3.3608290047500002, "idea": 0.73863592212, "william": 0.562375323877, "widrow": 7.18765716411, "acquir": 1.1332178178499999, "bloom": 3.2316172732700004, "for": 0.0037798847447640003, "color": 1.3417002006799998, "predict": 21.394623089969997, "output": 16.30581262616, "closer": 1.7167880323700002, "vehicl": 1.54604564512, "simplifi": 2.4940183301400003, "with": 0.00718495028034, "zero": 2.1692741832299998, "new": 0.0531898405533, "determin": 0.772833019022, "topic": 1.6969991554100001, "recommend": 1.36461126863, "better": 0.6964279406, "compani": 1.759109012388, "caption": 4.01657200308, "current": 0.42695282784500005, "team": 1.643805789772, "look": 0.6463866936, "option": 1.39846181161, "video": 1.19307248967, "predictor": 13.829906342640003, "ago": 1.80163421715, "work": 0.109034567273, "posit": 0.316652318608, "later": 0.0829654259878, "train": 10.574693005424, "compar": 1.2478383618539999, "strengthen": 1.83225083058, "group": 0.381189069594, "old": 0.424253510675, "littl": 0.438213989466, "could": 0.7438250891600001, "photo": 1.8593765463799998, "place": 0.1914141679144, "imman": 5.15077523685, "bodi": 0.6215709351609999, "error": 3.5971708686, "big": 2.01597127114, "type": 2.121304456161, "financ": 1.44813224068, "cisco": 4.89344032079, "argu": 0.984952970196, "rosenblatt": 6.305267983919999, "machin": 4.17707874186, "into": 0.0447385896861, "youtub": 3.00815479355, "paper": 0.979402539665, "marcian": 7.1076144564399995, "prior": 0.778442172521, "appl": 2.61725097056, "underw": 2.2817652921700002, "hire": 1.60103292035, "realiti": 1.51806363875, "via": 1.663967250828, "through": 0.1367173837698, "requir": 0.424253510675, "meant": 1.16501699954, "face": 1.179204742514, "what": 0.225887296827, "exponenti": 3.6686767468, "translat": 3.149790330089999, "loan": 2.11144222437, "cat": 4.70937523056, "nielsen": 3.50504732301, "forecast": 3.08639215905, "potenti": 0.9245764122419999, "brain": 4.37863879566, "tech": 2.9535506595200003, "base": 0.27304660457400004, "occur": 0.556973778473, "weather": 1.68537906567, "along": 0.260344385917, "twolay": 7.18765716411, "explod": 2.52029495787, "renew": 3.0604190741000004, "factor": 1.06169814662, "microsoft": 3.21265935953, "were": 0.024291143681099997, "comput": 8.208413495639999, "human": 1.920105549729, "layer": 16.775833298800002, "greater": 0.764545491118, "contain": 1.406535954708, "noisi": 4.1313002687400004, "belong": 1.2527629685, "problem": 0.569140724273, "voic": 2.3336722012, "neural": 40.853151555, "thing": 0.8781935346799999, "serv": 0.383135035608, "just": 0.579062868218, "test": 3.908897748412, "adapt": 2.4015729720400003, "understand": 1.0880858756799998, "interconnect": 3.41107212958, "internet": 1.6063562459, "birthplac": 2.89491722027, "dure": 0.0491209066894, "random": 1.9727214065099998, "defin": 1.00368010925, "led": 0.8731412887139999, "activ": 0.381196603284, "where": 0.0649921387457, "live": 0.266903399347, "echo": 2.35137525716, "tool": 1.60887117963, "start": 0.472886738582, "took": 0.337177952953, "ran": 1.25034086008, "enabl": 1.26473915954, "they": 0.1189079790704, "risk": 1.4100048408899999, "whi": 3.54206529141, "bankruptci": 2.9320444543, "studi": 0.426470272221, "giant": 1.83028503479, "singl": 0.475916769059, "autom": 2.9867028668299995, "central": 0.477540146039, "play": 0.38110439064199997, "mani": 0.0433157581221, "diseas": 1.6509792804499999, "over": 0.0748101644871, "afford": 1.95833266905, "netflix": 5.0978528354, "analysi": 2.4932182058400003, "display": 1.07655944206, "linear": 2.63027764196, "hinton": 5.02817291476, "consist": 0.797746252852, "traffic": 1.7834794068700002, "ensu": 2.13194228525, "synaps": 5.35507570037, "there": 0.12029367877649999, "explos": 1.90529981715, "connect": 1.9008151760460001, "inform": 0.454453704662, "bank": 1.0557062993700002, "baidu": 14.067012968579998, "say": 0.562154280552, "best": 0.918455865894, "exampl": 0.8173653499979999, "continu": 0.13040487398700001, "unknown": 1.32782105949, "secret": 1.13556799519, "illustr": 1.2978562707799999, "loos": 1.9552125417200001, "take": 0.130691962197, "follow": 0.09071382218839999, "now": 0.44727883506300004, "bernard": 2.14476982618, "predictor\u2013connect": 7.18765716411, "per": 1.345642048144, "high": 0.13782378654000002, "winter": 1.17598157639, "driven": 1.72311939365, "abl": 0.599303982475, "publish": 0.9419275964010001, "power": 0.58479256543, "audienc": 1.4992703749399998, "also": 0.0146571578, "person": 0.34018281601800004, "around": 0.19387710578200001, "such": 0.059695977806, "treatment": 1.3535776885100002, "role": 0.8807282151479999, "research": 3.982366908828, "imag": 4.96881053645, "accomplish": 1.64345675928, "repeat": 1.0567930591299999, "the": 0.0, "may": 0.050709995284400004, "becom": 0.11771217648900001, "age": 1.9812422650150001, "tag": 2.98296454472, "scientist": 7.7317064222, "hype": 4.38936008516, "open": 0.219591038029, "select": 0.704804687133, "six": 0.441636808318, "hospit": 1.24223655551, "want": 0.6916366062549999, "simul": 9.76221392896, "act": 0.358945092473, "howev": 0.0903151173475, "prove": 0.899024430345, "elimin": 1.30201620283, "readi": 1.6405284994999998, "flourish": 2.2923080254799997, "clark": 3.4998804793800002, "henri": 0.970053556713, "that": 0.039761483796399995, "which": 0.06214096614516, "intellig": 5.73399392852, "encompass": 2.08272230172, "bias": 2.61984276467, "mid": 2.27500227838, "other": 0.03949899167904, "appli": 1.6633883796239999, "whether": 1.583122379294, "procedur": 1.76970662262, "one": 0.0187660549365, "second": 0.10713976337999999, "known": 0.1648361611984, "custom": 3.8715098894399995, "begin": 0.285584668268, "algorithm": 19.98265437108, "becaus": 0.139343158825, "facebook": 3.3517955196499996, "hoff": 5.62951254607, "like": 0.27810715309, "overhyp": 7.18765716411, "belmont": 4.26539204244, "imagin": 1.88684291737, "technolog": 3.82739074542, "preset": 5.278114659230001, "detect": 6.75513097972, "part": 0.04239531098280001, "invest": 2.85173574036, "backpropag": 28.75062865644, "element": 0.8586792558769999, "outlin": 1.85332936004, "includ": 0.0188846813905, "precis": 1.67187902939, "gpus": 6.964513612799999, "receiv": 0.266574424922, "everi": 0.391485427421, "term": 0.6660779670920001, "autonom": 2.4057364663799996, "frank": 1.2389696463600002, "conjectur": 3.5456946297900003, "principl": 1.2389696463600002, "rang": 0.579319213803, "time": 0.0224230377252, "process": 4.750462791225, "back": 0.23166743089699998, "chang": 0.332551250116, "bit": 6.36097957902, "project": 2.246407543628, "differ": 0.212321121312, "been": 0.04729196473680001, "somewhat": 1.4567460220700001, "interchang": 2.62417740518, "most": 0.041495792591199995, "between": 0.10186104349589999, "heavili": 1.17598157639, "player": 1.26518548849, "drive": 1.07674430203, "credit": 2.22577202176, "fail": 1.313073223146, "need": 0.362740163442, "all": 0.011402632097799998, "busi": 0.720476170355, "today": 1.118790707358, "supervis": 4.09296211166, "recent": 0.434413741288, "almost": 0.8581576866680001, "exist": 0.38165779408699996, "structur": 0.7217716751350001, "day": 0.16865870631700003, "xray": 7.18765716411, "weight": 9.509541156720001, "built": 0.690379535065, "more": 0.06809972639999999, "improv": 0.7147958039319999, "correspond": 1.20141456099, "these": 0.2146008582024, "fund": 2.824166738895, "inaccur": 3.1864030249599997, "capabl": 1.2969341868100002, "amount": 0.819898886199, "artifici": 10.5911449509, "made": 0.0680215260973, "blueprint": 3.8203613341300007, "comment": 1.11826753454, "state": 0.0466100027668, "friend": 0.7893395836239999, "dartmouth": 8.53078408488, "can": 0.487023289182, "avail": 1.094909172578, "describ": 0.77089520625, "fundament": 1.67322086119, "onli": 0.0759728049873, "each": 0.521225067912, "andrew": 1.34145926585, "few": 0.826733740959, "this": 0.0340780414725, "accur": 3.5049612297, "rise": 1.415480844436, "link": 6.895533661605, "advanc": 1.3860424243560001, "imposs": 1.60165772512, "gartner": 11.82272739642, "subscript": 9.09806394024, "oper": 0.882685928694, "method": 0.944461608841, "pitt": 7.43345288888, "dean": 2.1135255584599997, "eckerson": 14.37531432822, "come": 0.28390990653000003, "perceptron": 7.18765716411, "aspect": 1.12795002691, "text": 4.56192803996, "send": 1.32189757338, "identifi": 2.5011660014159998, "first": 0.0379364490608, "grew": 1.12019654748, "input": 20.01340268312, "michael": 0.803165654019, "page": 0.711326032411, "while": 0.04324998379380001, "innov": 1.55614674111, "year": 0.14220671668380003, "farley": 9.564429371360001, "without": 0.258874517941, "socal": 7.033506484289999, "learn": 27.810818136585, "same": 0.112059649604, "multilay": 11.56148703158}, "logidf": {"after": 0.020490694648099998, "real": 0.824629060574, "googl": 2.43263122258, "web": 1.6431309733200001, "fall": 0.527402167952, "donald": 1.95967285241, "onc": 0.403765872355, "relat": 0.21310030165399999, "hebb": 7.18765716411, "data": 1.2168205848, "wide": 0.44458000675399995, "neuron": 4.16317547727, "organ": 0.49392052866999997, "would": 0.0796176279647, "number": 0.0966085784186, "incom": 1.3660916537999999, "recogn": 0.935913859031, "specif": 0.626980167541, "walter": 1.57270590317, "logic": 2.18931939783, "mcculloch": 5.25372320611, "well": 0.0635144383156, "unsupervis": 5.843922417409999, "done": 0.845975983129, "limitless": 5.03783482567, "assembl": 1.09899028905, "wesley": 3.36994483816, "higher": 0.752308398995, "umbrella": 3.14168618618, "their": 0.015360505122700001, "calculus": 4.1313002687400004, "chief": 0.883056027166, "creat": 0.222576818514, "room": 1.12387195543, "how": 0.47156695693000006, "billion": 1.5824680307199999, "million": 0.5469102500940001, "represent": 1.7797382876499999, "increas": 0.277820718929, "equat": 2.27930071914, "expert": 1.68029517063, "distribut": 1.00781305813, "found": 0.107841124048, "untrain": 4.81275140954, "unleash": 3.5456946297900003, "began": 0.25545320473099997, "summer": 0.797975937624, "deep": 1.2886734698, "will": 0.202786534915, "event": 0.428982108147, "consid": 0.214894723824, "those": 0.17854939087299998, "purpos": 0.803869037322, "nodes\u2013on": 7.18765716411, "next": 0.402163685499, "simpl": 1.2232212893899999, "perform": 0.42618085058, "but": 0.0161923720719, "gender": 2.2442306197099997, "met": 0.8592740514339999, "off": 0.41352852038800003, "expect": 0.78850775216, "applic": 1.23160392849, "hidden": 2.0557880052, "ann": 1.62601445662, "fraud": 2.8014725192900003, "has": 0.0427239448548, "have": 0.0147850023412, "besid": 1.63631387177, "enorm": 2.0214436382, "pass": 0.48130432974, "geoff": 3.6564066542, "experi": 0.626272953933, "govern": 0.411720459754, "onlin": 0.957503854357, "model": 0.7374500731110001, "unit": 0.143188061817, "alway": 0.726319204572, "slow": 1.39820680715, "concept": 0.977224437103, "mainstream": 2.0082171818, "much": 0.17749572930100002, "under": 0.07526180538319999, "decad": 0.760359972282, "cpus": 5.16170430739, "field": 0.5760642583510001, "global": 1.1957760371200001, "togeth": 0.458032237308, "short": 0.345685625679, "not": 0.0155524130075, "growth": 1.1476008852200001, "are": 0.0294674735827, "minim": 1.80968177926, "less": 0.3846144626, "stori": 0.705059626587, "happen": 1.08640441802, "true": 0.938325629634, "said": 0.436653165815, "solv": 1.9836504770400003, "than": 0.0322608622182, "then": 0.08303386523089999, "separ": 0.470759772949, "graphic": 2.20120072572, "design": 0.377239118022, "anoth": 0.127896361652, "reach": 0.40414323085000003, "last": 0.19204364461100001, "world": 0.107420248621, "card": 1.8601856079099999, "aros": 2.0721614794, "node": 3.7920308275, "featur": 0.423387418142, "practic": 0.533182530867, "respons": 0.40991566230300003, "alreadi": 0.670478380747, "influenc": 0.572373185428, "phone": 2.2103488741299997, "itself": 0.5570837229510001, "provid": 0.19517784432500002, "until": 0.138474663439, "valu": 0.823193310148, "accord": 0.243650319127, "develop": 0.178624694913, "pattern": 1.33282404788, "accuraci": 2.5464765406, "senior": 1.38805958664, "thousand": 0.906949263988, "nervous": 2.86905855629, "network": 0.9530830530519999, "confer": 1.0411494784, "three": 0.06411868822490001, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "collect": 0.49536666052, "add": 1.52875583713, "call": 0.0654627744488, "subset": 3.3078130570499997, "fellow": 1.4733744548199998, "cancel": 1.6545971104100001, "produc": 0.314320812003, "use": 0.0292080197316, "biolog": 1.88809057817, "languag": 0.8306818244059999, "media": 0.9530830530519999, "ani": 0.125608358366, "two": 0.0136988443582, "fed": 2.5289462112, "and": 6.29901420636e-05, "from": 0.000567054168866, "visibl": 1.5445687581299998, "behavior": 1.71014813378, "resurg": 3.06456318861, "num": 0.00031499039539700004, "jeff": 2.27561521128, "multipli": 3.01583728972, "diagnosi": 3.3608290047500002, "idea": 0.73863592212, "william": 0.562375323877, "widrow": 7.18765716411, "acquir": 1.1332178178499999, "bloom": 3.2316172732700004, "for": 0.00031499039539700004, "color": 1.3417002006799998, "predict": 1.6457402376899999, "output": 2.03822657827, "closer": 1.7167880323700002, "vehicl": 1.54604564512, "simplifi": 2.4940183301400003, "with": 0.00119749171339, "zero": 2.1692741832299998, "new": 0.0177299468511, "determin": 0.772833019022, "topic": 1.6969991554100001, "recommend": 1.36461126863, "better": 0.6964279406, "compani": 0.439777253097, "caption": 4.01657200308, "current": 0.42695282784500005, "team": 0.821902894886, "look": 0.6463866936, "option": 1.39846181161, "video": 1.19307248967, "predictor": 4.609968780880001, "ago": 1.80163421715, "work": 0.109034567273, "posit": 0.316652318608, "later": 0.0829654259878, "train": 0.660918312839, "compar": 0.6239191809269999, "strengthen": 1.83225083058, "group": 0.190594534797, "old": 0.424253510675, "littl": 0.438213989466, "could": 0.18595627229000003, "photo": 1.8593765463799998, "place": 0.0957070839572, "imman": 5.15077523685, "bodi": 0.6215709351609999, "error": 1.7985854343, "big": 1.00798563557, "type": 0.707101485387, "financ": 1.44813224068, "cisco": 4.89344032079, "argu": 0.984952970196, "rosenblatt": 6.305267983919999, "machin": 1.39235958062, "into": 0.0149128632287, "youtub": 3.00815479355, "paper": 0.979402539665, "marcian": 7.1076144564399995, "prior": 0.778442172521, "appl": 2.61725097056, "underw": 2.2817652921700002, "hire": 1.60103292035, "realiti": 1.51806363875, "via": 0.831983625414, "through": 0.0683586918849, "requir": 0.424253510675, "meant": 1.16501699954, "face": 0.589602371257, "what": 0.225887296827, "exponenti": 3.6686767468, "translat": 1.0499301100299998, "loan": 2.11144222437, "cat": 2.35468761528, "nielsen": 3.50504732301, "forecast": 3.08639215905, "potenti": 0.9245764122419999, "brain": 2.18931939783, "tech": 2.9535506595200003, "base": 0.13652330228700002, "occur": 0.556973778473, "weather": 1.68537906567, "along": 0.260344385917, "twolay": 7.18765716411, "explod": 2.52029495787, "renew": 1.5302095370500002, "factor": 1.06169814662, "microsoft": 3.21265935953, "were": 0.024291143681099997, "comput": 1.36806891594, "human": 0.640035183243, "layer": 2.0969791623500003, "greater": 0.764545491118, "contain": 0.468845318236, "noisi": 4.1313002687400004, "belong": 1.2527629685, "problem": 0.569140724273, "voic": 1.1668361006, "neural": 4.0853151555, "thing": 0.8781935346799999, "serv": 0.383135035608, "just": 0.289531434109, "test": 0.977224437103, "adapt": 1.2007864860200002, "understand": 1.0880858756799998, "interconnect": 3.41107212958, "internet": 1.6063562459, "birthplac": 2.89491722027, "dure": 0.0491209066894, "random": 1.9727214065099998, "defin": 1.00368010925, "led": 0.29104709623799996, "activ": 0.381196603284, "where": 0.0649921387457, "live": 0.266903399347, "echo": 2.35137525716, "tool": 1.60887117963, "start": 0.236443369291, "took": 0.337177952953, "ran": 1.25034086008, "enabl": 1.26473915954, "they": 0.0297269947676, "risk": 1.4100048408899999, "whi": 1.18068843047, "bankruptci": 2.9320444543, "studi": 0.426470272221, "giant": 1.83028503479, "singl": 0.475916769059, "autom": 2.9867028668299995, "central": 0.477540146039, "play": 0.38110439064199997, "mani": 0.0433157581221, "diseas": 1.6509792804499999, "over": 0.0249367214957, "afford": 1.95833266905, "netflix": 5.0978528354, "analysi": 1.2466091029200002, "display": 1.07655944206, "linear": 2.63027764196, "hinton": 5.02817291476, "consist": 0.398873126426, "traffic": 1.7834794068700002, "ensu": 2.13194228525, "synaps": 5.35507570037, "there": 0.0400978929255, "explos": 1.90529981715, "connect": 0.633605058682, "inform": 0.454453704662, "bank": 1.0557062993700002, "baidu": 7.033506484289999, "say": 0.562154280552, "best": 0.459227932947, "exampl": 0.40868267499899996, "continu": 0.13040487398700001, "unknown": 1.32782105949, "secret": 1.13556799519, "illustr": 1.2978562707799999, "loos": 1.9552125417200001, "take": 0.130691962197, "follow": 0.045356911094199995, "now": 0.149092945021, "bernard": 2.14476982618, "predictor\u2013connect": 7.18765716411, "per": 0.672821024072, "high": 0.13782378654000002, "winter": 1.17598157639, "driven": 1.72311939365, "abl": 0.599303982475, "publish": 0.313975865467, "power": 0.292396282715, "audienc": 1.4992703749399998, "also": 0.0146571578, "person": 0.34018281601800004, "around": 0.19387710578200001, "such": 0.059695977806, "treatment": 1.3535776885100002, "role": 0.44036410757399996, "research": 0.663727818138, "imag": 0.99376210729, "accomplish": 1.64345675928, "repeat": 1.0567930591299999, "the": 0.0, "may": 0.050709995284400004, "becom": 0.11771217648900001, "age": 0.39624845300300005, "tag": 2.98296454472, "scientist": 1.54634128444, "hype": 4.38936008516, "open": 0.219591038029, "select": 0.704804687133, "six": 0.441636808318, "hospit": 1.24223655551, "want": 0.6916366062549999, "simul": 2.44055348224, "act": 0.358945092473, "howev": 0.0903151173475, "prove": 0.899024430345, "elimin": 1.30201620283, "readi": 1.6405284994999998, "flourish": 2.2923080254799997, "clark": 1.7499402396900001, "henri": 0.970053556713, "that": 0.00397614837964, "which": 0.00517841384543, "intellig": 1.43349848213, "encompass": 2.08272230172, "bias": 2.61984276467, "mid": 2.27500227838, "other": 0.00987474791976, "appli": 0.8316941898119999, "whether": 0.791561189647, "procedur": 1.76970662262, "one": 0.0062553516455, "second": 0.10713976337999999, "known": 0.0824180805992, "custom": 1.2905032964799998, "begin": 0.285584668268, "algorithm": 3.33044239518, "becaus": 0.139343158825, "facebook": 3.3517955196499996, "hoff": 5.62951254607, "like": 0.139053576545, "overhyp": 7.18765716411, "belmont": 4.26539204244, "imagin": 1.88684291737, "technolog": 0.956847686355, "preset": 5.278114659230001, "detect": 1.68878274493, "part": 0.04239531098280001, "invest": 1.42586787018, "backpropag": 7.18765716411, "element": 0.8586792558769999, "outlin": 1.85332936004, "includ": 0.0188846813905, "precis": 1.67187902939, "gpus": 6.964513612799999, "receiv": 0.266574424922, "everi": 0.391485427421, "term": 0.33303898354600003, "autonom": 2.4057364663799996, "frank": 1.2389696463600002, "conjectur": 3.5456946297900003, "principl": 1.2389696463600002, "rang": 0.579319213803, "time": 0.0112115188626, "process": 0.527829199025, "back": 0.23166743089699998, "chang": 0.166275625058, "bit": 2.12032652634, "project": 0.561601885907, "differ": 0.212321121312, "been": 0.023645982368400004, "somewhat": 1.4567460220700001, "interchang": 2.62417740518, "most": 0.020747896295599998, "between": 0.033953681165299995, "heavili": 1.17598157639, "player": 1.26518548849, "drive": 1.07674430203, "credit": 1.11288601088, "fail": 0.656536611573, "need": 0.362740163442, "all": 0.011402632097799998, "busi": 0.720476170355, "today": 0.559395353679, "supervis": 2.04648105583, "recent": 0.434413741288, "almost": 0.42907884333400004, "exist": 0.38165779408699996, "structur": 0.7217716751350001, "day": 0.16865870631700003, "xray": 7.18765716411, "weight": 1.58492352612, "built": 0.690379535065, "more": 0.017024931599999998, "improv": 0.7147958039319999, "correspond": 1.20141456099, "these": 0.0715336194008, "fund": 0.9413889129649999, "inaccur": 3.1864030249599997, "capabl": 1.2969341868100002, "amount": 0.819898886199, "artifici": 2.11822899018, "made": 0.0680215260973, "blueprint": 3.8203613341300007, "comment": 1.11826753454, "state": 0.0466100027668, "friend": 0.7893395836239999, "dartmouth": 4.26539204244, "can": 0.162341096394, "avail": 0.547454586289, "describ": 0.385447603125, "fundament": 1.67322086119, "onli": 0.025324268329099998, "each": 0.173741689304, "andrew": 1.34145926585, "few": 0.275577913653, "this": 0.0037864490525, "accur": 1.75248061485, "rise": 0.707740422218, "link": 0.7661704068449999, "advanc": 0.6930212121780001, "imposs": 1.60165772512, "gartner": 5.91136369821, "subscript": 3.03268798008, "oper": 0.441342964347, "method": 0.944461608841, "pitt": 3.71672644444, "dean": 2.1135255584599997, "eckerson": 7.18765716411, "come": 0.28390990653000003, "perceptron": 7.18765716411, "aspect": 1.12795002691, "text": 1.14048200999, "send": 1.32189757338, "identifi": 0.833722000472, "first": 0.0075872898121599995, "grew": 1.12019654748, "input": 2.50167533539, "michael": 0.803165654019, "page": 0.711326032411, "while": 0.04324998379380001, "innov": 1.55614674111, "year": 0.047402238894600005, "farley": 4.7822146856800005, "without": 0.258874517941, "socal": 7.033506484289999, "learn": 0.842752064745, "same": 0.112059649604, "multilay": 5.78074351579}, "freq": {"after": 1, "real": 3, "googl": 3, "web": 1, "fall": 1, "donald": 1, "onc": 2, "relat": 1, "hebb": 1, "data": 19, "wide": 2, "neuron": 3, "organ": 1, "would": 2, "number": 2, "incom": 1, "recogn": 4, "specif": 1, "walter": 1, "logic": 1, "mcculloch": 2, "well": 1, "unsupervis": 3, "done": 2, "limitless": 1, "assembl": 1, "wesley": 1, "higher": 1, "umbrella": 1, "their": 2, "calculus": 1, "chief": 1, "creat": 1, "room": 1, "how": 1, "billion": 2, "million": 4, "represent": 1, "increas": 2, "equat": 1, "expert": 3, "distribut": 1, "found": 1, "untrain": 1, "unleash": 1, "began": 2, "summer": 1, "deep": 26, "will": 5, "event": 2, "consid": 2, "those": 1, "purpos": 1, "nodes\u2013on": 1, "next": 4, "simpl": 1, "perform": 2, "but": 2, "gender": 3, "met": 1, "off": 1, "expect": 1, "applic": 2, "hidden": 2, "ann": 12, "fraud": 2, "has": 3, "have": 6, "besid": 1, "enorm": 1, "pass": 1, "geoff": 1, "experi": 1, "govern": 1, "onlin": 1, "model": 2, "unit": 2, "alway": 1, "slow": 1, "concept": 1, "mainstream": 1, "much": 1, "under": 2, "decad": 1, "cpus": 1, "field": 1, "global": 1, "togeth": 1, "short": 1, "not": 4, "growth": 1, "are": 8, "minim": 1, "less": 1, "stori": 1, "happen": 2, "true": 1, "said": 1, "solv": 1, "than": 2, "then": 4, "separ": 1, "graphic": 1, "design": 1, "anoth": 1, "reach": 1, "last": 1, "world": 1, "card": 1, "aros": 1, "node": 17, "featur": 1, "practic": 1, "respons": 2, "alreadi": 1, "influenc": 1, "phone": 2, "itself": 1, "provid": 1, "until": 3, "valu": 10, "accord": 4, "develop": 5, "pattern": 2, "accuraci": 1, "senior": 1, "thousand": 2, "nervous": 1, "network": 12, "confer": 2, "three": 1, "lot": 1, "some": 1, "sourc": 1, "collect": 1, "add": 1, "call": 6, "subset": 1, "fellow": 1, "cancel": 1, "produc": 4, "use": 15, "biolog": 1, "languag": 1, "media": 1, "ani": 1, "two": 5, "fed": 1, "and": 51, "from": 6, "visibl": 2, "behavior": 1, "resurg": 2, "num": 28, "jeff": 1, "multipli": 1, "diagnosi": 1, "idea": 1, "william": 1, "widrow": 1, "acquir": 1, "bloom": 1, "for": 12, "color": 1, "predict": 13, "output": 8, "closer": 1, "vehicl": 1, "simplifi": 1, "with": 6, "zero": 1, "new": 3, "determin": 1, "topic": 1, "recommend": 1, "better": 1, "compani": 4, "caption": 1, "current": 1, "team": 2, "look": 1, "option": 1, "video": 1, "predictor": 3, "ago": 1, "work": 1, "posit": 1, "later": 1, "train": 16, "compar": 2, "strengthen": 1, "group": 2, "old": 1, "littl": 1, "could": 4, "photo": 1, "place": 2, "imman": 1, "bodi": 1, "error": 2, "big": 2, "type": 3, "financ": 1, "cisco": 1, "argu": 1, "rosenblatt": 1, "machin": 3, "into": 3, "youtub": 1, "paper": 1, "marcian": 1, "prior": 1, "appl": 1, "underw": 1, "hire": 1, "realiti": 1, "via": 2, "through": 2, "requir": 1, "meant": 1, "face": 2, "what": 1, "exponenti": 1, "translat": 3, "loan": 1, "cat": 2, "nielsen": 1, "forecast": 1, "potenti": 1, "brain": 2, "tech": 1, "base": 2, "occur": 1, "weather": 1, "along": 1, "twolay": 1, "explod": 1, "renew": 2, "factor": 1, "microsoft": 1, "were": 1, "comput": 6, "human": 3, "layer": 8, "greater": 1, "contain": 3, "noisi": 1, "belong": 1, "problem": 1, "voic": 2, "neural": 10, "thing": 1, "serv": 1, "just": 2, "test": 4, "adapt": 2, "understand": 1, "interconnect": 1, "internet": 1, "birthplac": 1, "dure": 1, "random": 1, "defin": 1, "led": 3, "activ": 1, "where": 1, "live": 1, "echo": 1, "tool": 1, "start": 2, "took": 1, "ran": 1, "enabl": 1, "they": 4, "risk": 1, "whi": 3, "bankruptci": 1, "studi": 1, "giant": 1, "singl": 1, "autom": 1, "central": 1, "play": 1, "mani": 1, "diseas": 1, "over": 3, "afford": 1, "netflix": 1, "analysi": 2, "display": 1, "linear": 1, "hinton": 1, "consist": 2, "traffic": 1, "ensu": 1, "synaps": 1, "there": 3, "explos": 1, "connect": 3, "inform": 1, "bank": 1, "baidu": 2, "say": 1, "best": 2, "exampl": 2, "continu": 1, "unknown": 1, "secret": 1, "illustr": 1, "loos": 1, "take": 1, "follow": 2, "now": 3, "bernard": 1, "predictor\u2013connect": 1, "per": 2, "high": 1, "winter": 1, "driven": 1, "abl": 1, "publish": 3, "power": 2, "audienc": 1, "also": 1, "person": 1, "around": 1, "such": 1, "treatment": 1, "role": 2, "research": 6, "imag": 5, "accomplish": 1, "repeat": 1, "the": 94, "may": 1, "becom": 1, "age": 5, "tag": 1, "scientist": 5, "hype": 1, "open": 1, "select": 1, "six": 1, "hospit": 1, "want": 1, "simul": 4, "act": 1, "howev": 1, "prove": 1, "elimin": 1, "readi": 1, "flourish": 1, "clark": 2, "henri": 1, "that": 10, "which": 12, "intellig": 4, "encompass": 1, "bias": 1, "mid": 1, "other": 4, "appli": 2, "whether": 2, "procedur": 1, "one": 3, "second": 1, "known": 2, "custom": 3, "begin": 1, "algorithm": 6, "becaus": 1, "facebook": 1, "hoff": 1, "like": 2, "overhyp": 1, "belmont": 1, "imagin": 1, "technolog": 4, "preset": 1, "detect": 4, "part": 1, "invest": 2, "backpropag": 4, "element": 1, "outlin": 1, "includ": 1, "precis": 1, "gpus": 1, "receiv": 1, "everi": 1, "term": 2, "autonom": 1, "frank": 1, "conjectur": 1, "principl": 1, "rang": 1, "time": 2, "process": 9, "back": 1, "chang": 2, "bit": 3, "project": 4, "differ": 1, "been": 2, "somewhat": 1, "interchang": 1, "most": 2, "between": 3, "heavili": 1, "player": 1, "drive": 1, "credit": 2, "fail": 2, "need": 1, "all": 1, "busi": 1, "today": 2, "supervis": 2, "recent": 1, "almost": 2, "exist": 1, "structur": 1, "day": 1, "xray": 1, "weight": 6, "built": 1, "more": 4, "improv": 1, "correspond": 1, "these": 3, "fund": 3, "inaccur": 1, "capabl": 1, "amount": 1, "artifici": 5, "made": 1, "blueprint": 1, "comment": 1, "state": 1, "friend": 1, "dartmouth": 2, "can": 3, "avail": 2, "describ": 2, "fundament": 1, "onli": 3, "each": 3, "andrew": 1, "few": 3, "this": 9, "accur": 2, "rise": 2, "link": 9, "advanc": 2, "imposs": 1, "gartner": 2, "subscript": 3, "oper": 2, "method": 1, "pitt": 2, "dean": 1, "eckerson": 2, "come": 1, "perceptron": 1, "aspect": 1, "text": 4, "send": 1, "identifi": 3, "first": 5, "grew": 1, "input": 8, "michael": 1, "page": 1, "while": 1, "innov": 1, "year": 3, "farley": 2, "without": 1, "socal": 1, "learn": 33, "same": 1, "multilay": 2}, "idf": {"after": 1.02070207021, "real": 2.28103448276, "googl": 11.388809182200001, "web": 5.17133550489, "fall": 1.6945244956799999, "donald": 7.0970049173000005, "onc": 1.4974533106999999, "relat": 1.23750876919, "hebb": 1323.0, "data": 3.37643555934, "wide": 1.5598349381, "neuron": 64.2753036437, "organ": 1.6387283237, "would": 1.0828729281799998, "number": 1.10142916609, "incom": 3.92, "recogn": 2.54954231572, "specif": 1.8719490626099997, "walter": 4.81967213115, "logic": 8.929133858270001, "mcculloch": 191.277108434, "well": 1.0655748708, "unsupervis": 345.13043478300006, "done": 2.3302509907499998, "limitless": 154.13592233, "assembl": 3.0011342155, "wesley": 29.0769230769, "higher": 2.1218925421, "umbrella": 23.1428571429, "their": 1.01547908405, "calculus": 62.2588235294, "chief": 2.41827875095, "creat": 1.2492917847, "room": 3.07674418605, "how": 1.60250328051, "billion": 4.8669527897, "million": 1.7279059643, "represent": 5.928304705, "increas": 1.32024948025, "equat": 9.76984615385, "expert": 5.36713995943, "distribut": 2.7396031061299997, "found": 1.11387076405, "untrain": 123.06976744200001, "unleash": 34.6637554585, "began": 1.29104659673, "summer": 2.22104085059, "deep": 3.6279707495399998, "will": 1.22481098596, "event": 1.5356935577500002, "consid": 1.2397313759200002, "those": 1.19548192771, "purpos": 2.23416830847, "nodes\u2013on": 1323.0, "next": 1.4950560316400001, "simpl": 3.3981164383599998, "perform": 1.5313977042500002, "but": 1.01632417899, "gender": 9.43315508021, "met": 2.3614457831299998, "off": 1.5121440137200002, "expect": 2.20011086475, "applic": 3.42672134686, "hidden": 7.81299212598, "ann": 5.08357348703, "fraud": 16.468879668, "has": 1.0436497502, "have": 1.0148948411399998, "besid": 5.1362018764199995, "enorm": 7.54921540656, "pass": 1.61818367139, "geoff": 38.7219512195, "experi": 1.87062566278, "govern": 1.50941243582, "onlin": 2.6051854282900004, "model": 2.0905978404, "unit": 1.15394679459, "alway": 2.06745670009, "slow": 4.04793472718, "concept": 2.65707112971, "mainstream": 7.450023463160001, "much": 1.1942229577299999, "under": 1.0781663837, "decad": 2.1390460792200003, "cpus": 174.46153846200002, "field": 1.7790228597, "global": 3.30612244898, "togeth": 1.58095996813, "short": 1.41295834817, "not": 1.01567398119, "growth": 3.15062512403, "are": 1.02990593578, "minim": 6.10850327049, "less": 1.46904783936, "stori": 2.02396736359, "happen": 2.96359902931, "true": 2.55569864778, "said": 1.54751925139, "solv": 7.26923076923, "than": 1.03278688525, "then": 1.08657860516, "separ": 1.6012102874399998, "graphic": 9.035856573710001, "design": 1.45825296225, "anoth": 1.13643521832, "reach": 1.49801849406, "last": 1.2117234010100002, "world": 1.11340206186, "card": 6.42492917847, "aros": 7.941970985489999, "node": 44.3463687151, "featur": 1.52712581762, "practic": 1.70434782609, "respons": 1.5066907089300001, "alreadi": 1.9551724137900002, "influenc": 1.77246846042, "phone": 9.118897185529999, "itself": 1.74557449148, "provid": 1.21552714187, "until": 1.14852058164, "valu": 2.2777618364400003, "accord": 1.27589809531, "develop": 1.1955719557200002, "pattern": 3.79173632673, "accuraci": 12.7620578778, "senior": 4.00706713781, "thousand": 2.4767550702000003, "nervous": 17.6204217536, "network": 2.59369384088, "confer": 2.8324710080299997, "three": 1.06621893889, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "collect": 1.64109985528, "add": 4.61243463103, "call": 1.0676529926, "subset": 27.3253012048, "fellow": 4.3639362287, "cancel": 5.23097199341, "produc": 1.36932896326, "use": 1.0296387573799999, "biolog": 6.60674157303, "languag": 2.29488291414, "media": 2.59369384088, "ani": 1.13383802314, "two": 1.01379310345, "fed": 12.5402843602, "and": 1.00006299213, "from": 1.00056721497, "visibl": 4.68595041322, "behavior": 5.52978056426, "resurg": 21.4251012146, "num": 1.00031504001, "jeff": 9.7339055794, "multipli": 20.4061696658, "diagnosi": 28.8130671506, "idea": 2.0930784443, "william": 1.75483585719, "widrow": 1323.0, "acquir": 3.10563380282, "bloom": 25.320574162699998, "for": 1.00031504001, "color": 3.8255421686699997, "predict": 5.18484650555, "output": 7.676982591880001, "closer": 5.5666199158500005, "vehicl": 4.6928761454300005, "simplifi": 12.109839816900001, "with": 1.0011982089899998, "zero": 8.75192943771, "new": 1.0178880554, "determin": 2.1658935879900003, "topic": 5.457545548300001, "recommend": 3.9142011834300003, "better": 2.0065722952500002, "compani": 1.5523613963, "caption": 55.5104895105, "current": 1.5325803649, "team": 2.2748244734200003, "look": 1.9086318826599997, "option": 4.04896710023, "video": 3.29719626168, "predictor": 100.481012658, "ago": 6.05954198473, "work": 1.11520089913, "posit": 1.37252528746, "later": 1.08650424309, "train": 1.9365698950999999, "compar": 1.8662278123900002, "strengthen": 6.247933884299999, "group": 1.20996875238, "old": 1.52844902282, "littl": 1.5499365420299998, "could": 1.2043695949, "photo": 6.41973311767, "place": 1.1004366812200002, "imman": 172.56521739099998, "bodi": 1.8618505922400002, "error": 6.04109589041, "big": 2.7400759406299997, "type": 2.0281042411900003, "financ": 4.255159474669999, "cisco": 133.411764706, "argu": 2.67768595041, "rosenblatt": 547.448275862, "machin": 4.02433460076, "into": 1.01502461479, "youtub": 20.25, "paper": 2.6628648104700003, "marcian": 1221.23076923, "prior": 2.17807655371, "appl": 13.6980155306, "underw": 9.793954349169999, "hire": 4.95815115553, "realiti": 4.563380281690001, "via": 2.2978723404299997, "through": 1.07074930869, "requir": 1.52844902282, "meant": 3.20597738288, "face": 1.80327124035, "what": 1.25343439128, "exponenti": 39.2, "translat": 2.85745140389, "loan": 8.26014568158, "cat": 10.5348374253, "nielsen": 33.2830188679, "forecast": 21.897931034499997, "potenti": 2.52080025405, "brain": 8.929133858270001, "tech": 19.1739130435, "base": 1.14628158845, "occur": 1.7453825857499998, "weather": 5.3944954128400004, "along": 1.2973768080399999, "twolay": 1323.0, "explod": 12.432263116700002, "renew": 4.6191446028500005, "factor": 2.89127663449, "microsoft": 24.8450704225, "were": 1.02458857696, "comput": 3.9277585353800006, "human": 1.8965476048299998, "layer": 8.14153846154, "greater": 2.14801785956, "contain": 1.59814777532, "noisi": 62.2588235294, "belong": 3.5, "problem": 1.76674827509, "voic": 3.21181468744, "neural": 59.4606741573, "thing": 2.4065484311099996, "serv": 1.4668760972, "just": 1.33580143037, "test": 2.65707112971, "adapt": 3.32272917539, "understand": 2.96858638743, "interconnect": 30.297709923699998, "internet": 4.98461538462, "birthplac": 18.082004555799998, "dure": 1.0503473370799998, "random": 7.1902173913, "defin": 2.72830383227, "led": 1.33782758911, "activ": 1.46403541129, "where": 1.06715063521, "live": 1.30591428806, "echo": 10.5, "tool": 4.99716713881, "start": 1.26673581744, "took": 1.4009883515700001, "ran": 3.4915328788199997, "enabl": 3.5421686747, "they": 1.03017325287, "risk": 4.095975232200001, "whi": 3.2566153846200003, "bankruptci": 18.7659574468, "studi": 1.53184098804, "giant": 6.23566378633, "singl": 1.60948905109, "autom": 19.8202247191, "central": 1.6121039805000001, "play": 1.46390041494, "mani": 1.04426757877, "diseas": 5.2120814182499995, "over": 1.02525024217, "afford": 7.0875, "netflix": 163.670103093, "analysi": 3.47852760736, "display": 2.93456561922, "linear": 13.8776223776, "hinton": 152.653846154, "consist": 1.4901445466499998, "traffic": 5.95052473763, "ensu": 8.4312267658, "synaps": 211.68, "there": 1.04091266719, "explos": 6.72142252329, "connect": 1.8843916913900003, "inform": 1.5753125620200001, "bank": 2.87400434468, "baidu": 1134.0, "say": 1.7544480053, "best": 1.5828514456600002, "exampl": 1.50483412322, "continu": 1.13928955867, "unknown": 3.77281368821, "secret": 3.11294117647, "illustr": 3.6614391143900002, "loos": 7.065420560750001, "take": 1.13961668222, "follow": 1.04640126549, "now": 1.160780873, "bernard": 8.540075309310001, "predictor\u2013connect": 1323.0, "per": 1.9597580545599997, "high": 1.14777327935, "winter": 3.24132298898, "driven": 5.601976005650001, "abl": 1.8208510150200001, "publish": 1.36885669943, "power": 1.3396337861799998, "audienc": 4.4784203103, "also": 1.01476510067, "person": 1.40520446097, "around": 1.21394708671, "such": 1.06151377374, "treatment": 3.87125091441, "role": 1.55327267391, "research": 1.9420183486200002, "imag": 2.70137825421, "accomplish": 5.17302052786, "repeat": 2.8771293947099994, "the": 1.0, "may": 1.05201775893, "becom": 1.12492028626, "age": 1.48623853211, "tag": 19.7462686567, "scientist": 4.69426374926, "hype": 80.5888324873, "open": 1.24556723678, "select": 2.02345144022, "six": 1.5552507837, "hospit": 3.4633507853400003, "want": 1.99698113208, "simul": 11.4793926247, "act": 1.4318181818200002, "howev": 1.0945191313299998, "prove": 2.45720476706, "elimin": 3.67670217693, "readi": 5.15789473684, "flourish": 9.89775561097, "clark": 5.754258789419999, "henri": 2.63808574277, "that": 1.00398406375, "which": 1.005191845, "intellig": 4.19334389857, "encompass": 8.02628918099, "bias": 13.7335640138, "mid": 9.727941176469999, "other": 1.00992366412, "appli": 2.2972073506, "whether": 2.20683903253, "procedur": 5.8691312384500005, "one": 1.00627495722, "second": 1.1130898128, "known": 1.0859097127200001, "custom": 3.6346153846199996, "begin": 1.3305397251100002, "algorithm": 27.9507042254, "becaus": 1.1495184997499999, "facebook": 28.5539568345, "hoff": 278.526315789, "like": 1.14918566775, "overhyp": 1323.0, "belmont": 71.1928251121, "imagin": 6.598503740650001, "technolog": 2.6034765496900003, "preset": 196.0, "detect": 5.41288782816, "part": 1.04330682789, "invest": 4.16146788991, "backpropag": 1323.0, "element": 2.36004162331, "outlin": 6.38102893891, "includ": 1.0190641247799999, "precis": 5.322158900440001, "gpus": 1058.4, "receiv": 1.3054847463200001, "everi": 1.47917637194, "term": 1.39520168732, "autonom": 11.086592178800002, "frank": 3.4520547945199995, "conjectur": 34.6637554585, "principl": 3.4520547945199995, "rang": 1.7848229342299997, "time": 1.01127460348, "process": 1.69524826482, "back": 1.26070038911, "chang": 1.1808985421, "bit": 8.33385826772, "project": 1.7534791252500002, "differ": 1.23654490225, "been": 1.0239277652399998, "somewhat": 4.29197080292, "interchang": 13.793223284100002, "most": 1.02096463023, "between": 1.03453668708, "heavili": 3.24132298898, "player": 3.54375, "drive": 2.93510815308, "credit": 3.04312823462, "fail": 1.9281029876099998, "need": 1.4372623574099999, "all": 1.01146788991, "busi": 2.05541170378, "today": 1.74961428257, "supervis": 7.74061433447, "recent": 1.54405757635, "almost": 1.53584212054, "exist": 1.4647107666799999, "structur": 2.0580762250499998, "day": 1.18371607516, "xray": 1323.0, "weight": 4.878918254459999, "built": 1.99447236181, "more": 1.0171706817, "improv": 2.04376930999, "correspond": 3.32481675393, "these": 1.07415426252, "fund": 2.5635394800599998, "inaccur": 24.201219512199998, "capabl": 3.6580645161300005, "amount": 2.27027027027, "artifici": 8.31639601886, "made": 1.07038834951, "blueprint": 45.6206896552, "comment": 3.05954904606, "state": 1.0477133240899998, "friend": 2.20194174757, "dartmouth": 71.1928251121, "can": 1.17626139142, "avail": 1.7288467821, "describ": 1.47027227264, "fundament": 5.32930513595, "onli": 1.0256476516600002, "each": 1.18974820144, "andrew": 3.82462057336, "few": 1.31729173581, "this": 1.00379362671, "accur": 5.768895348840001, "rise": 2.02940048575, "link": 2.15151104486, "advanc": 1.9997480791, "imposs": 4.96125, "gartner": 369.209302326, "subscript": 20.752941176500002, "oper": 1.55479384977, "method": 2.5714285714300003, "pitt": 41.1295336788, "dean": 8.27737226277, "eckerson": 1323.0, "come": 1.32831325301, "perceptron": 1323.0, "aspect": 3.0893169877399997, "text": 3.12827586207, "send": 3.75053153792, "identifi": 2.30187037843, "first": 1.00761614623, "grew": 3.06545665186, "input": 12.2029208301, "michael": 2.23259738433, "page": 2.03669018602, "while": 1.0441988950299999, "innov": 4.74051955808, "year": 1.0485436893200002, "farley": 119.36842105299999, "without": 1.29547123623, "socal": 1134.0, "learn": 2.32275054865, "same": 1.11857958148, "multilay": 324.0}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Deep Learning \u2013 Past, Present, and Future</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Deep Learning \u2013 Past, Present, and Future Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/frameworks-offer-data-scientists-programming-languages-lack.html\" rel=\"prev\" title=\"What Do Frameworks Offer Data Scientists that Programming Languages Lack?\"/>\n<link href=\"https://www.kdnuggets.com/jobs/17/05-02-apple-data-science-engineer.html\" rel=\"next\" title=\"Apple: Data Science Engineer\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=66244\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-66244 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 2-May, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/opinions-interviews.html\">Opinions, Interviews</a> \u00bb Deep Learning \u2013 Past, Present, and Future (\u00a0<a href=\"/2017/n17.html\">17:n17</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"Gold Blog, May 2017\" src=\"/images/top-kdnuggets-blog-2017-may-gold.png\" width=\"95\"/>Deep Learning \u2013 Past, Present, and Future</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/05/frameworks-offer-data-scientists-programming-languages-lack.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/17/05-02-apple-data-science-engineer.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 885</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/andrew-ng\" rel=\"tag\">Andrew Ng</a>, <a href=\"https://www.kdnuggets.com/tag/big-data\" rel=\"tag\">Big Data</a>, <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/geoff-hinton\" rel=\"tag\">Geoff Hinton</a>, <a href=\"https://www.kdnuggets.com/tag/google\" rel=\"tag\">Google</a>, <a href=\"https://www.kdnuggets.com/tag/gpu\" rel=\"tag\">GPU</a>, <a href=\"https://www.kdnuggets.com/tag/history\" rel=\"tag\">History</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/nvidia\" rel=\"tag\">NVIDIA</a></div>\n<br/>\n<p class=\"excerpt\">\n     There is a lot of buzz around deep learning technology. First developed in the 1940s, deep learning was meant to simulate neural networks found in brains, but in the last decade 3 key developments have unleashed its potential.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"2017/05/deep-learning-big-deal.html/2#comments\">comments</a></div>\n<p><strong>By Henry H. Eckerson, Eckerson Group.</strong></p>\n<p><center><img alt=\"\" height=\"299\" size-full=\"\" sizes=\"(max-width: 498px) 100vw, 498px\" src=\"/wp-content/uploads/deep-neural-network.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/deep-neural-network.jpg 498w, https://www.kdnuggets.com/wp-content/uploads/deep-neural-network-300x180.jpg 300w\" width=\"498\" wp-image-45318\"=\"\"/><br>\n<font size=\"-1\">From <a href=\"http://neuralnetworksanddeeplearning.com/\" target=\"_blank\">Neural Networks and Deep Learning</a>, by Michael Nielsen.</font></br></center></p>\n<p>Deep learning is exploding. According to <a href=\"http://www.gartner.com/smarterwithgartner/nueral-networks-and-modern-bi-platforms-will-evolve-data-and-analytics/\" rel=\"noopener noreferrer\" target=\"_blank\">Gartner</a>, the number of open positions for deep learning experts grew from almost zero in 2014 to 41,000 today. Much of this growth is being driven by high tech giants, such as Facebook, Apple, Netflix, Microsoft, Google, and Baidu.</p>\n<p>These big players and others have invested heavily in deep learning projects. Besides hiring experts, they have funded deep learning projects and experiments and acquired deep learning related companies. And these investments are only the beginning. Gartner predicts that 80% of data scientists will be using deep learning tools by 2018.</p>\n<p>Deep learning technology, which is meant to simulate biological neural networks in brains, arose in the 1950s, along with the first computers. So, if computers and deep learning began development together, why is deep learning only now reaching a mainstream computing audience?</p>\n<p>The increased processing power afforded by graphical processing units (GPUs), the enormous amount of available data, and the development of more advanced algorithms has led to the rise of deep learning.<strong>\u00a0</strong></p>\n<p><strong>The Current State Of Deep Learning</strong></p>\n<p>Deep learning is all around us. It\u2019s used to determine which online ads to display in real time, identify and tags friends in photos, translate your voice to text, translate text into different languages on a Web page, and drive autonomous vehicles.</p>\n<p>Deep learning is also found in less visible places. Credit card companies use deep learning for fraud detection; businesses use it to predict whether you will cancel a subscription and provide personalized customer recommendations; banks use it to predict bankruptcy and loan risk; hospitals use it for detection, diagnosis, and treatment of diseases.</p>\n<p>The range of applications is almost limitless. Other options include text analysis, image captioning, image colorization, x-ray analysis, weather forecasts, finance predictions, and more.</p>\n<p>Deep learning is already being widely used to automate processes, improve performance, detect patterns, and solve problems.</p>\n<p><strong>What Is Deep Learning?</strong></p>\n<p>Deep learning falls under the umbrella of machine learning which is a subset of artificial intelligence (AI). Loosely defined, artificial intelligence encompasses technology that simulates human capabilities while machine learning algorithms learn and adapt to new events.</p>\n<p>Deep learning is a term for technologies that use artificial neural network (ANNs) algorithms. Experts consider deep learning and ANNs to be the same thing and use the terms interchangeably. Just like neural networks in brains, ANNs have neurons (nodes) interconnected by synapses (links). Each node receives data, performs an operation, and passes the new data to another node via a link. The links contain weights or biases that influence the next node\u2019s operation.</p>\n<p>To illustrate the roles of nodes and links, imagine a company that wants to predict whether a customer will renew a subscription based on two predictors, gender and age. The company\u2019s neural network has two input nodes\u2013one for each predictor\u2013connected via separate links to one output node. Gender and age values are fed into the input nodes. Those values are multiplied by preset weights in the links. If age happens to be a better predictor than gender, then the link that sends age data will have a higher weight.</p>\n<p>The output node adds the weighted data from the input nodes and produces a value, which equates to a prediction. In this simplified example, the value could be between 0 and 1. The closer the value is to 1, the more likely the customer is to renew the subscription.</p>\n<p>In a real project, ANNs may contain thousands of nodes and billions of links. Each node belongs to a layer, which is a group of nodes. There are input layers, output layers, and layers in between the two, which are known as hidden layers. Adding nodes, links, and layers increases the accuracy of the ANN.<strong>\u00a0</strong></p>\n<p><strong>Role of Training.</strong> Once built, ANNs require a lot of \u2018training\u2019 to work well. An untrained ANN will always fail. This is where the \u2018learning\u2019 in deep learning comes into play.</p>\n<p>Data scientists can use supervised or unsupervised training. Under supervised training, ANNs process input values from test data and produce output values (predictions), which are compared to the real output values from the test data. Then, a training algorithm, specifically designed to train ANNs, is applied. A few types of training algorithms exist, but the most widely used type is called backpropagation. The backpropagation algorithm identifies the parts of the ANN responsible for an inaccurate prediction by following the error in the output nodes back through the ANN to the hidden and input layers and changes the weights accordingly. This process is repeated over and over until the ANN produces consistent, accurate predictions with the test data. Then, the ANN is ready to process new input values and predict unknown output values.</p>\n<p>The purpose of unsupervised training is to model the structure or distribution of data, not to produce a predictor. So with unsupervised training, once an ANN processes input data, the weights do not need to be changed because there is no corresponding output data to compare the ANN\u2019s prediction to.</p>\n<p><strong>Deep Learning Is Old Technology</strong></p>\n<p>The best place to start the AI and deep learning story is with William McCulloch and Walter Pitts. In 1943, they published <em>A Logical Calculus of the Ideas Immanent in Nervous Activity</em> in which they outlined the first computational model of a neural network. This paper served as the blueprint for the first ANNs.</p>\n<p>Six years later, Donald Hebb published <em>The Organization of Behavior</em>, which argued that the connections between neurons strengthened with use. This concept proved fundamental to understanding human learning and how to train ANNs.</p>\n<p>In 1954, Belmont Farley and Wesley Clark, using the research done by McCulloch and Pitts, ran the first computer simulations of an artificial neural network. These networks of up to 128 neurons were trained to recognize simple patterns.</p>\n<p>In the summer of 1956, computer scientists met \u201cto act on the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\u201d This event, known as the Dartmouth Conference, is considered the birthplace of AI.</p>\n<p>Following the Dartmouth Conference, the field of artificial intelligence took off. In 1957, Frank Rosenblatt began to study a type of neural network he called the perceptron and was able to apply the training method Farley and Clark used on their two-layer networks to multi-layer ones.</p>\n<p>In 1959, Bernard Widrow and Marcian Hoff developed a single layer neural network they called ADALINE short for Adaptive Linear Elements, which could predict the next bit of information on an incoming phone call based on the prior bits. Their next development, a multilayer neural network called MADALINE, eliminated echoes on phone calls and is said to be the first practical application of an ANN.</p>\n<p>Innovations continued through the \u201860s, but funding, research, and advances slowed in the \u201870s. AI scientists\u2019 accomplishments failed to live up to media hype and government expectations. The so-called \u2018AI winter\u2019 ensued during which there was little funding and minimal research done on the topic.</p>\n<p>Starting in 1986, research resurged for a few years after Geoff Hinton published <em>Learning Representations by Back-propagating Errors</em>, which describes the backpropagation learning procedure. However, true resurgence did not occur until the mid 2000s. Today, deep learning and AI are in deep bloom, and some would say overhyped.</p>\n<p><strong>So, Why Are ANNs Becoming Useful Now?</strong></p>\n<p>Three factors have unleashed the potential of deep learning:</p>\n<h3>1. The Exponential Explosion of Available Data</h3>\n<p>According to Cisco, the global Internet traffic in 1992 was 100 GB per day. In 2015, that number was 17.5 million times greater at 20,235 GB per second. Now, 90% of the world\u2019s data has been created in the last two years.</p>\n<p>Without this data, training ANNs containing millions of connections and thousands of nodes could not happen. For an ANN to recognize a face, detect credit fraud, or translate a voice to text in a noisy room it takes more than just a few bits of test data for consistent, accurate predictions. This is why ANNs flourish in the age of big data.</p>\n<p>The best and most visible example of data enabling an ANN is a project led by Google X, a somewhat secretive research and development team. Led by Andrew Ng, until recently the chief scientist at Baidu Research, and Jeff Dean, a Google Senior Fellow, the team assembled a 16,000 central processing units (CPUs) to power a ANN with over a billion connections.</p>\n<p>The ANN then underwent training, processing 10 million images from randomly selected YouTube videos. According to many sources, the ANN trained itself to recognize cats. In reality, only one node in the ANN was responsible for recognizing cat images. Other nodes could identify human bodies and faces. Two decades ago, it would have been impossible to collect 10 million images to train the ANN.</p>\n<p>Next, we look at the rise of the GPU.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/05/frameworks-offer-data-scientists-programming-languages-lack.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/17/05-02-apple-data-science-engineer.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/opinions-interviews.html\">Opinions, Interviews</a> \u00bb Deep Learning \u2013 Past, Present, and Future (\u00a0<a href=\"/2017/n17.html\">17:n17</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556445658\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.589 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-28 06:00:58 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "henri", "eckerson", "eckerson", "group", "from", "neural", "network", "and", "deep", "learn", "michael", "nielsen", "deep", "learn", "explod", "accord", "gartner", "the", "number", "open", "posit", "for", "deep", "learn", "expert", "grew", "from", "almost", "zero", "num", "num", "today", "much", "this", "growth", "driven", "high", "tech", "giant", "such", "facebook", "appl", "netflix", "microsoft", "googl", "and", "baidu", "these", "big", "player", "and", "other", "have", "invest", "heavili", "deep", "learn", "project", "besid", "hire", "expert", "they", "have", "fund", "deep", "learn", "project", "and", "experi", "and", "acquir", "deep", "learn", "relat", "compani", "and", "these", "invest", "are", "onli", "the", "begin", "gartner", "predict", "that", "num", "data", "scientist", "will", "use", "deep", "learn", "tool", "num", "deep", "learn", "technolog", "which", "meant", "simul", "biolog", "neural", "network", "brain", "aros", "the", "num", "along", "with", "the", "first", "comput", "comput", "and", "deep", "learn", "began", "develop", "togeth", "whi", "deep", "learn", "onli", "now", "reach", "mainstream", "comput", "audienc", "the", "increas", "process", "power", "afford", "graphic", "process", "unit", "gpus", "the", "enorm", "amount", "avail", "data", "and", "the", "develop", "more", "advanc", "algorithm", "has", "led", "the", "rise", "deep", "learn", "the", "current", "state", "deep", "learn", "deep", "learn", "all", "around", "use", "determin", "which", "onlin", "display", "real", "time", "identifi", "and", "tag", "friend", "photo", "translat", "voic", "text", "translat", "text", "into", "differ", "languag", "web", "page", "and", "drive", "autonom", "vehicl", "deep", "learn", "also", "found", "less", "visibl", "place", "credit", "card", "compani", "use", "deep", "learn", "for", "fraud", "detect", "busi", "use", "predict", "whether", "will", "cancel", "subscript", "and", "provid", "person", "custom", "recommend", "bank", "use", "predict", "bankruptci", "and", "loan", "risk", "hospit", "use", "for", "detect", "diagnosi", "and", "treatment", "diseas", "the", "rang", "applic", "almost", "limitless", "other", "option", "includ", "text", "analysi", "imag", "caption", "imag", "color", "xray", "analysi", "weather", "forecast", "financ", "predict", "and", "more", "deep", "learn", "alreadi", "wide", "use", "autom", "process", "improv", "perform", "detect", "pattern", "and", "solv", "problem", "what", "deep", "learn", "deep", "learn", "fall", "under", "the", "umbrella", "machin", "learn", "which", "subset", "artifici", "intellig", "loos", "defin", "artifici", "intellig", "encompass", "technolog", "that", "simul", "human", "capabl", "while", "machin", "learn", "algorithm", "learn", "and", "adapt", "new", "event", "deep", "learn", "term", "for", "technolog", "that", "use", "artifici", "neural", "network", "ann", "algorithm", "expert", "consid", "deep", "learn", "and", "ann", "the", "same", "thing", "and", "use", "the", "term", "interchang", "just", "like", "neural", "network", "brain", "ann", "have", "neuron", "node", "interconnect", "synaps", "link", "each", "node", "receiv", "data", "perform", "oper", "and", "pass", "the", "new", "data", "anoth", "node", "via", "link", "the", "link", "contain", "weight", "bias", "that", "influenc", "the", "next", "node", "oper", "illustr", "the", "role", "node", "and", "link", "imagin", "compani", "that", "want", "predict", "whether", "custom", "will", "renew", "subscript", "base", "two", "predictor", "gender", "and", "age", "the", "compani", "neural", "network", "has", "two", "input", "nodes\u2013on", "for", "each", "predictor\u2013connect", "via", "separ", "link", "one", "output", "node", "gender", "and", "age", "valu", "are", "fed", "into", "the", "input", "node", "those", "valu", "are", "multipli", "preset", "weight", "the", "link", "age", "happen", "better", "predictor", "than", "gender", "then", "the", "link", "that", "send", "age", "data", "will", "have", "higher", "weight", "the", "output", "node", "add", "the", "weight", "data", "from", "the", "input", "node", "and", "produc", "valu", "which", "equat", "predict", "this", "simplifi", "exampl", "the", "valu", "could", "between", "num", "and", "num", "the", "closer", "the", "valu", "num", "the", "more", "like", "the", "custom", "renew", "the", "subscript", "real", "project", "ann", "may", "contain", "thousand", "node", "and", "billion", "link", "each", "node", "belong", "layer", "which", "group", "node", "there", "are", "input", "layer", "output", "layer", "and", "layer", "between", "the", "two", "which", "are", "known", "hidden", "layer", "node", "link", "and", "layer", "increas", "the", "accuraci", "the", "role", "train", "onc", "built", "ann", "requir", "lot", "train", "work", "well", "untrain", "will", "alway", "fail", "this", "where", "the", "learn", "deep", "learn", "come", "into", "play", "data", "scientist", "can", "use", "supervis", "unsupervis", "train", "under", "supervis", "train", "ann", "process", "input", "valu", "from", "test", "data", "and", "produc", "output", "valu", "predict", "which", "are", "compar", "the", "real", "output", "valu", "from", "the", "test", "data", "then", "train", "algorithm", "specif", "design", "train", "ann", "appli", "few", "type", "train", "algorithm", "exist", "but", "the", "most", "wide", "use", "type", "call", "backpropag", "the", "backpropag", "algorithm", "identifi", "the", "part", "the", "respons", "for", "inaccur", "predict", "follow", "the", "error", "the", "output", "node", "back", "through", "the", "the", "hidden", "and", "input", "layer", "and", "chang", "the", "weight", "accord", "this", "process", "repeat", "over", "and", "over", "until", "the", "produc", "consist", "accur", "predict", "with", "the", "test", "data", "then", "the", "readi", "process", "new", "input", "valu", "and", "predict", "unknown", "output", "valu", "the", "purpos", "unsupervis", "train", "model", "the", "structur", "distribut", "data", "not", "produc", "predictor", "with", "unsupervis", "train", "onc", "process", "input", "data", "the", "weight", "not", "need", "chang", "becaus", "there", "correspond", "output", "data", "compar", "the", "predict", "deep", "learn", "old", "technolog", "the", "best", "place", "start", "the", "and", "deep", "learn", "stori", "with", "william", "mcculloch", "and", "walter", "pitt", "num", "they", "publish", "logic", "calculus", "the", "idea", "imman", "nervous", "activ", "which", "they", "outlin", "the", "first", "comput", "model", "neural", "network", "this", "paper", "serv", "the", "blueprint", "for", "the", "first", "ann", "six", "year", "later", "donald", "hebb", "publish", "the", "organ", "behavior", "which", "argu", "that", "the", "connect", "between", "neuron", "strengthen", "with", "use", "this", "concept", "prove", "fundament", "understand", "human", "learn", "and", "how", "train", "ann", "num", "belmont", "farley", "and", "wesley", "clark", "use", "the", "research", "done", "mcculloch", "and", "pitt", "ran", "the", "first", "comput", "simul", "artifici", "neural", "network", "these", "network", "num", "neuron", "were", "train", "recogn", "simpl", "pattern", "the", "summer", "num", "comput", "scientist", "met", "act", "the", "conjectur", "that", "everi", "aspect", "learn", "ani", "other", "featur", "intellig", "can", "principl", "precis", "describ", "that", "machin", "can", "made", "simul", "this", "event", "known", "the", "dartmouth", "confer", "consid", "the", "birthplac", "follow", "the", "dartmouth", "confer", "the", "field", "artifici", "intellig", "took", "off", "num", "frank", "rosenblatt", "began", "studi", "type", "neural", "network", "call", "the", "perceptron", "and", "abl", "appli", "the", "train", "method", "farley", "and", "clark", "use", "their", "twolay", "network", "multilay", "one", "num", "bernard", "widrow", "and", "marcian", "hoff", "develop", "singl", "layer", "neural", "network", "they", "call", "short", "for", "adapt", "linear", "element", "which", "could", "predict", "the", "next", "bit", "inform", "incom", "phone", "call", "base", "the", "prior", "bit", "their", "next", "develop", "multilay", "neural", "network", "call", "elimin", "echo", "phone", "call", "and", "said", "the", "first", "practic", "applic", "innov", "continu", "through", "the", "num", "but", "fund", "research", "and", "advanc", "slow", "the", "num", "scientist", "accomplish", "fail", "live", "media", "hype", "and", "govern", "expect", "the", "socal", "winter", "ensu", "dure", "which", "there", "littl", "fund", "and", "minim", "research", "done", "the", "topic", "start", "num", "research", "resurg", "for", "few", "year", "after", "geoff", "hinton", "publish", "learn", "represent", "backpropag", "error", "which", "describ", "the", "backpropag", "learn", "procedur", "howev", "true", "resurg", "not", "occur", "until", "the", "mid", "num", "today", "deep", "learn", "and", "are", "deep", "bloom", "and", "some", "would", "say", "overhyp", "whi", "are", "ann", "becom", "use", "now", "three", "factor", "have", "unleash", "the", "potenti", "deep", "learn", "num", "the", "exponenti", "explos", "avail", "data", "accord", "cisco", "the", "global", "internet", "traffic", "num", "num", "per", "day", "num", "that", "number", "num", "million", "time", "greater", "num", "per", "second", "now", "num", "the", "world", "data", "has", "been", "creat", "the", "last", "two", "year", "without", "this", "data", "train", "ann", "contain", "million", "connect", "and", "thousand", "node", "could", "not", "happen", "for", "recogn", "face", "detect", "credit", "fraud", "translat", "voic", "text", "noisi", "room", "take", "more", "than", "just", "few", "bit", "test", "data", "for", "consist", "accur", "predict", "this", "whi", "ann", "flourish", "the", "age", "big", "data", "the", "best", "and", "most", "visibl", "exampl", "data", "enabl", "project", "led", "googl", "somewhat", "secret", "research", "and", "develop", "team", "led", "andrew", "until", "recent", "the", "chief", "scientist", "baidu", "research", "and", "jeff", "dean", "googl", "senior", "fellow", "the", "team", "assembl", "num", "central", "process", "unit", "cpus", "power", "with", "over", "billion", "connect", "the", "then", "underw", "train", "process", "num", "million", "imag", "from", "random", "select", "youtub", "video", "accord", "mani", "sourc", "the", "train", "itself", "recogn", "cat", "realiti", "onli", "one", "node", "the", "respons", "for", "recogn", "cat", "imag", "other", "node", "could", "identifi", "human", "bodi", "and", "face", "two", "decad", "ago", "would", "have", "been", "imposs", "collect", "num", "million", "imag", "train", "the", "next", "look", "the", "rise", "the"], "timestamp_scraper": 1556482469.091611, "title": "Deep Learning \u2013 Past, Present, and Future", "read_time": 450.9, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"2017/05/deep-learning-big-deal.html/2#comments\">comments</a></div>\n<p><strong>By Henry H. Eckerson, Eckerson Group.</strong></p>\n<p><center><img alt=\"\" height=\"299\" size-full=\"\" sizes=\"(max-width: 498px) 100vw, 498px\" src=\"/wp-content/uploads/deep-neural-network.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/deep-neural-network.jpg 498w, https://www.kdnuggets.com/wp-content/uploads/deep-neural-network-300x180.jpg 300w\" width=\"498\" wp-image-45318\"=\"\"/><br>\n<font size=\"-1\">From <a href=\"http://neuralnetworksanddeeplearning.com/\" target=\"_blank\">Neural Networks and Deep Learning</a>, by Michael Nielsen.</font></br></center></p>\n<p>Deep learning is exploding. According to <a href=\"http://www.gartner.com/smarterwithgartner/nueral-networks-and-modern-bi-platforms-will-evolve-data-and-analytics/\" rel=\"noopener noreferrer\" target=\"_blank\">Gartner</a>, the number of open positions for deep learning experts grew from almost zero in 2014 to 41,000 today. Much of this growth is being driven by high tech giants, such as Facebook, Apple, Netflix, Microsoft, Google, and Baidu.</p>\n<p>These big players and others have invested heavily in deep learning projects. Besides hiring experts, they have funded deep learning projects and experiments and acquired deep learning related companies. And these investments are only the beginning. Gartner predicts that 80% of data scientists will be using deep learning tools by 2018.</p>\n<p>Deep learning technology, which is meant to simulate biological neural networks in brains, arose in the 1950s, along with the first computers. So, if computers and deep learning began development together, why is deep learning only now reaching a mainstream computing audience?</p>\n<p>The increased processing power afforded by graphical processing units (GPUs), the enormous amount of available data, and the development of more advanced algorithms has led to the rise of deep learning.<strong>\u00a0</strong></p>\n<p><strong>The Current State Of Deep Learning</strong></p>\n<p>Deep learning is all around us. It\u2019s used to determine which online ads to display in real time, identify and tags friends in photos, translate your voice to text, translate text into different languages on a Web page, and drive autonomous vehicles.</p>\n<p>Deep learning is also found in less visible places. Credit card companies use deep learning for fraud detection; businesses use it to predict whether you will cancel a subscription and provide personalized customer recommendations; banks use it to predict bankruptcy and loan risk; hospitals use it for detection, diagnosis, and treatment of diseases.</p>\n<p>The range of applications is almost limitless. Other options include text analysis, image captioning, image colorization, x-ray analysis, weather forecasts, finance predictions, and more.</p>\n<p>Deep learning is already being widely used to automate processes, improve performance, detect patterns, and solve problems.</p>\n<p><strong>What Is Deep Learning?</strong></p>\n<p>Deep learning falls under the umbrella of machine learning which is a subset of artificial intelligence (AI). Loosely defined, artificial intelligence encompasses technology that simulates human capabilities while machine learning algorithms learn and adapt to new events.</p>\n<p>Deep learning is a term for technologies that use artificial neural network (ANNs) algorithms. Experts consider deep learning and ANNs to be the same thing and use the terms interchangeably. Just like neural networks in brains, ANNs have neurons (nodes) interconnected by synapses (links). Each node receives data, performs an operation, and passes the new data to another node via a link. The links contain weights or biases that influence the next node\u2019s operation.</p>\n<p>To illustrate the roles of nodes and links, imagine a company that wants to predict whether a customer will renew a subscription based on two predictors, gender and age. The company\u2019s neural network has two input nodes\u2013one for each predictor\u2013connected via separate links to one output node. Gender and age values are fed into the input nodes. Those values are multiplied by preset weights in the links. If age happens to be a better predictor than gender, then the link that sends age data will have a higher weight.</p>\n<p>The output node adds the weighted data from the input nodes and produces a value, which equates to a prediction. In this simplified example, the value could be between 0 and 1. The closer the value is to 1, the more likely the customer is to renew the subscription.</p>\n<p>In a real project, ANNs may contain thousands of nodes and billions of links. Each node belongs to a layer, which is a group of nodes. There are input layers, output layers, and layers in between the two, which are known as hidden layers. Adding nodes, links, and layers increases the accuracy of the ANN.<strong>\u00a0</strong></p>\n<p><strong>Role of Training.</strong> Once built, ANNs require a lot of \u2018training\u2019 to work well. An untrained ANN will always fail. This is where the \u2018learning\u2019 in deep learning comes into play.</p>\n<p>Data scientists can use supervised or unsupervised training. Under supervised training, ANNs process input values from test data and produce output values (predictions), which are compared to the real output values from the test data. Then, a training algorithm, specifically designed to train ANNs, is applied. A few types of training algorithms exist, but the most widely used type is called backpropagation. The backpropagation algorithm identifies the parts of the ANN responsible for an inaccurate prediction by following the error in the output nodes back through the ANN to the hidden and input layers and changes the weights accordingly. This process is repeated over and over until the ANN produces consistent, accurate predictions with the test data. Then, the ANN is ready to process new input values and predict unknown output values.</p>\n<p>The purpose of unsupervised training is to model the structure or distribution of data, not to produce a predictor. So with unsupervised training, once an ANN processes input data, the weights do not need to be changed because there is no corresponding output data to compare the ANN\u2019s prediction to.</p>\n<p><strong>Deep Learning Is Old Technology</strong></p>\n<p>The best place to start the AI and deep learning story is with William McCulloch and Walter Pitts. In 1943, they published <em>A Logical Calculus of the Ideas Immanent in Nervous Activity</em> in which they outlined the first computational model of a neural network. This paper served as the blueprint for the first ANNs.</p>\n<p>Six years later, Donald Hebb published <em>The Organization of Behavior</em>, which argued that the connections between neurons strengthened with use. This concept proved fundamental to understanding human learning and how to train ANNs.</p>\n<p>In 1954, Belmont Farley and Wesley Clark, using the research done by McCulloch and Pitts, ran the first computer simulations of an artificial neural network. These networks of up to 128 neurons were trained to recognize simple patterns.</p>\n<p>In the summer of 1956, computer scientists met \u201cto act on the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\u201d This event, known as the Dartmouth Conference, is considered the birthplace of AI.</p>\n<p>Following the Dartmouth Conference, the field of artificial intelligence took off. In 1957, Frank Rosenblatt began to study a type of neural network he called the perceptron and was able to apply the training method Farley and Clark used on their two-layer networks to multi-layer ones.</p>\n<p>In 1959, Bernard Widrow and Marcian Hoff developed a single layer neural network they called ADALINE short for Adaptive Linear Elements, which could predict the next bit of information on an incoming phone call based on the prior bits. Their next development, a multilayer neural network called MADALINE, eliminated echoes on phone calls and is said to be the first practical application of an ANN.</p>\n<p>Innovations continued through the \u201860s, but funding, research, and advances slowed in the \u201870s. AI scientists\u2019 accomplishments failed to live up to media hype and government expectations. The so-called \u2018AI winter\u2019 ensued during which there was little funding and minimal research done on the topic.</p>\n<p>Starting in 1986, research resurged for a few years after Geoff Hinton published <em>Learning Representations by Back-propagating Errors</em>, which describes the backpropagation learning procedure. However, true resurgence did not occur until the mid 2000s. Today, deep learning and AI are in deep bloom, and some would say overhyped.</p>\n<p><strong>So, Why Are ANNs Becoming Useful Now?</strong></p>\n<p>Three factors have unleashed the potential of deep learning:</p>\n<h3>1. The Exponential Explosion of Available Data</h3>\n<p>According to Cisco, the global Internet traffic in 1992 was 100 GB per day. In 2015, that number was 17.5 million times greater at 20,235 GB per second. Now, 90% of the world\u2019s data has been created in the last two years.</p>\n<p>Without this data, training ANNs containing millions of connections and thousands of nodes could not happen. For an ANN to recognize a face, detect credit fraud, or translate a voice to text in a noisy room it takes more than just a few bits of test data for consistent, accurate predictions. This is why ANNs flourish in the age of big data.</p>\n<p>The best and most visible example of data enabling an ANN is a project led by Google X, a somewhat secretive research and development team. Led by Andrew Ng, until recently the chief scientist at Baidu Research, and Jeff Dean, a Google Senior Fellow, the team assembled a 16,000 central processing units (CPUs) to power a ANN with over a billion connections.</p>\n<p>The ANN then underwent training, processing 10 million images from randomly selected YouTube videos. According to many sources, the ANN trained itself to recognize cats. In reality, only one node in the ANN was responsible for recognizing cat images. Other nodes could identify human bodies and faces. Two decades ago, it would have been impossible to collect 10 million images to train the ANN.</p>\n<p>Next, we look at the rise of the GPU.</p>\n</div> ", "website": "kdnuggets"}