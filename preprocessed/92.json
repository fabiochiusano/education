{"content": "comments By Kevin Vu, Exxact Corp . PyTorch is one of the most popular\u00a0 Deep Learning frameworks \u00a0that is based on Python and is supported by Facebook. In this article we will be looking into the classes that PyTorch provides for helping with Natural Language Processing (NLP). There are 6 classes in PyTorch that can be used for NLP related tasks using recurrent layers: torch.nn.RNN torch.nn.LSTM torch.nn.GRU torch.nn.RNNCell torch.nn.LSTMCell torch.nn.GRUCell Understanding these classes, their parameters, their inputs and their outputs are key to getting started with building your own neural networks for Natural Language Processing (NLP) in Pytorch. If you have started your NLP journey, chances are that you have encountered a similar type of diagram (if not, we recommend that you check out this excellent and often-cited article by Chris Olah\u200a\u2014\u200a Understanding LSTM Networks ): Source\u200a\u2014\u200a\u00a0 /posts/2015-08-Understanding-LSTMs/ Such unrolled diagrams are used by teachers to provide students with a simple-to-grasp explanation of the recurrent structure of such neural networks. Going from these pretty, unrolled diagrams and intuitive explanations to the Pytorch API can prove to be challenging. PyTorch is one of the most popular\u00a0 Deep Learning frameworks \u00a0that is based on Python and is supported by Facebook. In this article we will be looking into the classes that PyTorch provides for helping with Natural Language Processing (NLP). There are 6 classes in PyTorch that can be used for NLP related tasks using recurrent layers: torch.nn.RNN torch.nn.LSTM torch.nn.GRU torch.nn.RNNCell torch.nn.LSTMCell torch.nn.GRUCell Understanding these classes, their parameters, their inputs and their outputs are key to getting started with building your own neural networks for Natural Language Processing (NLP) in Pytorch. If you have started your NLP journey, chances are that you have encountered a similar type of diagram (if not, we recommend that you check out this excellent and often-cited article by Chris Olah\u200a\u2014\u200a Understanding LSTM Networks ): Source\u200a\u2014\u200a\u00a0 /posts/2015-08-Understanding-LSTMs/ Such unrolled diagrams are used by teachers to provide students with a simple-to-grasp explanation of the recurrent structure of such neural networks. Going from these pretty, unrolled diagrams and intuitive explanations to the Pytorch API can prove to be challenging. Source \u2014 /docs/stable/nn.html#recurrent-layers Hence, in this article, we aim to bridge that gap by explaining the parameters, inputs and the outputs of the relevant classes in PyTorch in a clear and descriptive manner. Pytorch basically has 2 levels of classes for building recurrent networks: Multi-layer classes\u200a\u2014\u200ann.RNN\u00a0,\u00a0nn.GRU\u00a0andnn.LSTM \u00a0 Objects of these classes are capable of representing deep bidirectional recurrent neural networks ( or, as the class names suggest, one of more their evolved architectures\u200a\u2014\u200aGated Recurrent Unit (GRU) or Long Short Term Memory (LSTM) networks ). Cell-level classes\u200a\u2014\u200ann.RNNCell\u00a0,\u00a0nn.GRUCell\u00a0and\u00a0nn.LSTMCell \u00a0 Objects of these classes can represent only a single cell\u00a0 (again, a simple RNN or LSTM or GRU cell) \u00a0that can handle one timestep of the input data.\u00a0 (Remember, these Cells don\u2019t have cuDNN optimisation and thus don\u2019t have any fused operations, etc.) All the classes in the same level share the same API. Hence, understanding the parameters, inputs and outputs of any one of the classes in both the above levels is enough. To make explanations simple, we will use the simplest classes\u200a\u2014\u200atorch.nn.RNN\u00a0and\u00a0torch.nn.RNNCell torch.nn.RNN : We will use the following diagram to explain the API\u200a\u2014 Source\u200a\u2014\u200a /posts/2015-08-Understanding-LSTMs/ Parameters: input_size \u200a\u2014\u200aThe number of expected features in the input x This represents the dimensions of vector x[i] (i.e, any of the vectors from x[0] to x[t] in the above diagram). Note that it is easy to confuse this with the sequence length, which is the total number of cells that we get after unrolling the RNN as above. hidden_size \u200a\u2014\u200aThe number of features in the hidden state h This represents the dimension of vector h[i] (i.e, any of the vectors from h[0] to h[t] in the above diagram). Together,\u00a0hidden_size\u00a0and\u00a0input_size\u00a0are necessary and sufficient in determining the shape of the weight matrices of the network. num_layers \u200a\u2014\u200aNumber of recurrent layers. E.g., setting\u00a0num_layers=2would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1 This parameter is used to build deep RNNs like these: Here red cells represent the inputs, green blocks represent the RNN cells and blue blocks represent the output. So for the above diagram, we would set the\u00a0num_layers\u00a0parameter to 3. nonlinearity \u200a\u2014\u200aThe non-linearity to use. Can be either \u2018tanh\u2019 or \u2018relu\u2019. Default: \u2018tanh\u2019 This is self-explanatory. bias \u200a\u2014\u200aIf\u00a0False, then the layer does not use bias weights b_ih and b_hh. Default:\u00a0True In the Deep Learning community, some people find that removing/using bias does not affect the model\u2019s performance. Hence, this boolean parameter. batch_first \u200a\u2014\u200aIf\u00a0True, then the input and output tensors are provided as (batch, seq, feature). Default:\u00a0False dropout \u200a\u2014\u200aIf non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to\u00a0dropout. Default: 0 This parameter is used to control the dropout regularisation method in the RNN architecture. bidirectional \u200a\u2014\u200aIf\u00a0True, becomes a bidirectional RNN. Default:\u00a0False Creating a bidirectional RNN is as simple as setting this parameter to True! So, to make an RNN in PyTorch, we need to pass 2 mandatory parameters to the class\u200a\u2014\u200ainput_size\u00a0and\u00a0hidden_size. Once we have created an object, we can \u201ccall\u201d the object with the relevant inputs and it returns outputs. Inputs: We need to pass 2 inputs to the object\u200a\u2014\u200ainput\u00a0and\u00a0h_0\u00a0: input \u200a\u2014\u200aThis is a tensor of shape\u00a0 (seq_len, batch, input_size).\u00a0 In order to work with variable lengthed inputs, we pack the shorter input sequences. See\u00a0  \u00a0or  \u00a0for details. h_0 \u200a\u2014\u200aThis is a tensor of shape (num_layers * num_directions, batch, hidden_size).\u00a0num_directions\u00a0is 2 for bidirectional RNNs and 1 otherwise. This tensor contains the initial hidden state for each element in the batch. Outputs : In a similar manner, the object returns 2 outputs to us\u200a\u2014\u200aoutput\u00a0and\u00a0h_n\u00a0: output \u200a\u2014\u200aThis is a tensor of shape\u00a0 (seq_len, batch, num_directions * hidden_size).\u00a0 It contains\u00a0the output features (h_k) from the last layer of the RNN, for each k. h_n \u200a\u2014\u200aThis is a tensor of size (num_layers * num_directions, batch, hidden_size). It contains the hidden state for k = seq_len. As mentioned before, both\u00a0torch.nn.GRU\u00a0and\u00a0torch.nn.LSTM\u00a0have the same API, i.e, they accept the same set of parameters and accept inputs in the same format and return out in the same format too. torch.nn.RNNCell : Since this represents only a single cell of the RNN, it accepts only 4 parameters, all of which have the same meaning as they did in\u00a0torch.nn.RNN\u00a0. Parameters: input_size \u200a\u2014\u200aThe number of expected features in the input x hidden_size \u200a\u2014\u200aThe number of features in the hidden state h bias \u200a\u2014\u200aIf\u00a0False, then the layer does not use bias weights b_ih and b_hh. Default:\u00a0True nonlinearity \u200a\u2014\u200aThe non-linearity to use. Can be either \u2018tanh\u2019 or \u2018relu\u2019. Default: \u2018tanh\u2019 Again, since this is just a single cell of an RNN, the input and output dimensions are much simpler\u200a\u2014 Inputs (input, hidden): input \u200a\u2014\u200athis is a tensor of shape (batch, input_size) that contains the input features. hidden \u200a\u2014\u200athis is a tensor of shape (batch, hidden_size) that contains the initial hidden states for each of the elements in the batch. Output: h\u2019\u200a \u2014\u200athis is a tensor of shape (batch, hidden_size) and it gives us the hidden state for the next time step. This was all about getting started with the PyTorch framework for Natural Language Processing (NLP). If you are looking for ideas on what is possible and what you can build, check out\u200a\u2014\u200a Deep Learning for Natural Language Processing using RNNs and CNNs . Original . Reposted with permission. Resources: On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education Software for Analytics, Data Science, Data Mining, and Machine Learning Related: Building NLP Classifiers Cheaply With Transfer Learning and Weak Supervision Beyond news contents: the role of social context for fake news detection Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters", "title_html": "<h1 id=\"title\">Getting started with NLP using the PyTorch framework</h1> ", "url": "https://www.kdnuggets.com/2019/04/nlp-pytorch.html", "tfidf": {"tfidf": {"after": 1.02070207021, "base": 2.2925631769, "natur": 9.23560209426, "can": 11.7626139142, "nnrnn": 1134.0, "bih": 2116.8, "onc": 1.4974533106999999, "numlayersnumwould": 1134.0, "relat": 3.71252630757, "nnrnncell": 1134.0, "here": 2.42307692308, "form": 1.12755681818, "data": 16.8821777967, "pass": 3.23636734278, "softwar": 10.2624434389, "recurrentlay": 1134.0, "comput": 3.9277585353800006, "long": 1.2657259028899999, "would": 1.0828729281799998, "onlin": 2.6051854282900004, "layer": 73.27384615385999, "togeth": 3.16191993626, "contain": 7.9907388766, "similar": 4.12542226071, "etc": 4.2066772655, "about": 1.06486015159, "class": 35.98080255971, "communiti": 1.96121062384, "neural": 297.3033707865, "gate": 5.97291196388, "optimis": 131.20661157, "too": 1.81585268215, "boolean": 186.776470588, "python": 112.5957446808, "manner": 7.8632986627, "bridg": 3.7067476068199996, "nngrucel": 1134.0, "otherwis": 3.72151898734, "teacher": 8.98726294934, "gap": 7.302667893280001, "olah": 2268.0, "numlay": 4536.0, "permiss": 6.280063291139999, "classifi": 5.2937645882, "most": 2.04192926046, "check": 19.51967213115, "unit": 1.15394679459, "recommend": 7.828402366860001, "hnum": 112.5957446808, "equal": 2.542193755, "rememb": 4.88793103448, "creat": 2.4985835694, "their": 7.108353588350001, "start": 6.3336790872, "exxact": 1134.0, "vector": 103.5954323, "articl": 10.0902504131, "kevin": 7.82068965517, "singl": 4.82846715327, "news": 4.16365066876, "million": 1.7279059643, "such": 4.24605509496, "format": 5.0625, "matric": 96.80487804879999, "oftencit": 2268.0, "explain": 5.20098280098, "initi": 2.7, "order": 1.24625166811, "for": 20.006300800200002, "simpletograsp": 2268.0, "support": 2.5371154614400004, "social": 1.9904714142400002, "deep": 21.76782449724, "deconstruct": 78.5940594059, "will": 4.89924394384, "red": 2.22228443449, "the": 88.0, "recurr": 284.7713004488, "build": 9.805043746800001, "chris": 11.959322033900001, "provid": 6.07763570935, "confus": 4.1451697127900005, "bhh": 2268.0, "number": 6.60857499654, "repost": 933.882352941, "next": 1.4950560316400001, "regularis": 481.09090909099996, "oper": 1.55479384977, "same": 7.83005707036, "rnns": 4536.0, "need": 2.8745247148199997, "there": 2.08182533438, "output": 122.83172147008001, "inputs": 6804.0, "tanh": 4536.0, "expect": 4.4002217295, "torchnngrucel": 2268.0, "possibl": 1.4173734488, "key": 4.5601034037, "nnlstmcell": 1134.0, "hidden": 62.50393700784, "level": 4.96331804919, "origin": 1.13724928367, "has": 1.0436497502, "have": 9.134053570259999, "paramet": 258.84782608650005, "take": 1.13961668222, "journey": 10.83686006826, "use": 15.444581360699999, "follow": 1.04640126549, "default": 169.1185086552, "resourc": 2.9487369985100003, "green": 2.63065451533, "name": 1.10211732037, "out": 4.24066777964, "pack": 7.85163204748, "model": 2.0905978404, "cheapli": 86.28260869569999, "object": 14.09320905462, "basic": 2.7301805675, "intuit": 55.4136125654, "much": 1.1942229577299999, "languag": 13.76929748484, "cnns": 1134.0, "weak": 4.70539419087, "simplest": 28.0494699647, "mean": 2.89813800658, "short": 1.41295834817, "not": 5.07836990595, "henc": 16.172495755529997, "shape": 22.42372881357, "batch": 356.76404494400003, "length": 7.38246919322, "encount": 8.27953063886, "cudnn": 1134.0, "determin": 2.1658935879900003, "becom": 1.12492028626, "aim": 2.8960233491400005, "peopl": 1.21320495186, "evolv": 4.60173913043, "postsnumunderstandinglstm": 3402.0, "easi": 5.2937645882, "challeng": 5.11633902674, "handl": 3.9229058561900003, "which": 2.01038369, "then": 3.25973581548, "sinc": 2.16737201366, "they": 2.06034650574, "timestep": 1134.0, "blue": 3.07019918778, "last": 2.4234468020200004, "prove": 4.91440953412, "get": 7.1425036554, "scienc": 4.63939216832, "task": 7.77282741738, "pytorch": 15876.0, "role": 1.55327267391, "student": 4.9434843531, "nonzero": 174.46153846200002, "featur": 10.68988072334, "relev": 13.877622377620002, "tensor": 1373.884615386, "term": 1.39520168732, "thus": 1.6463756092500001, "simpl": 10.19434931508, "variabl": 8.747107438019999, "mine": 9.751842751839998, "one": 5.031374786100001, "second": 1.1130898128, "two": 1.01379310345, "either": 3.1660185462199997, "see": 1.27242125511, "shorter": 8.22590673575, "some": 1.04036697248, "pattern": 3.79173632673, "facebook": 57.107913669, "popular": 3.01538461538, "context": 4.25972632144, "webbas": 1134.0, "distil": 43.9778393352, "network": 25.9369384088, "like": 1.14918566775, "diagram": 221.73184357499997, "beyond": 2.54586273252, "control": 1.46959178006, "both": 2.10431440122, "except": 1.71948445792, "detect": 5.41288782816, "process": 10.17148958892, "celllevel": 1134.0, "element": 4.72008324662, "supervis": 7.74061433447, "cell": 56.8268456376, "content": 3.5421686747, "weight": 14.636754763379997, "introduc": 1.7258397651900002, "set": 4.74831763124, "ani": 4.53535209256, "pretti": 31.5, "time": 1.01127460348, "from": 6.00340328982, "result": 1.14611608432, "perform": 1.5313977042500002, "work": 1.11520089913, "detail": 2.26186066391, "num": 16.00504064016, "step": 2.8279301745599996, "andnnlstm": 1134.0, "relu": 2268.0, "idea": 2.0930784443, "numdirect": 4536.0, "analyt": 34.513043478200004, "return": 4.185972930209999, "unrol": 2737.2413793099995, "excel": 9.68935001526, "memori": 2.57392996109, "torchnngru": 3402.0, "all": 3.03440366973, "input": 268.4642582622, "with": 14.016774925859997, "docsstablennhtml": 1134.0, "torchnnlstm": 3402.0, "are": 13.38877716514, "true": 12.7784932389, "explan": 32.54612546125, "structur": 4.1161524500999995, "that": 17.06772908375, "torchnnlstmcel": 2268.0, "look": 5.725895647979999, "architectur": 10.25581395348, "call": 1.0676529926, "dropout": 835.5789473699999, "final": 1.34008609775, "more": 1.0171706817, "and": 36.002267716679995, "chanc": 8.489839572200001, "fake": 18.290322580599998, "these": 8.59323410016, "fuse": 19.1507840772, "capabl": 3.6580645161300005, "batchfirst": 1134.0, "bidirect": 1443.272727275, "befor": 1.10036041031, "comment": 3.05954904606, "again": 3.01767724768, "state": 6.286279944539999, "torchnnrnncel": 4536.0, "doe": 5.11743848715, "mandatori": 14.5785123967, "selfexplanatori": 1134.0, "give": 1.3653250774, "make": 2.1525320317200003, "simpler": 17.9187358916, "total": 1.5460122699399999, "torchnnrnn": 5670.0, "onli": 3.0769429549800007, "each": 4.75899280576, "size": 2.49387370405, "sourc": 6.79041916168, "this": 24.09104704104, "necessari": 2.8421052631599997, "removingus": 1134.0, "educ": 2.00733341763, "framework": 24.601239669419996, "transfer": 2.72549356223, "nngru": 1134.0, "type": 4.056208482380001, "block": 6.40548718984, "hiddens": 10206.0, "note": 1.42449528937, "fals": 24.86452623336, "accept": 5.213222416800001, "method": 2.5714285714300003, "sequenc": 12.14225621414, "probabl": 2.64555907349, "just": 1.33580143037, "machin": 8.04866920152, "into": 2.03004922958, "bias": 68.667820069, "repres": 11.75782262544, "dimens": 24.76755070203, "abov": 9.51912699365, "understand": 14.842931937149999, "stack": 39.297029703, "descript": 4.00504540868, "corp": 6.4932515337400005, "first": 1.00761614623, "what": 2.50686878256, "seqlen": 3402.0, "nonlinear": 396.9, "share": 1.8566249561500001, "enough": 2.2319696330700003, "mention": 2.53894130817, "help": 2.79925945518, "affect": 2.4794627518400003, "clear": 1.85423966363, "find": 1.7294117647099998, "suffici": 4.3117870722400005, "suggest": 1.7571665744299998, "learn": 16.259253840550002, "multilay": 324.0, "seq": 180.409090909, "own": 2.35688836104}, "logtfidf": {"after": 0.020490694648099998, "base": 0.27304660457400004, "natur": 2.587838035752, "can": 1.6234109639399998, "nnrnn": 7.033506484289999, "bih": 13.929027225599999, "onc": 0.403765872355, "numlayersnumwould": 7.033506484289999, "relat": 0.639300904962, "nnrnncell": 7.033506484289999, "here": 0.8850381883700001, "form": 0.120053184191, "data": 6.084102924, "pass": 0.96260865948, "softwar": 2.32849096333, "recurrentlay": 7.033506484289999, "comput": 1.36806891594, "long": 0.235645793878, "would": 0.0796176279647, "onlin": 0.957503854357, "layer": 18.87281246115, "togeth": 0.916064474616, "contain": 2.34422659118, "similar": 0.9556682763419999, "etc": 1.4366730879700003, "about": 0.0628434774746, "class": 12.746127228861003, "communiti": 0.673561947791, "neural": 20.4265757775, "gate": 1.78723457463, "optimis": 4.87677326831, "too": 0.5965551547219999, "boolean": 5.22991255741, "python": 8.06131348592, "manner": 2.73811803006, "bridg": 1.31015483629, "nngrucel": 7.033506484289999, "otherwis": 1.3141319148700001, "teacher": 3.0053223330799996, "gap": 1.98823974622, "olah": 14.067012968579998, "numlay": 28.134025937159997, "permiss": 1.8373800586400002, "classifi": 1.6665296351499999, "most": 0.041495792591199995, "check": 5.6184314868600005, "unit": 0.143188061817, "recommend": 2.72922253726, "hnum": 8.06131348592, "equal": 0.933027391343, "rememb": 1.5867691126199999, "creat": 0.445153637028, "their": 0.10752353585890001, "start": 1.182216846455, "exxact": 7.033506484289999, "vector": 13.01679551188, "articl": 3.51065869787, "kevin": 2.05677274187, "singl": 1.427750307177, "news": 1.46649014697, "million": 0.5469102500940001, "such": 0.238783911224, "format": 1.8574265037459998, "matric": 4.572697386080001, "oftencit": 14.067012968579998, "explain": 1.911400854716, "initi": 0.6002091849, "order": 0.22014038079300002, "for": 0.006299807907940001, "simpletograsp": 14.067012968579998, "support": 0.475761220074, "social": 0.688371502261, "deep": 7.7320408188, "deconstruct": 4.364296116499999, "will": 0.81114613966, "red": 0.798535691347, "the": 0.0, "recurr": 28.577958895040002, "build": 2.9468247125460003, "chris": 3.57672776046, "provid": 0.9758892216250001, "confus": 1.4219437317299999, "bhh": 14.067012968579998, "number": 0.5796514705116, "repost": 6.83935046985, "next": 0.402163685499, "regularis": 6.17605625244, "oper": 0.441342964347, "same": 0.784417547228, "rnns": 28.134025937159997, "need": 0.725480326884, "there": 0.080195785851, "output": 32.61162525232, "inputs": 42.20103890573999, "tanh": 28.134025937159997, "expect": 1.57701550432, "torchnngrucel": 14.067012968579998, "possibl": 0.348805474891, "key": 1.64839623792, "nnlstmcell": 7.033506484289999, "hidden": 16.4463040416, "level": 1.510386569829, "origin": 0.128612437587, "has": 0.0427239448548, "have": 0.1330650210708, "paramet": 42.72285215789999, "take": 0.130691962197, "journey": 3.37961222378, "use": 0.43812029597400004, "follow": 0.045356911094199995, "default": 24.409265297119997, "resourc": 1.08137694258, "green": 0.9672326803710001, "name": 0.09723316638430002, "out": 0.2337055636772, "pack": 2.06072141432, "model": 0.7374500731110001, "cheapli": 4.45762805629, "object": 5.123601508818, "basic": 1.00436774895, "intuit": 6.643356194380001, "much": 0.17749572930100002, "languag": 4.984090946436, "cnns": 7.033506484289999, "weak": 1.5487095508000002, "simplest": 3.3339697356999998, "mean": 0.74184256704, "short": 0.345685625679, "not": 0.0777620650375, "henc": 5.05409915346, "shape": 8.14946699805, "batch": 35.7448953174, "length": 2.6119219622400003, "encount": 2.8412782001999997, "cudnn": 7.033506484289999, "determin": 0.772833019022, "becom": 0.11771217648900001, "aim": 1.06333853704, "peopl": 0.193265578473, "evolv": 1.52643430388, "postsnumunderstandinglstm": 21.100519452869996, "easi": 1.6665296351499999, "challeng": 1.8785839377900002, "handl": 1.36683266903, "which": 0.01035682769086, "then": 0.24910159569269996, "sinc": 0.1607363989154, "they": 0.0594539895352, "timestep": 7.033506484289999, "blue": 1.1217424415100001, "last": 0.38408728922200003, "prove": 1.79804886069, "get": 2.319076023128, "scienc": 1.682872357782, "task": 2.71497361322, "pytorch": 98.46909078005999, "role": 0.44036410757399996, "student": 1.80984647329, "nonzero": 5.16170430739, "featur": 2.9637119269939998, "relev": 3.8742609227999996, "tensor": 45.25355623284, "term": 0.33303898354600003, "thus": 0.49857627139300004, "simpl": 3.66966386817, "variabl": 2.1687230672, "mine": 3.16861817356, "one": 0.0312767582275, "second": 0.10713976337999999, "two": 0.0136988443582, "either": 0.91865527763, "see": 0.240921585492, "shorter": 2.1072885319999997, "some": 0.0395735090645, "pattern": 1.33282404788, "facebook": 6.703591039299999, "popular": 0.8211604175499999, "context": 1.44920491442, "webbas": 7.033506484289999, "distil": 3.78368585557, "network": 9.53083053052, "like": 0.139053576545, "diagram": 30.9888364694, "beyond": 0.934469583725, "control": 0.38498466158600003, "both": 0.10168506677860001, "except": 0.54202451213, "detect": 1.68878274493, "process": 3.16697519415, "celllevel": 7.033506484289999, "element": 1.7173585117539998, "supervis": 2.04648105583, "cell": 15.684538454879998, "content": 1.26473915954, "weight": 4.7547705783600005, "introduc": 0.5457137524260001, "set": 0.685984045156, "ani": 0.502433433464, "pretti": 5.51368073054, "time": 0.0112115188626, "from": 0.0034023250131959997, "result": 0.136378908381, "perform": 0.42618085058, "work": 0.109034567273, "detail": 0.816187777173, "num": 0.005039846326352001, "step": 1.03954505698, "andnnlstm": 7.033506484289999, "relu": 14.067012968579998, "idea": 0.73863592212, "numdirect": 28.134025937159997, "analyt": 5.696380287719999, "return": 0.9993806057760001, "unrol": 31.526339919599998, "excel": 3.1557603304, "memori": 0.9454338986599999, "torchnngru": 21.100519452869996, "all": 0.03420789629339999, "input": 55.036857378579995, "with": 0.01676488398746, "docsstablennhtml": 7.033506484289999, "torchnnlstm": 21.100519452869996, "are": 0.3830771565751, "true": 4.69162814817, "explan": 9.36610207845, "structur": 1.4435433502700001, "that": 0.06759452245388, "torchnnlstmcel": 14.067012968579998, "look": 1.9391600808, "architectur": 3.26939515838, "call": 0.0654627744488, "dropout": 25.5934346115, "final": 0.292733863948, "more": 0.017024931599999998, "and": 0.0022676451142896, "chanc": 2.89144584698, "fake": 2.9063720992400004, "these": 0.5722689552064, "fuse": 2.9523436587700003, "capabl": 1.2969341868100002, "batchfirst": 7.033506484289999, "bidirect": 28.32615314335, "befor": 0.0956377718795, "comment": 1.11826753454, "again": 0.822680463224, "state": 0.27966001660080003, "torchnnrnncel": 28.134025937159997, "doe": 1.6021251891509998, "mandatori": 2.67954869097, "selfexplanatori": 7.033506484289999, "give": 0.311392552224, "make": 0.14699531564579998, "simpler": 2.8858468633, "total": 0.43567888670500005, "torchnnrnn": 35.16753242145, "onli": 0.0759728049873, "each": 0.694966757216, "size": 0.9138372060609999, "sourc": 2.116873243004, "this": 0.09087477726, "necessari": 1.0445450673999999, "removingus": 7.033506484289999, "educ": 0.696807183384, "framework": 6.31255363821, "transfer": 1.00264953547, "nngru": 7.033506484289999, "type": 1.414202970774, "block": 2.32801563176, "hiddens": 63.301558358609995, "note": 0.353817568083, "fals": 7.308591109239999, "accept": 1.657757646021, "method": 0.944461608841, "sequenc": 3.6070888748, "probabl": 0.972882412913, "just": 0.289531434109, "machin": 2.78471916124, "into": 0.0298257264574, "bias": 13.09921382335, "repres": 3.080617862, "dimens": 6.3327662049299995, "abov": 3.21932614908, "understand": 5.440429378399999, "stack": 5.95600351076, "descript": 1.38755491845, "corp": 1.87076341199, "first": 0.0075872898121599995, "what": 0.451774593654, "seqlen": 21.100519452869996, "nonlinear": 18.38955999468, "share": 0.618760299747, "enough": 0.802884439169, "mention": 0.931747186336, "help": 0.672415442688, "affect": 0.908041904384, "clear": 0.617474727198, "find": 0.547781330288, "suffici": 1.4613524521099999, "suggest": 0.563702610877, "learn": 5.899264453215, "multilay": 5.78074351579, "seq": 5.19522699942, "own": 0.328390154842}, "logidf": {"after": 0.020490694648099998, "base": 0.13652330228700002, "natur": 0.431306339292, "can": 0.162341096394, "nnrnn": 7.033506484289999, "bih": 6.964513612799999, "onc": 0.403765872355, "numlayersnumwould": 7.033506484289999, "relat": 0.21310030165399999, "nnrnncell": 7.033506484289999, "here": 0.8850381883700001, "form": 0.120053184191, "data": 1.2168205848, "pass": 0.48130432974, "softwar": 2.32849096333, "recurrentlay": 7.033506484289999, "comput": 1.36806891594, "long": 0.235645793878, "would": 0.0796176279647, "onlin": 0.957503854357, "layer": 2.0969791623500003, "togeth": 0.458032237308, "contain": 0.468845318236, "similar": 0.318556092114, "etc": 1.4366730879700003, "about": 0.0628434774746, "class": 0.7497721899330001, "communiti": 0.673561947791, "neural": 4.0853151555, "gate": 1.78723457463, "optimis": 4.87677326831, "too": 0.5965551547219999, "boolean": 5.22991255741, "python": 4.03065674296, "manner": 1.36905901503, "bridg": 1.31015483629, "nngrucel": 7.033506484289999, "otherwis": 1.3141319148700001, "teacher": 1.5026611665399998, "gap": 1.98823974622, "olah": 7.033506484289999, "numlay": 7.033506484289999, "permiss": 1.8373800586400002, "classifi": 1.6665296351499999, "most": 0.020747896295599998, "check": 1.87281049562, "unit": 0.143188061817, "recommend": 1.36461126863, "hnum": 4.03065674296, "equal": 0.933027391343, "rememb": 1.5867691126199999, "creat": 0.222576818514, "their": 0.015360505122700001, "start": 0.236443369291, "exxact": 7.033506484289999, "vector": 3.25419887797, "articl": 0.702131739574, "kevin": 2.05677274187, "singl": 0.475916769059, "news": 0.733245073485, "million": 0.5469102500940001, "such": 0.059695977806, "format": 0.9287132518729999, "matric": 4.572697386080001, "oftencit": 7.033506484289999, "explain": 0.955700427358, "initi": 0.30010459245, "order": 0.22014038079300002, "for": 0.00031499039539700004, "simpletograsp": 7.033506484289999, "support": 0.237880610037, "social": 0.688371502261, "deep": 1.2886734698, "deconstruct": 4.364296116499999, "will": 0.202786534915, "red": 0.798535691347, "the": 0.0, "recurr": 3.5722448618800002, "build": 0.491137452091, "chris": 1.78836388023, "provid": 0.19517784432500002, "confus": 1.4219437317299999, "bhh": 7.033506484289999, "number": 0.0966085784186, "repost": 6.83935046985, "next": 0.402163685499, "regularis": 6.17605625244, "oper": 0.441342964347, "same": 0.112059649604, "rnns": 7.033506484289999, "need": 0.362740163442, "there": 0.0400978929255, "output": 2.03822657827, "inputs": 7.033506484289999, "tanh": 7.033506484289999, "expect": 0.78850775216, "torchnngrucel": 7.033506484289999, "possibl": 0.348805474891, "key": 0.82419811896, "nnlstmcell": 7.033506484289999, "hidden": 2.0557880052, "level": 0.503462189943, "origin": 0.128612437587, "has": 0.0427239448548, "have": 0.0147850023412, "paramet": 2.8481901438599997, "take": 0.130691962197, "journey": 1.68980611189, "use": 0.0292080197316, "follow": 0.045356911094199995, "default": 3.0511581621399997, "resourc": 1.08137694258, "green": 0.9672326803710001, "name": 0.09723316638430002, "out": 0.0584263909193, "pack": 2.06072141432, "model": 0.7374500731110001, "cheapli": 4.45762805629, "object": 0.853933584803, "basic": 1.00436774895, "intuit": 3.3216780971900004, "much": 0.17749572930100002, "languag": 0.8306818244059999, "cnns": 7.033506484289999, "weak": 1.5487095508000002, "simplest": 3.3339697356999998, "mean": 0.37092128352, "short": 0.345685625679, "not": 0.0155524130075, "henc": 1.68469971782, "shape": 1.16420957115, "batch": 3.5744895317400003, "length": 1.3059609811200001, "encount": 1.4206391000999998, "cudnn": 7.033506484289999, "determin": 0.772833019022, "becom": 0.11771217648900001, "aim": 1.06333853704, "peopl": 0.193265578473, "evolv": 1.52643430388, "postsnumunderstandinglstm": 7.033506484289999, "easi": 1.6665296351499999, "challeng": 0.9392919688950001, "handl": 1.36683266903, "which": 0.00517841384543, "then": 0.08303386523089999, "sinc": 0.0803681994577, "they": 0.0297269947676, "timestep": 7.033506484289999, "blue": 1.1217424415100001, "last": 0.19204364461100001, "prove": 0.899024430345, "get": 0.579769005782, "scienc": 0.841436178891, "task": 1.35748680661, "pytorch": 7.033506484289999, "role": 0.44036410757399996, "student": 0.904923236645, "nonzero": 5.16170430739, "featur": 0.423387418142, "relev": 1.9371304613999998, "tensor": 5.02817291476, "term": 0.33303898354600003, "thus": 0.49857627139300004, "simpl": 1.2232212893899999, "variabl": 2.1687230672, "mine": 1.58430908678, "one": 0.0062553516455, "second": 0.10713976337999999, "two": 0.0136988443582, "either": 0.459327638815, "see": 0.240921585492, "shorter": 2.1072885319999997, "some": 0.0395735090645, "pattern": 1.33282404788, "facebook": 3.3517955196499996, "popular": 0.41058020877499996, "context": 1.44920491442, "webbas": 7.033506484289999, "distil": 3.78368585557, "network": 0.9530830530519999, "like": 0.139053576545, "diagram": 3.09888364694, "beyond": 0.934469583725, "control": 0.38498466158600003, "both": 0.050842533389300004, "except": 0.54202451213, "detect": 1.68878274493, "process": 0.527829199025, "celllevel": 7.033506484289999, "element": 0.8586792558769999, "supervis": 2.04648105583, "cell": 1.9605673068599998, "content": 1.26473915954, "weight": 1.58492352612, "introduc": 0.5457137524260001, "set": 0.171496011289, "ani": 0.125608358366, "pretti": 2.75684036527, "time": 0.0112115188626, "from": 0.000567054168866, "result": 0.136378908381, "perform": 0.42618085058, "work": 0.109034567273, "detail": 0.816187777173, "num": 0.00031499039539700004, "step": 1.03954505698, "andnnlstm": 7.033506484289999, "relu": 7.033506484289999, "idea": 0.73863592212, "numdirect": 7.033506484289999, "analyt": 2.8481901438599997, "return": 0.333126868592, "unrol": 6.305267983919999, "excel": 1.5778801652, "memori": 0.9454338986599999, "torchnngru": 7.033506484289999, "all": 0.011402632097799998, "input": 2.50167533539, "with": 0.00119749171339, "docsstablennhtml": 7.033506484289999, "torchnnlstm": 7.033506484289999, "are": 0.0294674735827, "true": 0.938325629634, "explan": 1.87322041569, "structur": 0.7217716751350001, "that": 0.00397614837964, "torchnnlstmcel": 7.033506484289999, "look": 0.6463866936, "architectur": 1.63469757919, "call": 0.0654627744488, "dropout": 5.1186869223, "final": 0.292733863948, "more": 0.017024931599999998, "and": 6.29901420636e-05, "chanc": 1.44572292349, "fake": 2.9063720992400004, "these": 0.0715336194008, "fuse": 2.9523436587700003, "capabl": 1.2969341868100002, "batchfirst": 7.033506484289999, "bidirect": 5.66523062867, "befor": 0.0956377718795, "comment": 1.11826753454, "again": 0.411340231612, "state": 0.0466100027668, "torchnnrnncel": 7.033506484289999, "doe": 0.5340417297169999, "mandatori": 2.67954869097, "selfexplanatori": 7.033506484289999, "give": 0.311392552224, "make": 0.07349765782289999, "simpler": 2.8858468633, "total": 0.43567888670500005, "torchnnrnn": 7.033506484289999, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "sourc": 0.529218310751, "this": 0.0037864490525, "necessari": 1.0445450673999999, "removingus": 7.033506484289999, "educ": 0.696807183384, "framework": 2.10418454607, "transfer": 1.00264953547, "nngru": 7.033506484289999, "type": 0.707101485387, "block": 1.16400781588, "hiddens": 7.033506484289999, "note": 0.353817568083, "fals": 1.8271477773099998, "accept": 0.552585882007, "method": 0.944461608841, "sequenc": 1.8035444374, "probabl": 0.972882412913, "just": 0.289531434109, "machin": 1.39235958062, "into": 0.0149128632287, "bias": 2.61984276467, "repres": 0.38507723275, "dimens": 2.11092206831, "abov": 0.643865229816, "understand": 1.0880858756799998, "stack": 2.97800175538, "descript": 1.38755491845, "corp": 1.87076341199, "first": 0.0075872898121599995, "what": 0.225887296827, "seqlen": 7.033506484289999, "nonlinear": 4.59738999867, "share": 0.618760299747, "enough": 0.802884439169, "mention": 0.931747186336, "help": 0.336207721344, "affect": 0.908041904384, "clear": 0.617474727198, "find": 0.547781330288, "suffici": 1.4613524521099999, "suggest": 0.563702610877, "learn": 0.842752064745, "multilay": 5.78074351579, "seq": 5.19522699942, "own": 0.164195077421}, "freq": {"after": 1, "base": 2, "natur": 6, "can": 10, "nnrnn": 1, "bih": 2, "onc": 1, "numlayersnumwould": 1, "relat": 3, "nnrnncell": 1, "here": 1, "form": 1, "data": 5, "pass": 2, "softwar": 1, "recurrentlay": 1, "comput": 1, "long": 1, "would": 1, "onlin": 1, "layer": 9, "togeth": 2, "contain": 5, "similar": 3, "etc": 1, "about": 1, "class": 17, "communiti": 1, "neural": 5, "gate": 1, "optimis": 1, "too": 1, "boolean": 1, "python": 2, "manner": 2, "bridg": 1, "nngrucel": 1, "otherwis": 1, "teacher": 2, "gap": 1, "olah": 2, "numlay": 4, "permiss": 1, "classifi": 1, "most": 2, "check": 3, "unit": 1, "recommend": 2, "hnum": 2, "equal": 1, "rememb": 1, "creat": 2, "their": 7, "start": 5, "exxact": 1, "vector": 4, "articl": 5, "kevin": 1, "singl": 3, "news": 2, "million": 1, "such": 4, "format": 2, "matric": 1, "oftencit": 2, "explain": 2, "initi": 2, "order": 1, "for": 20, "simpletograsp": 2, "support": 2, "social": 1, "deep": 6, "deconstruct": 1, "will": 4, "red": 1, "the": 88, "recurr": 8, "build": 6, "chris": 2, "provid": 5, "confus": 1, "bhh": 2, "number": 6, "repost": 1, "next": 1, "regularis": 1, "oper": 1, "same": 7, "rnns": 4, "need": 2, "there": 2, "output": 16, "inputs": 6, "tanh": 4, "expect": 2, "torchnngrucel": 2, "possibl": 1, "key": 2, "nnlstmcell": 1, "hidden": 8, "level": 3, "origin": 1, "has": 1, "have": 9, "paramet": 15, "take": 1, "journey": 2, "use": 15, "follow": 1, "default": 8, "resourc": 1, "green": 1, "name": 1, "out": 4, "pack": 1, "model": 1, "cheapli": 1, "object": 6, "basic": 1, "intuit": 2, "much": 1, "languag": 6, "cnns": 1, "weak": 1, "simplest": 1, "mean": 2, "short": 1, "not": 5, "henc": 3, "shape": 7, "batch": 10, "length": 2, "encount": 2, "cudnn": 1, "determin": 1, "becom": 1, "aim": 1, "peopl": 1, "evolv": 1, "postsnumunderstandinglstm": 3, "easi": 1, "challeng": 2, "handl": 1, "which": 2, "then": 3, "sinc": 2, "they": 2, "timestep": 1, "blue": 1, "last": 2, "prove": 2, "get": 4, "scienc": 2, "task": 2, "pytorch": 14, "role": 1, "student": 2, "nonzero": 1, "featur": 7, "relev": 2, "tensor": 9, "term": 1, "thus": 1, "simpl": 3, "variabl": 1, "mine": 2, "one": 5, "second": 1, "two": 1, "either": 2, "see": 1, "shorter": 1, "some": 1, "pattern": 1, "facebook": 2, "popular": 2, "context": 1, "webbas": 1, "distil": 1, "network": 10, "like": 1, "diagram": 10, "beyond": 1, "control": 1, "both": 2, "except": 1, "detect": 1, "process": 6, "celllevel": 1, "element": 2, "supervis": 1, "cell": 8, "content": 1, "weight": 3, "introduc": 1, "set": 4, "ani": 4, "pretti": 2, "time": 1, "from": 6, "result": 1, "perform": 1, "work": 1, "detail": 1, "num": 16, "step": 1, "andnnlstm": 1, "relu": 2, "idea": 1, "numdirect": 4, "analyt": 2, "return": 3, "unrol": 5, "excel": 2, "memori": 1, "torchnngru": 3, "all": 3, "input": 22, "with": 14, "docsstablennhtml": 1, "torchnnlstm": 3, "are": 13, "true": 5, "explan": 5, "structur": 2, "that": 17, "torchnnlstmcel": 2, "look": 3, "architectur": 2, "call": 1, "dropout": 5, "final": 1, "more": 1, "and": 36, "chanc": 2, "fake": 1, "these": 8, "fuse": 1, "capabl": 1, "batchfirst": 1, "bidirect": 5, "befor": 1, "comment": 1, "again": 2, "state": 6, "torchnnrnncel": 4, "doe": 3, "mandatori": 1, "selfexplanatori": 1, "give": 1, "make": 2, "simpler": 1, "total": 1, "torchnnrnn": 5, "onli": 3, "each": 4, "size": 1, "sourc": 4, "this": 24, "necessari": 1, "removingus": 1, "educ": 1, "framework": 3, "transfer": 1, "nngru": 1, "type": 2, "block": 2, "hiddens": 9, "note": 1, "fals": 4, "accept": 3, "method": 1, "sequenc": 2, "probabl": 1, "just": 1, "machin": 2, "into": 2, "bias": 5, "repres": 8, "dimens": 3, "abov": 5, "understand": 5, "stack": 2, "descript": 1, "corp": 1, "first": 1, "what": 2, "seqlen": 3, "nonlinear": 4, "share": 1, "enough": 1, "mention": 1, "help": 2, "affect": 1, "clear": 1, "find": 1, "suffici": 1, "suggest": 1, "learn": 7, "multilay": 1, "seq": 1, "own": 2}, "idf": {"after": 1.02070207021, "base": 1.14628158845, "natur": 1.5392670157100001, "can": 1.17626139142, "nnrnn": 1134.0, "bih": 1058.4, "onc": 1.4974533106999999, "numlayersnumwould": 1134.0, "relat": 1.23750876919, "nnrnncell": 1134.0, "here": 2.42307692308, "form": 1.12755681818, "data": 3.37643555934, "pass": 1.61818367139, "softwar": 10.2624434389, "recurrentlay": 1134.0, "comput": 3.9277585353800006, "long": 1.2657259028899999, "would": 1.0828729281799998, "onlin": 2.6051854282900004, "layer": 8.14153846154, "togeth": 1.58095996813, "contain": 1.59814777532, "similar": 1.37514075357, "etc": 4.2066772655, "about": 1.06486015159, "class": 2.11651779763, "communiti": 1.96121062384, "neural": 59.4606741573, "gate": 5.97291196388, "optimis": 131.20661157, "too": 1.81585268215, "boolean": 186.776470588, "python": 56.2978723404, "manner": 3.93164933135, "bridg": 3.7067476068199996, "nngrucel": 1134.0, "otherwis": 3.72151898734, "teacher": 4.49363147467, "gap": 7.302667893280001, "olah": 1134.0, "numlay": 1134.0, "permiss": 6.280063291139999, "classifi": 5.2937645882, "most": 1.02096463023, "check": 6.50655737705, "unit": 1.15394679459, "recommend": 3.9142011834300003, "hnum": 56.2978723404, "equal": 2.542193755, "rememb": 4.88793103448, "creat": 1.2492917847, "their": 1.01547908405, "start": 1.26673581744, "exxact": 1134.0, "vector": 25.898858075, "articl": 2.01805008262, "kevin": 7.82068965517, "singl": 1.60948905109, "news": 2.08182533438, "million": 1.7279059643, "such": 1.06151377374, "format": 2.53125, "matric": 96.80487804879999, "oftencit": 1134.0, "explain": 2.60049140049, "initi": 1.35, "order": 1.24625166811, "for": 1.00031504001, "simpletograsp": 1134.0, "support": 1.2685577307200002, "social": 1.9904714142400002, "deep": 3.6279707495399998, "deconstruct": 78.5940594059, "will": 1.22481098596, "red": 2.22228443449, "the": 1.0, "recurr": 35.5964125561, "build": 1.6341739578, "chris": 5.979661016950001, "provid": 1.21552714187, "confus": 4.1451697127900005, "bhh": 1134.0, "number": 1.10142916609, "repost": 933.882352941, "next": 1.4950560316400001, "regularis": 481.09090909099996, "oper": 1.55479384977, "same": 1.11857958148, "rnns": 1134.0, "need": 1.4372623574099999, "there": 1.04091266719, "output": 7.676982591880001, "inputs": 1134.0, "tanh": 1134.0, "expect": 2.20011086475, "torchnngrucel": 1134.0, "possibl": 1.4173734488, "key": 2.28005170185, "nnlstmcell": 1134.0, "hidden": 7.81299212598, "level": 1.6544393497299998, "origin": 1.13724928367, "has": 1.0436497502, "have": 1.0148948411399998, "paramet": 17.256521739100002, "take": 1.13961668222, "journey": 5.41843003413, "use": 1.0296387573799999, "follow": 1.04640126549, "default": 21.1398135819, "resourc": 2.9487369985100003, "green": 2.63065451533, "name": 1.10211732037, "out": 1.06016694491, "pack": 7.85163204748, "model": 2.0905978404, "cheapli": 86.28260869569999, "object": 2.3488681757700003, "basic": 2.7301805675, "intuit": 27.7068062827, "much": 1.1942229577299999, "languag": 2.29488291414, "cnns": 1134.0, "weak": 4.70539419087, "simplest": 28.0494699647, "mean": 1.44906900329, "short": 1.41295834817, "not": 1.01567398119, "henc": 5.390831918509999, "shape": 3.20338983051, "batch": 35.6764044944, "length": 3.69123459661, "encount": 4.13976531943, "cudnn": 1134.0, "determin": 2.1658935879900003, "becom": 1.12492028626, "aim": 2.8960233491400005, "peopl": 1.21320495186, "evolv": 4.60173913043, "postsnumunderstandinglstm": 1134.0, "easi": 5.2937645882, "challeng": 2.55816951337, "handl": 3.9229058561900003, "which": 1.005191845, "then": 1.08657860516, "sinc": 1.08368600683, "they": 1.03017325287, "timestep": 1134.0, "blue": 3.07019918778, "last": 1.2117234010100002, "prove": 2.45720476706, "get": 1.78562591385, "scienc": 2.31969608416, "task": 3.88641370869, "pytorch": 1134.0, "role": 1.55327267391, "student": 2.47174217655, "nonzero": 174.46153846200002, "featur": 1.52712581762, "relev": 6.938811188810001, "tensor": 152.653846154, "term": 1.39520168732, "thus": 1.6463756092500001, "simpl": 3.3981164383599998, "variabl": 8.747107438019999, "mine": 4.875921375919999, "one": 1.00627495722, "second": 1.1130898128, "two": 1.01379310345, "either": 1.5830092731099998, "see": 1.27242125511, "shorter": 8.22590673575, "some": 1.04036697248, "pattern": 3.79173632673, "facebook": 28.5539568345, "popular": 1.50769230769, "context": 4.25972632144, "webbas": 1134.0, "distil": 43.9778393352, "network": 2.59369384088, "like": 1.14918566775, "diagram": 22.1731843575, "beyond": 2.54586273252, "control": 1.46959178006, "both": 1.05215720061, "except": 1.71948445792, "detect": 5.41288782816, "process": 1.69524826482, "celllevel": 1134.0, "element": 2.36004162331, "supervis": 7.74061433447, "cell": 7.1033557047, "content": 3.5421686747, "weight": 4.878918254459999, "introduc": 1.7258397651900002, "set": 1.18707940781, "ani": 1.13383802314, "pretti": 15.75, "time": 1.01127460348, "from": 1.00056721497, "result": 1.14611608432, "perform": 1.5313977042500002, "work": 1.11520089913, "detail": 2.26186066391, "num": 1.00031504001, "step": 2.8279301745599996, "andnnlstm": 1134.0, "relu": 1134.0, "idea": 2.0930784443, "numdirect": 1134.0, "analyt": 17.256521739100002, "return": 1.39532431007, "unrol": 547.448275862, "excel": 4.84467500763, "memori": 2.57392996109, "torchnngru": 1134.0, "all": 1.01146788991, "input": 12.2029208301, "with": 1.0011982089899998, "docsstablennhtml": 1134.0, "torchnnlstm": 1134.0, "are": 1.02990593578, "true": 2.55569864778, "explan": 6.50922509225, "structur": 2.0580762250499998, "that": 1.00398406375, "torchnnlstmcel": 1134.0, "look": 1.9086318826599997, "architectur": 5.12790697674, "call": 1.0676529926, "dropout": 167.115789474, "final": 1.34008609775, "more": 1.0171706817, "and": 1.00006299213, "chanc": 4.2449197861000005, "fake": 18.290322580599998, "these": 1.07415426252, "fuse": 19.1507840772, "capabl": 3.6580645161300005, "batchfirst": 1134.0, "bidirect": 288.654545455, "befor": 1.10036041031, "comment": 3.05954904606, "again": 1.50883862384, "state": 1.0477133240899998, "torchnnrnncel": 1134.0, "doe": 1.70581282905, "mandatori": 14.5785123967, "selfexplanatori": 1134.0, "give": 1.3653250774, "make": 1.0762660158600001, "simpler": 17.9187358916, "total": 1.5460122699399999, "torchnnrnn": 1134.0, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "sourc": 1.69760479042, "this": 1.00379362671, "necessari": 2.8421052631599997, "removingus": 1134.0, "educ": 2.00733341763, "framework": 8.200413223139998, "transfer": 2.72549356223, "nngru": 1134.0, "type": 2.0281042411900003, "block": 3.20274359492, "hiddens": 1134.0, "note": 1.42449528937, "fals": 6.21613155834, "accept": 1.7377408056, "method": 2.5714285714300003, "sequenc": 6.07112810707, "probabl": 2.64555907349, "just": 1.33580143037, "machin": 4.02433460076, "into": 1.01502461479, "bias": 13.7335640138, "repres": 1.46972782818, "dimens": 8.25585023401, "abov": 1.90382539873, "understand": 2.96858638743, "stack": 19.6485148515, "descript": 4.00504540868, "corp": 6.4932515337400005, "first": 1.00761614623, "what": 1.25343439128, "seqlen": 1134.0, "nonlinear": 99.225, "share": 1.8566249561500001, "enough": 2.2319696330700003, "mention": 2.53894130817, "help": 1.39962972759, "affect": 2.4794627518400003, "clear": 1.85423966363, "find": 1.7294117647099998, "suffici": 4.3117870722400005, "suggest": 1.7571665744299998, "learn": 2.32275054865, "multilay": 324.0, "seq": 180.409090909, "own": 1.17844418052}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Getting started with NLP using the PyTorch framework</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/nlp-pytorch.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Getting started with NLP using the PyTorch framework Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html\" rel=\"prev\" title=\"How to DIY Your Data Science Education\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html\" rel=\"next\" title=\"Grow your data career at DataScienceGO, San Diego, Sep 27-29\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/04/nlp-pytorch.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=92506\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/nlp-pytorch.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-92506 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 3-Apr, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Getting started with NLP using the PyTorch framework (\u00a0<a href=\"/2019/n14.html\">19:n14</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Getting started with NLP using the PyTorch framework</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/pytorch\" rel=\"tag\">PyTorch</a>, <a href=\"https://www.kdnuggets.com/tag/recurrent-neural-networks\" rel=\"tag\">Recurrent Neural Networks</a></div>\n<br/>\n<p class=\"excerpt\">\n     We discuss the classes that PyTorch provides for helping with Natural Language Processing (NLP) and how they can be used for related tasks using recurrent layers.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By Kevin Vu, Exxact Corp</b>.</p>\n<p>PyTorch is one of the most popular\u00a0<a href=\"https://blog.exxactcorp.com/evaluating-popular-deep-learning-frameworks/\">Deep Learning frameworks</a>\u00a0that is based on Python and is supported by Facebook.</p>\n<p>In this article we will be looking into the classes that PyTorch provides for helping with Natural Language Processing (NLP).</p>\n<p>There are 6 classes in PyTorch that can be used for NLP related tasks using recurrent layers:</p>\n<ul>\n<li>torch.nn.RNN</li>\n<li>torch.nn.LSTM</li>\n<li>torch.nn.GRU</li>\n<li>torch.nn.RNNCell</li>\n<li>torch.nn.LSTMCell</li>\n<li>torch.nn.GRUCell</li>\n</ul>\n<p>Understanding these classes, their parameters, their inputs and their outputs are key to getting started with building your own neural networks for Natural Language Processing (NLP) in Pytorch.</p>\n<p>If you have started your NLP journey, chances are that you have encountered a similar type of diagram (if not, we recommend that you check out this excellent and often-cited article by Chris Olah\u200a\u2014\u200a<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>):</p>\n<p><img src=\"https://i2.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/1_PMeuhAtbcNskcO6qBJETvA.png?resize=300%2C96&amp;ssl=1\" width=\"50%\"/></p>\n<p><strong>Source\u200a\u2014\u200a\u00a0<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></strong></p>\n<p>Such unrolled diagrams are used by teachers to provide students with a simple-to-grasp explanation of the recurrent structure of such neural networks. Going from these pretty, unrolled diagrams and intuitive explanations to the Pytorch API can prove to be challenging.</p>\n<p><img src=\"https://i1.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/1_ii9ye0UrBHCcPfSzto64PA.png?w=800&amp;ssl=1\" width=\"100%\"/></p>\n<p>PyTorch is one of the most popular\u00a0<a href=\"https://blog.exxactcorp.com/evaluating-popular-deep-learning-frameworks/\">Deep Learning frameworks</a>\u00a0that is based on Python and is supported by Facebook.</p>\n<p>In this article we will be looking into the classes that PyTorch provides for helping with Natural Language Processing (NLP).</p>\n<p>There are 6 classes in PyTorch that can be used for NLP related tasks using recurrent layers:</p>\n<ul>\n<li>torch.nn.RNN</li>\n<li>torch.nn.LSTM</li>\n<li>torch.nn.GRU</li>\n<li>torch.nn.RNNCell</li>\n<li>torch.nn.LSTMCell</li>\n<li>torch.nn.GRUCell</li>\n</ul>\n<p>Understanding these classes, their parameters, their inputs and their outputs are key to getting started with building your own neural networks for Natural Language Processing (NLP) in Pytorch.</p>\n<p>If you have started your NLP journey, chances are that you have encountered a similar type of diagram (if not, we recommend that you check out this excellent and often-cited article by Chris Olah\u200a\u2014\u200a<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>):</p>\n<p>Source\u200a\u2014\u200a\u00a0<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>\n<p>Such unrolled diagrams are used by teachers to provide students with a simple-to-grasp explanation of the recurrent structure of such neural networks. Going from these pretty, unrolled diagrams and intuitive explanations to the Pytorch API can prove to be challenging.</p>\n<p>Source \u2014<a href=\"https://pytorch.org/docs/stable/nn.html#recurrent-layers\">https://pytorch.org/docs/stable/nn.html#recurrent-layers</a></p>\n<p>Hence, in this article, we aim to bridge that gap by explaining the parameters, inputs and the outputs of the relevant classes in PyTorch in a clear and descriptive manner.</p>\n<p>Pytorch basically has 2 levels of classes for building recurrent networks:</p>\n<ul>\n<li><strong>Multi-layer classes\u200a\u2014\u200ann.RNN\u00a0,\u00a0nn.GRU\u00a0andnn.LSTM</strong>\u00a0<strong><br>\n</br></strong>Objects of these classes are capable of representing deep bidirectional recurrent neural networks (<em>or, as the class names suggest, one of more their evolved architectures\u200a\u2014\u200aGated Recurrent Unit (GRU) or Long Short Term Memory (LSTM) networks</em>).</li>\n<li><strong>Cell-level classes\u200a\u2014\u200ann.RNNCell\u00a0,\u00a0nn.GRUCell\u00a0and\u00a0nn.LSTMCell</strong>\u00a0<strong><br>\n</br></strong>Objects of these classes can represent only a single cell\u00a0<em>(again, a simple RNN or LSTM or GRU cell)</em>\u00a0that can handle one timestep of the input data.\u00a0<em>(Remember, these Cells don\u2019t have cuDNN optimisation and thus don\u2019t have any fused operations, etc.)</em></li>\n</ul>\n<p>All the classes in the same level share the same API. Hence, understanding the parameters, inputs and outputs of any one of the classes in both the above levels is enough.</p>\n<p><strong>To make explanations simple, we will use the simplest classes\u200a\u2014\u200atorch.nn.RNN\u00a0and\u00a0torch.nn.RNNCell</strong></p>\n<h3>torch.nn.RNN :</h3>\n<p>We will use the following diagram to explain the API\u200a\u2014</p>\n<p><img src=\"https://i2.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/1_nTRob0WQCYG9PDSDkh4hAA.png?resize=300%2C89&amp;ssl=1\" width=\"50%\"/></p>\n<p>Source\u200a\u2014\u200a<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>\n<h4>Parameters:</h4>\n<ul>\n<li><strong>input_size</strong>\u200a\u2014\u200aThe number of expected features in the input x</li>\n</ul>\n<p>This represents the dimensions of vector x[i] (i.e, any of the vectors from x[0] to x[t] in the above diagram). Note that it is easy to confuse this with the sequence length, which is the total number of cells that we get after unrolling the RNN as above.</p>\n<ul>\n<li><strong>hidden_size</strong>\u200a\u2014\u200aThe number of features in the hidden state h</li>\n</ul>\n<p>This represents the dimension of vector h[i] (i.e, any of the vectors from h[0] to h[t] in the above diagram). Together,\u00a0hidden_size\u00a0and\u00a0input_size\u00a0are necessary and sufficient in determining the shape of the weight matrices of the network.</p>\n<ul>\n<li><strong>num_layers</strong>\u200a\u2014\u200aNumber of recurrent layers. E.g., setting\u00a0num_layers=2would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1</li>\n</ul>\n<p>This parameter is used to build deep RNNs like these:</p>\n<p><img src=\"https://i0.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/0_iLv3Tisjx68QrYU7.png?resize=257%2C300&amp;ssl=1\" width=\"50%\"/></p>\n<p>Here red cells represent the inputs, green blocks represent the RNN cells and blue blocks represent the output.</p>\n<p>So for the above diagram, we would set the\u00a0num_layers\u00a0parameter to 3.</p>\n<ul>\n<li><strong>nonlinearity</strong>\u200a\u2014\u200aThe non-linearity to use. Can be either \u2018tanh\u2019 or \u2018relu\u2019. Default: \u2018tanh\u2019</li>\n</ul>\n<p>This is self-explanatory.</p>\n<ul>\n<li><strong>bias</strong>\u200a\u2014\u200aIf\u00a0False, then the layer does not use bias weights b_ih and b_hh. Default:\u00a0True</li>\n</ul>\n<p>In the Deep Learning community, some people find that removing/using bias does not affect the model\u2019s performance. Hence, this boolean parameter.</p>\n<ul>\n<li><strong>batch_first</strong>\u200a\u2014\u200aIf\u00a0True, then the input and output tensors are provided as (batch, seq, feature). Default:\u00a0False</li>\n<li><strong>dropout</strong>\u200a\u2014\u200aIf non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to\u00a0dropout. Default: 0</li>\n</ul>\n<p>This parameter is used to control the dropout regularisation method in the RNN architecture.</p>\n<ul>\n<li><strong>bidirectional</strong>\u200a\u2014\u200aIf\u00a0True, becomes a bidirectional RNN. Default:\u00a0False</li>\n</ul>\n<p>Creating a bidirectional RNN is as simple as setting this parameter to True!</p>\n<p>So, to make an RNN in PyTorch, we need to pass 2 mandatory parameters to the class\u200a\u2014\u200ainput_size\u00a0and\u00a0hidden_size.</p>\n<p>Once we have created an object, we can \u201ccall\u201d the object with the relevant inputs and it returns outputs.</p>\n<h4>Inputs:</h4>\n<p>We need to pass 2 inputs to the object\u200a\u2014\u200ainput\u00a0and\u00a0h_0\u00a0:</p>\n<ul>\n<li><strong>input</strong>\u200a\u2014\u200aThis is a tensor of shape\u00a0<em>(seq_len, batch, input_size).\u00a0</em>In order to work with variable lengthed inputs, we pack the shorter input sequences. See\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence\">torch.nn.utils.rnn.pack_padded_sequence()</a>\u00a0or<a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence\">torch.nn.utils.rnn.pack_sequence()</a>\u00a0for details.</li>\n<li><strong>h_0</strong>\u200a\u2014\u200aThis is a tensor of shape (num_layers * num_directions, batch, hidden_size).\u00a0num_directions\u00a0is 2 for bidirectional RNNs and 1 otherwise. This tensor contains the initial hidden state for each element in the batch.</li>\n</ul>\n<p><strong>Outputs</strong>:</p>\n<p>In a similar manner, the object returns 2 outputs to us\u200a\u2014\u200aoutput\u00a0and\u00a0h_n\u00a0:</p>\n<ul>\n<li><strong>output</strong>\u200a\u2014\u200aThis is a tensor of shape\u00a0<em>(seq_len, batch, num_directions * hidden_size).\u00a0</em>It contains\u00a0the output features (h_k) from the last layer of the RNN, for each k.</li>\n<li><strong>h_n</strong>\u200a\u2014\u200aThis is a tensor of size (num_layers * num_directions, batch, hidden_size). It contains the hidden state for k = seq_len.</li>\n</ul>\n<p>As mentioned before, both\u00a0torch.nn.GRU\u00a0and\u00a0torch.nn.LSTM\u00a0have the same API, i.e, they accept the same set of parameters and accept inputs in the same format and return out in the same format too.</p>\n<h3>torch.nn.RNNCell :</h3>\n<p>Since this represents only a single cell of the RNN, it accepts only 4 parameters, all of which have the same meaning as they did in\u00a0torch.nn.RNN\u00a0.</p>\n<h4>Parameters:</h4>\n<ul>\n<li><strong>input_size</strong>\u200a\u2014\u200aThe number of expected features in the input x</li>\n<li><strong>hidden_size</strong>\u200a\u2014\u200aThe number of features in the hidden state h</li>\n<li><strong>bias</strong>\u200a\u2014\u200aIf\u00a0False, then the layer does not use bias weights b_ih and b_hh. Default:\u00a0True</li>\n<li><strong>nonlinearity</strong>\u200a\u2014\u200aThe non-linearity to use. Can be either \u2018tanh\u2019 or \u2018relu\u2019. Default: \u2018tanh\u2019</li>\n</ul>\n<p>Again, since this is just a single cell of an RNN, the input and output dimensions are much simpler\u200a\u2014</p>\n<h4>Inputs (input, hidden):</h4>\n<ul>\n<li><strong>input</strong>\u200a\u2014\u200athis is a tensor of shape (batch, input_size) that contains the input features.</li>\n<li><strong>hidden</strong>\u200a\u2014\u200athis is a tensor of shape (batch, hidden_size) that contains the initial hidden states for each of the elements in the batch.</li>\n</ul>\n<h4>Output:</h4>\n<ul>\n<li><strong>h\u2019\u200a</strong>\u2014\u200athis is a tensor of shape (batch, hidden_size) and it gives us the hidden state for the next time step.</li>\n</ul>\n<p>This was all about getting started with the PyTorch framework for Natural Language Processing (NLP). If you are looking for ideas on what is possible and what you can build, check out\u200a\u2014\u200a<a href=\"https://blog.exxactcorp.com/deep-learning-for-natural-language-processing/\">Deep Learning for Natural Language Processing using RNNs and CNNs</a>.</p>\n<p><a href=\"https://blog.exxactcorp.com/getting-started-with-natural-language-processing-using-pytorch/\">Original</a>. Reposted with permission.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/03/building-nlp-classifiers-cheaply-transfer-learning-weak-supervision.html\">Building NLP Classifiers Cheaply With Transfer Learning and Weak Supervision</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/03/beyond-news-contents-role-of-social-context-for-fake-news-detection.html\">Beyond news contents: the role of social context for fake news detection</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/02/deconstructing-bert-distilling-patterns-100-million-parameters.html\">Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Getting started with NLP using the PyTorch framework (\u00a0<a href=\"/2019/n14.html\">19:n14</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556326848\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.731 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 21:00:48 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "kevin", "exxact", "corp", "pytorch", "one", "the", "most", "popular", "deep", "learn", "framework", "that", "base", "python", "and", "support", "facebook", "this", "articl", "will", "look", "into", "the", "class", "that", "pytorch", "provid", "for", "help", "with", "natur", "languag", "process", "there", "are", "num", "class", "pytorch", "that", "can", "use", "for", "relat", "task", "use", "recurr", "layer", "torchnnrnn", "torchnnlstm", "torchnngru", "torchnnrnncel", "torchnnlstmcel", "torchnngrucel", "understand", "these", "class", "their", "paramet", "their", "input", "and", "their", "output", "are", "key", "get", "start", "with", "build", "own", "neural", "network", "for", "natur", "languag", "process", "pytorch", "have", "start", "journey", "chanc", "are", "that", "have", "encount", "similar", "type", "diagram", "not", "recommend", "that", "check", "out", "this", "excel", "and", "oftencit", "articl", "chris", "olah", "understand", "network", "sourc", "postsnumunderstandinglstm", "such", "unrol", "diagram", "are", "use", "teacher", "provid", "student", "with", "simpletograsp", "explan", "the", "recurr", "structur", "such", "neural", "network", "from", "these", "pretti", "unrol", "diagram", "and", "intuit", "explan", "the", "pytorch", "can", "prove", "challeng", "pytorch", "one", "the", "most", "popular", "deep", "learn", "framework", "that", "base", "python", "and", "support", "facebook", "this", "articl", "will", "look", "into", "the", "class", "that", "pytorch", "provid", "for", "help", "with", "natur", "languag", "process", "there", "are", "num", "class", "pytorch", "that", "can", "use", "for", "relat", "task", "use", "recurr", "layer", "torchnnrnn", "torchnnlstm", "torchnngru", "torchnnrnncel", "torchnnlstmcel", "torchnngrucel", "understand", "these", "class", "their", "paramet", "their", "input", "and", "their", "output", "are", "key", "get", "start", "with", "build", "own", "neural", "network", "for", "natur", "languag", "process", "pytorch", "have", "start", "journey", "chanc", "are", "that", "have", "encount", "similar", "type", "diagram", "not", "recommend", "that", "check", "out", "this", "excel", "and", "oftencit", "articl", "chris", "olah", "understand", "network", "sourc", "postsnumunderstandinglstm", "such", "unrol", "diagram", "are", "use", "teacher", "provid", "student", "with", "simpletograsp", "explan", "the", "recurr", "structur", "such", "neural", "network", "from", "these", "pretti", "unrol", "diagram", "and", "intuit", "explan", "the", "pytorch", "can", "prove", "challeng", "sourc", "docsstablennhtml", "recurrentlay", "henc", "this", "articl", "aim", "bridg", "that", "gap", "explain", "the", "paramet", "input", "and", "the", "output", "the", "relev", "class", "pytorch", "clear", "and", "descript", "manner", "pytorch", "basic", "has", "num", "level", "class", "for", "build", "recurr", "network", "multilay", "class", "nnrnn", "nngru", "andnnlstm", "object", "these", "class", "are", "capabl", "repres", "deep", "bidirect", "recurr", "neural", "network", "the", "class", "name", "suggest", "one", "more", "their", "evolv", "architectur", "gate", "recurr", "unit", "long", "short", "term", "memori", "network", "celllevel", "class", "nnrnncell", "nngrucel", "and", "nnlstmcell", "object", "these", "class", "can", "repres", "onli", "singl", "cell", "again", "simpl", "cell", "that", "can", "handl", "one", "timestep", "the", "input", "data", "rememb", "these", "cell", "have", "cudnn", "optimis", "and", "thus", "have", "ani", "fuse", "oper", "etc", "all", "the", "class", "the", "same", "level", "share", "the", "same", "henc", "understand", "the", "paramet", "input", "and", "output", "ani", "one", "the", "class", "both", "the", "abov", "level", "enough", "make", "explan", "simpl", "will", "use", "the", "simplest", "class", "torchnnrnn", "and", "torchnnrnncel", "torchnnrnn", "will", "use", "the", "follow", "diagram", "explain", "the", "sourc", "postsnumunderstandinglstm", "paramet", "inputs", "the", "number", "expect", "featur", "the", "input", "this", "repres", "the", "dimens", "vector", "ani", "the", "vector", "from", "num", "the", "abov", "diagram", "note", "that", "easi", "confus", "this", "with", "the", "sequenc", "length", "which", "the", "total", "number", "cell", "that", "get", "after", "unrol", "the", "abov", "hiddens", "the", "number", "featur", "the", "hidden", "state", "this", "repres", "the", "dimens", "vector", "ani", "the", "vector", "from", "num", "the", "abov", "diagram", "togeth", "hiddens", "and", "inputs", "are", "necessari", "and", "suffici", "determin", "the", "shape", "the", "weight", "matric", "the", "network", "numlay", "number", "recurr", "layer", "set", "numlayersnumwould", "mean", "stack", "two", "rnns", "togeth", "form", "stack", "with", "the", "second", "take", "output", "the", "first", "and", "comput", "the", "final", "result", "default", "num", "this", "paramet", "use", "build", "deep", "rnns", "like", "these", "here", "red", "cell", "repres", "the", "input", "green", "block", "repres", "the", "cell", "and", "blue", "block", "repres", "the", "output", "for", "the", "abov", "diagram", "would", "set", "the", "numlay", "paramet", "num", "nonlinear", "the", "nonlinear", "use", "can", "either", "tanh", "relu", "default", "tanh", "this", "selfexplanatori", "bias", "fals", "then", "the", "layer", "doe", "not", "use", "bias", "weight", "bih", "and", "bhh", "default", "true", "the", "deep", "learn", "communiti", "some", "peopl", "find", "that", "removingus", "bias", "doe", "not", "affect", "the", "model", "perform", "henc", "this", "boolean", "paramet", "batchfirst", "true", "then", "the", "input", "and", "output", "tensor", "are", "provid", "batch", "seq", "featur", "default", "fals", "dropout", "nonzero", "introduc", "dropout", "layer", "the", "output", "each", "layer", "except", "the", "last", "layer", "with", "dropout", "probabl", "equal", "dropout", "default", "num", "this", "paramet", "use", "control", "the", "dropout", "regularis", "method", "the", "architectur", "bidirect", "true", "becom", "bidirect", "default", "fals", "creat", "bidirect", "simpl", "set", "this", "paramet", "true", "make", "pytorch", "need", "pass", "num", "mandatori", "paramet", "the", "class", "inputs", "and", "hiddens", "onc", "have", "creat", "object", "can", "call", "the", "object", "with", "the", "relev", "input", "and", "return", "output", "input", "need", "pass", "num", "input", "the", "object", "input", "and", "hnum", "input", "this", "tensor", "shape", "seqlen", "batch", "inputs", "order", "work", "with", "variabl", "length", "input", "pack", "the", "shorter", "input", "sequenc", "see", "for", "detail", "hnum", "this", "tensor", "shape", "numlay", "numdirect", "batch", "hiddens", "numdirect", "num", "for", "bidirect", "rnns", "and", "num", "otherwis", "this", "tensor", "contain", "the", "initi", "hidden", "state", "for", "each", "element", "the", "batch", "output", "similar", "manner", "the", "object", "return", "num", "output", "output", "and", "output", "this", "tensor", "shape", "seqlen", "batch", "numdirect", "hiddens", "contain", "the", "output", "featur", "from", "the", "last", "layer", "the", "for", "each", "this", "tensor", "size", "numlay", "numdirect", "batch", "hiddens", "contain", "the", "hidden", "state", "for", "seqlen", "mention", "befor", "both", "torchnngru", "and", "torchnnlstm", "have", "the", "same", "they", "accept", "the", "same", "set", "paramet", "and", "accept", "input", "the", "same", "format", "and", "return", "out", "the", "same", "format", "too", "torchnnrnncel", "sinc", "this", "repres", "onli", "singl", "cell", "the", "accept", "onli", "num", "paramet", "all", "which", "have", "the", "same", "mean", "they", "torchnnrnn", "paramet", "inputs", "the", "number", "expect", "featur", "the", "input", "hiddens", "the", "number", "featur", "the", "hidden", "state", "bias", "fals", "then", "the", "layer", "doe", "not", "use", "bias", "weight", "bih", "and", "bhh", "default", "true", "nonlinear", "the", "nonlinear", "use", "can", "either", "tanh", "relu", "default", "tanh", "again", "sinc", "this", "just", "singl", "cell", "the", "input", "and", "output", "dimens", "are", "much", "simpler", "input", "input", "hidden", "input", "this", "tensor", "shape", "batch", "inputs", "that", "contain", "the", "input", "featur", "hidden", "this", "tensor", "shape", "batch", "hiddens", "that", "contain", "the", "initi", "hidden", "state", "for", "each", "the", "element", "the", "batch", "output", "this", "tensor", "shape", "batch", "hiddens", "and", "give", "the", "hidden", "state", "for", "the", "next", "time", "step", "this", "all", "about", "get", "start", "with", "the", "pytorch", "framework", "for", "natur", "languag", "process", "are", "look", "for", "idea", "what", "possibl", "and", "what", "can", "build", "check", "out", "deep", "learn", "for", "natur", "languag", "process", "use", "rnns", "and", "cnns", "origin", "repost", "with", "permiss", "resourc", "onlin", "and", "webbas", "analyt", "data", "mine", "data", "scienc", "machin", "learn", "educ", "softwar", "for", "analyt", "data", "scienc", "data", "mine", "and", "machin", "learn", "relat", "build", "classifi", "cheapli", "with", "transfer", "learn", "and", "weak", "supervis", "beyond", "news", "content", "the", "role", "social", "context", "for", "fake", "news", "detect", "deconstruct", "distil", "num", "pattern", "from", "num", "million", "paramet"], "timestamp_scraper": 1556362677.421488, "title": "Getting started with NLP using the PyTorch framework", "read_time": 388.5, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By Kevin Vu, Exxact Corp</b>.</p>\n<p>PyTorch is one of the most popular\u00a0<a href=\"https://blog.exxactcorp.com/evaluating-popular-deep-learning-frameworks/\">Deep Learning frameworks</a>\u00a0that is based on Python and is supported by Facebook.</p>\n<p>In this article we will be looking into the classes that PyTorch provides for helping with Natural Language Processing (NLP).</p>\n<p>There are 6 classes in PyTorch that can be used for NLP related tasks using recurrent layers:</p>\n<ul>\n<li>torch.nn.RNN</li>\n<li>torch.nn.LSTM</li>\n<li>torch.nn.GRU</li>\n<li>torch.nn.RNNCell</li>\n<li>torch.nn.LSTMCell</li>\n<li>torch.nn.GRUCell</li>\n</ul>\n<p>Understanding these classes, their parameters, their inputs and their outputs are key to getting started with building your own neural networks for Natural Language Processing (NLP) in Pytorch.</p>\n<p>If you have started your NLP journey, chances are that you have encountered a similar type of diagram (if not, we recommend that you check out this excellent and often-cited article by Chris Olah\u200a\u2014\u200a<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>):</p>\n<p><img src=\"https://i2.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/1_PMeuhAtbcNskcO6qBJETvA.png?resize=300%2C96&amp;ssl=1\" width=\"50%\"/></p>\n<p><strong>Source\u200a\u2014\u200a\u00a0<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></strong></p>\n<p>Such unrolled diagrams are used by teachers to provide students with a simple-to-grasp explanation of the recurrent structure of such neural networks. Going from these pretty, unrolled diagrams and intuitive explanations to the Pytorch API can prove to be challenging.</p>\n<p><img src=\"https://i1.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/1_ii9ye0UrBHCcPfSzto64PA.png?w=800&amp;ssl=1\" width=\"100%\"/></p>\n<p>PyTorch is one of the most popular\u00a0<a href=\"https://blog.exxactcorp.com/evaluating-popular-deep-learning-frameworks/\">Deep Learning frameworks</a>\u00a0that is based on Python and is supported by Facebook.</p>\n<p>In this article we will be looking into the classes that PyTorch provides for helping with Natural Language Processing (NLP).</p>\n<p>There are 6 classes in PyTorch that can be used for NLP related tasks using recurrent layers:</p>\n<ul>\n<li>torch.nn.RNN</li>\n<li>torch.nn.LSTM</li>\n<li>torch.nn.GRU</li>\n<li>torch.nn.RNNCell</li>\n<li>torch.nn.LSTMCell</li>\n<li>torch.nn.GRUCell</li>\n</ul>\n<p>Understanding these classes, their parameters, their inputs and their outputs are key to getting started with building your own neural networks for Natural Language Processing (NLP) in Pytorch.</p>\n<p>If you have started your NLP journey, chances are that you have encountered a similar type of diagram (if not, we recommend that you check out this excellent and often-cited article by Chris Olah\u200a\u2014\u200a<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>):</p>\n<p>Source\u200a\u2014\u200a\u00a0<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>\n<p>Such unrolled diagrams are used by teachers to provide students with a simple-to-grasp explanation of the recurrent structure of such neural networks. Going from these pretty, unrolled diagrams and intuitive explanations to the Pytorch API can prove to be challenging.</p>\n<p>Source \u2014<a href=\"https://pytorch.org/docs/stable/nn.html#recurrent-layers\">https://pytorch.org/docs/stable/nn.html#recurrent-layers</a></p>\n<p>Hence, in this article, we aim to bridge that gap by explaining the parameters, inputs and the outputs of the relevant classes in PyTorch in a clear and descriptive manner.</p>\n<p>Pytorch basically has 2 levels of classes for building recurrent networks:</p>\n<ul>\n<li><strong>Multi-layer classes\u200a\u2014\u200ann.RNN\u00a0,\u00a0nn.GRU\u00a0andnn.LSTM</strong>\u00a0<strong><br>\n</br></strong>Objects of these classes are capable of representing deep bidirectional recurrent neural networks (<em>or, as the class names suggest, one of more their evolved architectures\u200a\u2014\u200aGated Recurrent Unit (GRU) or Long Short Term Memory (LSTM) networks</em>).</li>\n<li><strong>Cell-level classes\u200a\u2014\u200ann.RNNCell\u00a0,\u00a0nn.GRUCell\u00a0and\u00a0nn.LSTMCell</strong>\u00a0<strong><br>\n</br></strong>Objects of these classes can represent only a single cell\u00a0<em>(again, a simple RNN or LSTM or GRU cell)</em>\u00a0that can handle one timestep of the input data.\u00a0<em>(Remember, these Cells don\u2019t have cuDNN optimisation and thus don\u2019t have any fused operations, etc.)</em></li>\n</ul>\n<p>All the classes in the same level share the same API. Hence, understanding the parameters, inputs and outputs of any one of the classes in both the above levels is enough.</p>\n<p><strong>To make explanations simple, we will use the simplest classes\u200a\u2014\u200atorch.nn.RNN\u00a0and\u00a0torch.nn.RNNCell</strong></p>\n<h3>torch.nn.RNN :</h3>\n<p>We will use the following diagram to explain the API\u200a\u2014</p>\n<p><img src=\"https://i2.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/1_nTRob0WQCYG9PDSDkh4hAA.png?resize=300%2C89&amp;ssl=1\" width=\"50%\"/></p>\n<p>Source\u200a\u2014\u200a<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>\n<h4>Parameters:</h4>\n<ul>\n<li><strong>input_size</strong>\u200a\u2014\u200aThe number of expected features in the input x</li>\n</ul>\n<p>This represents the dimensions of vector x[i] (i.e, any of the vectors from x[0] to x[t] in the above diagram). Note that it is easy to confuse this with the sequence length, which is the total number of cells that we get after unrolling the RNN as above.</p>\n<ul>\n<li><strong>hidden_size</strong>\u200a\u2014\u200aThe number of features in the hidden state h</li>\n</ul>\n<p>This represents the dimension of vector h[i] (i.e, any of the vectors from h[0] to h[t] in the above diagram). Together,\u00a0hidden_size\u00a0and\u00a0input_size\u00a0are necessary and sufficient in determining the shape of the weight matrices of the network.</p>\n<ul>\n<li><strong>num_layers</strong>\u200a\u2014\u200aNumber of recurrent layers. E.g., setting\u00a0num_layers=2would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1</li>\n</ul>\n<p>This parameter is used to build deep RNNs like these:</p>\n<p><img src=\"https://i0.wp.com/blog.exxactcorp.com/wp-content/uploads/2019/01/0_iLv3Tisjx68QrYU7.png?resize=257%2C300&amp;ssl=1\" width=\"50%\"/></p>\n<p>Here red cells represent the inputs, green blocks represent the RNN cells and blue blocks represent the output.</p>\n<p>So for the above diagram, we would set the\u00a0num_layers\u00a0parameter to 3.</p>\n<ul>\n<li><strong>nonlinearity</strong>\u200a\u2014\u200aThe non-linearity to use. Can be either \u2018tanh\u2019 or \u2018relu\u2019. Default: \u2018tanh\u2019</li>\n</ul>\n<p>This is self-explanatory.</p>\n<ul>\n<li><strong>bias</strong>\u200a\u2014\u200aIf\u00a0False, then the layer does not use bias weights b_ih and b_hh. Default:\u00a0True</li>\n</ul>\n<p>In the Deep Learning community, some people find that removing/using bias does not affect the model\u2019s performance. Hence, this boolean parameter.</p>\n<ul>\n<li><strong>batch_first</strong>\u200a\u2014\u200aIf\u00a0True, then the input and output tensors are provided as (batch, seq, feature). Default:\u00a0False</li>\n<li><strong>dropout</strong>\u200a\u2014\u200aIf non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to\u00a0dropout. Default: 0</li>\n</ul>\n<p>This parameter is used to control the dropout regularisation method in the RNN architecture.</p>\n<ul>\n<li><strong>bidirectional</strong>\u200a\u2014\u200aIf\u00a0True, becomes a bidirectional RNN. Default:\u00a0False</li>\n</ul>\n<p>Creating a bidirectional RNN is as simple as setting this parameter to True!</p>\n<p>So, to make an RNN in PyTorch, we need to pass 2 mandatory parameters to the class\u200a\u2014\u200ainput_size\u00a0and\u00a0hidden_size.</p>\n<p>Once we have created an object, we can \u201ccall\u201d the object with the relevant inputs and it returns outputs.</p>\n<h4>Inputs:</h4>\n<p>We need to pass 2 inputs to the object\u200a\u2014\u200ainput\u00a0and\u00a0h_0\u00a0:</p>\n<ul>\n<li><strong>input</strong>\u200a\u2014\u200aThis is a tensor of shape\u00a0<em>(seq_len, batch, input_size).\u00a0</em>In order to work with variable lengthed inputs, we pack the shorter input sequences. See\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence\">torch.nn.utils.rnn.pack_padded_sequence()</a>\u00a0or<a href=\"https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence\">torch.nn.utils.rnn.pack_sequence()</a>\u00a0for details.</li>\n<li><strong>h_0</strong>\u200a\u2014\u200aThis is a tensor of shape (num_layers * num_directions, batch, hidden_size).\u00a0num_directions\u00a0is 2 for bidirectional RNNs and 1 otherwise. This tensor contains the initial hidden state for each element in the batch.</li>\n</ul>\n<p><strong>Outputs</strong>:</p>\n<p>In a similar manner, the object returns 2 outputs to us\u200a\u2014\u200aoutput\u00a0and\u00a0h_n\u00a0:</p>\n<ul>\n<li><strong>output</strong>\u200a\u2014\u200aThis is a tensor of shape\u00a0<em>(seq_len, batch, num_directions * hidden_size).\u00a0</em>It contains\u00a0the output features (h_k) from the last layer of the RNN, for each k.</li>\n<li><strong>h_n</strong>\u200a\u2014\u200aThis is a tensor of size (num_layers * num_directions, batch, hidden_size). It contains the hidden state for k = seq_len.</li>\n</ul>\n<p>As mentioned before, both\u00a0torch.nn.GRU\u00a0and\u00a0torch.nn.LSTM\u00a0have the same API, i.e, they accept the same set of parameters and accept inputs in the same format and return out in the same format too.</p>\n<h3>torch.nn.RNNCell :</h3>\n<p>Since this represents only a single cell of the RNN, it accepts only 4 parameters, all of which have the same meaning as they did in\u00a0torch.nn.RNN\u00a0.</p>\n<h4>Parameters:</h4>\n<ul>\n<li><strong>input_size</strong>\u200a\u2014\u200aThe number of expected features in the input x</li>\n<li><strong>hidden_size</strong>\u200a\u2014\u200aThe number of features in the hidden state h</li>\n<li><strong>bias</strong>\u200a\u2014\u200aIf\u00a0False, then the layer does not use bias weights b_ih and b_hh. Default:\u00a0True</li>\n<li><strong>nonlinearity</strong>\u200a\u2014\u200aThe non-linearity to use. Can be either \u2018tanh\u2019 or \u2018relu\u2019. Default: \u2018tanh\u2019</li>\n</ul>\n<p>Again, since this is just a single cell of an RNN, the input and output dimensions are much simpler\u200a\u2014</p>\n<h4>Inputs (input, hidden):</h4>\n<ul>\n<li><strong>input</strong>\u200a\u2014\u200athis is a tensor of shape (batch, input_size) that contains the input features.</li>\n<li><strong>hidden</strong>\u200a\u2014\u200athis is a tensor of shape (batch, hidden_size) that contains the initial hidden states for each of the elements in the batch.</li>\n</ul>\n<h4>Output:</h4>\n<ul>\n<li><strong>h\u2019\u200a</strong>\u2014\u200athis is a tensor of shape (batch, hidden_size) and it gives us the hidden state for the next time step.</li>\n</ul>\n<p>This was all about getting started with the PyTorch framework for Natural Language Processing (NLP). If you are looking for ideas on what is possible and what you can build, check out\u200a\u2014\u200a<a href=\"https://blog.exxactcorp.com/deep-learning-for-natural-language-processing/\">Deep Learning for Natural Language Processing using RNNs and CNNs</a>.</p>\n<p><a href=\"https://blog.exxactcorp.com/getting-started-with-natural-language-processing-using-pytorch/\">Original</a>. Reposted with permission.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/03/building-nlp-classifiers-cheaply-transfer-learning-weak-supervision.html\">Building NLP Classifiers Cheaply With Transfer Learning and Weak Supervision</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/03/beyond-news-contents-role-of-social-context-for-fake-news-detection.html\">Beyond news contents: the role of social context for fake news detection</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/02/deconstructing-bert-distilling-patterns-100-million-parameters.html\">Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}