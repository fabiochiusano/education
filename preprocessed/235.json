{"content": "comments By Dipanjan Sarkar , Intel Editor's note: This post is only one part of a far more thorough and in-depth original, found here , which covers much more than what is included here. The Skip-gram Model \u00a0 The Skip-gram model architecture usually tries to achieve the reverse of what the CBOW model does. It tries to predict the source context words (surrounding words) given a target word (the center word). Considering our simple sentence from earlier,\u00a0 \u201cthe quick brown fox jumps over the lazy dog\u201d. If we used the CBOW model, we get pairs of\u00a0 (context_window, target_word) where if we consider a context window of size 2, we have examples like\u00a0 ([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0 and so on. Now considering that the skip-gram model\u2019s aim is to predict the context from the target word, the model typically inverts the contexts and targets, and tries to predict each context word from its target word. Hence the task becomes to predict the context\u00a0 [quick, fox] \u00a0given target word \u2018brown\u2019 or [the, brown] given target word\u00a0 \u2018quick\u2019 \u00a0and so on. Thus the model tries to predict the context_window words based on the target_word. The Skip-gram model architecture (Source:\u00a0 /pdf/1301.3781.pdf \u00a0Mikolov el\u00a0al.) Just like we discussed in the CBOW model, we need to model this Skip-gram architecture now as a deep learning classification model such that we take in the\u00a0 target word as our input\u00a0 and try to\u00a0 predict the context words. This becomes slightly complex since we have multiple words in our context. We simplify this further by breaking down each\u00a0 (target, context_words) pair \u00a0into\u00a0 (target, context) pairs \u00a0such that each context consists of only one word. Hence our dataset from earlier gets transformed into pairs like\u00a0 (brown, quick), (brown, fox), (quick, the), (quick, brown) \u00a0and so on. But how to supervise or train the model to know what is contextual and what is not? For this, we feed our skip-gram model pairs of\u00a0 (X, Y) \u00a0where\u00a0 X\u00a0 is our\u00a0 input\u00a0 and\u00a0 Y\u00a0 is our\u00a0 label . We do this by using\u00a0 [(target, context), 1]\u00a0 pairs as\u00a0 positive input samples \u00a0where\u00a0 target\u00a0 is our word of interest and\u00a0 context\u00a0 is a context word occurring near the target word and the\u00a0 positive label 1 \u00a0indicates this is a contextually relevant pair. We also feed in\u00a0 [(target, random), 0] \u00a0pairs as\u00a0 negative input samples \u00a0where\u00a0 target\u00a0 is again our word of interest but\u00a0 random\u00a0 is just a randomly selected word from our vocabulary which has no context or association with our target word. Hence the\u00a0 negative label 0 indicates this is a contextually irrelevant pair. We do this so that the model can then learn which pairs of words are contextually relevant and which are not and generate similar embeddings for semantically similar words. \u00a0 Implementing the Skip-gram Model \u00a0 Let\u2019s now try and implement this model from scratch to gain some perspective on how things work behind the scenes and also so that we can compare it with our implementation of the CBOW model. We will leverage our Bible corpus as usual which is contained in the\u00a0 norm_bible \u00a0variable for training our model. The implementation will focus on five parts Build the corpus vocabulary Build a skip-gram [(target, context), relevancy] generator Build the skip-gram model architecture Train the Model Get Word Embeddings Let\u2019s get cracking and build our skip-gram Word2Vec model! Build the corpus vocabulary To start off, we will follow the standard process of building our corpus vocabulary where we extract out each unique word from our vocabulary and assign a unique identifier, similar to what we did in the CBOW model. We also maintain mappings to transform words to their unique identifiers and vice-versa. Vocabulary Size: 12425\r Vocabulary Sample: [('perceived', 1460), ('flagon', 7287), ('gardener', 11641), ('named', 973), ('remain', 732), ('sticketh', 10622), ('abstinence', 11848), ('rufus', 8190), ('adversary', 2018), ('jehoiachin', 3189)] Just like we wanted, each unique word from the corpus is a part of our vocabulary now with a unique numeric identifier. Build a skip-gram [(target, context), relevancy] generator It\u2019s now time to build out our skip-gram generator which will give us pair of words and their relevance like we discussed earlier. Luckily,\u00a0 keras \u00a0has a nifty\u00a0 skipgrams \u00a0utility which can be used and we don\u2019t have to manually implement this generator like we did in CBOW. Note: \u00a0The function\u00a0  \u00a0is present in\u00a0 keras.preprocessing.sequence This function transforms a sequence of word indexes (list of integers) into tuples of words of the form: - (word, word in the same window), with label 1 (positive samples). - (word, random word from the vocabulary), with label 0 (negative samples). (james (1154), king (13)) -> 1\r (king (13), james (1154)) -> 1\r (james (1154), perform (1249)) -> 0\r (bible (5766), dismissed (6274)) -> 0\r (king (13), alter (5275)) -> 0\r (james (1154), bible (5766)) -> 1\r (king (13), bible (5766)) -> 1\r (bible (5766), king (13)) -> 1\r (king (13), compassion (1279)) -> 0\r (james (1154), foreskins (4844)) -> 0 Thus you can see we have successfully generated our required skip-grams and based on the sample skip-grams in the preceding output, you can clearly see what is relevant and what is irrelevant based on the label (0 or 1). Build the skip-gram model architecture We now leverage\u00a0 keras \u00a0on top of\u00a0 tensorflow \u00a0to build our deep learning architecture for the skip-gram model. For this our inputs will be our target word and context or random word pair. Each of which are passed to an embedding layer (initialized with random weights) of it\u2019s own. Once we obtain the word embeddings for the target and the context word, we pass it to a merge layer where we compute the dot product of these two vectors. Then we pass on this dot product value to a dense sigmoid layer which predicts either a 1 or a 0 depending on if the pair of words are contextually relevant or just random words ( Y\u2019 ). We match this with the actual relevance label ( Y ), compute the loss by leveraging the\u00a0 mean_squared_error \u00a0loss and perform backpropagation with each epoch to update the embedding layer in the process. Following code shows us our model architecture. Skip-gram model summary and architecture Understanding the above deep learning model is pretty straightforward. However, I will try to summarize the core concepts of this model in simple terms for ease of understanding. We have a pair of input words for each training example consisting of\u00a0 one input target word \u00a0having a unique numeric identifier and\u00a0 one context word \u00a0having a unique numeric identifier. If it is\u00a0 a positive sample \u00a0the word has contextual meaning, is\u00a0 a context word and our\u00a0 label Y=1 , else if it is a\u00a0 negative sample , the word has no contextual meaning, is just\u00a0 a random word \u00a0and our\u00a0 label Y=0 . We will pass each of them to an\u00a0 embedding layer \u00a0of their own, having size\u00a0 (vocab_size x embed_size) \u00a0which will give us\u00a0 dense word embeddings \u00a0for each of these two words\u00a0 (1 x embed_size for each word) . Next up we use a\u00a0 merge layer \u00a0to compute the\u00a0 dot product \u00a0of these two embeddings and get the dot product value. This is then sent to the\u00a0 dense sigmoid layer \u00a0which outputs either a 1 or 0. We compare this with the actual label Y (1 or 0), compute the loss, backpropagate the errors to adjust the weights (in the embedding layer) and repeat this process for all\u00a0 (target, context) \u00a0pairs for multiple epochs. The following figure tries to explain the same. Visual depiction of the Skip-gram deep learning\u00a0model Let\u2019s now start training our model with our skip-grams. Train the\u00a0Model Running the model on our complete corpus takes a fair bit of time but lesser than the CBOW model. Hence I just ran it for 5 epochs. You can leverage the following code and increase it for more epochs if necessary. Epoch: 1 Loss: 4529.63803683\r Epoch: 2 Loss: 3750.71884749\r Epoch: 3 Loss: 3752.47489296\r Epoch: 4 Loss: 3793.9177565\r Epoch: 5 Loss: 3716.07605051 Once this model is trained, similar words should have similar weights based off the embedding layer and we can test out the same. Get Word Embeddings To get word embeddings for our entire vocabulary, we can extract out the same from our embedding layer by leveraging the following code. Do note that we are only interested in the target word embedding layer, hence we will extract the embeddings from our\u00a0 word_model \u00a0embedding layer. We don\u2019t take the embedding at position 0 since none of our words in the vocabulary have a numeric identifier of 0 and we ignore it. Word Embeddings for our vocabulary based on the Skip-gram model Thus you can clearly see that each word has a dense embedding of size\u00a0 (1x100) \u00a0as depicted in the preceding output similar to what we had obtained from the CBOW model. Let\u2019s now apply the euclidean distance metric on these dense embedding vectors to generate a pairwise distance metric for each word in our vocabulary. We can then find out the n-nearest neighbors of each word of interest based on the shortest (euclidean) distance similar to what we did on the embeddings from our CBOW model. ( 12424, 12424) \r \r {'egypt': ['pharaoh', 'mighty', 'houses', 'kept', 'possess'],\r 'famine': ['rivers', 'foot', 'pestilence', 'wash', 'sabbaths'],\r 'god': ['evil', 'iniquity', 'none', 'mighty', 'mercy'],\r 'gospel': ['grace', 'shame', 'believed', 'verily', 'everlasting'],\r 'jesus': ['christ', 'faith', 'disciples', 'dead', 'say'],\r 'john': ['ghost', 'knew', 'peter', 'alone', 'master'],\r 'moses': ['commanded', 'offerings', 'kept', 'presence', 'lamb'],\r 'noah': ['flood', 'shem', 'peleg', 'abram', 'chose']} You can clearly see from the results that a lot of the similar words for each of the words of interest are making sense and we have obtained better results as compared to our CBOW model. Let\u2019s visualize these words embeddings now using\u00a0 t-SNE \u00a0 which stands for\u00a0 t-distributed stochastic neighbor embedding \u00a0 a popular\u00a0 dimensionality reduction \u00a0technique to visualize higher dimension spaces in lower dimensions (e.g. 2-D). Visualizing skip-gram word2vec word embeddings using\u00a0t-SNE I have marked some circles in red which seemed to show different words of contextual similarity positioned near each other in the vector space. If you find any other interesting patterns feel free to let me know! \u00a0 Bio: Dipanjan Sarkar is a Data Scientist @Intel, an author, a mentor @Springboard, a writer, and a sports and sitcom addict. Original . Reposted with permission. Related: Text Data Preprocessing: A Walkthrough in Python A General Approach to Preprocessing Text Data A Framework for Approaching Textual Data Science Tasks", "title_html": "<h1 id=\"title\">Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model</h1> ", "url": "https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html", "tfidf": {"tfidf": {"mark": 1.5079787234, "sabbath": 46.8318584071, "onc": 2.9949066213999997, "relat": 1.23750876919, "thorough": 10.956521739100001, "shortest": 39.789473684200004, "five": 1.37740760021, "faith": 4.11082340756, "form": 1.12755681818, "red": 2.22228443449, "reduct": 6.320063694269999, "assign": 3.83663605607, "space": 4.79637462236, "tupl": 661.5, "addict": 20.0454545455, "viceversa": 1323.0, "dataset": 193.609756098, "function": 4.99088337, "dog": 12.52544378698, "python": 56.2978723404, "product": 6.49059689288, "tri": 14.835650040879997, "fox": 26.12258329904, "complet": 1.24021560816, "approach": 4.15113086678, "higher": 2.1218925421, "know": 5.1865403463, "their": 3.0464372521500005, "chose": 4.42105263158, "pairwis": 387.219512195, "summar": 15.1056137012, "multipl": 5.49627834516, "vector": 77.696574225, "everlast": 89.6949152542, "test": 2.65707112971, "repost": 933.882352941, "dismiss": 5.2137931034500005, "perceiv": 4.92279069767, "keraspreprocessingsequ": 1323.0, "abstin": 120.27272727299999, "maintain": 1.77306231852, "jame": 9.65693430655, "increas": 1.32024948025, "circl": 4.3795862069, "initi": 1.35, "found": 1.11387076405, "given": 4.06278256419, "word": 113.18184904382998, "interest": 9.61987477278, "deep": 14.511882998159999, "will": 11.02329887364, "associ": 1.3263157894700002, "numxnum": 52.0524590164, "consid": 3.7191941277600007, "alter": 4.4247491638800005, "peter": 2.34090238868, "ran": 3.4915328788199997, "updat": 5.56466876972, "next": 1.4950560316400001, "indic": 4.1652892562, "similar": 12.37626678213, "but": 3.04897253697, "need": 1.4372623574099999, "our": 87.23076923083, "classif": 8.067073170730001, "off": 3.0242880274400004, "kept": 5.88654060066, "integ": 46.017391304300006, "sarkar": 738.418604652, "has": 5.218248751, "surround": 2.49858356941, "tensorflow": 1323.0, "adjust": 7.112903225810001, "pass": 6.47273468556, "use": 6.177832544279999, "out": 5.30083472455, "model": 79.44271793520001, "concept": 2.65707112971, "much": 1.1942229577299999, "brown": 25.772727272720005, "numer": 7.33302540416, "knew": 5.134540750319999, "loss": 19.40238313472, "process": 5.08574479446, "ghost": 11.2595744681, "far": 1.71022298826, "henc": 26.954159592549995, "are": 6.17943561468, "not": 2.03134796238, "aim": 2.8960233491400005, "sticketh": 1323.0, "dead": 2.9608355091400003, "quick": 17.64, "skipgram": 29106.0, "metric": 44.470588235200005, "than": 2.0655737705, "then": 4.34631442064, "index": 6.9969149405, "nifti": 1058.4, "core": 4.623179965059999, "sitcom": 34.588235294099995, "jump": 8.07117437722, "let": 20.91699604746, "normbibl": 1323.0, "scienc": 2.31969608416, "weight": 14.636754763379997, "distanc": 10.426444833629999, "lesser": 8.10413476263, "egypt": 7.492213308160001, "feed": 15.55707986282, "simpl": 6.7962328767199995, "preced": 8.871751886, "valu": 4.555523672880001, "offer": 1.53896859248, "either": 3.1660185462199997, "sent": 2.32683570277, "such": 2.12302754748, "context": 89.45425275023999, "with": 11.013180298889997, "lot": 4.40877534018, "some": 2.08073394496, "sourc": 3.39520958084, "should": 1.6643254009900001, "mose": 20.8073394495, "supervis": 7.74061433447, "springboard": 135.692307692, "vocabulari": 302.62170088019997, "dipanjan": 2646.0, "ani": 1.13383802314, "king": 12.168625447140002, "from": 14.00794100958, "jehoiachin": 1323.0, "foot": 5.65384615385, "num": 72.02268288072, "editor": 4.33060556465, "els": 5.44444444444, "possess": 3.17329602239, "free": 1.71818181818, "for": 20.006300800200002, "depend": 2.2411067193700003, "predict": 36.293925538850004, "output": 23.03094777564, "match": 3.5676404494400002, "pharaoh": 62.015625, "garden": 4.294292669730001, "simplifi": 12.109839816900001, "evil": 7.714285714289999, "merg": 10.56638935108, "better": 2.0065722952500002, "intel": 109.1134020618, "writer": 2.75816539263, "shame": 21.7181942544, "sens": 2.8365195640499996, "preprocess": 2442.46153846, "center": 1.7423178226499998, "popular": 1.50769230769, "summari": 7.80147420147, "tsne": 2646.0, "extract": 23.109170305680003, "work": 1.11520089913, "negat": 15.03409090908, "posit": 8.23515172476, "util": 4.65981802172, "focus": 2.01012914662, "again": 1.50883862384, "sigmoid": 2116.8, "map": 4.0728578758300005, "doe": 1.70581282905, "john": 1.35553278689, "give": 2.7306501548, "train": 13.5559892657, "master": 3.15125049623, "wordmodel": 1323.0, "scratch": 25.8146341463, "error": 6.04109589041, "framework": 8.200413223139998, "discipl": 24.5378670788, "hous": 1.4624170965399999, "note": 4.27348586811, "thing": 2.4065484311099996, "just": 8.01480858222, "into": 3.04507384437, "relev": 55.51048951048001, "compar": 5.598683437170001, "dimens": 16.51170046802, "abov": 1.90382539873, "requir": 1.52844902282, "figur": 2.0343413634, "contextu": 613.5652173912, "earlier": 5.60329411764, "techniqu": 3.7293868921800004, "peleg": 1323.0, "god": 3.5217391304300003, "present": 1.25551601423, "believ": 1.6450108797, "find": 3.4588235294199996, "manual": 7.72930866602, "cover": 1.69380134429, "success": 1.32002993265, "base": 6.8776895307, "occur": 1.7453825857499998, "label": 44.7715736041, "pestil": 191.277108434, "pdfnumpdf": 1323.0, "permiss": 6.280063291139999, "wash": 14.3027027027, "post": 2.23826307627, "here": 4.84615384616, "lower": 2.10055570257, "bibl": 47.3063170441, "contextword": 1323.0, "layer": 97.69846153847999, "grace": 8.73267326733, "contain": 1.59814777532, "meansquarederror": 1323.0, "epoch": 345.130434783, "scene": 3.45055422734, "how": 3.20500656102, "sentenc": 5.84536082474, "shem": 305.307692308, "jesus": 9.751842751839998, "perspect": 5.03520456708, "entir": 1.59365589239, "ignor": 4.58446433728, "can": 12.93887530562, "them": 1.09876115994, "contextwindow": 2646.0, "fair": 3.20533010297, "where": 6.40290381126, "complex": 2.34021226415, "start": 2.53347163488, "walkthrough": 793.8, "iniqu": 317.52, "pattern": 3.79173632673, "run": 1.55692850838, "mighti": 50.2405063292, "explain": 2.60049140049, "standard": 1.8915763135900003, "usual": 3.45017928936, "had": 1.0475750577399998, "uniqu": 21.11170212767, "over": 1.02525024217, "build": 16.341739578000002, "depict": 8.026289181000001, "seem": 2.29123971713, "adversari": 26.328358209, "flagon": 1323.0, "same": 4.47431832592, "command": 2.66689064337, "say": 1.7544480053, "origin": 2.27449856734, "verili": 330.75, "slight": 3.25327868852, "take": 3.4188500466600003, "visual": 20.91010865988, "follow": 5.23200632745, "now": 10.447027857, "foreskin": 835.5789473680001, "further": 1.3618116315, "name": 1.10211732037, "code": 11.64214128576, "mentor": 14.8373831776, "gospel": 15.6413793103, "semant": 39.1034482759, "leverag": 178.783783784, "break": 2.42863698944, "feel": 3.1356903021900004, "also": 3.04429530201, "typic": 2.2541530597799997, "irrelev": 59.5722326454, "rufus": 57.3140794224, "mean": 2.89813800658, "textual": 41.4516971279, "revers": 4.29894394801, "task": 7.77282741738, "stochast": 128.032258065, "window": 11.72958995198, "the": 101.0, "invert": 25.7309562399, "becom": 2.24984057252, "one": 4.02509982888, "stand": 2.0845588235299997, "scientist": 4.69426374926, "want": 1.99698113208, "christ": 8.839643652560001, "behind": 2.0845588235299997, "howev": 1.0945191313299998, "variabl": 8.747107438019999, "actual": 3.74964572508, "which": 13.067493984999999, "like": 6.8951140065, "term": 1.39520168732, "thus": 4.93912682775, "other": 2.01984732824, "appli": 2.2972073506, "abram": 38.255421686700004, "consist": 2.9802890932999997, "show": 2.5340782123, "merci": 16.8177966102, "lamb": 25.483146067399996, "see": 5.08968502044, "river": 2.5204000635, "corpus": 144.546282246, "crack": 13.7216940363, "get": 12.49938139695, "random": 57.5217391304, "implement": 17.8824059473, "select": 2.02345144022, "dot": 75.5101070156, "alon": 2.99716820842, "euclidean": 220.5, "part": 3.12992048367, "transform": 10.26023265834, "backpropag": 2646.0, "that": 8.03187251, "includ": 1.0190641247799999, "understand": 5.93717277486, "repeat": 2.8771293947099994, "straightforward": 27.7552447552, "famin": 20.780104712, "this": 20.075872534200002, "pretti": 15.75, "sampl": 57.86241457856, "time": 2.02254920696, "result": 2.29223216864, "lazi": 97.1009174312, "near": 2.57539135372, "differ": 1.23654490225, "embed": 404.05514316, "nnearest": 1323.0, "what": 11.280909521519998, "obtain": 8.05888324872, "all": 1.01146788991, "top": 1.8387769284200002, "input": 85.4204458107, "have": 12.178738093679998, "compass": 18.611957796, "author": 1.4229631621399998, "pair": 65.53109521185, "noah": 37.7102137767, "architectur": 41.02325581392, "more": 3.0515120451, "and": 37.00233070881, "list": 1.36321483771, "indepth": 1323.0, "clear": 5.56271899089, "discuss": 4.39352428394, "achiev": 1.87216981132, "these": 5.3707713126000005, "gain": 1.84819557625, "general": 1.1218202374200001, "kera": 1671.1578947360001, "comment": 3.05954904606, "none": 8.13111395646, "target": 70.81751824818001, "perform": 3.0627954085000004, "comput": 15.711034141520003, "make": 1.0762660158600001, "tdistribut": 1323.0, "onli": 3.0769429549800007, "each": 19.03597122304, "size": 9.9754948162, "eas": 9.04615384615, "wordnumvec": 2646.0, "necessari": 2.8421052631599997, "neighbor": 11.563000728339999, "two": 3.04137931035, "remain": 1.16598119859, "mikolov": 1323.0, "data": 13.50574223736, "flood": 6.94488188976, "sport": 3.29651162791, "sequenc": 6.07112810707, "sinc": 2.16737201366, "bio": 42.336000000000006, "down": 1.35889754344, "embeds": 2646.0, "exampl": 3.00966824644, "text": 6.25655172414, "dimension": 54.1843003413, "identifi": 13.81122227058, "vocabs": 1323.0, "targetword": 2646.0, "luckili": 191.277108434, "generat": 14.369278510440001, "presenc": 2.7476635514, "bit": 8.33385826772, "learn": 11.61375274325, "own": 2.35688836104, "dens": 52.086614173}, "logtfidf": {"mark": 0.410770160338, "sabbath": 3.8465637065199996, "onc": 0.80753174471, "relat": 0.21310030165399999, "thorough": 2.39393487158, "shortest": 3.6836023970099996, "five": 0.320203181906, "faith": 1.4136233509099998, "form": 0.120053184191, "red": 0.798535691347, "reduct": 1.8437292863099999, "assign": 1.3445959556, "space": 1.749426329944, "tupl": 6.4945099835599995, "addict": 2.99800242209, "viceversa": 7.18765716411, "dataset": 5.26584456664, "function": 1.828931483188, "dog": 3.6692297957599997, "python": 4.03065674296, "product": 1.936240546144, "tri": 4.94073223328, "fox": 7.506023358360001, "complet": 0.215285242047, "approach": 1.4604672291620002, "higher": 0.752308398995, "know": 1.905839388796, "their": 0.046081515368100005, "chose": 1.48637781968, "pairwis": 5.958991747200001, "summar": 2.7150664430299996, "multipl": 2.02184803624, "vector": 9.76259663391, "everlast": 4.49641408133, "test": 0.977224437103, "repost": 6.83935046985, "dismiss": 1.6513076337600001, "perceiv": 1.5938755846700001, "keraspreprocessingsequ": 7.18765716411, "abstin": 4.7897618913199995, "maintain": 0.572708175102, "jame": 3.291191629265, "increas": 0.277820718929, "circl": 1.47695424661, "initi": 0.30010459245, "found": 0.107841124048, "given": 0.9097674324930001, "word": 36.909248190255, "interest": 2.832430667892, "deep": 5.1546938792, "will": 1.825078814235, "associ": 0.28240501535100004, "numxnum": 3.9522520373, "consid": 0.644684171472, "alter": 1.48721359072, "peter": 0.850536491217, "ran": 1.25034086008, "updat": 1.7164374626899999, "next": 0.402163685499, "indic": 1.4672770838299998, "similar": 2.867004829026, "but": 0.0485771162157, "need": 0.362740163442, "our": 31.732650924734003, "classif": 2.08779073629, "off": 0.8270570407760001, "kept": 2.1590426203999997, "integ": 3.8290193968699997, "sarkar": 11.82272739642, "has": 0.213619724274, "surround": 0.915723999073, "tensorflow": 7.18765716411, "adjust": 1.9619104904, "pass": 1.92521731896, "use": 0.1752481183896, "out": 0.2921319545965, "model": 28.023102778218004, "concept": 0.977224437103, "much": 0.17749572930100002, "brown": 9.35900246952, "numer": 2.424375249384, "knew": 1.6359904042, "loss": 7.087634870736, "process": 1.583487597075, "ghost": 2.42121883053, "far": 0.536623764503, "henc": 8.4234985891, "are": 0.17680484149620002, "not": 0.031104826015, "aim": 1.06333853704, "sticketh": 7.18765716411, "dead": 1.0854714951100002, "quick": 6.325820071192, "skipgram": 158.12845761042, "metric": 6.203361703119999, "than": 0.0645217244364, "then": 0.33213546092359997, "index": 1.94546932912, "nifti": 6.964513612799999, "core": 1.53108277245, "sitcom": 3.54351360384, "jump": 2.08829899551, "let": 7.492815403679999, "normbibl": 7.18765716411, "scienc": 0.841436178891, "weight": 4.7547705783600005, "distanc": 3.73719918771, "lesser": 2.09237439596, "egypt": 2.01386425563, "feed": 4.10273730218, "simpl": 2.4464425787799997, "preced": 2.97945020628, "valu": 1.646386620296, "offer": 0.431112446902, "either": 0.91865527763, "sent": 0.844509277088, "such": 0.119391955612, "context": 30.433303202820003, "with": 0.01317240884729, "lot": 1.4835969502500002, "some": 0.079147018129, "sourc": 1.058436621502, "should": 0.509419876758, "mose": 3.03530578262, "supervis": 2.04648105583, "springboard": 4.91038987911, "vocabulari": 40.91794402878, "dipanjan": 14.37531432822, "ani": 0.125608358366, "king": 4.242608912322, "from": 0.007938758364123999, "jehoiachin": 7.18765716411, "foot": 1.73233604876, "num": 0.022679308468584004, "editor": 1.4657073855, "els": 1.6945957207700002, "possess": 1.15477080241, "free": 0.5412666492670001, "for": 0.006299807907940001, "depend": 0.806969815, "predict": 11.52018166383, "output": 6.11467973481, "match": 1.27190443874, "pharaoh": 4.12738636942, "garden": 1.45728685497, "simplifi": 2.4940183301400003, "evil": 2.04307389751, "merg": 3.32906193386, "better": 0.6964279406, "intel": 7.998481093460001, "writer": 1.0145657459, "shame": 3.0781503541500004, "sens": 1.04257779501, "preprocess": 14.215228912879999, "center": 0.555216308776, "popular": 0.41058020877499996, "summari": 2.0543127160299997, "tsne": 14.37531432822, "extract": 6.124851699030001, "work": 0.109034567273, "negat": 5.29610395408, "posit": 1.8999139116480002, "util": 1.5389763962399998, "focus": 0.6981989720559999, "again": 0.411340231612, "sigmoid": 13.929027225599999, "map": 1.40434493384, "doe": 0.5340417297169999, "john": 0.304194577702, "give": 0.622785104448, "train": 4.626428189873001, "master": 1.14779935699, "wordmodel": 7.18765716411, "scratch": 3.2509415461, "error": 1.7985854343, "framework": 2.10418454607, "discipl": 3.2002175193999998, "hous": 0.38009061238799996, "note": 1.061452704249, "thing": 0.8781935346799999, "just": 1.737188604654, "into": 0.0447385896861, "relev": 15.497043691199998, "compar": 1.8717575427809998, "dimens": 4.22184413662, "abov": 0.643865229816, "requir": 0.424253510675, "figur": 0.7101721121600001, "contextu": 34.71876016512, "earlier": 1.874227114275, "techniqu": 1.31624384807, "peleg": 7.18765716411, "god": 1.25895493874, "present": 0.227546654799, "believ": 0.497746997996, "find": 1.095562660576, "manual": 2.04501942341, "cover": 0.526975319156, "success": 0.27765441259199997, "base": 0.8191398137220001, "occur": 0.556973778473, "label": 14.9898832727, "pestil": 5.25372320611, "pdfnumpdf": 7.18765716411, "permiss": 1.8373800586400002, "wash": 2.6604485196, "post": 0.8057001527009999, "here": 1.7700763767400003, "lower": 0.742201929994, "bibl": 11.2360296344, "contextword": 7.18765716411, "layer": 25.163749948200003, "grace": 2.16707153917, "contain": 0.468845318236, "meansquarederror": 7.18765716411, "epoch": 32.82028056072, "scene": 1.23853486375, "how": 0.9431339138600001, "sentenc": 1.7656483252200001, "shem": 5.721320095319999, "jesus": 2.2774562673400003, "perspect": 1.61645415436, "entir": 0.46603068026999994, "ignor": 1.5226732694999998, "can": 1.7857520603339998, "them": 0.0941833269093, "contextwindow": 14.37531432822, "fair": 1.16481508131, "where": 0.38995283247420004, "complex": 0.8502416364309999, "start": 0.472886738582, "walkthrough": 6.676831540349999, "iniqu": 5.76054080847, "pattern": 1.33282404788, "run": 0.442714975539, "mighti": 6.44734883952, "explain": 0.955700427358, "standard": 0.63741050982, "usual": 1.090558034128, "had": 0.0464780244111, "uniqu": 7.7274213863000005, "over": 0.0249367214957, "build": 4.91137452091, "depict": 2.77915024232, "seem": 0.829093032276, "adversari": 3.27064661718, "flagon": 7.18765716411, "same": 0.448238598416, "command": 0.9809132407500001, "say": 0.562154280552, "origin": 0.257224875174, "verili": 5.801362803, "slight": 1.17966331506, "take": 0.392075886591, "visual": 6.6157533954400005, "follow": 0.22678455547099996, "now": 1.3418365051890002, "foreskin": 6.72812483474, "further": 0.308815895297, "name": 0.09723316638430002, "code": 4.06805728791, "mentor": 2.6971498864499996, "gospel": 2.7499199224299997, "semant": 3.6662106543, "leverag": 17.883696257349996, "break": 0.88733019029, "feel": 1.1428493419299999, "also": 0.0439714734, "typic": 0.812774319158, "irrelev": 6.788084779480001, "rufus": 4.04854630772, "mean": 0.74184256704, "textual": 3.7245288247199992, "revers": 1.45836939905, "task": 2.71497361322, "stochast": 4.8522822483, "window": 3.5379350485800005, "the": 0.0, "invert": 3.24769479, "becom": 0.23542435297800002, "one": 0.025021406582, "stand": 0.7345572374320001, "scientist": 1.54634128444, "want": 0.6916366062549999, "christ": 2.17924656504, "behind": 0.7345572374320001, "howev": 0.0903151173475, "variabl": 2.1687230672, "actual": 1.257028363296, "which": 0.06731937999059, "like": 0.83432145927, "term": 0.33303898354600003, "thus": 1.4957288141790002, "other": 0.01974949583952, "appli": 0.8316941898119999, "abram": 3.64428529367, "consist": 0.797746252852, "show": 0.473365532026, "merci": 2.8224376477599997, "lamb": 3.23801729512, "see": 0.963686341968, "river": 0.924417644281, "corpus": 19.0910416764, "crack": 2.61897808671, "get": 4.058383040474, "random": 15.781771252079999, "implement": 6.37189704535, "select": 0.704804687133, "dot": 11.75188861572, "alon": 1.09766791236, "euclidean": 9.40550102866, "part": 0.12718593294840003, "transform": 3.6889896812100003, "backpropag": 14.37531432822, "that": 0.03180918703712, "includ": 0.0188846813905, "understand": 2.1761717513599996, "repeat": 1.0567930591299999, "straightforward": 3.3234248225200003, "famin": 3.0339960247400004, "this": 0.07572898105, "pretti": 2.75684036527, "sampl": 15.829011907120002, "time": 0.0224230377252, "result": 0.272757816762, "lazi": 7.76520728602, "near": 0.505708648068, "differ": 0.212321121312, "embed": 67.76394075048, "nnearest": 7.18765716411, "what": 2.032985671443, "obtain": 2.964488110509, "all": 0.011402632097799998, "top": 0.609100637788, "input": 17.511727347729998, "have": 0.1774200280944, "compass": 2.92380426641, "author": 0.35274143130999996, "pair": 22.11711847425, "noah": 3.6299309802199997, "architectur": 13.07758063352, "more": 0.05107479479999999, "and": 0.0023306352563532, "list": 0.309845761506, "indepth": 7.18765716411, "clear": 1.852424181594, "discuss": 1.57396904524, "achiev": 0.6270980851169999, "these": 0.357668097004, "gain": 0.6142097989249999, "general": 0.114952578063, "kera": 13.45624966948, "comment": 1.11826753454, "none": 2.80510150326, "target": 25.719406891640002, "perform": 0.85236170116, "comput": 5.47227566376, "make": 0.07349765782289999, "tdistribut": 7.18765716411, "onli": 0.0759728049873, "each": 2.779867028864, "size": 3.6553488242439998, "eas": 2.202339678, "wordnumvec": 14.37531432822, "necessari": 1.0445450673999999, "neighbor": 3.5093264551599996, "two": 0.041096533074600004, "remain": 0.15356296309, "mikolov": 7.18765716411, "data": 4.8672823392, "flood": 1.9380049695500001, "sport": 1.19286482691, "sequenc": 1.8035444374, "sinc": 0.1607363989154, "bio": 3.7456377879300002, "down": 0.306673741186, "embeds": 14.37531432822, "exampl": 0.8173653499979999, "text": 2.28096401998, "dimension": 3.99239120489, "identifi": 5.0023320028319995, "vocabs": 7.18765716411, "targetword": 14.37531432822, "luckili": 5.25372320611, "generat": 5.034276392152, "presenc": 1.01075093288, "bit": 2.12032652634, "learn": 4.213760323724999, "own": 0.328390154842, "dens": 11.717350388299998}, "logidf": {"mark": 0.410770160338, "sabbath": 3.8465637065199996, "onc": 0.403765872355, "relat": 0.21310030165399999, "thorough": 2.39393487158, "shortest": 3.6836023970099996, "five": 0.320203181906, "faith": 1.4136233509099998, "form": 0.120053184191, "red": 0.798535691347, "reduct": 1.8437292863099999, "assign": 1.3445959556, "space": 0.874713164972, "tupl": 6.4945099835599995, "addict": 2.99800242209, "viceversa": 7.18765716411, "dataset": 5.26584456664, "function": 0.914465741594, "dog": 1.8346148978799999, "python": 4.03065674296, "product": 0.484060136536, "tri": 0.61759152916, "fox": 1.8765058395900003, "complet": 0.215285242047, "approach": 0.7302336145810001, "higher": 0.752308398995, "know": 0.952919694398, "their": 0.015360505122700001, "chose": 1.48637781968, "pairwis": 5.958991747200001, "summar": 2.7150664430299996, "multipl": 1.01092401812, "vector": 3.25419887797, "everlast": 4.49641408133, "test": 0.977224437103, "repost": 6.83935046985, "dismiss": 1.6513076337600001, "perceiv": 1.5938755846700001, "keraspreprocessingsequ": 7.18765716411, "abstin": 4.7897618913199995, "maintain": 0.572708175102, "jame": 0.658238325853, "increas": 0.277820718929, "circl": 1.47695424661, "initi": 0.30010459245, "found": 0.107841124048, "given": 0.303255810831, "word": 0.585861082385, "interest": 0.47207177798199995, "deep": 1.2886734698, "will": 0.202786534915, "associ": 0.28240501535100004, "numxnum": 3.9522520373, "consid": 0.214894723824, "alter": 1.48721359072, "peter": 0.850536491217, "ran": 1.25034086008, "updat": 1.7164374626899999, "next": 0.402163685499, "indic": 0.7336385419149999, "similar": 0.318556092114, "but": 0.0161923720719, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "off": 0.41352852038800003, "kept": 1.0795213101999999, "integ": 3.8290193968699997, "sarkar": 5.91136369821, "has": 0.0427239448548, "surround": 0.915723999073, "tensorflow": 7.18765716411, "adjust": 1.9619104904, "pass": 0.48130432974, "use": 0.0292080197316, "out": 0.0584263909193, "model": 0.7374500731110001, "concept": 0.977224437103, "much": 0.17749572930100002, "brown": 1.16987530869, "numer": 0.606093812346, "knew": 1.6359904042, "loss": 0.885954358842, "process": 0.527829199025, "ghost": 2.42121883053, "far": 0.536623764503, "henc": 1.68469971782, "are": 0.0294674735827, "not": 0.0155524130075, "aim": 1.06333853704, "sticketh": 7.18765716411, "dead": 1.0854714951100002, "quick": 0.790727508899, "skipgram": 7.18765716411, "metric": 3.1016808515599994, "than": 0.0322608622182, "then": 0.08303386523089999, "index": 1.94546932912, "nifti": 6.964513612799999, "core": 1.53108277245, "sitcom": 3.54351360384, "jump": 2.08829899551, "let": 1.2488025672799998, "normbibl": 7.18765716411, "scienc": 0.841436178891, "weight": 1.58492352612, "distanc": 1.24573306257, "lesser": 2.09237439596, "egypt": 2.01386425563, "feed": 2.05136865109, "simpl": 1.2232212893899999, "preced": 1.48972510314, "valu": 0.823193310148, "offer": 0.431112446902, "either": 0.459327638815, "sent": 0.844509277088, "such": 0.059695977806, "context": 1.44920491442, "with": 0.00119749171339, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "should": 0.509419876758, "mose": 3.03530578262, "supervis": 2.04648105583, "springboard": 4.91038987911, "vocabulari": 3.14753415606, "dipanjan": 7.18765716411, "ani": 0.125608358366, "king": 0.707101485387, "from": 0.000567054168866, "jehoiachin": 7.18765716411, "foot": 1.73233604876, "num": 0.00031499039539700004, "editor": 1.4657073855, "els": 1.6945957207700002, "possess": 1.15477080241, "free": 0.5412666492670001, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "output": 2.03822657827, "match": 1.27190443874, "pharaoh": 4.12738636942, "garden": 1.45728685497, "simplifi": 2.4940183301400003, "evil": 2.04307389751, "merg": 1.66453096693, "better": 0.6964279406, "intel": 3.9992405467300003, "writer": 1.0145657459, "shame": 3.0781503541500004, "sens": 1.04257779501, "preprocess": 7.1076144564399995, "center": 0.555216308776, "popular": 0.41058020877499996, "summari": 2.0543127160299997, "tsne": 7.18765716411, "extract": 2.04161723301, "work": 0.109034567273, "negat": 1.32402598852, "posit": 0.316652318608, "util": 1.5389763962399998, "focus": 0.6981989720559999, "again": 0.411340231612, "sigmoid": 6.964513612799999, "map": 1.40434493384, "doe": 0.5340417297169999, "john": 0.304194577702, "give": 0.311392552224, "train": 0.660918312839, "master": 1.14779935699, "wordmodel": 7.18765716411, "scratch": 3.2509415461, "error": 1.7985854343, "framework": 2.10418454607, "discipl": 3.2002175193999998, "hous": 0.38009061238799996, "note": 0.353817568083, "thing": 0.8781935346799999, "just": 0.289531434109, "into": 0.0149128632287, "relev": 1.9371304613999998, "compar": 0.6239191809269999, "dimens": 2.11092206831, "abov": 0.643865229816, "requir": 0.424253510675, "figur": 0.7101721121600001, "contextu": 4.33984502064, "earlier": 0.624742371425, "techniqu": 1.31624384807, "peleg": 7.18765716411, "god": 1.25895493874, "present": 0.227546654799, "believ": 0.497746997996, "find": 0.547781330288, "manual": 2.04501942341, "cover": 0.526975319156, "success": 0.27765441259199997, "base": 0.13652330228700002, "occur": 0.556973778473, "label": 1.49898832727, "pestil": 5.25372320611, "pdfnumpdf": 7.18765716411, "permiss": 1.8373800586400002, "wash": 2.6604485196, "post": 0.8057001527009999, "here": 0.8850381883700001, "lower": 0.742201929994, "bibl": 2.24720592688, "contextword": 7.18765716411, "layer": 2.0969791623500003, "grace": 2.16707153917, "contain": 0.468845318236, "meansquarederror": 7.18765716411, "epoch": 3.6466978400800003, "scene": 1.23853486375, "how": 0.47156695693000006, "sentenc": 1.7656483252200001, "shem": 5.721320095319999, "jesus": 2.2774562673400003, "perspect": 1.61645415436, "entir": 0.46603068026999994, "ignor": 1.5226732694999998, "can": 0.162341096394, "them": 0.0941833269093, "contextwindow": 7.18765716411, "fair": 1.16481508131, "where": 0.0649921387457, "complex": 0.8502416364309999, "start": 0.236443369291, "walkthrough": 6.676831540349999, "iniqu": 5.76054080847, "pattern": 1.33282404788, "run": 0.442714975539, "mighti": 3.22367441976, "explain": 0.955700427358, "standard": 0.63741050982, "usual": 0.545279017064, "had": 0.0464780244111, "uniqu": 1.1039173409, "over": 0.0249367214957, "build": 0.491137452091, "depict": 1.38957512116, "seem": 0.829093032276, "adversari": 3.27064661718, "flagon": 7.18765716411, "same": 0.112059649604, "command": 0.9809132407500001, "say": 0.562154280552, "origin": 0.128612437587, "verili": 5.801362803, "slight": 1.17966331506, "take": 0.130691962197, "visual": 1.6539383488600001, "follow": 0.045356911094199995, "now": 0.149092945021, "foreskin": 6.72812483474, "further": 0.308815895297, "name": 0.09723316638430002, "code": 1.35601909597, "mentor": 2.6971498864499996, "gospel": 2.7499199224299997, "semant": 3.6662106543, "leverag": 3.5767392514699994, "break": 0.88733019029, "feel": 1.1428493419299999, "also": 0.0146571578, "typic": 0.812774319158, "irrelev": 3.3940423897400005, "rufus": 4.04854630772, "mean": 0.37092128352, "textual": 3.7245288247199992, "revers": 1.45836939905, "task": 1.35748680661, "stochast": 4.8522822483, "window": 1.7689675242900003, "the": 0.0, "invert": 3.24769479, "becom": 0.11771217648900001, "one": 0.0062553516455, "stand": 0.7345572374320001, "scientist": 1.54634128444, "want": 0.6916366062549999, "christ": 2.17924656504, "behind": 0.7345572374320001, "howev": 0.0903151173475, "variabl": 2.1687230672, "actual": 0.628514181648, "which": 0.00517841384543, "like": 0.139053576545, "term": 0.33303898354600003, "thus": 0.49857627139300004, "other": 0.00987474791976, "appli": 0.8316941898119999, "abram": 3.64428529367, "consist": 0.398873126426, "show": 0.236682766013, "merci": 2.8224376477599997, "lamb": 3.23801729512, "see": 0.240921585492, "river": 0.924417644281, "corpus": 3.1818402794, "crack": 2.61897808671, "get": 0.579769005782, "random": 1.9727214065099998, "implement": 1.27437940907, "select": 0.704804687133, "dot": 2.93797215393, "alon": 1.09766791236, "euclidean": 4.70275051433, "part": 0.04239531098280001, "transform": 1.22966322707, "backpropag": 7.18765716411, "that": 0.00397614837964, "includ": 0.0188846813905, "understand": 1.0880858756799998, "repeat": 1.0567930591299999, "straightforward": 3.3234248225200003, "famin": 3.0339960247400004, "this": 0.0037864490525, "pretti": 2.75684036527, "sampl": 1.9786264883900002, "time": 0.0112115188626, "result": 0.136378908381, "lazi": 3.88260364301, "near": 0.252854324034, "differ": 0.212321121312, "embed": 2.82349753127, "nnearest": 7.18765716411, "what": 0.225887296827, "obtain": 0.988162703503, "all": 0.011402632097799998, "top": 0.609100637788, "input": 2.50167533539, "have": 0.0147850023412, "compass": 2.92380426641, "author": 0.35274143130999996, "pair": 1.47447456495, "noah": 3.6299309802199997, "architectur": 1.63469757919, "more": 0.017024931599999998, "and": 6.29901420636e-05, "list": 0.309845761506, "indepth": 7.18765716411, "clear": 0.617474727198, "discuss": 0.78698452262, "achiev": 0.6270980851169999, "these": 0.0715336194008, "gain": 0.6142097989249999, "general": 0.114952578063, "kera": 6.72812483474, "comment": 1.11826753454, "none": 1.40255075163, "target": 1.1690639496200002, "perform": 0.42618085058, "comput": 1.36806891594, "make": 0.07349765782289999, "tdistribut": 7.18765716411, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "eas": 2.202339678, "wordnumvec": 7.18765716411, "necessari": 1.0445450673999999, "neighbor": 1.7546632275799998, "two": 0.0136988443582, "remain": 0.15356296309, "mikolov": 7.18765716411, "data": 1.2168205848, "flood": 1.9380049695500001, "sport": 1.19286482691, "sequenc": 1.8035444374, "sinc": 0.0803681994577, "bio": 3.7456377879300002, "down": 0.306673741186, "embeds": 7.18765716411, "exampl": 0.40868267499899996, "text": 1.14048200999, "dimension": 3.99239120489, "identifi": 0.833722000472, "vocabs": 7.18765716411, "targetword": 7.18765716411, "luckili": 5.25372320611, "generat": 0.719182341736, "presenc": 1.01075093288, "bit": 2.12032652634, "learn": 0.842752064745, "own": 0.164195077421, "dens": 2.3434700776599997}, "freq": {"mark": 1, "sabbath": 1, "onc": 2, "relat": 1, "thorough": 1, "shortest": 1, "five": 1, "faith": 1, "form": 1, "red": 1, "reduct": 1, "assign": 1, "space": 2, "tupl": 1, "addict": 1, "viceversa": 1, "dataset": 1, "function": 2, "dog": 2, "python": 1, "product": 4, "tri": 8, "fox": 4, "complet": 1, "approach": 2, "higher": 1, "know": 2, "their": 3, "chose": 1, "pairwis": 1, "summar": 1, "multipl": 2, "vector": 3, "everlast": 1, "test": 1, "repost": 1, "dismiss": 1, "perceiv": 1, "keraspreprocessingsequ": 1, "abstin": 1, "maintain": 1, "jame": 5, "increas": 1, "circl": 1, "initi": 1, "found": 1, "given": 3, "word": 63, "interest": 6, "deep": 4, "will": 9, "associ": 1, "numxnum": 1, "consid": 3, "alter": 1, "peter": 1, "ran": 1, "updat": 1, "next": 1, "indic": 2, "similar": 9, "but": 3, "need": 1, "our": 37, "classif": 1, "off": 2, "kept": 2, "integ": 1, "sarkar": 2, "has": 5, "surround": 1, "tensorflow": 1, "adjust": 1, "pass": 4, "use": 6, "out": 5, "model": 38, "concept": 1, "much": 1, "brown": 8, "numer": 4, "knew": 1, "loss": 8, "process": 3, "ghost": 1, "far": 1, "henc": 5, "are": 6, "not": 2, "aim": 1, "sticketh": 1, "dead": 1, "quick": 8, "skipgram": 22, "metric": 2, "than": 2, "then": 4, "index": 1, "nifti": 1, "core": 1, "sitcom": 1, "jump": 1, "let": 6, "normbibl": 1, "scienc": 1, "weight": 3, "distanc": 3, "lesser": 1, "egypt": 1, "feed": 2, "simpl": 2, "preced": 2, "valu": 2, "offer": 1, "either": 2, "sent": 1, "such": 2, "context": 21, "with": 11, "lot": 1, "some": 2, "sourc": 2, "should": 1, "mose": 1, "supervis": 1, "springboard": 1, "vocabulari": 13, "dipanjan": 2, "ani": 1, "king": 6, "from": 14, "jehoiachin": 1, "foot": 1, "num": 72, "editor": 1, "els": 1, "possess": 1, "free": 1, "for": 20, "depend": 1, "predict": 7, "output": 3, "match": 1, "pharaoh": 1, "garden": 1, "simplifi": 1, "evil": 1, "merg": 2, "better": 1, "intel": 2, "writer": 1, "shame": 1, "sens": 1, "preprocess": 2, "center": 1, "popular": 1, "summari": 1, "tsne": 2, "extract": 3, "work": 1, "negat": 4, "posit": 6, "util": 1, "focus": 1, "again": 1, "sigmoid": 2, "map": 1, "doe": 1, "john": 1, "give": 2, "train": 7, "master": 1, "wordmodel": 1, "scratch": 1, "error": 1, "framework": 1, "discipl": 1, "hous": 1, "note": 3, "thing": 1, "just": 6, "into": 3, "relev": 8, "compar": 3, "dimens": 2, "abov": 1, "requir": 1, "figur": 1, "contextu": 8, "earlier": 3, "techniqu": 1, "peleg": 1, "god": 1, "present": 1, "believ": 1, "find": 2, "manual": 1, "cover": 1, "success": 1, "base": 6, "occur": 1, "label": 10, "pestil": 1, "pdfnumpdf": 1, "permiss": 1, "wash": 1, "post": 1, "here": 2, "lower": 1, "bibl": 5, "contextword": 1, "layer": 12, "grace": 1, "contain": 1, "meansquarederror": 1, "epoch": 9, "scene": 1, "how": 2, "sentenc": 1, "shem": 1, "jesus": 1, "perspect": 1, "entir": 1, "ignor": 1, "can": 11, "them": 1, "contextwindow": 2, "fair": 1, "where": 6, "complex": 1, "start": 2, "walkthrough": 1, "iniqu": 1, "pattern": 1, "run": 1, "mighti": 2, "explain": 1, "standard": 1, "usual": 2, "had": 1, "uniqu": 7, "over": 1, "build": 10, "depict": 2, "seem": 1, "adversari": 1, "flagon": 1, "same": 4, "command": 1, "say": 1, "origin": 2, "verili": 1, "slight": 1, "take": 3, "visual": 4, "follow": 5, "now": 9, "foreskin": 1, "further": 1, "name": 1, "code": 3, "mentor": 1, "gospel": 1, "semant": 1, "leverag": 5, "break": 1, "feel": 1, "also": 3, "typic": 1, "irrelev": 2, "rufus": 1, "mean": 2, "textual": 1, "revers": 1, "task": 2, "stochast": 1, "window": 2, "the": 101, "invert": 1, "becom": 2, "one": 4, "stand": 1, "scientist": 1, "want": 1, "christ": 1, "behind": 1, "howev": 1, "variabl": 1, "actual": 2, "which": 13, "like": 6, "term": 1, "thus": 3, "other": 2, "appli": 1, "abram": 1, "consist": 2, "show": 2, "merci": 1, "lamb": 1, "see": 4, "river": 1, "corpus": 6, "crack": 1, "get": 7, "random": 8, "implement": 5, "select": 1, "dot": 4, "alon": 1, "euclidean": 2, "part": 3, "transform": 3, "backpropag": 2, "that": 8, "includ": 1, "understand": 2, "repeat": 1, "straightforward": 1, "famin": 1, "this": 20, "pretti": 1, "sampl": 8, "time": 2, "result": 2, "lazi": 2, "near": 2, "differ": 1, "embed": 24, "nnearest": 1, "what": 9, "obtain": 3, "all": 1, "top": 1, "input": 7, "have": 12, "compass": 1, "author": 1, "pair": 15, "noah": 1, "architectur": 8, "more": 3, "and": 37, "list": 1, "indepth": 1, "clear": 3, "discuss": 2, "achiev": 1, "these": 5, "gain": 1, "general": 1, "kera": 2, "comment": 1, "none": 2, "target": 22, "perform": 2, "comput": 4, "make": 1, "tdistribut": 1, "onli": 3, "each": 16, "size": 4, "eas": 1, "wordnumvec": 2, "necessari": 1, "neighbor": 2, "two": 3, "remain": 1, "mikolov": 1, "data": 4, "flood": 1, "sport": 1, "sequenc": 1, "sinc": 2, "bio": 1, "down": 1, "embeds": 2, "exampl": 2, "text": 2, "dimension": 1, "identifi": 6, "vocabs": 1, "targetword": 2, "luckili": 1, "generat": 7, "presenc": 1, "bit": 1, "learn": 5, "own": 2, "dens": 5}, "idf": {"mark": 1.5079787234, "sabbath": 46.8318584071, "onc": 1.4974533106999999, "relat": 1.23750876919, "thorough": 10.956521739100001, "shortest": 39.789473684200004, "five": 1.37740760021, "faith": 4.11082340756, "form": 1.12755681818, "red": 2.22228443449, "reduct": 6.320063694269999, "assign": 3.83663605607, "space": 2.39818731118, "tupl": 661.5, "addict": 20.0454545455, "viceversa": 1323.0, "dataset": 193.609756098, "function": 2.495441685, "dog": 6.26272189349, "python": 56.2978723404, "product": 1.62264922322, "tri": 1.8544562551099997, "fox": 6.53064582476, "complet": 1.24021560816, "approach": 2.07556543339, "higher": 2.1218925421, "know": 2.59327017315, "their": 1.01547908405, "chose": 4.42105263158, "pairwis": 387.219512195, "summar": 15.1056137012, "multipl": 2.74813917258, "vector": 25.898858075, "everlast": 89.6949152542, "test": 2.65707112971, "repost": 933.882352941, "dismiss": 5.2137931034500005, "perceiv": 4.92279069767, "keraspreprocessingsequ": 1323.0, "abstin": 120.27272727299999, "maintain": 1.77306231852, "jame": 1.9313868613099998, "increas": 1.32024948025, "circl": 4.3795862069, "initi": 1.35, "found": 1.11387076405, "given": 1.35426085473, "word": 1.7965372864099998, "interest": 1.60331246213, "deep": 3.6279707495399998, "will": 1.22481098596, "associ": 1.3263157894700002, "numxnum": 52.0524590164, "consid": 1.2397313759200002, "alter": 4.4247491638800005, "peter": 2.34090238868, "ran": 3.4915328788199997, "updat": 5.56466876972, "next": 1.4950560316400001, "indic": 2.0826446281, "similar": 1.37514075357, "but": 1.01632417899, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "off": 1.5121440137200002, "kept": 2.94327030033, "integ": 46.017391304300006, "sarkar": 369.209302326, "has": 1.0436497502, "surround": 2.49858356941, "tensorflow": 1323.0, "adjust": 7.112903225810001, "pass": 1.61818367139, "use": 1.0296387573799999, "out": 1.06016694491, "model": 2.0905978404, "concept": 2.65707112971, "much": 1.1942229577299999, "brown": 3.2215909090900006, "numer": 1.83325635104, "knew": 5.134540750319999, "loss": 2.42529789184, "process": 1.69524826482, "ghost": 11.2595744681, "far": 1.71022298826, "henc": 5.390831918509999, "are": 1.02990593578, "not": 1.01567398119, "aim": 2.8960233491400005, "sticketh": 1323.0, "dead": 2.9608355091400003, "quick": 2.205, "skipgram": 1323.0, "metric": 22.235294117600002, "than": 1.03278688525, "then": 1.08657860516, "index": 6.9969149405, "nifti": 1058.4, "core": 4.623179965059999, "sitcom": 34.588235294099995, "jump": 8.07117437722, "let": 3.48616600791, "normbibl": 1323.0, "scienc": 2.31969608416, "weight": 4.878918254459999, "distanc": 3.4754816112099998, "lesser": 8.10413476263, "egypt": 7.492213308160001, "feed": 7.77853993141, "simpl": 3.3981164383599998, "preced": 4.435875943, "valu": 2.2777618364400003, "offer": 1.53896859248, "either": 1.5830092731099998, "sent": 2.32683570277, "such": 1.06151377374, "context": 4.25972632144, "with": 1.0011982089899998, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "should": 1.6643254009900001, "mose": 20.8073394495, "supervis": 7.74061433447, "springboard": 135.692307692, "vocabulari": 23.2785923754, "dipanjan": 1323.0, "ani": 1.13383802314, "king": 2.0281042411900003, "from": 1.00056721497, "jehoiachin": 1323.0, "foot": 5.65384615385, "num": 1.00031504001, "editor": 4.33060556465, "els": 5.44444444444, "possess": 3.17329602239, "free": 1.71818181818, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "output": 7.676982591880001, "match": 3.5676404494400002, "pharaoh": 62.015625, "garden": 4.294292669730001, "simplifi": 12.109839816900001, "evil": 7.714285714289999, "merg": 5.28319467554, "better": 2.0065722952500002, "intel": 54.5567010309, "writer": 2.75816539263, "shame": 21.7181942544, "sens": 2.8365195640499996, "preprocess": 1221.23076923, "center": 1.7423178226499998, "popular": 1.50769230769, "summari": 7.80147420147, "tsne": 1323.0, "extract": 7.703056768560001, "work": 1.11520089913, "negat": 3.75852272727, "posit": 1.37252528746, "util": 4.65981802172, "focus": 2.01012914662, "again": 1.50883862384, "sigmoid": 1058.4, "map": 4.0728578758300005, "doe": 1.70581282905, "john": 1.35553278689, "give": 1.3653250774, "train": 1.9365698950999999, "master": 3.15125049623, "wordmodel": 1323.0, "scratch": 25.8146341463, "error": 6.04109589041, "framework": 8.200413223139998, "discipl": 24.5378670788, "hous": 1.4624170965399999, "note": 1.42449528937, "thing": 2.4065484311099996, "just": 1.33580143037, "into": 1.01502461479, "relev": 6.938811188810001, "compar": 1.8662278123900002, "dimens": 8.25585023401, "abov": 1.90382539873, "requir": 1.52844902282, "figur": 2.0343413634, "contextu": 76.6956521739, "earlier": 1.86776470588, "techniqu": 3.7293868921800004, "peleg": 1323.0, "god": 3.5217391304300003, "present": 1.25551601423, "believ": 1.6450108797, "find": 1.7294117647099998, "manual": 7.72930866602, "cover": 1.69380134429, "success": 1.32002993265, "base": 1.14628158845, "occur": 1.7453825857499998, "label": 4.47715736041, "pestil": 191.277108434, "pdfnumpdf": 1323.0, "permiss": 6.280063291139999, "wash": 14.3027027027, "post": 2.23826307627, "here": 2.42307692308, "lower": 2.10055570257, "bibl": 9.461263408819999, "contextword": 1323.0, "layer": 8.14153846154, "grace": 8.73267326733, "contain": 1.59814777532, "meansquarederror": 1323.0, "epoch": 38.347826087, "scene": 3.45055422734, "how": 1.60250328051, "sentenc": 5.84536082474, "shem": 305.307692308, "jesus": 9.751842751839998, "perspect": 5.03520456708, "entir": 1.59365589239, "ignor": 4.58446433728, "can": 1.17626139142, "them": 1.09876115994, "contextwindow": 1323.0, "fair": 3.20533010297, "where": 1.06715063521, "complex": 2.34021226415, "start": 1.26673581744, "walkthrough": 793.8, "iniqu": 317.52, "pattern": 3.79173632673, "run": 1.55692850838, "mighti": 25.1202531646, "explain": 2.60049140049, "standard": 1.8915763135900003, "usual": 1.72508964468, "had": 1.0475750577399998, "uniqu": 3.01595744681, "over": 1.02525024217, "build": 1.6341739578, "depict": 4.0131445905000005, "seem": 2.29123971713, "adversari": 26.328358209, "flagon": 1323.0, "same": 1.11857958148, "command": 2.66689064337, "say": 1.7544480053, "origin": 1.13724928367, "verili": 330.75, "slight": 3.25327868852, "take": 1.13961668222, "visual": 5.22752716497, "follow": 1.04640126549, "now": 1.160780873, "foreskin": 835.5789473680001, "further": 1.3618116315, "name": 1.10211732037, "code": 3.8807137619199996, "mentor": 14.8373831776, "gospel": 15.6413793103, "semant": 39.1034482759, "leverag": 35.7567567568, "break": 2.42863698944, "feel": 3.1356903021900004, "also": 1.01476510067, "typic": 2.2541530597799997, "irrelev": 29.7861163227, "rufus": 57.3140794224, "mean": 1.44906900329, "textual": 41.4516971279, "revers": 4.29894394801, "task": 3.88641370869, "stochast": 128.032258065, "window": 5.86479497599, "the": 1.0, "invert": 25.7309562399, "becom": 1.12492028626, "one": 1.00627495722, "stand": 2.0845588235299997, "scientist": 4.69426374926, "want": 1.99698113208, "christ": 8.839643652560001, "behind": 2.0845588235299997, "howev": 1.0945191313299998, "variabl": 8.747107438019999, "actual": 1.87482286254, "which": 1.005191845, "like": 1.14918566775, "term": 1.39520168732, "thus": 1.6463756092500001, "other": 1.00992366412, "appli": 2.2972073506, "abram": 38.255421686700004, "consist": 1.4901445466499998, "show": 1.26703910615, "merci": 16.8177966102, "lamb": 25.483146067399996, "see": 1.27242125511, "river": 2.5204000635, "corpus": 24.091047041, "crack": 13.7216940363, "get": 1.78562591385, "random": 7.1902173913, "implement": 3.57648118946, "select": 2.02345144022, "dot": 18.8775267539, "alon": 2.99716820842, "euclidean": 110.25, "part": 1.04330682789, "transform": 3.42007755278, "backpropag": 1323.0, "that": 1.00398406375, "includ": 1.0190641247799999, "understand": 2.96858638743, "repeat": 2.8771293947099994, "straightforward": 27.7552447552, "famin": 20.780104712, "this": 1.00379362671, "pretti": 15.75, "sampl": 7.23280182232, "time": 1.01127460348, "result": 1.14611608432, "lazi": 48.5504587156, "near": 1.28769567686, "differ": 1.23654490225, "embed": 16.835630965, "nnearest": 1323.0, "what": 1.25343439128, "obtain": 2.68629441624, "all": 1.01146788991, "top": 1.8387769284200002, "input": 12.2029208301, "have": 1.0148948411399998, "compass": 18.611957796, "author": 1.4229631621399998, "pair": 4.36873968079, "noah": 37.7102137767, "architectur": 5.12790697674, "more": 1.0171706817, "and": 1.00006299213, "list": 1.36321483771, "indepth": 1323.0, "clear": 1.85423966363, "discuss": 2.19676214197, "achiev": 1.87216981132, "these": 1.07415426252, "gain": 1.84819557625, "general": 1.1218202374200001, "kera": 835.5789473680001, "comment": 3.05954904606, "none": 4.06555697823, "target": 3.2189781021900004, "perform": 1.5313977042500002, "comput": 3.9277585353800006, "make": 1.0762660158600001, "tdistribut": 1323.0, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "eas": 9.04615384615, "wordnumvec": 1323.0, "necessari": 2.8421052631599997, "neighbor": 5.781500364169999, "two": 1.01379310345, "remain": 1.16598119859, "mikolov": 1323.0, "data": 3.37643555934, "flood": 6.94488188976, "sport": 3.29651162791, "sequenc": 6.07112810707, "sinc": 1.08368600683, "bio": 42.336000000000006, "down": 1.35889754344, "embeds": 1323.0, "exampl": 1.50483412322, "text": 3.12827586207, "dimension": 54.1843003413, "identifi": 2.30187037843, "vocabs": 1323.0, "targetword": 1323.0, "luckili": 191.277108434, "generat": 2.05275407292, "presenc": 2.7476635514, "bit": 8.33385826772, "learn": 2.32275054865, "own": 1.17844418052, "dens": 10.4173228346}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/paw-cant-miss-keynotes-paw-financial-vegas.html\" rel=\"prev\" title=\"Can\u2019t-Miss Keynotes at PAW Financial, plus 3 other PAWs in Vegas \u2013 Save \u2019til April 27\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/cold-start-ai.html\" rel=\"next\" title=\"The Cold Start Problem with AI\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=79483\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-79483 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 10-Apr, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model (\u00a0<a href=\"/2018/n15.html\">18:n15</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/04/paw-cant-miss-keynotes-paw-financial-vegas.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/04/cold-start-ai.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/feature-engineering\" rel=\"tag\">Feature Engineering</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/python\" rel=\"tag\">Python</a>, <a href=\"https://www.kdnuggets.com/tag/text-mining\" rel=\"tag\">Text Mining</a>, <a href=\"https://www.kdnuggets.com/tag/word-embeddings\" rel=\"tag\">Word Embeddings</a></div>\n<br/>\n<p class=\"excerpt\">\n     Just like we discussed in the CBOW model, we need to model this Skip-gram architecture now as a deep learning classification model such that we take in the target word as our input and try to predict the context words.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a>, Intel</b></p>\n<blockquote><p>\n<b>Editor's note:</b> This post is only one part of a far more thorough and in-depth original, <a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener\" target=\"_blank\">found here</a>, which covers much more than what is included here.\n</p></blockquote>\n<h3>The Skip-gram Model</h3>\n<p>\u00a0<br>\nThe Skip-gram model architecture usually tries to achieve the reverse of what the CBOW model does. It tries to predict the source context words (surrounding words) given a target word (the center word). Considering our simple sentence from earlier,\u00a0<strong><em>\u201cthe quick brown fox jumps over the lazy dog\u201d.</em></strong> If we used the CBOW model, we get pairs of\u00a0<strong><em>(context_window, target_word)</em></strong>where if we consider a context window of size 2, we have examples like\u00a0<strong><em>([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0</em></strong>and so on. Now considering that the skip-gram model\u2019s aim is to predict the context from the target word, the model typically inverts the contexts and targets, and tries to predict each context word from its target word. Hence the task becomes to predict the context\u00a0<strong><em>[quick, fox]</em></strong>\u00a0given target word <strong><em>\u2018brown\u2019 </em></strong>or <strong><em>[the, brown]</em></strong> given target word\u00a0<strong><em>\u2018quick\u2019</em></strong>\u00a0and so on. Thus the model tries to predict the context_window words based on the target_word.</br></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*SR6l59udY05_bUICAjb6-w.png\" width=\"300\"><br>\n<font size=\"-1\">The Skip-gram model architecture (Source:\u00a0<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">https://arxiv.org/pdf/1301.3781.pdf</a>\u00a0Mikolov el\u00a0al.)</font></br></img></center></p>\n<p>Just like we discussed in the CBOW model, we need to model this Skip-gram architecture now as a deep learning classification model such that we take in the\u00a0<em>target word as our input\u00a0</em>and try to\u00a0<em>predict the context words.</em>This becomes slightly complex since we have multiple words in our context. We simplify this further by breaking down each\u00a0<strong><em>(target, context_words) pair</em></strong>\u00a0into\u00a0<strong><em>(target, context) pairs</em></strong>\u00a0such that each context consists of only one word. Hence our dataset from earlier gets transformed into pairs like\u00a0<strong><em>(brown, quick), (brown, fox), (quick, the), (quick, brown)</em></strong>\u00a0and so on. But how to supervise or train the model to know what is contextual and what is not?</p>\n<p>For this, we feed our skip-gram model pairs of\u00a0<strong><em>(X, Y)</em></strong>\u00a0where\u00a0<strong><em>X\u00a0</em></strong>is our\u00a0<strong><em>input\u00a0</em></strong>and\u00a0<strong><em>Y\u00a0</em></strong>is our\u00a0<strong><em>label</em></strong>. We do this by using\u00a0<strong><em>[(target, context), 1]\u00a0</em></strong>pairs as\u00a0<strong><em>positive input samples</em></strong>\u00a0where\u00a0<strong><em>target\u00a0</em></strong>is our word of interest and\u00a0<strong><em>context\u00a0</em></strong>is a context word occurring near the target word and the\u00a0<strong><em>positive label 1</em></strong>\u00a0indicates this is a contextually relevant pair. We also feed in\u00a0<strong><em>[(target, random), 0]</em></strong>\u00a0pairs as\u00a0<strong><em>negative input samples</em></strong>\u00a0where\u00a0<strong><em>target\u00a0</em></strong>is again our word of interest but\u00a0<strong><em>random\u00a0</em></strong>is just a randomly selected word from our vocabulary which has no context or association with our target word. Hence the\u00a0<strong><em>negative label 0</em></strong>indicates this is a contextually irrelevant pair. We do this so that the model can then learn which pairs of words are contextually relevant and which are not and generate similar embeddings for semantically similar words.</p>\n<p>\u00a0</p>\n<h3>Implementing the Skip-gram Model</h3>\n<p>\u00a0<br>\nLet\u2019s now try and implement this model from scratch to gain some perspective on how things work behind the scenes and also so that we can compare it with our implementation of the CBOW model. We will leverage our Bible corpus as usual which is contained in the\u00a0<code><strong>norm_bible</strong></code>\u00a0variable for training our model. The implementation will focus on five parts</br></p>\n<ul>\n<li><strong>Build the corpus vocabulary</strong>\n<li><strong>Build a skip-gram [(target, context), relevancy] generator</strong>\n<li><strong>Build the skip-gram model architecture</strong>\n<li><strong>Train the Model</strong>\n<li><strong>Get Word Embeddings</strong>\n</li></li></li></li></li></ul>\n<p>Let\u2019s get cracking and build our skip-gram Word2Vec model!</p>\n<p><b>Build the corpus vocabulary</b></p>\n<p>To start off, we will follow the standard process of building our corpus vocabulary where we extract out each unique word from our vocabulary and assign a unique identifier, similar to what we did in the CBOW model. We also maintain mappings to transform words to their unique identifiers and vice-versa.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/84f415ae0781c1d42f6fb0ac843bf63e.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Vocabulary Size: 12425\r\nVocabulary Sample: [('perceived', 1460), ('flagon', 7287), ('gardener', 11641), ('named', 973), ('remain', 732), ('sticketh', 10622), ('abstinence', 11848), ('rufus', 8190), ('adversary', 2018), ('jehoiachin', 3189)]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Just like we wanted, each unique word from the corpus is a part of our vocabulary now with a unique numeric identifier.</p>\n<p><b>Build a skip-gram [(target, context), relevancy] generator</b></p>\n<p>It\u2019s now time to build out our skip-gram generator which will give us pair of words and their relevance like we discussed earlier. Luckily,\u00a0<code>keras</code>\u00a0has a nifty\u00a0<code>skipgrams</code>\u00a0utility which can be used and we don\u2019t have to manually implement this generator like we did in CBOW.</p>\n<blockquote><p><strong>Note:</strong>\u00a0The function\u00a0<code><a href=\"https://keras.io/preprocessing/sequence/#skipgrams\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>skipgrams(\u2026)</strong></a></code>\u00a0is present in\u00a0<code><a href=\"https://keras.io/preprocessing/sequence\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>keras.preprocessing.sequence</strong></a></code></p>\n<p>This function transforms a sequence of word indexes (list of integers) into tuples of words of the form:<br/>\n- (word, word in the same window), with label 1 (positive samples).<br/>\n- (word, random word from the vocabulary), with label 0 (negative samples).</p></blockquote>\n<p><script src=\"https://gist.github.com/dipanjanS/865248edadb721f754bad10e874a9866.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre><strong>(james (1154), king (13)) -&gt; 1\r\n(king (13), james (1154)) -&gt; 1\r\n(james (1154), perform (1249)) -&gt; 0\r\n(bible (5766), dismissed (6274)) -&gt; 0\r\n(king (13), alter (5275)) -&gt; 0\r\n(james (1154), bible (5766)) -&gt; 1\r\n(king (13), bible (5766)) -&gt; 1\r\n(bible (5766), king (13)) -&gt; 1\r\n(king (13), compassion (1279)) -&gt; 0\r\n(james (1154), foreskins (4844)) -&gt; 0</strong></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Thus you can see we have successfully generated our required skip-grams and based on the sample skip-grams in the preceding output, you can clearly see what is relevant and what is irrelevant based on the label (0 or 1).</p>\n<p><b>Build the skip-gram model architecture</b></p>\n<p>We now leverage\u00a0<code>keras</code>\u00a0on top of\u00a0<code>tensorflow</code>\u00a0to build our deep learning architecture for the skip-gram model. For this our inputs will be our target word and context or random word pair. Each of which are passed to an embedding layer (initialized with random weights) of it\u2019s own. Once we obtain the word embeddings for the target and the context word, we pass it to a merge layer where we compute the dot product of these two vectors. Then we pass on this dot product value to a dense sigmoid layer which predicts either a 1 or a 0 depending on if the pair of words are contextually relevant or just random words (<strong><em>Y\u2019</em></strong>). We match this with the actual relevance label (<strong><em>Y</em></strong>), compute the loss by leveraging the\u00a0<code>mean_squared_error</code>\u00a0loss and perform backpropagation with each epoch to update the embedding layer in the process. Following code shows us our model architecture.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/dbff31351127c893a4579c9be11e113d.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*tXimFtA5R2jswNjVT80Q5Q.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Skip-gram model summary and architecture</font></center></p>\n<p>Understanding the above deep learning model is pretty straightforward. However, I will try to summarize the core concepts of this model in simple terms for ease of understanding. We have a pair of input words for each training example consisting of\u00a0<strong><em>one input target word</em></strong>\u00a0having a unique numeric identifier and\u00a0<strong><em>one context word</em></strong>\u00a0having a unique numeric identifier. If it is\u00a0<strong><em>a positive sample</em></strong>\u00a0the word has contextual meaning, is\u00a0<strong><em>a context word</em></strong>and our\u00a0<strong><em>label Y=1</em></strong>, else if it is a\u00a0<strong><em>negative sample</em></strong>, the word has no contextual meaning, is just\u00a0<strong><em>a random word</em></strong>\u00a0and our\u00a0<strong><em>label Y=0</em></strong>. We will pass each of them to an\u00a0<strong><em>embedding layer</em></strong>\u00a0of their own, having size\u00a0<code><strong>(vocab_size x embed_size)</strong></code>\u00a0which will give us\u00a0<strong><em>dense word embeddings</em></strong>\u00a0for each of these two words\u00a0<code><strong>(1 x embed_size for each word)</strong></code>. Next up we use a\u00a0<strong><em>merge layer</em></strong>\u00a0to compute the\u00a0<strong><em>dot product</em></strong>\u00a0of these two embeddings and get the dot product value. This is then sent to the\u00a0<strong><em>dense sigmoid layer</em></strong>\u00a0which outputs either a 1 or 0. We compare this with the actual label Y (1 or 0), compute the loss, backpropagate the errors to adjust the weights (in the embedding layer) and repeat this process for all\u00a0<strong><em>(target, context)</em></strong>\u00a0pairs for multiple epochs. The following figure tries to explain the same.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*4Uil1zWWF5-jlt-FnRJgAQ.png\" width=\"60%\"/><br/>\n<font size=\"-1\">Visual depiction of the Skip-gram deep learning\u00a0model</font></center></p>\n<p>Let\u2019s now start training our model with our skip-grams.</p>\n<p><b>Train the\u00a0Model</b></p>\n<p>Running the model on our complete corpus takes a fair bit of time but lesser than the CBOW model. Hence I just ran it for 5 epochs. You can leverage the following code and increase it for more epochs if necessary.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/a820a598b2d93c2d57e2dd8319936095.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Epoch: 1 Loss: 4529.63803683\r\nEpoch: 2 Loss: 3750.71884749\r\nEpoch: 3 Loss: 3752.47489296\r\nEpoch: 4 Loss: 3793.9177565\r\nEpoch: 5 Loss: 3716.07605051</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Once this model is trained, similar words should have similar weights based off the embedding layer and we can test out the same.</p>\n<p><b>Get Word Embeddings</b></p>\n<p>To get word embeddings for our entire vocabulary, we can extract out the same from our embedding layer by leveraging the following code. Do note that we are only interested in the target word embedding layer, hence we will extract the embeddings from our\u00a0<code><strong>word_model</strong></code>\u00a0embedding layer. We don\u2019t take the embedding at position 0 since none of our words in the vocabulary have a numeric identifier of 0 and we ignore it.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/e21c2fe26a54c3bbf90fe751989a7560.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*guUd_CKJHYOwNIIt_6YchA.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Word Embeddings for our vocabulary based on the Skip-gram model</font></center></p>\n<p>Thus you can clearly see that each word has a dense embedding of size\u00a0<code><strong>(1x100)</strong></code>\u00a0as depicted in the preceding output similar to what we had obtained from the CBOW model. Let\u2019s now apply the euclidean distance metric on these dense embedding vectors to generate a pairwise distance metric for each word in our vocabulary. We can then find out the n-nearest neighbors of each word of interest based on the shortest (euclidean) distance similar to what we did on the embeddings from our CBOW model.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/3557b2a27d4365e16890aee3e6e35dbe.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>(<strong>12424, 12424)</strong>\r\n\r\n<strong>{'egypt': ['pharaoh', 'mighty', 'houses', 'kept', 'possess'],\r\n 'famine': ['rivers', 'foot', 'pestilence', 'wash', 'sabbaths'],\r\n 'god': ['evil', 'iniquity', 'none', 'mighty', 'mercy'],\r\n 'gospel': ['grace', 'shame', 'believed', 'verily', 'everlasting'],\r\n 'jesus': ['christ', 'faith', 'disciples', 'dead', 'say'],\r\n 'john': ['ghost', 'knew', 'peter', 'alone', 'master'],\r\n 'moses': ['commanded', 'offerings', 'kept', 'presence', 'lamb'],\r\n 'noah': ['flood', 'shem', 'peleg', 'abram', 'chose']}</strong></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>You can clearly see from the results that a lot of the similar words for each of the words of interest are making sense and we have obtained better results as compared to our CBOW model. Let\u2019s visualize these words embeddings now using\u00a0<a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>t-SNE</strong></a><strong>\u00a0</strong>which stands for\u00a0<a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\" rel=\"noopener noreferrer\" target=\"_blank\"><strong><em>t-distributed stochastic neighbor embedding</em></strong></a><strong>\u00a0</strong>a popular\u00a0<a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\" rel=\"noopener noreferrer\" target=\"_blank\">dimensionality reduction</a>\u00a0technique to visualize higher dimension spaces in lower dimensions (e.g. 2-D).</p>\n<p><script src=\"https://gist.github.com/dipanjanS/7aa50bfdc663afdb106c1d842332f637.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*5N5p0cqCitIiGpfbQufc-A.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Visualizing skip-gram word2vec word embeddings using\u00a0t-SNE</font></center></p>\n<p>I have marked some circles in red which seemed to show different words of contextual similarity positioned near each other in the vector space. If you find any other interesting patterns feel free to let me know!</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a></b> is a Data Scientist @Intel, an author, a mentor @Springboard, a writer, and a sports and sitcom addict.</p>\n<p><a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/03/text-data-preprocessing-walkthrough-python.html\">Text Data Preprocessing: A Walkthrough in Python</a>\n<li><a href=\"/2017/12/general-approach-preprocessing-text-data.html\">A General Approach to Preprocessing Text Data</a>\n<li><a href=\"/2017/11/framework-approaching-textual-data-tasks.html\">A Framework for Approaching Textual Data Science Tasks<br/>\n</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/04/paw-cant-miss-keynotes-paw-financial-vegas.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/04/cold-start-ai.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model (\u00a0<a href=\"/2018/n15.html\">18:n15</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556326396\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.771 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 20:53:16 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "dipanjan", "sarkar", "intel", "editor", "note", "this", "post", "onli", "one", "part", "far", "more", "thorough", "and", "indepth", "origin", "found", "here", "which", "cover", "much", "more", "than", "what", "includ", "here", "the", "skipgram", "model", "the", "skipgram", "model", "architectur", "usual", "tri", "achiev", "the", "revers", "what", "the", "model", "doe", "tri", "predict", "the", "sourc", "context", "word", "surround", "word", "given", "target", "word", "the", "center", "word", "consid", "our", "simpl", "sentenc", "from", "earlier", "the", "quick", "brown", "fox", "jump", "over", "the", "lazi", "dog", "use", "the", "model", "get", "pair", "contextwindow", "targetword", "where", "consid", "context", "window", "size", "num", "have", "exampl", "like", "quick", "fox", "brown", "the", "brown", "quick", "the", "dog", "lazi", "and", "now", "consid", "that", "the", "skipgram", "model", "aim", "predict", "the", "context", "from", "the", "target", "word", "the", "model", "typic", "invert", "the", "context", "and", "target", "and", "tri", "predict", "each", "context", "word", "from", "target", "word", "henc", "the", "task", "becom", "predict", "the", "context", "quick", "fox", "given", "target", "word", "brown", "the", "brown", "given", "target", "word", "quick", "and", "thus", "the", "model", "tri", "predict", "the", "contextwindow", "word", "base", "the", "targetword", "the", "skipgram", "model", "architectur", "sourc", "pdfnumpdf", "mikolov", "just", "like", "discuss", "the", "model", "need", "model", "this", "skipgram", "architectur", "now", "deep", "learn", "classif", "model", "such", "that", "take", "the", "target", "word", "our", "input", "and", "tri", "predict", "the", "context", "word", "this", "becom", "slight", "complex", "sinc", "have", "multipl", "word", "our", "context", "simplifi", "this", "further", "break", "down", "each", "target", "contextword", "pair", "into", "target", "context", "pair", "such", "that", "each", "context", "consist", "onli", "one", "word", "henc", "our", "dataset", "from", "earlier", "get", "transform", "into", "pair", "like", "brown", "quick", "brown", "fox", "quick", "the", "quick", "brown", "and", "but", "how", "supervis", "train", "the", "model", "know", "what", "contextu", "and", "what", "not", "for", "this", "feed", "our", "skipgram", "model", "pair", "where", "our", "input", "and", "our", "label", "this", "use", "target", "context", "num", "pair", "posit", "input", "sampl", "where", "target", "our", "word", "interest", "and", "context", "context", "word", "occur", "near", "the", "target", "word", "and", "the", "posit", "label", "num", "indic", "this", "contextu", "relev", "pair", "also", "feed", "target", "random", "num", "pair", "negat", "input", "sampl", "where", "target", "again", "our", "word", "interest", "but", "random", "just", "random", "select", "word", "from", "our", "vocabulari", "which", "has", "context", "associ", "with", "our", "target", "word", "henc", "the", "negat", "label", "num", "indic", "this", "contextu", "irrelev", "pair", "this", "that", "the", "model", "can", "then", "learn", "which", "pair", "word", "are", "contextu", "relev", "and", "which", "are", "not", "and", "generat", "similar", "embed", "for", "semant", "similar", "word", "implement", "the", "skipgram", "model", "let", "now", "tri", "and", "implement", "this", "model", "from", "scratch", "gain", "some", "perspect", "how", "thing", "work", "behind", "the", "scene", "and", "also", "that", "can", "compar", "with", "our", "implement", "the", "model", "will", "leverag", "our", "bibl", "corpus", "usual", "which", "contain", "the", "normbibl", "variabl", "for", "train", "our", "model", "the", "implement", "will", "focus", "five", "part", "build", "the", "corpus", "vocabulari", "build", "skipgram", "target", "context", "relev", "generat", "build", "the", "skipgram", "model", "architectur", "train", "the", "model", "get", "word", "embed", "let", "get", "crack", "and", "build", "our", "skipgram", "wordnumvec", "model", "build", "the", "corpus", "vocabulari", "start", "off", "will", "follow", "the", "standard", "process", "build", "our", "corpus", "vocabulari", "where", "extract", "out", "each", "uniqu", "word", "from", "our", "vocabulari", "and", "assign", "uniqu", "identifi", "similar", "what", "the", "model", "also", "maintain", "map", "transform", "word", "their", "uniqu", "identifi", "and", "viceversa", "vocabulari", "size", "num", "vocabulari", "sampl", "perceiv", "num", "flagon", "num", "garden", "num", "name", "num", "remain", "num", "sticketh", "num", "abstin", "num", "rufus", "num", "adversari", "num", "jehoiachin", "num", "just", "like", "want", "each", "uniqu", "word", "from", "the", "corpus", "part", "our", "vocabulari", "now", "with", "uniqu", "numer", "identifi", "build", "skipgram", "target", "context", "relev", "generat", "now", "time", "build", "out", "our", "skipgram", "generat", "which", "will", "give", "pair", "word", "and", "their", "relev", "like", "discuss", "earlier", "luckili", "kera", "has", "nifti", "skipgram", "util", "which", "can", "use", "and", "have", "manual", "implement", "this", "generat", "like", "note", "the", "function", "present", "keraspreprocessingsequ", "this", "function", "transform", "sequenc", "word", "index", "list", "integ", "into", "tupl", "word", "the", "form", "word", "word", "the", "same", "window", "with", "label", "num", "posit", "sampl", "word", "random", "word", "from", "the", "vocabulari", "with", "label", "num", "negat", "sampl", "jame", "num", "king", "num", "num", "king", "num", "jame", "num", "num", "jame", "num", "perform", "num", "num", "bibl", "num", "dismiss", "num", "num", "king", "num", "alter", "num", "num", "jame", "num", "bibl", "num", "num", "king", "num", "bibl", "num", "num", "bibl", "num", "king", "num", "num", "king", "num", "compass", "num", "num", "jame", "num", "foreskin", "num", "num", "thus", "can", "see", "have", "success", "generat", "our", "requir", "skipgram", "and", "base", "the", "sampl", "skipgram", "the", "preced", "output", "can", "clear", "see", "what", "relev", "and", "what", "irrelev", "base", "the", "label", "num", "num", "build", "the", "skipgram", "model", "architectur", "now", "leverag", "kera", "top", "tensorflow", "build", "our", "deep", "learn", "architectur", "for", "the", "skipgram", "model", "for", "this", "our", "input", "will", "our", "target", "word", "and", "context", "random", "word", "pair", "each", "which", "are", "pass", "embed", "layer", "initi", "with", "random", "weight", "own", "onc", "obtain", "the", "word", "embed", "for", "the", "target", "and", "the", "context", "word", "pass", "merg", "layer", "where", "comput", "the", "dot", "product", "these", "two", "vector", "then", "pass", "this", "dot", "product", "valu", "dens", "sigmoid", "layer", "which", "predict", "either", "num", "num", "depend", "the", "pair", "word", "are", "contextu", "relev", "just", "random", "word", "match", "this", "with", "the", "actual", "relev", "label", "comput", "the", "loss", "leverag", "the", "meansquarederror", "loss", "and", "perform", "backpropag", "with", "each", "epoch", "updat", "the", "embed", "layer", "the", "process", "follow", "code", "show", "our", "model", "architectur", "skipgram", "model", "summari", "and", "architectur", "understand", "the", "abov", "deep", "learn", "model", "pretti", "straightforward", "howev", "will", "tri", "summar", "the", "core", "concept", "this", "model", "simpl", "term", "for", "eas", "understand", "have", "pair", "input", "word", "for", "each", "train", "exampl", "consist", "one", "input", "target", "word", "have", "uniqu", "numer", "identifi", "and", "one", "context", "word", "have", "uniqu", "numer", "identifi", "posit", "sampl", "the", "word", "has", "contextu", "mean", "context", "word", "and", "our", "label", "els", "negat", "sampl", "the", "word", "has", "contextu", "mean", "just", "random", "word", "and", "our", "label", "will", "pass", "each", "them", "embed", "layer", "their", "own", "have", "size", "vocabs", "embeds", "which", "will", "give", "dens", "word", "embed", "for", "each", "these", "two", "word", "num", "embeds", "for", "each", "word", "next", "use", "merg", "layer", "comput", "the", "dot", "product", "these", "two", "embed", "and", "get", "the", "dot", "product", "valu", "this", "then", "sent", "the", "dens", "sigmoid", "layer", "which", "output", "either", "num", "num", "compar", "this", "with", "the", "actual", "label", "num", "num", "comput", "the", "loss", "backpropag", "the", "error", "adjust", "the", "weight", "the", "embed", "layer", "and", "repeat", "this", "process", "for", "all", "target", "context", "pair", "for", "multipl", "epoch", "the", "follow", "figur", "tri", "explain", "the", "same", "visual", "depict", "the", "skipgram", "deep", "learn", "model", "let", "now", "start", "train", "our", "model", "with", "our", "skipgram", "train", "the", "model", "run", "the", "model", "our", "complet", "corpus", "take", "fair", "bit", "time", "but", "lesser", "than", "the", "model", "henc", "just", "ran", "for", "num", "epoch", "can", "leverag", "the", "follow", "code", "and", "increas", "for", "more", "epoch", "necessari", "epoch", "num", "loss", "num", "epoch", "num", "loss", "num", "epoch", "num", "loss", "num", "epoch", "num", "loss", "num", "epoch", "num", "loss", "num", "onc", "this", "model", "train", "similar", "word", "should", "have", "similar", "weight", "base", "off", "the", "embed", "layer", "and", "can", "test", "out", "the", "same", "get", "word", "embed", "get", "word", "embed", "for", "our", "entir", "vocabulari", "can", "extract", "out", "the", "same", "from", "our", "embed", "layer", "leverag", "the", "follow", "code", "note", "that", "are", "onli", "interest", "the", "target", "word", "embed", "layer", "henc", "will", "extract", "the", "embed", "from", "our", "wordmodel", "embed", "layer", "take", "the", "embed", "posit", "num", "sinc", "none", "our", "word", "the", "vocabulari", "have", "numer", "identifi", "num", "and", "ignor", "word", "embed", "for", "our", "vocabulari", "base", "the", "skipgram", "model", "thus", "can", "clear", "see", "that", "each", "word", "has", "dens", "embed", "size", "numxnum", "depict", "the", "preced", "output", "similar", "what", "had", "obtain", "from", "the", "model", "let", "now", "appli", "the", "euclidean", "distanc", "metric", "these", "dens", "embed", "vector", "generat", "pairwis", "distanc", "metric", "for", "each", "word", "our", "vocabulari", "can", "then", "find", "out", "the", "nnearest", "neighbor", "each", "word", "interest", "base", "the", "shortest", "euclidean", "distanc", "similar", "what", "the", "embed", "from", "our", "model", "num", "num", "egypt", "pharaoh", "mighti", "hous", "kept", "possess", "famin", "river", "foot", "pestil", "wash", "sabbath", "god", "evil", "iniqu", "none", "mighti", "merci", "gospel", "grace", "shame", "believ", "verili", "everlast", "jesus", "christ", "faith", "discipl", "dead", "say", "john", "ghost", "knew", "peter", "alon", "master", "mose", "command", "offer", "kept", "presenc", "lamb", "noah", "flood", "shem", "peleg", "abram", "chose", "can", "clear", "see", "from", "the", "result", "that", "lot", "the", "similar", "word", "for", "each", "the", "word", "interest", "are", "make", "sens", "and", "have", "obtain", "better", "result", "compar", "our", "model", "let", "visual", "these", "word", "embed", "now", "use", "tsne", "which", "stand", "for", "tdistribut", "stochast", "neighbor", "embed", "popular", "dimension", "reduct", "techniqu", "visual", "higher", "dimens", "space", "lower", "dimens", "visual", "skipgram", "wordnumvec", "word", "embed", "use", "tsne", "have", "mark", "some", "circl", "red", "which", "seem", "show", "differ", "word", "contextu", "similar", "posit", "near", "each", "other", "the", "vector", "space", "find", "ani", "other", "interest", "pattern", "feel", "free", "let", "know", "bio", "dipanjan", "sarkar", "data", "scientist", "intel", "author", "mentor", "springboard", "writer", "and", "sport", "and", "sitcom", "addict", "origin", "repost", "with", "permiss", "relat", "text", "data", "preprocess", "walkthrough", "python", "general", "approach", "preprocess", "text", "data", "framework", "for", "approach", "textual", "data", "scienc", "task"], "timestamp_scraper": 1556379290.373043, "title": "Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model", "read_time": 524.4, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a>, Intel</b></p>\n<blockquote><p>\n<b>Editor's note:</b> This post is only one part of a far more thorough and in-depth original, <a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener\" target=\"_blank\">found here</a>, which covers much more than what is included here.\n</p></blockquote>\n<h3>The Skip-gram Model</h3>\n<p>\u00a0<br>\nThe Skip-gram model architecture usually tries to achieve the reverse of what the CBOW model does. It tries to predict the source context words (surrounding words) given a target word (the center word). Considering our simple sentence from earlier,\u00a0<strong><em>\u201cthe quick brown fox jumps over the lazy dog\u201d.</em></strong> If we used the CBOW model, we get pairs of\u00a0<strong><em>(context_window, target_word)</em></strong>where if we consider a context window of size 2, we have examples like\u00a0<strong><em>([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0</em></strong>and so on. Now considering that the skip-gram model\u2019s aim is to predict the context from the target word, the model typically inverts the contexts and targets, and tries to predict each context word from its target word. Hence the task becomes to predict the context\u00a0<strong><em>[quick, fox]</em></strong>\u00a0given target word <strong><em>\u2018brown\u2019 </em></strong>or <strong><em>[the, brown]</em></strong> given target word\u00a0<strong><em>\u2018quick\u2019</em></strong>\u00a0and so on. Thus the model tries to predict the context_window words based on the target_word.</br></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*SR6l59udY05_bUICAjb6-w.png\" width=\"300\"><br>\n<font size=\"-1\">The Skip-gram model architecture (Source:\u00a0<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">https://arxiv.org/pdf/1301.3781.pdf</a>\u00a0Mikolov el\u00a0al.)</font></br></img></center></p>\n<p>Just like we discussed in the CBOW model, we need to model this Skip-gram architecture now as a deep learning classification model such that we take in the\u00a0<em>target word as our input\u00a0</em>and try to\u00a0<em>predict the context words.</em>This becomes slightly complex since we have multiple words in our context. We simplify this further by breaking down each\u00a0<strong><em>(target, context_words) pair</em></strong>\u00a0into\u00a0<strong><em>(target, context) pairs</em></strong>\u00a0such that each context consists of only one word. Hence our dataset from earlier gets transformed into pairs like\u00a0<strong><em>(brown, quick), (brown, fox), (quick, the), (quick, brown)</em></strong>\u00a0and so on. But how to supervise or train the model to know what is contextual and what is not?</p>\n<p>For this, we feed our skip-gram model pairs of\u00a0<strong><em>(X, Y)</em></strong>\u00a0where\u00a0<strong><em>X\u00a0</em></strong>is our\u00a0<strong><em>input\u00a0</em></strong>and\u00a0<strong><em>Y\u00a0</em></strong>is our\u00a0<strong><em>label</em></strong>. We do this by using\u00a0<strong><em>[(target, context), 1]\u00a0</em></strong>pairs as\u00a0<strong><em>positive input samples</em></strong>\u00a0where\u00a0<strong><em>target\u00a0</em></strong>is our word of interest and\u00a0<strong><em>context\u00a0</em></strong>is a context word occurring near the target word and the\u00a0<strong><em>positive label 1</em></strong>\u00a0indicates this is a contextually relevant pair. We also feed in\u00a0<strong><em>[(target, random), 0]</em></strong>\u00a0pairs as\u00a0<strong><em>negative input samples</em></strong>\u00a0where\u00a0<strong><em>target\u00a0</em></strong>is again our word of interest but\u00a0<strong><em>random\u00a0</em></strong>is just a randomly selected word from our vocabulary which has no context or association with our target word. Hence the\u00a0<strong><em>negative label 0</em></strong>indicates this is a contextually irrelevant pair. We do this so that the model can then learn which pairs of words are contextually relevant and which are not and generate similar embeddings for semantically similar words.</p>\n<p>\u00a0</p>\n<h3>Implementing the Skip-gram Model</h3>\n<p>\u00a0<br>\nLet\u2019s now try and implement this model from scratch to gain some perspective on how things work behind the scenes and also so that we can compare it with our implementation of the CBOW model. We will leverage our Bible corpus as usual which is contained in the\u00a0<code><strong>norm_bible</strong></code>\u00a0variable for training our model. The implementation will focus on five parts</br></p>\n<ul>\n<li><strong>Build the corpus vocabulary</strong>\n<li><strong>Build a skip-gram [(target, context), relevancy] generator</strong>\n<li><strong>Build the skip-gram model architecture</strong>\n<li><strong>Train the Model</strong>\n<li><strong>Get Word Embeddings</strong>\n</li></li></li></li></li></ul>\n<p>Let\u2019s get cracking and build our skip-gram Word2Vec model!</p>\n<p><b>Build the corpus vocabulary</b></p>\n<p>To start off, we will follow the standard process of building our corpus vocabulary where we extract out each unique word from our vocabulary and assign a unique identifier, similar to what we did in the CBOW model. We also maintain mappings to transform words to their unique identifiers and vice-versa.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/84f415ae0781c1d42f6fb0ac843bf63e.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Vocabulary Size: 12425\r\nVocabulary Sample: [('perceived', 1460), ('flagon', 7287), ('gardener', 11641), ('named', 973), ('remain', 732), ('sticketh', 10622), ('abstinence', 11848), ('rufus', 8190), ('adversary', 2018), ('jehoiachin', 3189)]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Just like we wanted, each unique word from the corpus is a part of our vocabulary now with a unique numeric identifier.</p>\n<p><b>Build a skip-gram [(target, context), relevancy] generator</b></p>\n<p>It\u2019s now time to build out our skip-gram generator which will give us pair of words and their relevance like we discussed earlier. Luckily,\u00a0<code>keras</code>\u00a0has a nifty\u00a0<code>skipgrams</code>\u00a0utility which can be used and we don\u2019t have to manually implement this generator like we did in CBOW.</p>\n<blockquote><p><strong>Note:</strong>\u00a0The function\u00a0<code><a href=\"https://keras.io/preprocessing/sequence/#skipgrams\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>skipgrams(\u2026)</strong></a></code>\u00a0is present in\u00a0<code><a href=\"https://keras.io/preprocessing/sequence\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>keras.preprocessing.sequence</strong></a></code></p>\n<p>This function transforms a sequence of word indexes (list of integers) into tuples of words of the form:<br/>\n- (word, word in the same window), with label 1 (positive samples).<br/>\n- (word, random word from the vocabulary), with label 0 (negative samples).</p></blockquote>\n<p><script src=\"https://gist.github.com/dipanjanS/865248edadb721f754bad10e874a9866.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre><strong>(james (1154), king (13)) -&gt; 1\r\n(king (13), james (1154)) -&gt; 1\r\n(james (1154), perform (1249)) -&gt; 0\r\n(bible (5766), dismissed (6274)) -&gt; 0\r\n(king (13), alter (5275)) -&gt; 0\r\n(james (1154), bible (5766)) -&gt; 1\r\n(king (13), bible (5766)) -&gt; 1\r\n(bible (5766), king (13)) -&gt; 1\r\n(king (13), compassion (1279)) -&gt; 0\r\n(james (1154), foreskins (4844)) -&gt; 0</strong></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Thus you can see we have successfully generated our required skip-grams and based on the sample skip-grams in the preceding output, you can clearly see what is relevant and what is irrelevant based on the label (0 or 1).</p>\n<p><b>Build the skip-gram model architecture</b></p>\n<p>We now leverage\u00a0<code>keras</code>\u00a0on top of\u00a0<code>tensorflow</code>\u00a0to build our deep learning architecture for the skip-gram model. For this our inputs will be our target word and context or random word pair. Each of which are passed to an embedding layer (initialized with random weights) of it\u2019s own. Once we obtain the word embeddings for the target and the context word, we pass it to a merge layer where we compute the dot product of these two vectors. Then we pass on this dot product value to a dense sigmoid layer which predicts either a 1 or a 0 depending on if the pair of words are contextually relevant or just random words (<strong><em>Y\u2019</em></strong>). We match this with the actual relevance label (<strong><em>Y</em></strong>), compute the loss by leveraging the\u00a0<code>mean_squared_error</code>\u00a0loss and perform backpropagation with each epoch to update the embedding layer in the process. Following code shows us our model architecture.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/dbff31351127c893a4579c9be11e113d.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*tXimFtA5R2jswNjVT80Q5Q.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Skip-gram model summary and architecture</font></center></p>\n<p>Understanding the above deep learning model is pretty straightforward. However, I will try to summarize the core concepts of this model in simple terms for ease of understanding. We have a pair of input words for each training example consisting of\u00a0<strong><em>one input target word</em></strong>\u00a0having a unique numeric identifier and\u00a0<strong><em>one context word</em></strong>\u00a0having a unique numeric identifier. If it is\u00a0<strong><em>a positive sample</em></strong>\u00a0the word has contextual meaning, is\u00a0<strong><em>a context word</em></strong>and our\u00a0<strong><em>label Y=1</em></strong>, else if it is a\u00a0<strong><em>negative sample</em></strong>, the word has no contextual meaning, is just\u00a0<strong><em>a random word</em></strong>\u00a0and our\u00a0<strong><em>label Y=0</em></strong>. We will pass each of them to an\u00a0<strong><em>embedding layer</em></strong>\u00a0of their own, having size\u00a0<code><strong>(vocab_size x embed_size)</strong></code>\u00a0which will give us\u00a0<strong><em>dense word embeddings</em></strong>\u00a0for each of these two words\u00a0<code><strong>(1 x embed_size for each word)</strong></code>. Next up we use a\u00a0<strong><em>merge layer</em></strong>\u00a0to compute the\u00a0<strong><em>dot product</em></strong>\u00a0of these two embeddings and get the dot product value. This is then sent to the\u00a0<strong><em>dense sigmoid layer</em></strong>\u00a0which outputs either a 1 or 0. We compare this with the actual label Y (1 or 0), compute the loss, backpropagate the errors to adjust the weights (in the embedding layer) and repeat this process for all\u00a0<strong><em>(target, context)</em></strong>\u00a0pairs for multiple epochs. The following figure tries to explain the same.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*4Uil1zWWF5-jlt-FnRJgAQ.png\" width=\"60%\"/><br/>\n<font size=\"-1\">Visual depiction of the Skip-gram deep learning\u00a0model</font></center></p>\n<p>Let\u2019s now start training our model with our skip-grams.</p>\n<p><b>Train the\u00a0Model</b></p>\n<p>Running the model on our complete corpus takes a fair bit of time but lesser than the CBOW model. Hence I just ran it for 5 epochs. You can leverage the following code and increase it for more epochs if necessary.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/a820a598b2d93c2d57e2dd8319936095.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Epoch: 1 Loss: 4529.63803683\r\nEpoch: 2 Loss: 3750.71884749\r\nEpoch: 3 Loss: 3752.47489296\r\nEpoch: 4 Loss: 3793.9177565\r\nEpoch: 5 Loss: 3716.07605051</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Once this model is trained, similar words should have similar weights based off the embedding layer and we can test out the same.</p>\n<p><b>Get Word Embeddings</b></p>\n<p>To get word embeddings for our entire vocabulary, we can extract out the same from our embedding layer by leveraging the following code. Do note that we are only interested in the target word embedding layer, hence we will extract the embeddings from our\u00a0<code><strong>word_model</strong></code>\u00a0embedding layer. We don\u2019t take the embedding at position 0 since none of our words in the vocabulary have a numeric identifier of 0 and we ignore it.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/e21c2fe26a54c3bbf90fe751989a7560.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*guUd_CKJHYOwNIIt_6YchA.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Word Embeddings for our vocabulary based on the Skip-gram model</font></center></p>\n<p>Thus you can clearly see that each word has a dense embedding of size\u00a0<code><strong>(1x100)</strong></code>\u00a0as depicted in the preceding output similar to what we had obtained from the CBOW model. Let\u2019s now apply the euclidean distance metric on these dense embedding vectors to generate a pairwise distance metric for each word in our vocabulary. We can then find out the n-nearest neighbors of each word of interest based on the shortest (euclidean) distance similar to what we did on the embeddings from our CBOW model.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/3557b2a27d4365e16890aee3e6e35dbe.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>(<strong>12424, 12424)</strong>\r\n\r\n<strong>{'egypt': ['pharaoh', 'mighty', 'houses', 'kept', 'possess'],\r\n 'famine': ['rivers', 'foot', 'pestilence', 'wash', 'sabbaths'],\r\n 'god': ['evil', 'iniquity', 'none', 'mighty', 'mercy'],\r\n 'gospel': ['grace', 'shame', 'believed', 'verily', 'everlasting'],\r\n 'jesus': ['christ', 'faith', 'disciples', 'dead', 'say'],\r\n 'john': ['ghost', 'knew', 'peter', 'alone', 'master'],\r\n 'moses': ['commanded', 'offerings', 'kept', 'presence', 'lamb'],\r\n 'noah': ['flood', 'shem', 'peleg', 'abram', 'chose']}</strong></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>You can clearly see from the results that a lot of the similar words for each of the words of interest are making sense and we have obtained better results as compared to our CBOW model. Let\u2019s visualize these words embeddings now using\u00a0<a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>t-SNE</strong></a><strong>\u00a0</strong>which stands for\u00a0<a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\" rel=\"noopener noreferrer\" target=\"_blank\"><strong><em>t-distributed stochastic neighbor embedding</em></strong></a><strong>\u00a0</strong>a popular\u00a0<a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\" rel=\"noopener noreferrer\" target=\"_blank\">dimensionality reduction</a>\u00a0technique to visualize higher dimension spaces in lower dimensions (e.g. 2-D).</p>\n<p><script src=\"https://gist.github.com/dipanjanS/7aa50bfdc663afdb106c1d842332f637.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*5N5p0cqCitIiGpfbQufc-A.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Visualizing skip-gram word2vec word embeddings using\u00a0t-SNE</font></center></p>\n<p>I have marked some circles in red which seemed to show different words of contextual similarity positioned near each other in the vector space. If you find any other interesting patterns feel free to let me know!</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a></b> is a Data Scientist @Intel, an author, a mentor @Springboard, a writer, and a sports and sitcom addict.</p>\n<p><a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/03/text-data-preprocessing-walkthrough-python.html\">Text Data Preprocessing: A Walkthrough in Python</a>\n<li><a href=\"/2017/12/general-approach-preprocessing-text-data.html\">A General Approach to Preprocessing Text Data</a>\n<li><a href=\"/2017/11/framework-approaching-textual-data-tasks.html\">A Framework for Approaching Textual Data Science Tasks<br/>\n</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}