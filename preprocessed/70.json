{"content": "By Danijar Hafner, Independent Machine Learning Researcher . Recurrent networks like LSTM and GRU are powerful sequence models. I will explain how to create recurrent networks in TensorFlow and use them for sequence classification and sequence labelling tasks. If you are not familiar with recurrent networks, I suggest you take a look at Christopher Olah\u2019s\u00a0 great post \u00a0first. On the TensorFlow part, I also expect some basic knowledge. The\u00a0 official tutorials \u00a0are a good place to start. from tensorflow.models.rnn import rnn_cell\r \r num_hidden = 200 \r num_layers = 3 \r dropout = \r \r network =  # Or  \r network = \r network = \r Defining the Network \u00a0 To use recurrent networks in TensorFlow we first need to define the network architecture consisting of one or more layers, the cell type and possibly dropout between the layers. Unrolling in Time \u00a0 We can now unroll this network in time using the\u00a0 rnn \u00a0operation. This takes placeholders for the input at each timestep and returns the hidden\u00a0 states \u00a0and\u00a0 output \u00a0activations for each timestep. from tensorflow.models.rnn import rnn\r max_length = 100 \r \r # Batch size times time steps times data width. \r data = \r outputs, states = , dtype = tf.float32)\r output = \r state = \r TensorFlow uses Python lists of one tensor for each timestep for the interface. Thus we make use of  \u00a0and\u00a0  \u00a0to split our data tensors into lists of frames and merge the results back to a single tensor. def unpack_sequence ( tensor ):\r \"\"\"Split the single tensor of a sequence into a list of frames.\"\"\" \r return )\r \r def pack_sequence ( sequence ):\r \"\"\"Combine a list of the frames into a single tensor of the sequence.\"\"\" \r return , perm = [ 1 , 0 , 2 ])\r As of version\u00a0 v0.8.0 , TensorFlow provides\u00a0 rnn.dynamic_rnn \u00a0as an alternative to\u00a0 rnn.rnn \u00a0that does not actually unroll the compute graph but uses a loop graph operation. The interface is the same except that you don\u2019t need\u00a0  \u00a0and\u00a0  \u00a0anymore, it already operates on single tensors. In the following sections, I will mention the modifications you need to make in order to use\u00a0 dynamic_rnn . Sequence Classification \u00a0 For classification, you might only care about the output activation at the last timestep, which is just outputs[-1] . The code below adds a softmax classifier ontop of that and defines the cross entropy error function. For now we assume sequences to be equal in length but I will cover variable length sequences in another post. in_size = num_hidden\r out_size = int ([ 2 ])\r weight = )\r bias = )\r prediction =  + bias)\r cross_entropy = - )\r When using\u00a0 dynamic_rnn , this is how to get the last output of the recurrent networks. We can\u2019t use outputs[-1] \u00a0because unlike Python lists, TensorFlow doesn\u2019t support negative indexing yet. Here is the complete gist for sequence classification . output, _ = \r output = \r last = [ 0 ]) - 1 )\r Sequence Labelling \u00a0 For sequence labelling, we want a prediction for each timestamp. However, we share the weights for the softmax layer across all timesteps. This way, we have one softmax layer ontop of an unrolled recurrent network as desired. in_size = num_hidden\r out_size = int ([ 2 ])\r weight = )\r bias = )\r predictions = [ + bias) for x in outputs]\r prediction = \r If you want to use\u00a0 dynamic_rnn \u00a0instead, you cannot apply the same weights and biases to all time steps in a Python list comprehension. Instead, we must flatten the outputs of each time step. This way time steps look the same as examples in the trainng batch to the weight matrix. Afterwards, we reshape back to the desired shape. max_length = int ( self .[ 1 ])\r num_classes = int ( self .[ 2 ])\r weight, bias = self .\r output = \r prediction =  + bias)\r prediction = \r Since this is a classification task as well, we keep using cross entropy as our error function. Here we have a prediction and target for every timestep. We thus compute the cross entropy for every timestep first and then average. Here is the\u00a0 complete gist for sequence labelling . cross_entropy = - , reduction_indices = [ 1 ])\r cross_entropy = \r That\u2019s all. We learned how to construct recurrent networks in TensorFlow and use them for sequence learning tasks. Please ask any questions below if you couldn\u2019t follow. Bio: Danijar Hafner is a Python and C++ developer from Berlin interested in Machine Intelligence research. He recently released a neural networks library , but he likes creating new things in general. Original . Reposted with permission. Related : Recurrent Neural Networks Tutorial, Introduction Learning to Code Neural Networks Implementing Neural Networks in Javascript", "title_html": "<h1 id=\"title\">Introduction to Recurrent Networks in TensorFlow</h1> ", "url": "https://www.kdnuggets.com/2016/05/intro-recurrent-networks-tensorflow.html", "tfidf": {"tfidf": {"relat": 1.23750876919, "label": 17.90862944164, "christoph": 5.41473396999, "tensorflow": 7938.0, "permiss": 6.280063291139999, "this": 6.02276176026, "post": 4.47652615254, "here": 7.26923076924, "new": 1.0178880554, "averag": 2.60390355913, "insiz": 2268.0, "rnn": 2268.0, "layer": 32.56615384616, "across": 1.7318642958400001, "care": 2.49426551453, "about": 1.06486015159, "function": 4.99088337, "int": 341.4193548388, "neural": 237.8426966292, "thing": 2.4065484311099996, "python": 225.1914893616, "just": 1.33580143037, "afterward": 4.72640666865, "danijar": 2268.0, "unlik": 2.42529789184, "reshap": 51.2129032258, "complet": 2.48043121632, "olah": 1134.0, "repost": 933.882352941, "classifi": 5.2937645882, "trainng": 1134.0, "defin": 8.184911496809999, "rnndynamicrnn": 1134.0, "tensorflowmodelsrnn": 2268.0, "equal": 2.542193755, "instead": 3.18923262354, "creat": 2.4985835694, "start": 1.26673581744, "how": 4.80750984153, "singl": 6.43795620436, "numlay": 1134.0, "them": 2.19752231988, "keep": 2.04245465071, "comprehens": 5.3544688027, "explain": 2.60049140049, "can": 3.52878417426, "frame": 18.840189873419998, "modif": 9.5753920386, "vnum": 29.291512915100004, "interest": 1.60331246213, "tutori": 118.9213483146, "target": 3.2189781021900004, "will": 3.67443295788, "entropi": 321.81081081, "the": 36.0, "anymor": 35.1238938053, "rnnrnn": 1134.0, "one": 3.01882487166, "below": 4.51215006394, "but": 3.04897253697, "couldn": 1134.0, "need": 4.31178707223, "our": 4.71517671518, "classif": 40.33536585365, "output": 92.12379110256, "interfac": 41.8339920948, "expect": 2.20011086475, "matrix": 22.6153846154, "possibl": 1.4173734488, "tensor": 1068.5769230780002, "hidden": 7.81299212598, "origin": 1.13724928367, "ask": 2.1744966443, "have": 2.0297896822799997, "tffloatnum": 1134.0, "knowledg": 3.3981164383599998, "take": 2.27923336444, "follow": 2.09280253098, "now": 2.321561746, "might": 2.1561863370900003, "code": 7.761427523839999, "model": 2.0905978404, "desir": 6.00340328984, "good": 1.51981619759, "timestamp": 529.2, "basic": 2.7301805675, "self": 35.918552036099996, "power": 1.3396337861799998, "maxlength": 2268.0, "also": 1.01476510067, "javascript": 174.46153846200002, "softmax": 3402.0, "not": 3.04702194357, "reductionindic": 1134.0, "task": 11.65924112607, "batch": 71.3528089888, "research": 3.8840366972400004, "are": 3.08971780734, "order": 1.24625166811, "altern": 2.1390460792200003, "pleas": 9.12938470385, "width": 17.294117647100002, "want": 3.99396226416, "placehold": 330.75, "index": 6.9969149405, "sinc": 1.08368600683, "loop": 13.5114893617, "recurr": 284.7713004488, "howev": 1.0945191313299998, "last": 3.6351702030300004, "share": 1.8566249561500001, "crossentropi": 3402.0, "anoth": 1.13643521832, "def": 163.67010309280002, "numclass": 1134.0, "perm": 324.0, "section": 2.1284354471099998, "construct": 1.9320920043799998, "which": 1.005191845, "intellig": 4.19334389857, "activ": 2.92807082258, "thus": 3.2927512185000003, "dtype": 1134.0, "alreadi": 1.9551724137900002, "flatten": 42.336000000000006, "variabl": 8.747107438019999, "appli": 2.2972073506, "provid": 1.21552714187, "consist": 1.4901445466499998, "graph": 75.4204275534, "develop": 1.1955719557200002, "becaus": 1.1495184997499999, "dynamicrnn": 3402.0, "get": 1.78562591385, "network": 44.09279529496, "like": 2.2983713355, "implement": 3.57648118946, "some": 1.04036697248, "cross": 6.993832599120001, "add": 4.61243463103, "except": 1.71948445792, "rnncell": 1134.0, "part": 1.04330682789, "independ": 1.58950740889, "version": 2.0083491461099996, "cell": 7.1033557047, "weight": 29.273509526759995, "well": 1.0655748708, "ani": 1.13383802314, "question": 2.20408163265, "time": 8.09019682784, "from": 3.00170164491, "result": 1.14611608432, "back": 2.52140077822, "num": 15.004725600150001, "same": 3.35573874444, "between": 1.03453668708, "return": 4.185972930209999, "unrol": 2189.793103448, "for": 16.00504064016, "predict": 36.293925538850004, "all": 3.03440366973, "yet": 2.1258703802900003, "releas": 1.8377126982299998, "with": 2.0023964179799996, "assum": 2.9575260804799997, "merg": 5.28319467554, "recent": 1.54405757635, "split": 6.9418452120600005, "hafner": 1512.0, "that": 4.015936255, "look": 3.8172637653199994, "architectur": 5.12790697674, "dropout": 334.231578948, "more": 1.0171706817, "and": 15.00094488195, "list": 8.17928902626, "type": 2.0281042411900003, "gist": 635.04, "negat": 3.75852272727, "combin": 1.69760479042, "general": 1.1218202374200001, "length": 7.38246919322, "unpacksequ": 1134.0, "librari": 2.68266306185, "state": 3.1431399722699993, "then": 1.08657860516, "doe": 1.70581282905, "ontop": 2268.0, "comput": 7.855517070760001, "make": 2.1525320317200003, "way": 2.4381478922, "onli": 1.0256476516600002, "each": 5.948741007200001, "introduct": 2.7808723068799996, "size": 2.49387370405, "place": 1.1004366812200002, "great": 1.26592775696, "berlin": 6.43534657479, "step": 11.311720698239998, "error": 12.08219178082, "packsequ": 1134.0, "familiar": 6.86381322957, "data": 10.12930667802, "oper": 4.66438154931, "shape": 3.20338983051, "sequenc": 84.99579349897999, "support": 1.2685577307200002, "machin": 8.04866920152, "into": 3.04507384437, "bio": 42.336000000000006, "bias": 96.1349480966, "must": 1.9220338983099996, "exampl": 1.50483412322, "offici": 1.40483143085, "numhidden": 3402.0, "import": 2.6803984467400004, "first": 3.0228484386899996, "everi": 2.95835274388, "input": 12.2029208301, "when": 1.02076769755, "use": 12.355665088559999, "outsiz": 814.1538461539999, "suggest": 1.7571665744299998, "learn": 9.2910021946, "actual": 1.87482286254, "cover": 1.69380134429, "mention": 2.53894130817, "timestep": 7938.0}, "logtfidf": {"relat": 0.21310030165399999, "label": 5.99595330908, "christoph": 1.6891237509, "tensorflow": 49.23454539002999, "permiss": 1.8373800586400002, "this": 0.022718694315, "post": 1.6114003054019999, "here": 2.6551145651100003, "new": 0.0177299468511, "averag": 0.957011687995, "insiz": 14.067012968579998, "rnn": 14.067012968579998, "layer": 8.387916649400001, "across": 0.549198455941, "care": 0.9139943029109999, "about": 0.0628434774746, "function": 1.828931483188, "int": 17.78726856076, "neural": 16.341260622, "thing": 0.8781935346799999, "python": 16.12262697184, "just": 0.289531434109, "afterward": 1.5531652242899998, "danijar": 14.067012968579998, "unlik": 0.885954358842, "reshap": 3.9359915164199997, "complet": 0.430570484094, "olah": 7.033506484289999, "repost": 6.83935046985, "classifi": 1.6665296351499999, "trainng": 7.033506484289999, "defin": 3.01104032775, "rnndynamicrnn": 7.033506484289999, "tensorflowmodelsrnn": 14.067012968579998, "equal": 0.933027391343, "instead": 0.9332663008300001, "creat": 0.445153637028, "start": 0.236443369291, "how": 1.4147008707900002, "singl": 1.903667076236, "numlay": 7.033506484289999, "them": 0.1883666538186, "keep": 0.7141523446729999, "comprehens": 1.6779315024700001, "explain": 0.955700427358, "can": 0.487023289182, "frame": 5.512140175920001, "modif": 2.25919647821, "vnum": 3.3772978124599997, "interest": 0.47207177798199995, "tutori": 8.170630311, "target": 1.1690639496200002, "will": 0.6083596047450001, "entropi": 14.026054620420002, "the": 0.0, "anymor": 3.5588816340699996, "rnnrnn": 7.033506484289999, "one": 0.0187660549365, "below": 1.627253183872, "but": 0.0485771162157, "couldn": 7.033506484289999, "need": 1.088220490326, "our": 1.7152784283640001, "classif": 10.43895368145, "output": 24.45871893924, "interfac": 6.081124073019999, "expect": 0.78850775216, "matrix": 3.1186304098799997, "possibl": 0.348805474891, "tensor": 35.19721040332, "hidden": 2.0557880052, "origin": 0.128612437587, "ask": 0.776797209847, "have": 0.0295700046824, "tffloatnum": 7.033506484289999, "knowledg": 1.2232212893899999, "take": 0.261383924394, "follow": 0.09071382218839999, "now": 0.298185890042, "might": 0.7683410765340001, "code": 2.71203819194, "model": 0.7374500731110001, "desir": 2.1983586856799997, "good": 0.418589404907, "timestamp": 6.27136643224, "basic": 1.00436774895, "self": 7.44792492948, "power": 0.292396282715, "maxlength": 14.067012968579998, "also": 0.0146571578, "javascript": 5.16170430739, "softmax": 21.100519452869996, "not": 0.0466572390225, "reductionindic": 7.033506484289999, "task": 4.0724604198300005, "batch": 7.148979063480001, "research": 1.327455636276, "are": 0.08840242074810001, "order": 0.22014038079300002, "altern": 0.760359972282, "pleas": 2.21149829955, "width": 2.85036642328, "want": 1.3832732125099998, "placehold": 5.801362803, "index": 1.94546932912, "sinc": 0.0803681994577, "loop": 2.60354038732, "recurr": 28.577958895040002, "howev": 0.0903151173475, "last": 0.5761309338330001, "share": 0.618760299747, "crossentropi": 21.100519452869996, "anoth": 0.127896361652, "def": 8.80941130968, "numclass": 7.033506484289999, "perm": 5.78074351579, "section": 0.755387177948, "construct": 0.658603355972, "which": 0.00517841384543, "intellig": 1.43349848213, "activ": 0.762393206568, "thus": 0.9971525427860001, "dtype": 7.033506484289999, "alreadi": 0.670478380747, "flatten": 3.7456377879300002, "variabl": 2.1687230672, "appli": 0.8316941898119999, "provid": 0.19517784432500002, "consist": 0.398873126426, "graph": 7.259861960439999, "develop": 0.178624694913, "becaus": 0.139343158825, "dynamicrnn": 21.100519452869996, "get": 0.579769005782, "network": 16.202411901884, "like": 0.27810715309, "implement": 1.27437940907, "some": 0.0395735090645, "cross": 2.539249244277, "add": 1.52875583713, "except": 0.54202451213, "rnncell": 7.033506484289999, "part": 0.04239531098280001, "independ": 0.463424162503, "version": 0.697313064259, "cell": 1.9605673068599998, "weight": 9.509541156720001, "well": 0.0635144383156, "ani": 0.125608358366, "question": 0.790310929014, "time": 0.0896921509008, "from": 0.0017011625065979999, "result": 0.136378908381, "back": 0.46333486179399996, "num": 0.004724855930955001, "same": 0.336178948812, "between": 0.033953681165299995, "return": 0.9993806057760001, "unrol": 25.221071935679998, "for": 0.005039846326352001, "predict": 11.52018166383, "all": 0.03420789629339999, "yet": 0.754181309241, "releas": 0.608521699544, "with": 0.00239498342678, "assum": 1.08435313525, "merg": 1.66453096693, "recent": 0.434413741288, "split": 2.48884087864, "hafner": 13.256082752360001, "that": 0.01590459351856, "look": 1.2927733872, "architectur": 1.63469757919, "dropout": 10.2373738446, "more": 0.017024931599999998, "and": 0.000944852130954, "list": 1.8590745690360002, "type": 0.707101485387, "gist": 11.52108161694, "negat": 1.32402598852, "combin": 0.529218310751, "general": 0.114952578063, "length": 2.6119219622400003, "unpacksequ": 7.033506484289999, "librari": 0.986809980943, "state": 0.13983000830040002, "then": 0.08303386523089999, "doe": 0.5340417297169999, "ontop": 14.067012968579998, "comput": 2.73613783188, "make": 0.14699531564579998, "way": 0.39618301987000004, "onli": 0.025324268329099998, "each": 0.86870844652, "introduct": 1.02276465794, "size": 0.9138372060609999, "place": 0.0957070839572, "great": 0.235805258079, "berlin": 1.8618056973700001, "step": 4.15818022792, "error": 3.5971708686, "packsequ": 7.033506484289999, "familiar": 1.92626315167, "data": 3.6504617544, "oper": 1.324028893041, "shape": 1.16420957115, "sequenc": 25.249622123600002, "support": 0.237880610037, "machin": 2.78471916124, "into": 0.0447385896861, "bio": 3.7456377879300002, "bias": 18.33889935269, "must": 0.653383947388, "exampl": 0.40868267499899996, "offici": 0.339917317543, "numhidden": 21.100519452869996, "import": 0.585636554132, "first": 0.02276186943648, "everi": 0.782970854842, "input": 2.50167533539, "when": 0.0205549888584, "use": 0.3504962367792, "outsiz": 12.018004335539999, "suggest": 0.563702610877, "learn": 3.37100825898, "actual": 0.628514181648, "cover": 0.526975319156, "mention": 0.931747186336, "timestep": 49.23454539002999}, "logidf": {"relat": 0.21310030165399999, "label": 1.49898832727, "christoph": 1.6891237509, "tensorflow": 7.033506484289999, "permiss": 1.8373800586400002, "this": 0.0037864490525, "post": 0.8057001527009999, "here": 0.8850381883700001, "new": 0.0177299468511, "averag": 0.957011687995, "insiz": 7.033506484289999, "rnn": 7.033506484289999, "layer": 2.0969791623500003, "across": 0.549198455941, "care": 0.9139943029109999, "about": 0.0628434774746, "function": 0.914465741594, "int": 4.44681714019, "neural": 4.0853151555, "thing": 0.8781935346799999, "python": 4.03065674296, "just": 0.289531434109, "afterward": 1.5531652242899998, "danijar": 7.033506484289999, "unlik": 0.885954358842, "reshap": 3.9359915164199997, "complet": 0.215285242047, "olah": 7.033506484289999, "repost": 6.83935046985, "classifi": 1.6665296351499999, "trainng": 7.033506484289999, "defin": 1.00368010925, "rnndynamicrnn": 7.033506484289999, "tensorflowmodelsrnn": 7.033506484289999, "equal": 0.933027391343, "instead": 0.46663315041500003, "creat": 0.222576818514, "start": 0.236443369291, "how": 0.47156695693000006, "singl": 0.475916769059, "numlay": 7.033506484289999, "them": 0.0941833269093, "keep": 0.7141523446729999, "comprehens": 1.6779315024700001, "explain": 0.955700427358, "can": 0.162341096394, "frame": 1.8373800586400002, "modif": 2.25919647821, "vnum": 3.3772978124599997, "interest": 0.47207177798199995, "tutori": 4.0853151555, "target": 1.1690639496200002, "will": 0.202786534915, "entropi": 4.67535154014, "the": 0.0, "anymor": 3.5588816340699996, "rnnrnn": 7.033506484289999, "one": 0.0062553516455, "below": 0.813626591936, "but": 0.0161923720719, "couldn": 7.033506484289999, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "output": 2.03822657827, "interfac": 3.0405620365099995, "expect": 0.78850775216, "matrix": 3.1186304098799997, "possibl": 0.348805474891, "tensor": 5.02817291476, "hidden": 2.0557880052, "origin": 0.128612437587, "ask": 0.776797209847, "have": 0.0147850023412, "tffloatnum": 7.033506484289999, "knowledg": 1.2232212893899999, "take": 0.130691962197, "follow": 0.045356911094199995, "now": 0.149092945021, "might": 0.7683410765340001, "code": 1.35601909597, "model": 0.7374500731110001, "desir": 1.0991793428399999, "good": 0.418589404907, "timestamp": 6.27136643224, "basic": 1.00436774895, "self": 2.48264164316, "power": 0.292396282715, "maxlength": 7.033506484289999, "also": 0.0146571578, "javascript": 5.16170430739, "softmax": 7.033506484289999, "not": 0.0155524130075, "reductionindic": 7.033506484289999, "task": 1.35748680661, "batch": 3.5744895317400003, "research": 0.663727818138, "are": 0.0294674735827, "order": 0.22014038079300002, "altern": 0.760359972282, "pleas": 2.21149829955, "width": 2.85036642328, "want": 0.6916366062549999, "placehold": 5.801362803, "index": 1.94546932912, "sinc": 0.0803681994577, "loop": 2.60354038732, "recurr": 3.5722448618800002, "howev": 0.0903151173475, "last": 0.19204364461100001, "share": 0.618760299747, "crossentropi": 7.033506484289999, "anoth": 0.127896361652, "def": 4.40470565484, "numclass": 7.033506484289999, "perm": 5.78074351579, "section": 0.755387177948, "construct": 0.658603355972, "which": 0.00517841384543, "intellig": 1.43349848213, "activ": 0.381196603284, "thus": 0.49857627139300004, "dtype": 7.033506484289999, "alreadi": 0.670478380747, "flatten": 3.7456377879300002, "variabl": 2.1687230672, "appli": 0.8316941898119999, "provid": 0.19517784432500002, "consist": 0.398873126426, "graph": 3.6299309802199997, "develop": 0.178624694913, "becaus": 0.139343158825, "dynamicrnn": 7.033506484289999, "get": 0.579769005782, "network": 0.9530830530519999, "like": 0.139053576545, "implement": 1.27437940907, "some": 0.0395735090645, "cross": 0.846416414759, "add": 1.52875583713, "except": 0.54202451213, "rnncell": 7.033506484289999, "part": 0.04239531098280001, "independ": 0.463424162503, "version": 0.697313064259, "cell": 1.9605673068599998, "weight": 1.58492352612, "well": 0.0635144383156, "ani": 0.125608358366, "question": 0.790310929014, "time": 0.0112115188626, "from": 0.000567054168866, "result": 0.136378908381, "back": 0.23166743089699998, "num": 0.00031499039539700004, "same": 0.112059649604, "between": 0.033953681165299995, "return": 0.333126868592, "unrol": 6.305267983919999, "for": 0.00031499039539700004, "predict": 1.6457402376899999, "all": 0.011402632097799998, "yet": 0.754181309241, "releas": 0.608521699544, "with": 0.00119749171339, "assum": 1.08435313525, "merg": 1.66453096693, "recent": 0.434413741288, "split": 1.24442043932, "hafner": 6.6280413761800006, "that": 0.00397614837964, "look": 0.6463866936, "architectur": 1.63469757919, "dropout": 5.1186869223, "more": 0.017024931599999998, "and": 6.29901420636e-05, "list": 0.309845761506, "type": 0.707101485387, "gist": 5.76054080847, "negat": 1.32402598852, "combin": 0.529218310751, "general": 0.114952578063, "length": 1.3059609811200001, "unpacksequ": 7.033506484289999, "librari": 0.986809980943, "state": 0.0466100027668, "then": 0.08303386523089999, "doe": 0.5340417297169999, "ontop": 7.033506484289999, "comput": 1.36806891594, "make": 0.07349765782289999, "way": 0.19809150993500002, "onli": 0.025324268329099998, "each": 0.173741689304, "introduct": 1.02276465794, "size": 0.9138372060609999, "place": 0.0957070839572, "great": 0.235805258079, "berlin": 1.8618056973700001, "step": 1.03954505698, "error": 1.7985854343, "packsequ": 7.033506484289999, "familiar": 1.92626315167, "data": 1.2168205848, "oper": 0.441342964347, "shape": 1.16420957115, "sequenc": 1.8035444374, "support": 0.237880610037, "machin": 1.39235958062, "into": 0.0149128632287, "bio": 3.7456377879300002, "bias": 2.61984276467, "must": 0.653383947388, "exampl": 0.40868267499899996, "offici": 0.339917317543, "numhidden": 7.033506484289999, "import": 0.292818277066, "first": 0.0075872898121599995, "everi": 0.391485427421, "input": 2.50167533539, "when": 0.0205549888584, "use": 0.0292080197316, "outsiz": 6.009002167769999, "suggest": 0.563702610877, "learn": 0.842752064745, "actual": 0.628514181648, "cover": 0.526975319156, "mention": 0.931747186336, "timestep": 7.033506484289999}, "freq": {"relat": 1, "label": 4, "christoph": 1, "tensorflow": 7, "permiss": 1, "this": 6, "post": 2, "here": 3, "new": 1, "averag": 1, "insiz": 2, "rnn": 2, "layer": 4, "across": 1, "care": 1, "about": 1, "function": 2, "int": 4, "neural": 4, "thing": 1, "python": 4, "just": 1, "afterward": 1, "danijar": 2, "unlik": 1, "reshap": 1, "complet": 2, "olah": 1, "repost": 1, "classifi": 1, "trainng": 1, "defin": 3, "rnndynamicrnn": 1, "tensorflowmodelsrnn": 2, "equal": 1, "instead": 2, "creat": 2, "start": 1, "how": 3, "singl": 4, "numlay": 1, "them": 2, "keep": 1, "comprehens": 1, "explain": 1, "can": 3, "frame": 3, "modif": 1, "vnum": 1, "interest": 1, "tutori": 2, "target": 1, "will": 3, "entropi": 3, "the": 36, "anymor": 1, "rnnrnn": 1, "one": 3, "below": 2, "but": 3, "couldn": 1, "need": 3, "our": 2, "classif": 5, "output": 12, "interfac": 2, "expect": 1, "matrix": 1, "possibl": 1, "tensor": 7, "hidden": 1, "origin": 1, "ask": 1, "have": 2, "tffloatnum": 1, "knowledg": 1, "take": 2, "follow": 2, "now": 2, "might": 1, "code": 2, "model": 1, "desir": 2, "good": 1, "timestamp": 1, "basic": 1, "self": 3, "power": 1, "maxlength": 2, "also": 1, "javascript": 1, "softmax": 3, "not": 3, "reductionindic": 1, "task": 3, "batch": 2, "research": 2, "are": 3, "order": 1, "altern": 1, "pleas": 1, "width": 1, "want": 2, "placehold": 1, "index": 1, "sinc": 1, "loop": 1, "recurr": 8, "howev": 1, "last": 3, "share": 1, "crossentropi": 3, "anoth": 1, "def": 2, "numclass": 1, "perm": 1, "section": 1, "construct": 1, "which": 1, "intellig": 1, "activ": 2, "thus": 2, "dtype": 1, "alreadi": 1, "flatten": 1, "variabl": 1, "appli": 1, "provid": 1, "consist": 1, "graph": 2, "develop": 1, "becaus": 1, "dynamicrnn": 3, "get": 1, "network": 17, "like": 2, "implement": 1, "some": 1, "cross": 3, "add": 1, "except": 1, "rnncell": 1, "part": 1, "independ": 1, "version": 1, "cell": 1, "weight": 6, "well": 1, "ani": 1, "question": 1, "time": 8, "from": 3, "result": 1, "back": 2, "num": 15, "same": 3, "between": 1, "return": 3, "unrol": 4, "for": 16, "predict": 7, "all": 3, "yet": 1, "releas": 1, "with": 2, "assum": 1, "merg": 1, "recent": 1, "split": 2, "hafner": 2, "that": 4, "look": 2, "architectur": 1, "dropout": 2, "more": 1, "and": 15, "list": 6, "type": 1, "gist": 2, "negat": 1, "combin": 1, "general": 1, "length": 2, "unpacksequ": 1, "librari": 1, "state": 3, "then": 1, "doe": 1, "ontop": 2, "comput": 2, "make": 2, "way": 2, "onli": 1, "each": 5, "introduct": 1, "size": 1, "place": 1, "great": 1, "berlin": 1, "step": 4, "error": 2, "packsequ": 1, "familiar": 1, "data": 3, "oper": 3, "shape": 1, "sequenc": 14, "support": 1, "machin": 2, "into": 3, "bio": 1, "bias": 7, "must": 1, "exampl": 1, "offici": 1, "numhidden": 3, "import": 2, "first": 3, "everi": 2, "input": 1, "when": 1, "use": 12, "outsiz": 2, "suggest": 1, "learn": 4, "actual": 1, "cover": 1, "mention": 1, "timestep": 7}, "idf": {"relat": 1.23750876919, "label": 4.47715736041, "christoph": 5.41473396999, "tensorflow": 1134.0, "permiss": 6.280063291139999, "this": 1.00379362671, "post": 2.23826307627, "here": 2.42307692308, "new": 1.0178880554, "averag": 2.60390355913, "insiz": 1134.0, "rnn": 1134.0, "layer": 8.14153846154, "across": 1.7318642958400001, "care": 2.49426551453, "about": 1.06486015159, "function": 2.495441685, "int": 85.3548387097, "neural": 59.4606741573, "thing": 2.4065484311099996, "python": 56.2978723404, "just": 1.33580143037, "afterward": 4.72640666865, "danijar": 1134.0, "unlik": 2.42529789184, "reshap": 51.2129032258, "complet": 1.24021560816, "olah": 1134.0, "repost": 933.882352941, "classifi": 5.2937645882, "trainng": 1134.0, "defin": 2.72830383227, "rnndynamicrnn": 1134.0, "tensorflowmodelsrnn": 1134.0, "equal": 2.542193755, "instead": 1.59461631177, "creat": 1.2492917847, "start": 1.26673581744, "how": 1.60250328051, "singl": 1.60948905109, "numlay": 1134.0, "them": 1.09876115994, "keep": 2.04245465071, "comprehens": 5.3544688027, "explain": 2.60049140049, "can": 1.17626139142, "frame": 6.280063291139999, "modif": 9.5753920386, "vnum": 29.291512915100004, "interest": 1.60331246213, "tutori": 59.4606741573, "target": 3.2189781021900004, "will": 1.22481098596, "entropi": 107.27027027, "the": 1.0, "anymor": 35.1238938053, "rnnrnn": 1134.0, "one": 1.00627495722, "below": 2.25607503197, "but": 1.01632417899, "couldn": 1134.0, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "output": 7.676982591880001, "interfac": 20.9169960474, "expect": 2.20011086475, "matrix": 22.6153846154, "possibl": 1.4173734488, "tensor": 152.653846154, "hidden": 7.81299212598, "origin": 1.13724928367, "ask": 2.1744966443, "have": 1.0148948411399998, "tffloatnum": 1134.0, "knowledg": 3.3981164383599998, "take": 1.13961668222, "follow": 1.04640126549, "now": 1.160780873, "might": 2.1561863370900003, "code": 3.8807137619199996, "model": 2.0905978404, "desir": 3.00170164492, "good": 1.51981619759, "timestamp": 529.2, "basic": 2.7301805675, "self": 11.972850678699999, "power": 1.3396337861799998, "maxlength": 1134.0, "also": 1.01476510067, "javascript": 174.46153846200002, "softmax": 1134.0, "not": 1.01567398119, "reductionindic": 1134.0, "task": 3.88641370869, "batch": 35.6764044944, "research": 1.9420183486200002, "are": 1.02990593578, "order": 1.24625166811, "altern": 2.1390460792200003, "pleas": 9.12938470385, "width": 17.294117647100002, "want": 1.99698113208, "placehold": 330.75, "index": 6.9969149405, "sinc": 1.08368600683, "loop": 13.5114893617, "recurr": 35.5964125561, "howev": 1.0945191313299998, "last": 1.2117234010100002, "share": 1.8566249561500001, "crossentropi": 1134.0, "anoth": 1.13643521832, "def": 81.83505154640001, "numclass": 1134.0, "perm": 324.0, "section": 2.1284354471099998, "construct": 1.9320920043799998, "which": 1.005191845, "intellig": 4.19334389857, "activ": 1.46403541129, "thus": 1.6463756092500001, "dtype": 1134.0, "alreadi": 1.9551724137900002, "flatten": 42.336000000000006, "variabl": 8.747107438019999, "appli": 2.2972073506, "provid": 1.21552714187, "consist": 1.4901445466499998, "graph": 37.7102137767, "develop": 1.1955719557200002, "becaus": 1.1495184997499999, "dynamicrnn": 1134.0, "get": 1.78562591385, "network": 2.59369384088, "like": 1.14918566775, "implement": 3.57648118946, "some": 1.04036697248, "cross": 2.33127753304, "add": 4.61243463103, "except": 1.71948445792, "rnncell": 1134.0, "part": 1.04330682789, "independ": 1.58950740889, "version": 2.0083491461099996, "cell": 7.1033557047, "weight": 4.878918254459999, "well": 1.0655748708, "ani": 1.13383802314, "question": 2.20408163265, "time": 1.01127460348, "from": 1.00056721497, "result": 1.14611608432, "back": 1.26070038911, "num": 1.00031504001, "same": 1.11857958148, "between": 1.03453668708, "return": 1.39532431007, "unrol": 547.448275862, "for": 1.00031504001, "predict": 5.18484650555, "all": 1.01146788991, "yet": 2.1258703802900003, "releas": 1.8377126982299998, "with": 1.0011982089899998, "assum": 2.9575260804799997, "merg": 5.28319467554, "recent": 1.54405757635, "split": 3.4709226060300002, "hafner": 756.0, "that": 1.00398406375, "look": 1.9086318826599997, "architectur": 5.12790697674, "dropout": 167.115789474, "more": 1.0171706817, "and": 1.00006299213, "list": 1.36321483771, "type": 2.0281042411900003, "gist": 317.52, "negat": 3.75852272727, "combin": 1.69760479042, "general": 1.1218202374200001, "length": 3.69123459661, "unpacksequ": 1134.0, "librari": 2.68266306185, "state": 1.0477133240899998, "then": 1.08657860516, "doe": 1.70581282905, "ontop": 1134.0, "comput": 3.9277585353800006, "make": 1.0762660158600001, "way": 1.2190739461, "onli": 1.0256476516600002, "each": 1.18974820144, "introduct": 2.7808723068799996, "size": 2.49387370405, "place": 1.1004366812200002, "great": 1.26592775696, "berlin": 6.43534657479, "step": 2.8279301745599996, "error": 6.04109589041, "packsequ": 1134.0, "familiar": 6.86381322957, "data": 3.37643555934, "oper": 1.55479384977, "shape": 3.20338983051, "sequenc": 6.07112810707, "support": 1.2685577307200002, "machin": 4.02433460076, "into": 1.01502461479, "bio": 42.336000000000006, "bias": 13.7335640138, "must": 1.9220338983099996, "exampl": 1.50483412322, "offici": 1.40483143085, "numhidden": 1134.0, "import": 1.3401992233700002, "first": 1.00761614623, "everi": 1.47917637194, "input": 12.2029208301, "when": 1.02076769755, "use": 1.0296387573799999, "outsiz": 407.07692307699995, "suggest": 1.7571665744299998, "learn": 2.32275054865, "actual": 1.87482286254, "cover": 1.69380134429, "mention": 2.53894130817, "timestep": 1134.0}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Introduction to Recurrent Networks in TensorFlow</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/05/intro-recurrent-networks-tensorflow.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Introduction to Recurrent Networks in TensorFlow Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/05/intel-investment-cognitive-tech-impact-new-opportunities.html\" rel=\"prev\" title=\"Intel\u2019s Investments in Cognitive Tech: Impact and New Opportunities\"/>\n<link href=\"https://www.kdnuggets.com/jobs/16/05-31-jobs-data-scientist.html\" rel=\"next\" title=\"USC: Data Scientist\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/05/intro-recurrent-networks-tensorflow.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=50278\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/05/intro-recurrent-networks-tensorflow.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-50278 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 31-May, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/05/tutorials.html\">Tutorials, Overviews</a> \u00bb Introduction to Recurrent Networks in TensorFlow (\u00a0<a href=\"/2016/n20.html\">16:n20</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Introduction to Recurrent Networks in TensorFlow</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/05/intel-investment-cognitive-tech-impact-new-opportunities.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/16/05-31-jobs-data-scientist.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 115</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/recurrent-neural-networks\" rel=\"tag\">Recurrent Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/tensorflow\" rel=\"tag\">TensorFlow</a></div>\n<br/>\n<p class=\"excerpt\">\n     A straightforward, introductory overview of implementing Recurrent Neural Networks in TensorFlow.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By Danijar Hafner, Independent Machine Learning Researcher</b>.</p>\n<p><img alt=\"TensorFlow\" src=\"/wp-content/uploads/tensorflow-white-bg.png\" width=\"99%\"/></p>\n<p>Recurrent networks like LSTM and GRU are powerful sequence models. I will explain how to create recurrent networks in TensorFlow and use them for sequence classification and sequence labelling tasks. If you are not familiar with recurrent networks, I suggest you take a look at Christopher Olah\u2019s\u00a0<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">great post</a>\u00a0first. On the TensorFlow part, I also expect some basic knowledge. The\u00a0<a href=\"https://www.tensorflow.org/versions/r0.8/tutorials/index.html\">official tutorials</a>\u00a0are a good place to start.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\"><span style=\"color:#e28964\">from</span> tensorflow.models.rnn <span style=\"color:#e28964\">import</span> rnn_cell\r\n\r\nnum_hidden <span style=\"color:#e28964\">=</span> <span style=\"color:#3387cc\">200</span>\r\nnum_layers <span style=\"color:#e28964\">=</span> <span style=\"color:#3387cc\">3</span>\r\ndropout <span style=\"color:#e28964\">=</span> tf.placeholder(tf.float32)\r\n\r\nnetwork <span style=\"color:#e28964\">=</span> rnn_cell.GRUCell(num_hidden)  <span style=\"color:#aeaeae;font-style:italic\"># Or LSTMCell(num_hidden)</span>\r\nnetwork <span style=\"color:#e28964\">=</span> rnn_cell.DropoutWrapper(network, <span style=\"color:#3e87e3\">output_keep_prob</span><span style=\"color:#e28964\">=</span>dropout)\r\nnetwork <span style=\"color:#e28964\">=</span> rnn_cell.MultiRNNCell([network] <span style=\"color:#e28964\">*</span> num_layers)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<h3>Defining the Network</h3>\n<p>\u00a0<br>\nTo use recurrent networks in TensorFlow we first need to define the network architecture consisting of one or more layers, the cell type and possibly dropout between the layers.</br></p>\n<h3>Unrolling in Time</h3>\n<p>\u00a0<br>\nWe can now unroll this network in time using the\u00a0<code>rnn</code>\u00a0operation. This takes placeholders for the input at each timestep and returns the hidden\u00a0<em>states</em>\u00a0and\u00a0<em>output</em>\u00a0activations for each timestep.</br></p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\"><span style=\"color:#e28964\">from</span> tensorflow.models.rnn <span style=\"color:#e28964\">import</span> rnn\r\nmax_length <span style=\"color:#e28964\">=</span> <span style=\"color:#3387cc\">100</span>\r\n\r\n<span style=\"color:#aeaeae;font-style:italic\"># Batch size times time steps times data width.</span>\r\ndata <span style=\"color:#e28964\">=</span> tf.placeholder(tf.float32, [<span style=\"color:#3387cc\">None</span>, max_length, <span style=\"color:#3387cc\">28</span>])\r\noutputs, states <span style=\"color:#e28964\">=</span> rnn.rnn(network, unpack_sequence(data), <span style=\"color:#3e87e3\">dtype</span><span style=\"color:#e28964\">=</span>tf.float32)\r\noutput <span style=\"color:#e28964\">=</span> pack_sequence(outputs)\r\nstate <span style=\"color:#e28964\">=</span> pack_sequence(states)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>TensorFlow uses Python lists of one tensor for each timestep for the interface. Thus we make use of<a href=\"https://www.tensorflow.org/versions/r0.8/api_docs/python/array_ops.html#pack\"><code>tf.pack()</code>\u00a0and\u00a0<code>tf.unpack()</code></a>\u00a0to split our data tensors into lists of frames and merge the results back to a single tensor.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\"><span style=\"color:#99cf50\">def</span> <span style=\"color:#89bdff\">unpack_sequence</span>(<span style=\"color:#3e87e3\">tensor</span>):\r\n    <span style=\"color:#65b042\">\"\"\"Split the single tensor of a sequence into a list of frames.\"\"\"</span>\r\n    <span style=\"color:#e28964\">return</span> tf.unpack(tf.transpose(tensor, <span style=\"color:#3e87e3\">perm</span><span style=\"color:#e28964\">=</span>[<span style=\"color:#3387cc\">1</span>, <span style=\"color:#3387cc\">0</span>, <span style=\"color:#3387cc\">2</span>]))\r\n\r\n<span style=\"color:#99cf50\">def</span> <span style=\"color:#89bdff\">pack_sequence</span>(<span style=\"color:#3e87e3\">sequence</span>):\r\n    <span style=\"color:#65b042\">\"\"\"Combine a list of the frames into a single tensor of the sequence.\"\"\"</span>\r\n    <span style=\"color:#e28964\">return</span> tf.transpose(tf.pack(sequence), <span style=\"color:#3e87e3\">perm</span><span style=\"color:#e28964\">=</span>[<span style=\"color:#3387cc\">1</span>, <span style=\"color:#3387cc\">0</span>, <span style=\"color:#3387cc\">2</span>])\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>As of version\u00a0<code>v0.8.0</code>, TensorFlow provides\u00a0<code>rnn.dynamic_rnn</code>\u00a0as an alternative to\u00a0<code>rnn.rnn</code>\u00a0that does not actually unroll the compute graph but uses a loop graph operation. The interface is the same except that you don\u2019t need\u00a0<code>unpack_sequence()</code>\u00a0and\u00a0<code>pack_sequence()</code>\u00a0anymore, it already operates on single tensors. In the following sections, I will mention the modifications you need to make in order to use\u00a0<code>dynamic_rnn</code>.</p>\n<h3>Sequence Classification</h3>\n<p>\u00a0<br/>\nFor classification, you might only care about the output activation at the last timestep, which is just<code>outputs[-1]</code>. The code below adds a softmax classifier ontop of that and defines the cross entropy error function. For now we assume sequences to be equal in length but I will cover variable length sequences in another post.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">in_size <span style=\"color:#e28964\">=</span> num_hidden\r\nout_size <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(target.get_shape()[<span style=\"color:#3387cc\">2</span>])\r\nweight <span style=\"color:#e28964\">=</span> tf.Variable(tf.truncated_normal([in_size, out_size], <span style=\"color:#3e87e3\">stddev</span><span style=\"color:#e28964\">=</span><span style=\"color:#3387cc\">0.1</span>))\r\nbias <span style=\"color:#e28964\">=</span> tf.Variable(tf.constant(<span style=\"color:#3387cc\">0.1</span>, <span style=\"color:#3e87e3\">shape</span><span style=\"color:#e28964\">=</span>[out_size]))\r\nprediction <span style=\"color:#e28964\">=</span> tf.nn.softmax(tf.matmul(outputs[<span style=\"color:#e28964\">-</span><span style=\"color:#3387cc\">1</span>], weight) <span style=\"color:#e28964\">+</span> bias)\r\ncross_entropy <span style=\"color:#e28964\">=</span> <span style=\"color:#e28964\">-</span>tf.reduce_sum(target <span style=\"color:#e28964\">*</span> tf.log(prediction))\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>When using\u00a0<code>dynamic_rnn</code>, this is how to get the last output of the recurrent networks. We can\u2019t use<code>outputs[-1]</code>\u00a0because unlike Python lists, TensorFlow doesn\u2019t support negative indexing yet. Here is the<a href=\"https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159\">complete gist for sequence classification</a>.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">output, _ <span style=\"color:#e28964\">=</span> rnn.dynamic_rnn(network, data, <span style=\"color:#3e87e3\">dtype</span><span style=\"color:#e28964\">=</span>tf.float32)\r\noutput <span style=\"color:#e28964\">=</span> tf.transpose(output, [<span style=\"color:#3387cc\">1</span>, <span style=\"color:#3387cc\">0</span>, <span style=\"color:#3387cc\">2</span>])\r\nlast <span style=\"color:#e28964\">=</span> tf.gather(output, <span style=\"color:#9b859d\">int</span>(output.get_shape()[<span style=\"color:#3387cc\">0</span>]) <span style=\"color:#e28964\">-</span> <span style=\"color:#3387cc\">1</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<h3>Sequence Labelling</h3>\n<p>\u00a0<br/>\nFor sequence labelling, we want a prediction for each timestamp. However, we share the weights for the softmax layer across all timesteps. This way, we have one softmax layer ontop of an unrolled recurrent network as desired.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">in_size <span style=\"color:#e28964\">=</span> num_hidden\r\nout_size <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(target.get_shape()[<span style=\"color:#3387cc\">2</span>])\r\nweight <span style=\"color:#e28964\">=</span> tf.Variable(tf.truncated_normal([in_size, out_size], <span style=\"color:#3e87e3\">stddev</span><span style=\"color:#e28964\">=</span><span style=\"color:#3387cc\">0.1</span>))\r\nbias <span style=\"color:#e28964\">=</span> tf.Variable(tf.constant(<span style=\"color:#3387cc\">0.1</span>, <span style=\"color:#3e87e3\">shape</span><span style=\"color:#e28964\">=</span>[out_size]))\r\npredictions <span style=\"color:#e28964\">=</span> [tf.nn.softmax(tf.matmul(x, weight) <span style=\"color:#e28964\">+</span> bias) <span style=\"color:#e28964\">for</span> x <span style=\"color:#e28964\">in</span> outputs]\r\nprediction <span style=\"color:#e28964\">=</span> pack_sequence(predictions)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>If you want to use\u00a0<code>dynamic_rnn</code>\u00a0instead, you cannot apply the same weights and biases to all time steps in a Python list comprehension. Instead, we must flatten the outputs of each time step. This way time steps look the same as examples in the trainng batch to the weight matrix. Afterwards, we reshape back to the desired shape.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">max_length <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(<span style=\"color:#3e87e3\">self</span>.target.get_shape()[<span style=\"color:#3387cc\">1</span>])\r\nnum_classes <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(<span style=\"color:#3e87e3\">self</span>.target.get_shape()[<span style=\"color:#3387cc\">2</span>])\r\nweight, bias <span style=\"color:#e28964\">=</span> <span style=\"color:#3e87e3\">self</span>._weight_and_bias(<span style=\"color:#3e87e3\">self</span>._num_hidden, num_classes)\r\noutput <span style=\"color:#e28964\">=</span> tf.reshape(output, [<span style=\"color:#e28964\">-</span><span style=\"color:#3387cc\">1</span>, <span style=\"color:#3e87e3\">self</span>._num_hidden])\r\nprediction <span style=\"color:#e28964\">=</span> tf.nn.softmax(tf.matmul(output, weight) <span style=\"color:#e28964\">+</span> bias)\r\nprediction <span style=\"color:#e28964\">=</span> tf.reshape(prediction, [<span style=\"color:#e28964\">-</span><span style=\"color:#3387cc\">1</span>, max_length, num_classes])\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Since this is a classification task as well, we keep using cross entropy as our error function. Here we have a prediction and target for every timestep. We thus compute the cross entropy for every timestep first and then average. Here is the\u00a0<a href=\"https://gist.github.com/danijar/61f9226f7ea498abce36187ddaf51ed5\">complete gist for sequence labelling</a>.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">cross_entropy <span style=\"color:#e28964\">=</span> <span style=\"color:#e28964\">-</span>tf.reduce_sum(\r\n    target <span style=\"color:#e28964\">*</span> tf.log(prediction), <span style=\"color:#3e87e3\">reduction_indices</span><span style=\"color:#e28964\">=</span>[<span style=\"color:#3387cc\">1</span>])\r\ncross_entropy <span style=\"color:#e28964\">=</span> tf.reduce_mean(cross_entropy)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>That\u2019s all. We learned how to construct recurrent networks in TensorFlow and use them for sequence learning tasks. Please ask any questions below if you couldn\u2019t follow.</p>\n<p><b>Bio: <a href=\"https://danijar.com/\">Danijar Hafner</a></b> is a Python and C++ developer from Berlin interested in Machine Intelligence research. He recently released a <a href=\"https://github.com/danijar/layered\">neural networks library</a>, but he likes creating new things in general.</p>\n<p><a href=\"http://danijar.com/introduction-to-recurrent-networks-in-tensorflow/\">Original</a>. Reposted with permission.</p>\n<p><b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2015/10/recurrent-neural-networks-tutorial.html\">Recurrent Neural Networks Tutorial, Introduction</a>\n<li><a href=\"/2016/01/learning-to-code-neural-networks.html\">Learning to Code Neural Networks</a>\n<li><a href=\"/2016/05/implementing-neural-networks-javascript.html\">Implementing Neural Networks in Javascript</a>\n</li></li></li></ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/05/intel-investment-cognitive-tech-impact-new-opportunities.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/jobs/16/05-31-jobs-data-scientist.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/05/tutorials.html\">Tutorials, Overviews</a> \u00bb Introduction to Recurrent Networks in TensorFlow (\u00a0<a href=\"/2016/n20.html\">16:n20</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556383225\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.613 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 12:40:25 -->\n<!-- Compression = gzip -->", "content_tokenized": ["danijar", "hafner", "independ", "machin", "learn", "research", "recurr", "network", "like", "and", "are", "power", "sequenc", "model", "will", "explain", "how", "creat", "recurr", "network", "tensorflow", "and", "use", "them", "for", "sequenc", "classif", "and", "sequenc", "label", "task", "are", "not", "familiar", "with", "recurr", "network", "suggest", "take", "look", "christoph", "olah", "great", "post", "first", "the", "tensorflow", "part", "also", "expect", "some", "basic", "knowledg", "the", "offici", "tutori", "are", "good", "place", "start", "from", "tensorflowmodelsrnn", "import", "rnncell", "numhidden", "num", "numlay", "num", "dropout", "network", "network", "network", "defin", "the", "network", "use", "recurr", "network", "tensorflow", "first", "need", "defin", "the", "network", "architectur", "consist", "one", "more", "layer", "the", "cell", "type", "and", "possibl", "dropout", "between", "the", "layer", "unrol", "time", "can", "now", "unrol", "this", "network", "time", "use", "the", "rnn", "oper", "this", "take", "placehold", "for", "the", "input", "each", "timestep", "and", "return", "the", "hidden", "state", "and", "output", "activ", "for", "each", "timestep", "from", "tensorflowmodelsrnn", "import", "rnn", "maxlength", "num", "batch", "size", "time", "time", "step", "time", "data", "width", "data", "output", "state", "dtype", "tffloatnum", "output", "state", "tensorflow", "use", "python", "list", "one", "tensor", "for", "each", "timestep", "for", "the", "interfac", "thus", "make", "use", "and", "split", "our", "data", "tensor", "into", "list", "frame", "and", "merg", "the", "result", "back", "singl", "tensor", "def", "unpacksequ", "tensor", "split", "the", "singl", "tensor", "sequenc", "into", "list", "frame", "return", "def", "packsequ", "sequenc", "combin", "list", "the", "frame", "into", "singl", "tensor", "the", "sequenc", "return", "perm", "num", "num", "num", "version", "vnum", "tensorflow", "provid", "rnndynamicrnn", "altern", "rnnrnn", "that", "doe", "not", "actual", "unrol", "the", "comput", "graph", "but", "use", "loop", "graph", "oper", "the", "interfac", "the", "same", "except", "that", "need", "and", "anymor", "alreadi", "oper", "singl", "tensor", "the", "follow", "section", "will", "mention", "the", "modif", "need", "make", "order", "use", "dynamicrnn", "sequenc", "classif", "for", "classif", "might", "onli", "care", "about", "the", "output", "activ", "the", "last", "timestep", "which", "just", "output", "num", "the", "code", "below", "add", "softmax", "classifi", "ontop", "that", "and", "defin", "the", "cross", "entropi", "error", "function", "for", "now", "assum", "sequenc", "equal", "length", "but", "will", "cover", "variabl", "length", "sequenc", "anoth", "post", "insiz", "numhidden", "outsiz", "int", "num", "weight", "bias", "predict", "bias", "crossentropi", "when", "use", "dynamicrnn", "this", "how", "get", "the", "last", "output", "the", "recurr", "network", "can", "use", "output", "num", "becaus", "unlik", "python", "list", "tensorflow", "support", "negat", "index", "yet", "here", "the", "complet", "gist", "for", "sequenc", "classif", "output", "output", "last", "num", "num", "sequenc", "label", "for", "sequenc", "label", "want", "predict", "for", "each", "timestamp", "howev", "share", "the", "weight", "for", "the", "softmax", "layer", "across", "all", "timestep", "this", "way", "have", "one", "softmax", "layer", "ontop", "unrol", "recurr", "network", "desir", "insiz", "numhidden", "outsiz", "int", "num", "weight", "bias", "predict", "bias", "for", "output", "predict", "want", "use", "dynamicrnn", "instead", "can", "not", "appli", "the", "same", "weight", "and", "bias", "all", "time", "step", "python", "list", "comprehens", "instead", "must", "flatten", "the", "output", "each", "time", "step", "this", "way", "time", "step", "look", "the", "same", "exampl", "the", "trainng", "batch", "the", "weight", "matrix", "afterward", "reshap", "back", "the", "desir", "shape", "maxlength", "int", "self", "num", "numclass", "int", "self", "num", "weight", "bias", "self", "output", "predict", "bias", "predict", "sinc", "this", "classif", "task", "well", "keep", "use", "cross", "entropi", "our", "error", "function", "here", "have", "predict", "and", "target", "for", "everi", "timestep", "thus", "comput", "the", "cross", "entropi", "for", "everi", "timestep", "first", "and", "then", "averag", "here", "the", "complet", "gist", "for", "sequenc", "label", "crossentropi", "reductionindic", "num", "crossentropi", "that", "all", "learn", "how", "construct", "recurr", "network", "tensorflow", "and", "use", "them", "for", "sequenc", "learn", "task", "pleas", "ask", "ani", "question", "below", "couldn", "follow", "bio", "danijar", "hafner", "python", "and", "develop", "from", "berlin", "interest", "machin", "intellig", "research", "recent", "releas", "neural", "network", "librari", "but", "like", "creat", "new", "thing", "general", "origin", "repost", "with", "permiss", "relat", "recurr", "neural", "network", "tutori", "introduct", "learn", "code", "neural", "network", "implement", "neural", "network", "javascript"], "timestamp_scraper": 1556383226.275058, "title": "Introduction to Recurrent Networks in TensorFlow", "read_time": 241.2, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By Danijar Hafner, Independent Machine Learning Researcher</b>.</p>\n<p><img alt=\"TensorFlow\" src=\"/wp-content/uploads/tensorflow-white-bg.png\" width=\"99%\"/></p>\n<p>Recurrent networks like LSTM and GRU are powerful sequence models. I will explain how to create recurrent networks in TensorFlow and use them for sequence classification and sequence labelling tasks. If you are not familiar with recurrent networks, I suggest you take a look at Christopher Olah\u2019s\u00a0<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">great post</a>\u00a0first. On the TensorFlow part, I also expect some basic knowledge. The\u00a0<a href=\"https://www.tensorflow.org/versions/r0.8/tutorials/index.html\">official tutorials</a>\u00a0are a good place to start.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\"><span style=\"color:#e28964\">from</span> tensorflow.models.rnn <span style=\"color:#e28964\">import</span> rnn_cell\r\n\r\nnum_hidden <span style=\"color:#e28964\">=</span> <span style=\"color:#3387cc\">200</span>\r\nnum_layers <span style=\"color:#e28964\">=</span> <span style=\"color:#3387cc\">3</span>\r\ndropout <span style=\"color:#e28964\">=</span> tf.placeholder(tf.float32)\r\n\r\nnetwork <span style=\"color:#e28964\">=</span> rnn_cell.GRUCell(num_hidden)  <span style=\"color:#aeaeae;font-style:italic\"># Or LSTMCell(num_hidden)</span>\r\nnetwork <span style=\"color:#e28964\">=</span> rnn_cell.DropoutWrapper(network, <span style=\"color:#3e87e3\">output_keep_prob</span><span style=\"color:#e28964\">=</span>dropout)\r\nnetwork <span style=\"color:#e28964\">=</span> rnn_cell.MultiRNNCell([network] <span style=\"color:#e28964\">*</span> num_layers)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<h3>Defining the Network</h3>\n<p>\u00a0<br>\nTo use recurrent networks in TensorFlow we first need to define the network architecture consisting of one or more layers, the cell type and possibly dropout between the layers.</br></p>\n<h3>Unrolling in Time</h3>\n<p>\u00a0<br>\nWe can now unroll this network in time using the\u00a0<code>rnn</code>\u00a0operation. This takes placeholders for the input at each timestep and returns the hidden\u00a0<em>states</em>\u00a0and\u00a0<em>output</em>\u00a0activations for each timestep.</br></p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\"><span style=\"color:#e28964\">from</span> tensorflow.models.rnn <span style=\"color:#e28964\">import</span> rnn\r\nmax_length <span style=\"color:#e28964\">=</span> <span style=\"color:#3387cc\">100</span>\r\n\r\n<span style=\"color:#aeaeae;font-style:italic\"># Batch size times time steps times data width.</span>\r\ndata <span style=\"color:#e28964\">=</span> tf.placeholder(tf.float32, [<span style=\"color:#3387cc\">None</span>, max_length, <span style=\"color:#3387cc\">28</span>])\r\noutputs, states <span style=\"color:#e28964\">=</span> rnn.rnn(network, unpack_sequence(data), <span style=\"color:#3e87e3\">dtype</span><span style=\"color:#e28964\">=</span>tf.float32)\r\noutput <span style=\"color:#e28964\">=</span> pack_sequence(outputs)\r\nstate <span style=\"color:#e28964\">=</span> pack_sequence(states)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>TensorFlow uses Python lists of one tensor for each timestep for the interface. Thus we make use of<a href=\"https://www.tensorflow.org/versions/r0.8/api_docs/python/array_ops.html#pack\"><code>tf.pack()</code>\u00a0and\u00a0<code>tf.unpack()</code></a>\u00a0to split our data tensors into lists of frames and merge the results back to a single tensor.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\"><span style=\"color:#99cf50\">def</span> <span style=\"color:#89bdff\">unpack_sequence</span>(<span style=\"color:#3e87e3\">tensor</span>):\r\n    <span style=\"color:#65b042\">\"\"\"Split the single tensor of a sequence into a list of frames.\"\"\"</span>\r\n    <span style=\"color:#e28964\">return</span> tf.unpack(tf.transpose(tensor, <span style=\"color:#3e87e3\">perm</span><span style=\"color:#e28964\">=</span>[<span style=\"color:#3387cc\">1</span>, <span style=\"color:#3387cc\">0</span>, <span style=\"color:#3387cc\">2</span>]))\r\n\r\n<span style=\"color:#99cf50\">def</span> <span style=\"color:#89bdff\">pack_sequence</span>(<span style=\"color:#3e87e3\">sequence</span>):\r\n    <span style=\"color:#65b042\">\"\"\"Combine a list of the frames into a single tensor of the sequence.\"\"\"</span>\r\n    <span style=\"color:#e28964\">return</span> tf.transpose(tf.pack(sequence), <span style=\"color:#3e87e3\">perm</span><span style=\"color:#e28964\">=</span>[<span style=\"color:#3387cc\">1</span>, <span style=\"color:#3387cc\">0</span>, <span style=\"color:#3387cc\">2</span>])\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>As of version\u00a0<code>v0.8.0</code>, TensorFlow provides\u00a0<code>rnn.dynamic_rnn</code>\u00a0as an alternative to\u00a0<code>rnn.rnn</code>\u00a0that does not actually unroll the compute graph but uses a loop graph operation. The interface is the same except that you don\u2019t need\u00a0<code>unpack_sequence()</code>\u00a0and\u00a0<code>pack_sequence()</code>\u00a0anymore, it already operates on single tensors. In the following sections, I will mention the modifications you need to make in order to use\u00a0<code>dynamic_rnn</code>.</p>\n<h3>Sequence Classification</h3>\n<p>\u00a0<br/>\nFor classification, you might only care about the output activation at the last timestep, which is just<code>outputs[-1]</code>. The code below adds a softmax classifier ontop of that and defines the cross entropy error function. For now we assume sequences to be equal in length but I will cover variable length sequences in another post.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">in_size <span style=\"color:#e28964\">=</span> num_hidden\r\nout_size <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(target.get_shape()[<span style=\"color:#3387cc\">2</span>])\r\nweight <span style=\"color:#e28964\">=</span> tf.Variable(tf.truncated_normal([in_size, out_size], <span style=\"color:#3e87e3\">stddev</span><span style=\"color:#e28964\">=</span><span style=\"color:#3387cc\">0.1</span>))\r\nbias <span style=\"color:#e28964\">=</span> tf.Variable(tf.constant(<span style=\"color:#3387cc\">0.1</span>, <span style=\"color:#3e87e3\">shape</span><span style=\"color:#e28964\">=</span>[out_size]))\r\nprediction <span style=\"color:#e28964\">=</span> tf.nn.softmax(tf.matmul(outputs[<span style=\"color:#e28964\">-</span><span style=\"color:#3387cc\">1</span>], weight) <span style=\"color:#e28964\">+</span> bias)\r\ncross_entropy <span style=\"color:#e28964\">=</span> <span style=\"color:#e28964\">-</span>tf.reduce_sum(target <span style=\"color:#e28964\">*</span> tf.log(prediction))\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>When using\u00a0<code>dynamic_rnn</code>, this is how to get the last output of the recurrent networks. We can\u2019t use<code>outputs[-1]</code>\u00a0because unlike Python lists, TensorFlow doesn\u2019t support negative indexing yet. Here is the<a href=\"https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159\">complete gist for sequence classification</a>.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">output, _ <span style=\"color:#e28964\">=</span> rnn.dynamic_rnn(network, data, <span style=\"color:#3e87e3\">dtype</span><span style=\"color:#e28964\">=</span>tf.float32)\r\noutput <span style=\"color:#e28964\">=</span> tf.transpose(output, [<span style=\"color:#3387cc\">1</span>, <span style=\"color:#3387cc\">0</span>, <span style=\"color:#3387cc\">2</span>])\r\nlast <span style=\"color:#e28964\">=</span> tf.gather(output, <span style=\"color:#9b859d\">int</span>(output.get_shape()[<span style=\"color:#3387cc\">0</span>]) <span style=\"color:#e28964\">-</span> <span style=\"color:#3387cc\">1</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<h3>Sequence Labelling</h3>\n<p>\u00a0<br/>\nFor sequence labelling, we want a prediction for each timestamp. However, we share the weights for the softmax layer across all timesteps. This way, we have one softmax layer ontop of an unrolled recurrent network as desired.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">in_size <span style=\"color:#e28964\">=</span> num_hidden\r\nout_size <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(target.get_shape()[<span style=\"color:#3387cc\">2</span>])\r\nweight <span style=\"color:#e28964\">=</span> tf.Variable(tf.truncated_normal([in_size, out_size], <span style=\"color:#3e87e3\">stddev</span><span style=\"color:#e28964\">=</span><span style=\"color:#3387cc\">0.1</span>))\r\nbias <span style=\"color:#e28964\">=</span> tf.Variable(tf.constant(<span style=\"color:#3387cc\">0.1</span>, <span style=\"color:#3e87e3\">shape</span><span style=\"color:#e28964\">=</span>[out_size]))\r\npredictions <span style=\"color:#e28964\">=</span> [tf.nn.softmax(tf.matmul(x, weight) <span style=\"color:#e28964\">+</span> bias) <span style=\"color:#e28964\">for</span> x <span style=\"color:#e28964\">in</span> outputs]\r\nprediction <span style=\"color:#e28964\">=</span> pack_sequence(predictions)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>If you want to use\u00a0<code>dynamic_rnn</code>\u00a0instead, you cannot apply the same weights and biases to all time steps in a Python list comprehension. Instead, we must flatten the outputs of each time step. This way time steps look the same as examples in the trainng batch to the weight matrix. Afterwards, we reshape back to the desired shape.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">max_length <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(<span style=\"color:#3e87e3\">self</span>.target.get_shape()[<span style=\"color:#3387cc\">1</span>])\r\nnum_classes <span style=\"color:#e28964\">=</span> <span style=\"color:#9b859d\">int</span>(<span style=\"color:#3e87e3\">self</span>.target.get_shape()[<span style=\"color:#3387cc\">2</span>])\r\nweight, bias <span style=\"color:#e28964\">=</span> <span style=\"color:#3e87e3\">self</span>._weight_and_bias(<span style=\"color:#3e87e3\">self</span>._num_hidden, num_classes)\r\noutput <span style=\"color:#e28964\">=</span> tf.reshape(output, [<span style=\"color:#e28964\">-</span><span style=\"color:#3387cc\">1</span>, <span style=\"color:#3e87e3\">self</span>._num_hidden])\r\nprediction <span style=\"color:#e28964\">=</span> tf.nn.softmax(tf.matmul(output, weight) <span style=\"color:#e28964\">+</span> bias)\r\nprediction <span style=\"color:#e28964\">=</span> tf.reshape(prediction, [<span style=\"color:#e28964\">-</span><span style=\"color:#3387cc\">1</span>, max_length, num_classes])\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Since this is a classification task as well, we keep using cross entropy as our error function. Here we have a prediction and target for every timestep. We thus compute the cross entropy for every timestep first and then average. Here is the\u00a0<a href=\"https://gist.github.com/danijar/61f9226f7ea498abce36187ddaf51ed5\">complete gist for sequence labelling</a>.</p>\n<div style=\"background:#000;width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre style=\"background:#000;color:#f8f8f8\">cross_entropy <span style=\"color:#e28964\">=</span> <span style=\"color:#e28964\">-</span>tf.reduce_sum(\r\n    target <span style=\"color:#e28964\">*</span> tf.log(prediction), <span style=\"color:#3e87e3\">reduction_indices</span><span style=\"color:#e28964\">=</span>[<span style=\"color:#3387cc\">1</span>])\r\ncross_entropy <span style=\"color:#e28964\">=</span> tf.reduce_mean(cross_entropy)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>That\u2019s all. We learned how to construct recurrent networks in TensorFlow and use them for sequence learning tasks. Please ask any questions below if you couldn\u2019t follow.</p>\n<p><b>Bio: <a href=\"https://danijar.com/\">Danijar Hafner</a></b> is a Python and C++ developer from Berlin interested in Machine Intelligence research. He recently released a <a href=\"https://github.com/danijar/layered\">neural networks library</a>, but he likes creating new things in general.</p>\n<p><a href=\"http://danijar.com/introduction-to-recurrent-networks-in-tensorflow/\">Original</a>. Reposted with permission.</p>\n<p><b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2015/10/recurrent-neural-networks-tutorial.html\">Recurrent Neural Networks Tutorial, Introduction</a>\n<li><a href=\"/2016/01/learning-to-code-neural-networks.html\">Learning to Code Neural Networks</a>\n<li><a href=\"/2016/05/implementing-neural-networks-javascript.html\">Implementing Neural Networks in Javascript</a>\n</li></li></li></ul>\n</div> ", "website": "kdnuggets"}