{"content": "comments By Matt Hergott , MiaBella AI . Is December 12, 2018, a day the world changed forever? That Wednesday, a team of researchers at NVIDIA released a dazzling new artificial intelligence design called the StyleGAN. [1] \u00a0The StyleGAN is a deep learning system based on the idea of a generative adversarial network (GAN), and this model generates ultra-realistic images of people, cars, and households. Inventions like this could change the way humankind interacts with nearly all media. For instance, when people see images in the news, their first reaction could be to try to determine whether what they are looking at is real or fake. GANs are some of the more futuristic AI designs, and people have many questions about them: What are GANs? Will I be able to understand them? Can I use GANs for my business analytics, or are they only good at creating images? This article will try to answer some of these questions. We\u2019ll start with an overview of GANs, then we\u2019ll discuss some challenges in helping GANs to learn. After that, we\u2019ll examine two promising GANs: the RadialGAN, [2] which is designed for numbers, and the StyleGAN, which is focused on images. The Generative Adversarial Network\u00a0(GAN) The original GAN [3] \u00a0was created by Ian Goodfellow, who described the GAN architecture in a paper published in mid-2014. A GAN consists of two neural networks playing a game with each other. The\u00a0 discriminator\u00a0 tries to determine whether information is real or fake. The other neural network, called a\u00a0 generator , tries to create data that the discriminator thinks is real. This concept is depicted in Figure 1. The neural network at the top is the discriminator, and its task is to distinguish the training set\u2019s real information from the generator\u2019s creations. In the simplest GAN structure, the generator starts with random data and learns to transform this noise into information that matches the distribution of the real data. The generator never sees the genuine data; it must learn to create realistic information by receiving feedback from the discriminator. This is called\u00a0 adversarial loss , and when implemented correctly it works surprisingly well. In fact, regularization techniques such as dropout layers are often used in GANs because the generator can overfit the training set through this entirely indirect learning process. The longer these two neural networks play this game, the more they sharpen each other\u2019s skills. The discriminator becomes very good at detecting fake data while the generator learns to produce information that is indistinguishable from what is observed in the real world. When we end up with two GAN neural networks that are very good at what they do, how could we use them? A trained discriminator can be used for detecting abnormalities, outliers, and anything out of the ordinary. This could be very valuable in fields such as cybersecurity, radiology, astronomy, and manufacturing. A skilled generator is used for making creations. Once the generator learns the distribution of the training data, we can sample the generator an unlimited number of times for realistic outputs such as images, language,\u00a0 pharmaceuticals , numerical simulations, and just about anything else one can imagine. Wasserstein GAN\u00a0(WGAN) The original GAN created a lot of excitement when it was first introduced. But there was a problem that showed up immediately: if one of the neural networks started to dominate the other in the GAN game, learning would stop for both. The GAN neural networks are called adversaries, but we want to keep one side from winning so they both can learn for an extended time. This training dilemma is illustrated in Figure 2. The standard binary classifier is a sigmoid curve\u200a\u2014\u200amore formally called a standard logistic sigmoid function\u200a\u2014\u200athat converts an input value into a result between 0 (a negative classification) and 1 (a positive classification).\u00a0 The tail ends of the sigmoid curve are very flat, which means that neural networks can lose their sense of direction if the GAN game ends up far out on one of these tails. For instance, if the discriminator can always tell that the generator\u2019s creations are fake, the discriminator will always return a 0 to the generator\u2019s training function. If the generator is always able to fool the discriminator, the discriminator always sends a 1 to the generator. In either case, learning stops for both neural networks because neither one is receiving any feedback on how to get better. An innovation in 2017 made training GANs much more stable. The Wasserstein GAN [4] (WGAN) changes the type of response the discriminator sends to the generator. Instead of returning the sigmoid value of the vertical axis, the WGAN returns the input value of the horizontal axis (see Figure 3). In other words, the standard neural network classifier returns\u00a0  , whereas the WGAN returns\u00a0 x . This means that even if one of the neural networks is always winning, at least the tiny variations that do occur will not get completely flattened out by a sigmoid function. For example, if a GAN discriminator is always able to detect fake data, it might output a value of -100 on one iteration and then -99 on the next iteration. Sending these numbers through a classic sigmoid function makes them indistinguishable at 40+ decimal places. This is why learning stops so easily in the simplest GAN: the generator can end up in a position where it is receiving essentially no direction from the discriminator. But the WGAN uses the raw numbers (-100 and -99), and this 1% change can be enough to give the generator a path for improvement. This means that learning can continue even if one of the neural networks is overwhelming the other. The basic WGAN training equations are shown in Figure 4. The terms inside the parentheses represent the desired learning direction of each neural network, and these expressions get multiplied by -1 since we typically optimize in the downhill direction. If the discriminator is very good at its job, it returns high values for real samples and low values for the fake information coming from the generator. The generator has the opposite goal: it wants the discriminator to assign high values\u200a\u2014\u200ain other words, false positives\u200a\u2014\u200ato the generated information. WGAN Refinements The Critic The WGAN authors changed the GAN terminology a bit by referring to the discriminator neural network as a\u00a0 critic . The word discriminator comes from\u00a0 discriminant analysis \u00a0and reflects a classifier that separates data into categories. The WGAN, on the other hand, returns much richer feedback, and this is somewhat analogous to a written review by a movie critic. Diverse Results One of the problems people can experience with GANs is that the neural networks appear to be learning properly, but in the end, the generator only re-creates a limited portion of the training distribution. This occurs because the generator can outsmart the training process. If the only instruction the generator receives is to fool the discriminator, the generator can learn to maximize its chance of success by sticking to the most heavily populated portion of the training set. We typically want a generator to produce a broad range of results, and two common practices help with this. Minibatch discrimination [5] dynamically collects statistics on a batch of samples\u200a\u2014\u200ain other words, from multiple observations\u200a\u2014\u200aat one or more layers of the discriminator neural network. The discriminator then uses these statistics as additional information in its assessment of whether the data set is genuine or fake. If the dispersion of samples is very different between the training set and the generated data, the discriminator can signal to the generator that the generator needs to increase the range of its results. Another option for producing a wide variety of results is to provide both the generator and the discriminator with extra variables that act as\u00a0 conditioning information \u00a0to tell the neural networks which environment they are operating in. This is a major advantage when we want to direct a generator to produce creations appropriate for a specific situation. Optimizers The WGAN might require some thought as to the best optimizer to use. A sigmoid curve is often called a \u201csquashing\u201d function because it flattens its inputs into a range of 0 to 1. But the WGAN can return any value at any time, and thus its outputs are\u00a0 nonstationary . For this type of problem, it might be helpful to use optimizers without momentum (like RMSProp [6] ) or at least turn down the momentum parameter of an optimizer like adaptive moment estimation (Adam [7] ). WGAN with Gradient Penalty (WGAN-GP) It turns out that implementing the Wasserstein GAN isn\u2019t quite as simple as eliminating the sigmoid function in the discriminator. The math behind the WGAN requires that the gradients of the discriminator can\u2019t be very steep. In other words, if we alter the inputs to the discriminator neural network, the discriminator\u2019s output can\u2019t change too drastically. To satisfy this condition, a group of machine learning researchers created the gradient penalty. [8] \u00a0This technique adds a penalty term to the discriminator\u2019s loss function if the gradients get too sharp, and it pushes the discriminator\u2019s learning process toward flatter gradients. The general programming pattern for the gradient penalty looks like this: Make a randomly weighted combination of the real data and the generator\u2019s manufactured output; this is a way to sample as much of the discriminator\u2019s function range as is feasible. Obtain the gradient by measuring how the discriminator\u2019s output changes with respect to this weighted mixture of inputs. This is usually done through a deep learning framework such as TensorFlow\u2019s\u00a0  function. Calculate the norm\u200a\u2014\u200ain other words, the length\u200a\u2014\u200aof the gradient and create a penalty based on how far this is from 1. Add the result from #3 to the discriminator\u2019s loss function. The discriminator then knows that it needs to learn its job without building a steep relationship between its inputs and output. The WGAN-GP approach leads to more stable GAN training and has probably helped to increase the pace of GAN innovation since 2017. For instance, Figure 6 shows how some of the most famous GANs were created over just the past couple of years. One drawback to the WGAN-GP is its training time. Each iteration requires a calculation of the discriminator\u2019s gradient. Moreover, it is typical to train the discriminator at least 5 times as often as the generator. This is because the excellent feedback a well-trained discriminator gives to the generator should allow the generator to become highly effective with fewer learning iterations. There is much research being done on how to help GANs learn faster while maintaining the stability of a WGAN-GP. [9] Sample GANs Now that we\u2019ve covered the essentials of GANs and how to train them, we\u2019ll look at two very promising GANs. The RadialGAN is designed for numerical analysis, while the StyleGAN received global media coverage for its stunning image creations. The RadialGAN Let\u2019s say we are data scientists working for a hospital that wants to evaluate the efficacy of a new medical treatment. Because this procedure is new, our hospital doesn\u2019t have enough data for us to render a credible judgment. We are, however, granted access to other hospitals\u2019 data, and this gives us enough information to give a proper assessment of the new treatment. But combining data from different hospitals has problems. There is\u00a0 distribution mismatch \u00a0because the hospitals service very different populations of people. There is also\u00a0 feature mismatch \u00a0because the hospitals collect their own data sets, use laboratories that give slightly different results, and measure outcomes in varying ways. This is where the RadialGAN comes in. The RadialGAN first transforms each data set into a\u00a0 latent space , which holds all the data from different sources in a uniform format. The data in the latent space can then be extracted and converted into the feature space of each unique data set. In GAN terminology, these data transformations are referred to as\u00a0 domain transfer , which is when we extract the essential knowledge of a data set and transport that intelligence onto another information set. In the RadialGAN, each data set has an\u00a0 encoder\u00a0 neural network that transforms the data into the homogeneous structure of the latent space. Every data source also has a\u00a0 decoder , which is a GAN with a generator that converts information from the latent space into a form consistent with the data set. Each of these decoder GANs has a discriminator that confirms the information coming out of the latent space matches the properties of the target data domain. This setup makes sure that the domain transfer of information works in both directions and is reversible. This concept is called\u00a0 cycle consistency . It originated with the CycleGAN, [10] \u00a0and it has become a crucial part of many GAN models. We train all these neural networks simultaneously, and once the learning process is complete, we can use the RadialGAN to create an augmented data set as shown in Figure 8. To construct our enhanced data set, we run each of the other data sets through their encoders to transfer that knowledge into the latent space. Then we extract that intelligence from the latent space using our decoder and append the transformed information to our original data set. The result is a new, larger data set that is bolstered by information from a variety of sources, but which matches the characteristics of the domain we are working in. The StyleGAN The spectacular new StyleGAN combines two innovations: the Progressive GAN [11] \u00a0(ProGAN) and neural style transfer. [12] The ProGAN begins by developing a tiny image of 4x4 or 8x8 pixels until this picture is considered realistic by the ProGAN discriminator. Once this learning is complete, the ProGAN gently adds a higher-resolution layer that also needs to be trained. This process continues until the ProGAN can create 1024x1024-pixel images with amazing realism. The StyleGAN builds on the ProGAN by bringing in some of the most successful elements of neural style transfer. The original style transfer works by copying the neural network layer correlations of a style image onto a content image. This requires an optimization process that can take too long to be useful in many real-time applications. Researchers repeatedly made improvements to the classic neural style transfer, and the StyleGAN uses one of the more recent style transfer methods called adaptive instance normalization (AdaIN). [13] Adaptive instance normalization doesn\u2019t involve an optimization, and it\u2019s therefore a very fast way to transfer styles between images. It\u2019s also very flexible in that it can transfer styles between any images, including those that neural networks have never seen before because they aren\u2019t in any training set. Applying AdaIN to a convolutional neural network layer of a content image is a simple process: Normalize the layer by subtracting its mean and dividing by its standard deviation. Scale this normalized layer to match the standard deviation of the style layer. Shift the layer by adding in the average value of the style layer. This sounds more complicated than it really is. All we\u2019re doing is changing the mean and variance of an image\u2019s neural network layers to match the mean and variance of a style image (i.e., the image whose style we want to emulate). Further refinements to the StyleGAN and AdaIN could include methods like histogram matching, which would transfer more style detail but would also be very fast to calculate. The StyleGAN is a somewhat complex architecture that incorporates many neural network tools and tricks that have been developed over the past several years. But at its core, the StyleGAN combines the highly effective ProGAN with the successes of neural style transfer to create images that are so realistic they could fundamentally change the relationship people have with the news and entertainment media. Conclusion The StyleGAN is a striking example of how generative adversarial networks could transform the way much of the media produces its content and alter how consumers interpret the information they see and hear. The RadialGAN, on the other hand, shows how the features and advantages of GANs can be used to bolster numerical data analysis. These are two examples of a thriving community of hundreds of innovative GANs that can be used for just about any purpose one can imagine. Some of the results we\u2019re seeing from GANs look like they come from a different century, and one thing is certain: pioneering AI techniques like GANs are rapidly changing our relationship to technology, and to each other. References [1] \u00a0Tero Karras, Samuli Laine, and Timo Aila A Style-Based Generator Architecture for Generative Adversarial Networks arxiv.org/abs/1812.04948 [2] \u00a0Jinsung Yoon, James Jordon, and Mihaela van der Schaar RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks arxiv.org/abs/1802.06403 [3] \u00a0Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio Generative Adversarial Networks arxiv.org/abs/1406.2661 [4] \u00a0Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou Wasserstein GAN arxiv.org/abs/1701.07875 [5] \u00a0Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen Improved Techniques for Training GANs arxiv.org/abs/1606.03498 [6]\u00a0 Geoffrey Hinton Neural Networks for Machine Learning, slide #27: \u201crprop: Using only the sign of the gradient\u201d www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf [7] \u00a0Diederik P. Kingma and Jimmy Ba Adam: A Method for Stochastic Optimization arxiv.org/abs/1412.6980 [8] \u00a0Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville Improved Training of Wasserstein GANs arxiv.org/abs/1704.00028 [9]\u00a0 Lars Mescheder, Andreas Geiger, and Sebastian Nowozin Which Training Methods for GANs do Actually Converge? arxiv.org/abs/1801.04406 [10] \u00a0Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks arxiv.org/abs/1703.10593 [11]\u00a0 Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen Progressive Growing of GANs for Improved Quality, Stability, and Variation arxiv.org/abs/1710.10196 [12] \u00a0Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge A Neural Algorithm of Artistic Style arxiv.org/abs/1508.06576 [13] \u00a0Xun Huang and Serge Belongie Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization arxiv.org/abs/1703.06868 Original . Reposted with permission. Bio :\u00a0 Matt Hergott \u00a0is a Quantitative Researcher at MiaBella AI. Resources: On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education Software for Analytics, Data Science, Data Mining, and Machine Learning Related: The Rise of Generative Adversarial Networks Which Face is Real? My favorite mind-blowing Machine Learning/AI breakthroughs", "title_html": "<h1 id=\"title\">Generative Adversarial Networks \u2013 Key Milestones and State of the Art</h1> ", "url": "https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html", "tfidf": {"tfidf": {"hand": 3.2304405331200003, "rprop": 1587.6, "strike": 3.5620372447800004, "realist": 51.79771615, "slight": 3.25327868852, "huang": 66.9873417722, "real": 20.52931034484, "els": 5.44444444444, "wide": 1.5598349381, "new": 6.1073283324, "extra": 5.33826496301, "addit": 1.24634950542, "would": 3.2486187845399996, "nois": 11.6907216495, "instanc": 19.543701272040003, "specif": 1.8719490626099997, "vari": 2.4970116388799997, "progress": 4.89395807644, "thought": 1.9854927463699998, "further": 1.3618116315, "never": 3.11538461538, "creation": 15.300693909, "complet": 3.72064682448, "path": 4.6421052631599995, "toward": 1.6303142329, "their": 4.0619163362, "bing": 48.1090909091, "scale": 3.7469907953699995, "creat": 13.7422096317, "ahm": 30.3556405354, "extend": 1.9604840701400004, "instruct": 4.169117647059999, "news": 4.16365066876, "laboratori": 7.6363636363600005, "jame": 1.9313868613099998, "hinton": 152.653846154, "ecker": 1323.0, "end": 5.53402119355, "correl": 13.1860465116, "word": 10.779223718459999, "deep": 7.2559414990799995, "will": 4.89924394384, "consid": 1.2397313759200002, "incorpor": 2.62847682119, "unlimit": 21.027814569500002, "portion": 6.603993344419999, "pougetabadi": 1587.6, "next": 1.4950560316400001, "near": 1.28769567686, "but": 9.14691761091, "mixtur": 9.02558271745, "certain": 1.8077886586200003, "obtain": 2.68629441624, "our": 11.78794178795, "classif": 16.134146341460003, "longer": 2.02319357716, "radiolog": 98.0, "domin": 2.320713346, "grow": 2.27287043665, "success": 3.9600897979500003, "enough": 6.695908899210001, "stop": 6.535126234920001, "advantag": 6.64824120604, "resourc": 2.9487369985100003, "arjovski": 3175.2, "out": 5.30083472455, "model": 6.2717935212, "format": 2.53125, "good": 6.07926479036, "alway": 12.404740200540001, "concept": 5.31414225942, "number": 4.40571666436, "dumoulin": 1587.6, "categori": 3.98194130926, "optim": 92.3023255816, "field": 1.7790228597, "loss": 7.275893675520001, "involv": 1.4498630137000001, "arbitrari": 17.8181818182, "length": 3.69123459661, "determin": 4.331787175980001, "down": 1.35889754344, "schaar": 1587.6, "logist": 14.0994671403, "soumith": 1587.6, "then": 6.51947163096, "separ": 1.6012102874399998, "they": 10.3017325287, "anoth": 2.27287043664, "effect": 2.7926121372000003, "allow": 1.2716059271100002, "higherresolut": 1587.6, "opposit": 2.4663663197099996, "major": 1.14852058164, "construct": 1.9320920043799998, "featur": 4.58137745286, "practic": 1.70434782609, "respons": 1.5066907089300001, "simpl": 6.7962328767199995, "appear": 1.3214582986499999, "jean": 6.043395508180001, "cheung": 236.955223881, "either": 1.5830092731099998, "develop": 2.3911439114400004, "moreov": 7.56, "such": 4.24605509496, "futurist": 47.109792284899996, "math": 22.0806675939, "without": 2.59094247246, "fast": 9.7458563536, "should": 1.6643254009900001, "add": 13.83730389309, "varieti": 4.5944147012, "content": 10.6265060241, "belongi": 1587.6, "ani": 6.80302813884, "two": 8.1103448276, "limit": 1.5186531471200002, "whether": 6.62051709759, "detail": 2.26186066391, "stun": 21.6, "aren": 481.09090909099996, "idea": 2.0930784443, "environ": 3.43561999567, "curv": 33.3296011197, "equat": 9.76984615385, "for": 31.00976624031, "car": 3.53743315508, "slide": 15.1056137012, "output": 53.73887814316001, "releas": 1.8377126982299998, "seen": 1.61079545455, "with": 19.022765970809996, "characterist": 3.6724496877199995, "sens": 2.8365195640499996, "look": 7.634527530639999, "veri": 15.10561370124, "formal": 2.44622496148, "progan": 11113.199999999999, "think": 2.90715986083, "work": 5.57600449565, "negat": 3.75852272727, "combin": 6.79041916168, "promis": 7.006178287739999, "focus": 2.01012914662, "educ": 2.00733341763, "iter": 149.7735849056, "sigmoid": 8467.2, "decod": 155.1400651467, "group": 1.20996875238, "drastic": 14.0620017715, "park": 2.4633048875099997, "give": 6.826625387, "decim": 27.372413793099998, "extract": 23.109170305680003, "place": 1.1004366812200002, "simul": 11.4793926247, "normal": 13.0537740503, "goal": 3.28152128979, "jimmi": 9.230232558139999, "stick": 11.5377906977, "continu": 2.27857911734, "fals": 6.21613155834, "probabl": 2.64555907349, "scientist": 4.69426374926, "machin": 20.121673003799998, "into": 9.13522153311, "paper": 2.6628648104700003, "medic": 3.27542809986, "wardefarley": 1587.6, "servic": 1.51300867245, "face": 1.80327124035, "what": 5.01373756512, "ozair": 1587.6, "translat": 2.85745140389, "flexibl": 9.68639414277, "help": 6.99814863795, "cover": 1.69380134429, "dazzl": 77.067961165, "ishaan": 1587.6, "own": 1.17844418052, "occur": 3.4907651714999997, "multipl": 5.49627834516, "quantit": 27.803852889699996, "paramet": 17.256521739100002, "surpris": 4.36633663366, "about": 3.19458045477, "norm": 11.299644128099999, "neural": 1843.2808988763, "thing": 2.4065484311099996, "just": 4.00740429111, "entir": 1.59365589239, "grant": 2.2490437739099995, "repost": 933.882352941, "refin": 19.932203389839998, "credibl": 15.6568047337, "artist": 2.86673889491, "render": 5.97740963855, "alec": 40.917525773200005, "train": 42.6045376922, "complex": 2.34021226415, "tool": 4.99716713881, "start": 3.8002074523200005, "geiger": 138.052173913, "run": 1.55692850838, "keep": 2.04245465071, "taesung": 1587.6, "anyth": 9.17687861272, "lose": 3.0851146521599997, "cyclegan": 1587.6, "usual": 1.72508964468, "play": 2.92780082988, "critic": 5.01030927834, "appli": 2.2972073506, "over": 2.05050048434, "centuri": 1.49604221636, "alexand": 4.19445178336, "generat": 88.26842513556, "build": 3.2683479156, "depict": 4.0131445905000005, "innov": 18.96207823232, "hundr": 2.4698195395099996, "consist": 4.4704336399499995, "framework": 8.200413223139998, "bottou": 1587.6, "matthia": 58.1538461538, "assess": 10.48612945838, "say": 1.7544480053, "origin": 6.823495702020001, "mindblow": 1587.6, "knowledg": 6.7962328767199995, "take": 1.13961668222, "martin": 6.15587436992, "than": 1.03278688525, "publish": 1.36885669943, "also": 5.07382550335, "trick": 14.7272727273, "mean": 8.69441401974, "treatment": 7.74250182882, "task": 3.88641370869, "batch": 35.6764044944, "squash": 46.017391304300006, "overwhelm": 6.86381322957, "wednesday": 16.249744114600002, "bengio": 1587.6, "challeng": 2.55816951337, "hospit": 20.78010471204, "want": 11.98188679248, "enhanc": 5.15957101072, "convert": 9.82223138793, "webbas": 1587.6, "system": 1.38739840951, "targetspecif": 1587.6, "genuin": 22.9587852494, "behind": 2.0845588235299997, "howev": 1.0945191313299998, "elimin": 3.67670217693, "actual": 1.87482286254, "ordinari": 6.920662598080001, "maxim": 12.928338762200001, "arxivorgabsnum": 19051.199999999997, "which": 11.057110295, "like": 8.04429967425, "zhu": 92.3023255814, "skill": 7.3979496738199995, "estim": 2.34991119005, "raw": 10.6478873239, "refer": 3.9007371007500002, "techniqu": 14.917547568720002, "one": 14.08784940108, "show": 3.80111731845, "terminolog": 35.397993311, "begin": 1.3305397251100002, "drawback": 49.9245283019, "see": 6.36210627555, "algorithm": 27.9507042254, "becaus": 10.345666497749999, "outlier": 269.084745763, "moment": 4.262013422819999, "get": 7.1425036554, "random": 14.3804347826, "through": 4.28299723476, "imagin": 13.197007481300002, "wojciech": 208.89473684200001, "detect": 16.23866348448, "transform": 20.52046531668, "jaakko": 882.0, "recent": 1.54405757635, "sign": 1.7606742819099999, "repeat": 2.8771293947099994, "tim": 8.217391304349999, "this": 38.144157814980005, "imagetoimag": 1587.6, "sampl": 43.39681093392, "indistinguish": 112.5957446808, "lehtinen": 1587.6, "process": 11.86673785374, "bit": 8.33385826772, "fool": 38.9595092024, "karra": 2442.46153846, "somewhat": 8.58394160584, "most": 3.06289389069, "forev": 12.0363912055, "low": 2.13072070863, "heavili": 3.24132298898, "domain": 37.57633136096, "excel": 4.84467500763, "midnum": 1587.6, "top": 1.8387769284200002, "augment": 16.5202913632, "situat": 2.06611140031, "gradient": 418.89182058000006, "condit": 3.84966052376, "appropri": 4.31413043478, "correct": 3.6631287494199998, "sherjil": 1587.6, "author": 1.4229631621399998, "weight": 9.757836508919999, "architectur": 15.38372093022, "gan": 2325.783439484, "cycl": 5.40919931857, "and": 65.00409448845, "l\u00e9on": 1587.6, "overfit": 1587.6, "discuss": 2.19676214197, "general": 1.1218202374200001, "made": 2.14077669902, "realtim": 858.162162162, "type": 4.056208482380001, "simultan": 5.32930513595, "can": 30.58279617692, "hergott": 3175.2, "encod": 58.0475319926, "analog": 9.05131128848, "onli": 4.102590606640001, "each": 11.897482014400001, "befor": 1.10036041031, "data": 124.92811569558, "junyan": 1587.6, "qualiti": 2.9329392204, "richer": 47.25, "method": 10.285714285720001, "sinc": 2.16737201366, "convolut": 101.121019108, "must": 1.9220338983099996, "time": 5.0563730174, "miabella": 3175.2, "direct": 7.33358996076, "has": 7.305548251399999, "game": 10.31914202144, "gulrajani": 1587.6, "busi": 2.05541170378, "use": 19.56313639022, "household": 5.35266351989, "year": 2.0970873786400004, "often": 3.88356164385, "radialgan": 14288.4, "flat": 5.67811158798, "after": 1.02070207021, "chintala": 1587.6, "onc": 4.492359932099999, "too": 5.44755804645, "relat": 1.23750876919, "form": 1.12755681818, "signal": 5.12459651388, "immedi": 2.02862254025, "assign": 3.83663605607, "space": 19.18549848944, "transport": 2.68175675676, "dataset": 193.609756098, "function": 24.954416849999998, "onto": 8.95179024528, "rmsprop": 1587.6, "lain": 233.470588236, "hear": 4.17899447223, "well": 1.0655748708, "done": 4.6605019814999995, "nonstationari": 1587.6, "approach": 2.07556543339, "pace": 10.322496748999999, "hold": 1.6551292744, "know": 2.59327017315, "unpair": 453.6, "momentum": 33.67126193, "minibatch": 1587.6, "measur": 4.82186788154, "instead": 1.59461631177, "least": 4.8496079829, "humankind": 73.8418604651, "express": 1.9120799710900003, "vicki": 71.5135135135, "sharpen": 73.1612903226, "how": 16.0250328051, "reaction": 4.67904509284, "discrimin": 417.2264150925, "increas": 2.6404989605, "distribut": 10.958412424519999, "converg": 15.2947976879, "sure": 7.453521126760001, "sharp": 7.02477876106, "simplest": 56.0989399294, "overview": 12.6805111821, "numxnum": 104.1049180328, "wherea": 4.13868613139, "alter": 8.849498327760001, "purpos": 2.23416830847, "yoon": 407.07692307699995, "need": 4.31178707223, "learningai": 1587.6, "all": 4.04587155964, "confirm": 3.0827184466000004, "tero": 3175.2, "amaz": 15.250720461099998, "applic": 3.42672134686, "review": 2.2099109131400003, "have": 5.0744742057, "long": 1.2657259028899999, "tensorflow": 1587.6, "mihaela": 1587.6, "experi": 1.87062566278, "famous": 2.28201811125, "sound": 3.11294117647, "quit": 2.8849718335500003, "excit": 9.818181818180001, "layer": 89.55692307694, "numer": 5.49976905312, "astronomi": 24.3870967742, "global": 3.30612244898, "alexei": 73.1612903226, "entertain": 4.02739726027, "not": 1.01567398119, "far": 3.42044597652, "respect": 1.6443293630200002, "jinsung": 1587.6, "saliman": 1587.6, "shown": 5.53846153846, "complic": 5.6478121664900005, "design": 5.833011849, "core": 4.623179965059999, "bolster": 44.8474576272, "turn": 2.7677824267799997, "case": 1.48498737256, "tell": 6.72284564896, "welltrain": 1587.6, "scienc": 4.63939216832, "outcom": 7.48867924528, "pixel": 86.28260869569999, "thrive": 13.153272576600001, "larger": 2.2407904022599996, "pioneer": 4.74051955808, "that": 39.15537848625, "whose": 1.73508196721, "mine": 9.751842751839998, "valu": 20.499856527960002, "softwar": 10.2624434389, "observ": 4.44892812106, "sever": 1.07241286139, "horizont": 11.6137527432, "transfer": 35.43141630899, "network": 88.18559058992, "numxnumpixel": 1587.6, "some": 7.28256880736, "sourc": 5.09281437126, "both": 5.26078600305, "stabl": 13.40312368088, "dropout": 167.115789474, "judgment": 10.911340206199998, "classic": 4.8174783796, "introduc": 1.7258397651900002, "media": 10.37477536352, "question": 4.4081632653, "diederik": 1587.6, "divid": 2.3169877408099997, "from": 17.00964265449, "efro": 1587.6, "abnorm": 29.8983050847, "ultrarealist": 1587.6, "num": 53.016697120530004, "multipli": 20.4061696658, "movi": 4.00403530895, "predict": 5.18484650555, "homogen": 26.4159733777, "match": 21.40584269664, "written": 1.9573418813999999, "are": 19.56821277982, "better": 2.0065722952500002, "feedback": 98.60869565200001, "option": 4.04896710023, "varianc": 102.7572815534, "chanc": 4.2449197861000005, "favorit": 8.116564417180001, "samuli": 3175.2, "posit": 4.11757586238, "efficaci": 37.8902147971, "dispers": 11.1567111736, "cybersecur": 441.0, "even": 2.32922535212, "faster": 7.61438848921, "proper": 6.677602523659999, "side": 1.5989525632, "ian": 23.415929203530002, "deviat": 38.3015681544, "binari": 32.4, "comment": 3.05954904606, "invent": 4.604408352669999, "shift": 3.3317943336799996, "goodfellow": 2164.909090908, "rapid": 2.62586834271, "kingma": 1587.6, "requir": 6.11379609128, "figur": 12.2060481804, "wwwcstorontoedu": 1587.6, "let": 3.48616600791, "axi": 24.219679633800002, "relationship": 7.17397198374, "interpret": 3.2150668286799995, "world": 2.22680412372, "conclus": 4.84615384615, "matt": 22.744985673400002, "base": 2.2925631769, "fact": 1.73375559681, "who": 1.06279287723, "pictur": 3.4953764861300005, "permiss": 6.280063291139999, "sebastian": 26.8175675676, "were": 1.02458857696, "averag": 2.60390355913, "describ": 1.47027227264, "onlin": 2.6051854282900004, "yoshua": 1587.6, "much": 5.97111478865, "fundament": 5.32930513595, "evalu": 6.9509632224199995, "intellig": 12.580031695710002, "problem": 7.06699310036, "articl": 2.01805008262, "job": 6.507890961259999, "adain": 4762.799999999999, "outsmart": 547.448275862, "fake": 128.0322580642, "adam": 8.86184761374, "adapt": 13.29091670156, "tini": 25.856677524400002, "flatter": 47.25, "realism": 24.4246153846, "decemb": 1.48166122259, "classifi": 15.8812937646, "spectacular": 16.4859813084, "dynam": 6.52527743527, "where": 2.13430127042, "faruk": 1134.0, "them": 5.4938057997000005, "leon": 12.5402843602, "whi": 3.2566153846200003, "latent": 464.98744769890004, "standard": 9.457881567950002, "until": 2.29704116328, "target": 3.2189781021900004, "analysi": 10.43558282208, "coverag": 8.26444560125, "provid": 1.21552714187, "parenthes": 75.2417061611, "calcul": 18.38918918919, "xun": 226.8, "adversari": 263.28358209, "team": 2.2748244734200003, "jordon": 1587.6, "there": 4.16365066876, "regular": 2.09418282548, "inform": 26.78031355434, "isola": 882.0, "gati": 1587.6, "best": 1.5828514456600002, "illustr": 3.6614391143900002, "stabil": 12.1237113402, "setup": 34.1419354839, "now": 1.160780873, "tri": 7.417825020439999, "interact": 4.4185917061, "desir": 3.00170164492, "high": 4.5910931174, "geoffrey": 15.236084453, "basic": 2.7301805675, "cycleconsist": 1587.6, "realli": 4.7476076555, "communiti": 1.96121062384, "leverag": 35.7567567568, "mesched": 1587.6, "lar": 56.9032258065, "coupl": 3.2572835453400004, "mani": 4.17707031508, "pattern": 3.79173632673, "style": 38.04913121632, "stylebas": 1587.6, "revers": 4.29894394801, "mehdi": 233.470588235, "exampl": 4.51450236966, "stochast": 128.032258065, "research": 9.710091743100001, "technolog": 2.6034765496900003, "therefor": 2.33401940606, "the": 245.0, "mismatch": 206.181818182, "becom": 3.37476085878, "aila": 3175.2, "past": 4.03404904078, "peopl": 7.279229711160001, "emul": 19.3138686131, "those": 1.19548192771, "andrea": 13.627467811199999, "satisfi": 7.680696661830001, "receiv": 6.527423731600001, "vertic": 8.974561899380001, "tail": 25.041009463800002, "act": 1.4318181818200002, "essenti": 8.784212467710002, "win": 5.50580891278, "crucial": 7.7443902439, "uniform": 5.7231434751300005, "wasserstein": 4961.25, "serg": 58.1538461538, "term": 2.79040337464, "thus": 1.6463756092500001, "flatten": 84.67200000000001, "other": 15.1488549618, "uniqu": 3.01595744681, "procedur": 5.8691312384500005, "might": 6.468559011270001, "recreat": 6.536023054759999, "lot": 4.40877534018, "breakthrough": 16.434782608699997, "divers": 3.97197898424, "imag": 45.92343032157, "chen": 34.0686695279, "maintain": 1.77306231852, "phillip": 10.431011826499999, "implement": 7.15296237892, "examin": 3.8505942275, "push": 3.75141776938, "collect": 3.28219971056, "dilemma": 27.9507042254, "insid": 2.7396031061299997, "broad": 4.27693965517, "part": 1.04330682789, "append": 55.125, "analyt": 51.769565217300006, "element": 2.36004162331, "includ": 2.0381282495599997, "structur": 4.1161524500999995, "david": 1.84970290108, "consum": 4.93043478261, "neither": 3.6622837370199997, "access": 1.8734953976900002, "typic": 6.762459179339999, "rang": 7.139291736919999, "abl": 5.46255304506, "variat": 9.408, "result": 10.31504475888, "chang": 11.808985421, "differ": 7.4192694134999995, "been": 1.0239277652399998, "statist": 8.48530197756, "valuabl": 7.46754468485, "bethg": 1587.6, "between": 5.1726834354, "steep": 33.109489051, "return": 11.16259448056, "zaremba": 1587.6, "copi": 3.8375634517800004, "van": 3.99295774648, "program": 2.02139037433, "vincent": 11.1802816901, "feasibl": 17.8181818182, "downhil": 81.83505154640001, "day": 1.18371607516, "nowozin": 1587.6, "radford": 157.188118812, "indirect": 8.618892508139998, "call": 8.5412239408, "more": 9.154536135299999, "improv": 12.26261585994, "histogram": 1058.4, "produc": 6.8466448163, "these": 10.741542625200001, "artifici": 8.31639601886, "could": 8.4305871643, "stylegan": 19051.199999999997, "lead": 1.2664326739, "pharmaceut": 24.767550701999998, "languag": 2.29488291414, "make": 4.305064063440001, "set": 21.36742934058, "way": 6.0953697305, "timo": 622.588235294, "distinguish": 3.36926994907, "bring": 2.03616775683, "rise": 2.02940048575, "penalti": 49.76802507835, "common": 1.4025974025999999, "oper": 1.55479384977, "mirza": 112.595744681, "repres": 1.46972782818, "bio": 42.336000000000006, "subtract": 45.4899713467, "come": 6.64156626505, "reflect": 2.3443591258099996, "variabl": 8.747107438019999, "fewer": 5.94829524166, "popul": 4.35615310742, "learn": 60.3915142649, "send": 11.25159461376, "understand": 2.96858638743, "gentl": 17.1447084233, "manufactur": 6.7157360405999995, "first": 3.0228484386899996, "everi": 1.47917637194, "der": 7.122476446839999, "input": 73.2175249806, "while": 3.1325966850899993, "properti": 2.5949656750599996, "easili": 3.6938110749199997, "aaron": 33.3179433368, "answer": 4.64890190337, "numetijmencscnumslideslectureslideslecnumpdf": 1587.6, "when": 6.124606185299999, "courvill": 3175.2}, "logtfidf": {"hand": 0.958942670672, "rprop": 7.369978720910001, "strike": 1.27033264096, "realist": 10.24420678964, "slight": 1.17966331506, "huang": 4.20450367277, "real": 7.421661545166, "els": 1.6945957207700002, "wide": 0.44458000675399995, "new": 0.1063796811066, "extra": 1.67490068688, "addit": 0.220218882972, "would": 0.23885288389409998, "nois": 2.45879550578, "instanc": 7.085361478319999, "specif": 0.626980167541, "vari": 0.915094672432, "progress": 1.789708436216, "thought": 0.685867118283, "further": 0.308815895297, "never": 0.886410872182, "creation": 5.59230134235, "complet": 0.6458557261410001, "path": 1.5351679838499999, "toward": 0.48877277716000006, "their": 0.061442020490800005, "bing": 3.87347115944, "scale": 1.32095306328, "creat": 2.448345003654, "ahm": 3.4129823498400005, "extend": 0.673191417311, "instruct": 1.42770441799, "news": 1.46649014697, "laboratori": 2.03292152604, "jame": 0.658238325853, "hinton": 5.02817291476, "ecker": 7.18765716411, "end": 0.50738399309, "correl": 2.57915918803, "word": 3.51516649431, "deep": 2.5773469396, "will": 0.81114613966, "consid": 0.214894723824, "incorpor": 0.9664045229739999, "unlimit": 3.0458460646499996, "portion": 2.3890546753799997, "pougetabadi": 7.369978720910001, "next": 0.402163685499, "near": 0.252854324034, "but": 0.1457313486471, "mixtur": 2.20006306917, "certain": 0.592104362781, "obtain": 0.988162703503, "our": 4.288196070910001, "classif": 4.17558147258, "longer": 0.7046772417749999, "radiolog": 4.584967478669999, "domin": 0.841874615142, "grow": 0.821043542212, "success": 0.8329632377759999, "enough": 2.408653317507, "stop": 2.335738124889, "advantag": 2.40241031766, "resourc": 1.08137694258, "arjovski": 14.739957441820001, "out": 0.2921319545965, "model": 2.2123502193330005, "format": 0.9287132518729999, "good": 1.674357619628, "alway": 4.3579152274320005, "concept": 1.954448874206, "number": 0.3864343136744, "dumoulin": 7.369978720910001, "categori": 1.38176946652, "optim": 19.565022363279997, "field": 0.5760642583510001, "loss": 2.657863076526, "involv": 0.371469078658, "arbitrari": 2.88021938643, "length": 1.3059609811200001, "determin": 1.545666038044, "down": 0.306673741186, "schaar": 7.369978720910001, "logist": 2.6461370052, "soumith": 7.369978720910001, "then": 0.4982031913853999, "separ": 0.470759772949, "they": 0.297269947676, "anoth": 0.255792723304, "effect": 0.667660454316, "allow": 0.24028061118900002, "higherresolut": 7.369978720910001, "opposit": 0.90274594185, "major": 0.138474663439, "construct": 0.658603355972, "featur": 1.2701622544259998, "practic": 0.533182530867, "respons": 0.40991566230300003, "simpl": 2.4464425787799997, "appear": 0.278735898493, "jean": 1.7989660242200003, "cheung": 5.46787119451, "either": 0.459327638815, "develop": 0.357249389826, "moreov": 2.02287119019, "such": 0.238783911224, "futurist": 3.85248088355, "math": 3.09470245618, "without": 0.517749035882, "fast": 3.1673900494800002, "should": 0.509419876758, "add": 4.58626751139, "varieti": 1.6633883796239999, "content": 3.79421747862, "belongi": 7.369978720910001, "ani": 0.753650150196, "two": 0.1095907548656, "limit": 0.41782385463, "whether": 2.3746835689409997, "detail": 0.816187777173, "stun": 3.0726933146900004, "aren": 6.17605625244, "idea": 0.73863592212, "environ": 1.2341974030299998, "curv": 7.223500907909999, "equat": 2.27930071914, "for": 0.009764702257307002, "car": 1.2634013667, "slide": 2.7150664430299996, "output": 14.267586047890001, "releas": 0.608521699544, "seen": 0.47672812813, "with": 0.02275234255441, "characterist": 1.30085892924, "sens": 1.04257779501, "look": 2.5855467744, "veri": 2.7619175188560003, "formal": 0.894546004205, "progan": 51.58985104637001, "think": 1.06717661175, "work": 0.545172836365, "negat": 1.32402598852, "combin": 2.116873243004, "promis": 2.50729038352, "focus": 0.6981989720559999, "educ": 0.696807183384, "iter": 14.49132143468, "sigmoid": 55.716108902399995, "decod": 11.83714819896, "group": 0.190594534797, "drastic": 2.64347624975, "park": 0.9015038985299999, "give": 1.5569627611199999, "decim": 3.30953571036, "extract": 6.124851699030001, "place": 0.0957070839572, "simul": 2.44055348224, "normal": 4.798196893915, "goal": 1.18830712273, "jimmi": 2.2224842441, "stick": 2.4456277954099996, "continu": 0.26080974797400003, "fals": 1.8271477773099998, "probabl": 0.972882412913, "scientist": 1.54634128444, "machin": 6.9617979031, "into": 0.1342157690583, "paper": 0.979402539665, "medic": 1.18644857806, "wardefarley": 7.369978720910001, "servic": 0.41410016674500005, "face": 0.589602371257, "what": 0.903549187308, "ozair": 7.369978720910001, "translat": 1.0499301100299998, "flexibl": 2.2707222351599996, "help": 1.68103860672, "cover": 0.526975319156, "dazzl": 4.34468764511, "ishaan": 7.369978720910001, "own": 0.164195077421, "occur": 1.113947556946, "multipl": 2.02184803624, "quantit": 3.3251746042500003, "paramet": 2.8481901438599997, "surpris": 1.47392435861, "about": 0.18853043242380002, "norm": 2.4247712321400003, "neural": 126.6447698205, "thing": 0.8781935346799999, "just": 0.868594302327, "entir": 0.46603068026999994, "grant": 0.8105051365070001, "repost": 6.83935046985, "refin": 4.59837900798, "credibl": 2.75090562975, "artist": 1.05317511017, "render": 1.7879873033099998, "alec": 3.7115584742800003, "train": 14.540202882458, "complex": 0.8502416364309999, "tool": 1.60887117963, "start": 0.709330107873, "geiger": 4.927631685540001, "run": 0.442714975539, "keep": 0.7141523446729999, "taesung": 7.369978720910001, "anyth": 3.0470798917, "lose": 1.1265888210600001, "cyclegan": 7.369978720910001, "usual": 0.545279017064, "play": 0.7622087812839999, "critic": 1.5386560701870002, "appli": 0.8316941898119999, "over": 0.0498734429914, "centuri": 0.402823098645, "alexand": 1.43376264803, "generat": 30.924840694648, "build": 0.982274904182, "depict": 1.38957512116, "innov": 6.22458696444, "hundr": 0.904145087046, "consist": 1.196619379278, "framework": 2.10418454607, "bottou": 7.369978720910001, "matthia": 4.06309201872, "assess": 3.3138123987, "say": 0.562154280552, "origin": 0.771674625522, "mindblow": 7.369978720910001, "knowledg": 2.4464425787799997, "take": 0.130691962197, "martin": 2.24851925492, "than": 0.0322608622182, "publish": 0.313975865467, "also": 0.073285789, "trick": 2.6897010624299997, "mean": 2.22552770112, "treatment": 2.7071553770200003, "task": 1.35748680661, "batch": 3.5744895317400003, "squash": 3.8290193968699997, "overwhelm": 1.92626315167, "wednesday": 2.78807716186, "bengio": 7.369978720910001, "challeng": 0.9392919688950001, "hospit": 7.453419333059999, "want": 4.149819637529999, "enhanc": 1.6408534385799998, "convert": 3.5581081104, "webbas": 7.369978720910001, "system": 0.327430345585, "targetspecif": 7.369978720910001, "genuin": 4.88110696448, "behind": 0.7345572374320001, "howev": 0.0903151173475, "elimin": 1.30201620283, "actual": 0.628514181648, "ordinari": 1.93451151621, "maxim": 2.5594217052, "arxivorgabsnum": 88.43974465092, "which": 0.056962552299730004, "like": 0.973375035815, "zhu": 4.52506933709, "skill": 2.6161114203, "estim": 0.854377535975, "raw": 2.36536149914, "refer": 0.787659740394, "techniqu": 5.26497539228, "one": 0.087574923037, "show": 0.710048298039, "terminolog": 5.74701590368, "begin": 0.285584668268, "drawback": 3.91051243112, "see": 1.20460792746, "algorithm": 3.33044239518, "becaus": 1.254088429425, "outlier": 5.59502637, "moment": 1.4497416830899998, "get": 2.319076023128, "random": 3.9454428130199997, "through": 0.2734347675396, "imagin": 3.77368583474, "wojciech": 5.34183047362, "detect": 5.0663482347899995, "transform": 7.3779793624200005, "jaakko": 6.7821920560099995, "recent": 0.434413741288, "sign": 0.565696850403, "repeat": 1.0567930591299999, "tim": 2.10625279913, "this": 0.143885063995, "imagetoimag": 7.369978720910001, "sampl": 11.87175893034, "indistinguish": 8.06131348592, "lehtinen": 7.369978720910001, "process": 3.694804393175, "bit": 2.12032652634, "fool": 5.938751401319999, "karra": 14.215228912879999, "somewhat": 2.9134920441400003, "most": 0.06224368888679999, "forev": 2.48793466119, "low": 0.7564602833490001, "heavili": 1.17598157639, "domain": 8.96032002396, "excel": 1.5778801652, "midnum": 7.369978720910001, "top": 0.609100637788, "augment": 2.8045894049299998, "situat": 0.725668290015, "gradient": 37.3502760882, "condit": 1.309675576412, "appropri": 1.4618957827399999, "correct": 1.29831763181, "sherjil": 7.369978720910001, "author": 0.35274143130999996, "weight": 3.16984705224, "architectur": 4.90409273757, "gan": 106.17531419665, "cycl": 1.68810108164, "and": 0.004094359234134, "l\u00e9on": 7.369978720910001, "overfit": 7.369978720910001, "discuss": 0.78698452262, "general": 0.114952578063, "made": 0.1360430521946, "realtim": 12.123291802519999, "type": 1.414202970774, "simultan": 1.67322086119, "can": 4.220868506244, "hergott": 14.739957441820001, "encod": 6.73623002296, "analog": 2.20290964097, "onli": 0.10129707331639999, "each": 1.73741689304, "befor": 0.0956377718795, "data": 45.0223616376, "junyan": 7.369978720910001, "qualiti": 1.07600506711, "richer": 3.85545265394, "method": 3.777846435364, "sinc": 0.1607363989154, "convolut": 4.61631800855, "must": 0.653383947388, "time": 0.056057594313, "miabella": 14.739957441820001, "direct": 1.2042341369760001, "has": 0.2990676139836, "game": 3.7908250320840002, "gulrajani": 7.369978720910001, "busi": 0.720476170355, "use": 0.5549523749004001, "household": 1.67759429121, "year": 0.09480447778920001, "often": 0.7744211800529999, "radialgan": 66.32980848819001, "flat": 1.7366187105500002, "after": 0.020490694648099998, "chintala": 7.369978720910001, "onc": 1.211297617065, "too": 1.7896654641659997, "relat": 0.21310030165399999, "form": 0.120053184191, "signal": 1.6340517929299998, "immedi": 0.707357011133, "assign": 1.3445959556, "space": 6.997705319776, "transport": 0.986472086025, "dataset": 5.26584456664, "function": 9.14465741594, "onto": 2.9974127182599997, "rmsprop": 7.369978720910001, "lain": 9.51981785634, "hear": 1.43007066072, "well": 0.0635144383156, "done": 1.691951966258, "nonstationari": 7.369978720910001, "approach": 0.7302336145810001, "pace": 2.33432566384, "hold": 0.503879117196, "know": 0.952919694398, "unpair": 6.117215752409999, "momentum": 5.64699506254, "minibatch": 7.369978720910001, "measur": 1.760028399452, "instead": 0.46663315041500003, "least": 1.440856754235, "humankind": 4.30192578578, "express": 0.648191639641, "vicki": 4.26988643203, "sharpen": 4.29266646036, "how": 4.715669569300001, "reaction": 1.54309404912, "discrimin": 92.43262821702, "increas": 0.555641437858, "distribut": 4.03125223252, "converg": 2.7275127501800003, "sure": 2.0086865552, "sharp": 1.94944372164, "simplest": 6.6679394713999995, "overview": 2.54006626224, "numxnum": 7.9045040746, "wherea": 1.4203783778999999, "alter": 2.97442718144, "purpos": 0.803869037322, "yoon": 6.009002167769999, "need": 1.088220490326, "learningai": 7.369978720910001, "all": 0.04561052839119999, "confirm": 1.12581182025, "tero": 14.739957441820001, "amaz": 2.7246267452900006, "applic": 1.23160392849, "review": 0.7929522039210001, "have": 0.07392501170600001, "long": 0.235645793878, "tensorflow": 7.369978720910001, "mihaela": 7.369978720910001, "experi": 0.626272953933, "famous": 0.825060187979, "sound": 1.13556799519, "quit": 1.05951513684, "excit": 2.28423595433, "layer": 23.066770785850004, "numer": 1.818281437038, "astronomi": 3.1940541716900004, "global": 1.1957760371200001, "alexei": 4.29266646036, "entertain": 1.3931203261899998, "not": 0.0155524130075, "far": 1.073247529006, "respect": 0.49733261904, "jinsung": 7.369978720910001, "saliman": 7.369978720910001, "shown": 2.03713916198, "complic": 1.7312682430000002, "design": 1.508956472088, "core": 1.53108277245, "bolster": 6.220239440419999, "turn": 0.649798502128, "case": 0.395406268889, "tell": 2.42472868802, "welltrain": 7.369978720910001, "scienc": 1.682872357782, "outcom": 2.01339244624, "pixel": 4.45762805629, "thrive": 2.5766705928099998, "larger": 0.806828661778, "pioneer": 1.55614674111, "that": 0.15506978680595998, "whose": 0.5510546556329999, "mine": 3.16861817356, "valu": 7.408739791332, "softwar": 2.32849096333, "observ": 1.5990320298640002, "sever": 0.06991112039689999, "horizont": 2.4521899771799998, "transfer": 13.03444396111, "network": 32.404823803768, "numxnumpixel": 7.369978720910001, "some": 0.2770145634515, "sourc": 1.587654932253, "both": 0.2542126669465, "stabl": 3.80468121948, "dropout": 5.1186869223, "judgment": 2.3898026343, "classic": 1.7582069056999998, "introduc": 0.5457137524260001, "media": 3.8123322122079997, "question": 1.580621858028, "diederik": 7.369978720910001, "divid": 0.8402679544589999, "from": 0.009639920870722, "efro": 7.369978720910001, "abnorm": 3.3978017926599997, "ultrarealist": 7.369978720910001, "num": 0.016694490956041003, "multipli": 3.01583728972, "movi": 1.3873026798299999, "predict": 1.6457402376899999, "homogen": 3.2739688793700004, "match": 7.63142663244, "written": 0.671587369833, "are": 0.5598819980713, "better": 0.6964279406, "feedback": 12.819460351199998, "option": 1.39846181161, "varianc": 7.878445074019999, "chanc": 1.44572292349, "favorit": 2.09390696331, "samuli": 14.739957441820001, "posit": 0.9499569558240001, "efficaci": 3.63469289398, "dispers": 2.4120412158099995, "cybersecur": 6.08904487545, "even": 0.304777129668, "faster": 2.03003967967, "proper": 2.4112236778400002, "side": 0.46934876686899996, "ian": 6.16441271187, "deviat": 5.9046873175400005, "binari": 3.4781584227999995, "comment": 1.11826753454, "invent": 1.52701418212, "shift": 1.20351099781, "goodfellow": 19.74456408162, "rapid": 0.965411638564, "kingma": 7.369978720910001, "requir": 1.6970140427, "figur": 4.261032672960001, "wwwcstorontoedu": 7.369978720910001, "let": 1.2488025672799998, "axi": 4.988036660280001, "relationship": 2.615541555552, "interpret": 1.1678481440000001, "world": 0.214840497242, "conclus": 1.57818536893, "matt": 4.86239506116, "base": 0.27304660457400004, "fact": 0.5502899207949999, "who": 0.0609002329859, "pictur": 1.25144109124, "permiss": 1.8373800586400002, "sebastian": 3.2890571790200003, "were": 0.024291143681099997, "averag": 0.957011687995, "describ": 0.385447603125, "onlin": 0.957503854357, "yoshua": 7.369978720910001, "much": 0.8874786465050001, "fundament": 1.67322086119, "evalu": 1.9388802431299998, "intellig": 4.30049544639, "problem": 2.276562897092, "articl": 0.702131739574, "job": 2.3597365081799997, "adain": 22.10993616273, "outsmart": 6.305267983919999, "fake": 20.34460469468, "adam": 2.9772161932, "adapt": 4.803145944080001, "tini": 5.1188434104, "flatter": 3.85545265394, "realism": 3.1955914510100003, "decemb": 0.393163905995, "classifi": 4.99958890545, "spectacular": 2.8025104021, "dynam": 1.8756834711200001, "where": 0.1299842774914, "faruk": 7.033506484289999, "them": 0.47091663454649996, "leon": 2.5289462112, "whi": 1.18068843047, "latent": 29.37270183379, "standard": 3.1870525491, "until": 0.276949326878, "target": 1.1690639496200002, "analysi": 3.7398273087600007, "coverag": 2.1119626511300003, "provid": 0.19517784432500002, "parenthes": 4.320705680430001, "calcul": 5.439451977629999, "xun": 5.4240685718499995, "adversari": 32.7064661718, "team": 0.821902894886, "jordon": 7.369978720910001, "there": 0.160391571702, "regular": 0.739163417847, "inform": 7.725712979254, "isola": 6.7821920560099995, "gati": 7.369978720910001, "best": 0.459227932947, "illustr": 1.2978562707799999, "stabil": 3.6040319388, "setup": 3.5305264083199996, "now": 0.149092945021, "tri": 2.47036611664, "interact": 1.4858210267899998, "desir": 1.0991793428399999, "high": 0.5512951461600001, "geoffrey": 2.7236665915900002, "basic": 1.00436774895, "cycleconsist": 7.369978720910001, "realli": 1.5576408397, "communiti": 0.673561947791, "leverag": 3.5767392514699994, "mesched": 7.369978720910001, "lar": 4.04135203208, "coupl": 1.18089357972, "mani": 0.1732630324884, "pattern": 1.33282404788, "style": 13.860632465936, "stylebas": 7.369978720910001, "revers": 1.45836939905, "mehdi": 5.45305610873, "exampl": 1.2260480249969998, "stochast": 4.8522822483, "research": 3.3186390906899996, "technolog": 0.956847686355, "therefor": 0.847591848336, "the": 0.0, "mismatch": 9.27122242298, "becom": 0.353136529467, "aila": 14.739957441820001, "past": 1.4032468315220001, "peopl": 1.159593470838, "emul": 2.96082341885, "those": 0.17854939087299998, "andrea": 2.6120874479, "satisfi": 2.03871025422, "receiv": 1.3328721246100002, "vertic": 2.19439411974, "tail": 5.054735357819999, "act": 0.358945092473, "essenti": 3.2230313515200004, "win": 2.02531304058, "crucial": 2.04696874177, "uniform": 1.74451821303, "wasserstein": 34.4998754583, "serg": 4.06309201872, "term": 0.6660779670920001, "thus": 0.49857627139300004, "flatten": 7.4912755758600005, "other": 0.1481212187964, "uniqu": 1.1039173409, "procedur": 1.76970662262, "might": 2.3050232296020003, "recreat": 1.8773288849, "lot": 1.4835969502500002, "breakthrough": 2.7993999796900004, "divers": 1.37926445519, "imag": 16.89395582393, "chen": 3.5283781797800002, "maintain": 0.572708175102, "phillip": 2.3447832754799998, "implement": 2.54875881814, "examin": 1.3482274812000001, "push": 1.32213384036, "collect": 0.99073332104, "dilemma": 3.33044239518, "insid": 1.00781305813, "broad": 1.45323772, "part": 0.04239531098280001, "append": 4.0096033337699994, "analyt": 8.544570431579999, "element": 0.8586792558769999, "includ": 0.037769362781, "structur": 1.4435433502700001, "david": 0.615025032185, "consum": 1.5954271753600002, "neither": 1.29808692469, "access": 0.627805882716, "typic": 2.438322957474, "rang": 2.317276855212, "abl": 1.7979119474250003, "variat": 3.0968264212, "result": 1.227410175429, "chang": 1.66275625058, "differ": 1.2739267278720001, "been": 0.023645982368400004, "statist": 2.8903766141400005, "valuabl": 2.010566255, "bethg": 7.369978720910001, "between": 0.1697684058265, "steep": 5.61334547804, "return": 2.665014948736, "zaremba": 7.369978720910001, "copi": 1.34483764744, "van": 1.38453224613, "program": 0.7037855787649999, "vincent": 2.4141516633099998, "feasibl": 2.88021938643, "downhil": 4.40470565484, "day": 0.16865870631700003, "nowozin": 7.369978720910001, "radford": 5.05744329706, "indirect": 2.15395659709, "call": 0.5237021955904, "more": 0.15322438439999997, "improv": 4.288774823592, "histogram": 6.964513612799999, "produc": 1.5716040600149999, "these": 0.715336194008, "artifici": 2.11822899018, "could": 1.3016939060300001, "stylegan": 88.43974465092, "lead": 0.23620402986699998, "pharmaceut": 3.2095343569800003, "languag": 0.8306818244059999, "make": 0.29399063129159997, "set": 3.086928203202, "way": 0.9904575496750001, "timo": 11.48147636236, "distinguish": 1.21469608857, "bring": 0.7110694905930001, "rise": 0.707740422218, "penalti": 11.4896739934, "common": 0.338325805271, "oper": 0.441342964347, "mirza": 4.72380392352, "repres": 0.38507723275, "bio": 3.7456377879300002, "subtract": 3.8174918917, "come": 1.41954953265, "reflect": 0.85201207065, "variabl": 2.1687230672, "fewer": 1.7831046645, "popul": 1.556884345042, "learn": 21.91155368337, "send": 3.96569272014, "understand": 1.0880858756799998, "gentl": 2.84168957926, "manufactur": 2.42261250964, "first": 0.02276186943648, "everi": 0.391485427421, "der": 1.9632554805200002, "input": 15.01005201234, "while": 0.12974995138140002, "properti": 0.953573289192, "easili": 1.3066587367, "aaron": 5.6258978205, "answer": 1.5366310419, "numetijmencscnumslideslectureslideslecnumpdf": 7.369978720910001, "when": 0.1233299331504, "courvill": 14.739957441820001}, "logidf": {"hand": 0.479471335336, "rprop": 7.369978720910001, "strike": 1.27033264096, "realist": 2.56105169741, "slight": 1.17966331506, "huang": 4.20450367277, "real": 0.824629060574, "els": 1.6945957207700002, "wide": 0.44458000675399995, "new": 0.0177299468511, "extra": 1.67490068688, "addit": 0.220218882972, "would": 0.0796176279647, "nois": 2.45879550578, "instanc": 1.18089357972, "specif": 0.626980167541, "vari": 0.915094672432, "progress": 0.894854218108, "thought": 0.685867118283, "further": 0.308815895297, "never": 0.443205436091, "creation": 1.11846026847, "complet": 0.215285242047, "path": 1.5351679838499999, "toward": 0.48877277716000006, "their": 0.015360505122700001, "bing": 3.87347115944, "scale": 1.32095306328, "creat": 0.222576818514, "ahm": 3.4129823498400005, "extend": 0.673191417311, "instruct": 1.42770441799, "news": 0.733245073485, "laboratori": 2.03292152604, "jame": 0.658238325853, "hinton": 5.02817291476, "ecker": 7.18765716411, "end": 0.101476798618, "correl": 2.57915918803, "word": 0.585861082385, "deep": 1.2886734698, "will": 0.202786534915, "consid": 0.214894723824, "incorpor": 0.9664045229739999, "unlimit": 3.0458460646499996, "portion": 1.1945273376899999, "pougetabadi": 7.369978720910001, "next": 0.402163685499, "near": 0.252854324034, "but": 0.0161923720719, "mixtur": 2.20006306917, "certain": 0.592104362781, "obtain": 0.988162703503, "our": 0.8576392141820001, "classif": 2.08779073629, "longer": 0.7046772417749999, "radiolog": 4.584967478669999, "domin": 0.841874615142, "grow": 0.821043542212, "success": 0.27765441259199997, "enough": 0.802884439169, "stop": 0.778579374963, "advantag": 1.20120515883, "resourc": 1.08137694258, "arjovski": 7.369978720910001, "out": 0.0584263909193, "model": 0.7374500731110001, "format": 0.9287132518729999, "good": 0.418589404907, "alway": 0.726319204572, "concept": 0.977224437103, "number": 0.0966085784186, "dumoulin": 7.369978720910001, "categori": 1.38176946652, "optim": 2.4456277954099996, "field": 0.5760642583510001, "loss": 0.885954358842, "involv": 0.371469078658, "arbitrari": 2.88021938643, "length": 1.3059609811200001, "determin": 0.772833019022, "down": 0.306673741186, "schaar": 7.369978720910001, "logist": 2.6461370052, "soumith": 7.369978720910001, "then": 0.08303386523089999, "separ": 0.470759772949, "they": 0.0297269947676, "anoth": 0.127896361652, "effect": 0.333830227158, "allow": 0.24028061118900002, "higherresolut": 7.369978720910001, "opposit": 0.90274594185, "major": 0.138474663439, "construct": 0.658603355972, "featur": 0.423387418142, "practic": 0.533182530867, "respons": 0.40991566230300003, "simpl": 1.2232212893899999, "appear": 0.278735898493, "jean": 1.7989660242200003, "cheung": 5.46787119451, "either": 0.459327638815, "develop": 0.178624694913, "moreov": 2.02287119019, "such": 0.059695977806, "futurist": 3.85248088355, "math": 3.09470245618, "without": 0.258874517941, "fast": 1.5836950247400001, "should": 0.509419876758, "add": 1.52875583713, "varieti": 0.8316941898119999, "content": 1.26473915954, "belongi": 7.369978720910001, "ani": 0.125608358366, "two": 0.0136988443582, "limit": 0.41782385463, "whether": 0.791561189647, "detail": 0.816187777173, "stun": 3.0726933146900004, "aren": 6.17605625244, "idea": 0.73863592212, "environ": 1.2341974030299998, "curv": 2.40783363597, "equat": 2.27930071914, "for": 0.00031499039539700004, "car": 1.2634013667, "slide": 2.7150664430299996, "output": 2.03822657827, "releas": 0.608521699544, "seen": 0.47672812813, "with": 0.00119749171339, "characterist": 1.30085892924, "sens": 1.04257779501, "look": 0.6463866936, "veri": 0.230159793238, "formal": 0.894546004205, "progan": 7.369978720910001, "think": 1.06717661175, "work": 0.109034567273, "negat": 1.32402598852, "combin": 0.529218310751, "promis": 1.25364519176, "focus": 0.6981989720559999, "educ": 0.696807183384, "iter": 3.62283035867, "sigmoid": 6.964513612799999, "decod": 3.9457160663199997, "group": 0.190594534797, "drastic": 2.64347624975, "park": 0.9015038985299999, "give": 0.311392552224, "decim": 3.30953571036, "extract": 2.04161723301, "place": 0.0957070839572, "simul": 2.44055348224, "normal": 0.959639378783, "goal": 1.18830712273, "jimmi": 2.2224842441, "stick": 2.4456277954099996, "continu": 0.13040487398700001, "fals": 1.8271477773099998, "probabl": 0.972882412913, "scientist": 1.54634128444, "machin": 1.39235958062, "into": 0.0149128632287, "paper": 0.979402539665, "medic": 1.18644857806, "wardefarley": 7.369978720910001, "servic": 0.41410016674500005, "face": 0.589602371257, "what": 0.225887296827, "ozair": 7.369978720910001, "translat": 1.0499301100299998, "flexibl": 2.2707222351599996, "help": 0.336207721344, "cover": 0.526975319156, "dazzl": 4.34468764511, "ishaan": 7.369978720910001, "own": 0.164195077421, "occur": 0.556973778473, "multipl": 1.01092401812, "quantit": 3.3251746042500003, "paramet": 2.8481901438599997, "surpris": 1.47392435861, "about": 0.0628434774746, "norm": 2.4247712321400003, "neural": 4.0853151555, "thing": 0.8781935346799999, "just": 0.289531434109, "entir": 0.46603068026999994, "grant": 0.8105051365070001, "repost": 6.83935046985, "refin": 2.29918950399, "credibl": 2.75090562975, "artist": 1.05317511017, "render": 1.7879873033099998, "alec": 3.7115584742800003, "train": 0.660918312839, "complex": 0.8502416364309999, "tool": 1.60887117963, "start": 0.236443369291, "geiger": 4.927631685540001, "run": 0.442714975539, "keep": 0.7141523446729999, "taesung": 7.369978720910001, "anyth": 1.52353994585, "lose": 1.1265888210600001, "cyclegan": 7.369978720910001, "usual": 0.545279017064, "play": 0.38110439064199997, "critic": 0.512885356729, "appli": 0.8316941898119999, "over": 0.0249367214957, "centuri": 0.402823098645, "alexand": 1.43376264803, "generat": 0.719182341736, "build": 0.491137452091, "depict": 1.38957512116, "innov": 1.55614674111, "hundr": 0.904145087046, "consist": 0.398873126426, "framework": 2.10418454607, "bottou": 7.369978720910001, "matthia": 4.06309201872, "assess": 1.65690619935, "say": 0.562154280552, "origin": 0.128612437587, "mindblow": 7.369978720910001, "knowledg": 1.2232212893899999, "take": 0.130691962197, "martin": 1.12425962746, "than": 0.0322608622182, "publish": 0.313975865467, "also": 0.0146571578, "trick": 2.6897010624299997, "mean": 0.37092128352, "treatment": 1.3535776885100002, "task": 1.35748680661, "batch": 3.5744895317400003, "squash": 3.8290193968699997, "overwhelm": 1.92626315167, "wednesday": 2.78807716186, "bengio": 7.369978720910001, "challeng": 0.9392919688950001, "hospit": 1.24223655551, "want": 0.6916366062549999, "enhanc": 1.6408534385799998, "convert": 1.1860360368, "webbas": 7.369978720910001, "system": 0.327430345585, "targetspecif": 7.369978720910001, "genuin": 2.44055348224, "behind": 0.7345572374320001, "howev": 0.0903151173475, "elimin": 1.30201620283, "actual": 0.628514181648, "ordinari": 1.93451151621, "maxim": 2.5594217052, "arxivorgabsnum": 7.369978720910001, "which": 0.00517841384543, "like": 0.139053576545, "zhu": 4.52506933709, "skill": 1.30805571015, "estim": 0.854377535975, "raw": 2.36536149914, "refer": 0.262553246798, "techniqu": 1.31624384807, "one": 0.0062553516455, "show": 0.236682766013, "terminolog": 2.87350795184, "begin": 0.285584668268, "drawback": 3.91051243112, "see": 0.240921585492, "algorithm": 3.33044239518, "becaus": 0.139343158825, "outlier": 5.59502637, "moment": 1.4497416830899998, "get": 0.579769005782, "random": 1.9727214065099998, "through": 0.0683586918849, "imagin": 1.88684291737, "wojciech": 5.34183047362, "detect": 1.68878274493, "transform": 1.22966322707, "jaakko": 6.7821920560099995, "recent": 0.434413741288, "sign": 0.565696850403, "repeat": 1.0567930591299999, "tim": 2.10625279913, "this": 0.0037864490525, "imagetoimag": 7.369978720910001, "sampl": 1.9786264883900002, "indistinguish": 4.03065674296, "lehtinen": 7.369978720910001, "process": 0.527829199025, "bit": 2.12032652634, "fool": 2.9693757006599997, "karra": 7.1076144564399995, "somewhat": 1.4567460220700001, "most": 0.020747896295599998, "forev": 2.48793466119, "low": 0.7564602833490001, "heavili": 1.17598157639, "domain": 2.24008000599, "excel": 1.5778801652, "midnum": 7.369978720910001, "top": 0.609100637788, "augment": 2.8045894049299998, "situat": 0.725668290015, "gradient": 3.73502760882, "condit": 0.654837788206, "appropri": 1.4618957827399999, "correct": 1.29831763181, "sherjil": 7.369978720910001, "author": 0.35274143130999996, "weight": 1.58492352612, "architectur": 1.63469757919, "gan": 4.61631800855, "cycl": 1.68810108164, "and": 6.29901420636e-05, "l\u00e9on": 7.369978720910001, "overfit": 7.369978720910001, "discuss": 0.78698452262, "general": 0.114952578063, "made": 0.0680215260973, "realtim": 6.0616459012599995, "type": 0.707101485387, "simultan": 1.67322086119, "can": 0.162341096394, "hergott": 7.369978720910001, "encod": 3.36811501148, "analog": 2.20290964097, "onli": 0.025324268329099998, "each": 0.173741689304, "befor": 0.0956377718795, "data": 1.2168205848, "junyan": 7.369978720910001, "qualiti": 1.07600506711, "richer": 3.85545265394, "method": 0.944461608841, "sinc": 0.0803681994577, "convolut": 4.61631800855, "must": 0.653383947388, "time": 0.0112115188626, "miabella": 7.369978720910001, "direct": 0.200705689496, "has": 0.0427239448548, "game": 0.9477062580210001, "gulrajani": 7.369978720910001, "busi": 0.720476170355, "use": 0.0292080197316, "household": 1.67759429121, "year": 0.047402238894600005, "often": 0.258140393351, "radialgan": 7.369978720910001, "flat": 1.7366187105500002, "after": 0.020490694648099998, "chintala": 7.369978720910001, "onc": 0.403765872355, "too": 0.5965551547219999, "relat": 0.21310030165399999, "form": 0.120053184191, "signal": 1.6340517929299998, "immedi": 0.707357011133, "assign": 1.3445959556, "space": 0.874713164972, "transport": 0.986472086025, "dataset": 5.26584456664, "function": 0.914465741594, "onto": 1.4987063591299998, "rmsprop": 7.369978720910001, "lain": 4.75990892817, "hear": 1.43007066072, "well": 0.0635144383156, "done": 0.845975983129, "nonstationari": 7.369978720910001, "approach": 0.7302336145810001, "pace": 2.33432566384, "hold": 0.503879117196, "know": 0.952919694398, "unpair": 6.117215752409999, "momentum": 2.82349753127, "minibatch": 7.369978720910001, "measur": 0.880014199726, "instead": 0.46663315041500003, "least": 0.480285584745, "humankind": 4.30192578578, "express": 0.648191639641, "vicki": 4.26988643203, "sharpen": 4.29266646036, "how": 0.47156695693000006, "reaction": 1.54309404912, "discrimin": 2.37006739018, "increas": 0.277820718929, "distribut": 1.00781305813, "converg": 2.7275127501800003, "sure": 2.0086865552, "sharp": 1.94944372164, "simplest": 3.3339697356999998, "overview": 2.54006626224, "numxnum": 3.9522520373, "wherea": 1.4203783778999999, "alter": 1.48721359072, "purpos": 0.803869037322, "yoon": 6.009002167769999, "need": 0.362740163442, "learningai": 7.369978720910001, "all": 0.011402632097799998, "confirm": 1.12581182025, "tero": 7.369978720910001, "amaz": 2.7246267452900006, "applic": 1.23160392849, "review": 0.7929522039210001, "have": 0.0147850023412, "long": 0.235645793878, "tensorflow": 7.369978720910001, "mihaela": 7.369978720910001, "experi": 0.626272953933, "famous": 0.825060187979, "sound": 1.13556799519, "quit": 1.05951513684, "excit": 2.28423595433, "layer": 2.0969791623500003, "numer": 0.606093812346, "astronomi": 3.1940541716900004, "global": 1.1957760371200001, "alexei": 4.29266646036, "entertain": 1.3931203261899998, "not": 0.0155524130075, "far": 0.536623764503, "respect": 0.49733261904, "jinsung": 7.369978720910001, "saliman": 7.369978720910001, "shown": 1.01856958099, "complic": 1.7312682430000002, "design": 0.377239118022, "core": 1.53108277245, "bolster": 3.1101197202099997, "turn": 0.324899251064, "case": 0.395406268889, "tell": 1.21236434401, "welltrain": 7.369978720910001, "scienc": 0.841436178891, "outcom": 2.01339244624, "pixel": 4.45762805629, "thrive": 2.5766705928099998, "larger": 0.806828661778, "pioneer": 1.55614674111, "that": 0.00397614837964, "whose": 0.5510546556329999, "mine": 1.58430908678, "valu": 0.823193310148, "softwar": 2.32849096333, "observ": 0.7995160149320001, "sever": 0.06991112039689999, "horizont": 2.4521899771799998, "transfer": 1.00264953547, "network": 0.9530830530519999, "numxnumpixel": 7.369978720910001, "some": 0.0395735090645, "sourc": 0.529218310751, "both": 0.050842533389300004, "stabl": 1.90234060974, "dropout": 5.1186869223, "judgment": 2.3898026343, "classic": 0.8791034528499999, "introduc": 0.5457137524260001, "media": 0.9530830530519999, "question": 0.790310929014, "diederik": 7.369978720910001, "divid": 0.8402679544589999, "from": 0.000567054168866, "efro": 7.369978720910001, "abnorm": 3.3978017926599997, "ultrarealist": 7.369978720910001, "num": 0.00031499039539700004, "multipli": 3.01583728972, "movi": 1.3873026798299999, "predict": 1.6457402376899999, "homogen": 3.2739688793700004, "match": 1.27190443874, "written": 0.671587369833, "are": 0.0294674735827, "better": 0.6964279406, "feedback": 3.2048650877999996, "option": 1.39846181161, "varianc": 3.9392225370099996, "chanc": 1.44572292349, "favorit": 2.09390696331, "samuli": 7.369978720910001, "posit": 0.316652318608, "efficaci": 3.63469289398, "dispers": 2.4120412158099995, "cybersecur": 6.08904487545, "even": 0.152388564834, "faster": 2.03003967967, "proper": 1.2056118389200001, "side": 0.46934876686899996, "ian": 2.05480423729, "deviat": 2.9523436587700003, "binari": 3.4781584227999995, "comment": 1.11826753454, "invent": 1.52701418212, "shift": 1.20351099781, "goodfellow": 6.58152136054, "rapid": 0.965411638564, "kingma": 7.369978720910001, "requir": 0.424253510675, "figur": 0.7101721121600001, "wwwcstorontoedu": 7.369978720910001, "let": 1.2488025672799998, "axi": 2.4940183301400003, "relationship": 0.871847185184, "interpret": 1.1678481440000001, "world": 0.107420248621, "conclus": 1.57818536893, "matt": 2.43119753058, "base": 0.13652330228700002, "fact": 0.5502899207949999, "who": 0.0609002329859, "pictur": 1.25144109124, "permiss": 1.8373800586400002, "sebastian": 3.2890571790200003, "were": 0.024291143681099997, "averag": 0.957011687995, "describ": 0.385447603125, "onlin": 0.957503854357, "yoshua": 7.369978720910001, "much": 0.17749572930100002, "fundament": 1.67322086119, "evalu": 1.9388802431299998, "intellig": 1.43349848213, "problem": 0.569140724273, "articl": 0.702131739574, "job": 1.1798682540899998, "adain": 7.369978720910001, "outsmart": 6.305267983919999, "fake": 2.9063720992400004, "adam": 1.4886080966, "adapt": 1.2007864860200002, "tini": 2.5594217052, "flatter": 3.85545265394, "realism": 3.1955914510100003, "decemb": 0.393163905995, "classifi": 1.6665296351499999, "spectacular": 2.8025104021, "dynam": 1.8756834711200001, "where": 0.0649921387457, "faruk": 7.033506484289999, "them": 0.0941833269093, "leon": 2.5289462112, "whi": 1.18068843047, "latent": 4.19610026197, "standard": 0.63741050982, "until": 0.138474663439, "target": 1.1690639496200002, "analysi": 1.2466091029200002, "coverag": 2.1119626511300003, "provid": 0.19517784432500002, "parenthes": 4.320705680430001, "calcul": 1.8131506592099997, "xun": 5.4240685718499995, "adversari": 3.27064661718, "team": 0.821902894886, "jordon": 7.369978720910001, "there": 0.0400978929255, "regular": 0.739163417847, "inform": 0.454453704662, "isola": 6.7821920560099995, "gati": 7.369978720910001, "best": 0.459227932947, "illustr": 1.2978562707799999, "stabil": 1.8020159694, "setup": 3.5305264083199996, "now": 0.149092945021, "tri": 0.61759152916, "interact": 1.4858210267899998, "desir": 1.0991793428399999, "high": 0.13782378654000002, "geoffrey": 2.7236665915900002, "basic": 1.00436774895, "cycleconsist": 7.369978720910001, "realli": 1.5576408397, "communiti": 0.673561947791, "leverag": 3.5767392514699994, "mesched": 7.369978720910001, "lar": 4.04135203208, "coupl": 1.18089357972, "mani": 0.0433157581221, "pattern": 1.33282404788, "style": 0.866289529121, "stylebas": 7.369978720910001, "revers": 1.45836939905, "mehdi": 5.45305610873, "exampl": 0.40868267499899996, "stochast": 4.8522822483, "research": 0.663727818138, "technolog": 0.956847686355, "therefor": 0.847591848336, "the": 0.0, "mismatch": 4.63561121149, "becom": 0.11771217648900001, "aila": 7.369978720910001, "past": 0.7016234157610001, "peopl": 0.193265578473, "emul": 2.96082341885, "those": 0.17854939087299998, "andrea": 2.6120874479, "satisfi": 2.03871025422, "receiv": 0.266574424922, "vertic": 2.19439411974, "tail": 2.5273676789099997, "act": 0.358945092473, "essenti": 1.07434378384, "win": 1.01265652029, "crucial": 2.04696874177, "uniform": 1.74451821303, "wasserstein": 6.89997509166, "serg": 4.06309201872, "term": 0.33303898354600003, "thus": 0.49857627139300004, "flatten": 3.7456377879300002, "other": 0.00987474791976, "uniqu": 1.1039173409, "procedur": 1.76970662262, "might": 0.7683410765340001, "recreat": 1.8773288849, "lot": 1.4835969502500002, "breakthrough": 2.7993999796900004, "divers": 1.37926445519, "imag": 0.99376210729, "chen": 3.5283781797800002, "maintain": 0.572708175102, "phillip": 2.3447832754799998, "implement": 1.27437940907, "examin": 1.3482274812000001, "push": 1.32213384036, "collect": 0.49536666052, "dilemma": 3.33044239518, "insid": 1.00781305813, "broad": 1.45323772, "part": 0.04239531098280001, "append": 4.0096033337699994, "analyt": 2.8481901438599997, "element": 0.8586792558769999, "includ": 0.0188846813905, "structur": 0.7217716751350001, "david": 0.615025032185, "consum": 1.5954271753600002, "neither": 1.29808692469, "access": 0.627805882716, "typic": 0.812774319158, "rang": 0.579319213803, "abl": 0.599303982475, "variat": 1.5484132106, "result": 0.136378908381, "chang": 0.166275625058, "differ": 0.212321121312, "been": 0.023645982368400004, "statist": 1.4451883070700002, "valuabl": 2.010566255, "bethg": 7.369978720910001, "between": 0.033953681165299995, "steep": 2.80667273902, "return": 0.333126868592, "zaremba": 7.369978720910001, "copi": 1.34483764744, "van": 1.38453224613, "program": 0.7037855787649999, "vincent": 2.4141516633099998, "feasibl": 2.88021938643, "downhil": 4.40470565484, "day": 0.16865870631700003, "nowozin": 7.369978720910001, "radford": 5.05744329706, "indirect": 2.15395659709, "call": 0.0654627744488, "more": 0.017024931599999998, "improv": 0.7147958039319999, "histogram": 6.964513612799999, "produc": 0.314320812003, "these": 0.0715336194008, "artifici": 2.11822899018, "could": 0.18595627229000003, "stylegan": 7.369978720910001, "lead": 0.23620402986699998, "pharmaceut": 3.2095343569800003, "languag": 0.8306818244059999, "make": 0.07349765782289999, "set": 0.171496011289, "way": 0.19809150993500002, "timo": 5.74073818118, "distinguish": 1.21469608857, "bring": 0.7110694905930001, "rise": 0.707740422218, "penalti": 2.29793479868, "common": 0.338325805271, "oper": 0.441342964347, "mirza": 4.72380392352, "repres": 0.38507723275, "bio": 3.7456377879300002, "subtract": 3.8174918917, "come": 0.28390990653000003, "reflect": 0.85201207065, "variabl": 2.1687230672, "fewer": 1.7831046645, "popul": 0.778442172521, "learn": 0.842752064745, "send": 1.32189757338, "understand": 1.0880858756799998, "gentl": 2.84168957926, "manufactur": 1.21130625482, "first": 0.0075872898121599995, "everi": 0.391485427421, "der": 1.9632554805200002, "input": 2.50167533539, "while": 0.04324998379380001, "properti": 0.953573289192, "easili": 1.3066587367, "aaron": 2.81294891025, "answer": 1.5366310419, "numetijmencscnumslideslectureslideslecnumpdf": 7.369978720910001, "when": 0.0205549888584, "courvill": 7.369978720910001}, "freq": {"hand": 2, "rprop": 1, "strike": 1, "realist": 4, "slight": 1, "huang": 1, "real": 9, "els": 1, "wide": 1, "new": 6, "extra": 1, "addit": 1, "would": 3, "nois": 1, "instanc": 6, "specif": 1, "vari": 1, "progress": 2, "thought": 1, "further": 1, "never": 2, "creation": 5, "complet": 3, "path": 1, "toward": 1, "their": 4, "bing": 1, "scale": 1, "creat": 11, "ahm": 1, "extend": 1, "instruct": 1, "news": 2, "laboratori": 1, "jame": 1, "hinton": 1, "ecker": 1, "end": 5, "correl": 1, "word": 6, "deep": 2, "will": 4, "consid": 1, "incorpor": 1, "unlimit": 1, "portion": 2, "pougetabadi": 1, "next": 1, "near": 1, "but": 9, "mixtur": 1, "certain": 1, "obtain": 1, "our": 5, "classif": 2, "longer": 1, "radiolog": 1, "domin": 1, "grow": 1, "success": 3, "enough": 3, "stop": 3, "advantag": 2, "resourc": 1, "arjovski": 2, "out": 5, "model": 3, "format": 1, "good": 4, "alway": 6, "concept": 2, "number": 4, "dumoulin": 1, "categori": 1, "optim": 8, "field": 1, "loss": 3, "involv": 1, "arbitrari": 1, "length": 1, "determin": 2, "down": 1, "schaar": 1, "logist": 1, "soumith": 1, "then": 6, "separ": 1, "they": 10, "anoth": 2, "effect": 2, "allow": 1, "higherresolut": 1, "opposit": 1, "major": 1, "construct": 1, "featur": 3, "practic": 1, "respons": 1, "simpl": 2, "appear": 1, "jean": 1, "cheung": 1, "either": 1, "develop": 2, "moreov": 1, "such": 4, "futurist": 1, "math": 1, "without": 2, "fast": 2, "should": 1, "add": 3, "varieti": 2, "content": 3, "belongi": 1, "ani": 6, "two": 8, "limit": 1, "whether": 3, "detail": 1, "stun": 1, "aren": 1, "idea": 1, "environ": 1, "curv": 3, "equat": 1, "for": 31, "car": 1, "slide": 1, "output": 7, "releas": 1, "seen": 1, "with": 19, "characterist": 1, "sens": 1, "look": 4, "veri": 12, "formal": 1, "progan": 7, "think": 1, "work": 5, "negat": 1, "combin": 4, "promis": 2, "focus": 1, "educ": 1, "iter": 4, "sigmoid": 8, "decod": 3, "group": 1, "drastic": 1, "park": 1, "give": 5, "decim": 1, "extract": 3, "place": 1, "simul": 1, "normal": 5, "goal": 1, "jimmi": 1, "stick": 1, "continu": 2, "fals": 1, "probabl": 1, "scientist": 1, "machin": 5, "into": 9, "paper": 1, "medic": 1, "wardefarley": 1, "servic": 1, "face": 1, "what": 4, "ozair": 1, "translat": 1, "flexibl": 1, "help": 5, "cover": 1, "dazzl": 1, "ishaan": 1, "own": 1, "occur": 2, "multipl": 2, "quantit": 1, "paramet": 1, "surpris": 1, "about": 3, "norm": 1, "neural": 31, "thing": 1, "just": 3, "entir": 1, "grant": 1, "repost": 1, "refin": 2, "credibl": 1, "artist": 1, "render": 1, "alec": 1, "train": 22, "complex": 1, "tool": 1, "start": 3, "geiger": 1, "run": 1, "keep": 1, "taesung": 1, "anyth": 2, "lose": 1, "cyclegan": 1, "usual": 1, "play": 2, "critic": 3, "appli": 1, "over": 2, "centuri": 1, "alexand": 1, "generat": 43, "build": 2, "depict": 1, "innov": 4, "hundr": 1, "consist": 3, "framework": 1, "bottou": 1, "matthia": 1, "assess": 2, "say": 1, "origin": 6, "mindblow": 1, "knowledg": 2, "take": 1, "martin": 2, "than": 1, "publish": 1, "also": 5, "trick": 1, "mean": 6, "treatment": 2, "task": 1, "batch": 1, "squash": 1, "overwhelm": 1, "wednesday": 1, "bengio": 1, "challeng": 1, "hospit": 6, "want": 6, "enhanc": 1, "convert": 3, "webbas": 1, "system": 1, "targetspecif": 1, "genuin": 2, "behind": 1, "howev": 1, "elimin": 1, "actual": 1, "ordinari": 1, "maxim": 1, "arxivorgabsnum": 12, "which": 11, "like": 7, "zhu": 1, "skill": 2, "estim": 1, "raw": 1, "refer": 3, "techniqu": 4, "one": 14, "show": 3, "terminolog": 2, "begin": 1, "drawback": 1, "see": 5, "algorithm": 1, "becaus": 9, "outlier": 1, "moment": 1, "get": 4, "random": 2, "through": 4, "imagin": 2, "wojciech": 1, "detect": 3, "transform": 6, "jaakko": 1, "recent": 1, "sign": 1, "repeat": 1, "tim": 1, "this": 38, "imagetoimag": 1, "sampl": 6, "indistinguish": 2, "lehtinen": 1, "process": 7, "bit": 1, "fool": 2, "karra": 2, "somewhat": 2, "most": 3, "forev": 1, "low": 1, "heavili": 1, "domain": 4, "excel": 1, "midnum": 1, "top": 1, "augment": 1, "situat": 1, "gradient": 10, "condit": 2, "appropri": 1, "correct": 1, "sherjil": 1, "author": 1, "weight": 2, "architectur": 3, "gan": 23, "cycl": 1, "and": 65, "l\u00e9on": 1, "overfit": 1, "discuss": 1, "general": 1, "made": 2, "realtim": 2, "type": 2, "simultan": 1, "can": 26, "hergott": 2, "encod": 2, "analog": 1, "onli": 4, "each": 10, "befor": 1, "data": 37, "junyan": 1, "qualiti": 1, "richer": 1, "method": 4, "sinc": 2, "convolut": 1, "must": 1, "time": 5, "miabella": 2, "direct": 6, "has": 7, "game": 4, "gulrajani": 1, "busi": 1, "use": 19, "household": 1, "year": 2, "often": 3, "radialgan": 9, "flat": 1, "after": 1, "chintala": 1, "onc": 3, "too": 3, "relat": 1, "form": 1, "signal": 1, "immedi": 1, "assign": 1, "space": 8, "transport": 1, "dataset": 1, "function": 10, "onto": 2, "rmsprop": 1, "lain": 2, "hear": 1, "well": 1, "done": 2, "nonstationari": 1, "approach": 1, "pace": 1, "hold": 1, "know": 1, "unpair": 1, "momentum": 2, "minibatch": 1, "measur": 2, "instead": 1, "least": 3, "humankind": 1, "express": 1, "vicki": 1, "sharpen": 1, "how": 10, "reaction": 1, "discrimin": 39, "increas": 2, "distribut": 4, "converg": 1, "sure": 1, "sharp": 1, "simplest": 2, "overview": 1, "numxnum": 2, "wherea": 1, "alter": 2, "purpos": 1, "yoon": 1, "need": 3, "learningai": 1, "all": 4, "confirm": 1, "tero": 2, "amaz": 1, "applic": 1, "review": 1, "have": 5, "long": 1, "tensorflow": 1, "mihaela": 1, "experi": 1, "famous": 1, "sound": 1, "quit": 1, "excit": 1, "layer": 11, "numer": 3, "astronomi": 1, "global": 1, "alexei": 1, "entertain": 1, "not": 1, "far": 2, "respect": 1, "jinsung": 1, "saliman": 1, "shown": 2, "complic": 1, "design": 4, "core": 1, "bolster": 2, "turn": 2, "case": 1, "tell": 2, "welltrain": 1, "scienc": 2, "outcom": 1, "pixel": 1, "thrive": 1, "larger": 1, "pioneer": 1, "that": 39, "whose": 1, "mine": 2, "valu": 9, "softwar": 1, "observ": 2, "sever": 1, "horizont": 1, "transfer": 13, "network": 34, "numxnumpixel": 1, "some": 7, "sourc": 3, "both": 5, "stabl": 2, "dropout": 1, "judgment": 1, "classic": 2, "introduc": 1, "media": 4, "question": 2, "diederik": 1, "divid": 1, "from": 17, "efro": 1, "abnorm": 1, "ultrarealist": 1, "num": 53, "multipli": 1, "movi": 1, "predict": 1, "homogen": 1, "match": 6, "written": 1, "are": 19, "better": 1, "feedback": 4, "option": 1, "varianc": 2, "chanc": 1, "favorit": 1, "samuli": 2, "posit": 3, "efficaci": 1, "dispers": 1, "cybersecur": 1, "even": 2, "faster": 1, "proper": 2, "side": 1, "ian": 3, "deviat": 2, "binari": 1, "comment": 1, "invent": 1, "shift": 1, "goodfellow": 3, "rapid": 1, "kingma": 1, "requir": 4, "figur": 6, "wwwcstorontoedu": 1, "let": 1, "axi": 2, "relationship": 3, "interpret": 1, "world": 2, "conclus": 1, "matt": 2, "base": 2, "fact": 1, "who": 1, "pictur": 1, "permiss": 1, "sebastian": 1, "were": 1, "averag": 1, "describ": 1, "onlin": 1, "yoshua": 1, "much": 5, "fundament": 1, "evalu": 1, "intellig": 3, "problem": 4, "articl": 1, "job": 2, "adain": 3, "outsmart": 1, "fake": 7, "adam": 2, "adapt": 4, "tini": 2, "flatter": 1, "realism": 1, "decemb": 1, "classifi": 3, "spectacular": 1, "dynam": 1, "where": 2, "faruk": 1, "them": 5, "leon": 1, "whi": 1, "latent": 7, "standard": 5, "until": 2, "target": 1, "analysi": 3, "coverag": 1, "provid": 1, "parenthes": 1, "calcul": 3, "xun": 1, "adversari": 10, "team": 1, "jordon": 1, "there": 4, "regular": 1, "inform": 17, "isola": 1, "gati": 1, "best": 1, "illustr": 1, "stabil": 2, "setup": 1, "now": 1, "tri": 4, "interact": 1, "desir": 1, "high": 4, "geoffrey": 1, "basic": 1, "cycleconsist": 1, "realli": 1, "communiti": 1, "leverag": 1, "mesched": 1, "lar": 1, "coupl": 1, "mani": 4, "pattern": 1, "style": 16, "stylebas": 1, "revers": 1, "mehdi": 1, "exampl": 3, "stochast": 1, "research": 5, "technolog": 1, "therefor": 1, "the": 245, "mismatch": 2, "becom": 3, "aila": 2, "past": 2, "peopl": 6, "emul": 1, "those": 1, "andrea": 1, "satisfi": 1, "receiv": 5, "vertic": 1, "tail": 2, "act": 1, "essenti": 3, "win": 2, "crucial": 1, "uniform": 1, "wasserstein": 5, "serg": 1, "term": 2, "thus": 1, "flatten": 2, "other": 15, "uniqu": 1, "procedur": 1, "might": 3, "recreat": 1, "lot": 1, "breakthrough": 1, "divers": 1, "imag": 17, "chen": 1, "maintain": 1, "phillip": 1, "implement": 2, "examin": 1, "push": 1, "collect": 2, "dilemma": 1, "insid": 1, "broad": 1, "part": 1, "append": 1, "analyt": 3, "element": 1, "includ": 2, "structur": 2, "david": 1, "consum": 1, "neither": 1, "access": 1, "typic": 3, "rang": 4, "abl": 3, "variat": 2, "result": 9, "chang": 10, "differ": 6, "been": 1, "statist": 2, "valuabl": 1, "bethg": 1, "between": 5, "steep": 2, "return": 8, "zaremba": 1, "copi": 1, "van": 1, "program": 1, "vincent": 1, "feasibl": 1, "downhil": 1, "day": 1, "nowozin": 1, "radford": 1, "indirect": 1, "call": 8, "more": 9, "improv": 6, "histogram": 1, "produc": 5, "these": 10, "artifici": 1, "could": 7, "stylegan": 12, "lead": 1, "pharmaceut": 1, "languag": 1, "make": 4, "set": 18, "way": 5, "timo": 2, "distinguish": 1, "bring": 1, "rise": 1, "penalti": 5, "common": 1, "oper": 1, "mirza": 1, "repres": 1, "bio": 1, "subtract": 1, "come": 5, "reflect": 1, "variabl": 1, "fewer": 1, "popul": 2, "learn": 26, "send": 3, "understand": 1, "gentl": 1, "manufactur": 2, "first": 3, "everi": 1, "der": 1, "input": 6, "while": 3, "properti": 1, "easili": 1, "aaron": 2, "answer": 1, "numetijmencscnumslideslectureslideslecnumpdf": 1, "when": 6, "courvill": 2}, "idf": {"hand": 1.6152202665600002, "rprop": 1587.6, "strike": 3.5620372447800004, "realist": 12.9494290375, "slight": 3.25327868852, "huang": 66.9873417722, "real": 2.28103448276, "els": 5.44444444444, "wide": 1.5598349381, "new": 1.0178880554, "extra": 5.33826496301, "addit": 1.24634950542, "would": 1.0828729281799998, "nois": 11.6907216495, "instanc": 3.2572835453400004, "specif": 1.8719490626099997, "vari": 2.4970116388799997, "progress": 2.44697903822, "thought": 1.9854927463699998, "further": 1.3618116315, "never": 1.55769230769, "creation": 3.0601387818, "complet": 1.24021560816, "path": 4.6421052631599995, "toward": 1.6303142329, "their": 1.01547908405, "bing": 48.1090909091, "scale": 3.7469907953699995, "creat": 1.2492917847, "ahm": 30.3556405354, "extend": 1.9604840701400004, "instruct": 4.169117647059999, "news": 2.08182533438, "laboratori": 7.6363636363600005, "jame": 1.9313868613099998, "hinton": 152.653846154, "ecker": 1323.0, "end": 1.10680423871, "correl": 13.1860465116, "word": 1.7965372864099998, "deep": 3.6279707495399998, "will": 1.22481098596, "consid": 1.2397313759200002, "incorpor": 2.62847682119, "unlimit": 21.027814569500002, "portion": 3.3019966722099996, "pougetabadi": 1587.6, "next": 1.4950560316400001, "near": 1.28769567686, "but": 1.01632417899, "mixtur": 9.02558271745, "certain": 1.8077886586200003, "obtain": 2.68629441624, "our": 2.35758835759, "classif": 8.067073170730001, "longer": 2.02319357716, "radiolog": 98.0, "domin": 2.320713346, "grow": 2.27287043665, "success": 1.32002993265, "enough": 2.2319696330700003, "stop": 2.1783754116400003, "advantag": 3.32412060302, "resourc": 2.9487369985100003, "arjovski": 1587.6, "out": 1.06016694491, "model": 2.0905978404, "format": 2.53125, "good": 1.51981619759, "alway": 2.06745670009, "concept": 2.65707112971, "number": 1.10142916609, "dumoulin": 1587.6, "categori": 3.98194130926, "optim": 11.5377906977, "field": 1.7790228597, "loss": 2.42529789184, "involv": 1.4498630137000001, "arbitrari": 17.8181818182, "length": 3.69123459661, "determin": 2.1658935879900003, "down": 1.35889754344, "schaar": 1587.6, "logist": 14.0994671403, "soumith": 1587.6, "then": 1.08657860516, "separ": 1.6012102874399998, "they": 1.03017325287, "anoth": 1.13643521832, "effect": 1.3963060686000002, "allow": 1.2716059271100002, "higherresolut": 1587.6, "opposit": 2.4663663197099996, "major": 1.14852058164, "construct": 1.9320920043799998, "featur": 1.52712581762, "practic": 1.70434782609, "respons": 1.5066907089300001, "simpl": 3.3981164383599998, "appear": 1.3214582986499999, "jean": 6.043395508180001, "cheung": 236.955223881, "either": 1.5830092731099998, "develop": 1.1955719557200002, "moreov": 7.56, "such": 1.06151377374, "futurist": 47.109792284899996, "math": 22.0806675939, "without": 1.29547123623, "fast": 4.8729281768, "should": 1.6643254009900001, "add": 4.61243463103, "varieti": 2.2972073506, "content": 3.5421686747, "belongi": 1587.6, "ani": 1.13383802314, "two": 1.01379310345, "limit": 1.5186531471200002, "whether": 2.20683903253, "detail": 2.26186066391, "stun": 21.6, "aren": 481.09090909099996, "idea": 2.0930784443, "environ": 3.43561999567, "curv": 11.1098670399, "equat": 9.76984615385, "for": 1.00031504001, "car": 3.53743315508, "slide": 15.1056137012, "output": 7.676982591880001, "releas": 1.8377126982299998, "seen": 1.61079545455, "with": 1.0011982089899998, "characterist": 3.6724496877199995, "sens": 2.8365195640499996, "look": 1.9086318826599997, "veri": 1.25880114177, "formal": 2.44622496148, "progan": 1587.6, "think": 2.90715986083, "work": 1.11520089913, "negat": 3.75852272727, "combin": 1.69760479042, "promis": 3.5030891438699996, "focus": 2.01012914662, "educ": 2.00733341763, "iter": 37.4433962264, "sigmoid": 1058.4, "decod": 51.713355048900006, "group": 1.20996875238, "drastic": 14.0620017715, "park": 2.4633048875099997, "give": 1.3653250774, "decim": 27.372413793099998, "extract": 7.703056768560001, "place": 1.1004366812200002, "simul": 11.4793926247, "normal": 2.61075481006, "goal": 3.28152128979, "jimmi": 9.230232558139999, "stick": 11.5377906977, "continu": 1.13928955867, "fals": 6.21613155834, "probabl": 2.64555907349, "scientist": 4.69426374926, "machin": 4.02433460076, "into": 1.01502461479, "paper": 2.6628648104700003, "medic": 3.27542809986, "wardefarley": 1587.6, "servic": 1.51300867245, "face": 1.80327124035, "what": 1.25343439128, "ozair": 1587.6, "translat": 2.85745140389, "flexibl": 9.68639414277, "help": 1.39962972759, "cover": 1.69380134429, "dazzl": 77.067961165, "ishaan": 1587.6, "own": 1.17844418052, "occur": 1.7453825857499998, "multipl": 2.74813917258, "quantit": 27.803852889699996, "paramet": 17.256521739100002, "surpris": 4.36633663366, "about": 1.06486015159, "norm": 11.299644128099999, "neural": 59.4606741573, "thing": 2.4065484311099996, "just": 1.33580143037, "entir": 1.59365589239, "grant": 2.2490437739099995, "repost": 933.882352941, "refin": 9.966101694919999, "credibl": 15.6568047337, "artist": 2.86673889491, "render": 5.97740963855, "alec": 40.917525773200005, "train": 1.9365698950999999, "complex": 2.34021226415, "tool": 4.99716713881, "start": 1.26673581744, "geiger": 138.052173913, "run": 1.55692850838, "keep": 2.04245465071, "taesung": 1587.6, "anyth": 4.58843930636, "lose": 3.0851146521599997, "cyclegan": 1587.6, "usual": 1.72508964468, "play": 1.46390041494, "critic": 1.67010309278, "appli": 2.2972073506, "over": 1.02525024217, "centuri": 1.49604221636, "alexand": 4.19445178336, "generat": 2.05275407292, "build": 1.6341739578, "depict": 4.0131445905000005, "innov": 4.74051955808, "hundr": 2.4698195395099996, "consist": 1.4901445466499998, "framework": 8.200413223139998, "bottou": 1587.6, "matthia": 58.1538461538, "assess": 5.24306472919, "say": 1.7544480053, "origin": 1.13724928367, "mindblow": 1587.6, "knowledg": 3.3981164383599998, "take": 1.13961668222, "martin": 3.07793718496, "than": 1.03278688525, "publish": 1.36885669943, "also": 1.01476510067, "trick": 14.7272727273, "mean": 1.44906900329, "treatment": 3.87125091441, "task": 3.88641370869, "batch": 35.6764044944, "squash": 46.017391304300006, "overwhelm": 6.86381322957, "wednesday": 16.249744114600002, "bengio": 1587.6, "challeng": 2.55816951337, "hospit": 3.4633507853400003, "want": 1.99698113208, "enhanc": 5.15957101072, "convert": 3.2740771293099997, "webbas": 1587.6, "system": 1.38739840951, "targetspecif": 1587.6, "genuin": 11.4793926247, "behind": 2.0845588235299997, "howev": 1.0945191313299998, "elimin": 3.67670217693, "actual": 1.87482286254, "ordinari": 6.920662598080001, "maxim": 12.928338762200001, "arxivorgabsnum": 1587.6, "which": 1.005191845, "like": 1.14918566775, "zhu": 92.3023255814, "skill": 3.6989748369099997, "estim": 2.34991119005, "raw": 10.6478873239, "refer": 1.30024570025, "techniqu": 3.7293868921800004, "one": 1.00627495722, "show": 1.26703910615, "terminolog": 17.6989966555, "begin": 1.3305397251100002, "drawback": 49.9245283019, "see": 1.27242125511, "algorithm": 27.9507042254, "becaus": 1.1495184997499999, "outlier": 269.084745763, "moment": 4.262013422819999, "get": 1.78562591385, "random": 7.1902173913, "through": 1.07074930869, "imagin": 6.598503740650001, "wojciech": 208.89473684200001, "detect": 5.41288782816, "transform": 3.42007755278, "jaakko": 882.0, "recent": 1.54405757635, "sign": 1.7606742819099999, "repeat": 2.8771293947099994, "tim": 8.217391304349999, "this": 1.00379362671, "imagetoimag": 1587.6, "sampl": 7.23280182232, "indistinguish": 56.2978723404, "lehtinen": 1587.6, "process": 1.69524826482, "bit": 8.33385826772, "fool": 19.4797546012, "karra": 1221.23076923, "somewhat": 4.29197080292, "most": 1.02096463023, "forev": 12.0363912055, "low": 2.13072070863, "heavili": 3.24132298898, "domain": 9.39408284024, "excel": 4.84467500763, "midnum": 1587.6, "top": 1.8387769284200002, "augment": 16.5202913632, "situat": 2.06611140031, "gradient": 41.889182058, "condit": 1.92483026188, "appropri": 4.31413043478, "correct": 3.6631287494199998, "sherjil": 1587.6, "author": 1.4229631621399998, "weight": 4.878918254459999, "architectur": 5.12790697674, "gan": 101.121019108, "cycl": 5.40919931857, "and": 1.00006299213, "l\u00e9on": 1587.6, "overfit": 1587.6, "discuss": 2.19676214197, "general": 1.1218202374200001, "made": 1.07038834951, "realtim": 429.081081081, "type": 2.0281042411900003, "simultan": 5.32930513595, "can": 1.17626139142, "hergott": 1587.6, "encod": 29.0237659963, "analog": 9.05131128848, "onli": 1.0256476516600002, "each": 1.18974820144, "befor": 1.10036041031, "data": 3.37643555934, "junyan": 1587.6, "qualiti": 2.9329392204, "richer": 47.25, "method": 2.5714285714300003, "sinc": 1.08368600683, "convolut": 101.121019108, "must": 1.9220338983099996, "time": 1.01127460348, "miabella": 1587.6, "direct": 1.22226499346, "has": 1.0436497502, "game": 2.57978550536, "gulrajani": 1587.6, "busi": 2.05541170378, "use": 1.0296387573799999, "household": 5.35266351989, "year": 1.0485436893200002, "often": 1.29452054795, "radialgan": 1587.6, "flat": 5.67811158798, "after": 1.02070207021, "chintala": 1587.6, "onc": 1.4974533106999999, "too": 1.81585268215, "relat": 1.23750876919, "form": 1.12755681818, "signal": 5.12459651388, "immedi": 2.02862254025, "assign": 3.83663605607, "space": 2.39818731118, "transport": 2.68175675676, "dataset": 193.609756098, "function": 2.495441685, "onto": 4.47589512264, "rmsprop": 1587.6, "lain": 116.735294118, "hear": 4.17899447223, "well": 1.0655748708, "done": 2.3302509907499998, "nonstationari": 1587.6, "approach": 2.07556543339, "pace": 10.322496748999999, "hold": 1.6551292744, "know": 2.59327017315, "unpair": 453.6, "momentum": 16.835630965, "minibatch": 1587.6, "measur": 2.41093394077, "instead": 1.59461631177, "least": 1.6165359943000002, "humankind": 73.8418604651, "express": 1.9120799710900003, "vicki": 71.5135135135, "sharpen": 73.1612903226, "how": 1.60250328051, "reaction": 4.67904509284, "discrimin": 10.6981132075, "increas": 1.32024948025, "distribut": 2.7396031061299997, "converg": 15.2947976879, "sure": 7.453521126760001, "sharp": 7.02477876106, "simplest": 28.0494699647, "overview": 12.6805111821, "numxnum": 52.0524590164, "wherea": 4.13868613139, "alter": 4.4247491638800005, "purpos": 2.23416830847, "yoon": 407.07692307699995, "need": 1.4372623574099999, "learningai": 1587.6, "all": 1.01146788991, "confirm": 3.0827184466000004, "tero": 1587.6, "amaz": 15.250720461099998, "applic": 3.42672134686, "review": 2.2099109131400003, "have": 1.0148948411399998, "long": 1.2657259028899999, "tensorflow": 1587.6, "mihaela": 1587.6, "experi": 1.87062566278, "famous": 2.28201811125, "sound": 3.11294117647, "quit": 2.8849718335500003, "excit": 9.818181818180001, "layer": 8.14153846154, "numer": 1.83325635104, "astronomi": 24.3870967742, "global": 3.30612244898, "alexei": 73.1612903226, "entertain": 4.02739726027, "not": 1.01567398119, "far": 1.71022298826, "respect": 1.6443293630200002, "jinsung": 1587.6, "saliman": 1587.6, "shown": 2.76923076923, "complic": 5.6478121664900005, "design": 1.45825296225, "core": 4.623179965059999, "bolster": 22.4237288136, "turn": 1.3838912133899999, "case": 1.48498737256, "tell": 3.36142282448, "welltrain": 1587.6, "scienc": 2.31969608416, "outcom": 7.48867924528, "pixel": 86.28260869569999, "thrive": 13.153272576600001, "larger": 2.2407904022599996, "pioneer": 4.74051955808, "that": 1.00398406375, "whose": 1.73508196721, "mine": 4.875921375919999, "valu": 2.2777618364400003, "softwar": 10.2624434389, "observ": 2.22446406053, "sever": 1.07241286139, "horizont": 11.6137527432, "transfer": 2.72549356223, "network": 2.59369384088, "numxnumpixel": 1587.6, "some": 1.04036697248, "sourc": 1.69760479042, "both": 1.05215720061, "stabl": 6.70156184044, "dropout": 167.115789474, "judgment": 10.911340206199998, "classic": 2.4087391898, "introduc": 1.7258397651900002, "media": 2.59369384088, "question": 2.20408163265, "diederik": 1587.6, "divid": 2.3169877408099997, "from": 1.00056721497, "efro": 1587.6, "abnorm": 29.8983050847, "ultrarealist": 1587.6, "num": 1.00031504001, "multipli": 20.4061696658, "movi": 4.00403530895, "predict": 5.18484650555, "homogen": 26.4159733777, "match": 3.5676404494400002, "written": 1.9573418813999999, "are": 1.02990593578, "better": 2.0065722952500002, "feedback": 24.652173913000002, "option": 4.04896710023, "varianc": 51.3786407767, "chanc": 4.2449197861000005, "favorit": 8.116564417180001, "samuli": 1587.6, "posit": 1.37252528746, "efficaci": 37.8902147971, "dispers": 11.1567111736, "cybersecur": 441.0, "even": 1.16461267606, "faster": 7.61438848921, "proper": 3.3388012618299996, "side": 1.5989525632, "ian": 7.805309734510001, "deviat": 19.1507840772, "binari": 32.4, "comment": 3.05954904606, "invent": 4.604408352669999, "shift": 3.3317943336799996, "goodfellow": 721.636363636, "rapid": 2.62586834271, "kingma": 1587.6, "requir": 1.52844902282, "figur": 2.0343413634, "wwwcstorontoedu": 1587.6, "let": 3.48616600791, "axi": 12.109839816900001, "relationship": 2.39132399458, "interpret": 3.2150668286799995, "world": 1.11340206186, "conclus": 4.84615384615, "matt": 11.372492836700001, "base": 1.14628158845, "fact": 1.73375559681, "who": 1.06279287723, "pictur": 3.4953764861300005, "permiss": 6.280063291139999, "sebastian": 26.8175675676, "were": 1.02458857696, "averag": 2.60390355913, "describ": 1.47027227264, "onlin": 2.6051854282900004, "yoshua": 1587.6, "much": 1.1942229577299999, "fundament": 5.32930513595, "evalu": 6.9509632224199995, "intellig": 4.19334389857, "problem": 1.76674827509, "articl": 2.01805008262, "job": 3.2539454806299997, "adain": 1587.6, "outsmart": 547.448275862, "fake": 18.290322580599998, "adam": 4.43092380687, "adapt": 3.32272917539, "tini": 12.928338762200001, "flatter": 47.25, "realism": 24.4246153846, "decemb": 1.48166122259, "classifi": 5.2937645882, "spectacular": 16.4859813084, "dynam": 6.52527743527, "where": 1.06715063521, "faruk": 1134.0, "them": 1.09876115994, "leon": 12.5402843602, "whi": 3.2566153846200003, "latent": 66.42677824270001, "standard": 1.8915763135900003, "until": 1.14852058164, "target": 3.2189781021900004, "analysi": 3.47852760736, "coverag": 8.26444560125, "provid": 1.21552714187, "parenthes": 75.2417061611, "calcul": 6.12972972973, "xun": 226.8, "adversari": 26.328358209, "team": 2.2748244734200003, "jordon": 1587.6, "there": 1.04091266719, "regular": 2.09418282548, "inform": 1.5753125620200001, "isola": 882.0, "gati": 1587.6, "best": 1.5828514456600002, "illustr": 3.6614391143900002, "stabil": 6.0618556701, "setup": 34.1419354839, "now": 1.160780873, "tri": 1.8544562551099997, "interact": 4.4185917061, "desir": 3.00170164492, "high": 1.14777327935, "geoffrey": 15.236084453, "basic": 2.7301805675, "cycleconsist": 1587.6, "realli": 4.7476076555, "communiti": 1.96121062384, "leverag": 35.7567567568, "mesched": 1587.6, "lar": 56.9032258065, "coupl": 3.2572835453400004, "mani": 1.04426757877, "pattern": 3.79173632673, "style": 2.37807070102, "stylebas": 1587.6, "revers": 4.29894394801, "mehdi": 233.470588235, "exampl": 1.50483412322, "stochast": 128.032258065, "research": 1.9420183486200002, "technolog": 2.6034765496900003, "therefor": 2.33401940606, "the": 1.0, "mismatch": 103.090909091, "becom": 1.12492028626, "aila": 1587.6, "past": 2.01702452039, "peopl": 1.21320495186, "emul": 19.3138686131, "those": 1.19548192771, "andrea": 13.627467811199999, "satisfi": 7.680696661830001, "receiv": 1.3054847463200001, "vertic": 8.974561899380001, "tail": 12.520504731900001, "act": 1.4318181818200002, "essenti": 2.9280708225700005, "win": 2.75290445639, "crucial": 7.7443902439, "uniform": 5.7231434751300005, "wasserstein": 992.25, "serg": 58.1538461538, "term": 1.39520168732, "thus": 1.6463756092500001, "flatten": 42.336000000000006, "other": 1.00992366412, "uniqu": 3.01595744681, "procedur": 5.8691312384500005, "might": 2.1561863370900003, "recreat": 6.536023054759999, "lot": 4.40877534018, "breakthrough": 16.434782608699997, "divers": 3.97197898424, "imag": 2.70137825421, "chen": 34.0686695279, "maintain": 1.77306231852, "phillip": 10.431011826499999, "implement": 3.57648118946, "examin": 3.8505942275, "push": 3.75141776938, "collect": 1.64109985528, "dilemma": 27.9507042254, "insid": 2.7396031061299997, "broad": 4.27693965517, "part": 1.04330682789, "append": 55.125, "analyt": 17.256521739100002, "element": 2.36004162331, "includ": 1.0190641247799999, "structur": 2.0580762250499998, "david": 1.84970290108, "consum": 4.93043478261, "neither": 3.6622837370199997, "access": 1.8734953976900002, "typic": 2.2541530597799997, "rang": 1.7848229342299997, "abl": 1.8208510150200001, "variat": 4.704, "result": 1.14611608432, "chang": 1.1808985421, "differ": 1.23654490225, "been": 1.0239277652399998, "statist": 4.24265098878, "valuabl": 7.46754468485, "bethg": 1587.6, "between": 1.03453668708, "steep": 16.5547445255, "return": 1.39532431007, "zaremba": 1587.6, "copi": 3.8375634517800004, "van": 3.99295774648, "program": 2.02139037433, "vincent": 11.1802816901, "feasibl": 17.8181818182, "downhil": 81.83505154640001, "day": 1.18371607516, "nowozin": 1587.6, "radford": 157.188118812, "indirect": 8.618892508139998, "call": 1.0676529926, "more": 1.0171706817, "improv": 2.04376930999, "histogram": 1058.4, "produc": 1.36932896326, "these": 1.07415426252, "artifici": 8.31639601886, "could": 1.2043695949, "stylegan": 1587.6, "lead": 1.2664326739, "pharmaceut": 24.767550701999998, "languag": 2.29488291414, "make": 1.0762660158600001, "set": 1.18707940781, "way": 1.2190739461, "timo": 311.294117647, "distinguish": 3.36926994907, "bring": 2.03616775683, "rise": 2.02940048575, "penalti": 9.95360501567, "common": 1.4025974025999999, "oper": 1.55479384977, "mirza": 112.595744681, "repres": 1.46972782818, "bio": 42.336000000000006, "subtract": 45.4899713467, "come": 1.32831325301, "reflect": 2.3443591258099996, "variabl": 8.747107438019999, "fewer": 5.94829524166, "popul": 2.17807655371, "learn": 2.32275054865, "send": 3.75053153792, "understand": 2.96858638743, "gentl": 17.1447084233, "manufactur": 3.3578680202999998, "first": 1.00761614623, "everi": 1.47917637194, "der": 7.122476446839999, "input": 12.2029208301, "while": 1.0441988950299999, "properti": 2.5949656750599996, "easili": 3.6938110749199997, "aaron": 16.6589716684, "answer": 4.64890190337, "numetijmencscnumslideslectureslideslecnumpdf": 1587.6, "when": 1.02076769755, "courvill": 1587.6}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Generative Adversarial Networks \u2013 Key Milestones and State of the Art</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Generative Adversarial Networks \u2013 Key Milestones and State of the Art Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\" rel=\"prev\" title=\"Attention Craving RNNS: Building Up To Transformer Networks\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\" rel=\"next\" title=\"Top 10 Python Use Cases\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=93355\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-93355 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 24-Apr, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Generative Adversarial Networks \u2013 Key Milestones and State of the Art (\u00a0<a href=\"/2019/n17.html\">19:n17</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Generative Adversarial Networks \u2013 Key Milestones and State of the Art</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/gans\" rel=\"tag\">GANs</a>, <a href=\"https://www.kdnuggets.com/tag/generative-adversarial-network\" rel=\"tag\">Generative Adversarial Network</a>, <a href=\"https://www.kdnuggets.com/tag/nvidia\" rel=\"tag\">NVIDIA</a></div>\n<br/>\n<p class=\"excerpt\">\n     We provide an overview of Generative Adversarial Networks (GANs), discuss challenges in GANs learning, and examine two promising GANs: the RadialGAN, designed for numbers, and the StyleGAN, which does style transfer for images. \n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/matthew-j-hergott/\">Matt Hergott</a>, MiaBella AI</b>.</p>\n<p>Is December 12, 2018, a day the world changed forever? That Wednesday, a team of researchers at NVIDIA released a dazzling new artificial intelligence design called the StyleGAN.<strong>[1]</strong>\u00a0The StyleGAN is a deep learning system based on the idea of a generative adversarial network (GAN), and this model generates ultra-realistic images of people, cars, and households.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*IUjB3NcYRi467MT8gaKQnQ.png\" width=\"60%\"/></p>\n<p>Inventions like this could change the way humankind interacts with nearly all media. For instance, when people see images in the news, their first reaction could be to try to determine whether what they are looking at is real or fake.</p>\n<p>GANs are some of the more futuristic AI designs, and people have many questions about them: What are GANs? Will I be able to understand them? Can I use GANs for my business analytics, or are they only good at creating images?</p>\n<p>This article will try to answer some of these questions. We\u2019ll start with an overview of GANs, then we\u2019ll discuss some challenges in helping GANs to learn. After that, we\u2019ll examine two promising GANs: the RadialGAN,<strong>[2]</strong>which is designed for numbers, and the StyleGAN, which is focused on images.</p>\n<h3>The Generative Adversarial Network\u00a0(GAN)</h3>\n<p>The original GAN<strong>[3]</strong>\u00a0was created by Ian Goodfellow, who described the GAN architecture in a paper published in mid-2014. A GAN consists of two neural networks playing a game with each other. The\u00a0<em>discriminator\u00a0</em>tries to determine whether information is real or fake. The other neural network, called a\u00a0<em>generator</em>, tries to create data that the discriminator thinks is real.</p>\n<p><img class=\"alignnone\" src=\"https://cdn-images-1.medium.com/max/1600/1*--AtNcFUNb_ts_uihuSJ2g.png\" width=\"100%\"/></p>\n<p>This concept is depicted in Figure 1. The neural network at the top is the discriminator, and its task is to distinguish the training set\u2019s real information from the generator\u2019s creations. In the simplest GAN structure, the generator starts with random data and learns to transform this noise into information that matches the distribution of the real data.</p>\n<p>The generator never sees the genuine data; it must learn to create realistic information by receiving feedback from the discriminator. This is called\u00a0<em>adversarial loss</em>, and when implemented correctly it works surprisingly well. In fact, regularization techniques such as dropout layers are often used in GANs because the generator can overfit the training set through this entirely indirect learning process.</p>\n<p>The longer these two neural networks play this game, the more they sharpen each other\u2019s skills. The discriminator becomes very good at detecting fake data while the generator learns to produce information that is indistinguishable from what is observed in the real world.</p>\n<p>When we end up with two GAN neural networks that are very good at what they do, how could we use them? A trained discriminator can be used for detecting abnormalities, outliers, and anything out of the ordinary. This could be very valuable in fields such as cybersecurity, radiology, astronomy, and manufacturing.</p>\n<p>A skilled generator is used for making creations. Once the generator learns the distribution of the training data, we can sample the generator an unlimited number of times for realistic outputs such as images, language,\u00a0<a data-href=\"https://www.news-medical.net/news/20170209/Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.aspx\" href=\"https://www.news-medical.net/news/20170209/Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.aspx\">pharmaceuticals</a>, numerical simulations, and just about anything else one can imagine.</p>\n<h3>Wasserstein GAN\u00a0(WGAN)</h3>\n<p>The original GAN created a lot of excitement when it was first introduced. But there was a problem that showed up immediately: if one of the neural networks started to dominate the other in the GAN game, learning would stop for both. The GAN neural networks are called adversaries, but we want to keep one side from winning so they both can learn for an extended time.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*UCMD_kWREM0GVWKIYEPsJA.png\" width=\"60%\"/></p>\n<p>This training dilemma is illustrated in Figure 2. The standard binary classifier is a sigmoid curve\u200a\u2014\u200amore formally called a standard logistic sigmoid function\u200a\u2014\u200athat converts an input value into a result between 0 (a negative classification) and 1 (a positive classification).\u00a0<span data-creator-ids=\"anon\">The tail ends of the sigmoid curve are very flat, which means that neural networks can lose their sense of direction if the GAN game ends up far out on one of these tails.</span></p>\n<p>For instance, if the discriminator can always tell that the generator\u2019s creations are fake, the discriminator will always return a 0 to the generator\u2019s training function. If the generator is always able to fool the discriminator, the discriminator always sends a 1 to the generator. In either case, learning stops for both neural networks because neither one is receiving any feedback on how to get better.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*rncFBOe8b0QKeDIactG_Wg.png\" width=\"60%\"/></p>\n<p>An innovation in 2017 made training GANs much more stable. The Wasserstein GAN<strong>[4]</strong>(WGAN) changes the type of response the discriminator sends to the generator. Instead of returning the sigmoid value of the vertical axis, the WGAN returns the input value of the horizontal axis (see Figure 3). In other words, the standard neural network classifier returns\u00a0<strong>f(x)</strong>, whereas the WGAN returns\u00a0<strong>x</strong>.</p>\n<p>This means that even if one of the neural networks is always winning, at least the tiny variations that do occur will not get completely flattened out by a sigmoid function. For example, if a GAN discriminator is always able to detect fake data, it might output a value of -100 on one iteration and then -99 on the next iteration. Sending these numbers through a classic sigmoid function makes them indistinguishable at 40+ decimal places. This is why learning stops so easily in the simplest GAN: the generator can end up in a position where it is receiving essentially no direction from the discriminator.</p>\n<p>But the WGAN uses the raw numbers (-100 and -99), and this 1% change can be enough to give the generator a path for improvement. This means that learning can continue even if one of the neural networks is overwhelming the other.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*Il4k2l_1yZbQuJhj7vwtMg.png\" width=\"60%\"/></p>\n<p>The basic WGAN training equations are shown in Figure 4. The terms inside the parentheses represent the desired learning direction of each neural network, and these expressions get multiplied by -1 since we typically optimize in the downhill direction.</p>\n<p>If the discriminator is very good at its job, it returns high values for real samples and low values for the fake information coming from the generator. The generator has the opposite goal: it wants the discriminator to assign high values\u200a\u2014\u200ain other words, false positives\u200a\u2014\u200ato the generated information.</p>\n<h3>WGAN Refinements</h3>\n<h3>The Critic</h3>\n<p>The WGAN authors changed the GAN terminology a bit by referring to the discriminator neural network as a\u00a0<em>critic</em>. The word discriminator comes from\u00a0<em>discriminant analysis</em>\u00a0and reflects a classifier that separates data into categories. The WGAN, on the other hand, returns much richer feedback, and this is somewhat analogous to a written review by a movie critic.</p>\n<h3>Diverse Results</h3>\n<p>One of the problems people can experience with GANs is that the neural networks appear to be learning properly, but in the end, the generator only re-creates a limited portion of the training distribution. This occurs because the generator can outsmart the training process. If the only instruction the generator receives is to fool the discriminator, the generator can learn to maximize its chance of success by sticking to the most heavily populated portion of the training set.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*amvRQapWAp_jJ9Qe6fcvrg.png\" width=\"60%\"/></p>\n<p>We typically want a generator to produce a broad range of results, and two common practices help with this.</p>\n<p><em>Minibatch discrimination</em><strong>[5]</strong>dynamically collects statistics on a batch of samples\u200a\u2014\u200ain other words, from multiple observations\u200a\u2014\u200aat one or more layers of the discriminator neural network. The discriminator then uses these statistics as additional information in its assessment of whether the data set is genuine or fake. If the dispersion of samples is very different between the training set and the generated data, the discriminator can signal to the generator that the generator needs to increase the range of its results.</p>\n<p>Another option for producing a wide variety of results is to provide both the generator and the discriminator with extra variables that act as\u00a0<em>conditioning information</em>\u00a0to tell the neural networks which environment they are operating in. This is a major advantage when we want to direct a generator to produce creations appropriate for a specific situation.</p>\n<h3>Optimizers</h3>\n<p>The WGAN might require some thought as to the best optimizer to use. A sigmoid curve is often called a \u201csquashing\u201d function because it flattens its inputs into a range of 0 to 1.</p>\n<p>But the WGAN can return any value at any time, and thus its outputs are\u00a0<em>nonstationary</em>. For this type of problem, it might be helpful to use optimizers without momentum (like RMSProp<strong>[6]</strong>) or at least turn down the momentum parameter of an optimizer like adaptive moment estimation (Adam<strong>[7]</strong>).</p>\n<h3>WGAN with Gradient Penalty (WGAN-GP)</h3>\n<p>It turns out that implementing the Wasserstein GAN isn\u2019t quite as simple as eliminating the sigmoid function in the discriminator. The math behind the WGAN requires that the gradients of the discriminator can\u2019t be very steep. In other words, if we alter the inputs to the discriminator neural network, the discriminator\u2019s output can\u2019t change too drastically.</p>\n<p>To satisfy this condition, a group of machine learning researchers created the gradient penalty.<strong>[8]</strong>\u00a0This technique adds a penalty term to the discriminator\u2019s loss function if the gradients get too sharp, and it pushes the discriminator\u2019s learning process toward flatter gradients.</p>\n<p>The general programming pattern for the gradient penalty looks like this:</p>\n<ol>\n<li>Make a randomly weighted combination of the real data and the generator\u2019s manufactured output; this is a way to sample as much of the discriminator\u2019s function range as is feasible.</li>\n<li>Obtain the gradient by measuring how the discriminator\u2019s output changes with respect to this weighted mixture of inputs. This is usually done through a deep learning framework such as TensorFlow\u2019s\u00a0<a data-href=\"https://www.tensorflow.org/api_docs/python/tf/gradients\" href=\"https://www.tensorflow.org/api_docs/python/tf/gradients\">gradients()</a>function.</li>\n<li>Calculate the norm\u200a\u2014\u200ain other words, the length\u200a\u2014\u200aof the gradient and create a penalty based on how far this is from 1.</li>\n<li>Add the result from #3 to the discriminator\u2019s loss function. The discriminator then knows that it needs to learn its job without building a steep relationship between its inputs and output.</li>\n</ol>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*u2IG4KkEBotf47I3TbZwEw.png\" width=\"60%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"3908\">The WGAN-GP approach leads to more stable GAN training and has probably helped to increase the pace of GAN innovation since 2017. For instance, Figure 6 shows how some of the most famous GANs were created over just the past couple of years.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"b901\">One drawback to the WGAN-GP is its training time. Each iteration requires a calculation of the discriminator\u2019s gradient. Moreover, it is typical to train the discriminator at least 5 times as often as the generator. This is because the excellent feedback a well-trained discriminator gives to the generator should allow the generator to become highly effective with fewer learning iterations.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"6d2d\">There is much research being done on how to help GANs learn faster while maintaining the stability of a WGAN-GP.<strong class=\"markup--strong markup--p-strong\">[9]</strong></p>\n<h3 class=\"graf graf--h3 graf-after--p\" id=\"227e\">Sample GANs</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"e537\">Now that we\u2019ve covered the essentials of GANs and how to train them, we\u2019ll look at two very promising GANs. The RadialGAN is designed for numerical analysis, while the StyleGAN received global media coverage for its stunning image creations.</p>\n<h3 class=\"graf graf--h3 graf-after--p\" id=\"408c\">The RadialGAN</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"e384\">Let\u2019s say we are data scientists working for a hospital that wants to evaluate the efficacy of a new medical treatment. Because this procedure is new, our hospital doesn\u2019t have enough data for us to render a credible judgment. We are, however, granted access to other hospitals\u2019 data, and this gives us enough information to give a proper assessment of the new treatment.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"07a3\">But combining data from different hospitals has problems. There is\u00a0<em class=\"markup--em markup--p-em\">distribution mismatch</em>\u00a0because the hospitals service very different populations of people. There is also\u00a0<em class=\"markup--em markup--p-em\">feature mismatch</em>\u00a0because the hospitals collect their own data sets, use laboratories that give slightly different results, and measure outcomes in varying ways.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"4044\">This is where the RadialGAN comes in. The RadialGAN first transforms each data set into a\u00a0<em class=\"markup--em markup--p-em\">latent space</em>, which holds all the data from different sources in a uniform format. The data in the latent space can then be extracted and converted into the feature space of each unique data set.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*guRpKNXKZJXzqltSvSKEEg.png\" width=\"60%\"/></p>\n<p>In GAN terminology, these data transformations are referred to as\u00a0<em>domain transfer</em>, which is when we extract the essential knowledge of a data set and transport that intelligence onto another information set.</p>\n<p>In the RadialGAN, each data set has an\u00a0<em>encoder\u00a0</em>neural network that transforms the data into the homogeneous structure of the latent space.</p>\n<p>Every data source also has a\u00a0<em>decoder</em>, which is a GAN with a generator that converts information from the latent space into a form consistent with the data set. Each of these decoder GANs has a discriminator that confirms the information coming out of the latent space matches the properties of the target data domain.</p>\n<p>This setup makes sure that the domain transfer of information works in both directions and is reversible. This concept is called\u00a0<em>cycle consistency</em>. It originated with the CycleGAN,<strong>[10]</strong>\u00a0and it has become a crucial part of many GAN models.</p>\n<p>We train all these neural networks simultaneously, and once the learning process is complete, we can use the RadialGAN to create an augmented data set as shown in Figure 8.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*UJ8RZi1DJYuWFV5OxxasxA.png\" width=\"60%\"/></p>\n<p>To construct our enhanced data set, we run each of the other data sets through their encoders to transfer that knowledge into the latent space. Then we extract that intelligence from the latent space using our decoder and append the transformed information to our original data set.</p>\n<p>The result is a new, larger data set that is bolstered by information from a variety of sources, but which matches the characteristics of the domain we are working in.</p>\n<h3>The StyleGAN</h3>\n<p>The spectacular new StyleGAN combines two innovations: the Progressive GAN<strong>[11]</strong>\u00a0(ProGAN) and neural style transfer.<strong>[12]</strong></p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*JIJZ2CiM_SiMTtlsiK1F1Q.png\" width=\"60%\"/></p>\n<p>The ProGAN begins by developing a tiny image of 4x4 or 8x8 pixels until this picture is considered realistic by the ProGAN discriminator.</p>\n<p>Once this learning is complete, the ProGAN gently adds a higher-resolution layer that also needs to be trained. This process continues until the ProGAN can create 1024x1024-pixel images with amazing realism.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*IEjyn7imY1eb1evQz2C5YQ.png\" width=\"60%\"/></p>\n<p>The StyleGAN builds on the ProGAN by bringing in some of the most successful elements of neural style transfer. The original style transfer works by copying the neural network layer correlations of a style image onto a content image. This requires an optimization process that can take too long to be useful in many real-time applications.</p>\n<p>Researchers repeatedly made improvements to the classic neural style transfer, and the StyleGAN uses one of the more recent style transfer methods called adaptive instance normalization (AdaIN).<strong>[13]</strong></p>\n<p>Adaptive instance normalization doesn\u2019t involve an optimization, and it\u2019s therefore a very fast way to transfer styles between images. It\u2019s also very flexible in that it can transfer styles between any images, including those that neural networks have never seen before because they aren\u2019t in any training set.</p>\n<p>Applying AdaIN to a convolutional neural network layer of a content image is a simple process:</p>\n<ol>\n<li>Normalize the layer by subtracting its mean and dividing by its standard deviation.</li>\n<li>Scale this normalized layer to match the standard deviation of the style layer.</li>\n<li>Shift the layer by adding in the average value of the style layer.</li>\n</ol>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*tmzVhW0gs0KQnSX-RDPbUg.png\" width=\"60%\"/></p>\n<p>This sounds more complicated than it really is. All we\u2019re doing is changing the mean and variance of an image\u2019s neural network layers to match the mean and variance of a style image (i.e., the image whose style we want to emulate).</p>\n<p>Further refinements to the StyleGAN and AdaIN could include methods like histogram matching, which would transfer more style detail but would also be very fast to calculate.</p>\n<p>The StyleGAN is a somewhat complex architecture that incorporates many neural network tools and tricks that have been developed over the past several years. But at its core, the StyleGAN combines the highly effective ProGAN with the successes of neural style transfer to create images that are so realistic they could fundamentally change the relationship people have with the news and entertainment media.</p>\n<h3>Conclusion</h3>\n<p>The StyleGAN is a striking example of how generative adversarial networks could transform the way much of the media produces its content and alter how consumers interpret the information they see and hear. The RadialGAN, on the other hand, shows how the features and advantages of GANs can be used to bolster numerical data analysis.</p>\n<p>These are two examples of a thriving community of hundreds of innovative GANs that can be used for just about any purpose one can imagine.</p>\n<p>Some of the results we\u2019re seeing from GANs look like they come from a different century, and one thing is certain: pioneering AI techniques like GANs are rapidly changing our relationship to technology, and to each other.</p>\n<h3>References</h3>\n<p><strong>[1]</strong>\u00a0Tero Karras, Samuli Laine, and Timo Aila</p>\n<p>A Style-Based Generator Architecture for Generative Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1812.04948\" href=\"https://arxiv.org/abs/1812.04948\">arxiv.org/abs/1812.04948</a></p>\n<p><strong>[2]</strong>\u00a0Jinsung Yoon, James Jordon, and Mihaela van der Schaar</p>\n<p>RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1802.06403\" href=\"https://arxiv.org/abs/1802.06403\">arxiv.org/abs/1802.06403</a></p>\n<p><strong>[3]</strong>\u00a0Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio</p>\n<p>Generative Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1406.2661\" href=\"https://arxiv.org/abs/1406.2661\">arxiv.org/abs/1406.2661</a></p>\n<p><strong>[4]</strong>\u00a0Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou</p>\n<p>Wasserstein GAN</p>\n<p><a data-href=\"https://arxiv.org/abs/1701.07875\" href=\"https://arxiv.org/abs/1701.07875\">arxiv.org/abs/1701.07875</a></p>\n<p><strong>[5]</strong>\u00a0Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen</p>\n<p>Improved Techniques for Training GANs</p>\n<p><a data-href=\"https://arxiv.org/abs/1606.03498\" href=\"https://arxiv.org/abs/1606.03498\">arxiv.org/abs/1606.03498</a></p>\n<p><strong>[6]\u00a0</strong>Geoffrey Hinton</p>\n<p>Neural Networks for Machine Learning, slide #27: \u201crprop: Using only the sign of the gradient\u201d</p>\n<p><a data-href=\"http://www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf\" href=\"http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\">www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf</a></p>\n<p><strong>[7]</strong>\u00a0Diederik P. Kingma and Jimmy Ba</p>\n<p>Adam: A Method for Stochastic Optimization</p>\n<p><a data-href=\"https://arxiv.org/abs/1412.6980\" href=\"https://arxiv.org/abs/1412.6980\">arxiv.org/abs/1412.6980</a></p>\n<p><strong>[8]</strong>\u00a0Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville</p>\n<p>Improved Training of Wasserstein GANs</p>\n<p><a data-href=\"https://arxiv.org/abs/1704.00028\" href=\"https://arxiv.org/abs/1704.00028\">arxiv.org/abs/1704.00028</a></p>\n<p><strong>[9]\u00a0</strong>Lars Mescheder, Andreas Geiger, and Sebastian Nowozin</p>\n<p>Which Training Methods for GANs do Actually Converge?</p>\n<p><a data-href=\"https://arxiv.org/abs/1801.04406\" href=\"https://arxiv.org/abs/1801.04406\">arxiv.org/abs/1801.04406</a></p>\n<p><strong>[10]</strong>\u00a0Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros</p>\n<p>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1703.10593\" href=\"https://arxiv.org/abs/1703.10593\">arxiv.org/abs/1703.10593</a></p>\n<p><strong>[11]\u00a0</strong>Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen</p>\n<p>Progressive Growing of GANs for Improved Quality, Stability, and Variation</p>\n<p><a data-href=\"https://arxiv.org/abs/1710.10196\" href=\"https://arxiv.org/abs/1710.10196\">arxiv.org/abs/1710.10196</a></p>\n<p><strong>[12]</strong>\u00a0Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge</p>\n<p>A Neural Algorithm of Artistic Style</p>\n<p><a data-href=\"https://arxiv.org/abs/1508.06576\" href=\"https://arxiv.org/abs/1508.06576\">arxiv.org/abs/1508.06576</a></p>\n<p><strong>[13]</strong>\u00a0Xun Huang and Serge Belongie</p>\n<p>Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</p>\n<p><a data-href=\"https://arxiv.org/abs/1703.06868\" href=\"https://arxiv.org/abs/1703.06868\">arxiv.org/abs/1703.06868</a></p>\n<p><a href=\"https://medium.com/datadriveninvestor/a-leap-into-the-future-generative-adversarial-networks-96a780ed8ee6\">Original</a>. Reposted with permission.</p>\n<p><strong>Bio</strong>:\u00a0<a href=\"https://www.linkedin.com/in/matthew-j-hergott/\">Matt Hergott</a>\u00a0is a Quantitative Researcher at MiaBella AI.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html\">The Rise of Generative Adversarial Networks</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html\">Which Face is Real?</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html\">My favorite mind-blowing Machine Learning/AI breakthroughs</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Generative Adversarial Networks \u2013 Key Milestones and State of the Art (\u00a0<a href=\"/2019/n17.html\">19:n17</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556323508\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.704 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 20:05:08 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "matt", "hergott", "miabella", "decemb", "num", "num", "day", "the", "world", "chang", "forev", "that", "wednesday", "team", "research", "releas", "dazzl", "new", "artifici", "intellig", "design", "call", "the", "stylegan", "num", "the", "stylegan", "deep", "learn", "system", "base", "the", "idea", "generat", "adversari", "network", "and", "this", "model", "generat", "ultrarealist", "imag", "peopl", "car", "and", "household", "invent", "like", "this", "could", "chang", "the", "way", "humankind", "interact", "with", "near", "all", "media", "for", "instanc", "when", "peopl", "see", "imag", "the", "news", "their", "first", "reaction", "could", "tri", "determin", "whether", "what", "they", "are", "look", "real", "fake", "gan", "are", "some", "the", "more", "futurist", "design", "and", "peopl", "have", "mani", "question", "about", "them", "what", "are", "gan", "will", "abl", "understand", "them", "can", "use", "gan", "for", "busi", "analyt", "are", "they", "onli", "good", "creat", "imag", "this", "articl", "will", "tri", "answer", "some", "these", "question", "start", "with", "overview", "gan", "then", "discuss", "some", "challeng", "help", "gan", "learn", "after", "that", "examin", "two", "promis", "gan", "the", "radialgan", "num", "which", "design", "for", "number", "and", "the", "stylegan", "which", "focus", "imag", "the", "generat", "adversari", "network", "the", "origin", "num", "creat", "ian", "goodfellow", "who", "describ", "the", "architectur", "paper", "publish", "midnum", "consist", "two", "neural", "network", "play", "game", "with", "each", "other", "the", "discrimin", "tri", "determin", "whether", "inform", "real", "fake", "the", "other", "neural", "network", "call", "generat", "tri", "creat", "data", "that", "the", "discrimin", "think", "real", "this", "concept", "depict", "figur", "num", "the", "neural", "network", "the", "top", "the", "discrimin", "and", "task", "distinguish", "the", "train", "set", "real", "inform", "from", "the", "generat", "creation", "the", "simplest", "structur", "the", "generat", "start", "with", "random", "data", "and", "learn", "transform", "this", "nois", "into", "inform", "that", "match", "the", "distribut", "the", "real", "data", "the", "generat", "never", "see", "the", "genuin", "data", "must", "learn", "creat", "realist", "inform", "receiv", "feedback", "from", "the", "discrimin", "this", "call", "adversari", "loss", "and", "when", "implement", "correct", "work", "surpris", "well", "fact", "regular", "techniqu", "such", "dropout", "layer", "are", "often", "use", "gan", "becaus", "the", "generat", "can", "overfit", "the", "train", "set", "through", "this", "entir", "indirect", "learn", "process", "the", "longer", "these", "two", "neural", "network", "play", "this", "game", "the", "more", "they", "sharpen", "each", "other", "skill", "the", "discrimin", "becom", "veri", "good", "detect", "fake", "data", "while", "the", "generat", "learn", "produc", "inform", "that", "indistinguish", "from", "what", "observ", "the", "real", "world", "when", "end", "with", "two", "neural", "network", "that", "are", "veri", "good", "what", "they", "how", "could", "use", "them", "train", "discrimin", "can", "use", "for", "detect", "abnorm", "outlier", "and", "anyth", "out", "the", "ordinari", "this", "could", "veri", "valuabl", "field", "such", "cybersecur", "radiolog", "astronomi", "and", "manufactur", "skill", "generat", "use", "for", "make", "creation", "onc", "the", "generat", "learn", "the", "distribut", "the", "train", "data", "can", "sampl", "the", "generat", "unlimit", "number", "time", "for", "realist", "output", "such", "imag", "languag", "pharmaceut", "numer", "simul", "and", "just", "about", "anyth", "els", "one", "can", "imagin", "wasserstein", "the", "origin", "creat", "lot", "excit", "when", "first", "introduc", "but", "there", "problem", "that", "show", "immedi", "one", "the", "neural", "network", "start", "domin", "the", "other", "the", "game", "learn", "would", "stop", "for", "both", "the", "neural", "network", "are", "call", "adversari", "but", "want", "keep", "one", "side", "from", "win", "they", "both", "can", "learn", "for", "extend", "time", "this", "train", "dilemma", "illustr", "figur", "num", "the", "standard", "binari", "classifi", "sigmoid", "curv", "more", "formal", "call", "standard", "logist", "sigmoid", "function", "that", "convert", "input", "valu", "into", "result", "between", "num", "negat", "classif", "and", "num", "posit", "classif", "the", "tail", "end", "the", "sigmoid", "curv", "are", "veri", "flat", "which", "mean", "that", "neural", "network", "can", "lose", "their", "sens", "direct", "the", "game", "end", "far", "out", "one", "these", "tail", "for", "instanc", "the", "discrimin", "can", "alway", "tell", "that", "the", "generat", "creation", "are", "fake", "the", "discrimin", "will", "alway", "return", "num", "the", "generat", "train", "function", "the", "generat", "alway", "abl", "fool", "the", "discrimin", "the", "discrimin", "alway", "send", "num", "the", "generat", "either", "case", "learn", "stop", "for", "both", "neural", "network", "becaus", "neither", "one", "receiv", "ani", "feedback", "how", "get", "better", "innov", "num", "made", "train", "gan", "much", "more", "stabl", "the", "wasserstein", "num", "chang", "the", "type", "respons", "the", "discrimin", "send", "the", "generat", "instead", "return", "the", "sigmoid", "valu", "the", "vertic", "axi", "the", "return", "the", "input", "valu", "the", "horizont", "axi", "see", "figur", "num", "other", "word", "the", "standard", "neural", "network", "classifi", "return", "wherea", "the", "return", "this", "mean", "that", "even", "one", "the", "neural", "network", "alway", "win", "least", "the", "tini", "variat", "that", "occur", "will", "not", "get", "complet", "flatten", "out", "sigmoid", "function", "for", "exampl", "discrimin", "alway", "abl", "detect", "fake", "data", "might", "output", "valu", "num", "one", "iter", "and", "then", "num", "the", "next", "iter", "send", "these", "number", "through", "classic", "sigmoid", "function", "make", "them", "indistinguish", "num", "decim", "place", "this", "whi", "learn", "stop", "easili", "the", "simplest", "the", "generat", "can", "end", "posit", "where", "receiv", "essenti", "direct", "from", "the", "discrimin", "but", "the", "use", "the", "raw", "number", "num", "and", "num", "and", "this", "num", "chang", "can", "enough", "give", "the", "generat", "path", "for", "improv", "this", "mean", "that", "learn", "can", "continu", "even", "one", "the", "neural", "network", "overwhelm", "the", "other", "the", "basic", "train", "equat", "are", "shown", "figur", "num", "the", "term", "insid", "the", "parenthes", "repres", "the", "desir", "learn", "direct", "each", "neural", "network", "and", "these", "express", "get", "multipli", "num", "sinc", "typic", "optim", "the", "downhil", "direct", "the", "discrimin", "veri", "good", "job", "return", "high", "valu", "for", "real", "sampl", "and", "low", "valu", "for", "the", "fake", "inform", "come", "from", "the", "generat", "the", "generat", "has", "the", "opposit", "goal", "want", "the", "discrimin", "assign", "high", "valu", "other", "word", "fals", "posit", "the", "generat", "inform", "refin", "the", "critic", "the", "author", "chang", "the", "terminolog", "bit", "refer", "the", "discrimin", "neural", "network", "critic", "the", "word", "discrimin", "come", "from", "discrimin", "analysi", "and", "reflect", "classifi", "that", "separ", "data", "into", "categori", "the", "the", "other", "hand", "return", "much", "richer", "feedback", "and", "this", "somewhat", "analog", "written", "review", "movi", "critic", "divers", "result", "one", "the", "problem", "peopl", "can", "experi", "with", "gan", "that", "the", "neural", "network", "appear", "learn", "proper", "but", "the", "end", "the", "generat", "onli", "recreat", "limit", "portion", "the", "train", "distribut", "this", "occur", "becaus", "the", "generat", "can", "outsmart", "the", "train", "process", "the", "onli", "instruct", "the", "generat", "receiv", "fool", "the", "discrimin", "the", "generat", "can", "learn", "maxim", "chanc", "success", "stick", "the", "most", "heavili", "popul", "portion", "the", "train", "set", "typic", "want", "generat", "produc", "broad", "rang", "result", "and", "two", "common", "practic", "help", "with", "this", "minibatch", "discrimin", "num", "dynam", "collect", "statist", "batch", "sampl", "other", "word", "from", "multipl", "observ", "one", "more", "layer", "the", "discrimin", "neural", "network", "the", "discrimin", "then", "use", "these", "statist", "addit", "inform", "assess", "whether", "the", "data", "set", "genuin", "fake", "the", "dispers", "sampl", "veri", "differ", "between", "the", "train", "set", "and", "the", "generat", "data", "the", "discrimin", "can", "signal", "the", "generat", "that", "the", "generat", "need", "increas", "the", "rang", "result", "anoth", "option", "for", "produc", "wide", "varieti", "result", "provid", "both", "the", "generat", "and", "the", "discrimin", "with", "extra", "variabl", "that", "act", "condit", "inform", "tell", "the", "neural", "network", "which", "environ", "they", "are", "oper", "this", "major", "advantag", "when", "want", "direct", "generat", "produc", "creation", "appropri", "for", "specif", "situat", "optim", "the", "might", "requir", "some", "thought", "the", "best", "optim", "use", "sigmoid", "curv", "often", "call", "squash", "function", "becaus", "flatten", "input", "into", "rang", "num", "num", "but", "the", "can", "return", "ani", "valu", "ani", "time", "and", "thus", "output", "are", "nonstationari", "for", "this", "type", "problem", "might", "help", "use", "optim", "without", "momentum", "like", "rmsprop", "num", "least", "turn", "down", "the", "momentum", "paramet", "optim", "like", "adapt", "moment", "estim", "adam", "num", "with", "gradient", "penalti", "turn", "out", "that", "implement", "the", "wasserstein", "quit", "simpl", "elimin", "the", "sigmoid", "function", "the", "discrimin", "the", "math", "behind", "the", "requir", "that", "the", "gradient", "the", "discrimin", "can", "veri", "steep", "other", "word", "alter", "the", "input", "the", "discrimin", "neural", "network", "the", "discrimin", "output", "can", "chang", "too", "drastic", "satisfi", "this", "condit", "group", "machin", "learn", "research", "creat", "the", "gradient", "penalti", "num", "this", "techniqu", "add", "penalti", "term", "the", "discrimin", "loss", "function", "the", "gradient", "get", "too", "sharp", "and", "push", "the", "discrimin", "learn", "process", "toward", "flatter", "gradient", "the", "general", "program", "pattern", "for", "the", "gradient", "penalti", "look", "like", "this", "make", "random", "weight", "combin", "the", "real", "data", "and", "the", "generat", "manufactur", "output", "this", "way", "sampl", "much", "the", "discrimin", "function", "rang", "feasibl", "obtain", "the", "gradient", "measur", "how", "the", "discrimin", "output", "chang", "with", "respect", "this", "weight", "mixtur", "input", "this", "usual", "done", "through", "deep", "learn", "framework", "such", "tensorflow", "function", "calcul", "the", "norm", "other", "word", "the", "length", "the", "gradient", "and", "creat", "penalti", "base", "how", "far", "this", "from", "num", "add", "the", "result", "from", "num", "the", "discrimin", "loss", "function", "the", "discrimin", "then", "know", "that", "need", "learn", "job", "without", "build", "steep", "relationship", "between", "input", "and", "output", "the", "approach", "lead", "more", "stabl", "train", "and", "has", "probabl", "help", "increas", "the", "pace", "innov", "sinc", "num", "for", "instanc", "figur", "num", "show", "how", "some", "the", "most", "famous", "gan", "were", "creat", "over", "just", "the", "past", "coupl", "year", "one", "drawback", "the", "train", "time", "each", "iter", "requir", "calcul", "the", "discrimin", "gradient", "moreov", "typic", "train", "the", "discrimin", "least", "num", "time", "often", "the", "generat", "this", "becaus", "the", "excel", "feedback", "welltrain", "discrimin", "give", "the", "generat", "should", "allow", "the", "generat", "becom", "high", "effect", "with", "fewer", "learn", "iter", "there", "much", "research", "done", "how", "help", "gan", "learn", "faster", "while", "maintain", "the", "stabil", "num", "sampl", "gan", "now", "that", "cover", "the", "essenti", "gan", "and", "how", "train", "them", "look", "two", "veri", "promis", "gan", "the", "radialgan", "design", "for", "numer", "analysi", "while", "the", "stylegan", "receiv", "global", "media", "coverag", "for", "stun", "imag", "creation", "the", "radialgan", "let", "say", "are", "data", "scientist", "work", "for", "hospit", "that", "want", "evalu", "the", "efficaci", "new", "medic", "treatment", "becaus", "this", "procedur", "new", "our", "hospit", "have", "enough", "data", "for", "render", "credibl", "judgment", "are", "howev", "grant", "access", "other", "hospit", "data", "and", "this", "give", "enough", "inform", "give", "proper", "assess", "the", "new", "treatment", "but", "combin", "data", "from", "differ", "hospit", "has", "problem", "there", "distribut", "mismatch", "becaus", "the", "hospit", "servic", "veri", "differ", "popul", "peopl", "there", "also", "featur", "mismatch", "becaus", "the", "hospit", "collect", "their", "own", "data", "set", "use", "laboratori", "that", "give", "slight", "differ", "result", "and", "measur", "outcom", "vari", "way", "this", "where", "the", "radialgan", "come", "the", "radialgan", "first", "transform", "each", "data", "set", "into", "latent", "space", "which", "hold", "all", "the", "data", "from", "differ", "sourc", "uniform", "format", "the", "data", "the", "latent", "space", "can", "then", "extract", "and", "convert", "into", "the", "featur", "space", "each", "uniqu", "data", "set", "terminolog", "these", "data", "transform", "are", "refer", "domain", "transfer", "which", "when", "extract", "the", "essenti", "knowledg", "data", "set", "and", "transport", "that", "intellig", "onto", "anoth", "inform", "set", "the", "radialgan", "each", "data", "set", "has", "encod", "neural", "network", "that", "transform", "the", "data", "into", "the", "homogen", "structur", "the", "latent", "space", "everi", "data", "sourc", "also", "has", "decod", "which", "with", "generat", "that", "convert", "inform", "from", "the", "latent", "space", "into", "form", "consist", "with", "the", "data", "set", "each", "these", "decod", "gan", "has", "discrimin", "that", "confirm", "the", "inform", "come", "out", "the", "latent", "space", "match", "the", "properti", "the", "target", "data", "domain", "this", "setup", "make", "sure", "that", "the", "domain", "transfer", "inform", "work", "both", "direct", "and", "revers", "this", "concept", "call", "cycl", "consist", "origin", "with", "the", "cyclegan", "num", "and", "has", "becom", "crucial", "part", "mani", "model", "train", "all", "these", "neural", "network", "simultan", "and", "onc", "the", "learn", "process", "complet", "can", "use", "the", "radialgan", "creat", "augment", "data", "set", "shown", "figur", "num", "construct", "our", "enhanc", "data", "set", "run", "each", "the", "other", "data", "set", "through", "their", "encod", "transfer", "that", "knowledg", "into", "the", "latent", "space", "then", "extract", "that", "intellig", "from", "the", "latent", "space", "use", "our", "decod", "and", "append", "the", "transform", "inform", "our", "origin", "data", "set", "the", "result", "new", "larger", "data", "set", "that", "bolster", "inform", "from", "varieti", "sourc", "but", "which", "match", "the", "characterist", "the", "domain", "are", "work", "the", "stylegan", "the", "spectacular", "new", "stylegan", "combin", "two", "innov", "the", "progress", "num", "progan", "and", "neural", "style", "transfer", "num", "the", "progan", "begin", "develop", "tini", "imag", "numxnum", "numxnum", "pixel", "until", "this", "pictur", "consid", "realist", "the", "progan", "discrimin", "onc", "this", "learn", "complet", "the", "progan", "gentl", "add", "higherresolut", "layer", "that", "also", "need", "train", "this", "process", "continu", "until", "the", "progan", "can", "creat", "numxnumpixel", "imag", "with", "amaz", "realism", "the", "stylegan", "build", "the", "progan", "bring", "some", "the", "most", "success", "element", "neural", "style", "transfer", "the", "origin", "style", "transfer", "work", "copi", "the", "neural", "network", "layer", "correl", "style", "imag", "onto", "content", "imag", "this", "requir", "optim", "process", "that", "can", "take", "too", "long", "use", "mani", "realtim", "applic", "research", "repeat", "made", "improv", "the", "classic", "neural", "style", "transfer", "and", "the", "stylegan", "use", "one", "the", "more", "recent", "style", "transfer", "method", "call", "adapt", "instanc", "normal", "adain", "num", "adapt", "instanc", "normal", "involv", "optim", "and", "therefor", "veri", "fast", "way", "transfer", "style", "between", "imag", "also", "veri", "flexibl", "that", "can", "transfer", "style", "between", "ani", "imag", "includ", "those", "that", "neural", "network", "have", "never", "seen", "befor", "becaus", "they", "aren", "ani", "train", "set", "appli", "adain", "convolut", "neural", "network", "layer", "content", "imag", "simpl", "process", "normal", "the", "layer", "subtract", "mean", "and", "divid", "standard", "deviat", "scale", "this", "normal", "layer", "match", "the", "standard", "deviat", "the", "style", "layer", "shift", "the", "layer", "the", "averag", "valu", "the", "style", "layer", "this", "sound", "more", "complic", "than", "realli", "all", "chang", "the", "mean", "and", "varianc", "imag", "neural", "network", "layer", "match", "the", "mean", "and", "varianc", "style", "imag", "the", "imag", "whose", "style", "want", "emul", "further", "refin", "the", "stylegan", "and", "adain", "could", "includ", "method", "like", "histogram", "match", "which", "would", "transfer", "more", "style", "detail", "but", "would", "also", "veri", "fast", "calcul", "the", "stylegan", "somewhat", "complex", "architectur", "that", "incorpor", "mani", "neural", "network", "tool", "and", "trick", "that", "have", "been", "develop", "over", "the", "past", "sever", "year", "but", "core", "the", "stylegan", "combin", "the", "high", "effect", "progan", "with", "the", "success", "neural", "style", "transfer", "creat", "imag", "that", "are", "realist", "they", "could", "fundament", "chang", "the", "relationship", "peopl", "have", "with", "the", "news", "and", "entertain", "media", "conclus", "the", "stylegan", "strike", "exampl", "how", "generat", "adversari", "network", "could", "transform", "the", "way", "much", "the", "media", "produc", "content", "and", "alter", "how", "consum", "interpret", "the", "inform", "they", "see", "and", "hear", "the", "radialgan", "the", "other", "hand", "show", "how", "the", "featur", "and", "advantag", "gan", "can", "use", "bolster", "numer", "data", "analysi", "these", "are", "two", "exampl", "thrive", "communiti", "hundr", "innov", "gan", "that", "can", "use", "for", "just", "about", "ani", "purpos", "one", "can", "imagin", "some", "the", "result", "see", "from", "gan", "look", "like", "they", "come", "from", "differ", "centuri", "and", "one", "thing", "certain", "pioneer", "techniqu", "like", "gan", "are", "rapid", "chang", "our", "relationship", "technolog", "and", "each", "other", "refer", "num", "tero", "karra", "samuli", "lain", "and", "timo", "aila", "stylebas", "generat", "architectur", "for", "generat", "adversari", "network", "arxivorgabsnum", "num", "jinsung", "yoon", "jame", "jordon", "and", "mihaela", "van", "der", "schaar", "radialgan", "leverag", "multipl", "dataset", "improv", "targetspecif", "predict", "model", "use", "generat", "adversari", "network", "arxivorgabsnum", "num", "ian", "goodfellow", "jean", "pougetabadi", "mehdi", "mirza", "bing", "david", "wardefarley", "sherjil", "ozair", "aaron", "courvill", "and", "yoshua", "bengio", "generat", "adversari", "network", "arxivorgabsnum", "num", "martin", "arjovski", "soumith", "chintala", "and", "l\u00e9on", "bottou", "wasserstein", "arxivorgabsnum", "num", "tim", "saliman", "ian", "goodfellow", "wojciech", "zaremba", "vicki", "cheung", "alec", "radford", "and", "chen", "improv", "techniqu", "for", "train", "gan", "arxivorgabsnum", "num", "geoffrey", "hinton", "neural", "network", "for", "machin", "learn", "slide", "num", "rprop", "use", "onli", "the", "sign", "the", "gradient", "wwwcstorontoedu", "numetijmencscnumslideslectureslideslecnumpdf", "num", "diederik", "kingma", "and", "jimmi", "adam", "method", "for", "stochast", "optim", "arxivorgabsnum", "num", "ishaan", "gulrajani", "faruk", "ahm", "martin", "arjovski", "vincent", "dumoulin", "and", "aaron", "courvill", "improv", "train", "wasserstein", "gan", "arxivorgabsnum", "num", "lar", "mesched", "andrea", "geiger", "and", "sebastian", "nowozin", "which", "train", "method", "for", "gan", "actual", "converg", "arxivorgabsnum", "num", "junyan", "zhu", "taesung", "park", "phillip", "isola", "and", "alexei", "efro", "unpair", "imagetoimag", "translat", "use", "cycleconsist", "adversari", "network", "arxivorgabsnum", "num", "tero", "karra", "timo", "aila", "samuli", "lain", "and", "jaakko", "lehtinen", "progress", "grow", "gan", "for", "improv", "qualiti", "stabil", "and", "variat", "arxivorgabsnum", "num", "leon", "gati", "alexand", "ecker", "and", "matthia", "bethg", "neural", "algorithm", "artist", "style", "arxivorgabsnum", "num", "xun", "huang", "and", "serg", "belongi", "arbitrari", "style", "transfer", "realtim", "with", "adapt", "instanc", "normal", "arxivorgabsnum", "origin", "repost", "with", "permiss", "bio", "matt", "hergott", "quantit", "research", "miabella", "resourc", "onlin", "and", "webbas", "analyt", "data", "mine", "data", "scienc", "machin", "learn", "educ", "softwar", "for", "analyt", "data", "scienc", "data", "mine", "and", "machin", "learn", "relat", "the", "rise", "generat", "adversari", "network", "which", "face", "real", "favorit", "mindblow", "machin", "learningai", "breakthrough"], "timestamp_scraper": 1556373893.542698, "title": "Generative Adversarial Networks \u2013 Key Milestones and State of the Art", "read_time": 912.0, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/matthew-j-hergott/\">Matt Hergott</a>, MiaBella AI</b>.</p>\n<p>Is December 12, 2018, a day the world changed forever? That Wednesday, a team of researchers at NVIDIA released a dazzling new artificial intelligence design called the StyleGAN.<strong>[1]</strong>\u00a0The StyleGAN is a deep learning system based on the idea of a generative adversarial network (GAN), and this model generates ultra-realistic images of people, cars, and households.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*IUjB3NcYRi467MT8gaKQnQ.png\" width=\"60%\"/></p>\n<p>Inventions like this could change the way humankind interacts with nearly all media. For instance, when people see images in the news, their first reaction could be to try to determine whether what they are looking at is real or fake.</p>\n<p>GANs are some of the more futuristic AI designs, and people have many questions about them: What are GANs? Will I be able to understand them? Can I use GANs for my business analytics, or are they only good at creating images?</p>\n<p>This article will try to answer some of these questions. We\u2019ll start with an overview of GANs, then we\u2019ll discuss some challenges in helping GANs to learn. After that, we\u2019ll examine two promising GANs: the RadialGAN,<strong>[2]</strong>which is designed for numbers, and the StyleGAN, which is focused on images.</p>\n<h3>The Generative Adversarial Network\u00a0(GAN)</h3>\n<p>The original GAN<strong>[3]</strong>\u00a0was created by Ian Goodfellow, who described the GAN architecture in a paper published in mid-2014. A GAN consists of two neural networks playing a game with each other. The\u00a0<em>discriminator\u00a0</em>tries to determine whether information is real or fake. The other neural network, called a\u00a0<em>generator</em>, tries to create data that the discriminator thinks is real.</p>\n<p><img class=\"alignnone\" src=\"https://cdn-images-1.medium.com/max/1600/1*--AtNcFUNb_ts_uihuSJ2g.png\" width=\"100%\"/></p>\n<p>This concept is depicted in Figure 1. The neural network at the top is the discriminator, and its task is to distinguish the training set\u2019s real information from the generator\u2019s creations. In the simplest GAN structure, the generator starts with random data and learns to transform this noise into information that matches the distribution of the real data.</p>\n<p>The generator never sees the genuine data; it must learn to create realistic information by receiving feedback from the discriminator. This is called\u00a0<em>adversarial loss</em>, and when implemented correctly it works surprisingly well. In fact, regularization techniques such as dropout layers are often used in GANs because the generator can overfit the training set through this entirely indirect learning process.</p>\n<p>The longer these two neural networks play this game, the more they sharpen each other\u2019s skills. The discriminator becomes very good at detecting fake data while the generator learns to produce information that is indistinguishable from what is observed in the real world.</p>\n<p>When we end up with two GAN neural networks that are very good at what they do, how could we use them? A trained discriminator can be used for detecting abnormalities, outliers, and anything out of the ordinary. This could be very valuable in fields such as cybersecurity, radiology, astronomy, and manufacturing.</p>\n<p>A skilled generator is used for making creations. Once the generator learns the distribution of the training data, we can sample the generator an unlimited number of times for realistic outputs such as images, language,\u00a0<a data-href=\"https://www.news-medical.net/news/20170209/Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.aspx\" href=\"https://www.news-medical.net/news/20170209/Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.aspx\">pharmaceuticals</a>, numerical simulations, and just about anything else one can imagine.</p>\n<h3>Wasserstein GAN\u00a0(WGAN)</h3>\n<p>The original GAN created a lot of excitement when it was first introduced. But there was a problem that showed up immediately: if one of the neural networks started to dominate the other in the GAN game, learning would stop for both. The GAN neural networks are called adversaries, but we want to keep one side from winning so they both can learn for an extended time.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*UCMD_kWREM0GVWKIYEPsJA.png\" width=\"60%\"/></p>\n<p>This training dilemma is illustrated in Figure 2. The standard binary classifier is a sigmoid curve\u200a\u2014\u200amore formally called a standard logistic sigmoid function\u200a\u2014\u200athat converts an input value into a result between 0 (a negative classification) and 1 (a positive classification).\u00a0<span data-creator-ids=\"anon\">The tail ends of the sigmoid curve are very flat, which means that neural networks can lose their sense of direction if the GAN game ends up far out on one of these tails.</span></p>\n<p>For instance, if the discriminator can always tell that the generator\u2019s creations are fake, the discriminator will always return a 0 to the generator\u2019s training function. If the generator is always able to fool the discriminator, the discriminator always sends a 1 to the generator. In either case, learning stops for both neural networks because neither one is receiving any feedback on how to get better.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*rncFBOe8b0QKeDIactG_Wg.png\" width=\"60%\"/></p>\n<p>An innovation in 2017 made training GANs much more stable. The Wasserstein GAN<strong>[4]</strong>(WGAN) changes the type of response the discriminator sends to the generator. Instead of returning the sigmoid value of the vertical axis, the WGAN returns the input value of the horizontal axis (see Figure 3). In other words, the standard neural network classifier returns\u00a0<strong>f(x)</strong>, whereas the WGAN returns\u00a0<strong>x</strong>.</p>\n<p>This means that even if one of the neural networks is always winning, at least the tiny variations that do occur will not get completely flattened out by a sigmoid function. For example, if a GAN discriminator is always able to detect fake data, it might output a value of -100 on one iteration and then -99 on the next iteration. Sending these numbers through a classic sigmoid function makes them indistinguishable at 40+ decimal places. This is why learning stops so easily in the simplest GAN: the generator can end up in a position where it is receiving essentially no direction from the discriminator.</p>\n<p>But the WGAN uses the raw numbers (-100 and -99), and this 1% change can be enough to give the generator a path for improvement. This means that learning can continue even if one of the neural networks is overwhelming the other.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*Il4k2l_1yZbQuJhj7vwtMg.png\" width=\"60%\"/></p>\n<p>The basic WGAN training equations are shown in Figure 4. The terms inside the parentheses represent the desired learning direction of each neural network, and these expressions get multiplied by -1 since we typically optimize in the downhill direction.</p>\n<p>If the discriminator is very good at its job, it returns high values for real samples and low values for the fake information coming from the generator. The generator has the opposite goal: it wants the discriminator to assign high values\u200a\u2014\u200ain other words, false positives\u200a\u2014\u200ato the generated information.</p>\n<h3>WGAN Refinements</h3>\n<h3>The Critic</h3>\n<p>The WGAN authors changed the GAN terminology a bit by referring to the discriminator neural network as a\u00a0<em>critic</em>. The word discriminator comes from\u00a0<em>discriminant analysis</em>\u00a0and reflects a classifier that separates data into categories. The WGAN, on the other hand, returns much richer feedback, and this is somewhat analogous to a written review by a movie critic.</p>\n<h3>Diverse Results</h3>\n<p>One of the problems people can experience with GANs is that the neural networks appear to be learning properly, but in the end, the generator only re-creates a limited portion of the training distribution. This occurs because the generator can outsmart the training process. If the only instruction the generator receives is to fool the discriminator, the generator can learn to maximize its chance of success by sticking to the most heavily populated portion of the training set.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*amvRQapWAp_jJ9Qe6fcvrg.png\" width=\"60%\"/></p>\n<p>We typically want a generator to produce a broad range of results, and two common practices help with this.</p>\n<p><em>Minibatch discrimination</em><strong>[5]</strong>dynamically collects statistics on a batch of samples\u200a\u2014\u200ain other words, from multiple observations\u200a\u2014\u200aat one or more layers of the discriminator neural network. The discriminator then uses these statistics as additional information in its assessment of whether the data set is genuine or fake. If the dispersion of samples is very different between the training set and the generated data, the discriminator can signal to the generator that the generator needs to increase the range of its results.</p>\n<p>Another option for producing a wide variety of results is to provide both the generator and the discriminator with extra variables that act as\u00a0<em>conditioning information</em>\u00a0to tell the neural networks which environment they are operating in. This is a major advantage when we want to direct a generator to produce creations appropriate for a specific situation.</p>\n<h3>Optimizers</h3>\n<p>The WGAN might require some thought as to the best optimizer to use. A sigmoid curve is often called a \u201csquashing\u201d function because it flattens its inputs into a range of 0 to 1.</p>\n<p>But the WGAN can return any value at any time, and thus its outputs are\u00a0<em>nonstationary</em>. For this type of problem, it might be helpful to use optimizers without momentum (like RMSProp<strong>[6]</strong>) or at least turn down the momentum parameter of an optimizer like adaptive moment estimation (Adam<strong>[7]</strong>).</p>\n<h3>WGAN with Gradient Penalty (WGAN-GP)</h3>\n<p>It turns out that implementing the Wasserstein GAN isn\u2019t quite as simple as eliminating the sigmoid function in the discriminator. The math behind the WGAN requires that the gradients of the discriminator can\u2019t be very steep. In other words, if we alter the inputs to the discriminator neural network, the discriminator\u2019s output can\u2019t change too drastically.</p>\n<p>To satisfy this condition, a group of machine learning researchers created the gradient penalty.<strong>[8]</strong>\u00a0This technique adds a penalty term to the discriminator\u2019s loss function if the gradients get too sharp, and it pushes the discriminator\u2019s learning process toward flatter gradients.</p>\n<p>The general programming pattern for the gradient penalty looks like this:</p>\n<ol>\n<li>Make a randomly weighted combination of the real data and the generator\u2019s manufactured output; this is a way to sample as much of the discriminator\u2019s function range as is feasible.</li>\n<li>Obtain the gradient by measuring how the discriminator\u2019s output changes with respect to this weighted mixture of inputs. This is usually done through a deep learning framework such as TensorFlow\u2019s\u00a0<a data-href=\"https://www.tensorflow.org/api_docs/python/tf/gradients\" href=\"https://www.tensorflow.org/api_docs/python/tf/gradients\">gradients()</a>function.</li>\n<li>Calculate the norm\u200a\u2014\u200ain other words, the length\u200a\u2014\u200aof the gradient and create a penalty based on how far this is from 1.</li>\n<li>Add the result from #3 to the discriminator\u2019s loss function. The discriminator then knows that it needs to learn its job without building a steep relationship between its inputs and output.</li>\n</ol>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*u2IG4KkEBotf47I3TbZwEw.png\" width=\"60%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"3908\">The WGAN-GP approach leads to more stable GAN training and has probably helped to increase the pace of GAN innovation since 2017. For instance, Figure 6 shows how some of the most famous GANs were created over just the past couple of years.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"b901\">One drawback to the WGAN-GP is its training time. Each iteration requires a calculation of the discriminator\u2019s gradient. Moreover, it is typical to train the discriminator at least 5 times as often as the generator. This is because the excellent feedback a well-trained discriminator gives to the generator should allow the generator to become highly effective with fewer learning iterations.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"6d2d\">There is much research being done on how to help GANs learn faster while maintaining the stability of a WGAN-GP.<strong class=\"markup--strong markup--p-strong\">[9]</strong></p>\n<h3 class=\"graf graf--h3 graf-after--p\" id=\"227e\">Sample GANs</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"e537\">Now that we\u2019ve covered the essentials of GANs and how to train them, we\u2019ll look at two very promising GANs. The RadialGAN is designed for numerical analysis, while the StyleGAN received global media coverage for its stunning image creations.</p>\n<h3 class=\"graf graf--h3 graf-after--p\" id=\"408c\">The RadialGAN</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"e384\">Let\u2019s say we are data scientists working for a hospital that wants to evaluate the efficacy of a new medical treatment. Because this procedure is new, our hospital doesn\u2019t have enough data for us to render a credible judgment. We are, however, granted access to other hospitals\u2019 data, and this gives us enough information to give a proper assessment of the new treatment.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"07a3\">But combining data from different hospitals has problems. There is\u00a0<em class=\"markup--em markup--p-em\">distribution mismatch</em>\u00a0because the hospitals service very different populations of people. There is also\u00a0<em class=\"markup--em markup--p-em\">feature mismatch</em>\u00a0because the hospitals collect their own data sets, use laboratories that give slightly different results, and measure outcomes in varying ways.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"4044\">This is where the RadialGAN comes in. The RadialGAN first transforms each data set into a\u00a0<em class=\"markup--em markup--p-em\">latent space</em>, which holds all the data from different sources in a uniform format. The data in the latent space can then be extracted and converted into the feature space of each unique data set.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*guRpKNXKZJXzqltSvSKEEg.png\" width=\"60%\"/></p>\n<p>In GAN terminology, these data transformations are referred to as\u00a0<em>domain transfer</em>, which is when we extract the essential knowledge of a data set and transport that intelligence onto another information set.</p>\n<p>In the RadialGAN, each data set has an\u00a0<em>encoder\u00a0</em>neural network that transforms the data into the homogeneous structure of the latent space.</p>\n<p>Every data source also has a\u00a0<em>decoder</em>, which is a GAN with a generator that converts information from the latent space into a form consistent with the data set. Each of these decoder GANs has a discriminator that confirms the information coming out of the latent space matches the properties of the target data domain.</p>\n<p>This setup makes sure that the domain transfer of information works in both directions and is reversible. This concept is called\u00a0<em>cycle consistency</em>. It originated with the CycleGAN,<strong>[10]</strong>\u00a0and it has become a crucial part of many GAN models.</p>\n<p>We train all these neural networks simultaneously, and once the learning process is complete, we can use the RadialGAN to create an augmented data set as shown in Figure 8.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*UJ8RZi1DJYuWFV5OxxasxA.png\" width=\"60%\"/></p>\n<p>To construct our enhanced data set, we run each of the other data sets through their encoders to transfer that knowledge into the latent space. Then we extract that intelligence from the latent space using our decoder and append the transformed information to our original data set.</p>\n<p>The result is a new, larger data set that is bolstered by information from a variety of sources, but which matches the characteristics of the domain we are working in.</p>\n<h3>The StyleGAN</h3>\n<p>The spectacular new StyleGAN combines two innovations: the Progressive GAN<strong>[11]</strong>\u00a0(ProGAN) and neural style transfer.<strong>[12]</strong></p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*JIJZ2CiM_SiMTtlsiK1F1Q.png\" width=\"60%\"/></p>\n<p>The ProGAN begins by developing a tiny image of 4x4 or 8x8 pixels until this picture is considered realistic by the ProGAN discriminator.</p>\n<p>Once this learning is complete, the ProGAN gently adds a higher-resolution layer that also needs to be trained. This process continues until the ProGAN can create 1024x1024-pixel images with amazing realism.</p>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*IEjyn7imY1eb1evQz2C5YQ.png\" width=\"60%\"/></p>\n<p>The StyleGAN builds on the ProGAN by bringing in some of the most successful elements of neural style transfer. The original style transfer works by copying the neural network layer correlations of a style image onto a content image. This requires an optimization process that can take too long to be useful in many real-time applications.</p>\n<p>Researchers repeatedly made improvements to the classic neural style transfer, and the StyleGAN uses one of the more recent style transfer methods called adaptive instance normalization (AdaIN).<strong>[13]</strong></p>\n<p>Adaptive instance normalization doesn\u2019t involve an optimization, and it\u2019s therefore a very fast way to transfer styles between images. It\u2019s also very flexible in that it can transfer styles between any images, including those that neural networks have never seen before because they aren\u2019t in any training set.</p>\n<p>Applying AdaIN to a convolutional neural network layer of a content image is a simple process:</p>\n<ol>\n<li>Normalize the layer by subtracting its mean and dividing by its standard deviation.</li>\n<li>Scale this normalized layer to match the standard deviation of the style layer.</li>\n<li>Shift the layer by adding in the average value of the style layer.</li>\n</ol>\n<p><img class=\"alignleft\" src=\"https://cdn-images-1.medium.com/max/1200/1*tmzVhW0gs0KQnSX-RDPbUg.png\" width=\"60%\"/></p>\n<p>This sounds more complicated than it really is. All we\u2019re doing is changing the mean and variance of an image\u2019s neural network layers to match the mean and variance of a style image (i.e., the image whose style we want to emulate).</p>\n<p>Further refinements to the StyleGAN and AdaIN could include methods like histogram matching, which would transfer more style detail but would also be very fast to calculate.</p>\n<p>The StyleGAN is a somewhat complex architecture that incorporates many neural network tools and tricks that have been developed over the past several years. But at its core, the StyleGAN combines the highly effective ProGAN with the successes of neural style transfer to create images that are so realistic they could fundamentally change the relationship people have with the news and entertainment media.</p>\n<h3>Conclusion</h3>\n<p>The StyleGAN is a striking example of how generative adversarial networks could transform the way much of the media produces its content and alter how consumers interpret the information they see and hear. The RadialGAN, on the other hand, shows how the features and advantages of GANs can be used to bolster numerical data analysis.</p>\n<p>These are two examples of a thriving community of hundreds of innovative GANs that can be used for just about any purpose one can imagine.</p>\n<p>Some of the results we\u2019re seeing from GANs look like they come from a different century, and one thing is certain: pioneering AI techniques like GANs are rapidly changing our relationship to technology, and to each other.</p>\n<h3>References</h3>\n<p><strong>[1]</strong>\u00a0Tero Karras, Samuli Laine, and Timo Aila</p>\n<p>A Style-Based Generator Architecture for Generative Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1812.04948\" href=\"https://arxiv.org/abs/1812.04948\">arxiv.org/abs/1812.04948</a></p>\n<p><strong>[2]</strong>\u00a0Jinsung Yoon, James Jordon, and Mihaela van der Schaar</p>\n<p>RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1802.06403\" href=\"https://arxiv.org/abs/1802.06403\">arxiv.org/abs/1802.06403</a></p>\n<p><strong>[3]</strong>\u00a0Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio</p>\n<p>Generative Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1406.2661\" href=\"https://arxiv.org/abs/1406.2661\">arxiv.org/abs/1406.2661</a></p>\n<p><strong>[4]</strong>\u00a0Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou</p>\n<p>Wasserstein GAN</p>\n<p><a data-href=\"https://arxiv.org/abs/1701.07875\" href=\"https://arxiv.org/abs/1701.07875\">arxiv.org/abs/1701.07875</a></p>\n<p><strong>[5]</strong>\u00a0Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen</p>\n<p>Improved Techniques for Training GANs</p>\n<p><a data-href=\"https://arxiv.org/abs/1606.03498\" href=\"https://arxiv.org/abs/1606.03498\">arxiv.org/abs/1606.03498</a></p>\n<p><strong>[6]\u00a0</strong>Geoffrey Hinton</p>\n<p>Neural Networks for Machine Learning, slide #27: \u201crprop: Using only the sign of the gradient\u201d</p>\n<p><a data-href=\"http://www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf\" href=\"http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\">www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf</a></p>\n<p><strong>[7]</strong>\u00a0Diederik P. Kingma and Jimmy Ba</p>\n<p>Adam: A Method for Stochastic Optimization</p>\n<p><a data-href=\"https://arxiv.org/abs/1412.6980\" href=\"https://arxiv.org/abs/1412.6980\">arxiv.org/abs/1412.6980</a></p>\n<p><strong>[8]</strong>\u00a0Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville</p>\n<p>Improved Training of Wasserstein GANs</p>\n<p><a data-href=\"https://arxiv.org/abs/1704.00028\" href=\"https://arxiv.org/abs/1704.00028\">arxiv.org/abs/1704.00028</a></p>\n<p><strong>[9]\u00a0</strong>Lars Mescheder, Andreas Geiger, and Sebastian Nowozin</p>\n<p>Which Training Methods for GANs do Actually Converge?</p>\n<p><a data-href=\"https://arxiv.org/abs/1801.04406\" href=\"https://arxiv.org/abs/1801.04406\">arxiv.org/abs/1801.04406</a></p>\n<p><strong>[10]</strong>\u00a0Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros</p>\n<p>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</p>\n<p><a data-href=\"https://arxiv.org/abs/1703.10593\" href=\"https://arxiv.org/abs/1703.10593\">arxiv.org/abs/1703.10593</a></p>\n<p><strong>[11]\u00a0</strong>Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen</p>\n<p>Progressive Growing of GANs for Improved Quality, Stability, and Variation</p>\n<p><a data-href=\"https://arxiv.org/abs/1710.10196\" href=\"https://arxiv.org/abs/1710.10196\">arxiv.org/abs/1710.10196</a></p>\n<p><strong>[12]</strong>\u00a0Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge</p>\n<p>A Neural Algorithm of Artistic Style</p>\n<p><a data-href=\"https://arxiv.org/abs/1508.06576\" href=\"https://arxiv.org/abs/1508.06576\">arxiv.org/abs/1508.06576</a></p>\n<p><strong>[13]</strong>\u00a0Xun Huang and Serge Belongie</p>\n<p>Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</p>\n<p><a data-href=\"https://arxiv.org/abs/1703.06868\" href=\"https://arxiv.org/abs/1703.06868\">arxiv.org/abs/1703.06868</a></p>\n<p><a href=\"https://medium.com/datadriveninvestor/a-leap-into-the-future-generative-adversarial-networks-96a780ed8ee6\">Original</a>. Reposted with permission.</p>\n<p><strong>Bio</strong>:\u00a0<a href=\"https://www.linkedin.com/in/matthew-j-hergott/\">Matt Hergott</a>\u00a0is a Quantitative Researcher at MiaBella AI.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html\">The Rise of Generative Adversarial Networks</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html\">Which Face is Real?</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html\">My favorite mind-blowing Machine Learning/AI breakthroughs</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}