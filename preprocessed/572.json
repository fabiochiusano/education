{"content": "By Madison May, indico . Deploying machine learning models has always been a struggle. Most of the software industry has adopted the use of container engines like Docker for deploying code to production, but since accessing hardware resources like GPUs from Docker was difficult and required hacky, driver specific workarounds, the machine learning community has shied away from this option. With the recent release of NVIDIA\u2019s\u00a0 nvidia-docker \u00a0tool, however, accessing GPUs from within Docker is a breeze, and we\u2019re already reaping the benefits here at indico. In this tutorial we\u2019ll walk you through setting up\u00a0 nvidia-docker \u00a0so you too can deploy machine learning models with ease. Before we get into the details however, let\u2019s talk briefly about why using Docker for your next data science project may be a good choice. There is certainly a learning curve for the tools in the Docker ecosystem, but the benefits are worth the effort. No inconsistencies between team environment configurations:Software configuration is always a pain. Docker\u2019s configure once, run anywhere model means your teammates will have to worry less about environment setup and can focus more on writing code and building machine learning models. Reliable deployments:Fewer bugs crop up in production when you can be assured that your development environment is identical to your production environment. Git-like tool for environment configuration:If something does go wrong in production, reverting to a previous Docker image ensures you can quickly get back to a functional state. Why is a special solution needed for using GPUs within Docker? \u00a0 Docker is designed to be hardware and platform agnostic. GPUs are specialized hardware that is not necessarily available on every host. Because of this, the Docker binary does not include GPU support out of the box, and requires a fair amount of configuration to get things working properly. When we first started using Docker in production and needed to enable access to GPU devices from within the container, we had to roll our own solution. It was educational to have to understand the mechanisms by which hardware like GPUs are exposed to an operating system (primarily the\u00a0 /dev \u00a0block), but we ended up with a solution that was not portable and required that the host\u2019s NVIDIA driver was identical to a second copy of the driver installed within the container. Whenever we updated our NVIDIA drivers to support newer CUDA versions, we had to make a breaking change to our Docker image in order to ensure drivers matched exactly. Thankfully, the nice folks at NVIDIA have rectified this problem by releasing\u00a0 nvidia-docker , a tool for configuring docker to allow GPU access from within containers. How does\u00a0 nvidia-docker \u00a0work? \u00a0 nvidia-docker \u00a0takes the following steps to get CUDA working within your container: It attaches the GPU device blocks to your container as Docker volumes (/dev/nvidia0, /dev/nvidiactl, etc.) It mounts the device drivers on your host within the Docker container This means that as long as you have a functional NVIDIA driver on your host and a CUDA version recent enough to support your driver is installed within your container, you should be able to execute CUDA code from your running Docker container. Importantly, the Docker container can also be run in another environment with different driver versions, making it easy to build once and then run anywhere. How do I install\u00a0 nvidia-docker ? \u00a0 Use of\u00a0 nvidia-docker \u00a0requires: Linux kernel > 3.10 NVIDIA GPU with Architecture > Fermi (2.1) NVIDIA drivers >= 340.29 with binary nvidia-modprobe Docker >= 1.9 If you already meet these requirements, installation of\u00a0 nvidia-docker \u00a0is as easy as installing a\u00a0 .deb file \u00a0(on Ubuntu 14.04): bash\r # Install nvidia-docker and nvidia-docker-plugin\r wget -P /tmp /NVIDIA/nvidia-docker/releases/download/v1.0.0-rc.3/nvidia-docker_1.0.0.rc.3-1_amd64.deb\r sudo dpkg -i /tmp/nvidia-docker*.deb && rm /tmp/nvidia-docker*.deb If you already have a working\u00a0 nvidia-docker \u00a0on your host machine, you can try out\u00a0 nvidia-docker \u00a0immediately by running the\u00a0 nvidia/cuda \u00a0Docker image provided by NVIDIA: # Test nvidia-smi\r nvidia-docker run --rm nvidia/cuda nvidia-smi Depending on your driver version, you may need to specify a different version of CUDA to run when testing your installation: # Test nvidia-smi\r nvidia-docker run --rm nvidia/cuda:7.5 nvidia-smi If all is well, you should see something like: $ nvidia-docker run --rm nvidia/cuda:7.5 nvidia-smi\r 7.5: Pulling from nvidia/cuda\r bf5d46315322: Already exists\r 9f13e0ac480c: Already exists\r e8988b5b3097: Already exists\r 40af181810e7: Already exists\r e6f7c7e5c03e: Already exists\r 261ad237e477: Already exists\r 83d2db6fdab9: Pull complete\r e8e8d0e851cd: Pull complete\r c0000b849c19: Pull complete\r 180b04fcdc2d: Pull complete\r 1e5b85df3d02: Pull complete\r Digest: sha256:c601c6902928d62c79f2cbf90bf07477b666e28b51b094b3a10924ec7dacde8b\r Status: Downloaded newer image for nvidia/cuda:7.5\r Fri Nov 4 16:34:00 2016 \r +------------------------------------------------------+ \r | NVIDIA-SMI 352.93 Driver Version: 352.93 | \r |-------------------------------+----------------------+----------------------+\r | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\r | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\r |===============================+======================+======================|\r | 0 GeForce GTX 760 Off | 0000:01:00.0 N/A | N/A |\r | 17% 31C P8 N/A / N/A | 172MiB / 4095MiB | N/A Default |\r +-------------------------------+----------------------+----------------------+\r \r +-----------------------------------------------------------------------------+\r | Processes: GPU Memory |\r | GPU PID Type Process name Usage |\r |=============================================================================|\r | 0 Not Supported |\r +-----------------------------------------------------------------------------+ For distributions other than Ubuntu or to install\u00a0 nvidia-docker \u00a0from source, check out the\u00a0 nvidia-docker \u00a0quick start guide \u00a0and\u00a0 installation documentation . Now let\u2019s use\u00a0 nvidia-docker \u00a0for something more substantial. We\u2019ll be setting up and running the\u00a0 \u201cneural doodle\u201d project \u00a0from Alex Champanard ( @alexjc ). The project takes rough sketches and turns them into artistic masterpieces using techniques from the\u00a0 Semantic Style Transfer paper . Alex has already done the hard work of providing us with a Docker image of his project, and has gone to the trouble of installing the necessary CUDA drivers in the Docker image as well. Normally we\u2019d need to have a functioning installation of CUDA, Theano, and the lasagne library in order to run his code, but since he\u2019s provided us with a Docker image we should be up and running in just a few minutes. git clone /alexjc/neural-doodle.git && cd neural-doodle\r alias doodle=\"nvidia-docker run -v ($pwd)/samples:/nd/samples -v ($pwd)/frames:/nd/frames -it alexjc/neural-doodle:gpu\"\r \r # paint a photo of a coastline in the style of Monet\r doodle --style samples/Monet.jpg --output samples/Coastline.png --device=gpu --iterations=40 This example takes this original Monet painting: and this sketch of a similar coastline: and creates a new work of art in style similar to the original Monet: Pretty cool, huh? Let\u2019s walk through the\u00a0 neural-doodle \u00a0dockerfile and the\u00a0 doodle \u00a0alias to remove some of the magic behind what we\u2019ve just done. The dockerfile used to build the\u00a0 alexjc/neural-doodle:gpu \u00a0image is below: FROM nvidia/cuda:7.5-cudnn4-devel\r \r # Install dependencies\r RUN apt-get -qq update && \\\r apt-get -qq install --assume-yes \\\r \"module-init-tools\" \\\r \"build-essential\" \\\r \"cmake\" \\\r \"git\" \\\r \"wget\" \\\r \"libopenjpeg2\" \\\r \"libopenblas-dev\" \\\r \"liblapack-dev\" \\\r \"libjpeg-dev\" \\\r \"libtiff5-dev\" \\\r \"zlib1g-dev\" \\\r \"libfreetype6-dev\" \\\r \"liblcms2-dev\" \\\r \"libwebp-dev\" \\\r \"gfortran\" \\\r \"pkg-config\" \\\r \"python3\" \\\r \"python3-dev\" \\\r \"python3-pip\" \\\r \"python3-numpy\" \\\r \"python3-scipy\" \\\r \"python3-matplotlib\" \\\r \"python3-six\" \\\r \"python3-networkx\" \\\r \"python3-tk\" && \\\r rm -rf /var/lib/apt/lists/* && \\\r python3 -m pip -q install \"cython\"\r \r # Install requirements before copying project files\r WORKDIR /nd\r COPY requirements.txt .\r RUN python3 -m pip -q install -r \"requirements.txt\"\r \r # Copy only required project files\r COPY doodle.py .\r \r # Get a pre-trained neural network (VGG19)\r RUN wget -q \"/alexjc/neural-doodle/releases/download/v0.0/vgg19_conv.pkl.bz2\"\r \r # Set an entrypoint to the main doodle.py script\r ENTRYPOINT [\"python3\", \"doodle.py\", \"--device=gpu\"] Hey, this isn\u2019t so bad. The dockerfile Alex used is based off of an official NVIDIA Docker image ( nvidia/cuda:7.5-cudnn4-devel ) that already includes the required CUDA libraries, so it only has to describe how to install a few system dependencies for working with image formats, install a few machine learning Python packages with\u00a0 pip \u00a0(Theano, lasagne, etc.), and download some pre-trained model weights. It\u2019s little more than a glorified bash setup script. The\u00a0 doodle \u00a0alias isn\u2019t bad either. It simply specifies the Docker image we\u2019ll be running ( alexjc/neural-doodle:gpu ) and lets Docker know that the\u00a0 ./samples \u00a0and\u00a0 ./frames \u00a0directories should be accessible from the Docker container at\u00a0 /nd/samples/ \u00a0and\u00a0 /nd/frames . This is done using Docker\u2019s \u201cvolumes\u201d feature, which the curious can read more about on the\u00a0 official Docker site . At indico, we now use a setup to the\u00a0 neural-doodle \u00a0configuration to host the indico API on Amazon GPUs. Instead of using our own bash scripts, we allow the\u00a0 nvidia-docker \u00a0tool to handle the process of ensuring device drivers within the Docker container match device drivers on the host. This means when our customers wish to run our APIs on their local machines, deployment is as easy as providing them with access to our production Docker image and letting the\u00a0 nvidia-docker \u00a0tool handle the rest. Operating System Support \u00a0 At the moment,\u00a0 nvidia-docker \u00a0is only portable in the sense that it\u2019s not reliant on a particular GPU model, NVIDIA driver version, or linux distribution. Running\u00a0 nvidia-docker \u00a0on\u00a0 OSX \u00a0or\u00a0 Windows \u00a0will likely not be supported anytime soon. Where can I find more information on\u00a0 nvidia-docker ? \u00a0 NVIDIA has done an excellent job of keeping the wiki of their Github page up-to-date. Chances are if you have questions that aren\u2019t answered in this blog post, you can probably find answers in the\u00a0 nvidia-docker \u00a0 Github wiki . If you\u2019re using a version of CUDA other than the one used in this demo (CUDA 7.5), you might also want to take a peek at the\u00a0 full list of base images \u00a0that NVIDIA provides for you to work with. I hope you\u2019ve enjoyed this whirlwind tour on using\u00a0 nvidia-docker \u00a0to build and run machine learning projects, and perhaps created a bit of original algorithmic art while you\u2019re at it. If you run into trouble trying out this tutorial, or want to learn more about how we\u2019re using Docker in production at indico, feel free to reach out over our site chat and say hello. Happy hacking! Bio: Madison May is a developer, designer, and engineer, and is the CTO of indico Data Solutions . Original . Reposted with permission. Related: Jupyter+Spark+Mesos: An \u201cOpinionated\u201d Docker Image Semi-supervised Feature Transfer: The Practical Benefit of Deep Learning Today? Text Mining and Election Analytics in Massachusetts", "title_html": "<h1 id=\"title\">Data Science Deployments With Docker</h1> ", "url": "https://www.kdnuggets.com/2016/12/data-science-deployments-docker.html", "tfidf": {"tfidf": {"art": 3.9989924433199997, "reliabl": 6.681818181819999, "enumenumdnumenumcd": 1587.6, "onc": 2.9949066213999997, "too": 1.81585268215, "relat": 1.23750876919, "entrypoint": 1587.6, "troubl": 9.98176674002, "pip": 407.07692307600007, "data": 6.75287111868, "immedi": 2.02862254025, "devicegpu": 3175.2, "thank": 6.00681044268, "reap": 73.1612903226, "devnvidiactl": 1587.6, "follow": 1.04640126549, "uptod": 1587.6, "etc": 8.413354531, "specif": 1.8719490626099997, "default": 21.1398135819, "function": 7.486325055, "happi": 6.125, "breez": 54.0, "crop": 9.71009174312, "driver": 108.7862955032, "pythonnum": 6350.4, "well": 2.1311497416, "product": 11.35854456254, "done": 9.321003962999999, "dispa": 1587.6, "complet": 6.2010780408, "huh": 661.5, "know": 2.59327017315, "primarili": 2.43459592087, "neuraldoodl": 4762.799999999999, "their": 2.0309581681, "dev": 148.373831776, "particular": 1.3814827706200001, "instead": 1.59461631177, "creat": 2.4985835694, "enjoy": 3.3269069572500003, "alex": 31.965100671000002, "how": 6.41001312204, "test": 7.97121338913, "teammat": 31.6886227545, "dpkg": 1587.6, "fair": 3.20533010297, "inconsist": 14.3934723481, "had": 2.0951501154799996, "special": 2.9763779527599996, "distribut": 5.479206212259999, "end": 1.10680423871, "frame": 12.560126582279999, "soon": 1.9817750592900003, "paint": 8.17297297298, "deep": 3.6279707495399998, "numbnumfcdcnumd": 1587.6, "wiki": 98.91588785040001, "site": 3.9443478260800005, "monet": 417.789473685, "second": 1.1130898128, "clone": 32.5327868852, "updat": 11.12933753944, "new": 1.0178880554, "below": 2.25607503197, "similar": 2.75028150714, "but": 4.06529671596, "certain": 1.8077886586200003, "need": 5.749049429639999, "our": 18.86070686072, "whirlwind": 138.052173913, "off": 3.0242880274400004, "these": 1.07415426252, "walk": 7.12727272728, "struggl": 3.36, "has": 7.305548251399999, "enough": 2.2319696330700003, "use": 16.474220118079998, "fri": 20.5914396887, "aptget": 3175.2, "libopenjpegnum": 1587.6, "perf": 933.882352941, "out": 5.30083472455, "model": 12.5435870424, "format": 2.53125, "good": 1.51981619759, "alway": 4.13491340018, "libjpegdev": 1587.6, "docker": 10809.191489376, "start": 2.53347163488, "pain": 6.55762081784, "tmp": 1587.6, "usag": 6.427530364369999, "not": 6.09404388714, "wish": 3.67755385685, "doodl": 702.477876105, "libtiffnumdev": 1587.6, "difficult": 2.48957189901, "less": 1.46904783936, "git": 721.636363636, "nvidiacudanumcudnnnumdevel": 3175.2, "quick": 4.41, "shanum": 1587.6, "easi": 15.8812937646, "about": 4.25944060636, "handl": 7.845811712380001, "gitlik": 1587.6, "than": 3.0983606557499996, "sketch": 21.913043478200002, "design": 2.9165059245, "anoth": 1.13643521832, "instal": 68.16984732828, "turn": 1.3838912133899999, "let": 17.43083003955, "scienc": 2.31969608416, "rectifi": 54.3698630137, "nvidianvidiadockerreleasesdownloadvnumrcnumnvidiadockernumrcnumamdnumdeb": 1587.6, "job": 3.2539454806299997, "github": 3175.2, "custom": 3.6346153846199996, "away": 1.85142857143, "ensur": 10.238177128110001, "uncorr": 1587.6, "libwebpdev": 1587.6, "alexjcneuraldoodl": 4762.799999999999, "practic": 1.70434782609, "alreadi": 21.50689655169, "sudo": 1587.6, "sens": 2.8365195640499996, "provid": 6.07763570935, "numadnumenum": 1587.6, "either": 1.5830092731099998, "numfnumenumacnumc": 1587.6, "develop": 2.3911439114400004, "setup": 102.4258064517, "gfortran": 1587.6, "elect": 2.5228031145700003, "talk": 3.0303493033, "transfer": 5.45098712446, "network": 2.59369384088, "python": 56.2978723404, "box": 4.12685209254, "cnumbnumcnum": 1587.6, "should": 6.657301603960001, "enumbnumbnum": 1587.6, "pkgconfig": 1587.6, "document": 2.5409731114, "industri": 2.02319357716, "version": 16.066793168879997, "pythonnumnetworkx": 1587.6, "platform": 6.2332155476999995, "set": 3.56123822343, "question": 2.20408163265, "pythonnummatplotlib": 1587.6, "from": 11.00623936467, "ecosystem": 26.111842105300003, "usagecap": 1587.6, "answer": 9.29780380674, "anywher": 20.3277848912, "pythonnumnumpi": 1587.6, "detail": 2.26186066391, "num": 17.005355680170002, "aren": 481.09090909099996, "free": 1.71818181818, "environ": 20.61371997402, "curv": 11.1098670399, "glorifi": 59.2388059701, "for": 11.00346544011, "dockerfil": 4762.799999999999, "assumey": 1587.6, "output": 7.676982591880001, "match": 7.1352808988800005, "releas": 3.6754253964599997, "roll": 4.27578777269, "with": 13.015576716869997, "theano": 3175.2, "samplescoastlinepng": 1587.6, "are": 4.11962374312, "solut": 18.9112567004, "newer": 19.845, "effort": 1.89247824532, "nvidiasmi": 7938.0, "gpuutil": 1587.6, "option": 4.04896710023, "fan": 4.805084745759999, "chanc": 4.2449197861000005, "work": 8.92160719304, "focus": 2.01012914662, "educ": 2.00733341763, "hacki": 1587.6, "remov": 2.0058117498400003, "then": 1.08657860516, "doe": 5.11743848715, "littl": 1.5499365420299998, "photo": 6.41973311767, "proper": 3.3388012618299996, "bug": 27.372413793099998, "alexjc": 1587.6, "step": 2.8279301745599996, "indico": 9525.599999999999, "pythonnumtk": 1587.6, "his": 2.1887364720400004, "massachusett": 7.632692307689999, "type": 2.0281042411900003, "requirementstxt": 3175.2, "thing": 2.4065484311099996, "probabl": 2.64555907349, "machin": 32.19467680608, "into": 3.04507384437, "nvidiacuda": 4762.799999999999, "paper": 2.6628648104700003, "reach": 1.49801849406, "champanard": 1587.6, "through": 2.14149861738, "download": 29.2915129152, "requir": 12.22759218256, "where": 1.06715063521, "what": 1.25343439128, "local": 1.51720183486, "allow": 2.5432118542200004, "main": 1.25303867403, "chat": 36.164009111599995, "find": 3.4588235294199996, "briefli": 4.8669527897, "demo": 28.7088607595, "jupytersparkmeso": 1587.6, "curious": 23.381443299, "wrong": 5.478260869570001, "own": 2.35688836104, "cmake": 1587.6, "base": 2.2925631769, "numenumbnumdfnumdnum": 1587.6, "hey": 39.3945409429, "permiss": 6.280063291139999, "post": 2.23826307627, "here": 2.42307692308, "wget": 4762.799999999999, "softwar": 20.5248868778, "blog": 14.1876675603, "describ": 1.47027227264, "long": 1.2657259028899999, "assur": 7.941970985489999, "script": 24.897020386830004, "contain": 19.17777330384, "adopt": 2.0442956477000003, "problem": 1.76674827509, "deploy": 37.09345794395, "communiti": 1.96121062384, "iterationsnum": 1587.6, "neural": 118.9213483146, "liblcmsnumdev": 1587.6, "memoryusag": 1587.6, "just": 2.67160286074, "devic": 25.0410094637, "understand": 2.96858638743, "temp": 63.2509960159, "coastlin": 42.5060240964, "nov": 26.0689655172, "featur": 3.05425163524, "simpli": 2.5192002538900002, "repost": 933.882352941, "madison": 31.40652819, "attach": 4.4885496183199995, "bfnumdnum": 1587.6, "artist": 2.86673889491, "check": 6.50655737705, "enumfnumcnumenumcnum": 1587.6, "persistencem": 1587.6, "rest": 1.9573418813999999, "numafnumenum": 1587.6, "tool": 29.983002832860002, "nvidiadockerplugin": 1587.6, "whenev": 11.622254758399999, "run": 28.02471315084, "enabl": 3.5421686747, "guid": 2.49113447356, "keep": 2.04245465071, "bad": 6.788967286719999, "execut": 2.2363713199, "order": 2.49250333622, "kernel": 70.56, "whi": 6.513230769240001, "liblapackdev": 1587.6, "hello": 44.4705882353, "abl": 1.8208510150200001, "pull": 31.11924207774, "over": 1.02525024217, "perhap": 3.14812611541, "build": 6.5366958312, "resourc": 2.9487369985100003, "mine": 4.875921375919999, "read": 2.3149606299200003, "team": 2.2748244734200003, "exact": 3.46864758575, "there": 1.04091266719, "exist": 8.78826460008, "busid": 1587.6, "volum": 4.8109090909, "inform": 1.5753125620200001, "nvidiadock": 39690.0, "hardwar": 75.2417061612, "say": 1.7544480053, "semisupervis": 1587.6, "exampl": 1.50483412322, "portabl": 39.0553505536, "doodlepi": 4762.799999999999, "nvidiamodprob": 1587.6, "take": 4.55846672888, "previous": 1.42846859816, "now": 2.321561746, "might": 2.1561863370900003, "tri": 3.7089125102199993, "configur": 80.53043478269998, "name": 2.20423464074, "code": 15.522855047679998, "hard": 2.73253012048, "support": 7.611346384320001, "see": 1.27242125511, "semant": 39.1034482759, "pwd": 2886.54545454, "break": 2.42863698944, "feel": 3.1356903021900004, "samplesmonetjpg": 1587.6, "also": 2.02953020134, "specifi": 13.841325196160001, "pythonnumpip": 1587.6, "mean": 4.34720700987, "style": 9.51228280408, "reliant": 57.7309090909, "will": 2.44962197192, "becaus": 1.1495184997499999, "nummib": 3175.2, "them": 2.19752231988, "tour": 3.4876977152900004, "ndframe": 3175.2, "the": 66.0, "may": 4.20807103572, "meet": 1.6658971668399998, "want": 3.99396226416, "geforc": 1587.6, "system": 4.16219522853, "behind": 2.0845588235299997, "howev": 2.1890382626599996, "gone": 5.22408687068, "minut": 3.11233091551, "that": 10.0398406375, "cython": 1587.6, "which": 2.01038369, "ident": 5.61584718784, "mechan": 3.41492794149, "other": 2.01984732824, "peek": 160.363636364, "techniqu": 3.7293868921800004, "one": 1.00627495722, "ndsampl": 3175.2, "hope": 2.50884955752, "status": 2.4636871508400002, "full": 1.66729678639, "some": 2.08073394496, "algorithm": 27.9507042254, "alia": 92.12379110250001, "imag": 37.819295558940006, "sourc": 1.69760479042, "get": 8.92812956925, "mount": 3.5030891438699996, "like": 5.745928338750001, "libopenblasdev": 1587.6, "moment": 4.262013422819999, "lasagn": 3175.2, "opinion": 3.8044572250199997, "process": 5.08574479446, "analyt": 17.256521739100002, "memori": 2.57392996109, "digest": 19.0588235294, "file": 11.313064133009998, "alexjcneuraldoodlereleasesdownloadvnumvggnumconvpklbznum": 1587.6, "next": 1.4950560316400001, "pwr": 992.25, "necessarili": 7.33302540416, "access": 11.240972386140001, "shi": 20.4324324324, "choic": 3.1319786940200003, "directori": 14.768372093, "nvidiacudanum": 4762.799999999999, "substanti": 3.4777656078900003, "api": 84.44680851060001, "engin": 4.94271481942, "back": 1.26070038911, "chang": 1.1808985421, "bit": 8.33385826772, "project": 12.274353876750002, "differ": 2.4730898045, "been": 1.0239277652399998, "first": 1.00761614623, "binari": 64.8, "most": 1.02096463023, "between": 1.03453668708, "magic": 7.9063745019899985, "hack": 43.3770491803, "tutori": 118.9213483146, "excel": 4.84467500763, "expos": 5.03680203046, "varlibaptlist": 1587.6, "all": 1.01146788991, "devnvidianum": 1587.6, "today": 1.74961428257, "gpu": 1082.454545454, "zlibnumgdev": 1587.6, "someth": 9.84456386937, "includ": 2.0381282495599997, "have": 7.104263887979998, "normal": 2.61075481006, "weight": 4.878918254459999, "architectur": 5.12790697674, "cool": 6.8578833693300005, "more": 6.1030240902, "and": 31.001952756029997, "list": 1.36321483771, "moduleinittool": 1587.6, "rough": 3.29582727839, "folk": 7.6658619024600005, "benefit": 9.20525705451, "amount": 2.27027027027, "buildessenti": 1587.6, "volatil": 32.5995893224, "befor": 2.20072082062, "librari": 5.3653261237, "state": 1.0477133240899998, "anytim": 114.215827338, "pythonnumsix": 1587.6, "window": 5.86479497599, "masterpiec": 19.3138686131, "can": 10.58635252278, "avail": 1.7288467821, "linux": 130.131147541, "workaround": 407.07692307699995, "comput": 3.9277585353800006, "make": 2.1525320317200003, "few": 3.95187520743, "depend": 6.723320158110001, "onli": 3.0769429549800007, "eas": 9.04615384615, "amazon": 33.1440501044, "this": 15.056904400650001, "necessari": 2.8421052631599997, "numdnumdbnumfdabnum": 1587.6, "pretrain": 3175.2, "packag": 7.828402366860001, "pretti": 15.75, "worri": 10.302401038300001, "while": 1.0441988950299999, "block": 6.40548718984, "sampl": 14.46560364464, "revert": 15.383720930199999, "oper": 3.10958769954, "cnumcnumdnumcnumfnumcbfnumbfnumbnumenumbnumbnumbnumanumecnumdacdenumb": 1587.6, "pythonnumscipi": 1587.6, "sinc": 2.16737201366, "bio": 42.336000000000006, "origin": 4.54899713468, "fewer": 5.94829524166, "offici": 2.8096628617, "worth": 5.210370856580001, "text": 3.12827586207, "pythonnumdev": 1587.6, "gpus": 6350.400000000001, "import": 1.3401992233700002, "alexjcneuraldoodlegit": 1587.6, "everi": 1.47917637194, "copi": 11.512690355340002, "when": 4.0830707902, "nice": 17.7583892617, "page": 2.03669018602, "ubuntu": 1058.4, "tmpnvidiadockerdeb": 3175.2, "bash": 249.3612565446, "host": 18.964505119419997, "write": 2.0575427682700003, "recent": 3.0881151527, "agnost": 63.504, "within": 11.1323724192, "libfreetypenumdev": 1587.6, "learn": 20.90475493785, "fermi": 131.20661157, "deb": 120.27272727299999}, "logtfidf": {"art": 1.3857905193239999, "reliabl": 1.89939013342, "enumenumdnumenumcd": 7.369978720910001, "onc": 0.80753174471, "too": 0.5965551547219999, "relat": 0.21310030165399999, "entrypoint": 7.369978720910001, "troubl": 3.2152258443, "pip": 14.731169637330002, "data": 2.4336411696, "immedi": 0.707357011133, "devicegpu": 14.739957441820001, "thank": 1.7928938993, "reap": 4.29266646036, "devnvidiactl": 7.369978720910001, "follow": 0.045356911094199995, "uptod": 7.369978720910001, "etc": 2.8733461759400005, "specif": 0.626980167541, "default": 3.0511581621399997, "function": 2.743397224782, "happi": 1.81237875643, "breez": 3.9889840465599997, "crop": 2.27316573057, "driver": 30.6687463008, "pythonnum": 29.479914883640003, "well": 0.1270288766312, "product": 3.388420955752, "done": 3.383903932516, "dispa": 7.369978720910001, "complet": 1.076426210235, "huh": 6.4945099835599995, "know": 0.952919694398, "primarili": 0.8897807965100001, "neuraldoodl": 22.10993616273, "their": 0.030721010245400002, "dev": 4.99973497944, "particular": 0.323157393804, "instead": 0.46663315041500003, "creat": 0.445153637028, "enjoy": 1.2020430306899998, "alex": 7.09809724488, "how": 1.8862678277200002, "test": 2.931673311309, "teammat": 3.4559577128199996, "dpkg": 7.369978720910001, "fair": 1.16481508131, "inconsist": 2.6667747946500002, "had": 0.0929560488222, "special": 0.7951198572020001, "distribut": 2.01562611626, "end": 0.101476798618, "frame": 3.6747601172800004, "soon": 0.6839929376880001, "paint": 2.8153711022000003, "deep": 1.2886734698, "numbnumfcdcnumd": 7.369978720910001, "wiki": 7.802245381539999, "site": 1.3582728869799998, "monet": 14.809096096530002, "second": 0.10713976337999999, "clone": 3.4822484080500002, "updat": 3.4328749253799997, "new": 0.0177299468511, "below": 0.813626591936, "similar": 0.637112184228, "but": 0.0647694882876, "certain": 0.592104362781, "need": 1.450960653768, "our": 6.8611137134560005, "whirlwind": 4.927631685540001, "off": 0.8270570407760001, "these": 0.0715336194008, "walk": 2.541562948, "struggl": 1.2119409739799998, "has": 0.2990676139836, "enough": 0.802884439169, "use": 0.4673283157056, "fri": 3.02487544034, "aptget": 14.739957441820001, "libopenjpegnum": 7.369978720910001, "perf": 6.83935046985, "out": 0.2921319545965, "model": 4.424700438666001, "format": 0.9287132518729999, "good": 0.418589404907, "alway": 1.452638409144, "libjpegdev": 7.369978720910001, "docker": 186.31731879007998, "start": 0.472886738582, "pain": 1.88062785696, "tmp": 7.369978720910001, "usag": 1.86059038428, "not": 0.093314478045, "wish": 1.30224781835, "doodl": 24.725879975949997, "libtiffnumdev": 7.369978720910001, "difficult": 0.912110767588, "less": 0.3846144626, "git": 11.776748359960001, "nvidiacudanumcudnnnumdevel": 14.739957441820001, "quick": 1.581455017798, "shanum": 7.369978720910001, "easi": 4.99958890545, "about": 0.2513739098984, "handl": 2.73366533806, "gitlik": 7.369978720910001, "than": 0.0967825866546, "sketch": 4.78786974316, "design": 0.754478236044, "anoth": 0.127896361652, "instal": 23.9693505822, "turn": 0.324899251064, "let": 6.2440128364, "scienc": 0.841436178891, "rectifi": 3.9958100116300006, "nvidianvidiadockerreleasesdownloadvnumrcnumnvidiadockernumrcnumamdnumdeb": 7.369978720910001, "job": 1.1798682540899998, "github": 14.739957441820001, "custom": 1.2905032964799998, "away": 0.615957541869, "ensur": 3.68253390078, "uncorr": 7.369978720910001, "libwebpdev": 7.369978720910001, "alexjcneuraldoodl": 22.10993616273, "practic": 0.533182530867, "alreadi": 7.3752621882169995, "sudo": 7.369978720910001, "sens": 1.04257779501, "provid": 0.9758892216250001, "numadnumenum": 7.369978720910001, "either": 0.459327638815, "numfnumenumacnumc": 7.369978720910001, "develop": 0.357249389826, "setup": 10.591579224959998, "gfortran": 7.369978720910001, "elect": 0.925370630376, "talk": 1.10867789449, "transfer": 2.00529907094, "network": 0.9530830530519999, "python": 4.03065674296, "box": 1.41751491115, "cnumbnumcnum": 7.369978720910001, "should": 2.037679507032, "enumbnumbnum": 7.369978720910001, "pkgconfig": 7.369978720910001, "document": 0.932547122383, "industri": 0.7046772417749999, "version": 5.578504514072, "pythonnumnetworkx": 7.369978720910001, "platform": 1.8298923389200001, "set": 0.5144880338669999, "question": 0.790310929014, "pythonnummatplotlib": 7.369978720910001, "from": 0.006237595857525999, "ecosystem": 3.26238893194, "usagecap": 7.369978720910001, "answer": 3.0732620838, "anywher": 4.637682967, "pythonnumnumpi": 7.369978720910001, "detail": 0.816187777173, "num": 0.005354836721749001, "aren": 6.17605625244, "free": 0.5412666492670001, "environ": 7.405184418179999, "curv": 2.40783363597, "glorifi": 4.08157683339, "for": 0.0034648943493670007, "dockerfil": 22.10993616273, "assumey": 7.369978720910001, "output": 2.03822657827, "match": 2.54380887748, "releas": 1.217043399088, "roll": 1.4529683597299998, "with": 0.01556739227407, "theano": 14.739957441820001, "samplescoastlinepng": 7.369978720910001, "are": 0.1178698943308, "solut": 6.21385190508, "newer": 4.58960981136, "effort": 0.637887211057, "nvidiasmi": 36.849893604550005, "gpuutil": 7.369978720910001, "option": 1.39846181161, "fan": 1.56967467926, "chanc": 1.44572292349, "work": 0.872276538184, "focus": 0.6981989720559999, "educ": 0.696807183384, "hacki": 7.369978720910001, "remov": 0.6960488415880001, "then": 0.08303386523089999, "doe": 1.6021251891509998, "littl": 0.438213989466, "photo": 1.8593765463799998, "proper": 1.2056118389200001, "bug": 3.30953571036, "alexjc": 7.369978720910001, "step": 1.03954505698, "indico": 44.21987232546, "pythonnumtk": 7.369978720910001, "his": 0.1803544867282, "massachusett": 2.03244064121, "type": 0.707101485387, "requirementstxt": 14.739957441820001, "thing": 0.8781935346799999, "probabl": 0.972882412913, "machin": 11.13887664496, "into": 0.0447385896861, "nvidiacuda": 22.10993616273, "paper": 0.979402539665, "reach": 0.40414323085000003, "champanard": 7.369978720910001, "through": 0.1367173837698, "download": 5.3683012638, "requir": 3.3940280854, "where": 0.0649921387457, "what": 0.225887296827, "local": 0.416867740206, "allow": 0.48056122237800003, "main": 0.225571540588, "chat": 3.58806440083, "find": 1.095562660576, "briefli": 1.5824680307199999, "demo": 3.3572058123799997, "jupytersparkmeso": 7.369978720910001, "curious": 3.15194268634, "wrong": 1.70078769102, "own": 0.328390154842, "cmake": 7.369978720910001, "base": 0.27304660457400004, "numenumbnumdfnumdnum": 7.369978720910001, "hey": 3.6736272519599997, "permiss": 1.8373800586400002, "post": 0.8057001527009999, "here": 0.8850381883700001, "wget": 22.10993616273, "softwar": 4.65698192666, "blog": 2.65237310559, "describ": 0.385447603125, "long": 0.235645793878, "assur": 2.0721614794, "script": 6.348407533379999, "contain": 5.626143818832, "adopt": 0.7150533036110001, "problem": 0.569140724273, "deploy": 10.02001352945, "communiti": 0.673561947791, "iterationsnum": 7.369978720910001, "neural": 8.170630311, "liblcmsnumdev": 7.369978720910001, "memoryusag": 7.369978720910001, "just": 0.579062868218, "devic": 8.055384735149998, "understand": 1.0880858756799998, "temp": 4.14711087477, "coastlin": 6.112997257540001, "nov": 3.2607455461900003, "featur": 0.846774836284, "simpli": 0.923941491586, "repost": 6.83935046985, "madison": 5.507737189759999, "attach": 1.5015296247, "bfnumdnum": 7.369978720910001, "artist": 1.05317511017, "check": 1.87281049562, "enumfnumcnumenumcnum": 7.369978720910001, "persistencem": 7.369978720910001, "rest": 0.671587369833, "numafnumenum": 7.369978720910001, "tool": 9.653227077779999, "nvidiadockerplugin": 7.369978720910001, "whenev": 2.45292177377, "run": 7.968869559702, "enabl": 1.26473915954, "guid": 0.912738218589, "keep": 0.7141523446729999, "bad": 2.4443033123599998, "execut": 0.804854605864, "order": 0.44028076158600005, "kernel": 4.2564634117, "whi": 2.36137686094, "liblapackdev": 7.369978720910001, "hello": 3.7948280321199994, "abl": 0.599303982475, "pull": 9.876401249759999, "over": 0.0249367214957, "perhap": 1.14680739183, "build": 1.964549808364, "resourc": 1.08137694258, "mine": 1.58430908678, "read": 0.83939268088, "team": 0.821902894886, "exact": 1.2437647732500001, "there": 0.0400978929255, "exist": 2.289946764522, "busid": 7.369978720910001, "volum": 1.755477771776, "inform": 0.454453704662, "nvidiadock": 184.24946802275002, "hardwar": 11.73764527724, "say": 0.562154280552, "semisupervis": 7.369978720910001, "exampl": 0.40868267499899996, "portabl": 5.943665408719999, "doodlepi": 22.10993616273, "nvidiamodprob": 7.369978720910001, "take": 0.522767848788, "previous": 0.356602960063, "now": 0.298185890042, "might": 0.7683410765340001, "tri": 1.23518305832, "configur": 17.099075250249996, "name": 0.19446633276860004, "code": 5.42407638388, "hard": 1.00522796406, "support": 1.427283660222, "see": 0.240921585492, "semant": 3.6662106543, "pwd": 14.549337082200001, "break": 0.88733019029, "feel": 1.1428493419299999, "samplesmonetjpg": 7.369978720910001, "also": 0.0293143156, "specifi": 3.86902303242, "pythonnumpip": 7.369978720910001, "mean": 1.11276385056, "style": 3.465158116484, "reliant": 4.05579271624, "will": 0.40557306983, "becaus": 0.139343158825, "nummib": 14.739957441820001, "them": 0.1883666538186, "tour": 1.2492418381000001, "ndframe": 14.739957441820001, "the": 0.0, "may": 0.20283998113760002, "meet": 0.510363817255, "want": 1.3832732125099998, "geforc": 7.369978720910001, "system": 0.982291036755, "behind": 0.7345572374320001, "howev": 0.180630234695, "gone": 1.65328002099, "minut": 1.1353719359799999, "that": 0.039761483796399995, "cython": 7.369978720910001, "which": 0.01035682769086, "ident": 2.0648905513, "mechan": 1.22815639221, "other": 0.01974949583952, "peek": 5.0774439637699995, "techniqu": 1.31624384807, "one": 0.0062553516455, "ndsampl": 14.739957441820001, "hope": 0.919824304455, "status": 0.9016590696060001, "full": 0.511203624148, "some": 0.079147018129, "algorithm": 3.33044239518, "alia": 10.273562818170001, "imag": 13.91266950206, "sourc": 0.529218310751, "get": 2.89884502891, "mount": 1.25364519176, "like": 0.6952678827250001, "libopenblasdev": 7.369978720910001, "moment": 1.4497416830899998, "lasagn": 14.739957441820001, "opinion": 1.33617333331, "process": 1.583487597075, "analyt": 2.8481901438599997, "memori": 0.9454338986599999, "digest": 2.9475301717400004, "file": 3.9820376616899997, "alexjcneuraldoodlereleasesdownloadvnumvggnumconvpklbznum": 7.369978720910001, "next": 0.402163685499, "pwr": 6.89997509166, "necessarili": 1.99238817347, "access": 3.766835296296, "shi": 3.0171234635400004, "choic": 1.14166497543, "directori": 2.6924878733399997, "nvidiacudanum": 22.10993616273, "substanti": 1.24639002087, "api": 4.43612185107, "engin": 1.809535116552, "back": 0.23166743089699998, "chang": 0.166275625058, "bit": 2.12032652634, "project": 3.931213201349, "differ": 0.424642242624, "been": 0.023645982368400004, "first": 0.0075872898121599995, "binari": 6.956316845599999, "most": 0.020747896295599998, "between": 0.033953681165299995, "magic": 2.06766933309, "hack": 3.7699304805000002, "tutori": 8.170630311, "excel": 1.5778801652, "expos": 1.6167713629299998, "varlibaptlist": 7.369978720910001, "all": 0.011402632097799998, "devnvidianum": 7.369978720910001, "today": 0.559395353679, "gpu": 17.66512253994, "zlibnumgdev": 7.369978720910001, "someth": 3.56492136819, "includ": 0.037769362781, "have": 0.1034950163884, "normal": 0.959639378783, "weight": 1.58492352612, "architectur": 1.63469757919, "cool": 1.9253988473800001, "more": 0.10214958959999998, "and": 0.0019526944039716, "list": 0.309845761506, "moduleinittool": 7.369978720910001, "rough": 1.1926572072700001, "folk": 2.03677695251, "benefit": 3.36348735348, "amount": 0.819898886199, "buildessenti": 7.369978720910001, "volatil": 3.4842996908199995, "befor": 0.191275543759, "librari": 1.973619961886, "state": 0.0466100027668, "anytim": 4.73808988077, "pythonnumsix": 7.369978720910001, "window": 1.7689675242900003, "masterpiec": 2.96082341885, "can": 1.4610698675459999, "avail": 0.547454586289, "linux": 8.35079117722, "workaround": 6.009002167769999, "comput": 1.36806891594, "make": 0.14699531564579998, "few": 0.826733740959, "depend": 2.420909445, "onli": 0.0759728049873, "eas": 2.202339678, "amazon": 3.50086321649, "this": 0.0567967357875, "necessari": 1.0445450673999999, "numdnumdbnumfdabnum": 7.369978720910001, "pretrain": 14.739957441820001, "packag": 2.0577584491900005, "pretti": 2.75684036527, "worri": 2.3323769785799997, "while": 0.04324998379380001, "block": 2.32801563176, "sampl": 3.9572529767800004, "revert": 2.73330986786, "oper": 0.882685928694, "cnumcnumdnumcnumfnumcbfnumbfnumbnumenumbnumbnumbnumanumecnumdacdenumb": 7.369978720910001, "pythonnumscipi": 7.369978720910001, "sinc": 0.1607363989154, "bio": 3.7456377879300002, "origin": 0.514449750348, "fewer": 1.7831046645, "offici": 0.679834635086, "worth": 1.65065103492, "text": 1.14048200999, "pythonnumdev": 7.369978720910001, "gpus": 41.7870816768, "import": 0.292818277066, "alexjcneuraldoodlegit": 7.369978720910001, "everi": 0.391485427421, "copi": 4.034512942319999, "when": 0.0822199554336, "nice": 2.8768580387299996, "page": 0.711326032411, "ubuntu": 12.54273286448, "tmpnvidiadockerdeb": 14.739957441820001, "bash": 13.260871157579999, "host": 6.976612519324, "write": 0.721512439877, "recent": 0.868827482576, "agnost": 4.15110289604, "within": 1.913694485382, "libfreetypenumdev": 7.369978720910001, "learn": 7.584768582704999, "fermi": 4.87677326831, "deb": 4.7897618913199995}, "logidf": {"art": 0.6928952596619999, "reliabl": 1.89939013342, "enumenumdnumenumcd": 7.369978720910001, "onc": 0.403765872355, "too": 0.5965551547219999, "relat": 0.21310030165399999, "entrypoint": 7.369978720910001, "troubl": 1.60761292215, "pip": 4.91038987911, "data": 1.2168205848, "immedi": 0.707357011133, "devicegpu": 7.369978720910001, "thank": 1.7928938993, "reap": 4.29266646036, "devnvidiactl": 7.369978720910001, "follow": 0.045356911094199995, "uptod": 7.369978720910001, "etc": 1.4366730879700003, "specif": 0.626980167541, "default": 3.0511581621399997, "function": 0.914465741594, "happi": 1.81237875643, "breez": 3.9889840465599997, "crop": 2.27316573057, "driver": 1.9167966438, "pythonnum": 7.369978720910001, "well": 0.0635144383156, "product": 0.484060136536, "done": 0.845975983129, "dispa": 7.369978720910001, "complet": 0.215285242047, "huh": 6.4945099835599995, "know": 0.952919694398, "primarili": 0.8897807965100001, "neuraldoodl": 7.369978720910001, "their": 0.015360505122700001, "dev": 4.99973497944, "particular": 0.323157393804, "instead": 0.46663315041500003, "creat": 0.222576818514, "enjoy": 1.2020430306899998, "alex": 2.36603241496, "how": 0.47156695693000006, "test": 0.977224437103, "teammat": 3.4559577128199996, "dpkg": 7.369978720910001, "fair": 1.16481508131, "inconsist": 2.6667747946500002, "had": 0.0464780244111, "special": 0.39755992860100003, "distribut": 1.00781305813, "end": 0.101476798618, "frame": 1.8373800586400002, "soon": 0.6839929376880001, "paint": 1.4076855511000002, "deep": 1.2886734698, "numbnumfcdcnumd": 7.369978720910001, "wiki": 3.9011226907699994, "site": 0.6791364434899999, "monet": 4.93636536551, "second": 0.10713976337999999, "clone": 3.4822484080500002, "updat": 1.7164374626899999, "new": 0.0177299468511, "below": 0.813626591936, "similar": 0.318556092114, "but": 0.0161923720719, "certain": 0.592104362781, "need": 0.362740163442, "our": 0.8576392141820001, "whirlwind": 4.927631685540001, "off": 0.41352852038800003, "these": 0.0715336194008, "walk": 1.270781474, "struggl": 1.2119409739799998, "has": 0.0427239448548, "enough": 0.802884439169, "use": 0.0292080197316, "fri": 3.02487544034, "aptget": 7.369978720910001, "libopenjpegnum": 7.369978720910001, "perf": 6.83935046985, "out": 0.0584263909193, "model": 0.7374500731110001, "format": 0.9287132518729999, "good": 0.418589404907, "alway": 0.726319204572, "libjpegdev": 7.369978720910001, "docker": 5.822416212189999, "start": 0.236443369291, "pain": 1.88062785696, "tmp": 7.369978720910001, "usag": 1.86059038428, "not": 0.0155524130075, "wish": 1.30224781835, "doodl": 4.94517599519, "libtiffnumdev": 7.369978720910001, "difficult": 0.912110767588, "less": 0.3846144626, "git": 5.8883741799800005, "nvidiacudanumcudnnnumdevel": 7.369978720910001, "quick": 0.790727508899, "shanum": 7.369978720910001, "easi": 1.6665296351499999, "about": 0.0628434774746, "handl": 1.36683266903, "gitlik": 7.369978720910001, "than": 0.0322608622182, "sketch": 2.39393487158, "design": 0.377239118022, "anoth": 0.127896361652, "instal": 1.3316305879, "turn": 0.324899251064, "let": 1.2488025672799998, "scienc": 0.841436178891, "rectifi": 3.9958100116300006, "nvidianvidiadockerreleasesdownloadvnumrcnumnvidiadockernumrcnumamdnumdeb": 7.369978720910001, "job": 1.1798682540899998, "github": 7.369978720910001, "custom": 1.2905032964799998, "away": 0.615957541869, "ensur": 1.22751130026, "uncorr": 7.369978720910001, "libwebpdev": 7.369978720910001, "alexjcneuraldoodl": 7.369978720910001, "practic": 0.533182530867, "alreadi": 0.670478380747, "sudo": 7.369978720910001, "sens": 1.04257779501, "provid": 0.19517784432500002, "numadnumenum": 7.369978720910001, "either": 0.459327638815, "numfnumenumacnumc": 7.369978720910001, "develop": 0.178624694913, "setup": 3.5305264083199996, "gfortran": 7.369978720910001, "elect": 0.925370630376, "talk": 1.10867789449, "transfer": 1.00264953547, "network": 0.9530830530519999, "python": 4.03065674296, "box": 1.41751491115, "cnumbnumcnum": 7.369978720910001, "should": 0.509419876758, "enumbnumbnum": 7.369978720910001, "pkgconfig": 7.369978720910001, "document": 0.932547122383, "industri": 0.7046772417749999, "version": 0.697313064259, "pythonnumnetworkx": 7.369978720910001, "platform": 1.8298923389200001, "set": 0.171496011289, "question": 0.790310929014, "pythonnummatplotlib": 7.369978720910001, "from": 0.000567054168866, "ecosystem": 3.26238893194, "usagecap": 7.369978720910001, "answer": 1.5366310419, "anywher": 2.3188414835, "pythonnumnumpi": 7.369978720910001, "detail": 0.816187777173, "num": 0.00031499039539700004, "aren": 6.17605625244, "free": 0.5412666492670001, "environ": 1.2341974030299998, "curv": 2.40783363597, "glorifi": 4.08157683339, "for": 0.00031499039539700004, "dockerfil": 7.369978720910001, "assumey": 7.369978720910001, "output": 2.03822657827, "match": 1.27190443874, "releas": 0.608521699544, "roll": 1.4529683597299998, "with": 0.00119749171339, "theano": 7.369978720910001, "samplescoastlinepng": 7.369978720910001, "are": 0.0294674735827, "solut": 1.55346297627, "newer": 2.29480490568, "effort": 0.637887211057, "nvidiasmi": 7.369978720910001, "gpuutil": 7.369978720910001, "option": 1.39846181161, "fan": 1.56967467926, "chanc": 1.44572292349, "work": 0.109034567273, "focus": 0.6981989720559999, "educ": 0.696807183384, "hacki": 7.369978720910001, "remov": 0.6960488415880001, "then": 0.08303386523089999, "doe": 0.5340417297169999, "littl": 0.438213989466, "photo": 1.8593765463799998, "proper": 1.2056118389200001, "bug": 3.30953571036, "alexjc": 7.369978720910001, "step": 1.03954505698, "indico": 7.369978720910001, "pythonnumtk": 7.369978720910001, "his": 0.0901772433641, "massachusett": 2.03244064121, "type": 0.707101485387, "requirementstxt": 7.369978720910001, "thing": 0.8781935346799999, "probabl": 0.972882412913, "machin": 1.39235958062, "into": 0.0149128632287, "nvidiacuda": 7.369978720910001, "paper": 0.979402539665, "reach": 0.40414323085000003, "champanard": 7.369978720910001, "through": 0.0683586918849, "download": 2.6841506319, "requir": 0.424253510675, "where": 0.0649921387457, "what": 0.225887296827, "local": 0.416867740206, "allow": 0.24028061118900002, "main": 0.225571540588, "chat": 3.58806440083, "find": 0.547781330288, "briefli": 1.5824680307199999, "demo": 3.3572058123799997, "jupytersparkmeso": 7.369978720910001, "curious": 3.15194268634, "wrong": 1.70078769102, "own": 0.164195077421, "cmake": 7.369978720910001, "base": 0.13652330228700002, "numenumbnumdfnumdnum": 7.369978720910001, "hey": 3.6736272519599997, "permiss": 1.8373800586400002, "post": 0.8057001527009999, "here": 0.8850381883700001, "wget": 7.369978720910001, "softwar": 2.32849096333, "blog": 2.65237310559, "describ": 0.385447603125, "long": 0.235645793878, "assur": 2.0721614794, "script": 2.1161358444599996, "contain": 0.468845318236, "adopt": 0.7150533036110001, "problem": 0.569140724273, "deploy": 2.00400270589, "communiti": 0.673561947791, "iterationsnum": 7.369978720910001, "neural": 4.0853151555, "liblcmsnumdev": 7.369978720910001, "memoryusag": 7.369978720910001, "just": 0.289531434109, "devic": 1.6110769470299997, "understand": 1.0880858756799998, "temp": 4.14711087477, "coastlin": 3.0564986287700004, "nov": 3.2607455461900003, "featur": 0.423387418142, "simpli": 0.923941491586, "repost": 6.83935046985, "madison": 2.7538685948799997, "attach": 1.5015296247, "bfnumdnum": 7.369978720910001, "artist": 1.05317511017, "check": 1.87281049562, "enumfnumcnumenumcnum": 7.369978720910001, "persistencem": 7.369978720910001, "rest": 0.671587369833, "numafnumenum": 7.369978720910001, "tool": 1.60887117963, "nvidiadockerplugin": 7.369978720910001, "whenev": 2.45292177377, "run": 0.442714975539, "enabl": 1.26473915954, "guid": 0.912738218589, "keep": 0.7141523446729999, "bad": 1.2221516561799999, "execut": 0.804854605864, "order": 0.22014038079300002, "kernel": 4.2564634117, "whi": 1.18068843047, "liblapackdev": 7.369978720910001, "hello": 3.7948280321199994, "abl": 0.599303982475, "pull": 1.6460668749599998, "over": 0.0249367214957, "perhap": 1.14680739183, "build": 0.491137452091, "resourc": 1.08137694258, "mine": 1.58430908678, "read": 0.83939268088, "team": 0.821902894886, "exact": 1.2437647732500001, "there": 0.0400978929255, "exist": 0.38165779408699996, "busid": 7.369978720910001, "volum": 0.877738885888, "inform": 0.454453704662, "nvidiadock": 7.369978720910001, "hardwar": 2.93441131931, "say": 0.562154280552, "semisupervis": 7.369978720910001, "exampl": 0.40868267499899996, "portabl": 2.9718327043599997, "doodlepi": 7.369978720910001, "nvidiamodprob": 7.369978720910001, "take": 0.130691962197, "previous": 0.356602960063, "now": 0.149092945021, "might": 0.7683410765340001, "tri": 0.61759152916, "configur": 2.4427250357499997, "name": 0.09723316638430002, "code": 1.35601909597, "hard": 1.00522796406, "support": 0.237880610037, "see": 0.240921585492, "semant": 3.6662106543, "pwd": 7.2746685411000005, "break": 0.88733019029, "feel": 1.1428493419299999, "samplesmonetjpg": 7.369978720910001, "also": 0.0146571578, "specifi": 1.93451151621, "pythonnumpip": 7.369978720910001, "mean": 0.37092128352, "style": 0.866289529121, "reliant": 4.05579271624, "will": 0.202786534915, "becaus": 0.139343158825, "nummib": 7.369978720910001, "them": 0.0941833269093, "tour": 1.2492418381000001, "ndframe": 7.369978720910001, "the": 0.0, "may": 0.050709995284400004, "meet": 0.510363817255, "want": 0.6916366062549999, "geforc": 7.369978720910001, "system": 0.327430345585, "behind": 0.7345572374320001, "howev": 0.0903151173475, "gone": 1.65328002099, "minut": 1.1353719359799999, "that": 0.00397614837964, "cython": 7.369978720910001, "which": 0.00517841384543, "ident": 1.03244527565, "mechan": 1.22815639221, "other": 0.00987474791976, "peek": 5.0774439637699995, "techniqu": 1.31624384807, "one": 0.0062553516455, "ndsampl": 7.369978720910001, "hope": 0.919824304455, "status": 0.9016590696060001, "full": 0.511203624148, "some": 0.0395735090645, "algorithm": 3.33044239518, "alia": 3.4245209393900002, "imag": 0.99376210729, "sourc": 0.529218310751, "get": 0.579769005782, "mount": 1.25364519176, "like": 0.139053576545, "libopenblasdev": 7.369978720910001, "moment": 1.4497416830899998, "lasagn": 7.369978720910001, "opinion": 1.33617333331, "process": 0.527829199025, "analyt": 2.8481901438599997, "memori": 0.9454338986599999, "digest": 2.9475301717400004, "file": 1.32734588723, "alexjcneuraldoodlereleasesdownloadvnumvggnumconvpklbznum": 7.369978720910001, "next": 0.402163685499, "pwr": 6.89997509166, "necessarili": 1.99238817347, "access": 0.627805882716, "shi": 3.0171234635400004, "choic": 1.14166497543, "directori": 2.6924878733399997, "nvidiacudanum": 7.369978720910001, "substanti": 1.24639002087, "api": 4.43612185107, "engin": 0.904767558276, "back": 0.23166743089699998, "chang": 0.166275625058, "bit": 2.12032652634, "project": 0.561601885907, "differ": 0.212321121312, "been": 0.023645982368400004, "first": 0.0075872898121599995, "binari": 3.4781584227999995, "most": 0.020747896295599998, "between": 0.033953681165299995, "magic": 2.06766933309, "hack": 3.7699304805000002, "tutori": 4.0853151555, "excel": 1.5778801652, "expos": 1.6167713629299998, "varlibaptlist": 7.369978720910001, "all": 0.011402632097799998, "devnvidianum": 7.369978720910001, "today": 0.559395353679, "gpu": 5.8883741799800005, "zlibnumgdev": 7.369978720910001, "someth": 1.18830712273, "includ": 0.0188846813905, "have": 0.0147850023412, "normal": 0.959639378783, "weight": 1.58492352612, "architectur": 1.63469757919, "cool": 1.9253988473800001, "more": 0.017024931599999998, "and": 6.29901420636e-05, "list": 0.309845761506, "moduleinittool": 7.369978720910001, "rough": 1.1926572072700001, "folk": 2.03677695251, "benefit": 1.12116245116, "amount": 0.819898886199, "buildessenti": 7.369978720910001, "volatil": 3.4842996908199995, "befor": 0.0956377718795, "librari": 0.986809980943, "state": 0.0466100027668, "anytim": 4.73808988077, "pythonnumsix": 7.369978720910001, "window": 1.7689675242900003, "masterpiec": 2.96082341885, "can": 0.162341096394, "avail": 0.547454586289, "linux": 4.17539558861, "workaround": 6.009002167769999, "comput": 1.36806891594, "make": 0.07349765782289999, "few": 0.275577913653, "depend": 0.806969815, "onli": 0.025324268329099998, "eas": 2.202339678, "amazon": 3.50086321649, "this": 0.0037864490525, "necessari": 1.0445450673999999, "numdnumdbnumfdabnum": 7.369978720910001, "pretrain": 7.369978720910001, "packag": 2.0577584491900005, "pretti": 2.75684036527, "worri": 2.3323769785799997, "while": 0.04324998379380001, "block": 1.16400781588, "sampl": 1.9786264883900002, "revert": 2.73330986786, "oper": 0.441342964347, "cnumcnumdnumcnumfnumcbfnumbfnumbnumenumbnumbnumbnumanumecnumdacdenumb": 7.369978720910001, "pythonnumscipi": 7.369978720910001, "sinc": 0.0803681994577, "bio": 3.7456377879300002, "origin": 0.128612437587, "fewer": 1.7831046645, "offici": 0.339917317543, "worth": 1.65065103492, "text": 1.14048200999, "pythonnumdev": 7.369978720910001, "gpus": 6.964513612799999, "import": 0.292818277066, "alexjcneuraldoodlegit": 7.369978720910001, "everi": 0.391485427421, "copi": 1.34483764744, "when": 0.0205549888584, "nice": 2.8768580387299996, "page": 0.711326032411, "ubuntu": 6.27136643224, "tmpnvidiadockerdeb": 7.369978720910001, "bash": 4.42029038586, "host": 0.996658931332, "write": 0.721512439877, "recent": 0.434413741288, "agnost": 4.15110289604, "within": 0.21263272059799998, "libfreetypenumdev": 7.369978720910001, "learn": 0.842752064745, "fermi": 4.87677326831, "deb": 4.7897618913199995}, "freq": {"art": 2, "reliabl": 1, "enumenumdnumenumcd": 1, "onc": 2, "too": 1, "relat": 1, "entrypoint": 1, "troubl": 2, "pip": 3, "data": 2, "immedi": 1, "devicegpu": 2, "thank": 1, "reap": 1, "devnvidiactl": 1, "follow": 1, "uptod": 1, "etc": 2, "specif": 1, "default": 1, "function": 3, "happi": 1, "breez": 1, "crop": 1, "driver": 16, "pythonnum": 4, "well": 2, "product": 7, "done": 4, "dispa": 1, "complet": 5, "huh": 1, "know": 1, "primarili": 1, "neuraldoodl": 3, "their": 2, "dev": 1, "particular": 1, "instead": 1, "creat": 2, "enjoy": 1, "alex": 3, "how": 4, "test": 3, "teammat": 1, "dpkg": 1, "fair": 1, "inconsist": 1, "had": 2, "special": 2, "distribut": 2, "end": 1, "frame": 2, "soon": 1, "paint": 2, "deep": 1, "numbnumfcdcnumd": 1, "wiki": 2, "site": 2, "monet": 3, "second": 1, "clone": 1, "updat": 2, "new": 1, "below": 1, "similar": 2, "but": 4, "certain": 1, "need": 4, "our": 8, "whirlwind": 1, "off": 2, "these": 1, "walk": 2, "struggl": 1, "has": 7, "enough": 1, "use": 16, "fri": 1, "aptget": 2, "libopenjpegnum": 1, "perf": 1, "out": 5, "model": 6, "format": 1, "good": 1, "alway": 2, "libjpegdev": 1, "docker": 32, "start": 2, "pain": 1, "tmp": 1, "usag": 1, "not": 6, "wish": 1, "doodl": 5, "libtiffnumdev": 1, "difficult": 1, "less": 1, "git": 2, "nvidiacudanumcudnnnumdevel": 2, "quick": 2, "shanum": 1, "easi": 3, "about": 4, "handl": 2, "gitlik": 1, "than": 3, "sketch": 2, "design": 2, "anoth": 1, "instal": 18, "turn": 1, "let": 5, "scienc": 1, "rectifi": 1, "nvidianvidiadockerreleasesdownloadvnumrcnumnvidiadockernumrcnumamdnumdeb": 1, "job": 1, "github": 2, "custom": 1, "away": 1, "ensur": 3, "uncorr": 1, "libwebpdev": 1, "alexjcneuraldoodl": 3, "practic": 1, "alreadi": 11, "sudo": 1, "sens": 1, "provid": 5, "numadnumenum": 1, "either": 1, "numfnumenumacnumc": 1, "develop": 2, "setup": 3, "gfortran": 1, "elect": 1, "talk": 1, "transfer": 2, "network": 1, "python": 1, "box": 1, "cnumbnumcnum": 1, "should": 4, "enumbnumbnum": 1, "pkgconfig": 1, "document": 1, "industri": 1, "version": 8, "pythonnumnetworkx": 1, "platform": 1, "set": 3, "question": 1, "pythonnummatplotlib": 1, "from": 11, "ecosystem": 1, "usagecap": 1, "answer": 2, "anywher": 2, "pythonnumnumpi": 1, "detail": 1, "num": 17, "aren": 1, "free": 1, "environ": 6, "curv": 1, "glorifi": 1, "for": 11, "dockerfil": 3, "assumey": 1, "output": 1, "match": 2, "releas": 2, "roll": 1, "with": 13, "theano": 2, "samplescoastlinepng": 1, "are": 4, "solut": 4, "newer": 2, "effort": 1, "nvidiasmi": 5, "gpuutil": 1, "option": 1, "fan": 1, "chanc": 1, "work": 8, "focus": 1, "educ": 1, "hacki": 1, "remov": 1, "then": 1, "doe": 3, "littl": 1, "photo": 1, "proper": 1, "bug": 1, "alexjc": 1, "step": 1, "indico": 6, "pythonnumtk": 1, "his": 2, "massachusett": 1, "type": 1, "requirementstxt": 2, "thing": 1, "probabl": 1, "machin": 8, "into": 3, "nvidiacuda": 3, "paper": 1, "reach": 1, "champanard": 1, "through": 2, "download": 2, "requir": 8, "where": 1, "what": 1, "local": 1, "allow": 2, "main": 1, "chat": 1, "find": 2, "briefli": 1, "demo": 1, "jupytersparkmeso": 1, "curious": 1, "wrong": 1, "own": 2, "cmake": 1, "base": 2, "numenumbnumdfnumdnum": 1, "hey": 1, "permiss": 1, "post": 1, "here": 1, "wget": 3, "softwar": 2, "blog": 1, "describ": 1, "long": 1, "assur": 1, "script": 3, "contain": 12, "adopt": 1, "problem": 1, "deploy": 5, "communiti": 1, "iterationsnum": 1, "neural": 2, "liblcmsnumdev": 1, "memoryusag": 1, "just": 2, "devic": 5, "understand": 1, "temp": 1, "coastlin": 2, "nov": 1, "featur": 2, "simpli": 1, "repost": 1, "madison": 2, "attach": 1, "bfnumdnum": 1, "artist": 1, "check": 1, "enumfnumcnumenumcnum": 1, "persistencem": 1, "rest": 1, "numafnumenum": 1, "tool": 6, "nvidiadockerplugin": 1, "whenev": 1, "run": 18, "enabl": 1, "guid": 1, "keep": 1, "bad": 2, "execut": 1, "order": 2, "kernel": 1, "whi": 2, "liblapackdev": 1, "hello": 1, "abl": 1, "pull": 6, "over": 1, "perhap": 1, "build": 4, "resourc": 1, "mine": 1, "read": 1, "team": 1, "exact": 1, "there": 1, "exist": 6, "busid": 1, "volum": 2, "inform": 1, "nvidiadock": 25, "hardwar": 4, "say": 1, "semisupervis": 1, "exampl": 1, "portabl": 2, "doodlepi": 3, "nvidiamodprob": 1, "take": 4, "previous": 1, "now": 2, "might": 1, "tri": 2, "configur": 7, "name": 2, "code": 4, "hard": 1, "support": 6, "see": 1, "semant": 1, "pwd": 2, "break": 1, "feel": 1, "samplesmonetjpg": 1, "also": 2, "specifi": 2, "pythonnumpip": 1, "mean": 3, "style": 4, "reliant": 1, "will": 2, "becaus": 1, "nummib": 2, "them": 2, "tour": 1, "ndframe": 2, "the": 66, "may": 4, "meet": 1, "want": 2, "geforc": 1, "system": 3, "behind": 1, "howev": 2, "gone": 1, "minut": 1, "that": 10, "cython": 1, "which": 2, "ident": 2, "mechan": 1, "other": 2, "peek": 1, "techniqu": 1, "one": 1, "ndsampl": 2, "hope": 1, "status": 1, "full": 1, "some": 2, "algorithm": 1, "alia": 3, "imag": 14, "sourc": 1, "get": 5, "mount": 1, "like": 5, "libopenblasdev": 1, "moment": 1, "lasagn": 2, "opinion": 1, "process": 3, "analyt": 1, "memori": 1, "digest": 1, "file": 3, "alexjcneuraldoodlereleasesdownloadvnumvggnumconvpklbznum": 1, "next": 1, "pwr": 1, "necessarili": 1, "access": 6, "shi": 1, "choic": 1, "directori": 1, "nvidiacudanum": 3, "substanti": 1, "api": 1, "engin": 2, "back": 1, "chang": 1, "bit": 1, "project": 7, "differ": 2, "been": 1, "first": 1, "binari": 2, "most": 1, "between": 1, "magic": 1, "hack": 1, "tutori": 2, "excel": 1, "expos": 1, "varlibaptlist": 1, "all": 1, "devnvidianum": 1, "today": 1, "gpu": 3, "zlibnumgdev": 1, "someth": 3, "includ": 2, "have": 7, "normal": 1, "weight": 1, "architectur": 1, "cool": 1, "more": 6, "and": 31, "list": 1, "moduleinittool": 1, "rough": 1, "folk": 1, "benefit": 3, "amount": 1, "buildessenti": 1, "volatil": 1, "befor": 2, "librari": 2, "state": 1, "anytim": 1, "pythonnumsix": 1, "window": 1, "masterpiec": 1, "can": 9, "avail": 1, "linux": 2, "workaround": 1, "comput": 1, "make": 2, "few": 3, "depend": 3, "onli": 3, "eas": 1, "amazon": 1, "this": 15, "necessari": 1, "numdnumdbnumfdabnum": 1, "pretrain": 2, "packag": 1, "pretti": 1, "worri": 1, "while": 1, "block": 2, "sampl": 2, "revert": 1, "oper": 2, "cnumcnumdnumcnumfnumcbfnumbfnumbnumenumbnumbnumbnumanumecnumdacdenumb": 1, "pythonnumscipi": 1, "sinc": 2, "bio": 1, "origin": 4, "fewer": 1, "offici": 2, "worth": 1, "text": 1, "pythonnumdev": 1, "gpus": 6, "import": 1, "alexjcneuraldoodlegit": 1, "everi": 1, "copi": 3, "when": 4, "nice": 1, "page": 1, "ubuntu": 2, "tmpnvidiadockerdeb": 2, "bash": 3, "host": 7, "write": 1, "recent": 2, "agnost": 1, "within": 9, "libfreetypenumdev": 1, "learn": 9, "fermi": 1, "deb": 1}, "idf": {"art": 1.9994962216599999, "reliabl": 6.681818181819999, "enumenumdnumenumcd": 1587.6, "onc": 1.4974533106999999, "too": 1.81585268215, "relat": 1.23750876919, "entrypoint": 1587.6, "troubl": 4.99088337001, "pip": 135.692307692, "data": 3.37643555934, "immedi": 2.02862254025, "devicegpu": 1587.6, "thank": 6.00681044268, "reap": 73.1612903226, "devnvidiactl": 1587.6, "follow": 1.04640126549, "uptod": 1587.6, "etc": 4.2066772655, "specif": 1.8719490626099997, "default": 21.1398135819, "function": 2.495441685, "happi": 6.125, "breez": 54.0, "crop": 9.71009174312, "driver": 6.79914346895, "pythonnum": 1587.6, "well": 1.0655748708, "product": 1.62264922322, "done": 2.3302509907499998, "dispa": 1587.6, "complet": 1.24021560816, "huh": 661.5, "know": 2.59327017315, "primarili": 2.43459592087, "neuraldoodl": 1587.6, "their": 1.01547908405, "dev": 148.373831776, "particular": 1.3814827706200001, "instead": 1.59461631177, "creat": 1.2492917847, "enjoy": 3.3269069572500003, "alex": 10.655033557000001, "how": 1.60250328051, "test": 2.65707112971, "teammat": 31.6886227545, "dpkg": 1587.6, "fair": 3.20533010297, "inconsist": 14.3934723481, "had": 1.0475750577399998, "special": 1.4881889763799998, "distribut": 2.7396031061299997, "end": 1.10680423871, "frame": 6.280063291139999, "soon": 1.9817750592900003, "paint": 4.08648648649, "deep": 3.6279707495399998, "numbnumfcdcnumd": 1587.6, "wiki": 49.457943925200006, "site": 1.9721739130400002, "monet": 139.263157895, "second": 1.1130898128, "clone": 32.5327868852, "updat": 5.56466876972, "new": 1.0178880554, "below": 2.25607503197, "similar": 1.37514075357, "but": 1.01632417899, "certain": 1.8077886586200003, "need": 1.4372623574099999, "our": 2.35758835759, "whirlwind": 138.052173913, "off": 1.5121440137200002, "these": 1.07415426252, "walk": 3.56363636364, "struggl": 3.36, "has": 1.0436497502, "enough": 2.2319696330700003, "use": 1.0296387573799999, "fri": 20.5914396887, "aptget": 1587.6, "libopenjpegnum": 1587.6, "perf": 933.882352941, "out": 1.06016694491, "model": 2.0905978404, "format": 2.53125, "good": 1.51981619759, "alway": 2.06745670009, "libjpegdev": 1587.6, "docker": 337.787234043, "start": 1.26673581744, "pain": 6.55762081784, "tmp": 1587.6, "usag": 6.427530364369999, "not": 1.01567398119, "wish": 3.67755385685, "doodl": 140.495575221, "libtiffnumdev": 1587.6, "difficult": 2.48957189901, "less": 1.46904783936, "git": 360.818181818, "nvidiacudanumcudnnnumdevel": 1587.6, "quick": 2.205, "shanum": 1587.6, "easi": 5.2937645882, "about": 1.06486015159, "handl": 3.9229058561900003, "gitlik": 1587.6, "than": 1.03278688525, "sketch": 10.956521739100001, "design": 1.45825296225, "anoth": 1.13643521832, "instal": 3.78721374046, "turn": 1.3838912133899999, "let": 3.48616600791, "scienc": 2.31969608416, "rectifi": 54.3698630137, "nvidianvidiadockerreleasesdownloadvnumrcnumnvidiadockernumrcnumamdnumdeb": 1587.6, "job": 3.2539454806299997, "github": 1587.6, "custom": 3.6346153846199996, "away": 1.85142857143, "ensur": 3.4127257093700005, "uncorr": 1587.6, "libwebpdev": 1587.6, "alexjcneuraldoodl": 1587.6, "practic": 1.70434782609, "alreadi": 1.9551724137900002, "sudo": 1587.6, "sens": 2.8365195640499996, "provid": 1.21552714187, "numadnumenum": 1587.6, "either": 1.5830092731099998, "numfnumenumacnumc": 1587.6, "develop": 1.1955719557200002, "setup": 34.1419354839, "gfortran": 1587.6, "elect": 2.5228031145700003, "talk": 3.0303493033, "transfer": 2.72549356223, "network": 2.59369384088, "python": 56.2978723404, "box": 4.12685209254, "cnumbnumcnum": 1587.6, "should": 1.6643254009900001, "enumbnumbnum": 1587.6, "pkgconfig": 1587.6, "document": 2.5409731114, "industri": 2.02319357716, "version": 2.0083491461099996, "pythonnumnetworkx": 1587.6, "platform": 6.2332155476999995, "set": 1.18707940781, "question": 2.20408163265, "pythonnummatplotlib": 1587.6, "from": 1.00056721497, "ecosystem": 26.111842105300003, "usagecap": 1587.6, "answer": 4.64890190337, "anywher": 10.1638924456, "pythonnumnumpi": 1587.6, "detail": 2.26186066391, "num": 1.00031504001, "aren": 481.09090909099996, "free": 1.71818181818, "environ": 3.43561999567, "curv": 11.1098670399, "glorifi": 59.2388059701, "for": 1.00031504001, "dockerfil": 1587.6, "assumey": 1587.6, "output": 7.676982591880001, "match": 3.5676404494400002, "releas": 1.8377126982299998, "roll": 4.27578777269, "with": 1.0011982089899998, "theano": 1587.6, "samplescoastlinepng": 1587.6, "are": 1.02990593578, "solut": 4.7278141751, "newer": 9.9225, "effort": 1.89247824532, "nvidiasmi": 1587.6, "gpuutil": 1587.6, "option": 4.04896710023, "fan": 4.805084745759999, "chanc": 4.2449197861000005, "work": 1.11520089913, "focus": 2.01012914662, "educ": 2.00733341763, "hacki": 1587.6, "remov": 2.0058117498400003, "then": 1.08657860516, "doe": 1.70581282905, "littl": 1.5499365420299998, "photo": 6.41973311767, "proper": 3.3388012618299996, "bug": 27.372413793099998, "alexjc": 1587.6, "step": 2.8279301745599996, "indico": 1587.6, "pythonnumtk": 1587.6, "his": 1.0943682360200002, "massachusett": 7.632692307689999, "type": 2.0281042411900003, "requirementstxt": 1587.6, "thing": 2.4065484311099996, "probabl": 2.64555907349, "machin": 4.02433460076, "into": 1.01502461479, "nvidiacuda": 1587.6, "paper": 2.6628648104700003, "reach": 1.49801849406, "champanard": 1587.6, "through": 1.07074930869, "download": 14.6457564576, "requir": 1.52844902282, "where": 1.06715063521, "what": 1.25343439128, "local": 1.51720183486, "allow": 1.2716059271100002, "main": 1.25303867403, "chat": 36.164009111599995, "find": 1.7294117647099998, "briefli": 4.8669527897, "demo": 28.7088607595, "jupytersparkmeso": 1587.6, "curious": 23.381443299, "wrong": 5.478260869570001, "own": 1.17844418052, "cmake": 1587.6, "base": 1.14628158845, "numenumbnumdfnumdnum": 1587.6, "hey": 39.3945409429, "permiss": 6.280063291139999, "post": 2.23826307627, "here": 2.42307692308, "wget": 1587.6, "softwar": 10.2624434389, "blog": 14.1876675603, "describ": 1.47027227264, "long": 1.2657259028899999, "assur": 7.941970985489999, "script": 8.299006795610001, "contain": 1.59814777532, "adopt": 2.0442956477000003, "problem": 1.76674827509, "deploy": 7.41869158879, "communiti": 1.96121062384, "iterationsnum": 1587.6, "neural": 59.4606741573, "liblcmsnumdev": 1587.6, "memoryusag": 1587.6, "just": 1.33580143037, "devic": 5.00820189274, "understand": 2.96858638743, "temp": 63.2509960159, "coastlin": 21.2530120482, "nov": 26.0689655172, "featur": 1.52712581762, "simpli": 2.5192002538900002, "repost": 933.882352941, "madison": 15.703264095, "attach": 4.4885496183199995, "bfnumdnum": 1587.6, "artist": 2.86673889491, "check": 6.50655737705, "enumfnumcnumenumcnum": 1587.6, "persistencem": 1587.6, "rest": 1.9573418813999999, "numafnumenum": 1587.6, "tool": 4.99716713881, "nvidiadockerplugin": 1587.6, "whenev": 11.622254758399999, "run": 1.55692850838, "enabl": 3.5421686747, "guid": 2.49113447356, "keep": 2.04245465071, "bad": 3.3944836433599996, "execut": 2.2363713199, "order": 1.24625166811, "kernel": 70.56, "whi": 3.2566153846200003, "liblapackdev": 1587.6, "hello": 44.4705882353, "abl": 1.8208510150200001, "pull": 5.18654034629, "over": 1.02525024217, "perhap": 3.14812611541, "build": 1.6341739578, "resourc": 2.9487369985100003, "mine": 4.875921375919999, "read": 2.3149606299200003, "team": 2.2748244734200003, "exact": 3.46864758575, "there": 1.04091266719, "exist": 1.4647107666799999, "busid": 1587.6, "volum": 2.40545454545, "inform": 1.5753125620200001, "nvidiadock": 1587.6, "hardwar": 18.8104265403, "say": 1.7544480053, "semisupervis": 1587.6, "exampl": 1.50483412322, "portabl": 19.5276752768, "doodlepi": 1587.6, "nvidiamodprob": 1587.6, "take": 1.13961668222, "previous": 1.42846859816, "now": 1.160780873, "might": 2.1561863370900003, "tri": 1.8544562551099997, "configur": 11.504347826099998, "name": 1.10211732037, "code": 3.8807137619199996, "hard": 2.73253012048, "support": 1.2685577307200002, "see": 1.27242125511, "semant": 39.1034482759, "pwd": 1443.27272727, "break": 2.42863698944, "feel": 3.1356903021900004, "samplesmonetjpg": 1587.6, "also": 1.01476510067, "specifi": 6.920662598080001, "pythonnumpip": 1587.6, "mean": 1.44906900329, "style": 2.37807070102, "reliant": 57.7309090909, "will": 1.22481098596, "becaus": 1.1495184997499999, "nummib": 1587.6, "them": 1.09876115994, "tour": 3.4876977152900004, "ndframe": 1587.6, "the": 1.0, "may": 1.05201775893, "meet": 1.6658971668399998, "want": 1.99698113208, "geforc": 1587.6, "system": 1.38739840951, "behind": 2.0845588235299997, "howev": 1.0945191313299998, "gone": 5.22408687068, "minut": 3.11233091551, "that": 1.00398406375, "cython": 1587.6, "which": 1.005191845, "ident": 2.80792359392, "mechan": 3.41492794149, "other": 1.00992366412, "peek": 160.363636364, "techniqu": 3.7293868921800004, "one": 1.00627495722, "ndsampl": 1587.6, "hope": 2.50884955752, "status": 2.4636871508400002, "full": 1.66729678639, "some": 1.04036697248, "algorithm": 27.9507042254, "alia": 30.7079303675, "imag": 2.70137825421, "sourc": 1.69760479042, "get": 1.78562591385, "mount": 3.5030891438699996, "like": 1.14918566775, "libopenblasdev": 1587.6, "moment": 4.262013422819999, "lasagn": 1587.6, "opinion": 3.8044572250199997, "process": 1.69524826482, "analyt": 17.256521739100002, "memori": 2.57392996109, "digest": 19.0588235294, "file": 3.7710213776699995, "alexjcneuraldoodlereleasesdownloadvnumvggnumconvpklbznum": 1587.6, "next": 1.4950560316400001, "pwr": 992.25, "necessarili": 7.33302540416, "access": 1.8734953976900002, "shi": 20.4324324324, "choic": 3.1319786940200003, "directori": 14.768372093, "nvidiacudanum": 1587.6, "substanti": 3.4777656078900003, "api": 84.44680851060001, "engin": 2.47135740971, "back": 1.26070038911, "chang": 1.1808985421, "bit": 8.33385826772, "project": 1.7534791252500002, "differ": 1.23654490225, "been": 1.0239277652399998, "first": 1.00761614623, "binari": 32.4, "most": 1.02096463023, "between": 1.03453668708, "magic": 7.9063745019899985, "hack": 43.3770491803, "tutori": 59.4606741573, "excel": 4.84467500763, "expos": 5.03680203046, "varlibaptlist": 1587.6, "all": 1.01146788991, "devnvidianum": 1587.6, "today": 1.74961428257, "gpu": 360.818181818, "zlibnumgdev": 1587.6, "someth": 3.28152128979, "includ": 1.0190641247799999, "have": 1.0148948411399998, "normal": 2.61075481006, "weight": 4.878918254459999, "architectur": 5.12790697674, "cool": 6.8578833693300005, "more": 1.0171706817, "and": 1.00006299213, "list": 1.36321483771, "moduleinittool": 1587.6, "rough": 3.29582727839, "folk": 7.6658619024600005, "benefit": 3.06841901817, "amount": 2.27027027027, "buildessenti": 1587.6, "volatil": 32.5995893224, "befor": 1.10036041031, "librari": 2.68266306185, "state": 1.0477133240899998, "anytim": 114.215827338, "pythonnumsix": 1587.6, "window": 5.86479497599, "masterpiec": 19.3138686131, "can": 1.17626139142, "avail": 1.7288467821, "linux": 65.0655737705, "workaround": 407.07692307699995, "comput": 3.9277585353800006, "make": 1.0762660158600001, "few": 1.31729173581, "depend": 2.2411067193700003, "onli": 1.0256476516600002, "eas": 9.04615384615, "amazon": 33.1440501044, "this": 1.00379362671, "necessari": 2.8421052631599997, "numdnumdbnumfdabnum": 1587.6, "pretrain": 1587.6, "packag": 7.828402366860001, "pretti": 15.75, "worri": 10.302401038300001, "while": 1.0441988950299999, "block": 3.20274359492, "sampl": 7.23280182232, "revert": 15.383720930199999, "oper": 1.55479384977, "cnumcnumdnumcnumfnumcbfnumbfnumbnumenumbnumbnumbnumanumecnumdacdenumb": 1587.6, "pythonnumscipi": 1587.6, "sinc": 1.08368600683, "bio": 42.336000000000006, "origin": 1.13724928367, "fewer": 5.94829524166, "offici": 1.40483143085, "worth": 5.210370856580001, "text": 3.12827586207, "pythonnumdev": 1587.6, "gpus": 1058.4, "import": 1.3401992233700002, "alexjcneuraldoodlegit": 1587.6, "everi": 1.47917637194, "copi": 3.8375634517800004, "when": 1.02076769755, "nice": 17.7583892617, "page": 2.03669018602, "ubuntu": 529.2, "tmpnvidiadockerdeb": 1587.6, "bash": 83.1204188482, "host": 2.7092150170599996, "write": 2.0575427682700003, "recent": 1.54405757635, "agnost": 63.504, "within": 1.2369302688, "libfreetypenumdev": 1587.6, "learn": 2.32275054865, "fermi": 131.20661157, "deb": 120.27272727299999}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Data Science Deployments With Docker</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/12/data-science-deployments-docker.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Data Science Deployments With Docker Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/12/northwestern-online-master-science-predictive-analytics.html\" rel=\"prev\" title=\"Online Master of Science in Predictive Analytics.\"/>\n<link href=\"https://www.kdnuggets.com/2016/12/hard-thing-about-deep-learning.html\" rel=\"next\" title=\"The hard thing about deep learning\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/12/data-science-deployments-docker.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=58785\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/12/data-science-deployments-docker.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-58785 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 1-Dec, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/12/index.html\">Dec</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/12/tutorials.html\">Tutorials, Overviews</a> \u00bb Data Science Deployments With Docker (\u00a0<a href=\"/2016/n43.html\">16:n43</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Data Science Deployments With Docker</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/12/northwestern-online-master-science-predictive-analytics.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/12/hard-thing-about-deep-learning.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 105</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/data-science\" rel=\"tag\">Data Science</a>, <a href=\"https://www.kdnuggets.com/tag/docker\" rel=\"tag\">Docker</a>, <a href=\"https://www.kdnuggets.com/tag/gpu\" rel=\"tag\">GPU</a>, <a href=\"https://www.kdnuggets.com/tag/indico\" rel=\"tag\">indico</a>, <a href=\"https://www.kdnuggets.com/tag/nvidia\" rel=\"tag\">NVIDIA</a></div>\n<br/>\n<p class=\"excerpt\">\n     With the recent release of NVIDIA\u2019s\u00a0nvidia-docker tool, accessing GPUs from within Docker is a breeze. In this tutorial we\u2019ll walk you through setting up\u00a0nvidia-docker\u00a0so you too can deploy machine learning models with ease.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By Madison May, <a href=\"https://indico.io/\" target=\"_blank\">indico</a></b>.</p>\n<p><img alt=\"Docker\" src=\"/wp-content/uploads/docker-logo.jpg\" width=\"99%\"/></p>\n<p>Deploying machine learning models has always been a struggle. Most of the software industry has adopted the use of container engines like Docker for deploying code to production, but since accessing hardware resources like GPUs from Docker was difficult and required hacky, driver specific workarounds, the machine learning community has shied away from this option. With the recent release of NVIDIA\u2019s\u00a0<code>nvidia-docker</code>\u00a0tool, however, accessing GPUs from within Docker is a breeze, and we\u2019re already reaping the benefits here at indico. In this tutorial we\u2019ll walk you through setting up\u00a0<code>nvidia-docker</code>\u00a0so you too can deploy machine learning models with ease.</p>\n<p>Before we get into the details however, let\u2019s talk briefly about why using Docker for your next data science project may be a good choice. There is certainly a learning curve for the tools in the Docker ecosystem, but the benefits are worth the effort.</p>\n<ol>\n<li>No inconsistencies between team environment configurations:Software configuration is always a pain. Docker\u2019s configure once, run anywhere model means your teammates will have to worry less about environment setup and can focus more on writing code and building machine learning models.\n<li>Reliable deployments:Fewer bugs crop up in production when you can be assured that your development environment is identical to your production environment.\n<li>Git-like tool for environment configuration:If something does go wrong in production, reverting to a previous Docker image ensures you can quickly get back to a functional state.\n</li></li></li></ol>\n<h3>Why is a special solution needed for using GPUs within Docker?</h3>\n<p>\u00a0<br>\nDocker is designed to be hardware and platform agnostic. GPUs are specialized hardware that is not necessarily available on every host. Because of this, the Docker binary does not include GPU support out of the box, and requires a fair amount of configuration to get things working properly. When we first started using Docker in production and needed to enable access to GPU devices from within the container, we had to roll our own solution. It was educational to have to understand the mechanisms by which hardware like GPUs are exposed to an operating system (primarily the\u00a0<code>/dev</code>\u00a0block), but we ended up with a solution that was not portable and required that the host\u2019s NVIDIA driver was identical to a second copy of the driver installed within the container. Whenever we updated our NVIDIA drivers to support newer CUDA versions, we had to make a breaking change to our Docker image in order to ensure drivers matched exactly.</br></p>\n<p>Thankfully, the nice folks at NVIDIA have rectified this problem by releasing\u00a0<code>nvidia-docker</code>, a tool for configuring docker to allow GPU access from within containers.</p>\n<h3>How does\u00a0<code>nvidia-docker</code>\u00a0work?</h3>\n<p>\u00a0<br>\n<code>nvidia-docker</code>\u00a0takes the following steps to get CUDA working within your container:</br></p>\n<ul>\n<li>It attaches the GPU device blocks to your container as Docker volumes (/dev/nvidia0, /dev/nvidiactl, etc.)\n<li>It mounts the device drivers on your host within the Docker container\n</li></li></ul>\n<p>This means that as long as you have a functional NVIDIA driver on your host and a CUDA version recent enough to support your driver is installed within your container, you should be able to execute CUDA code from your running Docker container. Importantly, the Docker container can also be run in another environment with different driver versions, making it easy to build once and then run anywhere.</p>\n<h3>How do I install\u00a0<code>nvidia-docker</code>?</h3>\n<p>\u00a0<br>\nUse of\u00a0<code>nvidia-docker</code>\u00a0requires:</br></p>\n<ul>\n<li>Linux kernel &gt; 3.10\n<li>NVIDIA GPU with Architecture &gt; Fermi (2.1)\n<li>NVIDIA drivers &gt;= 340.29 with binary nvidia-modprobe\n<li><a href=\"https://docs.docker.com/engine/installation/linux/ubuntulinux/\" target=\"_blank\">Docker &gt;= 1.9</a>\n</li></li></li></li></ul>\n<p>If you already meet these requirements, installation of\u00a0<code>nvidia-docker</code>\u00a0is as easy as installing a\u00a0<code>.deb file</code>\u00a0(on Ubuntu 14.04):</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>bash\r\n# Install nvidia-docker and nvidia-docker-plugin\r\nwget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.0-rc.3/nvidia-docker_1.0.0.rc.3-1_amd64.deb\r\nsudo dpkg -i /tmp/nvidia-docker*.deb &amp;&amp; rm /tmp/nvidia-docker*.deb</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>If you already have a working\u00a0<code>nvidia-docker</code>\u00a0on your host machine, you can try out\u00a0<code>nvidia-docker</code>\u00a0immediately by running the\u00a0<code>nvidia/cuda</code>\u00a0Docker image provided by NVIDIA:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># Test nvidia-smi\r\nnvidia-docker run --rm nvidia/cuda nvidia-smi</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Depending on your driver version, you may need to specify a different version of CUDA to run when testing your installation:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># Test nvidia-smi\r\nnvidia-docker run --rm nvidia/cuda:7.5 nvidia-smi</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>If all is well, you should see something like:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ nvidia-docker run --rm nvidia/cuda:7.5 nvidia-smi\r\n7.5: Pulling from nvidia/cuda\r\nbf5d46315322: Already exists\r\n9f13e0ac480c: Already exists\r\ne8988b5b3097: Already exists\r\n40af181810e7: Already exists\r\ne6f7c7e5c03e: Already exists\r\n261ad237e477: Already exists\r\n83d2db6fdab9: Pull complete\r\ne8e8d0e851cd: Pull complete\r\nc0000b849c19: Pull complete\r\n180b04fcdc2d: Pull complete\r\n1e5b85df3d02: Pull complete\r\nDigest: sha256:c601c6902928d62c79f2cbf90bf07477b666e28b51b094b3a10924ec7dacde8b\r\nStatus: Downloaded newer image for nvidia/cuda:7.5\r\nFri Nov  4 16:34:00 2016       \r\n+------------------------------------------------------+                       \r\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |                       \r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 760     Off  | 0000:01:00.0     N/A |                  N/A |\r\n| 17%   31C    P8    N/A /  N/A |    172MiB /  4095MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0                  Not Supported                                         |\r\n+-----------------------------------------------------------------------------+</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>For distributions other than Ubuntu or to install\u00a0<code>nvidia-docker</code>\u00a0from source, check out the\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/wiki#quick-start\" target=\"_blank\"><code>nvidia-docker</code>\u00a0quick start guide</a>\u00a0and\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/wiki/Installation\" target=\"_blank\">installation documentation</a>.</p>\n<p>Now let\u2019s use\u00a0<code>nvidia-docker</code>\u00a0for something more substantial. We\u2019ll be setting up and running the\u00a0<a href=\"https://github.com/alexjc/neural-doodle\" target=\"_blank\">\u201cneural doodle\u201d project</a>\u00a0from Alex Champanard (<a href=\"https://twitter.com/alexjc\" target=\"_blank\">@alexjc</a>). The project takes rough sketches and turns them into artistic masterpieces using techniques from the\u00a0<a href=\"https://arxiv.org/abs/1603.01768\" target=\"_blank\">Semantic Style Transfer paper</a>.</p>\n<p>Alex has already done the hard work of providing us with a Docker image of his project, and has gone to the trouble of installing the necessary CUDA drivers in the Docker image as well. Normally we\u2019d need to have a functioning installation of CUDA, Theano, and the lasagne library in order to run his code, but since he\u2019s provided us with a Docker image we should be up and running in just a few minutes.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>git clone https://github.com/alexjc/neural-doodle.git &amp;&amp; cd neural-doodle\r\nalias doodle=\"nvidia-docker run -v ($pwd)/samples:/nd/samples -v ($pwd)/frames:/nd/frames -it alexjc/neural-doodle:gpu\"\r\n\r\n# paint a photo of a coastline in the style of Monet\r\ndoodle --style samples/Monet.jpg --output samples/Coastline.png --device=gpu --iterations=40</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>This example takes this original Monet painting:</p>\n<p><img alt=\"original Monet painting\" src=\"https://indico.io/blog/wp-content/uploads/2016/11/Monet.jpg\" width=\"99%\"/></p>\n<p>and this sketch of a similar coastline:</p>\n<p><img alt=\"coastline sketch\" src=\"https://indico.io/blog/wp-content/uploads/2016/11/Coastline_sem.png\" width=\"99%\"/></p>\n<p>and creates a new work of art in style similar to the original Monet:</p>\n<p><img alt=\"new art, Monet style\" src=\"https://indico.io/blog/wp-content/uploads/2016/11/new_work_of_art.png\" width=\"99%\"/></p>\n<p>Pretty cool, huh?</p>\n<p>Let\u2019s walk through the\u00a0<code>neural-doodle</code>\u00a0dockerfile and the\u00a0<code>doodle</code>\u00a0alias to remove some of the magic behind what we\u2019ve just done.</p>\n<p>The dockerfile used to build the\u00a0<code>alexjc/neural-doodle:gpu</code>\u00a0image is below:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>FROM nvidia/cuda:7.5-cudnn4-devel\r\n\r\n# Install dependencies\r\nRUN apt-get -qq update            &amp;&amp; \\\r\n    apt-get -qq install --assume-yes \\\r\n        \"module-init-tools\"         \\\r\n        \"build-essential\"           \\\r\n        \"cmake\"                     \\\r\n        \"git\"                       \\\r\n        \"wget\"                      \\\r\n        \"libopenjpeg2\"              \\\r\n        \"libopenblas-dev\"           \\\r\n        \"liblapack-dev\"             \\\r\n        \"libjpeg-dev\"               \\\r\n        \"libtiff5-dev\"              \\\r\n        \"zlib1g-dev\"                \\\r\n        \"libfreetype6-dev\"          \\\r\n        \"liblcms2-dev\"              \\\r\n        \"libwebp-dev\"               \\\r\n        \"gfortran\"                  \\\r\n        \"pkg-config\"                \\\r\n        \"python3\"                   \\\r\n        \"python3-dev\"               \\\r\n        \"python3-pip\"               \\\r\n        \"python3-numpy\"             \\\r\n        \"python3-scipy\"             \\\r\n        \"python3-matplotlib\"        \\\r\n        \"python3-six\"               \\\r\n        \"python3-networkx\"          \\\r\n        \"python3-tk\"             &amp;&amp;  \\\r\n    rm -rf /var/lib/apt/lists/*  &amp;&amp;  \\\r\n    python3 -m pip -q install \"cython\"\r\n\r\n# Install requirements before copying project files\r\nWORKDIR /nd\r\nCOPY requirements.txt .\r\nRUN python3 -m pip -q install -r \"requirements.txt\"\r\n\r\n# Copy only required project files\r\nCOPY doodle.py .\r\n\r\n# Get a pre-trained neural network (VGG19)\r\nRUN wget -q \"https://github.com/alexjc/neural-doodle/releases/download/v0.0/vgg19_conv.pkl.bz2\"\r\n\r\n# Set an entrypoint to the main doodle.py script\r\nENTRYPOINT [\"python3\", \"doodle.py\", \"--device=gpu\"]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Hey, this isn\u2019t so bad. The dockerfile Alex used is based off of an official NVIDIA Docker image (<code>nvidia/cuda:7.5-cudnn4-devel</code>) that already includes the required CUDA libraries, so it only has to describe how to install a few system dependencies for working with image formats, install a few machine learning Python packages with\u00a0<code>pip</code>\u00a0(Theano, lasagne, etc.), and download some pre-trained model weights. It\u2019s little more than a glorified bash setup script.</p>\n<p>The\u00a0<code>doodle</code>\u00a0alias isn\u2019t bad either. It simply specifies the Docker image we\u2019ll be running (<code>alexjc/neural-doodle:gpu</code>) and lets Docker know that the\u00a0<code>./samples</code>\u00a0and\u00a0<code>./frames</code>\u00a0directories should be accessible from the Docker container at\u00a0<code>/nd/samples/</code>\u00a0and\u00a0<code>/nd/frames</code>. This is done using Docker\u2019s \u201cvolumes\u201d feature, which the curious can read more about on the\u00a0<a href=\"https://docs.docker.com/engine/tutorials/dockervolumes/\" target=\"_blank\">official Docker site</a>.</p>\n<p>At indico, we now use a setup to the\u00a0<code>neural-doodle</code>\u00a0configuration to host the indico API on Amazon GPUs. Instead of using our own bash scripts, we allow the\u00a0<code>nvidia-docker</code>\u00a0tool to handle the process of ensuring device drivers within the Docker container match device drivers on the host. This means when our customers wish to run our APIs on their local machines, deployment is as easy as providing them with access to our production Docker image and letting the\u00a0<code>nvidia-docker</code>\u00a0tool handle the rest.</p>\n<h3>Operating System Support</h3>\n<p>\u00a0<br/>\nAt the moment,\u00a0<code>nvidia-docker</code>\u00a0is only portable in the sense that it\u2019s not reliant on a particular GPU model, NVIDIA driver version, or linux distribution. Running\u00a0<code>nvidia-docker</code>\u00a0on\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/issues/101\" target=\"_blank\">OSX</a>\u00a0or\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/issues/197\" target=\"_blank\">Windows</a>\u00a0will likely not be supported anytime soon.</p>\n<h3>Where can I find more information on\u00a0<code>nvidia-docker</code>?</h3>\n<p>\u00a0<br/>\nNVIDIA has done an excellent job of keeping the wiki of their Github page up-to-date. Chances are if you have questions that aren\u2019t answered in this blog post, you can probably find answers in the\u00a0<code>nvidia-docker</code>\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/wiki\" target=\"_blank\">Github wiki</a>.</p>\n<p>If you\u2019re using a version of CUDA other than the one used in this demo (CUDA 7.5), you might also want to take a peek at the\u00a0<a href=\"https://hub.docker.com/r/nvidia/cuda/\" target=\"_blank\">full list of base images</a>\u00a0that NVIDIA provides for you to work with.</p>\n<p>I hope you\u2019ve enjoyed this whirlwind tour on using\u00a0<code>nvidia-docker</code>\u00a0to build and run machine learning projects, and perhaps created a bit of original algorithmic art while you\u2019re at it. If you run into trouble trying out this tutorial, or want to learn more about how we\u2019re using Docker in production at indico, feel free to reach out over our site chat and say hello. Happy hacking!</p>\n<p><b>Bio: <a href=\"https://www.linkedin.com/in/madison-may-49a1924a\" target=\"_blank\">Madison May</a></b> is a developer, designer, and engineer, and is the CTO of <a href=\"https://indico.io/\" target=\"_blank\">indico Data Solutions</a>.</p>\n<p><a href=\"https://indico.io/blog/data-science-deployments-docker/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2016/05/ibm-jupyter-spark-mesos-docker.html\">Jupyter+Spark+Mesos: An \u201cOpinionated\u201d Docker Image</a>\n<li><a href=\"/2016/07/semi-supervised-feature-transfer-deep-learning.html\">Semi-supervised Feature Transfer: The Practical Benefit of Deep Learning Today?</a>\n<li><a href=\"/2014/10/text-mining-election-analytics-massachusetts.html\">Text Mining and Election Analytics in Massachusetts</a>\n</li></li></li></ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2016/12/northwestern-online-master-science-predictive-analytics.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/12/hard-thing-about-deep-learning.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/12/index.html\">Dec</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/12/tutorials.html\">Tutorials, Overviews</a> \u00bb Data Science Deployments With Docker (\u00a0<a href=\"/2016/n43.html\">16:n43</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556479912\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.768 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-28 15:31:52 -->\n<!-- Compression = gzip -->", "content_tokenized": ["madison", "may", "indico", "deploy", "machin", "learn", "model", "has", "alway", "been", "struggl", "most", "the", "softwar", "industri", "has", "adopt", "the", "use", "contain", "engin", "like", "docker", "for", "deploy", "code", "product", "but", "sinc", "access", "hardwar", "resourc", "like", "gpus", "from", "docker", "difficult", "and", "requir", "hacki", "driver", "specif", "workaround", "the", "machin", "learn", "communiti", "has", "shi", "away", "from", "this", "option", "with", "the", "recent", "releas", "nvidiadock", "tool", "howev", "access", "gpus", "from", "within", "docker", "breez", "and", "alreadi", "reap", "the", "benefit", "here", "indico", "this", "tutori", "walk", "through", "set", "nvidiadock", "too", "can", "deploy", "machin", "learn", "model", "with", "eas", "befor", "get", "into", "the", "detail", "howev", "let", "talk", "briefli", "about", "whi", "use", "docker", "for", "next", "data", "scienc", "project", "may", "good", "choic", "there", "certain", "learn", "curv", "for", "the", "tool", "the", "docker", "ecosystem", "but", "the", "benefit", "are", "worth", "the", "effort", "inconsist", "between", "team", "environ", "configur", "softwar", "configur", "alway", "pain", "docker", "configur", "onc", "run", "anywher", "model", "mean", "teammat", "will", "have", "worri", "less", "about", "environ", "setup", "and", "can", "focus", "more", "write", "code", "and", "build", "machin", "learn", "model", "reliabl", "deploy", "fewer", "bug", "crop", "product", "when", "can", "assur", "that", "develop", "environ", "ident", "product", "environ", "gitlik", "tool", "for", "environ", "configur", "someth", "doe", "wrong", "product", "revert", "previous", "docker", "imag", "ensur", "can", "quick", "get", "back", "function", "state", "whi", "special", "solut", "need", "for", "use", "gpus", "within", "docker", "docker", "design", "hardwar", "and", "platform", "agnost", "gpus", "are", "special", "hardwar", "that", "not", "necessarili", "avail", "everi", "host", "becaus", "this", "the", "docker", "binari", "doe", "not", "includ", "support", "out", "the", "box", "and", "requir", "fair", "amount", "configur", "get", "thing", "work", "proper", "when", "first", "start", "use", "docker", "product", "and", "need", "enabl", "access", "devic", "from", "within", "the", "contain", "had", "roll", "our", "own", "solut", "educ", "have", "understand", "the", "mechan", "which", "hardwar", "like", "gpus", "are", "expos", "oper", "system", "primarili", "the", "dev", "block", "but", "end", "with", "solut", "that", "not", "portabl", "and", "requir", "that", "the", "host", "driver", "ident", "second", "copi", "the", "driver", "instal", "within", "the", "contain", "whenev", "updat", "our", "driver", "support", "newer", "version", "had", "make", "break", "chang", "our", "docker", "imag", "order", "ensur", "driver", "match", "exact", "thank", "the", "nice", "folk", "have", "rectifi", "this", "problem", "releas", "nvidiadock", "tool", "for", "configur", "docker", "allow", "access", "from", "within", "contain", "how", "doe", "nvidiadock", "work", "nvidiadock", "take", "the", "follow", "step", "get", "work", "within", "contain", "attach", "the", "devic", "block", "contain", "docker", "volum", "devnvidianum", "devnvidiactl", "etc", "mount", "the", "devic", "driver", "host", "within", "the", "docker", "contain", "this", "mean", "that", "long", "have", "function", "driver", "host", "and", "version", "recent", "enough", "support", "driver", "instal", "within", "contain", "should", "abl", "execut", "code", "from", "run", "docker", "contain", "import", "the", "docker", "contain", "can", "also", "run", "anoth", "environ", "with", "differ", "driver", "version", "make", "easi", "build", "onc", "and", "then", "run", "anywher", "how", "instal", "nvidiadock", "use", "nvidiadock", "requir", "linux", "kernel", "num", "with", "architectur", "fermi", "num", "driver", "num", "with", "binari", "nvidiamodprob", "docker", "num", "alreadi", "meet", "these", "requir", "instal", "nvidiadock", "easi", "instal", "deb", "file", "ubuntu", "num", "bash", "instal", "nvidiadock", "and", "nvidiadockerplugin", "wget", "tmp", "nvidianvidiadockerreleasesdownloadvnumrcnumnvidiadockernumrcnumamdnumdeb", "sudo", "dpkg", "tmpnvidiadockerdeb", "tmpnvidiadockerdeb", "alreadi", "have", "work", "nvidiadock", "host", "machin", "can", "tri", "out", "nvidiadock", "immedi", "run", "the", "nvidiacuda", "docker", "imag", "provid", "test", "nvidiasmi", "nvidiadock", "run", "nvidiacuda", "nvidiasmi", "depend", "driver", "version", "may", "need", "specifi", "differ", "version", "run", "when", "test", "instal", "test", "nvidiasmi", "nvidiadock", "run", "nvidiacudanum", "nvidiasmi", "all", "well", "should", "see", "someth", "like", "nvidiadock", "run", "nvidiacudanum", "nvidiasmi", "num", "pull", "from", "nvidiacuda", "bfnumdnum", "alreadi", "exist", "numfnumenumacnumc", "alreadi", "exist", "enumbnumbnum", "alreadi", "exist", "numafnumenum", "alreadi", "exist", "enumfnumcnumenumcnum", "alreadi", "exist", "numadnumenum", "alreadi", "exist", "numdnumdbnumfdabnum", "pull", "complet", "enumenumdnumenumcd", "pull", "complet", "cnumbnumcnum", "pull", "complet", "numbnumfcdcnumd", "pull", "complet", "numenumbnumdfnumdnum", "pull", "complet", "digest", "shanum", "cnumcnumdnumcnumfnumcbfnumbfnumbnumenumbnumbnumbnumanumecnumdacdenumb", "status", "download", "newer", "imag", "for", "nvidiacudanum", "fri", "nov", "num", "num", "num", "num", "driver", "version", "num", "name", "persistencem", "busid", "dispa", "volatil", "uncorr", "fan", "temp", "perf", "pwr", "usagecap", "memoryusag", "gpuutil", "comput", "num", "geforc", "num", "off", "num", "num", "nummib", "nummib", "default", "process", "memori", "type", "process", "name", "usag", "num", "not", "support", "for", "distribut", "other", "than", "ubuntu", "instal", "nvidiadock", "from", "sourc", "check", "out", "the", "nvidiadock", "quick", "start", "guid", "and", "instal", "document", "now", "let", "use", "nvidiadock", "for", "someth", "more", "substanti", "set", "and", "run", "the", "neural", "doodl", "project", "from", "alex", "champanard", "alexjc", "the", "project", "take", "rough", "sketch", "and", "turn", "them", "into", "artist", "masterpiec", "use", "techniqu", "from", "the", "semant", "style", "transfer", "paper", "alex", "has", "alreadi", "done", "the", "hard", "work", "provid", "with", "docker", "imag", "his", "project", "and", "has", "gone", "the", "troubl", "instal", "the", "necessari", "driver", "the", "docker", "imag", "well", "normal", "need", "have", "function", "instal", "theano", "and", "the", "lasagn", "librari", "order", "run", "his", "code", "but", "sinc", "provid", "with", "docker", "imag", "should", "and", "run", "just", "few", "minut", "git", "clone", "alexjcneuraldoodlegit", "neuraldoodl", "alia", "doodl", "nvidiadock", "run", "pwd", "sampl", "ndsampl", "pwd", "frame", "ndframe", "alexjcneuraldoodl", "gpu", "paint", "photo", "coastlin", "the", "style", "monet", "doodl", "style", "samplesmonetjpg", "output", "samplescoastlinepng", "devicegpu", "iterationsnum", "this", "exampl", "take", "this", "origin", "monet", "paint", "and", "this", "sketch", "similar", "coastlin", "and", "creat", "new", "work", "art", "style", "similar", "the", "origin", "monet", "pretti", "cool", "huh", "let", "walk", "through", "the", "neuraldoodl", "dockerfil", "and", "the", "doodl", "alia", "remov", "some", "the", "magic", "behind", "what", "just", "done", "the", "dockerfil", "use", "build", "the", "alexjcneuraldoodl", "gpu", "imag", "below", "nvidiacudanumcudnnnumdevel", "instal", "depend", "aptget", "updat", "aptget", "instal", "assumey", "moduleinittool", "buildessenti", "cmake", "git", "wget", "libopenjpegnum", "libopenblasdev", "liblapackdev", "libjpegdev", "libtiffnumdev", "zlibnumgdev", "libfreetypenumdev", "liblcmsnumdev", "libwebpdev", "gfortran", "pkgconfig", "pythonnum", "pythonnumdev", "pythonnumpip", "pythonnumnumpi", "pythonnumscipi", "pythonnummatplotlib", "pythonnumsix", "pythonnumnetworkx", "pythonnumtk", "varlibaptlist", "pythonnum", "pip", "instal", "cython", "instal", "requir", "befor", "copi", "project", "file", "requirementstxt", "pythonnum", "pip", "instal", "requirementstxt", "copi", "onli", "requir", "project", "file", "doodlepi", "get", "pretrain", "neural", "network", "wget", "alexjcneuraldoodlereleasesdownloadvnumvggnumconvpklbznum", "set", "entrypoint", "the", "main", "doodlepi", "script", "pythonnum", "doodlepi", "devicegpu", "hey", "this", "bad", "the", "dockerfil", "alex", "use", "base", "off", "offici", "docker", "imag", "nvidiacudanumcudnnnumdevel", "that", "alreadi", "includ", "the", "requir", "librari", "onli", "has", "describ", "how", "instal", "few", "system", "depend", "for", "work", "with", "imag", "format", "instal", "few", "machin", "learn", "python", "packag", "with", "pip", "theano", "lasagn", "etc", "and", "download", "some", "pretrain", "model", "weight", "littl", "more", "than", "glorifi", "bash", "setup", "script", "the", "doodl", "alia", "bad", "either", "simpli", "specifi", "the", "docker", "imag", "run", "alexjcneuraldoodl", "gpu", "and", "let", "docker", "know", "that", "the", "sampl", "and", "frame", "directori", "should", "access", "from", "the", "docker", "contain", "ndsampl", "and", "ndframe", "this", "done", "use", "docker", "volum", "featur", "which", "the", "curious", "can", "read", "more", "about", "the", "offici", "docker", "site", "indico", "now", "use", "setup", "the", "neuraldoodl", "configur", "host", "the", "indico", "amazon", "gpus", "instead", "use", "our", "own", "bash", "script", "allow", "the", "nvidiadock", "tool", "handl", "the", "process", "ensur", "devic", "driver", "within", "the", "docker", "contain", "match", "devic", "driver", "the", "host", "this", "mean", "when", "our", "custom", "wish", "run", "our", "api", "their", "local", "machin", "deploy", "easi", "provid", "them", "with", "access", "our", "product", "docker", "imag", "and", "let", "the", "nvidiadock", "tool", "handl", "the", "rest", "oper", "system", "support", "the", "moment", "nvidiadock", "onli", "portabl", "the", "sens", "that", "not", "reliant", "particular", "model", "driver", "version", "linux", "distribut", "run", "nvidiadock", "window", "will", "like", "not", "support", "anytim", "soon", "where", "can", "find", "more", "inform", "nvidiadock", "has", "done", "excel", "job", "keep", "the", "wiki", "their", "github", "page", "uptod", "chanc", "are", "have", "question", "that", "aren", "answer", "this", "blog", "post", "can", "probabl", "find", "answer", "the", "nvidiadock", "github", "wiki", "use", "version", "other", "than", "the", "one", "use", "this", "demo", "num", "might", "also", "want", "take", "peek", "the", "full", "list", "base", "imag", "that", "provid", "for", "work", "with", "hope", "enjoy", "this", "whirlwind", "tour", "use", "nvidiadock", "build", "and", "run", "machin", "learn", "project", "and", "perhap", "creat", "bit", "origin", "algorithm", "art", "while", "run", "into", "troubl", "tri", "out", "this", "tutori", "want", "learn", "more", "about", "how", "use", "docker", "product", "indico", "feel", "free", "reach", "out", "over", "our", "site", "chat", "and", "say", "hello", "happi", "hack", "bio", "madison", "may", "develop", "design", "and", "engin", "and", "the", "indico", "data", "solut", "origin", "repost", "with", "permiss", "relat", "jupytersparkmeso", "opinion", "docker", "imag", "semisupervis", "featur", "transfer", "the", "practic", "benefit", "deep", "learn", "today", "text", "mine", "and", "elect", "analyt", "massachusett"], "timestamp_scraper": 1556479913.327366, "title": "Data Science Deployments With Docker", "read_time": 500.7, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By Madison May, <a href=\"https://indico.io/\" target=\"_blank\">indico</a></b>.</p>\n<p><img alt=\"Docker\" src=\"/wp-content/uploads/docker-logo.jpg\" width=\"99%\"/></p>\n<p>Deploying machine learning models has always been a struggle. Most of the software industry has adopted the use of container engines like Docker for deploying code to production, but since accessing hardware resources like GPUs from Docker was difficult and required hacky, driver specific workarounds, the machine learning community has shied away from this option. With the recent release of NVIDIA\u2019s\u00a0<code>nvidia-docker</code>\u00a0tool, however, accessing GPUs from within Docker is a breeze, and we\u2019re already reaping the benefits here at indico. In this tutorial we\u2019ll walk you through setting up\u00a0<code>nvidia-docker</code>\u00a0so you too can deploy machine learning models with ease.</p>\n<p>Before we get into the details however, let\u2019s talk briefly about why using Docker for your next data science project may be a good choice. There is certainly a learning curve for the tools in the Docker ecosystem, but the benefits are worth the effort.</p>\n<ol>\n<li>No inconsistencies between team environment configurations:Software configuration is always a pain. Docker\u2019s configure once, run anywhere model means your teammates will have to worry less about environment setup and can focus more on writing code and building machine learning models.\n<li>Reliable deployments:Fewer bugs crop up in production when you can be assured that your development environment is identical to your production environment.\n<li>Git-like tool for environment configuration:If something does go wrong in production, reverting to a previous Docker image ensures you can quickly get back to a functional state.\n</li></li></li></ol>\n<h3>Why is a special solution needed for using GPUs within Docker?</h3>\n<p>\u00a0<br>\nDocker is designed to be hardware and platform agnostic. GPUs are specialized hardware that is not necessarily available on every host. Because of this, the Docker binary does not include GPU support out of the box, and requires a fair amount of configuration to get things working properly. When we first started using Docker in production and needed to enable access to GPU devices from within the container, we had to roll our own solution. It was educational to have to understand the mechanisms by which hardware like GPUs are exposed to an operating system (primarily the\u00a0<code>/dev</code>\u00a0block), but we ended up with a solution that was not portable and required that the host\u2019s NVIDIA driver was identical to a second copy of the driver installed within the container. Whenever we updated our NVIDIA drivers to support newer CUDA versions, we had to make a breaking change to our Docker image in order to ensure drivers matched exactly.</br></p>\n<p>Thankfully, the nice folks at NVIDIA have rectified this problem by releasing\u00a0<code>nvidia-docker</code>, a tool for configuring docker to allow GPU access from within containers.</p>\n<h3>How does\u00a0<code>nvidia-docker</code>\u00a0work?</h3>\n<p>\u00a0<br>\n<code>nvidia-docker</code>\u00a0takes the following steps to get CUDA working within your container:</br></p>\n<ul>\n<li>It attaches the GPU device blocks to your container as Docker volumes (/dev/nvidia0, /dev/nvidiactl, etc.)\n<li>It mounts the device drivers on your host within the Docker container\n</li></li></ul>\n<p>This means that as long as you have a functional NVIDIA driver on your host and a CUDA version recent enough to support your driver is installed within your container, you should be able to execute CUDA code from your running Docker container. Importantly, the Docker container can also be run in another environment with different driver versions, making it easy to build once and then run anywhere.</p>\n<h3>How do I install\u00a0<code>nvidia-docker</code>?</h3>\n<p>\u00a0<br>\nUse of\u00a0<code>nvidia-docker</code>\u00a0requires:</br></p>\n<ul>\n<li>Linux kernel &gt; 3.10\n<li>NVIDIA GPU with Architecture &gt; Fermi (2.1)\n<li>NVIDIA drivers &gt;= 340.29 with binary nvidia-modprobe\n<li><a href=\"https://docs.docker.com/engine/installation/linux/ubuntulinux/\" target=\"_blank\">Docker &gt;= 1.9</a>\n</li></li></li></li></ul>\n<p>If you already meet these requirements, installation of\u00a0<code>nvidia-docker</code>\u00a0is as easy as installing a\u00a0<code>.deb file</code>\u00a0(on Ubuntu 14.04):</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>bash\r\n# Install nvidia-docker and nvidia-docker-plugin\r\nwget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.0-rc.3/nvidia-docker_1.0.0.rc.3-1_amd64.deb\r\nsudo dpkg -i /tmp/nvidia-docker*.deb &amp;&amp; rm /tmp/nvidia-docker*.deb</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>If you already have a working\u00a0<code>nvidia-docker</code>\u00a0on your host machine, you can try out\u00a0<code>nvidia-docker</code>\u00a0immediately by running the\u00a0<code>nvidia/cuda</code>\u00a0Docker image provided by NVIDIA:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># Test nvidia-smi\r\nnvidia-docker run --rm nvidia/cuda nvidia-smi</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Depending on your driver version, you may need to specify a different version of CUDA to run when testing your installation:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># Test nvidia-smi\r\nnvidia-docker run --rm nvidia/cuda:7.5 nvidia-smi</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>If all is well, you should see something like:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>$ nvidia-docker run --rm nvidia/cuda:7.5 nvidia-smi\r\n7.5: Pulling from nvidia/cuda\r\nbf5d46315322: Already exists\r\n9f13e0ac480c: Already exists\r\ne8988b5b3097: Already exists\r\n40af181810e7: Already exists\r\ne6f7c7e5c03e: Already exists\r\n261ad237e477: Already exists\r\n83d2db6fdab9: Pull complete\r\ne8e8d0e851cd: Pull complete\r\nc0000b849c19: Pull complete\r\n180b04fcdc2d: Pull complete\r\n1e5b85df3d02: Pull complete\r\nDigest: sha256:c601c6902928d62c79f2cbf90bf07477b666e28b51b094b3a10924ec7dacde8b\r\nStatus: Downloaded newer image for nvidia/cuda:7.5\r\nFri Nov  4 16:34:00 2016       \r\n+------------------------------------------------------+                       \r\n| NVIDIA-SMI 352.93     Driver Version: 352.93         |                       \r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 760     Off  | 0000:01:00.0     N/A |                  N/A |\r\n| 17%   31C    P8    N/A /  N/A |    172MiB /  4095MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0                  Not Supported                                         |\r\n+-----------------------------------------------------------------------------+</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>For distributions other than Ubuntu or to install\u00a0<code>nvidia-docker</code>\u00a0from source, check out the\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/wiki#quick-start\" target=\"_blank\"><code>nvidia-docker</code>\u00a0quick start guide</a>\u00a0and\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/wiki/Installation\" target=\"_blank\">installation documentation</a>.</p>\n<p>Now let\u2019s use\u00a0<code>nvidia-docker</code>\u00a0for something more substantial. We\u2019ll be setting up and running the\u00a0<a href=\"https://github.com/alexjc/neural-doodle\" target=\"_blank\">\u201cneural doodle\u201d project</a>\u00a0from Alex Champanard (<a href=\"https://twitter.com/alexjc\" target=\"_blank\">@alexjc</a>). The project takes rough sketches and turns them into artistic masterpieces using techniques from the\u00a0<a href=\"https://arxiv.org/abs/1603.01768\" target=\"_blank\">Semantic Style Transfer paper</a>.</p>\n<p>Alex has already done the hard work of providing us with a Docker image of his project, and has gone to the trouble of installing the necessary CUDA drivers in the Docker image as well. Normally we\u2019d need to have a functioning installation of CUDA, Theano, and the lasagne library in order to run his code, but since he\u2019s provided us with a Docker image we should be up and running in just a few minutes.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>git clone https://github.com/alexjc/neural-doodle.git &amp;&amp; cd neural-doodle\r\nalias doodle=\"nvidia-docker run -v ($pwd)/samples:/nd/samples -v ($pwd)/frames:/nd/frames -it alexjc/neural-doodle:gpu\"\r\n\r\n# paint a photo of a coastline in the style of Monet\r\ndoodle --style samples/Monet.jpg --output samples/Coastline.png --device=gpu --iterations=40</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>This example takes this original Monet painting:</p>\n<p><img alt=\"original Monet painting\" src=\"https://indico.io/blog/wp-content/uploads/2016/11/Monet.jpg\" width=\"99%\"/></p>\n<p>and this sketch of a similar coastline:</p>\n<p><img alt=\"coastline sketch\" src=\"https://indico.io/blog/wp-content/uploads/2016/11/Coastline_sem.png\" width=\"99%\"/></p>\n<p>and creates a new work of art in style similar to the original Monet:</p>\n<p><img alt=\"new art, Monet style\" src=\"https://indico.io/blog/wp-content/uploads/2016/11/new_work_of_art.png\" width=\"99%\"/></p>\n<p>Pretty cool, huh?</p>\n<p>Let\u2019s walk through the\u00a0<code>neural-doodle</code>\u00a0dockerfile and the\u00a0<code>doodle</code>\u00a0alias to remove some of the magic behind what we\u2019ve just done.</p>\n<p>The dockerfile used to build the\u00a0<code>alexjc/neural-doodle:gpu</code>\u00a0image is below:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>FROM nvidia/cuda:7.5-cudnn4-devel\r\n\r\n# Install dependencies\r\nRUN apt-get -qq update            &amp;&amp; \\\r\n    apt-get -qq install --assume-yes \\\r\n        \"module-init-tools\"         \\\r\n        \"build-essential\"           \\\r\n        \"cmake\"                     \\\r\n        \"git\"                       \\\r\n        \"wget\"                      \\\r\n        \"libopenjpeg2\"              \\\r\n        \"libopenblas-dev\"           \\\r\n        \"liblapack-dev\"             \\\r\n        \"libjpeg-dev\"               \\\r\n        \"libtiff5-dev\"              \\\r\n        \"zlib1g-dev\"                \\\r\n        \"libfreetype6-dev\"          \\\r\n        \"liblcms2-dev\"              \\\r\n        \"libwebp-dev\"               \\\r\n        \"gfortran\"                  \\\r\n        \"pkg-config\"                \\\r\n        \"python3\"                   \\\r\n        \"python3-dev\"               \\\r\n        \"python3-pip\"               \\\r\n        \"python3-numpy\"             \\\r\n        \"python3-scipy\"             \\\r\n        \"python3-matplotlib\"        \\\r\n        \"python3-six\"               \\\r\n        \"python3-networkx\"          \\\r\n        \"python3-tk\"             &amp;&amp;  \\\r\n    rm -rf /var/lib/apt/lists/*  &amp;&amp;  \\\r\n    python3 -m pip -q install \"cython\"\r\n\r\n# Install requirements before copying project files\r\nWORKDIR /nd\r\nCOPY requirements.txt .\r\nRUN python3 -m pip -q install -r \"requirements.txt\"\r\n\r\n# Copy only required project files\r\nCOPY doodle.py .\r\n\r\n# Get a pre-trained neural network (VGG19)\r\nRUN wget -q \"https://github.com/alexjc/neural-doodle/releases/download/v0.0/vgg19_conv.pkl.bz2\"\r\n\r\n# Set an entrypoint to the main doodle.py script\r\nENTRYPOINT [\"python3\", \"doodle.py\", \"--device=gpu\"]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Hey, this isn\u2019t so bad. The dockerfile Alex used is based off of an official NVIDIA Docker image (<code>nvidia/cuda:7.5-cudnn4-devel</code>) that already includes the required CUDA libraries, so it only has to describe how to install a few system dependencies for working with image formats, install a few machine learning Python packages with\u00a0<code>pip</code>\u00a0(Theano, lasagne, etc.), and download some pre-trained model weights. It\u2019s little more than a glorified bash setup script.</p>\n<p>The\u00a0<code>doodle</code>\u00a0alias isn\u2019t bad either. It simply specifies the Docker image we\u2019ll be running (<code>alexjc/neural-doodle:gpu</code>) and lets Docker know that the\u00a0<code>./samples</code>\u00a0and\u00a0<code>./frames</code>\u00a0directories should be accessible from the Docker container at\u00a0<code>/nd/samples/</code>\u00a0and\u00a0<code>/nd/frames</code>. This is done using Docker\u2019s \u201cvolumes\u201d feature, which the curious can read more about on the\u00a0<a href=\"https://docs.docker.com/engine/tutorials/dockervolumes/\" target=\"_blank\">official Docker site</a>.</p>\n<p>At indico, we now use a setup to the\u00a0<code>neural-doodle</code>\u00a0configuration to host the indico API on Amazon GPUs. Instead of using our own bash scripts, we allow the\u00a0<code>nvidia-docker</code>\u00a0tool to handle the process of ensuring device drivers within the Docker container match device drivers on the host. This means when our customers wish to run our APIs on their local machines, deployment is as easy as providing them with access to our production Docker image and letting the\u00a0<code>nvidia-docker</code>\u00a0tool handle the rest.</p>\n<h3>Operating System Support</h3>\n<p>\u00a0<br/>\nAt the moment,\u00a0<code>nvidia-docker</code>\u00a0is only portable in the sense that it\u2019s not reliant on a particular GPU model, NVIDIA driver version, or linux distribution. Running\u00a0<code>nvidia-docker</code>\u00a0on\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/issues/101\" target=\"_blank\">OSX</a>\u00a0or\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/issues/197\" target=\"_blank\">Windows</a>\u00a0will likely not be supported anytime soon.</p>\n<h3>Where can I find more information on\u00a0<code>nvidia-docker</code>?</h3>\n<p>\u00a0<br/>\nNVIDIA has done an excellent job of keeping the wiki of their Github page up-to-date. Chances are if you have questions that aren\u2019t answered in this blog post, you can probably find answers in the\u00a0<code>nvidia-docker</code>\u00a0<a href=\"https://github.com/NVIDIA/nvidia-docker/wiki\" target=\"_blank\">Github wiki</a>.</p>\n<p>If you\u2019re using a version of CUDA other than the one used in this demo (CUDA 7.5), you might also want to take a peek at the\u00a0<a href=\"https://hub.docker.com/r/nvidia/cuda/\" target=\"_blank\">full list of base images</a>\u00a0that NVIDIA provides for you to work with.</p>\n<p>I hope you\u2019ve enjoyed this whirlwind tour on using\u00a0<code>nvidia-docker</code>\u00a0to build and run machine learning projects, and perhaps created a bit of original algorithmic art while you\u2019re at it. If you run into trouble trying out this tutorial, or want to learn more about how we\u2019re using Docker in production at indico, feel free to reach out over our site chat and say hello. Happy hacking!</p>\n<p><b>Bio: <a href=\"https://www.linkedin.com/in/madison-may-49a1924a\" target=\"_blank\">Madison May</a></b> is a developer, designer, and engineer, and is the CTO of <a href=\"https://indico.io/\" target=\"_blank\">indico Data Solutions</a>.</p>\n<p><a href=\"https://indico.io/blog/data-science-deployments-docker/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2016/05/ibm-jupyter-spark-mesos-docker.html\">Jupyter+Spark+Mesos: An \u201cOpinionated\u201d Docker Image</a>\n<li><a href=\"/2016/07/semi-supervised-feature-transfer-deep-learning.html\">Semi-supervised Feature Transfer: The Practical Benefit of Deep Learning Today?</a>\n<li><a href=\"/2014/10/text-mining-election-analytics-massachusetts.html\">Text Mining and Election Analytics in Massachusetts</a>\n</li></li></li></ul>\n</div> ", "website": "kdnuggets"}