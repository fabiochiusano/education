{"content": "By Yogesh H. Kulkarni Summary This article demonstrates a framework for mining relevant entities from a text resume. It shows how separation of parsing logic from entity specification can be achieved. Although only one resume sample is considered here, the framework can be enhanced further to be used not only for different resume formats, but also for documents such as judgments, contracts, patents, medical papers, etc. Introduction Majority of world\u2019s unstructured data is in the textual form. To make sense of it, one must, either go through it painstakingly or employ certain automated techniques to extract relevant information. Looking at the volume, variety and velocity of such textual data, it is imperative to employ Text Mining techniques to extract the relevant information, transforming unstructured data into structured form, so that further insights, processing, analysis, visualizations are possible. This article deals with a specific domain, of applicant profiles or resumes. They, as we know, come not only in different file formats (txt, doc, pdf, etc.) but also with different contents and layouts. Such heterogeneity makes extraction of relevant information, a challenging task. Even though it may not be possible to fully extract all the relevant information from all the types of formats, one can get started with simple steps and at least extract whatever is possible from some of the known formats. Broadly there are two approaches: linguistics based and Machine Learning based. In \u201clinguistic\u201d based approaches pattern searches are made to find key information, whereas in \u201cmachine learning\u201d approaches supervised-unsupervised methods are used to extract the information. \u201cRegular expression\u201d (RegEx), used here, is one of the \u201clinguistic\u201d based pattern-matching method. Framework A primitive way of implementing entity extraction in a resume could be to write the pattern-matching logic for each entity, in a code-program, monolithically. In case of any change in the patterns, or if there is an introduction of new entities/patterns, one needs to change the code-program. This makes maintenance cumbersome as the complexity increases. To alleviate this problem, separation of parsing-logic and specification of entities is proposed in a framework, which is demonstrated below. Entities and their RegEx patterns are specified in a configuration file. The file also specifies type of extraction method to be used for each type of the entity. Parser uses these patterns to extract entities by the specified method. Advantages of such separation is not just maintainability but also its potential use in other domains such as legal/contracts, medical, etc. Entities Specification The configuration file specifies entities to be extracted along with their patterns and extraction-method. It also specifies the section within which the given entities are to be looked for. Specification shown in the textbox below, describes meta data entities like Name, Phone, Email, etc. Method used to extract them is \u201cunivalue_extractor\u201d. Section within which these entities are to be searched is named \u201c\u201d, it\u2019s a non-labelled section, like the initial few lines of the resume. Entities like Email or Phone can have multiple regular-expressions patterns. If first fails then the second one is tried and so on. Here is a brief description of the patterns used: Name: Resume\u2019s first line is assumed to have the Name, with an optional \u201cName:\u201d prefix. Email: Is a word (with optional dot in the middle) then \u201c@\u201d, then a word, dot and then a word. Phone: Optional International code in bracket, then digit pattern of 3-3-4, with optional bracket to the first 3 digits. For India number, it can be hard coded to \u201c+91\u201d as shown in the next entry. Python\u2019s \u2018etree\u2019 ElementTree library is used to parse the config xml into internal dictionary. Parser reads this specifications\u2019 dictionary and uses it to find entities from the text resume. Once an entity is matched it is stored as the node-tag, like Email, Phone, etc. Like Metadata described above, Educational qualifications can be searched with a config below: Method \u201csection_value_extractor\u201d of the parser is to be used and within section \u201cEducationSection\u201d. It finds value within a section just by matching given words. If parser finds any of the words, say \u201c10 th \u201c or \u201cX\u201d or \u201cSSC\u201d, then those are the values extracted for the entity \u201cSecondary\u201d, describing Secondary School level education. If parser finds any of the words, say \u201c12 th \u201d or \u201cXII\u201d or \u201cHSC\u201d, then those are the values extracted for the entity \u201cHigherSecondary\u201d, describing Higher Secondary School level education. Segmentation The sections mentioned in the above code snippets are blocks of text, labelled such as SummarySection, EducationSection, etc. These are specified at the top of the config file. Method \u201csection_extractor\u201d parses the document line-wise and looks for section headings. Sections are recognised by keywords used for its headings. Say, for SummarySection, keywords are \u201cSummary\u201d, \u201cAim\u201d, \u201cObjective\u201d, etc. Once the match is found, state of \u201cSummarySection\u201d is set and further lines are clubbed under it, till the next section is found. Once the new heading matches, the new state of the next section starts, so on. Results A sample resume is shown below: Entities extracted are shown below: Implementation of the parser, along its config file and sample resume can be found at github . End note This article demonstrates unearthing of structured information from unstructured data such as a resume. As the implementation is shown only for one sample, it may not work for other formats. One would need to enhance, customize it to cater to the other resume types. Apart from resumes, the parsing-specifications separation framework can be leveraged for the other types of documents from different domains as well, by specifying domain specific configuration files. Bio: \u00a0 Yogesh H. Kulkarni , after working in the field of Geometric Modelling for more than 16 years, has recently finished a PhD in it. He got into Data Sciences while doing the doctoral research and wishes to pursue further career in it now. He is keenly interested in Text Mining, Machine/Deep Learning and primarily uses Python stack for implementations. He would love to hear from you about this article as well as on any such topics, projects, assignments, opportunities, etc. Related: Using Deep Learning To Extract Knowledge From Job Descriptions Making sense of text analytics Text Mining Amazon Mobile Phone Reviews: Interesting Insights", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"Silver Blog, May 2017\" src=\"/images/top-kdnuggets-blog-2017-may-silver.png\" width=\"80\"/>Text Mining 101: Mining Information From A Resume</h1> ", "url": "https://www.kdnuggets.com/2017/05/text-mining-information-resume.html", "tfidf": {"tfidf": {"after": 1.02070207021, "base": 4.5851263538, "relat": 1.23750876919, "deal": 2.18346857379, "mainten": 7.16749435666, "bracket": 64.93251533739999, "onc": 4.492359932099999, "email": 133.9746835444, "here": 7.26923076924, "txt": 1443.27272727, "label": 4.47715736041, "sectionextractor": 1587.6, "patternmatch": 3175.2, "express": 1.9120799710900003, "assign": 3.83663605607, "parsingspecif": 1587.6, "through": 1.07074930869, "describ": 5.88108909056, "apart": 3.1032056294, "config": 6350.4, "resum": 83.1539081386, "etc": 33.653418124, "specif": 13.103643438269998, "about": 1.06486015159, "problem": 1.76674827509, "educationsect": 3175.2, "say": 5.2633440159, "shown": 13.846153846149999, "python": 112.5957446808, "just": 2.67160286074, "hear": 4.17899447223, "well": 2.1311497416, "nodetag": 1587.6, "tri": 1.8544562551099997, "imper": 32.9377593361, "approach": 6.2266963001699995, "type": 10.140521205950002, "higher": 2.1218925421, "would": 2.1657458563599996, "know": 2.59327017315, "codeprogram": 3175.2, "their": 2.0309581681, "but": 3.04897253697, "supervisedunsupervis": 1587.6, "start": 2.53347163488, "cumbersom": 79.38, "profil": 4.8314059647, "complex": 2.34021226415, "least": 1.6165359943000002, "model": 2.0905978404, "multipl": 2.74813917258, "articl": 8.07220033048, "how": 1.60250328051, "love": 2.97303370787, "segment": 7.55640171347, "phone": 45.59448592765, "insight": 23.6074349442, "volum": 2.40545454545, "word": 10.779223718459999, "dictionari": 10.458498023719999, "maintain": 1.77306231852, "increas": 1.32024948025, "initi": 1.35, "can": 9.41009113136, "end": 1.10680423871, "found": 3.34161229215, "given": 2.70852170946, "autom": 19.8202247191, "form": 2.25511363636, "interest": 3.20662492426, "now": 1.160780873, "deep": 3.6279707495399998, "unstructur": 643.621621623, "the": 55.0, "consid": 1.2397313759200002, "analysi": 3.47852760736, "snippet": 135.692307692, "second": 1.1130898128, "number": 1.10142916609, "broad": 4.27693965517, "new": 3.0536641662, "below": 11.28037515985, "under": 1.0781663837, "along": 2.5947536160799998, "demonstr": 7.94992488732, "certain": 1.8077886586200003, "need": 2.8745247148199997, "school": 3.28016528926, "there": 2.08182533438, "metadata": 211.68, "object": 2.3488681757700003, "inform": 11.02718793414, "top": 1.8387769284200002, "num": 6.00189024006, "applic": 3.42672134686, "linguist": 28.935601458090005, "review": 2.2099109131400003, "level": 3.3088786994599997, "has": 1.0436497502, "have": 2.0297896822799997, "either": 1.5830092731099998, "knowledg": 3.3981164383599998, "secondari": 13.10621904237, "advantag": 3.32412060302, "painstak": 131.20661157, "data": 20.25861335604, "opportun": 3.0119521912400002, "further": 5.447246526, "configur": 34.51304347829999, "name": 5.510586601850001, "code": 11.64214128576, "hard": 2.73253012048, "heterogen": 52.0524590164, "format": 12.65625, "than": 1.03278688525, "specifi": 48.444638186560006, "possibl": 4.2521203464, "line": 4.254779346089999, "leverag": 35.7567567568, "also": 5.07382550335, "field": 1.7790228597, "such": 8.49211018992, "textual": 82.9033942558, "not": 5.07836990595, "task": 3.88641370869, "major": 1.14852058164, "them": 1.09876115994, "research": 1.9420183486200002, "sectionvalueextractor": 1587.6, "nonlabel": 1587.6, "may": 2.10403551786, "doc": 34.8157894737, "extractionmethod": 1587.6, "aim": 2.8960233491400005, "techniqu": 7.458773784360001, "till": 11.563000728299999, "wherea": 4.13868613139, "challeng": 2.55816951337, "primarili": 2.43459592087, "recognis": 5.93939393939, "whatev": 7.6473988439300005, "enhanc": 10.31914202144, "though": 1.36076112111, "then": 7.60605023612, "sens": 5.673039128099999, "they": 1.03017325287, "parser": 3072.7741935480003, "primit": 13.7573656846, "descript": 8.01009081736, "machinedeep": 1587.6, "although": 1.14968498805, "scienc": 2.31969608416, "paper": 2.6628648104700003, "employ": 4.33060556464, "work": 2.23040179826, "job": 3.2539454806299997, "github": 1587.6, "section": 21.2843544711, "entiti": 130.97872340432, "which": 3.015575535, "relev": 34.69405594405001, "xml": 191.277108434, "simpl": 3.3981164383599998, "other": 4.03969465648, "introduct": 5.561744613759999, "implement": 14.30592475784, "mine": 19.503685503679996, "career": 2.98757997742, "show": 1.26703910615, "valu": 6.833285509320001, "known": 1.0859097127200001, "univalueextractor": 1587.6, "custom": 3.6346153846199996, "got": 3.61969904241, "entri": 3.9909502262400003, "cater": 17.6989966555, "pattern": 30.33389061384, "those": 2.39096385542, "stack": 19.6485148515, "get": 1.78562591385, "write": 2.0575427682700003, "like": 5.745928338750001, "meta": 151.2, "text": 21.89793103449, "some": 1.04036697248, "phd": 22.3605633803, "dot": 37.7550535078, "file": 26.397149643689996, "process": 1.69524826482, "entitiespattern": 1587.6, "qualif": 17.2004333694, "analyt": 17.256521739100002, "club": 2.92375690608, "varieti": 2.2972073506, "judgment": 10.911340206199998, "content": 3.5421686747, "recent": 1.54405757635, "india": 3.92387543253, "next": 4.485168094920001, "set": 1.18707940781, "ani": 4.53535209256, "two": 1.01379310345, "sampl": 28.93120728928, "from": 10.0056721497, "even": 1.16461267606, "chang": 2.3617970842, "document": 7.622919334200001, "project": 1.7534791252500002, "differ": 4.946179609, "monolith": 66.9873417722, "transform": 3.42007755278, "kulkarni": 1984.5, "prefix": 25.8146341463, "unearth": 42.449197861, "domain": 37.57633136096, "for": 17.005355680170002, "brief": 3.39013452915, "fail": 1.9281029876099998, "geometr": 24.4622496148, "all": 2.02293577982, "match": 14.270561797760001, "fulli": 2.79015817223, "with": 8.009585671919998, "store": 3.44680851064, "assum": 2.9575260804799997, "keen": 13.6509028375, "are": 15.4485890367, "layout": 15.034090909100001, "case": 1.48498737256, "middl": 2.04245465071, "structur": 4.1161524500999995, "result": 1.14611608432, "parsinglog": 1587.6, "look": 5.725895647979999, "veloc": 23.873684210500002, "option": 16.19586840092, "patent": 10.5558510638, "summari": 15.60294840294, "regular": 2.09418282548, "more": 1.0171706817, "and": 16.00100787408, "linewis": 1587.6, "while": 1.0441988950299999, "extract": 115.54585152840001, "intern": 2.60711060022, "finish": 3.22879804759, "achiev": 1.87216981132, "these": 3.22246278756, "separ": 6.404841149759999, "pars": 436.954128441, "etre": 1587.6, "keyword": 278.52631579, "made": 1.07038834951, "could": 1.2043695949, "visual": 5.22752716497, "educ": 6.02200025289, "librari": 2.68266306185, "state": 2.0954266481799997, "elementtre": 1587.6, "year": 1.0485436893200002, "yogesh": 3175.2, "mobil": 4.89697717458, "one": 8.05019965776, "topic": 5.457545548300001, "allevi": 22.6153846154, "make": 4.305064063440001, "way": 1.2190739461, "search": 9.761836441889999, "onli": 4.102590606640001, "each": 2.37949640288, "highersecondari": 1587.6, "few": 1.31729173581, "amazon": 33.1440501044, "this": 7.02655538697, "step": 2.8279301745599996, "read": 2.3149606299200003, "framework": 41.00206611569999, "pursu": 4.15384615385, "contract": 3.0165304959099997, "regex": 3175.2, "block": 3.20274359492, "summarysect": 4762.799999999999, "note": 1.42449528937, "key": 2.28005170185, "method": 18.00000000001, "machin": 8.04866920152, "into": 3.04507384437, "bio": 42.336000000000006, "medic": 6.55085619972, "come": 1.32831325301, "must": 1.9220338983099996, "digit": 8.832267037560001, "that": 1.00398406375, "abov": 3.80765079746, "wish": 3.67755385685, "potenti": 2.52080025405, "doctor": 3.9394540942900003, "first": 3.0228484386899996, "regularexpress": 1587.6, "use": 14.414942603319998, "head": 4.73345259393, "textbox": 1587.6, "world": 1.11340206186, "logic": 17.858267716540002, "legalcontract": 1587.6, "find": 8.64705882355, "within": 4.9477210752, "learn": 9.2910021946, "propos": 1.9902218879299998, "mention": 2.53894130817, "pdf": 10.8665297741}, "logtfidf": {"after": 0.020490694648099998, "base": 0.5460932091480001, "relat": 0.21310030165399999, "deal": 0.780914701253, "mainten": 1.9695561314200003, "bracket": 6.960402648860001, "onc": 1.211297617065, "email": 14.045425968839998, "here": 2.6551145651100003, "txt": 7.2746685411000005, "label": 1.49898832727, "sectionextractor": 7.369978720910001, "patternmatch": 14.739957441820001, "express": 0.648191639641, "assign": 1.3445959556, "parsingspecif": 7.369978720910001, "through": 0.0683586918849, "describ": 1.5417904125, "apart": 1.1324356512, "config": 29.479914883640003, "resum": 24.124670025820002, "etc": 11.493384703760002, "specif": 4.388861172787, "about": 0.0628434774746, "problem": 0.569140724273, "educationsect": 14.739957441820001, "say": 1.6864628416560001, "shown": 5.09284790495, "python": 8.06131348592, "just": 0.579062868218, "hear": 1.43007066072, "well": 0.1270288766312, "nodetag": 7.369978720910001, "tri": 0.61759152916, "imper": 3.4946196998500003, "approach": 2.1907008437430004, "type": 3.535507426935, "higher": 0.752308398995, "would": 0.1592352559294, "know": 0.952919694398, "codeprogram": 14.739957441820001, "their": 0.030721010245400002, "but": 0.0485771162157, "supervisedunsupervis": 7.369978720910001, "start": 0.472886738582, "cumbersom": 4.37424644735, "profil": 1.5751375153100002, "complex": 0.8502416364309999, "least": 0.480285584745, "model": 0.7374500731110001, "multipl": 1.01092401812, "articl": 2.808526958296, "how": 0.47156695693000006, "love": 1.08958288195, "segment": 2.02239511306, "phone": 11.051744370649999, "insight": 4.93682904374, "volum": 0.877738885888, "word": 3.51516649431, "dictionari": 3.30853535078, "maintain": 0.572708175102, "increas": 0.277820718929, "initi": 0.30010459245, "can": 1.298728771152, "end": 0.101476798618, "found": 0.323523372144, "given": 0.606511621662, "autom": 2.9867028668299995, "form": 0.240106368382, "interest": 0.9441435559639999, "now": 0.149092945021, "deep": 1.2886734698, "unstructur": 16.1054961621, "the": 0.0, "consid": 0.214894723824, "analysi": 1.2466091029200002, "snippet": 4.91038987911, "second": 0.10713976337999999, "number": 0.0966085784186, "broad": 1.45323772, "new": 0.0531898405533, "below": 4.06813295968, "under": 0.07526180538319999, "along": 0.520688771834, "demonstr": 2.9236505754569997, "certain": 0.592104362781, "need": 0.725480326884, "school": 0.989493267264, "there": 0.080195785851, "metadata": 5.35507570037, "object": 0.853933584803, "inform": 3.1811759326340003, "top": 0.609100637788, "num": 0.0018899423723820002, "applic": 1.23160392849, "linguist": 6.799381298010001, "review": 0.7929522039210001, "level": 1.006924379886, "has": 0.0427239448548, "have": 0.0295700046824, "either": 0.459327638815, "knowledg": 1.2232212893899999, "secondari": 4.423423694849999, "advantag": 1.20120515883, "painstak": 4.87677326831, "data": 7.3009235088, "opportun": 1.10258843705, "further": 1.235263581188, "configur": 7.328175107249999, "name": 0.4861658319215001, "code": 4.06805728791, "hard": 1.00522796406, "heterogen": 3.9522520373, "format": 4.643566259365, "than": 0.0322608622182, "specifi": 13.54158061347, "possibl": 1.0464164246730001, "line": 1.048291843356, "leverag": 3.5767392514699994, "also": 0.073285789, "field": 0.5760642583510001, "such": 0.477567822448, "textual": 7.4490576494399985, "not": 0.0777620650375, "task": 1.35748680661, "major": 0.138474663439, "them": 0.0941833269093, "research": 0.663727818138, "sectionvalueextractor": 7.369978720910001, "nonlabel": 7.369978720910001, "may": 0.10141999056880001, "doc": 3.55007100439, "extractionmethod": 7.369978720910001, "aim": 1.06333853704, "techniqu": 2.63248769614, "till": 2.44781040813, "wherea": 1.4203783778999999, "challeng": 0.9392919688950001, "primarili": 0.8897807965100001, "recognis": 1.78160709776, "whatev": 2.0343655696200003, "enhanc": 3.2817068771599995, "though": 0.308044191079, "then": 0.5812370566163, "sens": 2.08515559002, "they": 0.0297269947676, "parser": 37.43145965651999, "primit": 2.62157436683, "descript": 2.7751098369, "machinedeep": 7.369978720910001, "although": 0.139487981418, "scienc": 0.841436178891, "paper": 0.979402539665, "employ": 1.5451204098859999, "work": 0.218069134546, "job": 1.1798682540899998, "github": 7.369978720910001, "section": 7.5538717794800005, "entiti": 36.681322367519996, "which": 0.01553524153629, "relev": 9.685652306999998, "xml": 5.25372320611, "simpl": 1.2232212893899999, "other": 0.03949899167904, "introduct": 2.04552931588, "implement": 5.09751763628, "mine": 6.33723634712, "career": 1.0944636875799998, "show": 0.236682766013, "valu": 2.469579930444, "known": 0.0824180805992, "univalueextractor": 7.369978720910001, "custom": 1.2905032964799998, "got": 1.2863908849299999, "entri": 1.38402935449, "cater": 2.87350795184, "pattern": 10.66259238304, "those": 0.35709878174599996, "stack": 2.97800175538, "get": 0.579769005782, "write": 0.721512439877, "like": 0.6952678827250001, "meta": 5.01860346375, "text": 7.983374069929999, "some": 0.0395735090645, "phd": 3.10729884387, "dot": 5.87594430786, "file": 9.29142121061, "process": 0.527829199025, "entitiespattern": 7.369978720910001, "qualif": 2.8449345794, "analyt": 2.8481901438599997, "club": 1.07286940097, "varieti": 0.8316941898119999, "judgment": 2.3898026343, "content": 1.26473915954, "recent": 0.434413741288, "india": 1.36707979618, "next": 1.206491056497, "set": 0.171496011289, "ani": 0.502433433464, "two": 0.0136988443582, "sampl": 7.914505953560001, "from": 0.00567054168866, "even": 0.152388564834, "chang": 0.332551250116, "document": 2.7976413671489997, "project": 0.561601885907, "differ": 0.849284485248, "monolith": 4.20450367277, "transform": 1.22966322707, "kulkarni": 13.79995018332, "prefix": 3.2509415461, "unearth": 3.74830801649, "domain": 8.96032002396, "for": 0.005354836721749001, "brief": 1.22086960472, "fail": 0.656536611573, "geometr": 3.1971310972, "all": 0.022805264195599997, "match": 5.08761775496, "fulli": 1.02609828678, "with": 0.00957993370712, "store": 1.2374487335200002, "assum": 1.08435313525, "keen": 2.61380566138, "are": 0.4420121037405, "layout": 2.71032034964, "case": 0.395406268889, "middl": 0.7141523446729999, "structur": 1.4435433502700001, "result": 0.136378908381, "parsinglog": 7.369978720910001, "look": 1.9391600808, "veloc": 3.17277677325, "option": 5.59384724644, "patent": 2.35668030939, "summari": 4.108625432059999, "regular": 0.739163417847, "more": 0.017024931599999998, "and": 0.0010078422730176, "linewis": 7.369978720910001, "while": 0.04324998379380001, "extract": 30.624258495150002, "intern": 0.530190755632, "finish": 1.17210994649, "achiev": 0.6270980851169999, "these": 0.2146008582024, "separ": 1.883039091796, "pars": 14.943647795009998, "etre": 7.369978720910001, "keyword": 9.87273073102, "made": 0.0680215260973, "could": 0.18595627229000003, "visual": 1.6539383488600001, "educ": 2.090421550152, "librari": 0.986809980943, "state": 0.0932200055336, "elementtre": 7.369978720910001, "year": 0.047402238894600005, "yogesh": 14.739957441820001, "mobil": 1.5886181116100002, "one": 0.050042813164, "topic": 1.6969991554100001, "allevi": 3.1186304098799997, "make": 0.29399063129159997, "way": 0.19809150993500002, "search": 3.5396047622699998, "onli": 0.10129707331639999, "each": 0.347483378608, "highersecondari": 7.369978720910001, "few": 0.275577913653, "amazon": 3.50086321649, "this": 0.026505143367499998, "step": 1.03954505698, "read": 0.83939268088, "framework": 10.52092273035, "pursu": 1.4240346891, "contract": 1.10410732855, "regex": 14.739957441820001, "block": 1.16400781588, "summarysect": 22.10993616273, "note": 0.353817568083, "key": 0.82419811896, "method": 6.611231261887, "machin": 2.78471916124, "into": 0.0447385896861, "bio": 3.7456377879300002, "medic": 2.37289715612, "come": 0.28390990653000003, "must": 0.653383947388, "digit": 2.9705290875, "that": 0.00397614837964, "abov": 1.287730459632, "wish": 1.30224781835, "potenti": 0.9245764122419999, "doctor": 1.37104215896, "first": 0.02276186943648, "regularexpress": 7.369978720910001, "use": 0.4089122762424, "head": 1.368127748556, "textbox": 7.369978720910001, "world": 0.107420248621, "logic": 4.37863879566, "legalcontract": 7.369978720910001, "find": 2.7389066514400002, "within": 0.8505308823919999, "learn": 3.37100825898, "propos": 0.6882461339920001, "mention": 0.931747186336, "pdf": 2.38568740215}, "logidf": {"after": 0.020490694648099998, "base": 0.13652330228700002, "relat": 0.21310030165399999, "deal": 0.780914701253, "mainten": 1.9695561314200003, "bracket": 3.4802013244300003, "onc": 0.403765872355, "email": 3.5113564922099996, "here": 0.8850381883700001, "txt": 7.2746685411000005, "label": 1.49898832727, "sectionextractor": 7.369978720910001, "patternmatch": 7.369978720910001, "express": 0.648191639641, "assign": 1.3445959556, "parsingspecif": 7.369978720910001, "through": 0.0683586918849, "describ": 0.385447603125, "apart": 1.1324356512, "config": 7.369978720910001, "resum": 1.8557438481400002, "etc": 1.4366730879700003, "specif": 0.626980167541, "about": 0.0628434774746, "problem": 0.569140724273, "educationsect": 7.369978720910001, "say": 0.562154280552, "shown": 1.01856958099, "python": 4.03065674296, "just": 0.289531434109, "hear": 1.43007066072, "well": 0.0635144383156, "nodetag": 7.369978720910001, "tri": 0.61759152916, "imper": 3.4946196998500003, "approach": 0.7302336145810001, "type": 0.707101485387, "higher": 0.752308398995, "would": 0.0796176279647, "know": 0.952919694398, "codeprogram": 7.369978720910001, "their": 0.015360505122700001, "but": 0.0161923720719, "supervisedunsupervis": 7.369978720910001, "start": 0.236443369291, "cumbersom": 4.37424644735, "profil": 1.5751375153100002, "complex": 0.8502416364309999, "least": 0.480285584745, "model": 0.7374500731110001, "multipl": 1.01092401812, "articl": 0.702131739574, "how": 0.47156695693000006, "love": 1.08958288195, "segment": 2.02239511306, "phone": 2.2103488741299997, "insight": 2.46841452187, "volum": 0.877738885888, "word": 0.585861082385, "dictionari": 1.65426767539, "maintain": 0.572708175102, "increas": 0.277820718929, "initi": 0.30010459245, "can": 0.162341096394, "end": 0.101476798618, "found": 0.107841124048, "given": 0.303255810831, "autom": 2.9867028668299995, "form": 0.120053184191, "interest": 0.47207177798199995, "now": 0.149092945021, "deep": 1.2886734698, "unstructur": 5.3684987207, "the": 0.0, "consid": 0.214894723824, "analysi": 1.2466091029200002, "snippet": 4.91038987911, "second": 0.10713976337999999, "number": 0.0966085784186, "broad": 1.45323772, "new": 0.0177299468511, "below": 0.813626591936, "under": 0.07526180538319999, "along": 0.260344385917, "demonstr": 0.9745501918189999, "certain": 0.592104362781, "need": 0.362740163442, "school": 0.494746633632, "there": 0.0400978929255, "metadata": 5.35507570037, "object": 0.853933584803, "inform": 0.454453704662, "top": 0.609100637788, "num": 0.00031499039539700004, "applic": 1.23160392849, "linguist": 2.26646043267, "review": 0.7929522039210001, "level": 0.503462189943, "has": 0.0427239448548, "have": 0.0147850023412, "either": 0.459327638815, "knowledg": 1.2232212893899999, "secondari": 1.47447456495, "advantag": 1.20120515883, "painstak": 4.87677326831, "data": 1.2168205848, "opportun": 1.10258843705, "further": 0.308815895297, "configur": 2.4427250357499997, "name": 0.09723316638430002, "code": 1.35601909597, "hard": 1.00522796406, "heterogen": 3.9522520373, "format": 0.9287132518729999, "than": 0.0322608622182, "specifi": 1.93451151621, "possibl": 0.348805474891, "line": 0.349430614452, "leverag": 3.5767392514699994, "also": 0.0146571578, "field": 0.5760642583510001, "such": 0.059695977806, "textual": 3.7245288247199992, "not": 0.0155524130075, "task": 1.35748680661, "major": 0.138474663439, "them": 0.0941833269093, "research": 0.663727818138, "sectionvalueextractor": 7.369978720910001, "nonlabel": 7.369978720910001, "may": 0.050709995284400004, "doc": 3.55007100439, "extractionmethod": 7.369978720910001, "aim": 1.06333853704, "techniqu": 1.31624384807, "till": 2.44781040813, "wherea": 1.4203783778999999, "challeng": 0.9392919688950001, "primarili": 0.8897807965100001, "recognis": 1.78160709776, "whatev": 2.0343655696200003, "enhanc": 1.6408534385799998, "though": 0.308044191079, "then": 0.08303386523089999, "sens": 1.04257779501, "they": 0.0297269947676, "parser": 6.238576609419999, "primit": 2.62157436683, "descript": 1.38755491845, "machinedeep": 7.369978720910001, "although": 0.139487981418, "scienc": 0.841436178891, "paper": 0.979402539665, "employ": 0.7725602049429999, "work": 0.109034567273, "job": 1.1798682540899998, "github": 7.369978720910001, "section": 0.755387177948, "entiti": 1.93059591408, "which": 0.00517841384543, "relev": 1.9371304613999998, "xml": 5.25372320611, "simpl": 1.2232212893899999, "other": 0.00987474791976, "introduct": 1.02276465794, "implement": 1.27437940907, "mine": 1.58430908678, "career": 1.0944636875799998, "show": 0.236682766013, "valu": 0.823193310148, "known": 0.0824180805992, "univalueextractor": 7.369978720910001, "custom": 1.2905032964799998, "got": 1.2863908849299999, "entri": 1.38402935449, "cater": 2.87350795184, "pattern": 1.33282404788, "those": 0.17854939087299998, "stack": 2.97800175538, "get": 0.579769005782, "write": 0.721512439877, "like": 0.139053576545, "meta": 5.01860346375, "text": 1.14048200999, "some": 0.0395735090645, "phd": 3.10729884387, "dot": 2.93797215393, "file": 1.32734588723, "process": 0.527829199025, "entitiespattern": 7.369978720910001, "qualif": 2.8449345794, "analyt": 2.8481901438599997, "club": 1.07286940097, "varieti": 0.8316941898119999, "judgment": 2.3898026343, "content": 1.26473915954, "recent": 0.434413741288, "india": 1.36707979618, "next": 0.402163685499, "set": 0.171496011289, "ani": 0.125608358366, "two": 0.0136988443582, "sampl": 1.9786264883900002, "from": 0.000567054168866, "even": 0.152388564834, "chang": 0.166275625058, "document": 0.932547122383, "project": 0.561601885907, "differ": 0.212321121312, "monolith": 4.20450367277, "transform": 1.22966322707, "kulkarni": 6.89997509166, "prefix": 3.2509415461, "unearth": 3.74830801649, "domain": 2.24008000599, "for": 0.00031499039539700004, "brief": 1.22086960472, "fail": 0.656536611573, "geometr": 3.1971310972, "all": 0.011402632097799998, "match": 1.27190443874, "fulli": 1.02609828678, "with": 0.00119749171339, "store": 1.2374487335200002, "assum": 1.08435313525, "keen": 2.61380566138, "are": 0.0294674735827, "layout": 2.71032034964, "case": 0.395406268889, "middl": 0.7141523446729999, "structur": 0.7217716751350001, "result": 0.136378908381, "parsinglog": 7.369978720910001, "look": 0.6463866936, "veloc": 3.17277677325, "option": 1.39846181161, "patent": 2.35668030939, "summari": 2.0543127160299997, "regular": 0.739163417847, "more": 0.017024931599999998, "and": 6.29901420636e-05, "linewis": 7.369978720910001, "while": 0.04324998379380001, "extract": 2.04161723301, "intern": 0.265095377816, "finish": 1.17210994649, "achiev": 0.6270980851169999, "these": 0.0715336194008, "separ": 0.470759772949, "pars": 4.9812159316699995, "etre": 7.369978720910001, "keyword": 4.93636536551, "made": 0.0680215260973, "could": 0.18595627229000003, "visual": 1.6539383488600001, "educ": 0.696807183384, "librari": 0.986809980943, "state": 0.0466100027668, "elementtre": 7.369978720910001, "year": 0.047402238894600005, "yogesh": 7.369978720910001, "mobil": 1.5886181116100002, "one": 0.0062553516455, "topic": 1.6969991554100001, "allevi": 3.1186304098799997, "make": 0.07349765782289999, "way": 0.19809150993500002, "search": 1.1798682540899998, "onli": 0.025324268329099998, "each": 0.173741689304, "highersecondari": 7.369978720910001, "few": 0.275577913653, "amazon": 3.50086321649, "this": 0.0037864490525, "step": 1.03954505698, "read": 0.83939268088, "framework": 2.10418454607, "pursu": 1.4240346891, "contract": 1.10410732855, "regex": 7.369978720910001, "block": 1.16400781588, "summarysect": 7.369978720910001, "note": 0.353817568083, "key": 0.82419811896, "method": 0.944461608841, "machin": 1.39235958062, "into": 0.0149128632287, "bio": 3.7456377879300002, "medic": 1.18644857806, "come": 0.28390990653000003, "must": 0.653383947388, "digit": 1.48526454375, "that": 0.00397614837964, "abov": 0.643865229816, "wish": 1.30224781835, "potenti": 0.9245764122419999, "doctor": 1.37104215896, "first": 0.0075872898121599995, "regularexpress": 7.369978720910001, "use": 0.0292080197316, "head": 0.456042582852, "textbox": 7.369978720910001, "world": 0.107420248621, "logic": 2.18931939783, "legalcontract": 7.369978720910001, "find": 0.547781330288, "within": 0.21263272059799998, "learn": 0.842752064745, "propos": 0.6882461339920001, "mention": 0.931747186336, "pdf": 2.38568740215}, "freq": {"after": 1, "base": 4, "relat": 1, "deal": 1, "mainten": 1, "bracket": 2, "onc": 3, "email": 4, "here": 3, "txt": 1, "label": 1, "sectionextractor": 1, "patternmatch": 2, "express": 1, "assign": 1, "parsingspecif": 1, "through": 1, "describ": 4, "apart": 1, "config": 4, "resum": 13, "etc": 8, "specif": 7, "about": 1, "problem": 1, "educationsect": 2, "say": 3, "shown": 5, "python": 2, "just": 2, "hear": 1, "well": 2, "nodetag": 1, "tri": 1, "imper": 1, "approach": 3, "type": 5, "higher": 1, "would": 2, "know": 1, "codeprogram": 2, "their": 2, "but": 3, "supervisedunsupervis": 1, "start": 2, "cumbersom": 1, "profil": 1, "complex": 1, "least": 1, "model": 1, "multipl": 1, "articl": 4, "how": 1, "love": 1, "segment": 1, "phone": 5, "insight": 2, "volum": 1, "word": 6, "dictionari": 2, "maintain": 1, "increas": 1, "initi": 1, "can": 8, "end": 1, "found": 3, "given": 2, "autom": 1, "form": 2, "interest": 2, "now": 1, "deep": 1, "unstructur": 3, "the": 55, "consid": 1, "analysi": 1, "snippet": 1, "second": 1, "number": 1, "broad": 1, "new": 3, "below": 5, "under": 1, "along": 2, "demonstr": 3, "certain": 1, "need": 2, "school": 2, "there": 2, "metadata": 1, "object": 1, "inform": 7, "top": 1, "num": 6, "applic": 1, "linguist": 3, "review": 1, "level": 2, "has": 1, "have": 2, "either": 1, "knowledg": 1, "secondari": 3, "advantag": 1, "painstak": 1, "data": 6, "opportun": 1, "further": 4, "configur": 3, "name": 5, "code": 3, "hard": 1, "heterogen": 1, "format": 5, "than": 1, "specifi": 7, "possibl": 3, "line": 3, "leverag": 1, "also": 5, "field": 1, "such": 8, "textual": 2, "not": 5, "task": 1, "major": 1, "them": 1, "research": 1, "sectionvalueextractor": 1, "nonlabel": 1, "may": 2, "doc": 1, "extractionmethod": 1, "aim": 1, "techniqu": 2, "till": 1, "wherea": 1, "challeng": 1, "primarili": 1, "recognis": 1, "whatev": 1, "enhanc": 2, "though": 1, "then": 7, "sens": 2, "they": 1, "parser": 6, "primit": 1, "descript": 2, "machinedeep": 1, "although": 1, "scienc": 1, "paper": 1, "employ": 2, "work": 2, "job": 1, "github": 1, "section": 10, "entiti": 19, "which": 3, "relev": 5, "xml": 1, "simpl": 1, "other": 4, "introduct": 2, "implement": 4, "mine": 4, "career": 1, "show": 1, "valu": 3, "known": 1, "univalueextractor": 1, "custom": 1, "got": 1, "entri": 1, "cater": 1, "pattern": 8, "those": 2, "stack": 1, "get": 1, "write": 1, "like": 5, "meta": 1, "text": 7, "some": 1, "phd": 1, "dot": 2, "file": 7, "process": 1, "entitiespattern": 1, "qualif": 1, "analyt": 1, "club": 1, "varieti": 1, "judgment": 1, "content": 1, "recent": 1, "india": 1, "next": 3, "set": 1, "ani": 4, "two": 1, "sampl": 4, "from": 10, "even": 1, "chang": 2, "document": 3, "project": 1, "differ": 4, "monolith": 1, "transform": 1, "kulkarni": 2, "prefix": 1, "unearth": 1, "domain": 4, "for": 17, "brief": 1, "fail": 1, "geometr": 1, "all": 2, "match": 4, "fulli": 1, "with": 8, "store": 1, "assum": 1, "keen": 1, "are": 15, "layout": 1, "case": 1, "middl": 1, "structur": 2, "result": 1, "parsinglog": 1, "look": 3, "veloc": 1, "option": 4, "patent": 1, "summari": 2, "regular": 1, "more": 1, "and": 16, "linewis": 1, "while": 1, "extract": 15, "intern": 2, "finish": 1, "achiev": 1, "these": 3, "separ": 4, "pars": 3, "etre": 1, "keyword": 2, "made": 1, "could": 1, "visual": 1, "educ": 3, "librari": 1, "state": 2, "elementtre": 1, "year": 1, "yogesh": 2, "mobil": 1, "one": 8, "topic": 1, "allevi": 1, "make": 4, "way": 1, "search": 3, "onli": 4, "each": 2, "highersecondari": 1, "few": 1, "amazon": 1, "this": 7, "step": 1, "read": 1, "framework": 5, "pursu": 1, "contract": 1, "regex": 2, "block": 1, "summarysect": 3, "note": 1, "key": 1, "method": 7, "machin": 2, "into": 3, "bio": 1, "medic": 2, "come": 1, "must": 1, "digit": 2, "that": 1, "abov": 2, "wish": 1, "potenti": 1, "doctor": 1, "first": 3, "regularexpress": 1, "use": 14, "head": 3, "textbox": 1, "world": 1, "logic": 2, "legalcontract": 1, "find": 5, "within": 4, "learn": 4, "propos": 1, "mention": 1, "pdf": 1}, "idf": {"after": 1.02070207021, "base": 1.14628158845, "relat": 1.23750876919, "deal": 2.18346857379, "mainten": 7.16749435666, "bracket": 32.466257668699996, "onc": 1.4974533106999999, "email": 33.4936708861, "here": 2.42307692308, "txt": 1443.27272727, "label": 4.47715736041, "sectionextractor": 1587.6, "patternmatch": 1587.6, "express": 1.9120799710900003, "assign": 3.83663605607, "parsingspecif": 1587.6, "through": 1.07074930869, "describ": 1.47027227264, "apart": 3.1032056294, "config": 1587.6, "resum": 6.3964544722, "etc": 4.2066772655, "specif": 1.8719490626099997, "about": 1.06486015159, "problem": 1.76674827509, "educationsect": 1587.6, "say": 1.7544480053, "shown": 2.76923076923, "python": 56.2978723404, "just": 1.33580143037, "hear": 4.17899447223, "well": 1.0655748708, "nodetag": 1587.6, "tri": 1.8544562551099997, "imper": 32.9377593361, "approach": 2.07556543339, "type": 2.0281042411900003, "higher": 2.1218925421, "would": 1.0828729281799998, "know": 2.59327017315, "codeprogram": 1587.6, "their": 1.01547908405, "but": 1.01632417899, "supervisedunsupervis": 1587.6, "start": 1.26673581744, "cumbersom": 79.38, "profil": 4.8314059647, "complex": 2.34021226415, "least": 1.6165359943000002, "model": 2.0905978404, "multipl": 2.74813917258, "articl": 2.01805008262, "how": 1.60250328051, "love": 2.97303370787, "segment": 7.55640171347, "phone": 9.118897185529999, "insight": 11.8037174721, "volum": 2.40545454545, "word": 1.7965372864099998, "dictionari": 5.2292490118599995, "maintain": 1.77306231852, "increas": 1.32024948025, "initi": 1.35, "can": 1.17626139142, "end": 1.10680423871, "found": 1.11387076405, "given": 1.35426085473, "autom": 19.8202247191, "form": 1.12755681818, "interest": 1.60331246213, "now": 1.160780873, "deep": 3.6279707495399998, "unstructur": 214.54054054099998, "the": 1.0, "consid": 1.2397313759200002, "analysi": 3.47852760736, "snippet": 135.692307692, "second": 1.1130898128, "number": 1.10142916609, "broad": 4.27693965517, "new": 1.0178880554, "below": 2.25607503197, "under": 1.0781663837, "along": 1.2973768080399999, "demonstr": 2.64997496244, "certain": 1.8077886586200003, "need": 1.4372623574099999, "school": 1.64008264463, "there": 1.04091266719, "metadata": 211.68, "object": 2.3488681757700003, "inform": 1.5753125620200001, "top": 1.8387769284200002, "num": 1.00031504001, "applic": 3.42672134686, "linguist": 9.645200486030001, "review": 2.2099109131400003, "level": 1.6544393497299998, "has": 1.0436497502, "have": 1.0148948411399998, "either": 1.5830092731099998, "knowledg": 3.3981164383599998, "secondari": 4.36873968079, "advantag": 3.32412060302, "painstak": 131.20661157, "data": 3.37643555934, "opportun": 3.0119521912400002, "further": 1.3618116315, "configur": 11.504347826099998, "name": 1.10211732037, "code": 3.8807137619199996, "hard": 2.73253012048, "heterogen": 52.0524590164, "format": 2.53125, "than": 1.03278688525, "specifi": 6.920662598080001, "possibl": 1.4173734488, "line": 1.4182597820299998, "leverag": 35.7567567568, "also": 1.01476510067, "field": 1.7790228597, "such": 1.06151377374, "textual": 41.4516971279, "not": 1.01567398119, "task": 3.88641370869, "major": 1.14852058164, "them": 1.09876115994, "research": 1.9420183486200002, "sectionvalueextractor": 1587.6, "nonlabel": 1587.6, "may": 1.05201775893, "doc": 34.8157894737, "extractionmethod": 1587.6, "aim": 2.8960233491400005, "techniqu": 3.7293868921800004, "till": 11.563000728299999, "wherea": 4.13868613139, "challeng": 2.55816951337, "primarili": 2.43459592087, "recognis": 5.93939393939, "whatev": 7.6473988439300005, "enhanc": 5.15957101072, "though": 1.36076112111, "then": 1.08657860516, "sens": 2.8365195640499996, "they": 1.03017325287, "parser": 512.129032258, "primit": 13.7573656846, "descript": 4.00504540868, "machinedeep": 1587.6, "although": 1.14968498805, "scienc": 2.31969608416, "paper": 2.6628648104700003, "employ": 2.16530278232, "work": 1.11520089913, "job": 3.2539454806299997, "github": 1587.6, "section": 2.1284354471099998, "entiti": 6.89361702128, "which": 1.005191845, "relev": 6.938811188810001, "xml": 191.277108434, "simpl": 3.3981164383599998, "other": 1.00992366412, "introduct": 2.7808723068799996, "implement": 3.57648118946, "mine": 4.875921375919999, "career": 2.98757997742, "show": 1.26703910615, "valu": 2.2777618364400003, "known": 1.0859097127200001, "univalueextractor": 1587.6, "custom": 3.6346153846199996, "got": 3.61969904241, "entri": 3.9909502262400003, "cater": 17.6989966555, "pattern": 3.79173632673, "those": 1.19548192771, "stack": 19.6485148515, "get": 1.78562591385, "write": 2.0575427682700003, "like": 1.14918566775, "meta": 151.2, "text": 3.12827586207, "some": 1.04036697248, "phd": 22.3605633803, "dot": 18.8775267539, "file": 3.7710213776699995, "process": 1.69524826482, "entitiespattern": 1587.6, "qualif": 17.2004333694, "analyt": 17.256521739100002, "club": 2.92375690608, "varieti": 2.2972073506, "judgment": 10.911340206199998, "content": 3.5421686747, "recent": 1.54405757635, "india": 3.92387543253, "next": 1.4950560316400001, "set": 1.18707940781, "ani": 1.13383802314, "two": 1.01379310345, "sampl": 7.23280182232, "from": 1.00056721497, "even": 1.16461267606, "chang": 1.1808985421, "document": 2.5409731114, "project": 1.7534791252500002, "differ": 1.23654490225, "monolith": 66.9873417722, "transform": 3.42007755278, "kulkarni": 992.25, "prefix": 25.8146341463, "unearth": 42.449197861, "domain": 9.39408284024, "for": 1.00031504001, "brief": 3.39013452915, "fail": 1.9281029876099998, "geometr": 24.4622496148, "all": 1.01146788991, "match": 3.5676404494400002, "fulli": 2.79015817223, "with": 1.0011982089899998, "store": 3.44680851064, "assum": 2.9575260804799997, "keen": 13.6509028375, "are": 1.02990593578, "layout": 15.034090909100001, "case": 1.48498737256, "middl": 2.04245465071, "structur": 2.0580762250499998, "result": 1.14611608432, "parsinglog": 1587.6, "look": 1.9086318826599997, "veloc": 23.873684210500002, "option": 4.04896710023, "patent": 10.5558510638, "summari": 7.80147420147, "regular": 2.09418282548, "more": 1.0171706817, "and": 1.00006299213, "linewis": 1587.6, "while": 1.0441988950299999, "extract": 7.703056768560001, "intern": 1.30355530011, "finish": 3.22879804759, "achiev": 1.87216981132, "these": 1.07415426252, "separ": 1.6012102874399998, "pars": 145.651376147, "etre": 1587.6, "keyword": 139.263157895, "made": 1.07038834951, "could": 1.2043695949, "visual": 5.22752716497, "educ": 2.00733341763, "librari": 2.68266306185, "state": 1.0477133240899998, "elementtre": 1587.6, "year": 1.0485436893200002, "yogesh": 1587.6, "mobil": 4.89697717458, "one": 1.00627495722, "topic": 5.457545548300001, "allevi": 22.6153846154, "make": 1.0762660158600001, "way": 1.2190739461, "search": 3.2539454806299997, "onli": 1.0256476516600002, "each": 1.18974820144, "highersecondari": 1587.6, "few": 1.31729173581, "amazon": 33.1440501044, "this": 1.00379362671, "step": 2.8279301745599996, "read": 2.3149606299200003, "framework": 8.200413223139998, "pursu": 4.15384615385, "contract": 3.0165304959099997, "regex": 1587.6, "block": 3.20274359492, "summarysect": 1587.6, "note": 1.42449528937, "key": 2.28005170185, "method": 2.5714285714300003, "machin": 4.02433460076, "into": 1.01502461479, "bio": 42.336000000000006, "medic": 3.27542809986, "come": 1.32831325301, "must": 1.9220338983099996, "digit": 4.416133518780001, "that": 1.00398406375, "abov": 1.90382539873, "wish": 3.67755385685, "potenti": 2.52080025405, "doctor": 3.9394540942900003, "first": 1.00761614623, "regularexpress": 1587.6, "use": 1.0296387573799999, "head": 1.57781753131, "textbox": 1587.6, "world": 1.11340206186, "logic": 8.929133858270001, "legalcontract": 1587.6, "find": 1.7294117647099998, "within": 1.2369302688, "learn": 2.32275054865, "propos": 1.9902218879299998, "mention": 2.53894130817, "pdf": 10.8665297741}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Text Mining 101: Mining Information From A Resume</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/text-mining-information-resume.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Text Mining 101: Mining Information From A Resume Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/machine-learning-crash-course-part-1.html\" rel=\"prev\" title=\"Machine Learning Crash Course: Part 1\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/datascience-skater-python-package-interpreting-predictive-models.html\" rel=\"next\" title=\"DataScience.com Releases Python Package for Interpreting the Decision-Making Processes of Predictive Models\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/05/text-mining-information-resume.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=67089\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/05/text-mining-information-resume.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-67089 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 24-May, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/tutorials.html\">Tutorials, Overviews</a> \u00bb Text Mining 101: Mining Information From A Resume (\u00a0<a href=\"/2017/n21.html\">17:n21</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"Silver Blog, May 2017\" src=\"/images/top-kdnuggets-blog-2017-may-silver.png\" width=\"80\"/>Text Mining 101: Mining Information From A Resume</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/05/machine-learning-crash-course-part-1.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/05/datascience-skater-python-package-interpreting-predictive-models.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 116</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/career\" rel=\"tag\">Career</a>, <a href=\"https://www.kdnuggets.com/tag/natural-language-processing\" rel=\"tag\">Natural Language Processing</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/text-analytics\" rel=\"tag\">Text Analytics</a>, <a href=\"https://www.kdnuggets.com/tag/text-mining\" rel=\"tag\">Text Mining</a></div>\n<br/>\n<p class=\"excerpt\">\n     We show a framework for mining relevant entities from a text resume, and how to separation  parsing logic from entity specification. \n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><strong>By Yogesh H. Kulkarni</strong></p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67105\" sizes=\"(max-width: 465px) 100vw, 465px\" src=\"/wp-content/uploads/regex-resume-mining.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/regex-resume-mining.jpg 465w, https://www.kdnuggets.com/wp-content/uploads/regex-resume-mining-300x178.jpg 300w\" width=\"95%\"/></p>\n<h3>Summary</h3>\n<p>This article demonstrates a framework for mining relevant entities from a text resume. It shows how separation of parsing logic from entity specification can be achieved. Although only one resume sample is considered here, the framework can be enhanced further to be used not only for different resume formats, but also for documents such as judgments, contracts, patents, medical papers, etc.</p>\n<h3>Introduction</h3>\n<p>Majority of world\u2019s unstructured data is in the textual form. To make sense of it, one must, either go through it painstakingly or employ certain automated techniques to extract relevant information. Looking at the volume, variety and velocity of such textual data, it is imperative to employ Text Mining techniques to extract the relevant information, transforming unstructured data into structured form, so that further insights, processing, analysis, visualizations are possible.</p>\n<p>This article deals with a specific domain, of applicant profiles or resumes. They, as we know, come not only in different file formats (txt, doc, pdf, etc.) but also with different contents and layouts. Such heterogeneity makes extraction of relevant information, a challenging task. Even though it may not be possible to fully extract all the relevant information from all the types of formats, one can get started with simple steps and at least extract whatever is possible from some of the known formats.</p>\n<p>Broadly there are two approaches: linguistics based and Machine Learning based. In \u201clinguistic\u201d based approaches pattern searches are made to find key information, whereas in \u201cmachine learning\u201d approaches supervised-unsupervised methods are used to extract the information. \u201cRegular expression\u201d (RegEx), used here, is one of the \u201clinguistic\u201d based pattern-matching method.</p>\n<h3>Framework</h3>\n<p>A primitive way of implementing entity extraction in a resume could be to write the pattern-matching logic for each entity, in a code-program, monolithically. In case of any change in the patterns, or if there is an introduction of new entities/patterns, one needs to change the code-program. This makes maintenance cumbersome as the complexity increases. To alleviate this problem, separation of parsing-logic and specification of entities is proposed in a framework, which is demonstrated below. Entities and their RegEx patterns are specified in a configuration file. The file also specifies type of extraction method to be used for each type of the entity. Parser uses these patterns to extract entities by the specified method. Advantages of such separation is not just maintainability but also its potential use in other domains such as legal/contracts, medical, etc.</p>\n<h3>Entities Specification</h3>\n<p>The configuration file specifies entities to be extracted along with their patterns and extraction-method. It also specifies the section within which the given entities are to be looked for. Specification shown in the textbox below, describes meta data entities like Name, Phone, Email, etc. Method used to extract them is \u201cunivalue_extractor\u201d. Section within which these entities are to be searched is named \u201c\u201d, it\u2019s a non-labelled section, like the initial few lines of the resume. Entities like Email or Phone can have multiple regular-expressions patterns. If first fails then the second one is tried and so on. Here is a brief description of the patterns used:<img alt=\"\" class=\"aligncenter size-full wp-image-67096\" sizes=\"(max-width: 920px) 100vw, 920px\" src=\"/wp-content/uploads/mining-resume-fig1.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig1.png 920w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig1-300x115.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig1-768x294.png 768w\" width=\"95%\"/></p>\n<ul>\n<li>Name: Resume\u2019s first line is assumed to have the Name, with an optional \u201cName:\u201d prefix.</li>\n<li>Email: Is a word (with optional dot in the middle) then \u201c@\u201d, then a word, dot and then a word.</li>\n<li>Phone: Optional International code in bracket, then digit pattern of 3-3-4, with optional bracket to the first 3 digits. For India number, it can be hard coded to \u201c+91\u201d as shown in the next entry.</li>\n<li>Python\u2019s \u2018etree\u2019 ElementTree library is used to parse the config xml into internal dictionary.</li>\n<li>Parser reads this specifications\u2019 dictionary and uses it to find entities from the text resume.</li>\n<li>Once an entity is matched it is stored as the node-tag, like Email, Phone, etc.</li>\n</ul>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67097\" sizes=\"(max-width: 918px) 100vw, 918px\" src=\"/wp-content/uploads/mining-resume-fig2.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig2.png 918w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig2-300x95.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig2-768x244.png 768w\" width=\"95%\"/></p>\n<p>Like Metadata described above, Educational qualifications can be searched with a config below:</p>\n<ul>\n<li>Method \u201csection_value_extractor\u201d of the parser is to be used and within section \u201cEducationSection\u201d. It finds value within a section just by matching given words.</li>\n<li>If parser finds any of the words, say \u201c10<sup>th</sup>\u201c or \u201cX\u201d or \u201cSSC\u201d, then those are the values extracted for the entity \u201cSecondary\u201d, describing Secondary School level education.</li>\n<li>If parser finds any of the words, say \u201c12<sup>th</sup>\u201d or \u201cXII\u201d or \u201cHSC\u201d, then those are the values extracted for the entity \u201cHigherSecondary\u201d, describing Higher Secondary School level education.</li>\n</ul>\n<h3>Segmentation</h3>\n<p>The sections mentioned in the above code snippets are blocks of text, labelled such as SummarySection, EducationSection, etc. These are specified at the top of the config file.</p>\n<ul>\n<li>Method \u201csection_extractor\u201d parses the document line-wise and looks for section headings.</li>\n<li>Sections are recognised by keywords used for its headings. Say, for SummarySection, keywords are \u201cSummary\u201d, \u201cAim\u201d, \u201cObjective\u201d, etc.</li>\n<li>Once the match is found, state of \u201cSummarySection\u201d is set and further lines are clubbed under it, till the next section is found.</li>\n<li>Once the new heading matches, the new state of the next section starts, so on.</li>\n</ul>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67098\" sizes=\"(max-width: 918px) 100vw, 918px\" src=\"/wp-content/uploads/mining-resume-fig3.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig3.png 918w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig3-300x87.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig3-768x223.png 768w\" width=\"95%\"/></p>\n<p><strong>Results</strong></p>\n<p>A sample resume is shown below:</p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67099\" sizes=\"(max-width: 876px) 100vw, 876px\" src=\"/wp-content/uploads/mining-resume-fig4.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig4.png 876w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig4-258x300.png 258w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig4-768x892.png 768w\" width=\"95%\"/></p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67100\" sizes=\"(max-width: 920px) 100vw, 920px\" src=\"/wp-content/uploads/mining-resume-fig5.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig5.png 920w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig5-300x202.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig5-768x518.png 768w\" width=\"95%\"/></p>\n<p>Entities extracted are shown below:</p>\n<p>Implementation of the parser, along its config file and sample resume can be found at <a href=\"https://github.com/yogeshhk/MiningResume\" rel=\"noopener noreferrer\" target=\"_blank\">github</a>.</p>\n<h3>End note</h3>\n<p>This article demonstrates unearthing of structured information from unstructured data such as a resume. As the implementation is shown only for one sample, it may not work for other formats. One would need to enhance, customize it to cater to the other resume types. Apart from resumes, the parsing-specifications separation framework can be leveraged for the other types of documents from different domains as well, by specifying domain specific configuration files.</p>\n<p><strong><img alt=\"\" class=\"size-full wp-image-67102 alignright\" src=\"/wp-content/uploads/yogesh-kulkarni.png\" width=\"20%\"/>Bio:</strong>\u00a0<a href=\"https://www.linkedin.com/in/yogeshkulkarni/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Yogesh H. Kulkarni</strong></a>, after working in the field of Geometric Modelling for more than 16 years, has recently finished a PhD in it. He got into Data Sciences while doing the doctoral research and wishes to pursue further career in it now. He is keenly interested in Text Mining, Machine/Deep Learning and primarily uses Python stack for implementations. He would love to hear from you about this article as well as on any such topics, projects, assignments, opportunities, etc.</p>\n<p dir=\"ltr\"><strong>Related:</strong></p>\n<ul>\n<li><a href=\"/2017/05/deep-learning-extract-knowledge-job-descriptions.html\" rel=\"noopener noreferrer\" target=\"_blank\">Using Deep Learning To Extract Knowledge From Job Descriptions</a></li>\n<li><a href=\"/2017/02/sas-text-analytics-nyc.html\" rel=\"noopener noreferrer\" target=\"_blank\">Making sense of text analytics</a></li>\n<li><a href=\"/2017/01/data-mining-amazon-mobile-phone-reviews-interesting-insights.html\" rel=\"noopener noreferrer\" target=\"_blank\">Text Mining Amazon Mobile Phone Reviews: Interesting Insights</a></li>\n</ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/05/machine-learning-crash-course-part-1.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/05/datascience-skater-python-package-interpreting-predictive-models.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/index.html\">May</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/05/tutorials.html\">Tutorials, Overviews</a> \u00bb Text Mining 101: Mining Information From A Resume (\u00a0<a href=\"/2017/n21.html\">17:n21</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556416285\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.603 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 21:51:25 -->\n<!-- Compression = gzip -->", "content_tokenized": ["yogesh", "kulkarni", "summari", "this", "articl", "demonstr", "framework", "for", "mine", "relev", "entiti", "from", "text", "resum", "show", "how", "separ", "pars", "logic", "from", "entiti", "specif", "can", "achiev", "although", "onli", "one", "resum", "sampl", "consid", "here", "the", "framework", "can", "enhanc", "further", "use", "not", "onli", "for", "differ", "resum", "format", "but", "also", "for", "document", "such", "judgment", "contract", "patent", "medic", "paper", "etc", "introduct", "major", "world", "unstructur", "data", "the", "textual", "form", "make", "sens", "one", "must", "either", "through", "painstak", "employ", "certain", "autom", "techniqu", "extract", "relev", "inform", "look", "the", "volum", "varieti", "and", "veloc", "such", "textual", "data", "imper", "employ", "text", "mine", "techniqu", "extract", "the", "relev", "inform", "transform", "unstructur", "data", "into", "structur", "form", "that", "further", "insight", "process", "analysi", "visual", "are", "possibl", "this", "articl", "deal", "with", "specif", "domain", "applic", "profil", "resum", "they", "know", "come", "not", "onli", "differ", "file", "format", "txt", "doc", "pdf", "etc", "but", "also", "with", "differ", "content", "and", "layout", "such", "heterogen", "make", "extract", "relev", "inform", "challeng", "task", "even", "though", "may", "not", "possibl", "fulli", "extract", "all", "the", "relev", "inform", "from", "all", "the", "type", "format", "one", "can", "get", "start", "with", "simpl", "step", "and", "least", "extract", "whatev", "possibl", "from", "some", "the", "known", "format", "broad", "there", "are", "two", "approach", "linguist", "base", "and", "machin", "learn", "base", "linguist", "base", "approach", "pattern", "search", "are", "made", "find", "key", "inform", "wherea", "machin", "learn", "approach", "supervisedunsupervis", "method", "are", "use", "extract", "the", "inform", "regular", "express", "regex", "use", "here", "one", "the", "linguist", "base", "patternmatch", "method", "framework", "primit", "way", "implement", "entiti", "extract", "resum", "could", "write", "the", "patternmatch", "logic", "for", "each", "entiti", "codeprogram", "monolith", "case", "ani", "chang", "the", "pattern", "there", "introduct", "new", "entitiespattern", "one", "need", "chang", "the", "codeprogram", "this", "make", "mainten", "cumbersom", "the", "complex", "increas", "allevi", "this", "problem", "separ", "parsinglog", "and", "specif", "entiti", "propos", "framework", "which", "demonstr", "below", "entiti", "and", "their", "regex", "pattern", "are", "specifi", "configur", "file", "the", "file", "also", "specifi", "type", "extract", "method", "use", "for", "each", "type", "the", "entiti", "parser", "use", "these", "pattern", "extract", "entiti", "the", "specifi", "method", "advantag", "such", "separ", "not", "just", "maintain", "but", "also", "potenti", "use", "other", "domain", "such", "legalcontract", "medic", "etc", "entiti", "specif", "the", "configur", "file", "specifi", "entiti", "extract", "along", "with", "their", "pattern", "and", "extractionmethod", "also", "specifi", "the", "section", "within", "which", "the", "given", "entiti", "are", "look", "for", "specif", "shown", "the", "textbox", "below", "describ", "meta", "data", "entiti", "like", "name", "phone", "email", "etc", "method", "use", "extract", "them", "univalueextractor", "section", "within", "which", "these", "entiti", "are", "search", "name", "nonlabel", "section", "like", "the", "initi", "few", "line", "the", "resum", "entiti", "like", "email", "phone", "can", "have", "multipl", "regularexpress", "pattern", "first", "fail", "then", "the", "second", "one", "tri", "and", "here", "brief", "descript", "the", "pattern", "use", "name", "resum", "first", "line", "assum", "have", "the", "name", "with", "option", "name", "prefix", "email", "word", "with", "option", "dot", "the", "middl", "then", "then", "word", "dot", "and", "then", "word", "phone", "option", "intern", "code", "bracket", "then", "digit", "pattern", "num", "with", "option", "bracket", "the", "first", "num", "digit", "for", "india", "number", "can", "hard", "code", "num", "shown", "the", "next", "entri", "python", "etre", "elementtre", "librari", "use", "pars", "the", "config", "xml", "into", "intern", "dictionari", "parser", "read", "this", "specif", "dictionari", "and", "use", "find", "entiti", "from", "the", "text", "resum", "onc", "entiti", "match", "store", "the", "nodetag", "like", "email", "phone", "etc", "like", "metadata", "describ", "abov", "educ", "qualif", "can", "search", "with", "config", "below", "method", "sectionvalueextractor", "the", "parser", "use", "and", "within", "section", "educationsect", "find", "valu", "within", "section", "just", "match", "given", "word", "parser", "find", "ani", "the", "word", "say", "num", "then", "those", "are", "the", "valu", "extract", "for", "the", "entiti", "secondari", "describ", "secondari", "school", "level", "educ", "parser", "find", "ani", "the", "word", "say", "num", "then", "those", "are", "the", "valu", "extract", "for", "the", "entiti", "highersecondari", "describ", "higher", "secondari", "school", "level", "educ", "segment", "the", "section", "mention", "the", "abov", "code", "snippet", "are", "block", "text", "label", "such", "summarysect", "educationsect", "etc", "these", "are", "specifi", "the", "top", "the", "config", "file", "method", "sectionextractor", "pars", "the", "document", "linewis", "and", "look", "for", "section", "head", "section", "are", "recognis", "keyword", "use", "for", "head", "say", "for", "summarysect", "keyword", "are", "summari", "aim", "object", "etc", "onc", "the", "match", "found", "state", "summarysect", "set", "and", "further", "line", "are", "club", "under", "till", "the", "next", "section", "found", "onc", "the", "new", "head", "match", "the", "new", "state", "the", "next", "section", "start", "result", "sampl", "resum", "shown", "below", "entiti", "extract", "are", "shown", "below", "implement", "the", "parser", "along", "config", "file", "and", "sampl", "resum", "can", "found", "github", "end", "note", "this", "articl", "demonstr", "unearth", "structur", "inform", "from", "unstructur", "data", "such", "resum", "the", "implement", "shown", "onli", "for", "one", "sampl", "may", "not", "work", "for", "other", "format", "one", "would", "need", "enhanc", "custom", "cater", "the", "other", "resum", "type", "apart", "from", "resum", "the", "parsingspecif", "separ", "framework", "can", "leverag", "for", "the", "other", "type", "document", "from", "differ", "domain", "well", "specifi", "domain", "specif", "configur", "file", "bio", "yogesh", "kulkarni", "after", "work", "the", "field", "geometr", "model", "for", "more", "than", "num", "year", "has", "recent", "finish", "phd", "got", "into", "data", "scienc", "while", "the", "doctor", "research", "and", "wish", "pursu", "further", "career", "now", "keen", "interest", "text", "mine", "machinedeep", "learn", "and", "primarili", "use", "python", "stack", "for", "implement", "would", "love", "hear", "from", "about", "this", "articl", "well", "ani", "such", "topic", "project", "assign", "opportun", "etc", "relat", "use", "deep", "learn", "extract", "knowledg", "from", "job", "descript", "make", "sens", "text", "analyt", "text", "mine", "amazon", "mobil", "phone", "review", "interest", "insight"], "timestamp_scraper": 1556484239.029381, "title": "Text Mining 101: Mining Information From A Resume", "read_time": 308.7, "content_html": "<div class=\"post\" id=\"post-\">\n<p><strong>By Yogesh H. Kulkarni</strong></p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67105\" sizes=\"(max-width: 465px) 100vw, 465px\" src=\"/wp-content/uploads/regex-resume-mining.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/regex-resume-mining.jpg 465w, https://www.kdnuggets.com/wp-content/uploads/regex-resume-mining-300x178.jpg 300w\" width=\"95%\"/></p>\n<h3>Summary</h3>\n<p>This article demonstrates a framework for mining relevant entities from a text resume. It shows how separation of parsing logic from entity specification can be achieved. Although only one resume sample is considered here, the framework can be enhanced further to be used not only for different resume formats, but also for documents such as judgments, contracts, patents, medical papers, etc.</p>\n<h3>Introduction</h3>\n<p>Majority of world\u2019s unstructured data is in the textual form. To make sense of it, one must, either go through it painstakingly or employ certain automated techniques to extract relevant information. Looking at the volume, variety and velocity of such textual data, it is imperative to employ Text Mining techniques to extract the relevant information, transforming unstructured data into structured form, so that further insights, processing, analysis, visualizations are possible.</p>\n<p>This article deals with a specific domain, of applicant profiles or resumes. They, as we know, come not only in different file formats (txt, doc, pdf, etc.) but also with different contents and layouts. Such heterogeneity makes extraction of relevant information, a challenging task. Even though it may not be possible to fully extract all the relevant information from all the types of formats, one can get started with simple steps and at least extract whatever is possible from some of the known formats.</p>\n<p>Broadly there are two approaches: linguistics based and Machine Learning based. In \u201clinguistic\u201d based approaches pattern searches are made to find key information, whereas in \u201cmachine learning\u201d approaches supervised-unsupervised methods are used to extract the information. \u201cRegular expression\u201d (RegEx), used here, is one of the \u201clinguistic\u201d based pattern-matching method.</p>\n<h3>Framework</h3>\n<p>A primitive way of implementing entity extraction in a resume could be to write the pattern-matching logic for each entity, in a code-program, monolithically. In case of any change in the patterns, or if there is an introduction of new entities/patterns, one needs to change the code-program. This makes maintenance cumbersome as the complexity increases. To alleviate this problem, separation of parsing-logic and specification of entities is proposed in a framework, which is demonstrated below. Entities and their RegEx patterns are specified in a configuration file. The file also specifies type of extraction method to be used for each type of the entity. Parser uses these patterns to extract entities by the specified method. Advantages of such separation is not just maintainability but also its potential use in other domains such as legal/contracts, medical, etc.</p>\n<h3>Entities Specification</h3>\n<p>The configuration file specifies entities to be extracted along with their patterns and extraction-method. It also specifies the section within which the given entities are to be looked for. Specification shown in the textbox below, describes meta data entities like Name, Phone, Email, etc. Method used to extract them is \u201cunivalue_extractor\u201d. Section within which these entities are to be searched is named \u201c\u201d, it\u2019s a non-labelled section, like the initial few lines of the resume. Entities like Email or Phone can have multiple regular-expressions patterns. If first fails then the second one is tried and so on. Here is a brief description of the patterns used:<img alt=\"\" class=\"aligncenter size-full wp-image-67096\" sizes=\"(max-width: 920px) 100vw, 920px\" src=\"/wp-content/uploads/mining-resume-fig1.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig1.png 920w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig1-300x115.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig1-768x294.png 768w\" width=\"95%\"/></p>\n<ul>\n<li>Name: Resume\u2019s first line is assumed to have the Name, with an optional \u201cName:\u201d prefix.</li>\n<li>Email: Is a word (with optional dot in the middle) then \u201c@\u201d, then a word, dot and then a word.</li>\n<li>Phone: Optional International code in bracket, then digit pattern of 3-3-4, with optional bracket to the first 3 digits. For India number, it can be hard coded to \u201c+91\u201d as shown in the next entry.</li>\n<li>Python\u2019s \u2018etree\u2019 ElementTree library is used to parse the config xml into internal dictionary.</li>\n<li>Parser reads this specifications\u2019 dictionary and uses it to find entities from the text resume.</li>\n<li>Once an entity is matched it is stored as the node-tag, like Email, Phone, etc.</li>\n</ul>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67097\" sizes=\"(max-width: 918px) 100vw, 918px\" src=\"/wp-content/uploads/mining-resume-fig2.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig2.png 918w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig2-300x95.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig2-768x244.png 768w\" width=\"95%\"/></p>\n<p>Like Metadata described above, Educational qualifications can be searched with a config below:</p>\n<ul>\n<li>Method \u201csection_value_extractor\u201d of the parser is to be used and within section \u201cEducationSection\u201d. It finds value within a section just by matching given words.</li>\n<li>If parser finds any of the words, say \u201c10<sup>th</sup>\u201c or \u201cX\u201d or \u201cSSC\u201d, then those are the values extracted for the entity \u201cSecondary\u201d, describing Secondary School level education.</li>\n<li>If parser finds any of the words, say \u201c12<sup>th</sup>\u201d or \u201cXII\u201d or \u201cHSC\u201d, then those are the values extracted for the entity \u201cHigherSecondary\u201d, describing Higher Secondary School level education.</li>\n</ul>\n<h3>Segmentation</h3>\n<p>The sections mentioned in the above code snippets are blocks of text, labelled such as SummarySection, EducationSection, etc. These are specified at the top of the config file.</p>\n<ul>\n<li>Method \u201csection_extractor\u201d parses the document line-wise and looks for section headings.</li>\n<li>Sections are recognised by keywords used for its headings. Say, for SummarySection, keywords are \u201cSummary\u201d, \u201cAim\u201d, \u201cObjective\u201d, etc.</li>\n<li>Once the match is found, state of \u201cSummarySection\u201d is set and further lines are clubbed under it, till the next section is found.</li>\n<li>Once the new heading matches, the new state of the next section starts, so on.</li>\n</ul>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67098\" sizes=\"(max-width: 918px) 100vw, 918px\" src=\"/wp-content/uploads/mining-resume-fig3.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig3.png 918w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig3-300x87.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig3-768x223.png 768w\" width=\"95%\"/></p>\n<p><strong>Results</strong></p>\n<p>A sample resume is shown below:</p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67099\" sizes=\"(max-width: 876px) 100vw, 876px\" src=\"/wp-content/uploads/mining-resume-fig4.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig4.png 876w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig4-258x300.png 258w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig4-768x892.png 768w\" width=\"95%\"/></p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-67100\" sizes=\"(max-width: 920px) 100vw, 920px\" src=\"/wp-content/uploads/mining-resume-fig5.png\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig5.png 920w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig5-300x202.png 300w, https://www.kdnuggets.com/wp-content/uploads/mining-resume-fig5-768x518.png 768w\" width=\"95%\"/></p>\n<p>Entities extracted are shown below:</p>\n<p>Implementation of the parser, along its config file and sample resume can be found at <a href=\"https://github.com/yogeshhk/MiningResume\" rel=\"noopener noreferrer\" target=\"_blank\">github</a>.</p>\n<h3>End note</h3>\n<p>This article demonstrates unearthing of structured information from unstructured data such as a resume. As the implementation is shown only for one sample, it may not work for other formats. One would need to enhance, customize it to cater to the other resume types. Apart from resumes, the parsing-specifications separation framework can be leveraged for the other types of documents from different domains as well, by specifying domain specific configuration files.</p>\n<p><strong><img alt=\"\" class=\"size-full wp-image-67102 alignright\" src=\"/wp-content/uploads/yogesh-kulkarni.png\" width=\"20%\"/>Bio:</strong>\u00a0<a href=\"https://www.linkedin.com/in/yogeshkulkarni/\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>Yogesh H. Kulkarni</strong></a>, after working in the field of Geometric Modelling for more than 16 years, has recently finished a PhD in it. He got into Data Sciences while doing the doctoral research and wishes to pursue further career in it now. He is keenly interested in Text Mining, Machine/Deep Learning and primarily uses Python stack for implementations. He would love to hear from you about this article as well as on any such topics, projects, assignments, opportunities, etc.</p>\n<p dir=\"ltr\"><strong>Related:</strong></p>\n<ul>\n<li><a href=\"/2017/05/deep-learning-extract-knowledge-job-descriptions.html\" rel=\"noopener noreferrer\" target=\"_blank\">Using Deep Learning To Extract Knowledge From Job Descriptions</a></li>\n<li><a href=\"/2017/02/sas-text-analytics-nyc.html\" rel=\"noopener noreferrer\" target=\"_blank\">Making sense of text analytics</a></li>\n<li><a href=\"/2017/01/data-mining-amazon-mobile-phone-reviews-interesting-insights.html\" rel=\"noopener noreferrer\" target=\"_blank\">Text Mining Amazon Mobile Phone Reviews: Interesting Insights</a></li>\n</ul>\n</div> ", "website": "kdnuggets"}