{"content": "comments By Preet Gandhi , NYU Introduction In the era of data science, artificial intelligence is making impossible feats possible. Driverless cars, IBM Watson\u2019s question-answering system, cancer detection, electronic trading, etc. are all made possible through the advanced decision making ability of artificial intelligence. The deep layers of neural networks have a magical ability to recreate the human mind and its functionalities. When humans make decisions, they have the ability to explain their thought process behind it. They can explain the rationale; whether its driven by observation, intuition, experience or logical thinking ability. Basic ML algorithms like decision trees can be explained by following the tree path which led to the decision. But when it comes to complex AI algorithms, the deep layers are often incomprehensible by human intuition and are quite opaque. Data scientists may have trouble explaining why their algorithm gave a decision and the laymen end-user may not simply trust the machine\u2019s predictions without contextual proof and reasoning. Explainability is a multifaceted topic. It encompasses both individual models and the larger systems that incorporate them. It refers not only to whether the decisions a model outputs are interpretable, but also whether or not the whole process and intention surrounding the model can be properly accounted for. They try have an efficient trade-off between accuracy and explainability along with a great human-computer interface which can help translate the model to understandable representation for the end users. There need to be three steps which should be fulfilled by the system : 1) Explained the intent behind how the system affects the concerned parties 2) Explain the data sources you use and how you audit outcomes 3) Explain how inputs in a model lead to outputs. The necessity Explainability is motivated due to lacking transparency of the black-box approaches, which do not foster trust and acceptance of AI generally and ML specifically. Rising legal and privacy aspects, e.g. with the new European General Data Protection Regulations will make black-box approaches difficult to use in Business, because they often are not able to explain why a machine decision has been made. IBM Watson shook the world when it won jeopardy beating the best human players. But when it was marketed to hospitals to help the oncology department detect cancer, it failed miserably. Cancer detection is a very difficult and serious topic. The doctors as well as the patients were unable to trust the machine at each stage of consulting and treatment as Watson wouldn\u2019t provide the reasons for its results. Moreover when its results agreed with the doctor\u2019s, it couldn't provide a diagnosis. Using AI for military practices is a hotly debated topic. Proponents claim that lethal autonomous weapon systems (LAWS) might cause less collateral damage but despite there being large training data to distinguish between combatants and civilians or targets and non-targets, it is very risky to leave the final decision making power to machines. CIA has 137 AI projects, one of which is the automated AI-enabled drones where the lack of explainability of the AI software\u2019s selection of the targets is controversial. The extent of an explanation currently may be, \u201cThere is a 95 percent chance this is what you should do,\u201d but that\u2019s it. When the algorithm can't describe it\u2019s features that contributed towards identifying a legitimate target, it leaves room open for debate on racism and stereotype issues which bias the model. Moreover in case of a false target, explanations would help diagnose the cause of failure and help improve the model. New methods in academia There are two main set of techniques used to develop explainable systems; post-hoc and ante-hoc. Ante-hoc techniques entail baking explainability into a model from the beginning. Post-hoc techniques allow models to be trained normally, with explainability only being incorporated at testing time. Ante-Hoc Methods: Reversed Time Attention Model\u00a0(RETAIN) : Researchers at Georgia-Tech developed the RETAIN model to help doctors understand the AI software\u2019s predictions. The patients hospital visits data were sent to two RNN\u2019s both of which had attention mechanism. The attention mechanism helped explain which part the neural network was focusing on and which features helped influence its choice. Bayesian deep learning (BDL): BDL enables one to gauge how uncertain a neural network is about its predictions. These deep architectures can model complex tasks by leveraging the hierarchical representation power of deep learning, while also being able to infer complex multi-modal posterior distributions. Bayesian deep learning models typically form uncertainty estimates by either placing distributions over model weights, or by learning a direct mapping to probabilistic outputs. By knowing the weight distributions of various predictions and classes, we can tell a lot about what feature led to what decisions and the relative important of it. Post-Hoc Methods: Local Interpretable Model-Agnostic Explanations (LIME) : This isn\u2019t a purely transparent model as it provides the explanation after a decision has been made. Hence it can have wide range of applications as it isn\u2019t customized to one domain unlike RETAIN. For example for an image classification problem using a CNN, we get the probability distribution over classes. Then we make small changes to input to see how it affects the distribution and collect the results. Then using a linear interpretable model, on the collected perturbation set, we can explain changed in the key features extracted with their weights telling us how prominent they are. It blacks out different parts of the original image and feeds the resulting \u201cperturbed\u201d images back through the model, checking to see which perturbations throw the algorithm off the furthest to derive reasoning behind the algorithms decisions. For example, for an image of a tree frog, LIME found that erasing parts of the frog\u2019s face made it much harder for the model to identify the image, showing that much of the original classification decision was based on the frog\u2019s face. LIME is generally applicable to image classifications tasks. In 2015, a black software developer reported that Google Photos labeled images of him and his black friend as \u201cgorillas.\u201d It\u2019s not hard to see how explanation techniques like LIME could mitigate this kind of bias by having a human operator override the decisions upon evaluating the reasons given by the algorithm. Layer-wise Relevance Propagation (LRP) : This approach is based on the principles of redistribution and conservation. Here when we have an image and probability distribution of classes, we redistribute these to the input pixels, layer by layer. We can decide the relevance of inputs and features by going backwards using Deep CNN to extract relevant features before identifying similarity between the images in feature space. We try to infer pixel-level details of the images that may have significantly informed the model\u2019s choice. x_j\u200a\u2014\u200athe activation value for neuron j in layer l w_j,k\u200a\u2014\u200athe weighing of the connection between neuron j in layer l and neuron k in layer l + 1 R_j\u200a\u2014\u200aRelevance scores for each neuron in layer l R_k\u200a\u2014\u200aRelevance scores for each neuron in layer l+1 BETA : BETA is closely connected to Interpretable Decision Sets. BETA learns a compact two-level decision set in which each rule explains part of the model behavior unambiguously. It uses a objective function so that the learning process is optimized for high fidelity (high agreement between explanation and the model), low unambiguity (little overlaps between decision rules in the explanation), and high interpretability (the explanation decision set is lightweight and small). These aspects are combined into one objection function to optimize for. Explainability vs Accuracy Will we need to \u2018dumb down\u2019 AI algorithms to make them explainable? Explainable models are easily understandable but don\u2019t work very well as they are simple. Accurate models work well but aren\u2019t explainable as they are complicated. The main issue with explainable AI is whether it can accurately fulfill the task it was designed for. The tradeoff decision to be made should depend on the application field of the algorithm and the end-user to whom its accountable. When dealing with technical users who are acquainted with the field and have high trust level, especially tech companies or researchers, having highly accurate models would be preferred over high explainability as performance is very important. But dealing with laymen users is a different scenario. It would be difficult to garner their trust. The machine learning approach is very different specially in banks, insurance companies, healthcare providers and other regulated industries. The reason is mainly that they are prone to legal or even ethical requirements which tend to limit more and more the use of black box models. Such institutions are answerable for their decisions and process and in this case a simple explainable albeit less efficient algorithm would do. Hence the tradeoff should be decided according to the application domain and the users concerned. If you want your system to be explainable, you\u2019re going to have to make do with a simpler system that isn\u2019t as powerful or accurate. Simple systems can give a prediction to the user but the ultimate action should be taken by the user. When performance matters most, even with a complicated model, opt for the trust that comes from making sure that you\u2019re able to verify that your system does, in fact, work. Use Case : DARPA XAI The Department of Defense (DoD) is increasingly investing in AI research in collaboration with technological giants like Google to have artificial intelligence programs for military activities. Due to ethical reasons, many government departments agree to have a \u201cman in the loop\u201d to control any lethal system of these \u201ckiller robots\u201d. Due to the increasing debates and strikes by the AI community to not contribute towards military AI, the DARPA division is pushing towards their $2 Billion Explainable Artificial Intelligence ( XAI ) program. XAI is their hope to usher in the third-wave AI systems which can understand the context in which they function and can characterize the real world phenomena. Its main aim is to: Explain the decisions and it\u2019s process Understand it\u2019s strength and weakness Convey how the system may behave in the future Offer insight on how to correct the mistakes The final goal of XAI is to have a toolkit library of ML and HCI modules for more understandable AI implementations. The Phase 1 of the project was completed in May 2018 and further advancements are expected in the coming years. In case of a gray area in decision output, XAI aims to give the analyst reasons for red flags upon which the analyst can act to make a decision using human input. Conclusion The success of AI models is due to the machines\u2019 own internal representations which are even more complicated then manually generated features leading to its inexplicable nature. There are a lot of on-going research on the ante-hoc and post-hoc methods to make the AI more answerable and awareness to inculcate these methods in existing programs. Good initiatives by leading institutions like DARPA, Google, DeepMind, etc. are leading the necessary change. Despite this, there will always be a tradeoff between explainability and accuracy whose balance depends on various factors like end-user, legal liability, technicality of the concerned parties and the field of application. Artificial intelligence should not become a powerful deity which we follow blindly without understanding its reasoning but we shouldn\u2019t forget about its beneficial insight it can have. Ideally, we should build flexible and interpretable models that can work in collaboration with experts and their domain knowledge. References LRP - /pdf/1807.06160.pdf DARPA XAI - /attachments/XAIProgramUpdate.pdf XAI methods - /an-introduction-to-explainable-ai-and-why-we-need-it-a326417dd000 Bio : Preet Gandhi is a student at NYU and was a Data Science Intern at Apple Inc. Resources: On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education Software for Analytics, Data Science, Data Mining, and Machine Learning Related: A Case For Explainable AI & Machine Learning Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI Four Approaches to Explaining AI and Machine Learning", "title_html": "<h1 id=\"title\">Explainable Artificial Intelligence</h1> ", "url": "https://www.kdnuggets.com/2019/01/explainable-ai.html", "tfidf": {"tfidf": {"after": 1.02070207021, "strike": 3.5620372447800004, "real": 2.28103448276, "failur": 3.28559602649, "audit": 15.12, "awar": 4.27693965517, "then": 3.25973581548, "relat": 2.47501753838, "analyst": 29.6747663552, "stage": 2.0831911822599998, "troubl": 4.99088337001, "label": 4.47715736041, "red": 2.22228443449, "opaqu": 75.961722488, "kind": 2.5806241872599998, "space": 2.39818731118, "topic": 16.372636644900002, "googl": 34.166427546600005, "miser": 38.8166259169, "propon": 12.2029208301, "been": 2.0478555304799997, "etc": 8.413354531, "four": 1.20950784702, "function": 9.98176674, "class": 6.34955339289, "intent": 6.38744719372, "logic": 8.929133858270001, "weapon": 4.57126403686, "era": 2.5693477909, "three": 1.06621893889, "thought": 1.9854927463699998, "whom": 2.30320615117, "well": 3.1967246123999997, "behav": 15.6413793103, "tri": 3.7089125102199993, "tree": 12.383775351, "nontarget": 721.636363636, "complet": 1.24021560816, "approach": 10.37782716695, "diagnosi": 28.8130671506, "toward": 4.8909426987, "know": 2.59327017315, "most": 1.02096463023, "anintroductiontoexplainableaiandwhyweneeditanumddnum": 721.636363636, "regul": 7.77473065622, "motiv": 5.01611374408, "applic": 17.1336067343, "uncertain": 10.8590971272, "legal": 7.800196528020001, "won": 2.31732593782, "translat": 2.85745140389, "magic": 7.9063745019899985, "overlap": 12.0913937548, "defens": 3.19115577889, "room": 3.07674418605, "verifi": 14.2258064516, "how": 14.422529524589999, "billion": 4.8669527897, "inexplic": 89.6949152542, "upon": 3.20662492426, "transpar": 31.752, "origin": 2.27449856734, "had": 1.0475750577399998, "increas": 2.6404989605, "especi": 1.66712170534, "expert": 5.36713995943, "distribut": 16.437618636779998, "due": 4.95157894736, "end": 1.10680423871, "found": 1.11387076405, "given": 1.35426085473, "form": 1.12755681818, "driven": 5.601976005650001, "deep": 25.395795246779997, "depend": 4.4822134387400006, "will": 3.67443295788, "conserv": 3.3199498117900004, "scenario": 15.3986420951, "toolkit": 189.0, "open": 1.24556723678, "propag": 18.8104265403, "wide": 1.5598349381, "incorpor": 5.25695364238, "neuron": 321.3765182185, "claim": 1.52697893623, "perform": 3.0627954085000004, "but": 10.163241789899999, "success": 1.32002993265, "surround": 2.49858356941, "need": 2.8745247148199997, "furthest": 84.8983957219, "classif": 24.201219512190004, "output": 30.707930367520003, "sure": 7.453521126760001, "final": 2.6801721955, "expect": 2.20011086475, "parti": 4.12738853504, "key": 2.28005170185, "killer": 13.9141104294, "lead": 5.0657306956, "level": 1.6544393497299998, "robot": 20.0201765448, "has": 3.1309492505999996, "generat": 2.05275407292, "collabor": 8.9090909091, "use": 11.32602633118, "experi": 1.87062566278, "govern": 1.50941243582, "resourc": 2.9487369985100003, "onlin": 2.6051854282900004, "out": 1.06016694491, "mistak": 8.71350164654, "model": 58.5367395312, "oncolog": 158.76, "good": 1.51981619759, "alway": 2.06745670009, "concept": 2.65707112971, "much": 2.3884459154599997, "opt": 12.721153846199998, "optim": 23.0755813954, "field": 5.3370685791, "reason": 13.78723404256, "percent": 3.9026548672600003, "not": 8.12539184952, "proof": 9.70415647922, "overrid": 34.8157894737, "uncertainti": 16.0688259109, "redistribut": 69.0260869566, "perturb": 224.66037735839998, "difficult": 7.4687156970299995, "less": 2.93809567872, "agreement": 3.0245761097400004, "aim": 5.792046698280001, "garner": 12.5900079302, "specif": 1.8719490626099997, "deepmind": 721.636363636, "lethal": 53.544688027, "whole": 2.29488291414, "fidel": 26.637583892600002, "complic": 16.943436499470003, "bayesian": 356.76404494400003, "they": 9.27155927583, "design": 1.45825296225, "consult": 5.21721984883, "cancer": 24.03027245208, "allow": 1.2716059271100002, "world": 2.22680412372, "scienc": 9.27878433664, "outcom": 7.48867924528, "pixel": 86.28260869569999, "posthoc": 2886.545454544, "larger": 2.2407904022599996, "student": 2.47174217655, "behavior": 5.52978056426, "featur": 12.21700654096, "feed": 7.77853993141, "practic": 1.70434782609, "lack": 3.8543335761199997, "simpl": 10.19434931508, "influenc": 1.77246846042, "that": 16.06374502, "whose": 1.73508196721, "algorithm": 279.507042254, "albeit": 11.172413793099999, "offer": 1.53896859248, "mind": 3.5918552036199998, "either": 1.5830092731099998, "accord": 1.27589809531, "develop": 3.5867158671600006, "moreov": 15.12, "observ": 2.22446406053, "accuraci": 38.2861736334, "agre": 4.45892430838, "with": 13.015576716869997, "more": 5.085853408499999, "network": 7.781081522639999, "deriv": 2.78379800105, "lot": 8.81755068036, "eras": 30.7079303675, "racism": 21.6885245902, "small": 2.7189587258, "control": 1.46959178006, "invest": 4.16146788991, "may": 6.31210655358, "twolevel": 721.636363636, "privaci": 28.2994652406, "concern": 5.655860349120001, "off": 1.5121440137200002, "beat": 4.95660318451, "easili": 3.6938110749199997, "without": 2.59094247246, "protect": 1.96460834055, "set": 5.93539703905, "caus": 2.77043887968, "ani": 1.13383802314, "two": 3.04137931035, "drone": 52.92, "and": 54.00340157502, "from": 2.00113442994, "account": 3.8892699657, "answer": 9.29780380674, "limit": 1.5186531471200002, "patient": 19.09320505112, "detail": 2.26186066391, "num": 10.003150400100001, "technolog": 2.6034765496900003, "depart": 5.9744104365299995, "market": 2.36602086438, "aren": 481.09090909099996, "balanc": 4.45329593268, "for": 23.00724592023, "car": 3.53743315508, "predict": 25.92423252775, "friend": 2.20194174757, "militari": 6.39387837294, "unlik": 2.42529789184, "new": 2.0357761108, "are": 18.53830684404, "simpli": 2.5192002538900002, "controversi": 2.62543409955, "explan": 52.073800738, "compani": 3.1047227926, "result": 4.58446433728, "current": 1.5325803649, "lnum": 53.8169491525, "attachmentsxaiprogramupdatepdf": 721.636363636, "usher": 23.2105263158, "sent": 2.32683570277, "path": 4.6421052631599995, "chanc": 4.2449197861000005, "extract": 15.406113537120001, "intern": 2.60711060022, "restor": 2.97526236882, "harder": 17.1262135922, "think": 2.90715986083, "tend": 3.3735656608599998, "combin": 1.69760479042, "focus": 2.01012914662, "educ": 2.00733341763, "legitim": 9.16099249856, "general": 3.3654607122600004, "map": 4.0728578758300005, "doe": 1.70581282905, "even": 3.49383802818, "ongo": 6.04569687738, "littl": 1.5499365420299998, "give": 2.7306501548, "dod": 87.7127071823, "simpler": 17.9187358916, "photo": 6.41973311767, "proper": 3.3388012618299996, "damag": 2.7808723068799996, "check": 6.50655737705, "place": 1.1004366812200002, "great": 1.26592775696, "man": 1.7494214875999998, "goal": 3.28152128979, "gaug": 20.538163001300003, "electron": 4.5738980121, "his": 1.0943682360200002, "comment": 3.05954904606, "taken": 1.6012102874399998, "matter": 2.44773358002, "fals": 6.21613155834, "accept": 1.7377408056, "preet": 1443.272727272, "probabl": 5.29111814698, "scientist": 4.69426374926, "machin": 44.267680608359996, "into": 2.03004922958, "bias": 27.4671280276, "appl": 13.6980155306, "strength": 4.02739726027, "through": 2.14149861738, "requir": 1.52844902282, "where": 1.06715063521, "doctor": 11.818362282870002, "contextu": 76.6956521739, "prefer": 3.0216977540900003, "gave": 1.85121268657, "what": 3.7603031738399997, "local": 1.51720183486, "techniqu": 14.917547568720002, "prone": 18.144000000000002, "posterior": 86.28260869569999, "interpret": 22.505467800759995, "flexibl": 9.68639414277, "help": 11.19703782072, "main": 5.01215469612, "larg": 1.18574949585, "abil": 10.83501109024, "manual": 7.72930866602, "conclus": 4.84615384615, "tech": 19.1739130435, "humancomput": 721.636363636, "deiti": 21.2815013405, "base": 2.2925631769, "natur": 1.5392670157100001, "deal": 4.36693714758, "fact": 1.73375559681, "pixellevel": 721.636363636, "driverless": 721.636363636, "decid": 3.8515283842800003, "hot": 4.6178010471199995, "here": 2.42307692308, "ideal": 4.65571847507, "factor": 2.89127663449, "unambigu": 118.0371747212, "black": 7.79668508288, "attent": 8.43122676579, "infer": 42.2796271638, "valu": 2.2777618364400003, "human": 11.37928562898, "liabil": 27.1384615385, "layer": 73.27384615385999, "evalu": 6.9509632224199995, "henc": 10.781663837019998, "similar": 1.37514075357, "about": 3.19458045477, "problem": 1.76674827509, "intuit": 55.4136125654, "communiti": 1.96121062384, "neural": 178.3820224719, "report": 1.3634489866, "insur": 9.36637168142, "context": 4.25972632144, "test": 2.65707112971, "softwar": 41.0497737556, "understand": 20.780104712009997, "unabl": 3.3081892060799998, "watson": 51.2129032257, "treatment": 3.87125091441, "correct": 3.6631287494199998, "him": 1.63434218653, "convey": 12.297443842, "represent": 17.784914115, "would": 4.331491712719999, "weak": 4.70539419087, "visit": 2.20622568093, "blackbox": 1443.272727272, "layerwis": 721.636363636, "serious": 2.583984375, "contribut": 3.8510612492400003, "led": 2.67565517822, "flag": 5.95275590551, "train": 3.8731397901999998, "complex": 7.0206367924499995, "pure": 4.716577540109999, "bake": 41.2363636364, "enabl": 3.5421686747, "them": 2.19752231988, "insight": 23.6074349442, "trust": 34.26827012028, "mitig": 22.8103448276, "explain": 83.21572481568, "giant": 6.23566378633, "stereotyp": 19.3138686131, "blind": 8.849498327760001, "autom": 19.8202247191, "quit": 2.8849718335500003, "abl": 5.46255304506, "mani": 1.04426757877, "refer": 2.6004914005, "over": 3.07575072651, "accur": 23.075581395360004, "often": 2.5890410959, "build": 1.6341739578, "veri": 6.29400570885, "provid": 4.86210856748, "special": 1.4881889763799998, "mine": 9.751842751839998, "multifacet": 162.0, "linear": 13.8776223776, "initi": 1.35, "frog": 99.4321503132, "questionansw": 721.636363636, "show": 1.26703910615, "character": 4.563380281690001, "target": 12.875912408760001, "there": 6.24547600314, "exist": 1.4647107666799999, "connect": 3.7687833827800006, "inform": 1.5753125620200001, "endus": 2164.909090908, "possibl": 2.8347468976, "diagnos": 16.283076923099998, "fulfil": 13.75140753572, "best": 1.5828514456600002, "exampl": 3.00966824644, "technic": 6.280063291139999, "custom": 3.6346153846199996, "knowledg": 3.3981164383599998, "trade": 2.37522441652, "follow": 2.09280253098, "modelagnost": 721.636363636, "further": 1.3618116315, "necess": 12.128342245999999, "hard": 2.73253012048, "thirdwav": 721.636363636, "shouldn": 721.636363636, "high": 6.8866396761, "basic": 2.7301805675, "laymen": 256.06451613, "power": 5.358535144719999, "leverag": 35.7567567568, "issu": 2.87843350558, "also": 2.02953020134, "typic": 2.2541530597799997, "rational": 36.75, "such": 1.06151377374, "revers": 4.29894394801, "task": 11.65924112607, "user": 46.2632345799, "research": 7.768073394480001, "phenomena": 16.5202913632, "signific": 1.4529147982100001, "the": 128.0, "area": 1.3881262568900001, "becom": 1.12492028626, "shook": 44.4705882353, "antehoc": 2886.545454544, "whi": 6.513230769240001, "select": 2.02345144022, "hospit": 6.926701570680001, "promin": 2.39746300211, "want": 1.99698113208, "webbas": 721.636363636, "system": 18.03617932363, "individu": 1.8004082558400003, "act": 1.4318181818200002, "various": 2.6646525679799997, "bio": 42.336000000000006, "work": 4.46080359652, "backward": 14.605335786600001, "could": 3.6131087846999996, "debat": 9.688364523990002, "were": 2.04917715392, "which": 17.088261364999997, "pdfnumpdf": 721.636363636, "intellig": 20.96671949285, "encompass": 8.02628918099, "relev": 34.69405594405001, "activ": 2.92807082258, "gray": 9.020454545449999, "estim": 2.34991119005, "mechan": 6.82985588298, "other": 1.00992366412, "introduct": 2.7808723068799996, "benefici": 18.269275028800003, "one": 4.02509982888, "recreat": 6.536023054759999, "bank": 2.87400434468, "hope": 2.50884955752, "begin": 1.3305397251100002, "see": 3.81726376533, "box": 4.12685209254, "riski": 36.5806451613, "becaus": 1.1495184997499999, "imag": 27.013782542100003, "sourc": 1.69760479042, "academia": 33.4936708861, "loop": 13.5114893617, "get": 1.78562591385, "like": 5.745928338750001, "implement": 3.57648118946, "push": 3.75141776938, "collect": 3.28219971056, "tell": 6.72284564896, "autonom": 11.086592178800002, "detect": 16.23866348448, "part": 4.17322731156, "both": 2.10431440122, "analyt": 34.513043478200004, "despit": 3.21213960546, "rule": 3.4831066257199996, "this": 6.02276176026, "choic": 6.263957388040001, "principl": 3.4520547945199995, "rang": 1.7848229342299997, "should": 11.650277806930001, "time": 2.02254920696, "step": 2.8279301745599996, "leav": 3.3230769230799995, "back": 1.26070038911, "chang": 3.5426956263, "busi": 2.05541170378, "project": 3.5069582505000003, "differ": 3.7096347067499997, "healthcar": 18.7659574468, "institut": 3.5584444693400004, "face": 3.6065424807, "forget": 16.9978586724, "aienabl": 721.636363636, "between": 7.241756809559999, "low": 2.13072070863, "player": 3.54375, "multimod": 256.064516129, "domain": 28.182248520719998, "who": 1.06279287723, "fail": 1.9281029876099998, "along": 1.2973768080399999, "all": 1.01146788991, "input": 61.0146041505, "action": 1.81855670103, "program": 6.06417112299, "divis": 2.32854209446, "combat": 5.01294600568, "feat": 17.070967741900002, "case": 7.4249368628, "european": 1.96290801187, "normal": 2.61075481006, "weight": 14.636754763379997, "architectur": 5.12790697674, "tradeoff": 835.5789473680001, "object": 4.697736351540001, "futur": 1.8577112099200002, "improv": 2.04376930999, "while": 1.0441988950299999, "interfac": 20.9169960474, "these": 5.3707713126000005, "compact": 12.451764705899999, "artifici": 41.58198009430001, "made": 5.35194174755, "entail": 21.2530120482, "befor": 1.10036041031, "librari": 2.68266306185, "probabilist": 127.008, "gorilla": 81.4153846154, "close": 1.2848818387799998, "affect": 4.958925503680001, "can": 18.82018226272, "dumb": 66.15, "process": 8.4762413241, "weigh": 10.9944598338, "describ": 1.47027227264, "make": 11.838926174460001, "civilian": 5.55104895105, "onli": 2.0512953033200003, "each": 4.75899280576, "throw": 8.39555790587, "ethic": 17.87837837838, "distinguish": 3.36926994907, "foster": 7.353404353869999, "industri": 2.02319357716, "necessari": 2.8421052631599997, "jeopardi": 77.443902439, "rise": 2.02940048575, "inculc": 162.0, "advanc": 3.9994961582, "imposs": 4.96125, "data": 37.14079115274, "lightweight": 32.4, "oper": 1.55479384977, "their": 8.1238326724, "method": 15.428571428580002, "behind": 6.253676470589999, "whether": 8.82735613012, "phase": 4.3012733676499995, "ultim": 2.58524670249, "inc": 18.5250875146, "come": 3.9849397590299995, "might": 2.1561863370900003, "aspect": 6.1786339754799995, "identifi": 6.90561113529, "modul": 16.9434364995, "direct": 1.22226499346, "import": 2.6803984467400004, "decis": 47.52, "acquaint": 16.503118503099998, "extent": 4.09491875161, "have": 15.223422617099997, "score": 8.576985413300001, "georgiatech": 721.636363636, "incomprehens": 91.76878612719999, "year": 1.0485436893200002, "collater": 71.5135135135, "gandhi": 77.82352941180001, "effici": 10.18671799808, "down": 1.35889754344, "learn": 27.873006583800002, "own": 1.17844418052, "when": 9.186909277949999, "hierarch": 30.24}, "logtfidf": {"after": 0.020490694648099998, "strike": 1.27033264096, "real": 0.824629060574, "failur": 1.18954807429, "audit": 2.71601837075, "awar": 1.45323772, "then": 0.24910159569269996, "relat": 0.42620060330799997, "analyst": 5.394299772899999, "stage": 0.733900940237, "troubl": 1.60761292215, "label": 1.49898832727, "red": 0.798535691347, "opaqu": 4.33022956194, "kind": 0.948031302717, "space": 0.874713164972, "topic": 5.09099746623, "googl": 7.29789366774, "miser": 3.65884865786, "propon": 2.50167533539, "been": 0.04729196473680001, "etc": 2.8733461759400005, "four": 0.190213538869, "function": 3.657862966376, "class": 2.2493165697990003, "intent": 2.32237501562, "logic": 2.18931939783, "weapon": 1.51978976116, "era": 0.943652088842, "three": 0.06411868822490001, "thought": 0.685867118283, "whom": 0.8343021310169999, "well": 0.1905433149468, "behav": 2.7499199224299997, "tri": 1.23518305832, "tree": 4.25332466325, "nontarget": 6.58152136054, "complet": 0.215285242047, "approach": 3.6511680729050005, "diagnosi": 3.3608290047500002, "toward": 1.4663183314800001, "know": 0.952919694398, "most": 0.020747896295599998, "anintroductiontoexplainableaiandwhyweneeditanumddnum": 6.58152136054, "regul": 2.7154632692400003, "motiv": 1.61265547932, "applic": 6.15801964245, "uncertain": 2.3850031735900004, "legal": 2.866609921824, "won": 0.8404139079, "translat": 1.0499301100299998, "magic": 2.06766933309, "overlap": 2.4924939396, "defens": 1.16038316431, "room": 1.12387195543, "verifi": 2.65505767096, "how": 4.244102612370001, "billion": 1.5824680307199999, "inexplic": 4.49641408133, "upon": 0.9441435559639999, "transpar": 5.52961706984, "origin": 0.257224875174, "had": 0.0464780244111, "increas": 0.555641437858, "especi": 0.511098609709, "expert": 1.68029517063, "distribut": 6.04687834878, "due": 0.8536485754559999, "end": 0.101476798618, "found": 0.107841124048, "given": 0.303255810831, "form": 0.120053184191, "driven": 1.72311939365, "deep": 9.0207142886, "depend": 1.61393963, "will": 0.6083596047450001, "conserv": 1.19994966588, "scenario": 2.73427932989, "toolkit": 5.24174701506, "open": 0.219591038029, "propag": 2.93441131931, "wide": 0.44458000675399995, "incorpor": 1.9328090459479998, "neuron": 20.815877386350003, "claim": 0.423291231925, "perform": 0.85236170116, "but": 0.161923720719, "success": 0.27765441259199997, "surround": 0.915723999073, "need": 0.725480326884, "furthest": 4.44145519705, "classif": 6.263372208870001, "output": 8.15290631308, "sure": 2.0086865552, "final": 0.585467727896, "expect": 0.78850775216, "parti": 1.448995420888, "key": 0.82419811896, "killer": 2.63290346404, "lead": 0.9448161194679999, "level": 0.503462189943, "robot": 2.99674059227, "has": 0.1281718345644, "generat": 0.719182341736, "collabor": 2.9878500506200005, "use": 0.3212882170476, "experi": 0.626272953933, "govern": 0.411720459754, "resourc": 1.08137694258, "onlin": 0.957503854357, "out": 0.0584263909193, "mistak": 2.1648737360799997, "model": 20.648602047108003, "oncolog": 5.0673936279100005, "good": 0.418589404907, "alway": 0.726319204572, "concept": 0.977224437103, "much": 0.35499145860200004, "opt": 2.54326626497, "optim": 4.891255590819999, "field": 1.7281927750530002, "reason": 4.354412423696, "percent": 1.3616570567299997, "not": 0.12441930406, "proof": 2.27255429674, "overrid": 3.55007100439, "uncertainti": 2.7768811161599998, "redistribut": 7.082674648839999, "perturb": 12.94793261769, "difficult": 2.736332302764, "less": 0.7692289252, "agreement": 1.10677095265, "aim": 2.12667707408, "garner": 2.53290347794, "specif": 0.626980167541, "deepmind": 6.58152136054, "lethal": 6.57473882982, "whole": 0.8306818244059999, "fidel": 3.28232314684, "complic": 5.193804729, "bayesian": 10.36785488834, "they": 0.2675429529084, "design": 0.377239118022, "consult": 1.6519646640099999, "cancer": 6.242106297029999, "allow": 0.24028061118900002, "world": 0.214840497242, "scienc": 3.365744715564, "outcom": 2.01339244624, "pixel": 4.45762805629, "posthoc": 26.32608544216, "larger": 0.806828661778, "student": 0.904923236645, "behavior": 1.71014813378, "featur": 3.387099345136, "feed": 2.05136865109, "practic": 0.533182530867, "lack": 1.312101877814, "simpl": 3.66966386817, "influenc": 0.572373185428, "that": 0.06361837407424, "whose": 0.5510546556329999, "algorithm": 33.3044239518, "albeit": 2.4134476858099996, "offer": 0.431112446902, "mind": 1.2786688388299998, "either": 0.459327638815, "accord": 0.243650319127, "develop": 0.535874084739, "moreov": 4.04574238038, "observ": 0.7995160149320001, "accuraci": 7.6394296218, "agre": 1.603520739842, "with": 0.01556739227407, "more": 0.08512465799999999, "network": 2.8592491591559996, "deriv": 1.02381618275, "lot": 2.9671939005000003, "eras": 3.4245209393900002, "racism": 3.07678329994, "small": 0.614203610118, "control": 0.38498466158600003, "invest": 1.42586787018, "may": 0.3042599717064, "twolevel": 6.58152136054, "privaci": 3.34284290838, "concern": 1.902239846619, "off": 0.41352852038800003, "beat": 1.6007206642899998, "easili": 1.3066587367, "without": 0.517749035882, "protect": 0.67529290767, "set": 0.857480056445, "caus": 0.651717134812, "ani": 0.125608358366, "two": 0.041096533074600004, "drone": 3.96878133925, "and": 0.0034014676714344, "from": 0.001134108337732, "account": 1.330148579946, "answer": 3.0732620838, "limit": 0.41782385463, "patient": 4.51237066942, "detail": 0.816187777173, "num": 0.0031499039539700006, "technolog": 0.956847686355, "depart": 2.0666193977100002, "market": 0.8612095839370001, "aren": 6.17605625244, "balanc": 1.4936444810499998, "for": 0.007244779094131001, "car": 1.2634013667, "predict": 8.22870118845, "friend": 0.7893395836239999, "militari": 2.270186219181, "unlik": 0.885954358842, "new": 0.0354598937022, "are": 0.5304145244886, "simpli": 0.923941491586, "controversi": 0.9652462536299999, "explan": 14.98576332552, "compani": 0.879554506194, "result": 0.545515633524, "current": 0.42695282784500005, "lnum": 3.98558845756, "attachmentsxaiprogramupdatepdf": 6.58152136054, "usher": 3.1446058962800003, "sent": 0.844509277088, "path": 1.5351679838499999, "chanc": 1.44572292349, "extract": 4.08323446602, "intern": 0.530190755632, "restor": 1.09033222631, "harder": 2.84061024834, "think": 1.06717661175, "tend": 1.21597024462, "combin": 0.529218310751, "focus": 0.6981989720559999, "educ": 0.696807183384, "legitim": 2.2149545241900004, "general": 0.344857734189, "map": 1.40434493384, "doe": 0.5340417297169999, "even": 0.45716569450200006, "ongo": 1.79934675904, "littl": 0.438213989466, "give": 0.622785104448, "dod": 4.47406678264, "simpler": 2.8858468633, "photo": 1.8593765463799998, "proper": 1.2056118389200001, "damag": 1.02276465794, "check": 1.87281049562, "place": 0.0957070839572, "great": 0.235805258079, "man": 0.55928515477, "goal": 1.18830712273, "gaug": 3.0222847653200002, "electron": 1.5203657980399998, "his": 0.0901772433641, "comment": 1.11826753454, "taken": 0.470759772949, "matter": 0.8951625270360001, "fals": 1.8271477773099998, "accept": 0.552585882007, "preet": 13.16304272108, "probabl": 1.945764825826, "scientist": 1.54634128444, "machin": 15.31595538682, "into": 0.0298257264574, "bias": 5.23968552934, "appl": 2.61725097056, "strength": 1.3931203261899998, "through": 0.1367173837698, "requir": 0.424253510675, "where": 0.0649921387457, "doctor": 4.11312647688, "contextu": 4.33984502064, "prefer": 1.10581884366, "gave": 0.615840930592, "what": 0.677661890481, "local": 0.416867740206, "techniqu": 5.26497539228, "prone": 2.89833992755, "posterior": 4.45762805629, "interpret": 8.174937008, "flexibl": 2.2707222351599996, "help": 2.689661770752, "main": 0.902286162352, "larg": 0.17037506060600002, "abil": 3.985953189708, "manual": 2.04501942341, "conclus": 1.57818536893, "tech": 2.9535506595200003, "humancomput": 6.58152136054, "deiti": 3.0578382137, "base": 0.27304660457400004, "natur": 0.431306339292, "deal": 1.561829402506, "fact": 0.5502899207949999, "pixellevel": 6.58152136054, "driverless": 6.58152136054, "decid": 1.310645743786, "hot": 1.52991862796, "here": 0.8850381883700001, "ideal": 1.53809624363, "factor": 1.06169814662, "unambigu": 8.1557048686, "black": 2.669617171468, "attent": 3.09998998974, "infer": 6.102316324279999, "valu": 0.823193310148, "human": 3.840211099458, "liabil": 3.30095196667, "layer": 18.87281246115, "evalu": 1.9388802431299998, "henc": 3.36939943564, "similar": 0.318556092114, "about": 0.18853043242380002, "problem": 0.569140724273, "intuit": 6.643356194380001, "communiti": 0.673561947791, "neural": 12.2559454665, "report": 0.31001750903700004, "insur": 2.2371257940900002, "context": 1.44920491442, "test": 0.977224437103, "softwar": 9.31396385332, "understand": 7.6166011297599985, "unabl": 1.19640097204, "watson": 8.512137683279999, "treatment": 1.3535776885100002, "correct": 1.29831763181, "him": 0.49124039099699995, "convey": 2.50939142306, "represent": 5.33921486295, "would": 0.3184705118588, "weak": 1.5487095508000002, "visit": 0.791283218833, "blackbox": 13.16304272108, "layerwis": 6.58152136054, "serious": 0.949332539075, "contribut": 1.310403157818, "led": 0.5820941924759999, "flag": 1.78385428972, "train": 1.321836625678, "complex": 2.5507249092929998, "pure": 1.55108343915, "bake": 3.7193204796199995, "enabl": 1.26473915954, "them": 0.1883666538186, "insight": 4.93682904374, "trust": 11.118167953199999, "mitig": 3.1272141535699998, "explain": 30.582413675456, "giant": 1.83028503479, "stereotyp": 2.96082341885, "blind": 2.1803607712799997, "autom": 2.9867028668299995, "quit": 1.05951513684, "abl": 1.7979119474250003, "mani": 0.0433157581221, "refer": 0.525106493596, "over": 0.0748101644871, "accur": 7.0099224594, "often": 0.516280786702, "build": 0.491137452091, "veri": 1.15079896619, "provid": 0.7807113773000001, "special": 0.39755992860100003, "mine": 3.16861817356, "multifacet": 5.08759633523, "linear": 2.63027764196, "initi": 0.30010459245, "frog": 10.50258964947, "questionansw": 6.58152136054, "show": 0.236682766013, "character": 1.51806363875, "target": 4.676255798480001, "there": 0.24058735755299998, "exist": 0.38165779408699996, "connect": 1.267210117364, "inform": 0.454453704662, "endus": 19.74456408162, "possibl": 0.697610949782, "diagnos": 2.7901263429100003, "fulfil": 3.8559880091000003, "best": 0.459227932947, "exampl": 0.8173653499979999, "technic": 2.28846575616, "custom": 1.2905032964799998, "knowledg": 1.2232212893899999, "trade": 0.865091924188, "follow": 0.09071382218839999, "modelagnost": 6.58152136054, "further": 0.308815895297, "necess": 2.4955450479900003, "hard": 1.00522796406, "thirdwav": 6.58152136054, "shouldn": 6.58152136054, "high": 0.8269427192400001, "basic": 1.00436774895, "laymen": 9.7045644966, "power": 1.16958513086, "leverag": 3.5767392514699994, "issu": 0.728198087868, "also": 0.0293143156, "typic": 0.812774319158, "rational": 3.60413822566, "such": 0.059695977806, "revers": 1.45836939905, "task": 4.0724604198300005, "user": 12.255528641279998, "research": 2.654911272552, "phenomena": 2.8045894049299998, "signific": 0.373571744332, "the": 0.0, "area": 0.327954821122, "becom": 0.11771217648900001, "shook": 3.7948280321199994, "antehoc": 26.32608544216, "whi": 2.36137686094, "select": 0.704804687133, "hospit": 2.48447311102, "promin": 0.8744110957960001, "want": 0.6916366062549999, "webbas": 6.58152136054, "system": 4.256594492605, "individu": 0.588013447985, "act": 0.358945092473, "various": 0.57385300014, "bio": 3.7456377879300002, "work": 0.436138269092, "backward": 2.68138692678, "could": 0.5578688168700001, "debat": 3.5169400296600006, "were": 0.048582287362199994, "which": 0.08803303537231, "pdfnumpdf": 6.58152136054, "intellig": 7.16749241065, "encompass": 2.08272230172, "relev": 9.685652306999998, "activ": 0.762393206568, "gray": 2.19949472587, "estim": 0.854377535975, "mechan": 2.45631278442, "other": 0.00987474791976, "introduct": 1.02276465794, "benefici": 2.90522068864, "one": 0.025021406582, "recreat": 1.8773288849, "bank": 1.0557062993700002, "hope": 0.919824304455, "begin": 0.285584668268, "see": 0.722764756476, "box": 1.41751491115, "riski": 3.5995192798, "becaus": 0.139343158825, "imag": 9.9376210729, "sourc": 0.529218310751, "academia": 3.5113564922099996, "loop": 2.60354038732, "get": 0.579769005782, "like": 0.6952678827250001, "implement": 1.27437940907, "push": 1.32213384036, "collect": 0.99073332104, "tell": 2.42472868802, "autonom": 2.4057364663799996, "detect": 5.0663482347899995, "part": 0.16958124393120003, "both": 0.10168506677860001, "analyt": 5.696380287719999, "despit": 0.947580156596, "rule": 1.109554847074, "this": 0.022718694315, "choic": 2.28332995086, "principl": 1.2389696463600002, "rang": 0.579319213803, "should": 3.5659391373060005, "time": 0.0224230377252, "step": 1.03954505698, "leav": 1.015487914458, "back": 0.23166743089699998, "chang": 0.49882687517400004, "busi": 0.720476170355, "project": 1.123203771814, "differ": 0.6369633639360001, "healthcar": 2.9320444543, "institut": 1.152352644006, "face": 1.179204742514, "forget": 2.8330873756700004, "aienabl": 6.58152136054, "between": 0.23767576815709995, "low": 0.7564602833490001, "player": 1.26518548849, "multimod": 5.54542942886, "domain": 6.720240017969999, "who": 0.0609002329859, "fail": 0.656536611573, "along": 0.260344385917, "all": 0.011402632097799998, "input": 12.50837667695, "action": 0.598043165069, "program": 2.111356736295, "divis": 0.845242361205, "combat": 1.61202376736, "feat": 2.8373792277599996, "case": 1.9770313444449998, "european": 0.674427053203, "normal": 0.959639378783, "weight": 4.7547705783600005, "architectur": 1.63469757919, "tradeoff": 21.36732189448, "object": 1.707867169606, "futur": 0.619345197699, "improv": 0.7147958039319999, "while": 0.04324998379380001, "interfac": 3.0405620365099995, "these": 0.357668097004, "compact": 2.5218623563099998, "artifici": 10.5911449509, "made": 0.3401076304865, "entail": 3.0564986287700004, "befor": 0.0956377718795, "librari": 0.986809980943, "probabilist": 4.8442500766, "gorilla": 4.3995642553400005, "close": 0.250666759864, "affect": 1.816083808768, "can": 2.597457542304, "dumb": 4.19192489056, "process": 2.6391459951250003, "weigh": 2.39739149445, "describ": 0.385447603125, "make": 0.8084742360518999, "civilian": 1.71398691009, "onli": 0.050648536658199995, "each": 0.694966757216, "throw": 2.12770274524, "ethic": 4.3808897807, "distinguish": 1.21469608857, "foster": 1.9951633833900002, "industri": 0.7046772417749999, "necessari": 1.0445450673999999, "jeopardi": 4.34955383476, "rise": 0.707740422218, "inculc": 5.08759633523, "advanc": 1.3860424243560001, "imposs": 1.60165772512, "data": 13.3850264328, "lightweight": 3.4781584227999995, "oper": 0.441342964347, "their": 0.12288404098160001, "method": 5.666769653046, "behind": 2.2036717122960003, "whether": 3.166244758588, "phase": 1.4589111108700001, "ultim": 0.9498209395739999, "inc": 2.9191258953099997, "come": 0.8517297195900001, "might": 0.7683410765340001, "aspect": 2.25590005382, "identifi": 2.5011660014159998, "modul": 2.82988053166, "direct": 0.200705689496, "import": 0.585636554132, "decis": 16.942380877311997, "acquaint": 2.80354936324, "extent": 1.40974687623, "have": 0.221775035118, "score": 2.9118706415400006, "georgiatech": 6.58152136054, "incomprehens": 4.5192722194099995, "year": 0.047402238894600005, "collater": 4.26988643203, "gandhi": 7.3225932789999995, "effici": 3.25587506828, "down": 0.306673741186, "learn": 10.11302477694, "own": 0.164195077421, "when": 0.18499489972560001, "hierarch": 3.4091655513099997}, "logidf": {"after": 0.020490694648099998, "strike": 1.27033264096, "real": 0.824629060574, "failur": 1.18954807429, "audit": 2.71601837075, "awar": 1.45323772, "then": 0.08303386523089999, "relat": 0.21310030165399999, "analyst": 2.6971498864499996, "stage": 0.733900940237, "troubl": 1.60761292215, "label": 1.49898832727, "red": 0.798535691347, "opaqu": 4.33022956194, "kind": 0.948031302717, "space": 0.874713164972, "topic": 1.6969991554100001, "googl": 2.43263122258, "miser": 3.65884865786, "propon": 2.50167533539, "been": 0.023645982368400004, "etc": 1.4366730879700003, "four": 0.190213538869, "function": 0.914465741594, "class": 0.7497721899330001, "intent": 1.16118750781, "logic": 2.18931939783, "weapon": 1.51978976116, "era": 0.943652088842, "three": 0.06411868822490001, "thought": 0.685867118283, "whom": 0.8343021310169999, "well": 0.0635144383156, "behav": 2.7499199224299997, "tri": 0.61759152916, "tree": 1.41777488775, "nontarget": 6.58152136054, "complet": 0.215285242047, "approach": 0.7302336145810001, "diagnosi": 3.3608290047500002, "toward": 0.48877277716000006, "know": 0.952919694398, "most": 0.020747896295599998, "anintroductiontoexplainableaiandwhyweneeditanumddnum": 6.58152136054, "regul": 1.3577316346200001, "motiv": 1.61265547932, "applic": 1.23160392849, "uncertain": 2.3850031735900004, "legal": 0.955536640608, "won": 0.8404139079, "translat": 1.0499301100299998, "magic": 2.06766933309, "overlap": 2.4924939396, "defens": 1.16038316431, "room": 1.12387195543, "verifi": 2.65505767096, "how": 0.47156695693000006, "billion": 1.5824680307199999, "inexplic": 4.49641408133, "upon": 0.47207177798199995, "transpar": 2.76480853492, "origin": 0.128612437587, "had": 0.0464780244111, "increas": 0.277820718929, "especi": 0.511098609709, "expert": 1.68029517063, "distribut": 1.00781305813, "due": 0.21341214386399998, "end": 0.101476798618, "found": 0.107841124048, "given": 0.303255810831, "form": 0.120053184191, "driven": 1.72311939365, "deep": 1.2886734698, "depend": 0.806969815, "will": 0.202786534915, "conserv": 1.19994966588, "scenario": 2.73427932989, "toolkit": 5.24174701506, "open": 0.219591038029, "propag": 2.93441131931, "wide": 0.44458000675399995, "incorpor": 0.9664045229739999, "neuron": 4.16317547727, "claim": 0.423291231925, "perform": 0.42618085058, "but": 0.0161923720719, "success": 0.27765441259199997, "surround": 0.915723999073, "need": 0.362740163442, "furthest": 4.44145519705, "classif": 2.08779073629, "output": 2.03822657827, "sure": 2.0086865552, "final": 0.292733863948, "expect": 0.78850775216, "parti": 0.724497710444, "key": 0.82419811896, "killer": 2.63290346404, "lead": 0.23620402986699998, "level": 0.503462189943, "robot": 2.99674059227, "has": 0.0427239448548, "generat": 0.719182341736, "collabor": 1.4939250253100003, "use": 0.0292080197316, "experi": 0.626272953933, "govern": 0.411720459754, "resourc": 1.08137694258, "onlin": 0.957503854357, "out": 0.0584263909193, "mistak": 2.1648737360799997, "model": 0.7374500731110001, "oncolog": 5.0673936279100005, "good": 0.418589404907, "alway": 0.726319204572, "concept": 0.977224437103, "much": 0.17749572930100002, "opt": 2.54326626497, "optim": 2.4456277954099996, "field": 0.5760642583510001, "reason": 0.544301552962, "percent": 1.3616570567299997, "not": 0.0155524130075, "proof": 2.27255429674, "overrid": 3.55007100439, "uncertainti": 2.7768811161599998, "redistribut": 3.5413373244199997, "perturb": 4.31597753923, "difficult": 0.912110767588, "less": 0.3846144626, "agreement": 1.10677095265, "aim": 1.06333853704, "garner": 2.53290347794, "specif": 0.626980167541, "deepmind": 6.58152136054, "lethal": 3.28736941491, "whole": 0.8306818244059999, "fidel": 3.28232314684, "complic": 1.7312682430000002, "bayesian": 5.18392744417, "they": 0.0297269947676, "design": 0.377239118022, "consult": 1.6519646640099999, "cancer": 2.08070209901, "allow": 0.24028061118900002, "world": 0.107420248621, "scienc": 0.841436178891, "outcom": 2.01339244624, "pixel": 4.45762805629, "posthoc": 6.58152136054, "larger": 0.806828661778, "student": 0.904923236645, "behavior": 1.71014813378, "featur": 0.423387418142, "feed": 2.05136865109, "practic": 0.533182530867, "lack": 0.656050938907, "simpl": 1.2232212893899999, "influenc": 0.572373185428, "that": 0.00397614837964, "whose": 0.5510546556329999, "algorithm": 3.33044239518, "albeit": 2.4134476858099996, "offer": 0.431112446902, "mind": 1.2786688388299998, "either": 0.459327638815, "accord": 0.243650319127, "develop": 0.178624694913, "moreov": 2.02287119019, "observ": 0.7995160149320001, "accuraci": 2.5464765406, "agre": 0.801760369921, "with": 0.00119749171339, "more": 0.017024931599999998, "network": 0.9530830530519999, "deriv": 1.02381618275, "lot": 1.4835969502500002, "eras": 3.4245209393900002, "racism": 3.07678329994, "small": 0.307101805059, "control": 0.38498466158600003, "invest": 1.42586787018, "may": 0.050709995284400004, "twolevel": 6.58152136054, "privaci": 3.34284290838, "concern": 0.634079948873, "off": 0.41352852038800003, "beat": 1.6007206642899998, "easili": 1.3066587367, "without": 0.258874517941, "protect": 0.67529290767, "set": 0.171496011289, "caus": 0.325858567406, "ani": 0.125608358366, "two": 0.0136988443582, "drone": 3.96878133925, "and": 6.29901420636e-05, "from": 0.000567054168866, "account": 0.665074289973, "answer": 1.5366310419, "limit": 0.41782385463, "patient": 2.25618533471, "detail": 0.816187777173, "num": 0.00031499039539700004, "technolog": 0.956847686355, "depart": 0.68887313257, "market": 0.8612095839370001, "aren": 6.17605625244, "balanc": 1.4936444810499998, "for": 0.00031499039539700004, "car": 1.2634013667, "predict": 1.6457402376899999, "friend": 0.7893395836239999, "militari": 0.7567287397269999, "unlik": 0.885954358842, "new": 0.0177299468511, "are": 0.0294674735827, "simpli": 0.923941491586, "controversi": 0.9652462536299999, "explan": 1.87322041569, "compani": 0.439777253097, "result": 0.136378908381, "current": 0.42695282784500005, "lnum": 3.98558845756, "attachmentsxaiprogramupdatepdf": 6.58152136054, "usher": 3.1446058962800003, "sent": 0.844509277088, "path": 1.5351679838499999, "chanc": 1.44572292349, "extract": 2.04161723301, "intern": 0.265095377816, "restor": 1.09033222631, "harder": 2.84061024834, "think": 1.06717661175, "tend": 1.21597024462, "combin": 0.529218310751, "focus": 0.6981989720559999, "educ": 0.696807183384, "legitim": 2.2149545241900004, "general": 0.114952578063, "map": 1.40434493384, "doe": 0.5340417297169999, "even": 0.152388564834, "ongo": 1.79934675904, "littl": 0.438213989466, "give": 0.311392552224, "dod": 4.47406678264, "simpler": 2.8858468633, "photo": 1.8593765463799998, "proper": 1.2056118389200001, "damag": 1.02276465794, "check": 1.87281049562, "place": 0.0957070839572, "great": 0.235805258079, "man": 0.55928515477, "goal": 1.18830712273, "gaug": 3.0222847653200002, "electron": 1.5203657980399998, "his": 0.0901772433641, "comment": 1.11826753454, "taken": 0.470759772949, "matter": 0.8951625270360001, "fals": 1.8271477773099998, "accept": 0.552585882007, "preet": 6.58152136054, "probabl": 0.972882412913, "scientist": 1.54634128444, "machin": 1.39235958062, "into": 0.0149128632287, "bias": 2.61984276467, "appl": 2.61725097056, "strength": 1.3931203261899998, "through": 0.0683586918849, "requir": 0.424253510675, "where": 0.0649921387457, "doctor": 1.37104215896, "contextu": 4.33984502064, "prefer": 1.10581884366, "gave": 0.615840930592, "what": 0.225887296827, "local": 0.416867740206, "techniqu": 1.31624384807, "prone": 2.89833992755, "posterior": 4.45762805629, "interpret": 1.1678481440000001, "flexibl": 2.2707222351599996, "help": 0.336207721344, "main": 0.225571540588, "larg": 0.17037506060600002, "abil": 0.996488297427, "manual": 2.04501942341, "conclus": 1.57818536893, "tech": 2.9535506595200003, "humancomput": 6.58152136054, "deiti": 3.0578382137, "base": 0.13652330228700002, "natur": 0.431306339292, "deal": 0.780914701253, "fact": 0.5502899207949999, "pixellevel": 6.58152136054, "driverless": 6.58152136054, "decid": 0.655322871893, "hot": 1.52991862796, "here": 0.8850381883700001, "ideal": 1.53809624363, "factor": 1.06169814662, "unambigu": 4.0778524343, "black": 0.667404292867, "attent": 1.03332999658, "infer": 3.0511581621399997, "valu": 0.823193310148, "human": 0.640035183243, "liabil": 3.30095196667, "layer": 2.0969791623500003, "evalu": 1.9388802431299998, "henc": 1.68469971782, "similar": 0.318556092114, "about": 0.0628434774746, "problem": 0.569140724273, "intuit": 3.3216780971900004, "communiti": 0.673561947791, "neural": 4.0853151555, "report": 0.31001750903700004, "insur": 2.2371257940900002, "context": 1.44920491442, "test": 0.977224437103, "softwar": 2.32849096333, "understand": 1.0880858756799998, "unabl": 1.19640097204, "watson": 2.8373792277599996, "treatment": 1.3535776885100002, "correct": 1.29831763181, "him": 0.49124039099699995, "convey": 2.50939142306, "represent": 1.7797382876499999, "would": 0.0796176279647, "weak": 1.5487095508000002, "visit": 0.791283218833, "blackbox": 6.58152136054, "layerwis": 6.58152136054, "serious": 0.949332539075, "contribut": 0.655201578909, "led": 0.29104709623799996, "flag": 1.78385428972, "train": 0.660918312839, "complex": 0.8502416364309999, "pure": 1.55108343915, "bake": 3.7193204796199995, "enabl": 1.26473915954, "them": 0.0941833269093, "insight": 2.46841452187, "trust": 1.5883097076, "mitig": 3.1272141535699998, "explain": 0.955700427358, "giant": 1.83028503479, "stereotyp": 2.96082341885, "blind": 2.1803607712799997, "autom": 2.9867028668299995, "quit": 1.05951513684, "abl": 0.599303982475, "mani": 0.0433157581221, "refer": 0.262553246798, "over": 0.0249367214957, "accur": 1.75248061485, "often": 0.258140393351, "build": 0.491137452091, "veri": 0.230159793238, "provid": 0.19517784432500002, "special": 0.39755992860100003, "mine": 1.58430908678, "multifacet": 5.08759633523, "linear": 2.63027764196, "initi": 0.30010459245, "frog": 3.50086321649, "questionansw": 6.58152136054, "show": 0.236682766013, "character": 1.51806363875, "target": 1.1690639496200002, "there": 0.0400978929255, "exist": 0.38165779408699996, "connect": 0.633605058682, "inform": 0.454453704662, "endus": 6.58152136054, "possibl": 0.348805474891, "diagnos": 2.7901263429100003, "fulfil": 1.9279940045500001, "best": 0.459227932947, "exampl": 0.40868267499899996, "technic": 1.14423287808, "custom": 1.2905032964799998, "knowledg": 1.2232212893899999, "trade": 0.865091924188, "follow": 0.045356911094199995, "modelagnost": 6.58152136054, "further": 0.308815895297, "necess": 2.4955450479900003, "hard": 1.00522796406, "thirdwav": 6.58152136054, "shouldn": 6.58152136054, "high": 0.13782378654000002, "basic": 1.00436774895, "laymen": 4.8522822483, "power": 0.292396282715, "leverag": 3.5767392514699994, "issu": 0.364099043934, "also": 0.0146571578, "typic": 0.812774319158, "rational": 3.60413822566, "such": 0.059695977806, "revers": 1.45836939905, "task": 1.35748680661, "user": 2.04258810688, "research": 0.663727818138, "phenomena": 2.8045894049299998, "signific": 0.373571744332, "the": 0.0, "area": 0.327954821122, "becom": 0.11771217648900001, "shook": 3.7948280321199994, "antehoc": 6.58152136054, "whi": 1.18068843047, "select": 0.704804687133, "hospit": 1.24223655551, "promin": 0.8744110957960001, "want": 0.6916366062549999, "webbas": 6.58152136054, "system": 0.327430345585, "individu": 0.588013447985, "act": 0.358945092473, "various": 0.28692650007, "bio": 3.7456377879300002, "work": 0.109034567273, "backward": 2.68138692678, "could": 0.18595627229000003, "debat": 1.1723133432200001, "were": 0.024291143681099997, "which": 0.00517841384543, "pdfnumpdf": 6.58152136054, "intellig": 1.43349848213, "encompass": 2.08272230172, "relev": 1.9371304613999998, "activ": 0.381196603284, "gray": 2.19949472587, "estim": 0.854377535975, "mechan": 1.22815639221, "other": 0.00987474791976, "introduct": 1.02276465794, "benefici": 2.90522068864, "one": 0.0062553516455, "recreat": 1.8773288849, "bank": 1.0557062993700002, "hope": 0.919824304455, "begin": 0.285584668268, "see": 0.240921585492, "box": 1.41751491115, "riski": 3.5995192798, "becaus": 0.139343158825, "imag": 0.99376210729, "sourc": 0.529218310751, "academia": 3.5113564922099996, "loop": 2.60354038732, "get": 0.579769005782, "like": 0.139053576545, "implement": 1.27437940907, "push": 1.32213384036, "collect": 0.49536666052, "tell": 1.21236434401, "autonom": 2.4057364663799996, "detect": 1.68878274493, "part": 0.04239531098280001, "both": 0.050842533389300004, "analyt": 2.8481901438599997, "despit": 0.473790078298, "rule": 0.554777423537, "this": 0.0037864490525, "choic": 1.14166497543, "principl": 1.2389696463600002, "rang": 0.579319213803, "should": 0.509419876758, "time": 0.0112115188626, "step": 1.03954505698, "leav": 0.507743957229, "back": 0.23166743089699998, "chang": 0.166275625058, "busi": 0.720476170355, "project": 0.561601885907, "differ": 0.212321121312, "healthcar": 2.9320444543, "institut": 0.576176322003, "face": 0.589602371257, "forget": 2.8330873756700004, "aienabl": 6.58152136054, "between": 0.033953681165299995, "low": 0.7564602833490001, "player": 1.26518548849, "multimod": 5.54542942886, "domain": 2.24008000599, "who": 0.0609002329859, "fail": 0.656536611573, "along": 0.260344385917, "all": 0.011402632097799998, "input": 2.50167533539, "action": 0.598043165069, "program": 0.7037855787649999, "divis": 0.845242361205, "combat": 1.61202376736, "feat": 2.8373792277599996, "case": 0.395406268889, "european": 0.674427053203, "normal": 0.959639378783, "weight": 1.58492352612, "architectur": 1.63469757919, "tradeoff": 5.34183047362, "object": 0.853933584803, "futur": 0.619345197699, "improv": 0.7147958039319999, "while": 0.04324998379380001, "interfac": 3.0405620365099995, "these": 0.0715336194008, "compact": 2.5218623563099998, "artifici": 2.11822899018, "made": 0.0680215260973, "entail": 3.0564986287700004, "befor": 0.0956377718795, "librari": 0.986809980943, "probabilist": 4.8442500766, "gorilla": 4.3995642553400005, "close": 0.250666759864, "affect": 0.908041904384, "can": 0.162341096394, "dumb": 4.19192489056, "process": 0.527829199025, "weigh": 2.39739149445, "describ": 0.385447603125, "make": 0.07349765782289999, "civilian": 1.71398691009, "onli": 0.025324268329099998, "each": 0.173741689304, "throw": 2.12770274524, "ethic": 2.19044489035, "distinguish": 1.21469608857, "foster": 1.9951633833900002, "industri": 0.7046772417749999, "necessari": 1.0445450673999999, "jeopardi": 4.34955383476, "rise": 0.707740422218, "inculc": 5.08759633523, "advanc": 0.6930212121780001, "imposs": 1.60165772512, "data": 1.2168205848, "lightweight": 3.4781584227999995, "oper": 0.441342964347, "their": 0.015360505122700001, "method": 0.944461608841, "behind": 0.7345572374320001, "whether": 0.791561189647, "phase": 1.4589111108700001, "ultim": 0.9498209395739999, "inc": 2.9191258953099997, "come": 0.28390990653000003, "might": 0.7683410765340001, "aspect": 1.12795002691, "identifi": 0.833722000472, "modul": 2.82988053166, "direct": 0.200705689496, "import": 0.292818277066, "decis": 0.7701082216959999, "acquaint": 2.80354936324, "extent": 1.40974687623, "have": 0.0147850023412, "score": 1.4559353207700003, "georgiatech": 6.58152136054, "incomprehens": 4.5192722194099995, "year": 0.047402238894600005, "collater": 4.26988643203, "gandhi": 3.6612966394999997, "effici": 1.62793753414, "down": 0.306673741186, "learn": 0.842752064745, "own": 0.164195077421, "when": 0.0205549888584, "hierarch": 3.4091655513099997}, "freq": {"after": 1, "strike": 1, "real": 1, "failur": 1, "audit": 1, "awar": 1, "then": 3, "relat": 2, "analyst": 2, "stage": 1, "troubl": 1, "label": 1, "red": 1, "opaqu": 1, "kind": 1, "space": 1, "topic": 3, "googl": 3, "miser": 1, "propon": 1, "been": 2, "etc": 2, "four": 1, "function": 4, "class": 3, "intent": 2, "logic": 1, "weapon": 1, "era": 1, "three": 1, "thought": 1, "whom": 1, "well": 3, "behav": 1, "tri": 2, "tree": 3, "nontarget": 1, "complet": 1, "approach": 5, "diagnosi": 1, "toward": 3, "know": 1, "most": 1, "anintroductiontoexplainableaiandwhyweneeditanumddnum": 1, "regul": 2, "motiv": 1, "applic": 5, "uncertain": 1, "legal": 3, "won": 1, "translat": 1, "magic": 1, "overlap": 1, "defens": 1, "room": 1, "verifi": 1, "how": 9, "billion": 1, "inexplic": 1, "upon": 2, "transpar": 2, "origin": 2, "had": 1, "increas": 2, "especi": 1, "expert": 1, "distribut": 6, "due": 4, "end": 1, "found": 1, "given": 1, "form": 1, "driven": 1, "deep": 7, "depend": 2, "will": 3, "conserv": 1, "scenario": 1, "toolkit": 1, "open": 1, "propag": 1, "wide": 1, "incorpor": 2, "neuron": 5, "claim": 1, "perform": 2, "but": 10, "success": 1, "surround": 1, "need": 2, "furthest": 1, "classif": 3, "output": 4, "sure": 1, "final": 2, "expect": 1, "parti": 2, "key": 1, "killer": 1, "lead": 4, "level": 1, "robot": 1, "has": 3, "generat": 1, "collabor": 2, "use": 11, "experi": 1, "govern": 1, "resourc": 1, "onlin": 1, "out": 1, "mistak": 1, "model": 28, "oncolog": 1, "good": 1, "alway": 1, "concept": 1, "much": 2, "opt": 1, "optim": 2, "field": 3, "reason": 8, "percent": 1, "not": 8, "proof": 1, "overrid": 1, "uncertainti": 1, "redistribut": 2, "perturb": 3, "difficult": 3, "less": 2, "agreement": 1, "aim": 2, "garner": 1, "specif": 1, "deepmind": 1, "lethal": 2, "whole": 1, "fidel": 1, "complic": 3, "bayesian": 2, "they": 9, "design": 1, "consult": 1, "cancer": 3, "allow": 1, "world": 2, "scienc": 4, "outcom": 1, "pixel": 1, "posthoc": 4, "larger": 1, "student": 1, "behavior": 1, "featur": 8, "feed": 1, "practic": 1, "lack": 2, "simpl": 3, "influenc": 1, "that": 16, "whose": 1, "algorithm": 10, "albeit": 1, "offer": 1, "mind": 1, "either": 1, "accord": 1, "develop": 3, "moreov": 2, "observ": 1, "accuraci": 3, "agre": 2, "with": 13, "more": 5, "network": 3, "deriv": 1, "lot": 2, "eras": 1, "racism": 1, "small": 2, "control": 1, "invest": 1, "may": 6, "twolevel": 1, "privaci": 1, "concern": 3, "off": 1, "beat": 1, "easili": 1, "without": 2, "protect": 1, "set": 5, "caus": 2, "ani": 1, "two": 3, "drone": 1, "and": 54, "from": 2, "account": 2, "answer": 2, "limit": 1, "patient": 2, "detail": 1, "num": 10, "technolog": 1, "depart": 3, "market": 1, "aren": 1, "balanc": 1, "for": 23, "car": 1, "predict": 5, "friend": 1, "militari": 3, "unlik": 1, "new": 2, "are": 18, "simpli": 1, "controversi": 1, "explan": 8, "compani": 2, "result": 4, "current": 1, "lnum": 1, "attachmentsxaiprogramupdatepdf": 1, "usher": 1, "sent": 1, "path": 1, "chanc": 1, "extract": 2, "intern": 2, "restor": 1, "harder": 1, "think": 1, "tend": 1, "combin": 1, "focus": 1, "educ": 1, "legitim": 1, "general": 3, "map": 1, "doe": 1, "even": 3, "ongo": 1, "littl": 1, "give": 2, "dod": 1, "simpler": 1, "photo": 1, "proper": 1, "damag": 1, "check": 1, "place": 1, "great": 1, "man": 1, "goal": 1, "gaug": 1, "electron": 1, "his": 1, "comment": 1, "taken": 1, "matter": 1, "fals": 1, "accept": 1, "preet": 2, "probabl": 2, "scientist": 1, "machin": 11, "into": 2, "bias": 2, "appl": 1, "strength": 1, "through": 2, "requir": 1, "where": 1, "doctor": 3, "contextu": 1, "prefer": 1, "gave": 1, "what": 3, "local": 1, "techniqu": 4, "prone": 1, "posterior": 1, "interpret": 7, "flexibl": 1, "help": 8, "main": 4, "larg": 1, "abil": 4, "manual": 1, "conclus": 1, "tech": 1, "humancomput": 1, "deiti": 1, "base": 2, "natur": 1, "deal": 2, "fact": 1, "pixellevel": 1, "driverless": 1, "decid": 2, "hot": 1, "here": 1, "ideal": 1, "factor": 1, "unambigu": 2, "black": 4, "attent": 3, "infer": 2, "valu": 1, "human": 6, "liabil": 1, "layer": 9, "evalu": 1, "henc": 2, "similar": 1, "about": 3, "problem": 1, "intuit": 2, "communiti": 1, "neural": 3, "report": 1, "insur": 1, "context": 1, "test": 1, "softwar": 4, "understand": 7, "unabl": 1, "watson": 3, "treatment": 1, "correct": 1, "him": 1, "convey": 1, "represent": 3, "would": 4, "weak": 1, "visit": 1, "blackbox": 2, "layerwis": 1, "serious": 1, "contribut": 2, "led": 2, "flag": 1, "train": 2, "complex": 3, "pure": 1, "bake": 1, "enabl": 1, "them": 2, "insight": 2, "trust": 7, "mitig": 1, "explain": 32, "giant": 1, "stereotyp": 1, "blind": 1, "autom": 1, "quit": 1, "abl": 3, "mani": 1, "refer": 2, "over": 3, "accur": 4, "often": 2, "build": 1, "veri": 5, "provid": 4, "special": 1, "mine": 2, "multifacet": 1, "linear": 1, "initi": 1, "frog": 3, "questionansw": 1, "show": 1, "character": 1, "target": 4, "there": 6, "exist": 1, "connect": 2, "inform": 1, "endus": 3, "possibl": 2, "diagnos": 1, "fulfil": 2, "best": 1, "exampl": 2, "technic": 2, "custom": 1, "knowledg": 1, "trade": 1, "follow": 2, "modelagnost": 1, "further": 1, "necess": 1, "hard": 1, "thirdwav": 1, "shouldn": 1, "high": 6, "basic": 1, "laymen": 2, "power": 4, "leverag": 1, "issu": 2, "also": 2, "typic": 1, "rational": 1, "such": 1, "revers": 1, "task": 3, "user": 6, "research": 4, "phenomena": 1, "signific": 1, "the": 128, "area": 1, "becom": 1, "shook": 1, "antehoc": 4, "whi": 2, "select": 1, "hospit": 2, "promin": 1, "want": 1, "webbas": 1, "system": 13, "individu": 1, "act": 1, "various": 2, "bio": 1, "work": 4, "backward": 1, "could": 3, "debat": 3, "were": 2, "which": 17, "pdfnumpdf": 1, "intellig": 5, "encompass": 1, "relev": 5, "activ": 2, "gray": 1, "estim": 1, "mechan": 2, "other": 1, "introduct": 1, "benefici": 1, "one": 4, "recreat": 1, "bank": 1, "hope": 1, "begin": 1, "see": 3, "box": 1, "riski": 1, "becaus": 1, "imag": 10, "sourc": 1, "academia": 1, "loop": 1, "get": 1, "like": 5, "implement": 1, "push": 1, "collect": 2, "tell": 2, "autonom": 1, "detect": 3, "part": 4, "both": 2, "analyt": 2, "despit": 2, "rule": 2, "this": 6, "choic": 2, "principl": 1, "rang": 1, "should": 7, "time": 2, "step": 1, "leav": 2, "back": 1, "chang": 3, "busi": 1, "project": 2, "differ": 3, "healthcar": 1, "institut": 2, "face": 2, "forget": 1, "aienabl": 1, "between": 7, "low": 1, "player": 1, "multimod": 1, "domain": 3, "who": 1, "fail": 1, "along": 1, "all": 1, "input": 5, "action": 1, "program": 3, "divis": 1, "combat": 1, "feat": 1, "case": 5, "european": 1, "normal": 1, "weight": 3, "architectur": 1, "tradeoff": 4, "object": 2, "futur": 1, "improv": 1, "while": 1, "interfac": 1, "these": 5, "compact": 1, "artifici": 5, "made": 5, "entail": 1, "befor": 1, "librari": 1, "probabilist": 1, "gorilla": 1, "close": 1, "affect": 2, "can": 16, "dumb": 1, "process": 5, "weigh": 1, "describ": 1, "make": 11, "civilian": 1, "onli": 2, "each": 4, "throw": 1, "ethic": 2, "distinguish": 1, "foster": 1, "industri": 1, "necessari": 1, "jeopardi": 1, "rise": 1, "inculc": 1, "advanc": 2, "imposs": 1, "data": 11, "lightweight": 1, "oper": 1, "their": 8, "method": 6, "behind": 3, "whether": 4, "phase": 1, "ultim": 1, "inc": 1, "come": 3, "might": 1, "aspect": 2, "identifi": 3, "modul": 1, "direct": 1, "import": 2, "decis": 22, "acquaint": 1, "extent": 1, "have": 15, "score": 2, "georgiatech": 1, "incomprehens": 1, "year": 1, "collater": 1, "gandhi": 2, "effici": 2, "down": 1, "learn": 12, "own": 1, "when": 9, "hierarch": 1}, "idf": {"after": 1.02070207021, "strike": 3.5620372447800004, "real": 2.28103448276, "failur": 3.28559602649, "audit": 15.12, "awar": 4.27693965517, "then": 1.08657860516, "relat": 1.23750876919, "analyst": 14.8373831776, "stage": 2.0831911822599998, "troubl": 4.99088337001, "label": 4.47715736041, "red": 2.22228443449, "opaqu": 75.961722488, "kind": 2.5806241872599998, "space": 2.39818731118, "topic": 5.457545548300001, "googl": 11.388809182200001, "miser": 38.8166259169, "propon": 12.2029208301, "been": 1.0239277652399998, "etc": 4.2066772655, "four": 1.20950784702, "function": 2.495441685, "class": 2.11651779763, "intent": 3.19372359686, "logic": 8.929133858270001, "weapon": 4.57126403686, "era": 2.5693477909, "three": 1.06621893889, "thought": 1.9854927463699998, "whom": 2.30320615117, "well": 1.0655748708, "behav": 15.6413793103, "tri": 1.8544562551099997, "tree": 4.127925117, "nontarget": 721.636363636, "complet": 1.24021560816, "approach": 2.07556543339, "diagnosi": 28.8130671506, "toward": 1.6303142329, "know": 2.59327017315, "most": 1.02096463023, "anintroductiontoexplainableaiandwhyweneeditanumddnum": 721.636363636, "regul": 3.88736532811, "motiv": 5.01611374408, "applic": 3.42672134686, "uncertain": 10.8590971272, "legal": 2.6000655093400002, "won": 2.31732593782, "translat": 2.85745140389, "magic": 7.9063745019899985, "overlap": 12.0913937548, "defens": 3.19115577889, "room": 3.07674418605, "verifi": 14.2258064516, "how": 1.60250328051, "billion": 4.8669527897, "inexplic": 89.6949152542, "upon": 1.60331246213, "transpar": 15.876, "origin": 1.13724928367, "had": 1.0475750577399998, "increas": 1.32024948025, "especi": 1.66712170534, "expert": 5.36713995943, "distribut": 2.7396031061299997, "due": 1.23789473684, "end": 1.10680423871, "found": 1.11387076405, "given": 1.35426085473, "form": 1.12755681818, "driven": 5.601976005650001, "deep": 3.6279707495399998, "depend": 2.2411067193700003, "will": 1.22481098596, "conserv": 3.3199498117900004, "scenario": 15.3986420951, "toolkit": 189.0, "open": 1.24556723678, "propag": 18.8104265403, "wide": 1.5598349381, "incorpor": 2.62847682119, "neuron": 64.2753036437, "claim": 1.52697893623, "perform": 1.5313977042500002, "but": 1.01632417899, "success": 1.32002993265, "surround": 2.49858356941, "need": 1.4372623574099999, "furthest": 84.8983957219, "classif": 8.067073170730001, "output": 7.676982591880001, "sure": 7.453521126760001, "final": 1.34008609775, "expect": 2.20011086475, "parti": 2.06369426752, "key": 2.28005170185, "killer": 13.9141104294, "lead": 1.2664326739, "level": 1.6544393497299998, "robot": 20.0201765448, "has": 1.0436497502, "generat": 2.05275407292, "collabor": 4.45454545455, "use": 1.0296387573799999, "experi": 1.87062566278, "govern": 1.50941243582, "resourc": 2.9487369985100003, "onlin": 2.6051854282900004, "out": 1.06016694491, "mistak": 8.71350164654, "model": 2.0905978404, "oncolog": 158.76, "good": 1.51981619759, "alway": 2.06745670009, "concept": 2.65707112971, "much": 1.1942229577299999, "opt": 12.721153846199998, "optim": 11.5377906977, "field": 1.7790228597, "reason": 1.72340425532, "percent": 3.9026548672600003, "not": 1.01567398119, "proof": 9.70415647922, "overrid": 34.8157894737, "uncertainti": 16.0688259109, "redistribut": 34.5130434783, "perturb": 74.8867924528, "difficult": 2.48957189901, "less": 1.46904783936, "agreement": 3.0245761097400004, "aim": 2.8960233491400005, "garner": 12.5900079302, "specif": 1.8719490626099997, "deepmind": 721.636363636, "lethal": 26.7723440135, "whole": 2.29488291414, "fidel": 26.637583892600002, "complic": 5.6478121664900005, "bayesian": 178.38202247200002, "they": 1.03017325287, "design": 1.45825296225, "consult": 5.21721984883, "cancer": 8.01009081736, "allow": 1.2716059271100002, "world": 1.11340206186, "scienc": 2.31969608416, "outcom": 7.48867924528, "pixel": 86.28260869569999, "posthoc": 721.636363636, "larger": 2.2407904022599996, "student": 2.47174217655, "behavior": 5.52978056426, "featur": 1.52712581762, "feed": 7.77853993141, "practic": 1.70434782609, "lack": 1.9271667880599999, "simpl": 3.3981164383599998, "influenc": 1.77246846042, "that": 1.00398406375, "whose": 1.73508196721, "algorithm": 27.9507042254, "albeit": 11.172413793099999, "offer": 1.53896859248, "mind": 3.5918552036199998, "either": 1.5830092731099998, "accord": 1.27589809531, "develop": 1.1955719557200002, "moreov": 7.56, "observ": 2.22446406053, "accuraci": 12.7620578778, "agre": 2.22946215419, "with": 1.0011982089899998, "more": 1.0171706817, "network": 2.59369384088, "deriv": 2.78379800105, "lot": 4.40877534018, "eras": 30.7079303675, "racism": 21.6885245902, "small": 1.3594793629, "control": 1.46959178006, "invest": 4.16146788991, "may": 1.05201775893, "twolevel": 721.636363636, "privaci": 28.2994652406, "concern": 1.8852867830400002, "off": 1.5121440137200002, "beat": 4.95660318451, "easili": 3.6938110749199997, "without": 1.29547123623, "protect": 1.96460834055, "set": 1.18707940781, "caus": 1.38521943984, "ani": 1.13383802314, "two": 1.01379310345, "drone": 52.92, "and": 1.00006299213, "from": 1.00056721497, "account": 1.94463498285, "answer": 4.64890190337, "limit": 1.5186531471200002, "patient": 9.54660252556, "detail": 2.26186066391, "num": 1.00031504001, "technolog": 2.6034765496900003, "depart": 1.99147014551, "market": 2.36602086438, "aren": 481.09090909099996, "balanc": 4.45329593268, "for": 1.00031504001, "car": 3.53743315508, "predict": 5.18484650555, "friend": 2.20194174757, "militari": 2.13129279098, "unlik": 2.42529789184, "new": 1.0178880554, "are": 1.02990593578, "simpli": 2.5192002538900002, "controversi": 2.62543409955, "explan": 6.50922509225, "compani": 1.5523613963, "result": 1.14611608432, "current": 1.5325803649, "lnum": 53.8169491525, "attachmentsxaiprogramupdatepdf": 721.636363636, "usher": 23.2105263158, "sent": 2.32683570277, "path": 4.6421052631599995, "chanc": 4.2449197861000005, "extract": 7.703056768560001, "intern": 1.30355530011, "restor": 2.97526236882, "harder": 17.1262135922, "think": 2.90715986083, "tend": 3.3735656608599998, "combin": 1.69760479042, "focus": 2.01012914662, "educ": 2.00733341763, "legitim": 9.16099249856, "general": 1.1218202374200001, "map": 4.0728578758300005, "doe": 1.70581282905, "even": 1.16461267606, "ongo": 6.04569687738, "littl": 1.5499365420299998, "give": 1.3653250774, "dod": 87.7127071823, "simpler": 17.9187358916, "photo": 6.41973311767, "proper": 3.3388012618299996, "damag": 2.7808723068799996, "check": 6.50655737705, "place": 1.1004366812200002, "great": 1.26592775696, "man": 1.7494214875999998, "goal": 3.28152128979, "gaug": 20.538163001300003, "electron": 4.5738980121, "his": 1.0943682360200002, "comment": 3.05954904606, "taken": 1.6012102874399998, "matter": 2.44773358002, "fals": 6.21613155834, "accept": 1.7377408056, "preet": 721.636363636, "probabl": 2.64555907349, "scientist": 4.69426374926, "machin": 4.02433460076, "into": 1.01502461479, "bias": 13.7335640138, "appl": 13.6980155306, "strength": 4.02739726027, "through": 1.07074930869, "requir": 1.52844902282, "where": 1.06715063521, "doctor": 3.9394540942900003, "contextu": 76.6956521739, "prefer": 3.0216977540900003, "gave": 1.85121268657, "what": 1.25343439128, "local": 1.51720183486, "techniqu": 3.7293868921800004, "prone": 18.144000000000002, "posterior": 86.28260869569999, "interpret": 3.2150668286799995, "flexibl": 9.68639414277, "help": 1.39962972759, "main": 1.25303867403, "larg": 1.18574949585, "abil": 2.70875277256, "manual": 7.72930866602, "conclus": 4.84615384615, "tech": 19.1739130435, "humancomput": 721.636363636, "deiti": 21.2815013405, "base": 1.14628158845, "natur": 1.5392670157100001, "deal": 2.18346857379, "fact": 1.73375559681, "pixellevel": 721.636363636, "driverless": 721.636363636, "decid": 1.9257641921400002, "hot": 4.6178010471199995, "here": 2.42307692308, "ideal": 4.65571847507, "factor": 2.89127663449, "unambigu": 59.0185873606, "black": 1.94917127072, "attent": 2.81040892193, "infer": 21.1398135819, "valu": 2.2777618364400003, "human": 1.8965476048299998, "liabil": 27.1384615385, "layer": 8.14153846154, "evalu": 6.9509632224199995, "henc": 5.390831918509999, "similar": 1.37514075357, "about": 1.06486015159, "problem": 1.76674827509, "intuit": 27.7068062827, "communiti": 1.96121062384, "neural": 59.4606741573, "report": 1.3634489866, "insur": 9.36637168142, "context": 4.25972632144, "test": 2.65707112971, "softwar": 10.2624434389, "understand": 2.96858638743, "unabl": 3.3081892060799998, "watson": 17.070967741900002, "treatment": 3.87125091441, "correct": 3.6631287494199998, "him": 1.63434218653, "convey": 12.297443842, "represent": 5.928304705, "would": 1.0828729281799998, "weak": 4.70539419087, "visit": 2.20622568093, "blackbox": 721.636363636, "layerwis": 721.636363636, "serious": 2.583984375, "contribut": 1.9255306246200001, "led": 1.33782758911, "flag": 5.95275590551, "train": 1.9365698950999999, "complex": 2.34021226415, "pure": 4.716577540109999, "bake": 41.2363636364, "enabl": 3.5421686747, "them": 1.09876115994, "insight": 11.8037174721, "trust": 4.89546716004, "mitig": 22.8103448276, "explain": 2.60049140049, "giant": 6.23566378633, "stereotyp": 19.3138686131, "blind": 8.849498327760001, "autom": 19.8202247191, "quit": 2.8849718335500003, "abl": 1.8208510150200001, "mani": 1.04426757877, "refer": 1.30024570025, "over": 1.02525024217, "accur": 5.768895348840001, "often": 1.29452054795, "build": 1.6341739578, "veri": 1.25880114177, "provid": 1.21552714187, "special": 1.4881889763799998, "mine": 4.875921375919999, "multifacet": 162.0, "linear": 13.8776223776, "initi": 1.35, "frog": 33.1440501044, "questionansw": 721.636363636, "show": 1.26703910615, "character": 4.563380281690001, "target": 3.2189781021900004, "there": 1.04091266719, "exist": 1.4647107666799999, "connect": 1.8843916913900003, "inform": 1.5753125620200001, "endus": 721.636363636, "possibl": 1.4173734488, "diagnos": 16.283076923099998, "fulfil": 6.87570376786, "best": 1.5828514456600002, "exampl": 1.50483412322, "technic": 3.1400316455699997, "custom": 3.6346153846199996, "knowledg": 3.3981164383599998, "trade": 2.37522441652, "follow": 1.04640126549, "modelagnost": 721.636363636, "further": 1.3618116315, "necess": 12.128342245999999, "hard": 2.73253012048, "thirdwav": 721.636363636, "shouldn": 721.636363636, "high": 1.14777327935, "basic": 2.7301805675, "laymen": 128.032258065, "power": 1.3396337861799998, "leverag": 35.7567567568, "issu": 1.43921675279, "also": 1.01476510067, "typic": 2.2541530597799997, "rational": 36.75, "such": 1.06151377374, "revers": 4.29894394801, "task": 3.88641370869, "user": 7.71053909665, "research": 1.9420183486200002, "phenomena": 16.5202913632, "signific": 1.4529147982100001, "the": 1.0, "area": 1.3881262568900001, "becom": 1.12492028626, "shook": 44.4705882353, "antehoc": 721.636363636, "whi": 3.2566153846200003, "select": 2.02345144022, "hospit": 3.4633507853400003, "promin": 2.39746300211, "want": 1.99698113208, "webbas": 721.636363636, "system": 1.38739840951, "individu": 1.8004082558400003, "act": 1.4318181818200002, "various": 1.3323262839899999, "bio": 42.336000000000006, "work": 1.11520089913, "backward": 14.605335786600001, "could": 1.2043695949, "debat": 3.2294548413300004, "were": 1.02458857696, "which": 1.005191845, "pdfnumpdf": 721.636363636, "intellig": 4.19334389857, "encompass": 8.02628918099, "relev": 6.938811188810001, "activ": 1.46403541129, "gray": 9.020454545449999, "estim": 2.34991119005, "mechan": 3.41492794149, "other": 1.00992366412, "introduct": 2.7808723068799996, "benefici": 18.269275028800003, "one": 1.00627495722, "recreat": 6.536023054759999, "bank": 2.87400434468, "hope": 2.50884955752, "begin": 1.3305397251100002, "see": 1.27242125511, "box": 4.12685209254, "riski": 36.5806451613, "becaus": 1.1495184997499999, "imag": 2.70137825421, "sourc": 1.69760479042, "academia": 33.4936708861, "loop": 13.5114893617, "get": 1.78562591385, "like": 1.14918566775, "implement": 3.57648118946, "push": 3.75141776938, "collect": 1.64109985528, "tell": 3.36142282448, "autonom": 11.086592178800002, "detect": 5.41288782816, "part": 1.04330682789, "both": 1.05215720061, "analyt": 17.256521739100002, "despit": 1.60606980273, "rule": 1.7415533128599998, "this": 1.00379362671, "choic": 3.1319786940200003, "principl": 3.4520547945199995, "rang": 1.7848229342299997, "should": 1.6643254009900001, "time": 1.01127460348, "step": 2.8279301745599996, "leav": 1.6615384615399997, "back": 1.26070038911, "chang": 1.1808985421, "busi": 2.05541170378, "project": 1.7534791252500002, "differ": 1.23654490225, "healthcar": 18.7659574468, "institut": 1.7792222346700002, "face": 1.80327124035, "forget": 16.9978586724, "aienabl": 721.636363636, "between": 1.03453668708, "low": 2.13072070863, "player": 3.54375, "multimod": 256.064516129, "domain": 9.39408284024, "who": 1.06279287723, "fail": 1.9281029876099998, "along": 1.2973768080399999, "all": 1.01146788991, "input": 12.2029208301, "action": 1.81855670103, "program": 2.02139037433, "divis": 2.32854209446, "combat": 5.01294600568, "feat": 17.070967741900002, "case": 1.48498737256, "european": 1.96290801187, "normal": 2.61075481006, "weight": 4.878918254459999, "architectur": 5.12790697674, "tradeoff": 208.89473684200001, "object": 2.3488681757700003, "futur": 1.8577112099200002, "improv": 2.04376930999, "while": 1.0441988950299999, "interfac": 20.9169960474, "these": 1.07415426252, "compact": 12.451764705899999, "artifici": 8.31639601886, "made": 1.07038834951, "entail": 21.2530120482, "befor": 1.10036041031, "librari": 2.68266306185, "probabilist": 127.008, "gorilla": 81.4153846154, "close": 1.2848818387799998, "affect": 2.4794627518400003, "can": 1.17626139142, "dumb": 66.15, "process": 1.69524826482, "weigh": 10.9944598338, "describ": 1.47027227264, "make": 1.0762660158600001, "civilian": 5.55104895105, "onli": 1.0256476516600002, "each": 1.18974820144, "throw": 8.39555790587, "ethic": 8.93918918919, "distinguish": 3.36926994907, "foster": 7.353404353869999, "industri": 2.02319357716, "necessari": 2.8421052631599997, "jeopardi": 77.443902439, "rise": 2.02940048575, "inculc": 162.0, "advanc": 1.9997480791, "imposs": 4.96125, "data": 3.37643555934, "lightweight": 32.4, "oper": 1.55479384977, "their": 1.01547908405, "method": 2.5714285714300003, "behind": 2.0845588235299997, "whether": 2.20683903253, "phase": 4.3012733676499995, "ultim": 2.58524670249, "inc": 18.5250875146, "come": 1.32831325301, "might": 2.1561863370900003, "aspect": 3.0893169877399997, "identifi": 2.30187037843, "modul": 16.9434364995, "direct": 1.22226499346, "import": 1.3401992233700002, "decis": 2.16, "acquaint": 16.503118503099998, "extent": 4.09491875161, "have": 1.0148948411399998, "score": 4.2884927066500005, "georgiatech": 721.636363636, "incomprehens": 91.76878612719999, "year": 1.0485436893200002, "collater": 71.5135135135, "gandhi": 38.911764705900005, "effici": 5.09335899904, "down": 1.35889754344, "learn": 2.32275054865, "own": 1.17844418052, "when": 1.02076769755, "hierarch": 30.24}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Explainable Artificial Intelligence</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/explainable-ai.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Explainable Artificial Intelligence Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/role-data-engineer-changing.html\" rel=\"prev\" title=\"The Role of the Data Engineer is Changing\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/principles-database-management-practical-guide.html\" rel=\"next\" title=\"Principles of Database Management: The Practical Guide to Storing, Managing and Analyzing Big and Small Data\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/01/explainable-ai.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=89265\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/explainable-ai.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-89265 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 10-Jan, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/index.html\">Jan</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/opinions.html\">Opinions</a> \u00bb Explainable Artificial Intelligence (\u00a0<a href=\"/2019/n03.html\">19:n03</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Explainable Artificial Intelligence</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/01/role-data-engineer-changing.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/01/principles-database-management-practical-guide.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/ai\" rel=\"tag\">AI</a>, <a href=\"https://www.kdnuggets.com/tag/explainable-ai\" rel=\"tag\">Explainable AI</a>, <a href=\"https://www.kdnuggets.com/tag/lime\" rel=\"tag\">LIME</a>, <a href=\"https://www.kdnuggets.com/tag/xai\" rel=\"tag\">XAI</a></div>\n<br/>\n<p class=\"excerpt\">\n     We outline the necessity of explainable AI, discuss some of the methods in academia, take a look at explainability vs accuracy, investigate use cases, and more.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/preetgandhi/\">Preet Gandhi</a>, NYU</b></p>\n<p><b>Introduction</b><br>\nIn the era of data science, artificial intelligence is making impossible feats possible. Driverless cars, IBM Watson\u2019s question-answering system, cancer detection, electronic trading, etc. are all made possible through the advanced decision making ability of artificial intelligence. The deep layers of neural networks have a magical ability to recreate the human mind and its functionalities. When humans make decisions, they have the ability to explain their thought process behind it. They can explain the rationale; whether its driven by observation, intuition, experience or logical thinking ability. Basic ML algorithms like decision trees can be explained by following the tree path which led to the decision. But when it comes to complex AI algorithms, the deep layers are often incomprehensible by human intuition and are quite opaque. Data scientists may have trouble explaining why their algorithm gave a decision and the laymen end-user may not simply trust the machine\u2019s predictions without contextual proof and reasoning.</br></p>\n<p><img alt=\"Xai Fig1 Venn Diagram\" src=\"/images/xai-fig1-venn-500.jpg\" width=\"500\"/></p>\n<p>Explainability is a multifaceted topic. It encompasses both individual models and the larger systems that incorporate them. It refers not only to whether the decisions a model outputs are interpretable, but also whether or not the whole process and intention surrounding the model can be properly accounted for. They try have an efficient trade-off between accuracy and explainability along with a great human-computer interface which can help translate the model to understandable representation for the end users.</p>\n<p>There need to be three steps which should be fulfilled by the system :</p>\n<p>1) Explained the intent behind how the system affects the concerned parties</p>\n<p>2) Explain the data sources you use and how you audit outcomes</p>\n<p>3) Explain how inputs in a model lead to outputs.</p>\n<p><strong>The necessity</strong></p>\n<p>Explainability is motivated due to lacking transparency of the black-box approaches, which do not foster trust and acceptance of AI generally and ML specifically. Rising legal and privacy aspects, e.g. with the new European General Data Protection Regulations will make black-box approaches difficult to use in Business, because they often are not able to explain why a machine decision has been made.</p>\n<p>IBM Watson shook the world when it won jeopardy beating the best human players. But when it was marketed to hospitals to help the oncology department detect cancer, it failed miserably. Cancer detection is a very difficult and serious topic. The doctors as well as the patients were unable to trust the machine at each stage of consulting and treatment as Watson wouldn\u2019t provide the reasons for its results. Moreover when its results agreed with the doctor\u2019s, it couldn't provide a diagnosis.</p>\n<p>Using AI for military practices is a hotly debated topic. Proponents claim that lethal autonomous weapon systems (LAWS) might cause less collateral damage but despite there being large training data to distinguish between combatants and civilians or targets and non-targets, it is very risky to leave the final decision making power to machines. CIA has 137 AI projects, one of which is the automated AI-enabled drones where the lack of explainability of the AI software\u2019s selection of the targets is controversial. The extent of an explanation currently may be, \u201cThere is a 95 percent chance this is what you should do,\u201d but that\u2019s it. When the algorithm can't describe it\u2019s features that contributed towards identifying a legitimate target, it leaves room open for debate on racism and stereotype issues which bias the model. Moreover in case of a false target, explanations would help diagnose the cause of failure and help improve the model.</p>\n<p><strong>New methods in academia</strong></p>\n<p>There are two main set of techniques used to develop explainable systems; post-hoc and ante-hoc. Ante-hoc techniques entail baking explainability into a model from the beginning. Post-hoc techniques allow models to be trained normally, with explainability only being incorporated at testing time.</p>\n<p><strong>Ante-Hoc Methods:</strong></p>\n<ul>\n<li><strong>Reversed Time Attention Model\u00a0(RETAIN)</strong>: Researchers at Georgia-Tech developed the RETAIN model to help doctors understand the AI software\u2019s predictions. The patients hospital visits data were sent to two RNN\u2019s both of which had attention mechanism. The attention mechanism helped explain which part the neural network was focusing on and which features helped influence its choice.<br>\n<img alt=\"Xai Fig2 Retain\" src=\"/images/xai-fig2-retain-500.jpg\" width=\"500\"/></br></li>\n<li><strong>Bayesian deep learning (BDL):</strong> BDL enables one to gauge how uncertain a neural network is about its predictions. These deep architectures can model complex tasks by leveraging the hierarchical representation power of deep learning, while also being able to infer complex multi-modal posterior distributions. Bayesian deep learning models typically form uncertainty estimates by either placing distributions over model weights, or by learning a direct mapping to probabilistic outputs. By knowing the weight distributions of various predictions and classes, we can tell a lot about what feature led to what decisions and the relative important of it.</li>\n</ul>\n<p><strong>Post-Hoc Methods:</strong></p>\n<ul>\n<li><strong>Local Interpretable Model-Agnostic Explanations (LIME)</strong>: This isn\u2019t a purely transparent model as it provides the explanation after a decision has been made. Hence it can have wide range of applications as it isn\u2019t customized to one domain unlike RETAIN. For example for an image classification problem using a CNN, we get the probability distribution over classes. Then we make small changes to input to see how it affects the distribution and collect the results. Then using a linear interpretable model, on the collected perturbation set, we can explain changed in the key features extracted with their weights telling us how prominent they are. It blacks out different parts of the original image and feeds the resulting \u201cperturbed\u201d images back through the model, checking to see which perturbations throw the algorithm off the furthest to derive reasoning behind the algorithms decisions. For example, for an image of a tree frog, LIME found that erasing parts of the frog\u2019s face made it much harder for the model to identify the image, showing that much of the original classification decision was based on the frog\u2019s face. LIME is generally applicable to image classifications tasks.\n<p>In 2015, a black software developer <a href=\"https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/\">reported</a> that Google Photos labeled images of him and his black friend as \u201cgorillas.\u201d It\u2019s not hard to see how explanation techniques like LIME could mitigate this kind of bias by having a human operator override the decisions upon evaluating the reasons given by the algorithm.</p></li>\n<li><strong>Layer-wise Relevance Propagation (LRP)</strong>: This approach is based on the principles of redistribution and conservation. Here when we have an image and probability distribution of classes, we redistribute these to the input pixels, layer by layer. We can decide the relevance of inputs and features by going backwards using Deep CNN to extract relevant features before identifying similarity between the images in feature space. We try to infer pixel-level details of the images that may have significantly informed the model\u2019s choice.</li>\n</ul>\n<p><img alt=\"Explainable AI Figure 5\" class=\"size-full wp-image-89284 aligncenter\" sizes=\"(max-width: 503px) 100vw, 503px\" src=\"https://www.kdnuggets.com/wp-content/uploads/xai-fig5-equation.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/xai-fig5-equation.jpg 503w, https://www.kdnuggets.com/wp-content/uploads/xai-fig5-equation-300x81.jpg 300w\" width=\"50%\"/></p>\n<p>x_j\u200a\u2014\u200athe activation value for neuron j in layer l</p>\n<p>w_j,k\u200a\u2014\u200athe weighing of the connection between neuron j in layer l and neuron k in layer l + 1</p>\n<p>R_j\u200a\u2014\u200aRelevance scores for each neuron in layer l</p>\n<p>R_k\u200a\u2014\u200aRelevance scores for each neuron in layer l+1</p>\n<ul>\n<li><strong>BETA </strong>: BETA is closely connected to Interpretable Decision Sets. BETA learns a compact two-level decision set in which each rule explains part of the model behavior unambiguously. It uses a objective function so that the learning process is optimized for high fidelity (high agreement between explanation and the model), low unambiguity (little overlaps between decision rules in the explanation), and high interpretability (the explanation decision set is lightweight and small). These aspects are combined into one objection function to optimize for.</li>\n</ul>\n<p><strong>Explainability vs Accuracy</strong></p>\n<p>Will we need to \u2018dumb down\u2019 AI algorithms to make them explainable? Explainable models are easily understandable but don\u2019t work very well as they are simple. Accurate models work well but aren\u2019t explainable as they are complicated. The main issue with explainable AI is whether it can accurately fulfill the task it was designed for. The tradeoff decision to be made should depend on the application field of the algorithm and the end-user to whom its accountable.</p>\n<p>When dealing with technical users who are acquainted with the field and have high trust level, especially tech companies or researchers, having highly accurate models would be preferred over high explainability as performance is very important. But dealing with laymen users is a different scenario. It would be difficult to garner their trust. The machine learning approach is very different specially in banks, insurance companies, healthcare providers and other regulated industries. The reason is mainly that they are prone to <strong>legal or even ethical requirements</strong> which tend to limit more and more the use of black box models. Such institutions are answerable for their decisions and process and in this case a simple explainable albeit less efficient algorithm would do.</p>\n<p>Hence the tradeoff should be decided according to the application domain and the users concerned. If you want your system to be explainable, you\u2019re going to have to make do with a simpler system that isn\u2019t as powerful or accurate. Simple systems can give a prediction to the user but the ultimate action should be taken by the user. When performance matters most, even with a complicated model, opt for the trust that comes from making sure that you\u2019re able to verify that your system does, in fact, work.</p>\n<p><img alt=\"Xai Fig3 Accuracy Vs Explainability\" src=\"/images/xai-fig3-accuracy-vs-explainability-600.jpg\" width=\"100%\"/><br>\n<strong>Use Case : DARPA XAI</strong></br></p>\n<p>The Department of Defense (DoD) is increasingly investing in AI research in collaboration with technological giants like Google to have artificial intelligence programs for military activities. Due to ethical reasons, many government departments agree to have a \u201cman in the loop\u201d to control any lethal system of these \u201ckiller robots\u201d. Due to the increasing debates and strikes by the AI community to not contribute towards military AI, the DARPA division is pushing towards their $2 Billion Explainable Artificial Intelligence ( XAI ) program. XAI is their hope to usher in the third-wave AI systems which can understand the context in which they function and can characterize the real world phenomena. Its main aim is to:</p>\n<ul>\n<li>Explain the decisions and it\u2019s process</li>\n<li>Understand it\u2019s strength and weakness</li>\n<li>Convey how the system may behave in the future</li>\n</ul>\n<p><img alt=\"Xai Fig4 Darpa\" src=\"/images/xai-fig4-darpa-700.jpg\" width=\"100%\"/></p>\n<ul>\n<li>Offer insight on how to correct the mistakes</li>\n</ul>\n<p>The final goal of XAI is to have a toolkit library of ML and HCI modules for more understandable AI implementations. The Phase 1 of the project was completed in May 2018 and further advancements are expected in the coming years. In case of a gray area in decision output, XAI aims to give the analyst reasons for red flags upon which the analyst can act to make a decision using human input.</p>\n<p><strong>Conclusion</strong></p>\n<p>The success of AI models is due to the machines\u2019 own internal representations which are even more complicated then manually generated features leading to its inexplicable nature. There are a lot of on-going research on the ante-hoc and post-hoc methods to make the AI more answerable and awareness to inculcate these methods in existing programs. Good initiatives by leading institutions like DARPA, Google, DeepMind, etc. are leading the necessary change. Despite this, there will always be a tradeoff between explainability and accuracy whose balance depends on various factors like end-user, legal liability, technicality of the concerned parties and the field of application. Artificial intelligence should not become a powerful deity which we follow blindly without understanding its reasoning but we shouldn\u2019t forget about its beneficial insight it can have. Ideally, we should build flexible and interpretable models that can work in collaboration with experts and their domain knowledge.</p>\n<p><strong>References</strong></p>\n<ol>\n<li>LRP - <a href=\"https://arxiv.org/pdf/1807.06160.pdf\">https://arxiv.org/pdf/1807.06160.pdf</a></li>\n<li>DARPA XAI - <a href=\"https://www.darpa.mil/attachments/XAIProgramUpdate.pdf\">https://www.darpa.mil/attachments/XAIProgramUpdate.pdf</a></li>\n<li>XAI methods - https://medium.freecodecamp.org/an-introduction-to-explainable-ai-and-why-we-need-it-a326417dd000</li>\n</ol>\n<p><b>Bio</b>: <a href=\"https://www.linkedin.com/in/preetgandhi/\">Preet Gandhi</a> is a student at NYU and was a Data Science Intern at Apple Inc.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2018/12/explainable-ai-machine-learning.html\">A Case For Explainable AI &amp; Machine Learning</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html\">Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/four-approaches-ai-machine-learning.html\">Four Approaches to Explaining AI and Machine Learning</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/01/role-data-engineer-changing.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/01/principles-database-management-practical-guide.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/index.html\">Jan</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/opinions.html\">Opinions</a> \u00bb Explainable Artificial Intelligence (\u00a0<a href=\"/2019/n03.html\">19:n03</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556330212\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.727 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 21:56:52 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "preet", "gandhi", "introduct", "the", "era", "data", "scienc", "artifici", "intellig", "make", "imposs", "feat", "possibl", "driverless", "car", "watson", "questionansw", "system", "cancer", "detect", "electron", "trade", "etc", "are", "all", "made", "possibl", "through", "the", "advanc", "decis", "make", "abil", "artifici", "intellig", "the", "deep", "layer", "neural", "network", "have", "magic", "abil", "recreat", "the", "human", "mind", "and", "function", "when", "human", "make", "decis", "they", "have", "the", "abil", "explain", "their", "thought", "process", "behind", "they", "can", "explain", "the", "rational", "whether", "driven", "observ", "intuit", "experi", "logic", "think", "abil", "basic", "algorithm", "like", "decis", "tree", "can", "explain", "follow", "the", "tree", "path", "which", "led", "the", "decis", "but", "when", "come", "complex", "algorithm", "the", "deep", "layer", "are", "often", "incomprehens", "human", "intuit", "and", "are", "quit", "opaqu", "data", "scientist", "may", "have", "troubl", "explain", "whi", "their", "algorithm", "gave", "decis", "and", "the", "laymen", "endus", "may", "not", "simpli", "trust", "the", "machin", "predict", "without", "contextu", "proof", "and", "reason", "explain", "multifacet", "topic", "encompass", "both", "individu", "model", "and", "the", "larger", "system", "that", "incorpor", "them", "refer", "not", "onli", "whether", "the", "decis", "model", "output", "are", "interpret", "but", "also", "whether", "not", "the", "whole", "process", "and", "intent", "surround", "the", "model", "can", "proper", "account", "for", "they", "tri", "have", "effici", "tradeoff", "between", "accuraci", "and", "explain", "along", "with", "great", "humancomput", "interfac", "which", "can", "help", "translat", "the", "model", "understand", "represent", "for", "the", "end", "user", "there", "need", "three", "step", "which", "should", "fulfil", "the", "system", "num", "explain", "the", "intent", "behind", "how", "the", "system", "affect", "the", "concern", "parti", "num", "explain", "the", "data", "sourc", "use", "and", "how", "audit", "outcom", "num", "explain", "how", "input", "model", "lead", "output", "the", "necess", "explain", "motiv", "due", "lack", "transpar", "the", "blackbox", "approach", "which", "not", "foster", "trust", "and", "accept", "general", "and", "specif", "rise", "legal", "and", "privaci", "aspect", "with", "the", "new", "european", "general", "data", "protect", "regul", "will", "make", "blackbox", "approach", "difficult", "use", "busi", "becaus", "they", "often", "are", "not", "abl", "explain", "whi", "machin", "decis", "has", "been", "made", "watson", "shook", "the", "world", "when", "won", "jeopardi", "beat", "the", "best", "human", "player", "but", "when", "market", "hospit", "help", "the", "oncolog", "depart", "detect", "cancer", "fail", "miser", "cancer", "detect", "veri", "difficult", "and", "serious", "topic", "the", "doctor", "well", "the", "patient", "were", "unabl", "trust", "the", "machin", "each", "stage", "consult", "and", "treatment", "watson", "provid", "the", "reason", "for", "result", "moreov", "when", "result", "agre", "with", "the", "doctor", "could", "provid", "diagnosi", "use", "for", "militari", "practic", "hot", "debat", "topic", "propon", "claim", "that", "lethal", "autonom", "weapon", "system", "might", "caus", "less", "collater", "damag", "but", "despit", "there", "larg", "train", "data", "distinguish", "between", "combat", "and", "civilian", "target", "and", "nontarget", "veri", "riski", "leav", "the", "final", "decis", "make", "power", "machin", "has", "num", "project", "one", "which", "the", "autom", "aienabl", "drone", "where", "the", "lack", "explain", "the", "softwar", "select", "the", "target", "controversi", "the", "extent", "explan", "current", "may", "there", "num", "percent", "chanc", "this", "what", "should", "but", "that", "when", "the", "algorithm", "describ", "featur", "that", "contribut", "toward", "identifi", "legitim", "target", "leav", "room", "open", "for", "debat", "racism", "and", "stereotyp", "issu", "which", "bias", "the", "model", "moreov", "case", "fals", "target", "explan", "would", "help", "diagnos", "the", "caus", "failur", "and", "help", "improv", "the", "model", "new", "method", "academia", "there", "are", "two", "main", "set", "techniqu", "use", "develop", "explain", "system", "posthoc", "and", "antehoc", "antehoc", "techniqu", "entail", "bake", "explain", "into", "model", "from", "the", "begin", "posthoc", "techniqu", "allow", "model", "train", "normal", "with", "explain", "onli", "incorpor", "test", "time", "antehoc", "method", "revers", "time", "attent", "model", "research", "georgiatech", "develop", "the", "model", "help", "doctor", "understand", "the", "softwar", "predict", "the", "patient", "hospit", "visit", "data", "were", "sent", "two", "both", "which", "had", "attent", "mechan", "the", "attent", "mechan", "help", "explain", "which", "part", "the", "neural", "network", "focus", "and", "which", "featur", "help", "influenc", "choic", "bayesian", "deep", "learn", "enabl", "one", "gaug", "how", "uncertain", "neural", "network", "about", "predict", "these", "deep", "architectur", "can", "model", "complex", "task", "leverag", "the", "hierarch", "represent", "power", "deep", "learn", "while", "also", "abl", "infer", "complex", "multimod", "posterior", "distribut", "bayesian", "deep", "learn", "model", "typic", "form", "uncertainti", "estim", "either", "place", "distribut", "over", "model", "weight", "learn", "direct", "map", "probabilist", "output", "know", "the", "weight", "distribut", "various", "predict", "and", "class", "can", "tell", "lot", "about", "what", "featur", "led", "what", "decis", "and", "the", "relat", "import", "posthoc", "method", "local", "interpret", "modelagnost", "explan", "this", "pure", "transpar", "model", "provid", "the", "explan", "after", "decis", "has", "been", "made", "henc", "can", "have", "wide", "rang", "applic", "custom", "one", "domain", "unlik", "for", "exampl", "for", "imag", "classif", "problem", "use", "get", "the", "probabl", "distribut", "over", "class", "then", "make", "small", "chang", "input", "see", "how", "affect", "the", "distribut", "and", "collect", "the", "result", "then", "use", "linear", "interpret", "model", "the", "collect", "perturb", "set", "can", "explain", "chang", "the", "key", "featur", "extract", "with", "their", "weight", "tell", "how", "promin", "they", "are", "black", "out", "differ", "part", "the", "origin", "imag", "and", "feed", "the", "result", "perturb", "imag", "back", "through", "the", "model", "check", "see", "which", "perturb", "throw", "the", "algorithm", "off", "the", "furthest", "deriv", "reason", "behind", "the", "algorithm", "decis", "for", "exampl", "for", "imag", "tree", "frog", "found", "that", "eras", "part", "the", "frog", "face", "made", "much", "harder", "for", "the", "model", "identifi", "the", "imag", "show", "that", "much", "the", "origin", "classif", "decis", "base", "the", "frog", "face", "general", "applic", "imag", "classif", "task", "num", "black", "softwar", "develop", "report", "that", "googl", "photo", "label", "imag", "him", "and", "his", "black", "friend", "gorilla", "not", "hard", "see", "how", "explan", "techniqu", "like", "could", "mitig", "this", "kind", "bias", "have", "human", "oper", "overrid", "the", "decis", "upon", "evalu", "the", "reason", "given", "the", "algorithm", "layerwis", "relev", "propag", "this", "approach", "base", "the", "principl", "redistribut", "and", "conserv", "here", "when", "have", "imag", "and", "probabl", "distribut", "class", "redistribut", "these", "the", "input", "pixel", "layer", "layer", "can", "decid", "the", "relev", "input", "and", "featur", "backward", "use", "deep", "extract", "relev", "featur", "befor", "identifi", "similar", "between", "the", "imag", "featur", "space", "tri", "infer", "pixellevel", "detail", "the", "imag", "that", "may", "have", "signific", "inform", "the", "model", "choic", "the", "activ", "valu", "for", "neuron", "layer", "the", "weigh", "the", "connect", "between", "neuron", "layer", "and", "neuron", "layer", "num", "relev", "score", "for", "each", "neuron", "layer", "relev", "score", "for", "each", "neuron", "layer", "lnum", "close", "connect", "interpret", "decis", "set", "learn", "compact", "twolevel", "decis", "set", "which", "each", "rule", "explain", "part", "the", "model", "behavior", "unambigu", "use", "object", "function", "that", "the", "learn", "process", "optim", "for", "high", "fidel", "high", "agreement", "between", "explan", "and", "the", "model", "low", "unambigu", "littl", "overlap", "between", "decis", "rule", "the", "explan", "and", "high", "interpret", "the", "explan", "decis", "set", "lightweight", "and", "small", "these", "aspect", "are", "combin", "into", "one", "object", "function", "optim", "for", "explain", "accuraci", "will", "need", "dumb", "down", "algorithm", "make", "them", "explain", "explain", "model", "are", "easili", "understand", "but", "work", "veri", "well", "they", "are", "simpl", "accur", "model", "work", "well", "but", "aren", "explain", "they", "are", "complic", "the", "main", "issu", "with", "explain", "whether", "can", "accur", "fulfil", "the", "task", "design", "for", "the", "tradeoff", "decis", "made", "should", "depend", "the", "applic", "field", "the", "algorithm", "and", "the", "endus", "whom", "account", "when", "deal", "with", "technic", "user", "who", "are", "acquaint", "with", "the", "field", "and", "have", "high", "trust", "level", "especi", "tech", "compani", "research", "have", "high", "accur", "model", "would", "prefer", "over", "high", "explain", "perform", "veri", "import", "but", "deal", "with", "laymen", "user", "differ", "scenario", "would", "difficult", "garner", "their", "trust", "the", "machin", "learn", "approach", "veri", "differ", "special", "bank", "insur", "compani", "healthcar", "provid", "and", "other", "regul", "industri", "the", "reason", "main", "that", "they", "are", "prone", "legal", "even", "ethic", "requir", "which", "tend", "limit", "more", "and", "more", "the", "use", "black", "box", "model", "such", "institut", "are", "answer", "for", "their", "decis", "and", "process", "and", "this", "case", "simpl", "explain", "albeit", "less", "effici", "algorithm", "would", "henc", "the", "tradeoff", "should", "decid", "accord", "the", "applic", "domain", "and", "the", "user", "concern", "want", "system", "explain", "have", "make", "with", "simpler", "system", "that", "power", "accur", "simpl", "system", "can", "give", "predict", "the", "user", "but", "the", "ultim", "action", "should", "taken", "the", "user", "when", "perform", "matter", "most", "even", "with", "complic", "model", "opt", "for", "the", "trust", "that", "come", "from", "make", "sure", "that", "abl", "verifi", "that", "system", "doe", "fact", "work", "use", "case", "the", "depart", "defens", "dod", "increas", "invest", "research", "collabor", "with", "technolog", "giant", "like", "googl", "have", "artifici", "intellig", "program", "for", "militari", "activ", "due", "ethic", "reason", "mani", "govern", "depart", "agre", "have", "man", "the", "loop", "control", "ani", "lethal", "system", "these", "killer", "robot", "due", "the", "increas", "debat", "and", "strike", "the", "communiti", "not", "contribut", "toward", "militari", "the", "divis", "push", "toward", "their", "num", "billion", "explain", "artifici", "intellig", "program", "their", "hope", "usher", "the", "thirdwav", "system", "which", "can", "understand", "the", "context", "which", "they", "function", "and", "can", "character", "the", "real", "world", "phenomena", "main", "aim", "explain", "the", "decis", "and", "process", "understand", "strength", "and", "weak", "convey", "how", "the", "system", "may", "behav", "the", "futur", "offer", "insight", "how", "correct", "the", "mistak", "the", "final", "goal", "have", "toolkit", "librari", "and", "modul", "for", "more", "understand", "implement", "the", "phase", "num", "the", "project", "complet", "may", "num", "and", "further", "advanc", "are", "expect", "the", "come", "year", "case", "gray", "area", "decis", "output", "aim", "give", "the", "analyst", "reason", "for", "red", "flag", "upon", "which", "the", "analyst", "can", "act", "make", "decis", "use", "human", "input", "conclus", "the", "success", "model", "due", "the", "machin", "own", "intern", "represent", "which", "are", "even", "more", "complic", "then", "manual", "generat", "featur", "lead", "inexplic", "natur", "there", "are", "lot", "ongo", "research", "the", "antehoc", "and", "posthoc", "method", "make", "the", "more", "answer", "and", "awar", "inculc", "these", "method", "exist", "program", "good", "initi", "lead", "institut", "like", "googl", "deepmind", "etc", "are", "lead", "the", "necessari", "chang", "despit", "this", "there", "will", "alway", "tradeoff", "between", "explain", "and", "accuraci", "whose", "balanc", "depend", "various", "factor", "like", "endus", "legal", "liabil", "technic", "the", "concern", "parti", "and", "the", "field", "applic", "artifici", "intellig", "should", "not", "becom", "power", "deiti", "which", "follow", "blind", "without", "understand", "reason", "but", "shouldn", "forget", "about", "benefici", "insight", "can", "have", "ideal", "should", "build", "flexibl", "and", "interpret", "model", "that", "can", "work", "collabor", "with", "expert", "and", "their", "domain", "knowledg", "refer", "pdfnumpdf", "attachmentsxaiprogramupdatepdf", "method", "anintroductiontoexplainableaiandwhyweneeditanumddnum", "bio", "preet", "gandhi", "student", "and", "data", "scienc", "intern", "appl", "inc", "resourc", "onlin", "and", "webbas", "analyt", "data", "mine", "data", "scienc", "machin", "learn", "educ", "softwar", "for", "analyt", "data", "scienc", "data", "mine", "and", "machin", "learn", "relat", "case", "for", "explain", "machin", "learn", "machin", "learn", "explain", "interpret", "two", "concept", "that", "could", "help", "restor", "trust", "four", "approach", "explain", "and", "machin", "learn"], "timestamp_scraper": 1556376253.112402, "title": "Explainable Artificial Intelligence", "read_time": 594.3, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/preetgandhi/\">Preet Gandhi</a>, NYU</b></p>\n<p><b>Introduction</b><br>\nIn the era of data science, artificial intelligence is making impossible feats possible. Driverless cars, IBM Watson\u2019s question-answering system, cancer detection, electronic trading, etc. are all made possible through the advanced decision making ability of artificial intelligence. The deep layers of neural networks have a magical ability to recreate the human mind and its functionalities. When humans make decisions, they have the ability to explain their thought process behind it. They can explain the rationale; whether its driven by observation, intuition, experience or logical thinking ability. Basic ML algorithms like decision trees can be explained by following the tree path which led to the decision. But when it comes to complex AI algorithms, the deep layers are often incomprehensible by human intuition and are quite opaque. Data scientists may have trouble explaining why their algorithm gave a decision and the laymen end-user may not simply trust the machine\u2019s predictions without contextual proof and reasoning.</br></p>\n<p><img alt=\"Xai Fig1 Venn Diagram\" src=\"/images/xai-fig1-venn-500.jpg\" width=\"500\"/></p>\n<p>Explainability is a multifaceted topic. It encompasses both individual models and the larger systems that incorporate them. It refers not only to whether the decisions a model outputs are interpretable, but also whether or not the whole process and intention surrounding the model can be properly accounted for. They try have an efficient trade-off between accuracy and explainability along with a great human-computer interface which can help translate the model to understandable representation for the end users.</p>\n<p>There need to be three steps which should be fulfilled by the system :</p>\n<p>1) Explained the intent behind how the system affects the concerned parties</p>\n<p>2) Explain the data sources you use and how you audit outcomes</p>\n<p>3) Explain how inputs in a model lead to outputs.</p>\n<p><strong>The necessity</strong></p>\n<p>Explainability is motivated due to lacking transparency of the black-box approaches, which do not foster trust and acceptance of AI generally and ML specifically. Rising legal and privacy aspects, e.g. with the new European General Data Protection Regulations will make black-box approaches difficult to use in Business, because they often are not able to explain why a machine decision has been made.</p>\n<p>IBM Watson shook the world when it won jeopardy beating the best human players. But when it was marketed to hospitals to help the oncology department detect cancer, it failed miserably. Cancer detection is a very difficult and serious topic. The doctors as well as the patients were unable to trust the machine at each stage of consulting and treatment as Watson wouldn\u2019t provide the reasons for its results. Moreover when its results agreed with the doctor\u2019s, it couldn't provide a diagnosis.</p>\n<p>Using AI for military practices is a hotly debated topic. Proponents claim that lethal autonomous weapon systems (LAWS) might cause less collateral damage but despite there being large training data to distinguish between combatants and civilians or targets and non-targets, it is very risky to leave the final decision making power to machines. CIA has 137 AI projects, one of which is the automated AI-enabled drones where the lack of explainability of the AI software\u2019s selection of the targets is controversial. The extent of an explanation currently may be, \u201cThere is a 95 percent chance this is what you should do,\u201d but that\u2019s it. When the algorithm can't describe it\u2019s features that contributed towards identifying a legitimate target, it leaves room open for debate on racism and stereotype issues which bias the model. Moreover in case of a false target, explanations would help diagnose the cause of failure and help improve the model.</p>\n<p><strong>New methods in academia</strong></p>\n<p>There are two main set of techniques used to develop explainable systems; post-hoc and ante-hoc. Ante-hoc techniques entail baking explainability into a model from the beginning. Post-hoc techniques allow models to be trained normally, with explainability only being incorporated at testing time.</p>\n<p><strong>Ante-Hoc Methods:</strong></p>\n<ul>\n<li><strong>Reversed Time Attention Model\u00a0(RETAIN)</strong>: Researchers at Georgia-Tech developed the RETAIN model to help doctors understand the AI software\u2019s predictions. The patients hospital visits data were sent to two RNN\u2019s both of which had attention mechanism. The attention mechanism helped explain which part the neural network was focusing on and which features helped influence its choice.<br>\n<img alt=\"Xai Fig2 Retain\" src=\"/images/xai-fig2-retain-500.jpg\" width=\"500\"/></br></li>\n<li><strong>Bayesian deep learning (BDL):</strong> BDL enables one to gauge how uncertain a neural network is about its predictions. These deep architectures can model complex tasks by leveraging the hierarchical representation power of deep learning, while also being able to infer complex multi-modal posterior distributions. Bayesian deep learning models typically form uncertainty estimates by either placing distributions over model weights, or by learning a direct mapping to probabilistic outputs. By knowing the weight distributions of various predictions and classes, we can tell a lot about what feature led to what decisions and the relative important of it.</li>\n</ul>\n<p><strong>Post-Hoc Methods:</strong></p>\n<ul>\n<li><strong>Local Interpretable Model-Agnostic Explanations (LIME)</strong>: This isn\u2019t a purely transparent model as it provides the explanation after a decision has been made. Hence it can have wide range of applications as it isn\u2019t customized to one domain unlike RETAIN. For example for an image classification problem using a CNN, we get the probability distribution over classes. Then we make small changes to input to see how it affects the distribution and collect the results. Then using a linear interpretable model, on the collected perturbation set, we can explain changed in the key features extracted with their weights telling us how prominent they are. It blacks out different parts of the original image and feeds the resulting \u201cperturbed\u201d images back through the model, checking to see which perturbations throw the algorithm off the furthest to derive reasoning behind the algorithms decisions. For example, for an image of a tree frog, LIME found that erasing parts of the frog\u2019s face made it much harder for the model to identify the image, showing that much of the original classification decision was based on the frog\u2019s face. LIME is generally applicable to image classifications tasks.\n<p>In 2015, a black software developer <a href=\"https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/\">reported</a> that Google Photos labeled images of him and his black friend as \u201cgorillas.\u201d It\u2019s not hard to see how explanation techniques like LIME could mitigate this kind of bias by having a human operator override the decisions upon evaluating the reasons given by the algorithm.</p></li>\n<li><strong>Layer-wise Relevance Propagation (LRP)</strong>: This approach is based on the principles of redistribution and conservation. Here when we have an image and probability distribution of classes, we redistribute these to the input pixels, layer by layer. We can decide the relevance of inputs and features by going backwards using Deep CNN to extract relevant features before identifying similarity between the images in feature space. We try to infer pixel-level details of the images that may have significantly informed the model\u2019s choice.</li>\n</ul>\n<p><img alt=\"Explainable AI Figure 5\" class=\"size-full wp-image-89284 aligncenter\" sizes=\"(max-width: 503px) 100vw, 503px\" src=\"https://www.kdnuggets.com/wp-content/uploads/xai-fig5-equation.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/xai-fig5-equation.jpg 503w, https://www.kdnuggets.com/wp-content/uploads/xai-fig5-equation-300x81.jpg 300w\" width=\"50%\"/></p>\n<p>x_j\u200a\u2014\u200athe activation value for neuron j in layer l</p>\n<p>w_j,k\u200a\u2014\u200athe weighing of the connection between neuron j in layer l and neuron k in layer l + 1</p>\n<p>R_j\u200a\u2014\u200aRelevance scores for each neuron in layer l</p>\n<p>R_k\u200a\u2014\u200aRelevance scores for each neuron in layer l+1</p>\n<ul>\n<li><strong>BETA </strong>: BETA is closely connected to Interpretable Decision Sets. BETA learns a compact two-level decision set in which each rule explains part of the model behavior unambiguously. It uses a objective function so that the learning process is optimized for high fidelity (high agreement between explanation and the model), low unambiguity (little overlaps between decision rules in the explanation), and high interpretability (the explanation decision set is lightweight and small). These aspects are combined into one objection function to optimize for.</li>\n</ul>\n<p><strong>Explainability vs Accuracy</strong></p>\n<p>Will we need to \u2018dumb down\u2019 AI algorithms to make them explainable? Explainable models are easily understandable but don\u2019t work very well as they are simple. Accurate models work well but aren\u2019t explainable as they are complicated. The main issue with explainable AI is whether it can accurately fulfill the task it was designed for. The tradeoff decision to be made should depend on the application field of the algorithm and the end-user to whom its accountable.</p>\n<p>When dealing with technical users who are acquainted with the field and have high trust level, especially tech companies or researchers, having highly accurate models would be preferred over high explainability as performance is very important. But dealing with laymen users is a different scenario. It would be difficult to garner their trust. The machine learning approach is very different specially in banks, insurance companies, healthcare providers and other regulated industries. The reason is mainly that they are prone to <strong>legal or even ethical requirements</strong> which tend to limit more and more the use of black box models. Such institutions are answerable for their decisions and process and in this case a simple explainable albeit less efficient algorithm would do.</p>\n<p>Hence the tradeoff should be decided according to the application domain and the users concerned. If you want your system to be explainable, you\u2019re going to have to make do with a simpler system that isn\u2019t as powerful or accurate. Simple systems can give a prediction to the user but the ultimate action should be taken by the user. When performance matters most, even with a complicated model, opt for the trust that comes from making sure that you\u2019re able to verify that your system does, in fact, work.</p>\n<p><img alt=\"Xai Fig3 Accuracy Vs Explainability\" src=\"/images/xai-fig3-accuracy-vs-explainability-600.jpg\" width=\"100%\"/><br>\n<strong>Use Case : DARPA XAI</strong></br></p>\n<p>The Department of Defense (DoD) is increasingly investing in AI research in collaboration with technological giants like Google to have artificial intelligence programs for military activities. Due to ethical reasons, many government departments agree to have a \u201cman in the loop\u201d to control any lethal system of these \u201ckiller robots\u201d. Due to the increasing debates and strikes by the AI community to not contribute towards military AI, the DARPA division is pushing towards their $2 Billion Explainable Artificial Intelligence ( XAI ) program. XAI is their hope to usher in the third-wave AI systems which can understand the context in which they function and can characterize the real world phenomena. Its main aim is to:</p>\n<ul>\n<li>Explain the decisions and it\u2019s process</li>\n<li>Understand it\u2019s strength and weakness</li>\n<li>Convey how the system may behave in the future</li>\n</ul>\n<p><img alt=\"Xai Fig4 Darpa\" src=\"/images/xai-fig4-darpa-700.jpg\" width=\"100%\"/></p>\n<ul>\n<li>Offer insight on how to correct the mistakes</li>\n</ul>\n<p>The final goal of XAI is to have a toolkit library of ML and HCI modules for more understandable AI implementations. The Phase 1 of the project was completed in May 2018 and further advancements are expected in the coming years. In case of a gray area in decision output, XAI aims to give the analyst reasons for red flags upon which the analyst can act to make a decision using human input.</p>\n<p><strong>Conclusion</strong></p>\n<p>The success of AI models is due to the machines\u2019 own internal representations which are even more complicated then manually generated features leading to its inexplicable nature. There are a lot of on-going research on the ante-hoc and post-hoc methods to make the AI more answerable and awareness to inculcate these methods in existing programs. Good initiatives by leading institutions like DARPA, Google, DeepMind, etc. are leading the necessary change. Despite this, there will always be a tradeoff between explainability and accuracy whose balance depends on various factors like end-user, legal liability, technicality of the concerned parties and the field of application. Artificial intelligence should not become a powerful deity which we follow blindly without understanding its reasoning but we shouldn\u2019t forget about its beneficial insight it can have. Ideally, we should build flexible and interpretable models that can work in collaboration with experts and their domain knowledge.</p>\n<p><strong>References</strong></p>\n<ol>\n<li>LRP - <a href=\"https://arxiv.org/pdf/1807.06160.pdf\">https://arxiv.org/pdf/1807.06160.pdf</a></li>\n<li>DARPA XAI - <a href=\"https://www.darpa.mil/attachments/XAIProgramUpdate.pdf\">https://www.darpa.mil/attachments/XAIProgramUpdate.pdf</a></li>\n<li>XAI methods - https://medium.freecodecamp.org/an-introduction-to-explainable-ai-and-why-we-need-it-a326417dd000</li>\n</ol>\n<p><b>Bio</b>: <a href=\"https://www.linkedin.com/in/preetgandhi/\">Preet Gandhi</a> is a student at NYU and was a Data Science Intern at Apple Inc.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2018/12/explainable-ai-machine-learning.html\">A Case For Explainable AI &amp; Machine Learning</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html\">Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/four-approaches-ai-machine-learning.html\">Four Approaches to Explaining AI and Machine Learning</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}