{"content": "By Matthew Mayo , KDnuggets. Traditionally (whatever that means in this context), machine learning has been executed in single processor environments, where algorithmic bottlenecks can lead to substantial delays in model processing, from training, to classification, to distance and error calculations, and beyond. Beyond recent technology-harnessing in neural networking training, much of machine learning - including both off-the-shelf libraries like scikit-learn and DIY algorithm implementation - has been approached without the use of parallel processing. The lack of parallel processing, in this context referring to parallel execution on a shared-memory architecture, inhibits the potential exploitation of large numbers of concurrently-executing threads performing independent tasks in order to achieve economy of performance. The dearth of parallelism is attributable to all sorts of reasons, not the least of which being that parallel programming is hard . It really is . Fig. 1: Parallel Problem Overview. Also, parallel processing is not magic, and cannot \"just be used\" in every situation; there are both practical and theoretical algorithmic design issues that must be considered when even thinking about incorporating parallel processing into a project. However, with Big Data encompassing such large amounts of data, sets of which are increasingly being relied upon for routine machine learning tasks, the trouble associated with parallelism may very well be worth it in a given situation due solely to the potential of dramatic time-savings related to algorithm execution. General Purpose Computing on Graphics Processing Units \u00a0 A contemporary favorite for parallelism in appropriate situations , and focus of this article, is utilizing general purpose computing on graphics processing units (GPGPU) , a strategy exploiting the numerous processing cores found on high-end modern graphics processing units (GPUs) for the simultaneous execution of computationally expensive tasks. While not all machine learning tasks, or any other collection of software tasks for that matter, can benefit from GPGPU, there are undoubtedly numerous computationally expensive and time-monopolizing tasks to which GPGPU could be an asset. Modifying algorithms to allow certain of their tasks to take advantage of GPU parallelization can demonstrate noteworthy gains in both task performance and completion speed. Fig. 2: Flynn's Taxonomy. The GPGPU paradigm fits into Flynn\u2019s taxonomy as single program, multiple data (SPMD) architecture, which differs from from the traditional multicore CPU computing paradigm. Fig. 3: Single Program Multiple Data (SPMD) subdivision of MIMD. It should be noted that, while these modifications would undoubtedly benefit the processing of the very large datasets which are the very definition of Big Data, their implementation could have a positive effect on much smaller sets of data as well. A number of particular machine learning tasks can be computationally expensive and time-consuming regardless of data size. Parallelizing those which are not necessarily required to be executed in serial could potentially lead to gains for small datasets as well. Machine learning algorithms could also see performance gains by parallelizing common tasks which may be shared among numerous algorithms, such as performing matrix multiplication, which is used by several classification, regression, and clustering techniques, including, of particular interest, linear regression. An interesting sidenote relates to the theoretical expected speedup in task execution latency. Amdahl's Law states that the theoretical speedup of an entire task's execution increases with the incremental improvement of each system resource. However, regardless of the collective improvement's magnitude, theoretical speedup is limited by the consitutent task which cannot benefit from parallel improvements, or improves the least. The chain is only as strong (fast) as its weakest (slowest) link. For an in-depth introductory treatment of generalized parallel computing, read this . CUDA Parallel Programming Framework \u00a0 The CUDA parallel programming framework from NVIDIA is a particular implementation of the GPGPU paradigm. CUDA once was an acronym for Compute Unified Device Architecture, but NVIDIA dropped the expansion and now just uses CUDA. This architecture, facilitating our machine learning parallelization via GPU acceleration (another way to refer to GPGPU), requires particular consideration in order to effectively manage available resources and provide the maximum execution speed benefit. CUDA is technically a heterogeneous computing environment, meaning that it facilitates coordinated computing on both CPUs and GPUs. The CUDA architecture consists of hosts and devices, with host referring to a traditional CPU, and device referencing processors with large numbers of arithmetic units, typically GPUs. CUDA provides extensions to traditional programming languages (the native CUDA bindings are C, but have been ported or made otherwise available to many additional languages), enabling the creation of kernels , which are parallel-executing functions. A kernel, when launched, gets simultaneously executed by a large number of CUDA device threads , a collection of which are referred to as a block of threads, blocks being collected into grids . Threads are arranged in 3-dimensional layouts within blocks, which are, in turn, arranged in 3-dimensional layouts within grids. Figure 4 demonstrates these relationships and layouts. The total number of threads, blocks, and grids employed by a particular kernel are strategically dictated by a programmer\u2019s code executing on the host at kernel launch, based on given situational requirements.", "title_html": "<h1 id=\"title\">Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications</h1> ", "url": "https://www.kdnuggets.com/2016/11/parallelism-machine-learning-gpu-cuda-threading.html", "tfidf": {"tfidf": {"base": 1.14628158845, "relat": 2.47501753838, "matthew": 6.908616187989999, "onc": 1.4974533106999999, "this": 5.0189681335500005, "troubl": 4.99088337001, "fit": 3.37070063694, "launch": 5.132880698359999, "subdivis": 20.511627907, "bind": 11.874345549700001, "delay": 4.23247134098, "maximum": 4.80072573329, "addit": 1.24634950542, "way": 1.2190739461, "sharedmemori": 1443.27272727, "routin": 7.997984886649999, "much": 2.3884459154599997, "includ": 2.0381282495599997, "parallel": 82.42515142776, "the": 30.0, "dataset": 387.219512196, "about": 1.06486015159, "function": 2.495441685, "parallelexecut": 1443.27272727, "neural": 59.4606741573, "increment": 31.8795180723, "context": 8.51945264288, "just": 2.67160286074, "flynn": 104.79207920799999, "devic": 20.03280757096, "resourc": 5.8974739970200005, "offtheshelf": 1443.27272727, "otherwis": 3.72151898734, "creation": 3.0601387818, "complet": 1.24021560816, "approach": 2.07556543339, "technic": 3.1400316455699997, "upon": 1.60331246213, "collect": 6.56439942112, "expens": 10.635998213490002, "where": 1.06715063521, "train": 3.8731397901999998, "particular": 6.9074138531000004, "environ": 6.87123999134, "least": 3.2330719886000003, "their": 2.0309581681, "multipl": 8.24441751774, "among": 1.25670862028, "noteworthi": 27.0, "articl": 2.01805008262, "enabl": 3.5421686747, "singl": 4.82846715327, "speed": 7.740614334480001, "increas": 2.6404989605, "execut": 22.363713199, "order": 2.49250333622, "due": 1.23789473684, "referenc": 14.0994671403, "found": 1.11387076405, "given": 2.70852170946, "modif": 9.5753920386, "heterogen": 52.0524590164, "overview": 12.6805111821, "mani": 1.04426757877, "thread": 121.1908396945, "associ": 1.3263157894700002, "exploit": 11.58832116788, "theoret": 31.34452122408, "consid": 1.2397313759200002, "recent": 1.54405757635, "unit": 4.61578717836, "provid": 2.43105428374, "purpos": 4.46833661694, "algorithm": 195.6549295778, "incorpor": 2.62847682119, "linear": 13.8776223776, "timemonopol": 1443.27272727, "perform": 7.6569885212500015, "but": 2.03264835798, "demonstr": 5.29994992488, "definit": 3.24, "our": 2.35758835759, "classif": 16.134146341460003, "arrang": 5.767847411440001, "arithmet": 38.911764705900005, "expect": 2.20011086475, "matrix": 22.6153846154, "num": 4.00126016004, "modifi": 4.45329593268, "slowest": 200.962025316, "port": 3.9443478260900005, "concurrentlyexecut": 1443.27272727, "big": 5.480151881259999, "has": 2.0872995004, "have": 2.0297896822799997, "introductori": 30.297709923699998, "read": 2.3149606299200003, "take": 1.13961668222, "advantag": 3.32412060302, "would": 1.0828729281799998, "timeconsum": 1443.27272727, "block": 12.81097437968, "strategi": 4.44208170118, "paradigm": 72.8256880734, "code": 3.8807137619199996, "hard": 2.73253012048, "model": 2.0905978404, "technologyhar": 1443.27272727, "regress": 102.4258064516, "realli": 4.7476076555, "number": 5.50714583045, "note": 1.42449528937, "issu": 1.43921675279, "numer": 5.49976905312, "also": 2.02953020134, "cpus": 174.46153846200002, "typic": 2.2541530597799997, "reason": 1.72340425532, "modern": 1.5319888063299998, "mean": 2.89813800658, "not": 6.09404388714, "acceler": 8.15408320493, "necessarili": 7.33302540416, "task": 50.52337821297, "law": 1.7973508434299998, "numdimension": 2886.54545454, "magnitud": 15.6568047337, "may": 2.10403551786, "consitut": 1443.27272727, "mayo": 49.7680250784, "comput": 39.277585353800006, "unifi": 7.60709151893, "which": 12.06230214, "speedup": 2268.0, "via": 2.2978723404299997, "programm": 5.181462140990001, "amount": 2.27027027027, "expans": 3.4770039421800005, "util": 4.65981802172, "problem": 1.76674827509, "graphic": 27.107569721130005, "design": 1.45825296225, "anoth": 1.13643521832, "core": 4.623179965059999, "extens": 1.99171998495, "howev": 2.1890382626599996, "effect": 2.7926121372000003, "allow": 1.2716059271100002, "attribut": 3.4156626506, "kdnugget": 1443.27272727, "employ": 2.16530278232, "reli": 4.16146788991, "scikitlearn": 1443.27272727, "dearth": 168.893617021, "encompass": 8.02628918099, "bottleneck": 90.72, "practic": 1.70434782609, "tradit": 6.4320875114, "lack": 1.9271667880599999, "asset": 8.63295269168, "other": 1.00992366412, "refer": 5.200982801, "techniqu": 3.7293868921800004, "calcul": 6.12972972973, "consist": 1.4901445466499998, "timesav": 1443.27272727, "coordin": 5.65586034913, "softwar": 10.2624434389, "see": 1.27242125511, "should": 1.6643254009900001, "regardless": 12.70588235294, "such": 2.12302754748, "sever": 1.07241286139, "those": 1.19548192771, "get": 1.78562591385, "network": 2.59369384088, "like": 1.14918566775, "implement": 10.729443568379999, "fast": 4.8729281768, "manag": 1.6448404475799998, "beyond": 5.09172546504, "small": 1.3594793629, "drop": 2.4594887684, "both": 4.20862880244, "processor": 75.961722488, "dictat": 9.28964306612, "process": 16.9524826482, "turn": 1.3838912133899999, "highend": 1443.27272727, "inhibit": 25.160063391399998, "entir": 1.59365589239, "interest": 3.20662492426, "think": 2.90715986083, "sole": 4.04175152749, "well": 3.1967246123999997, "sidenot": 1443.27272727, "languag": 4.58976582828, "grid": 54.369863013599996, "ani": 1.13383802314, "amdahl": 1443.27272727, "and": 17.00107086621, "from": 6.00340328982, "limit": 1.5186531471200002, "smaller": 2.59369384088, "project": 1.7534791252500002, "differ": 1.23654490225, "been": 3.0717832957199995, "independ": 1.58950740889, "facilit": 12.907317073180002, "indepth": 1443.27272727, "magic": 7.9063745019899985, "strateg": 5.67, "certain": 1.8077886586200003, "for": 7.00220528007, "economi": 3.6446280991699997, "contemporari": 2.835, "all": 2.02293577982, "with": 5.005991044949999, "requir": 4.58534706846, "program": 12.12834224598, "strong": 1.6439888163999998, "there": 2.08182533438, "are": 11.32896529358, "layout": 45.102272727300004, "taxonomi": 149.7735849056, "appropri": 4.31413043478, "nativ": 3.00738776283, "distanc": 3.4754816112099998, "that": 7.0278884462499995, "sort": 5.188235294119999, "architectur": 25.6395348837, "undoubt": 54.0919931856, "relationship": 2.39132399458, "cluster": 12.5007874016, "improv": 8.17507723996, "veri": 3.77640342531, "favorit": 8.116564417180001, "system": 1.38739840951, "achiev": 1.87216981132, "these": 2.14830852504, "whatev": 7.6473988439300005, "benefit": 12.27367607268, "posit": 1.37252528746, "gain": 5.54458672875, "general": 3.3654607122600004, "made": 1.07038834951, "latenc": 174.46153846200002, "treatment": 3.87125091441, "focus": 2.01012914662, "lead": 2.5328653478, "weakest": 68.72727272729999, "state": 1.0477133240899998, "simultan": 10.6586102719, "can": 7.05756834852, "avail": 3.4576935642, "could": 4.8174783796, "set": 2.37415881562, "total": 1.5460122699399999, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "situat": 8.26444560124, "now": 1.160780873, "serial": 11.3643521832, "kernel": 282.24, "error": 6.04109589041, "framework": 16.400826446279996, "link": 2.15151104486, "common": 1.4025974025999999, "chain": 5.17639387023, "librari": 2.68266306185, "data": 23.63504891538, "matter": 2.44773358002, "machin": 28.170342205319997, "into": 3.04507384437, "acronym": 35.0463576159, "must": 1.9220338983099996, "substanti": 3.4777656078900003, "worth": 5.210370856580001, "potenti": 7.56240076215, "gpus": 3175.2000000000003, "figur": 2.0343413634, "everi": 1.47917637194, "share": 1.8566249561500001, "use": 4.1185550295199995, "fig": 163.6701030927, "while": 2.0883977900599997, "dramat": 3.9849397590400004, "multicor": 1443.27272727, "host": 8.127645051179998, "without": 1.29547123623, "larg": 5.928747479249999, "within": 2.4738605376, "learn": 16.259253840550002, "consider": 2.29920347574, "when": 2.0415353951, "even": 1.16461267606}, "logtfidf": {"base": 0.13652330228700002, "relat": 0.42620060330799997, "matthew": 1.9327693554900003, "onc": 0.403765872355, "this": 0.0189322452625, "troubl": 1.60761292215, "fit": 1.2151206268899999, "launch": 1.885039721316, "subdivis": 3.0209919403099996, "bind": 2.4743802368, "delay": 1.44278606382, "maximum": 1.5687671009200002, "addit": 0.220218882972, "way": 0.19809150993500002, "sharedmemori": 7.2746685411000005, "routin": 2.07918962078, "much": 0.35499145860200004, "includ": 0.037769362781, "parallel": 27.38733962796, "the": 0.0, "dataset": 10.53168913328, "about": 0.0628434774746, "function": 0.914465741594, "parallelexecut": 7.2746685411000005, "neural": 4.0853151555, "increment": 3.46196373688, "context": 2.89840982884, "just": 0.579062868218, "flynn": 7.91766201678, "devic": 6.444307788119999, "resourc": 2.16275388516, "offtheshelf": 7.2746685411000005, "otherwis": 1.3141319148700001, "creation": 1.11846026847, "complet": 0.215285242047, "approach": 0.7302336145810001, "technic": 1.14423287808, "upon": 0.47207177798199995, "collect": 1.98146664208, "expens": 3.79689605022, "where": 0.0649921387457, "train": 1.321836625678, "particular": 1.61578696902, "environ": 2.4683948060599996, "least": 0.96057116949, "their": 0.030721010245400002, "multipl": 3.0327720543600005, "among": 0.228496097073, "noteworthi": 3.295836866, "articl": 0.702131739574, "enabl": 1.26473915954, "singl": 1.427750307177, "speed": 2.7066677505400003, "increas": 0.555641437858, "execut": 8.04854605864, "order": 0.44028076158600005, "due": 0.21341214386399998, "referenc": 2.6461370052, "found": 0.107841124048, "given": 0.606511621662, "modif": 2.25919647821, "heterogen": 3.9522520373, "overview": 2.54006626224, "mani": 0.0433157581221, "thread": 15.939642891350001, "associ": 0.28240501535100004, "exploit": 3.5137012290400005, "theoret": 8.23498051636, "consid": 0.214894723824, "recent": 0.434413741288, "unit": 0.572752247268, "provid": 0.39035568865000003, "purpos": 1.607738074644, "algorithm": 23.31309676626, "incorpor": 0.9664045229739999, "linear": 2.63027764196, "timemonopol": 7.2746685411000005, "perform": 2.1309042528999997, "but": 0.0323847441438, "demonstr": 1.9491003836379999, "definit": 1.1755733298, "our": 0.8576392141820001, "classif": 4.17558147258, "arrang": 2.1183035295, "arithmet": 3.6612966394999997, "expect": 0.78850775216, "matrix": 3.1186304098799997, "num": 0.0012599615815880002, "modifi": 1.4936444810499998, "slowest": 5.30311596144, "port": 1.37228362405, "concurrentlyexecut": 7.2746685411000005, "big": 2.01597127114, "has": 0.0854478897096, "have": 0.0295700046824, "introductori": 3.41107212958, "read": 0.83939268088, "take": 0.130691962197, "advantag": 1.20120515883, "would": 0.0796176279647, "timeconsum": 7.2746685411000005, "block": 4.65603126352, "strategi": 1.49112311818, "paradigm": 9.56836938735, "code": 1.35601909597, "hard": 1.00522796406, "model": 0.7374500731110001, "technologyhar": 7.2746685411000005, "regress": 7.871983032839999, "realli": 1.5576408397, "number": 0.483042892093, "note": 0.353817568083, "issu": 0.364099043934, "numer": 1.818281437038, "also": 0.0293143156, "cpus": 5.16170430739, "typic": 0.812774319158, "reason": 0.544301552962, "modern": 0.426566764719, "mean": 0.74184256704, "not": 0.093314478045, "acceler": 2.0985188085299997, "necessarili": 1.99238817347, "task": 17.64732848593, "law": 0.5863138271580001, "numdimension": 14.549337082200001, "magnitud": 2.75090562975, "may": 0.10141999056880001, "consitut": 7.2746685411000005, "mayo": 3.90737271112, "comput": 13.6806891594, "unifi": 2.02908090683, "which": 0.06214096614516, "speedup": 19.88412412854, "via": 0.831983625414, "programm": 1.6450872830399998, "amount": 0.819898886199, "expans": 1.2461709868100002, "util": 1.5389763962399998, "problem": 0.569140724273, "graphic": 6.603602177160001, "design": 0.377239118022, "anoth": 0.127896361652, "core": 1.53108277245, "extens": 0.6889985794750001, "howev": 0.180630234695, "effect": 0.667660454316, "allow": 0.24028061118900002, "attribut": 1.2283715153700001, "kdnugget": 7.2746685411000005, "employ": 0.7725602049429999, "reli": 1.42586787018, "scikitlearn": 7.2746685411000005, "dearth": 5.129269031630001, "encompass": 2.08272230172, "bottleneck": 4.50777783998, "practic": 0.533182530867, "tradit": 1.9000191051679998, "lack": 0.656050938907, "asset": 2.1555865893, "other": 0.00987474791976, "refer": 1.050212987192, "techniqu": 1.31624384807, "calcul": 1.8131506592099997, "consist": 0.398873126426, "timesav": 7.2746685411000005, "coordin": 1.73269223754, "softwar": 2.32849096333, "see": 0.240921585492, "should": 0.509419876758, "regardless": 3.6978357661400003, "such": 0.119391955612, "sever": 0.06991112039689999, "those": 0.17854939087299998, "get": 0.579769005782, "network": 0.9530830530519999, "like": 0.139053576545, "implement": 3.8231382272100003, "fast": 1.5836950247400001, "manag": 0.497643387158, "beyond": 1.86893916745, "small": 0.307101805059, "drop": 0.8999535106219999, "both": 0.20337013355720002, "processor": 7.27416476276, "dictat": 2.22890013079, "process": 5.2782919902500005, "turn": 0.324899251064, "highend": 7.2746685411000005, "inhibit": 3.2252579513599997, "entir": 0.46603068026999994, "interest": 0.9441435559639999, "think": 1.06717661175, "sole": 1.3966781444299998, "well": 0.1905433149468, "sidenot": 7.2746685411000005, "languag": 1.6613636488119998, "grid": 8.69159316891, "ani": 0.125608358366, "amdahl": 7.2746685411000005, "and": 0.0010708324150812, "from": 0.0034023250131959997, "limit": 0.41782385463, "smaller": 0.9530830530519999, "project": 0.561601885907, "differ": 0.212321121312, "been": 0.07093794710520002, "independ": 0.463424162503, "facilit": 3.72929436996, "indepth": 7.2746685411000005, "magic": 2.06766933309, "strateg": 1.7351891177400003, "certain": 0.592104362781, "for": 0.0022049327677790003, "economi": 1.2932543298499999, "contemporari": 1.04204193718, "all": 0.022805264195599997, "with": 0.00598745856695, "requir": 1.272760532025, "program": 4.22271347259, "strong": 0.49712549393600003, "there": 0.080195785851, "are": 0.3241422094097, "layout": 8.13096104892, "taxonomi": 8.63195507846, "appropri": 1.4618957827399999, "nativ": 1.10107184908, "distanc": 1.24573306257, "that": 0.02783303865748, "sort": 1.64639361896, "architectur": 8.17348789595, "undoubt": 6.59507798814, "relationship": 0.871847185184, "cluster": 2.52579163445, "improv": 2.8591832157279997, "veri": 0.6904793797140001, "favorit": 2.09390696331, "system": 0.327430345585, "achiev": 0.6270980851169999, "these": 0.1430672388016, "whatev": 2.0343655696200003, "benefit": 4.48464980464, "posit": 0.316652318608, "gain": 1.8426293967749998, "general": 0.344857734189, "made": 0.0680215260973, "latenc": 5.16170430739, "treatment": 1.3535776885100002, "focus": 0.6981989720559999, "lead": 0.47240805973399996, "weakest": 4.230146103380001, "state": 0.0466100027668, "simultan": 3.34644172238, "can": 0.974046578364, "avail": 1.094909172578, "could": 0.7438250891600001, "set": 0.342992022578, "total": 0.43567888670500005, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "situat": 2.90267316006, "now": 0.149092945021, "serial": 2.43048145465, "kernel": 17.0258536468, "error": 1.7985854343, "framework": 4.20836909214, "link": 0.7661704068449999, "common": 0.338325805271, "chain": 1.64410864979, "librari": 0.986809980943, "data": 8.5177440936, "matter": 0.8951625270360001, "machin": 9.74651706434, "into": 0.0447385896861, "acronym": 3.5566716884199994, "must": 0.653383947388, "substanti": 1.24639002087, "worth": 1.65065103492, "potenti": 2.773729236726, "gpus": 20.8935408384, "figur": 0.7101721121600001, "everi": 0.391485427421, "share": 0.618760299747, "use": 0.1168320789264, "fig": 11.99772164019, "while": 0.08649996758760002, "dramat": 1.3825221952000002, "multicor": 7.2746685411000005, "host": 2.989976793996, "without": 0.258874517941, "larg": 0.8518753030300001, "within": 0.42526544119599996, "learn": 5.899264453215, "consider": 0.8325627480600001, "when": 0.0411099777168, "even": 0.152388564834}, "logidf": {"base": 0.13652330228700002, "relat": 0.21310030165399999, "matthew": 1.9327693554900003, "onc": 0.403765872355, "this": 0.0037864490525, "troubl": 1.60761292215, "fit": 1.2151206268899999, "launch": 0.942519860658, "subdivis": 3.0209919403099996, "bind": 2.4743802368, "delay": 1.44278606382, "maximum": 1.5687671009200002, "addit": 0.220218882972, "way": 0.19809150993500002, "sharedmemori": 7.2746685411000005, "routin": 2.07918962078, "much": 0.17749572930100002, "includ": 0.0188846813905, "parallel": 1.52151886822, "the": 0.0, "dataset": 5.26584456664, "about": 0.0628434774746, "function": 0.914465741594, "parallelexecut": 7.2746685411000005, "neural": 4.0853151555, "increment": 3.46196373688, "context": 1.44920491442, "just": 0.289531434109, "flynn": 3.95883100839, "devic": 1.6110769470299997, "resourc": 1.08137694258, "offtheshelf": 7.2746685411000005, "otherwis": 1.3141319148700001, "creation": 1.11846026847, "complet": 0.215285242047, "approach": 0.7302336145810001, "technic": 1.14423287808, "upon": 0.47207177798199995, "collect": 0.49536666052, "expens": 1.26563201674, "where": 0.0649921387457, "train": 0.660918312839, "particular": 0.323157393804, "environ": 1.2341974030299998, "least": 0.480285584745, "their": 0.015360505122700001, "multipl": 1.01092401812, "among": 0.228496097073, "noteworthi": 3.295836866, "articl": 0.702131739574, "enabl": 1.26473915954, "singl": 0.475916769059, "speed": 1.3533338752700002, "increas": 0.277820718929, "execut": 0.804854605864, "order": 0.22014038079300002, "due": 0.21341214386399998, "referenc": 2.6461370052, "found": 0.107841124048, "given": 0.303255810831, "modif": 2.25919647821, "heterogen": 3.9522520373, "overview": 2.54006626224, "mani": 0.0433157581221, "thread": 3.18792857827, "associ": 0.28240501535100004, "exploit": 1.7568506145200002, "theoret": 2.05874512909, "consid": 0.214894723824, "recent": 0.434413741288, "unit": 0.143188061817, "provid": 0.19517784432500002, "purpos": 0.803869037322, "algorithm": 3.33044239518, "incorpor": 0.9664045229739999, "linear": 2.63027764196, "timemonopol": 7.2746685411000005, "perform": 0.42618085058, "but": 0.0161923720719, "demonstr": 0.9745501918189999, "definit": 1.1755733298, "our": 0.8576392141820001, "classif": 2.08779073629, "arrang": 1.05915176475, "arithmet": 3.6612966394999997, "expect": 0.78850775216, "matrix": 3.1186304098799997, "num": 0.00031499039539700004, "modifi": 1.4936444810499998, "slowest": 5.30311596144, "port": 1.37228362405, "concurrentlyexecut": 7.2746685411000005, "big": 1.00798563557, "has": 0.0427239448548, "have": 0.0147850023412, "introductori": 3.41107212958, "read": 0.83939268088, "take": 0.130691962197, "advantag": 1.20120515883, "would": 0.0796176279647, "timeconsum": 7.2746685411000005, "block": 1.16400781588, "strategi": 1.49112311818, "paradigm": 3.18945646245, "code": 1.35601909597, "hard": 1.00522796406, "model": 0.7374500731110001, "technologyhar": 7.2746685411000005, "regress": 3.9359915164199997, "realli": 1.5576408397, "number": 0.0966085784186, "note": 0.353817568083, "issu": 0.364099043934, "numer": 0.606093812346, "also": 0.0146571578, "cpus": 5.16170430739, "typic": 0.812774319158, "reason": 0.544301552962, "modern": 0.426566764719, "mean": 0.37092128352, "not": 0.0155524130075, "acceler": 2.0985188085299997, "necessarili": 1.99238817347, "task": 1.35748680661, "law": 0.5863138271580001, "numdimension": 7.2746685411000005, "magnitud": 2.75090562975, "may": 0.050709995284400004, "consitut": 7.2746685411000005, "mayo": 3.90737271112, "comput": 1.36806891594, "unifi": 2.02908090683, "which": 0.00517841384543, "speedup": 6.6280413761800006, "via": 0.831983625414, "programm": 1.6450872830399998, "amount": 0.819898886199, "expans": 1.2461709868100002, "util": 1.5389763962399998, "problem": 0.569140724273, "graphic": 2.20120072572, "design": 0.377239118022, "anoth": 0.127896361652, "core": 1.53108277245, "extens": 0.6889985794750001, "howev": 0.0903151173475, "effect": 0.333830227158, "allow": 0.24028061118900002, "attribut": 1.2283715153700001, "kdnugget": 7.2746685411000005, "employ": 0.7725602049429999, "reli": 1.42586787018, "scikitlearn": 7.2746685411000005, "dearth": 5.129269031630001, "encompass": 2.08272230172, "bottleneck": 4.50777783998, "practic": 0.533182530867, "tradit": 0.47500477629199994, "lack": 0.656050938907, "asset": 2.1555865893, "other": 0.00987474791976, "refer": 0.262553246798, "techniqu": 1.31624384807, "calcul": 1.8131506592099997, "consist": 0.398873126426, "timesav": 7.2746685411000005, "coordin": 1.73269223754, "softwar": 2.32849096333, "see": 0.240921585492, "should": 0.509419876758, "regardless": 1.8489178830700002, "such": 0.059695977806, "sever": 0.06991112039689999, "those": 0.17854939087299998, "get": 0.579769005782, "network": 0.9530830530519999, "like": 0.139053576545, "implement": 1.27437940907, "fast": 1.5836950247400001, "manag": 0.497643387158, "beyond": 0.934469583725, "small": 0.307101805059, "drop": 0.8999535106219999, "both": 0.050842533389300004, "processor": 3.63708238138, "dictat": 2.22890013079, "process": 0.527829199025, "turn": 0.324899251064, "highend": 7.2746685411000005, "inhibit": 3.2252579513599997, "entir": 0.46603068026999994, "interest": 0.47207177798199995, "think": 1.06717661175, "sole": 1.3966781444299998, "well": 0.0635144383156, "sidenot": 7.2746685411000005, "languag": 0.8306818244059999, "grid": 2.89719772297, "ani": 0.125608358366, "amdahl": 7.2746685411000005, "and": 6.29901420636e-05, "from": 0.000567054168866, "limit": 0.41782385463, "smaller": 0.9530830530519999, "project": 0.561601885907, "differ": 0.212321121312, "been": 0.023645982368400004, "independ": 0.463424162503, "facilit": 1.86464718498, "indepth": 7.2746685411000005, "magic": 2.06766933309, "strateg": 1.7351891177400003, "certain": 0.592104362781, "for": 0.00031499039539700004, "economi": 1.2932543298499999, "contemporari": 1.04204193718, "all": 0.011402632097799998, "with": 0.00119749171339, "requir": 0.424253510675, "program": 0.7037855787649999, "strong": 0.49712549393600003, "there": 0.0400978929255, "are": 0.0294674735827, "layout": 2.71032034964, "taxonomi": 4.31597753923, "appropri": 1.4618957827399999, "nativ": 1.10107184908, "distanc": 1.24573306257, "that": 0.00397614837964, "sort": 1.64639361896, "architectur": 1.63469757919, "undoubt": 3.29753899407, "relationship": 0.871847185184, "cluster": 2.52579163445, "improv": 0.7147958039319999, "veri": 0.230159793238, "favorit": 2.09390696331, "system": 0.327430345585, "achiev": 0.6270980851169999, "these": 0.0715336194008, "whatev": 2.0343655696200003, "benefit": 1.12116245116, "posit": 0.316652318608, "gain": 0.6142097989249999, "general": 0.114952578063, "made": 0.0680215260973, "latenc": 5.16170430739, "treatment": 1.3535776885100002, "focus": 0.6981989720559999, "lead": 0.23620402986699998, "weakest": 4.230146103380001, "state": 0.0466100027668, "simultan": 1.67322086119, "can": 0.162341096394, "avail": 0.547454586289, "could": 0.18595627229000003, "set": 0.171496011289, "total": 0.43567888670500005, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "situat": 0.725668290015, "now": 0.149092945021, "serial": 2.43048145465, "kernel": 4.2564634117, "error": 1.7985854343, "framework": 2.10418454607, "link": 0.7661704068449999, "common": 0.338325805271, "chain": 1.64410864979, "librari": 0.986809980943, "data": 1.2168205848, "matter": 0.8951625270360001, "machin": 1.39235958062, "into": 0.0149128632287, "acronym": 3.5566716884199994, "must": 0.653383947388, "substanti": 1.24639002087, "worth": 1.65065103492, "potenti": 0.9245764122419999, "gpus": 6.964513612799999, "figur": 0.7101721121600001, "everi": 0.391485427421, "share": 0.618760299747, "use": 0.0292080197316, "fig": 3.9992405467300003, "while": 0.04324998379380001, "dramat": 1.3825221952000002, "multicor": 7.2746685411000005, "host": 0.996658931332, "without": 0.258874517941, "larg": 0.17037506060600002, "within": 0.21263272059799998, "learn": 0.842752064745, "consider": 0.8325627480600001, "when": 0.0205549888584, "even": 0.152388564834}, "freq": {"base": 1, "relat": 2, "matthew": 1, "onc": 1, "this": 5, "troubl": 1, "fit": 1, "launch": 2, "subdivis": 1, "bind": 1, "delay": 1, "maximum": 1, "addit": 1, "way": 1, "sharedmemori": 1, "routin": 1, "much": 2, "includ": 2, "parallel": 18, "the": 30, "dataset": 2, "about": 1, "function": 1, "parallelexecut": 1, "neural": 1, "increment": 1, "context": 2, "just": 2, "flynn": 2, "devic": 4, "resourc": 2, "offtheshelf": 1, "otherwis": 1, "creation": 1, "complet": 1, "approach": 1, "technic": 1, "upon": 1, "collect": 4, "expens": 3, "where": 1, "train": 2, "particular": 5, "environ": 2, "least": 2, "their": 2, "multipl": 3, "among": 1, "noteworthi": 1, "articl": 1, "enabl": 1, "singl": 3, "speed": 2, "increas": 2, "execut": 10, "order": 2, "due": 1, "referenc": 1, "found": 1, "given": 2, "modif": 1, "heterogen": 1, "overview": 1, "mani": 1, "thread": 5, "associ": 1, "exploit": 2, "theoret": 4, "consid": 1, "recent": 1, "unit": 4, "provid": 2, "purpos": 2, "algorithm": 7, "incorpor": 1, "linear": 1, "timemonopol": 1, "perform": 5, "but": 2, "demonstr": 2, "definit": 1, "our": 1, "classif": 2, "arrang": 2, "arithmet": 1, "expect": 1, "matrix": 1, "num": 4, "modifi": 1, "slowest": 1, "port": 1, "concurrentlyexecut": 1, "big": 2, "has": 2, "have": 2, "introductori": 1, "read": 1, "take": 1, "advantag": 1, "would": 1, "timeconsum": 1, "block": 4, "strategi": 1, "paradigm": 3, "code": 1, "hard": 1, "model": 1, "technologyhar": 1, "regress": 2, "realli": 1, "number": 5, "note": 1, "issu": 1, "numer": 3, "also": 2, "cpus": 1, "typic": 1, "reason": 1, "modern": 1, "mean": 2, "not": 6, "acceler": 1, "necessarili": 1, "task": 13, "law": 1, "numdimension": 2, "magnitud": 1, "may": 2, "consitut": 1, "mayo": 1, "comput": 10, "unifi": 1, "which": 12, "speedup": 3, "via": 1, "programm": 1, "amount": 1, "expans": 1, "util": 1, "problem": 1, "graphic": 3, "design": 1, "anoth": 1, "core": 1, "extens": 1, "howev": 2, "effect": 2, "allow": 1, "attribut": 1, "kdnugget": 1, "employ": 1, "reli": 1, "scikitlearn": 1, "dearth": 1, "encompass": 1, "bottleneck": 1, "practic": 1, "tradit": 4, "lack": 1, "asset": 1, "other": 1, "refer": 4, "techniqu": 1, "calcul": 1, "consist": 1, "timesav": 1, "coordin": 1, "softwar": 1, "see": 1, "should": 1, "regardless": 2, "such": 2, "sever": 1, "those": 1, "get": 1, "network": 1, "like": 1, "implement": 3, "fast": 1, "manag": 1, "beyond": 2, "small": 1, "drop": 1, "both": 4, "processor": 2, "dictat": 1, "process": 10, "turn": 1, "highend": 1, "inhibit": 1, "entir": 1, "interest": 2, "think": 1, "sole": 1, "well": 3, "sidenot": 1, "languag": 2, "grid": 3, "ani": 1, "amdahl": 1, "and": 17, "from": 6, "limit": 1, "smaller": 1, "project": 1, "differ": 1, "been": 3, "independ": 1, "facilit": 2, "indepth": 1, "magic": 1, "strateg": 1, "certain": 1, "for": 7, "economi": 1, "contemporari": 1, "all": 2, "with": 5, "requir": 3, "program": 6, "strong": 1, "there": 2, "are": 11, "layout": 3, "taxonomi": 2, "appropri": 1, "nativ": 1, "distanc": 1, "that": 7, "sort": 1, "architectur": 5, "undoubt": 2, "relationship": 1, "cluster": 1, "improv": 4, "veri": 3, "favorit": 1, "system": 1, "achiev": 1, "these": 2, "whatev": 1, "benefit": 4, "posit": 1, "gain": 3, "general": 3, "made": 1, "latenc": 1, "treatment": 1, "focus": 1, "lead": 2, "weakest": 1, "state": 1, "simultan": 2, "can": 6, "avail": 2, "could": 4, "set": 2, "total": 1, "onli": 1, "each": 1, "size": 1, "situat": 4, "now": 1, "serial": 1, "kernel": 4, "error": 1, "framework": 2, "link": 1, "common": 1, "chain": 1, "librari": 1, "data": 7, "matter": 1, "machin": 7, "into": 3, "acronym": 1, "must": 1, "substanti": 1, "worth": 1, "potenti": 3, "gpus": 3, "figur": 1, "everi": 1, "share": 1, "use": 4, "fig": 3, "while": 2, "dramat": 1, "multicor": 1, "host": 3, "without": 1, "larg": 5, "within": 2, "learn": 7, "consider": 1, "when": 2, "even": 1}, "idf": {"base": 1.14628158845, "relat": 1.23750876919, "matthew": 6.908616187989999, "onc": 1.4974533106999999, "this": 1.00379362671, "troubl": 4.99088337001, "fit": 3.37070063694, "launch": 2.5664403491799996, "subdivis": 20.511627907, "bind": 11.874345549700001, "delay": 4.23247134098, "maximum": 4.80072573329, "addit": 1.24634950542, "way": 1.2190739461, "sharedmemori": 1443.27272727, "routin": 7.997984886649999, "much": 1.1942229577299999, "includ": 1.0190641247799999, "parallel": 4.57917507932, "the": 1.0, "dataset": 193.609756098, "about": 1.06486015159, "function": 2.495441685, "parallelexecut": 1443.27272727, "neural": 59.4606741573, "increment": 31.8795180723, "context": 4.25972632144, "just": 1.33580143037, "flynn": 52.396039603999995, "devic": 5.00820189274, "resourc": 2.9487369985100003, "offtheshelf": 1443.27272727, "otherwis": 3.72151898734, "creation": 3.0601387818, "complet": 1.24021560816, "approach": 2.07556543339, "technic": 3.1400316455699997, "upon": 1.60331246213, "collect": 1.64109985528, "expens": 3.5453327378300004, "where": 1.06715063521, "train": 1.9365698950999999, "particular": 1.3814827706200001, "environ": 3.43561999567, "least": 1.6165359943000002, "their": 1.01547908405, "multipl": 2.74813917258, "among": 1.25670862028, "noteworthi": 27.0, "articl": 2.01805008262, "enabl": 3.5421686747, "singl": 1.60948905109, "speed": 3.8703071672400005, "increas": 1.32024948025, "execut": 2.2363713199, "order": 1.24625166811, "due": 1.23789473684, "referenc": 14.0994671403, "found": 1.11387076405, "given": 1.35426085473, "modif": 9.5753920386, "heterogen": 52.0524590164, "overview": 12.6805111821, "mani": 1.04426757877, "thread": 24.2381679389, "associ": 1.3263157894700002, "exploit": 5.79416058394, "theoret": 7.83613030602, "consid": 1.2397313759200002, "recent": 1.54405757635, "unit": 1.15394679459, "provid": 1.21552714187, "purpos": 2.23416830847, "algorithm": 27.9507042254, "incorpor": 2.62847682119, "linear": 13.8776223776, "timemonopol": 1443.27272727, "perform": 1.5313977042500002, "but": 1.01632417899, "demonstr": 2.64997496244, "definit": 3.24, "our": 2.35758835759, "classif": 8.067073170730001, "arrang": 2.8839237057200005, "arithmet": 38.911764705900005, "expect": 2.20011086475, "matrix": 22.6153846154, "num": 1.00031504001, "modifi": 4.45329593268, "slowest": 200.962025316, "port": 3.9443478260900005, "concurrentlyexecut": 1443.27272727, "big": 2.7400759406299997, "has": 1.0436497502, "have": 1.0148948411399998, "introductori": 30.297709923699998, "read": 2.3149606299200003, "take": 1.13961668222, "advantag": 3.32412060302, "would": 1.0828729281799998, "timeconsum": 1443.27272727, "block": 3.20274359492, "strategi": 4.44208170118, "paradigm": 24.2752293578, "code": 3.8807137619199996, "hard": 2.73253012048, "model": 2.0905978404, "technologyhar": 1443.27272727, "regress": 51.2129032258, "realli": 4.7476076555, "number": 1.10142916609, "note": 1.42449528937, "issu": 1.43921675279, "numer": 1.83325635104, "also": 1.01476510067, "cpus": 174.46153846200002, "typic": 2.2541530597799997, "reason": 1.72340425532, "modern": 1.5319888063299998, "mean": 1.44906900329, "not": 1.01567398119, "acceler": 8.15408320493, "necessarili": 7.33302540416, "task": 3.88641370869, "law": 1.7973508434299998, "numdimension": 1443.27272727, "magnitud": 15.6568047337, "may": 1.05201775893, "consitut": 1443.27272727, "mayo": 49.7680250784, "comput": 3.9277585353800006, "unifi": 7.60709151893, "which": 1.005191845, "speedup": 756.0, "via": 2.2978723404299997, "programm": 5.181462140990001, "amount": 2.27027027027, "expans": 3.4770039421800005, "util": 4.65981802172, "problem": 1.76674827509, "graphic": 9.035856573710001, "design": 1.45825296225, "anoth": 1.13643521832, "core": 4.623179965059999, "extens": 1.99171998495, "howev": 1.0945191313299998, "effect": 1.3963060686000002, "allow": 1.2716059271100002, "attribut": 3.4156626506, "kdnugget": 1443.27272727, "employ": 2.16530278232, "reli": 4.16146788991, "scikitlearn": 1443.27272727, "dearth": 168.893617021, "encompass": 8.02628918099, "bottleneck": 90.72, "practic": 1.70434782609, "tradit": 1.60802187785, "lack": 1.9271667880599999, "asset": 8.63295269168, "other": 1.00992366412, "refer": 1.30024570025, "techniqu": 3.7293868921800004, "calcul": 6.12972972973, "consist": 1.4901445466499998, "timesav": 1443.27272727, "coordin": 5.65586034913, "softwar": 10.2624434389, "see": 1.27242125511, "should": 1.6643254009900001, "regardless": 6.35294117647, "such": 1.06151377374, "sever": 1.07241286139, "those": 1.19548192771, "get": 1.78562591385, "network": 2.59369384088, "like": 1.14918566775, "implement": 3.57648118946, "fast": 4.8729281768, "manag": 1.6448404475799998, "beyond": 2.54586273252, "small": 1.3594793629, "drop": 2.4594887684, "both": 1.05215720061, "processor": 37.980861244, "dictat": 9.28964306612, "process": 1.69524826482, "turn": 1.3838912133899999, "highend": 1443.27272727, "inhibit": 25.160063391399998, "entir": 1.59365589239, "interest": 1.60331246213, "think": 2.90715986083, "sole": 4.04175152749, "well": 1.0655748708, "sidenot": 1443.27272727, "languag": 2.29488291414, "grid": 18.1232876712, "ani": 1.13383802314, "amdahl": 1443.27272727, "and": 1.00006299213, "from": 1.00056721497, "limit": 1.5186531471200002, "smaller": 2.59369384088, "project": 1.7534791252500002, "differ": 1.23654490225, "been": 1.0239277652399998, "independ": 1.58950740889, "facilit": 6.453658536590001, "indepth": 1443.27272727, "magic": 7.9063745019899985, "strateg": 5.67, "certain": 1.8077886586200003, "for": 1.00031504001, "economi": 3.6446280991699997, "contemporari": 2.835, "all": 1.01146788991, "with": 1.0011982089899998, "requir": 1.52844902282, "program": 2.02139037433, "strong": 1.6439888163999998, "there": 1.04091266719, "are": 1.02990593578, "layout": 15.034090909100001, "taxonomi": 74.8867924528, "appropri": 4.31413043478, "nativ": 3.00738776283, "distanc": 3.4754816112099998, "that": 1.00398406375, "sort": 5.188235294119999, "architectur": 5.12790697674, "undoubt": 27.0459965928, "relationship": 2.39132399458, "cluster": 12.5007874016, "improv": 2.04376930999, "veri": 1.25880114177, "favorit": 8.116564417180001, "system": 1.38739840951, "achiev": 1.87216981132, "these": 1.07415426252, "whatev": 7.6473988439300005, "benefit": 3.06841901817, "posit": 1.37252528746, "gain": 1.84819557625, "general": 1.1218202374200001, "made": 1.07038834951, "latenc": 174.46153846200002, "treatment": 3.87125091441, "focus": 2.01012914662, "lead": 1.2664326739, "weakest": 68.72727272729999, "state": 1.0477133240899998, "simultan": 5.32930513595, "can": 1.17626139142, "avail": 1.7288467821, "could": 1.2043695949, "set": 1.18707940781, "total": 1.5460122699399999, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "situat": 2.06611140031, "now": 1.160780873, "serial": 11.3643521832, "kernel": 70.56, "error": 6.04109589041, "framework": 8.200413223139998, "link": 2.15151104486, "common": 1.4025974025999999, "chain": 5.17639387023, "librari": 2.68266306185, "data": 3.37643555934, "matter": 2.44773358002, "machin": 4.02433460076, "into": 1.01502461479, "acronym": 35.0463576159, "must": 1.9220338983099996, "substanti": 3.4777656078900003, "worth": 5.210370856580001, "potenti": 2.52080025405, "gpus": 1058.4, "figur": 2.0343413634, "everi": 1.47917637194, "share": 1.8566249561500001, "use": 1.0296387573799999, "fig": 54.5567010309, "while": 1.0441988950299999, "dramat": 3.9849397590400004, "multicor": 1443.27272727, "host": 2.7092150170599996, "without": 1.29547123623, "larg": 1.18574949585, "within": 1.2369302688, "learn": 2.32275054865, "consider": 2.29920347574, "when": 1.02076769755, "even": 1.16461267606}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/11/parallelism-machine-learning-gpu-cuda-threading.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/16/11-09-sap-senior-data-scientist.html\" rel=\"prev\" title=\"SAP.iO Start-Up Incubator: Senior Data Scientist\"/>\n<link href=\"https://www.kdnuggets.com/2016/11/sap-transform-future-predictive-analytics.html\" rel=\"next\" title=\"Transform the Future with Predictive Analytics\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/11/parallelism-machine-learning-gpu-cuda-threading.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=56839\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/11/parallelism-machine-learning-gpu-cuda-threading.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-56839 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 10-Nov, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/tutorials.html\">Tutorials, Overviews</a> \u00bb Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications (\u00a0<a href=\"/2016/n40.html\">16:n40</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/16/11-09-sap-senior-data-scientist.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/11/sap-transform-future-predictive-analytics.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 491</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/algorithms\" rel=\"tag\">Algorithms</a>, <a href=\"https://www.kdnuggets.com/tag/cuda\" rel=\"tag\">CUDA</a>, <a href=\"https://www.kdnuggets.com/tag/gpu\" rel=\"tag\">GPU</a>, <a href=\"https://www.kdnuggets.com/tag/nvidia\" rel=\"tag\">NVIDIA</a>, <a href=\"https://www.kdnuggets.com/tag/parallelism\" rel=\"tag\">Parallelism</a></div>\n<br/>\n<p class=\"excerpt\">\n     The lack of parallel processing in machine learning tasks inhibits economy of performance, yet it may very well be worth the trouble. Read on for an introductory overview to GPU-based parallelism, the CUDA framework, and some thoughts on practical implementation.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/matt-mayo\" rel=\"author\" title=\"Posts by Matthew Mayo\">Matthew Mayo</a>, KDnuggets.</b></div>\n<p>Traditionally (whatever that means in this context), machine learning has been executed in single processor environments, where algorithmic bottlenecks can lead to substantial delays in model processing, from training, to classification, to distance and error calculations, and beyond. Beyond recent technology-harnessing in neural networking training, much of machine learning - including both off-the-shelf libraries like <a href=\"http://scikit-learn.org/stable/\" target=\"_blank\">scikit-learn</a> and <a href=\"/2016/05/implement-machine-learning-algorithms-scratch.html\" target=\"_blank\">DIY algorithm implementation</a> - has been approached without the use of parallel processing.</p>\n<p>The lack of parallel processing, in this context referring to parallel execution on a shared-memory architecture, inhibits the potential exploitation of large numbers of concurrently-executing threads performing independent tasks in order to achieve economy of performance. The dearth of parallelism is attributable to all sorts of reasons, not the least of which being that parallel programming is <b>hard</b>. <a href=\"http://parallel.illinois.edu/blog/three-challenges-parallel-programming\" target=\"_blank\">It really is</a>. </p>\n<p><center><img alt=\"Parallel problem overview\" src=\"/wp-content/uploads/parallel-problem.gif\" width=\"80%\"/><br>\n<b>Fig. 1: Parallel Problem Overview.</b></br></center></p>\n<p>Also, parallel processing is not magic, and cannot \"just be used\" in every situation; there are both practical and theoretical algorithmic design issues that must be considered when even thinking about incorporating parallel processing into a project. However, with Big Data encompassing such large amounts of data, sets of which are increasingly being relied upon for routine machine learning tasks, the trouble associated with parallelism may very well be worth it in a given situation due solely to the potential of dramatic time-savings related to algorithm execution.</p>\n<h3>General Purpose Computing on Graphics Processing Units</h3>\n<p>\u00a0<br>\nA contemporary favorite for parallelism <b>in appropriate situations</b>, and focus of this article, is utilizing <a href=\"https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units\" target=\"_blank\">general purpose computing on graphics processing units (GPGPU)</a>, a strategy exploiting the numerous processing cores found on high-end modern graphics processing units (GPUs) for the simultaneous execution of computationally expensive tasks. While not all machine learning tasks, or any other collection of software tasks for that matter, can benefit from GPGPU, there are undoubtedly numerous computationally expensive and time-monopolizing tasks to which GPGPU <b>could</b> be an asset. Modifying algorithms to allow certain of their tasks to take advantage of GPU parallelization can demonstrate noteworthy gains in both task performance and completion speed.</br></p>\n<p><center><img alt=\"Flynn's Taxonomy\" src=\"/wp-content/uploads/flynns-taxonomy.gif\" width=\"70%\"/><br>\n<b>Fig. 2: Flynn's Taxonomy.</b></br></center></p>\n<p>The GPGPU paradigm fits into <a href=\"https://en.wikipedia.org/wiki/Flynn%27s_taxonomy\" target=\"_blank\">Flynn\u2019s taxonomy</a> as <a href=\"https://en.wikipedia.org/wiki/SPMD\" target=\"_blank\">single program, multiple data (SPMD)</a> architecture, which differs from from the traditional multicore CPU computing paradigm.</p>\n<p><center><img alt=\"SPMD\" src=\"/wp-content/uploads/spmd.jpg\" width=\"85%\"/><br>\n<b>Fig. 3: Single Program Multiple Data (SPMD) subdivision of MIMD.</b></br></center></p>\n<p>It should be noted that, while these modifications would undoubtedly benefit the processing of the very large datasets which are the very definition of Big Data, their implementation could have a positive effect on much smaller sets of data as well. A number of particular machine learning tasks can be computationally expensive and time-consuming regardless of data size. Parallelizing those which are not necessarily required to be executed in serial could <strong>potentially</strong> lead to gains for small datasets as well.</p>\n<p>Machine learning algorithms could also see performance gains by parallelizing common tasks which may be shared among numerous algorithms, such as performing matrix multiplication, which is used by several classification, regression, and clustering techniques, including, of particular interest, linear regression.</p>\n<p>An interesting sidenote relates to the theoretical expected speedup in task execution latency. <a href=\"https://en.wikipedia.org/wiki/Amdahl%27s_law\" target=\"_blank\">Amdahl's Law</a> states that the theoretical speedup of an entire task's execution increases with the incremental improvement of each system resource. However, regardless of the collective improvement's magnitude, theoretical speedup is limited by the consitutent task which cannot benefit from parallel improvements, or improves the least. The chain is only as strong (fast) as its weakest (slowest) link.</p>\n<p>For an in-depth introductory treatment of generalized parallel computing, <a href=\"https://computing.llnl.gov/tutorials/parallel_comp/\" target=\"_blank\">read this</a>.</p>\n<h3>CUDA Parallel Programming Framework</h3>\n<p>\u00a0<br/>\nThe <a href=\"http://www.nvidia.ca/object/cuda_home_new.html\" target=\"_blank\">CUDA parallel programming framework</a> from NVIDIA is a particular implementation of the GPGPU paradigm. CUDA once was an acronym for Compute Unified Device Architecture, but NVIDIA dropped the expansion and now just uses CUDA. This architecture, facilitating our machine learning parallelization via GPU acceleration (another way to refer to GPGPU), requires particular consideration in order to effectively manage available resources and provide the maximum execution speed benefit.</p>\n<p>CUDA is technically a heterogeneous computing environment, meaning that it facilitates coordinated computing on both CPUs and GPUs. The CUDA architecture consists of hosts and devices, with <strong>host</strong> referring to a traditional CPU, and <strong>device</strong> referencing processors with large numbers of arithmetic units, typically GPUs. CUDA provides extensions to traditional programming languages (the native CUDA bindings are C, but have been ported or made otherwise available to many additional languages), enabling the creation of <strong>kernels</strong>, which are parallel-executing functions. </p>\n<p>A kernel, when launched, gets simultaneously executed by a large number of CUDA device <strong>threads</strong>, a collection of which are referred to as a <strong>block</strong> of threads, blocks being collected into <strong>grids</strong>. Threads are arranged in 3-dimensional layouts within blocks, which are, in turn, arranged in 3-dimensional layouts within grids. Figure 4 demonstrates these relationships and layouts. The total number of threads, blocks, and grids employed by a particular kernel are strategically dictated by a programmer\u2019s code executing on the host at kernel launch, based on given situational requirements.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2016/11/parallelism-machine-learning-gpu-cuda-threading.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/16/11-09-sap-senior-data-scientist.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/11/sap-transform-future-predictive-analytics.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/tutorials.html\">Tutorials, Overviews</a> \u00bb Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications (\u00a0<a href=\"/2016/n40.html\">16:n40</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556441258\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.791 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-28 04:47:38 -->\n<!-- Compression = gzip -->", "content_tokenized": ["matthew", "mayo", "kdnugget", "tradit", "whatev", "that", "mean", "this", "context", "machin", "learn", "has", "been", "execut", "singl", "processor", "environ", "where", "algorithm", "bottleneck", "can", "lead", "substanti", "delay", "model", "process", "from", "train", "classif", "distanc", "and", "error", "calcul", "and", "beyond", "beyond", "recent", "technologyhar", "neural", "network", "train", "much", "machin", "learn", "includ", "both", "offtheshelf", "librari", "like", "scikitlearn", "and", "algorithm", "implement", "has", "been", "approach", "without", "the", "use", "parallel", "process", "the", "lack", "parallel", "process", "this", "context", "refer", "parallel", "execut", "sharedmemori", "architectur", "inhibit", "the", "potenti", "exploit", "larg", "number", "concurrentlyexecut", "thread", "perform", "independ", "task", "order", "achiev", "economi", "perform", "the", "dearth", "parallel", "attribut", "all", "sort", "reason", "not", "the", "least", "which", "that", "parallel", "program", "hard", "realli", "fig", "num", "parallel", "problem", "overview", "also", "parallel", "process", "not", "magic", "and", "can", "not", "just", "use", "everi", "situat", "there", "are", "both", "practic", "and", "theoret", "algorithm", "design", "issu", "that", "must", "consid", "when", "even", "think", "about", "incorpor", "parallel", "process", "into", "project", "howev", "with", "big", "data", "encompass", "such", "larg", "amount", "data", "set", "which", "are", "increas", "reli", "upon", "for", "routin", "machin", "learn", "task", "the", "troubl", "associ", "with", "parallel", "may", "veri", "well", "worth", "given", "situat", "due", "sole", "the", "potenti", "dramat", "timesav", "relat", "algorithm", "execut", "general", "purpos", "comput", "graphic", "process", "unit", "contemporari", "favorit", "for", "parallel", "appropri", "situat", "and", "focus", "this", "articl", "util", "general", "purpos", "comput", "graphic", "process", "unit", "strategi", "exploit", "the", "numer", "process", "core", "found", "highend", "modern", "graphic", "process", "unit", "gpus", "for", "the", "simultan", "execut", "comput", "expens", "task", "while", "not", "all", "machin", "learn", "task", "ani", "other", "collect", "softwar", "task", "for", "that", "matter", "can", "benefit", "from", "there", "are", "undoubt", "numer", "comput", "expens", "and", "timemonopol", "task", "which", "could", "asset", "modifi", "algorithm", "allow", "certain", "their", "task", "take", "advantag", "parallel", "can", "demonstr", "noteworthi", "gain", "both", "task", "perform", "and", "complet", "speed", "fig", "num", "flynn", "taxonomi", "the", "paradigm", "fit", "into", "flynn", "taxonomi", "singl", "program", "multipl", "data", "architectur", "which", "differ", "from", "from", "the", "tradit", "multicor", "comput", "paradigm", "fig", "num", "singl", "program", "multipl", "data", "subdivis", "should", "note", "that", "while", "these", "modif", "would", "undoubt", "benefit", "the", "process", "the", "veri", "larg", "dataset", "which", "are", "the", "veri", "definit", "big", "data", "their", "implement", "could", "have", "posit", "effect", "much", "smaller", "set", "data", "well", "number", "particular", "machin", "learn", "task", "can", "comput", "expens", "and", "timeconsum", "regardless", "data", "size", "parallel", "those", "which", "are", "not", "necessarili", "requir", "execut", "serial", "could", "potenti", "lead", "gain", "for", "small", "dataset", "well", "machin", "learn", "algorithm", "could", "also", "see", "perform", "gain", "parallel", "common", "task", "which", "may", "share", "among", "numer", "algorithm", "such", "perform", "matrix", "multipl", "which", "use", "sever", "classif", "regress", "and", "cluster", "techniqu", "includ", "particular", "interest", "linear", "regress", "interest", "sidenot", "relat", "the", "theoret", "expect", "speedup", "task", "execut", "latenc", "amdahl", "law", "state", "that", "the", "theoret", "speedup", "entir", "task", "execut", "increas", "with", "the", "increment", "improv", "each", "system", "resourc", "howev", "regardless", "the", "collect", "improv", "magnitud", "theoret", "speedup", "limit", "the", "consitut", "task", "which", "can", "not", "benefit", "from", "parallel", "improv", "improv", "the", "least", "the", "chain", "onli", "strong", "fast", "weakest", "slowest", "link", "for", "indepth", "introductori", "treatment", "general", "parallel", "comput", "read", "this", "parallel", "program", "framework", "the", "parallel", "program", "framework", "from", "particular", "implement", "the", "paradigm", "onc", "acronym", "for", "comput", "unifi", "devic", "architectur", "but", "drop", "the", "expans", "and", "now", "just", "use", "this", "architectur", "facilit", "our", "machin", "learn", "parallel", "via", "acceler", "anoth", "way", "refer", "requir", "particular", "consider", "order", "effect", "manag", "avail", "resourc", "and", "provid", "the", "maximum", "execut", "speed", "benefit", "technic", "heterogen", "comput", "environ", "mean", "that", "facilit", "coordin", "comput", "both", "cpus", "and", "gpus", "the", "architectur", "consist", "host", "and", "devic", "with", "host", "refer", "tradit", "and", "devic", "referenc", "processor", "with", "larg", "number", "arithmet", "unit", "typic", "gpus", "provid", "extens", "tradit", "program", "languag", "the", "nativ", "bind", "are", "but", "have", "been", "port", "made", "otherwis", "avail", "mani", "addit", "languag", "enabl", "the", "creation", "kernel", "which", "are", "parallelexecut", "function", "kernel", "when", "launch", "get", "simultan", "execut", "larg", "number", "devic", "thread", "collect", "which", "are", "refer", "block", "thread", "block", "collect", "into", "grid", "thread", "are", "arrang", "numdimension", "layout", "within", "block", "which", "are", "turn", "arrang", "numdimension", "layout", "within", "grid", "figur", "num", "demonstr", "these", "relationship", "and", "layout", "the", "total", "number", "thread", "block", "and", "grid", "employ", "particular", "kernel", "are", "strateg", "dictat", "programm", "code", "execut", "the", "host", "kernel", "launch", "base", "given", "situat", "requir"], "timestamp_scraper": 1556480370.136946, "title": "Parallelism in Machine Learning: GPUs, CUDA, and Practical Applications", "read_time": 249.6, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/matt-mayo\" rel=\"author\" title=\"Posts by Matthew Mayo\">Matthew Mayo</a>, KDnuggets.</b></div>\n<p>Traditionally (whatever that means in this context), machine learning has been executed in single processor environments, where algorithmic bottlenecks can lead to substantial delays in model processing, from training, to classification, to distance and error calculations, and beyond. Beyond recent technology-harnessing in neural networking training, much of machine learning - including both off-the-shelf libraries like <a href=\"http://scikit-learn.org/stable/\" target=\"_blank\">scikit-learn</a> and <a href=\"/2016/05/implement-machine-learning-algorithms-scratch.html\" target=\"_blank\">DIY algorithm implementation</a> - has been approached without the use of parallel processing.</p>\n<p>The lack of parallel processing, in this context referring to parallel execution on a shared-memory architecture, inhibits the potential exploitation of large numbers of concurrently-executing threads performing independent tasks in order to achieve economy of performance. The dearth of parallelism is attributable to all sorts of reasons, not the least of which being that parallel programming is <b>hard</b>. <a href=\"http://parallel.illinois.edu/blog/three-challenges-parallel-programming\" target=\"_blank\">It really is</a>. </p>\n<p><center><img alt=\"Parallel problem overview\" src=\"/wp-content/uploads/parallel-problem.gif\" width=\"80%\"/><br>\n<b>Fig. 1: Parallel Problem Overview.</b></br></center></p>\n<p>Also, parallel processing is not magic, and cannot \"just be used\" in every situation; there are both practical and theoretical algorithmic design issues that must be considered when even thinking about incorporating parallel processing into a project. However, with Big Data encompassing such large amounts of data, sets of which are increasingly being relied upon for routine machine learning tasks, the trouble associated with parallelism may very well be worth it in a given situation due solely to the potential of dramatic time-savings related to algorithm execution.</p>\n<h3>General Purpose Computing on Graphics Processing Units</h3>\n<p>\u00a0<br>\nA contemporary favorite for parallelism <b>in appropriate situations</b>, and focus of this article, is utilizing <a href=\"https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units\" target=\"_blank\">general purpose computing on graphics processing units (GPGPU)</a>, a strategy exploiting the numerous processing cores found on high-end modern graphics processing units (GPUs) for the simultaneous execution of computationally expensive tasks. While not all machine learning tasks, or any other collection of software tasks for that matter, can benefit from GPGPU, there are undoubtedly numerous computationally expensive and time-monopolizing tasks to which GPGPU <b>could</b> be an asset. Modifying algorithms to allow certain of their tasks to take advantage of GPU parallelization can demonstrate noteworthy gains in both task performance and completion speed.</br></p>\n<p><center><img alt=\"Flynn's Taxonomy\" src=\"/wp-content/uploads/flynns-taxonomy.gif\" width=\"70%\"/><br>\n<b>Fig. 2: Flynn's Taxonomy.</b></br></center></p>\n<p>The GPGPU paradigm fits into <a href=\"https://en.wikipedia.org/wiki/Flynn%27s_taxonomy\" target=\"_blank\">Flynn\u2019s taxonomy</a> as <a href=\"https://en.wikipedia.org/wiki/SPMD\" target=\"_blank\">single program, multiple data (SPMD)</a> architecture, which differs from from the traditional multicore CPU computing paradigm.</p>\n<p><center><img alt=\"SPMD\" src=\"/wp-content/uploads/spmd.jpg\" width=\"85%\"/><br>\n<b>Fig. 3: Single Program Multiple Data (SPMD) subdivision of MIMD.</b></br></center></p>\n<p>It should be noted that, while these modifications would undoubtedly benefit the processing of the very large datasets which are the very definition of Big Data, their implementation could have a positive effect on much smaller sets of data as well. A number of particular machine learning tasks can be computationally expensive and time-consuming regardless of data size. Parallelizing those which are not necessarily required to be executed in serial could <strong>potentially</strong> lead to gains for small datasets as well.</p>\n<p>Machine learning algorithms could also see performance gains by parallelizing common tasks which may be shared among numerous algorithms, such as performing matrix multiplication, which is used by several classification, regression, and clustering techniques, including, of particular interest, linear regression.</p>\n<p>An interesting sidenote relates to the theoretical expected speedup in task execution latency. <a href=\"https://en.wikipedia.org/wiki/Amdahl%27s_law\" target=\"_blank\">Amdahl's Law</a> states that the theoretical speedup of an entire task's execution increases with the incremental improvement of each system resource. However, regardless of the collective improvement's magnitude, theoretical speedup is limited by the consitutent task which cannot benefit from parallel improvements, or improves the least. The chain is only as strong (fast) as its weakest (slowest) link.</p>\n<p>For an in-depth introductory treatment of generalized parallel computing, <a href=\"https://computing.llnl.gov/tutorials/parallel_comp/\" target=\"_blank\">read this</a>.</p>\n<h3>CUDA Parallel Programming Framework</h3>\n<p>\u00a0<br/>\nThe <a href=\"http://www.nvidia.ca/object/cuda_home_new.html\" target=\"_blank\">CUDA parallel programming framework</a> from NVIDIA is a particular implementation of the GPGPU paradigm. CUDA once was an acronym for Compute Unified Device Architecture, but NVIDIA dropped the expansion and now just uses CUDA. This architecture, facilitating our machine learning parallelization via GPU acceleration (another way to refer to GPGPU), requires particular consideration in order to effectively manage available resources and provide the maximum execution speed benefit.</p>\n<p>CUDA is technically a heterogeneous computing environment, meaning that it facilitates coordinated computing on both CPUs and GPUs. The CUDA architecture consists of hosts and devices, with <strong>host</strong> referring to a traditional CPU, and <strong>device</strong> referencing processors with large numbers of arithmetic units, typically GPUs. CUDA provides extensions to traditional programming languages (the native CUDA bindings are C, but have been ported or made otherwise available to many additional languages), enabling the creation of <strong>kernels</strong>, which are parallel-executing functions. </p>\n<p>A kernel, when launched, gets simultaneously executed by a large number of CUDA device <strong>threads</strong>, a collection of which are referred to as a <strong>block</strong> of threads, blocks being collected into <strong>grids</strong>. Threads are arranged in 3-dimensional layouts within blocks, which are, in turn, arranged in 3-dimensional layouts within grids. Figure 4 demonstrates these relationships and layouts. The total number of threads, blocks, and grids employed by a particular kernel are strategically dictated by a programmer\u2019s code executing on the host at kernel launch, based on given situational requirements.</p>\n</div> ", "website": "kdnuggets"}