{"content": "By Adrian Colyer , Venture Partner, Accel. comments Beyond news contents: the role of social context for fake news detection \u00a0Shu et al.,\u00a0 WSDM\u201919 Today we\u2019re looking at a more general fake news problem: detecting fake news that is being spread on a social network. Forgetting the computer science angle for a minute, it seems intuitive to me that some important factors here might be: what \u00a0is being said (the content of the news), and perhaps\u00a0 how \u00a0it is being said (although fake news can be deliberately written to mislead users by mimicking true news) where \u00a0it was published (the credibility / authority of the source publication). For example, something in the Financial Times is more likely to be true than something in The Onion! who \u00a0is spreading the news (the credibility of the user accounts retweeting it for example \u2013 are they bots??) Therefore I\u2019m a little surprised to read in the introduction that: The majority of existing detection algorithms focus on finding clues from the news\u00a0 content , which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news. (The related work section does however discuss several works that include social context.). So instead of just looking at the content, we should also look at the social context: the publishers and the users spreading the information! The fake news detection system developed in this paper, TriFN considers tri-relationships between news pieces, publishers, and social network users. \u2026 we are to our best knowledge the first to classify fake news by learning the effective news features through the tri-relationship embedding among publishers, news contents, and social engagements. And guess what, considering publishers and users does indeed turn out to improve fake news detection! \u00a0 Inputs \u00a0 We have\u00a0 \u00a0publishers,\u00a0 \u00a0social network users, and\u00a0 \u00a0news articles. Using a vocabulary of\u00a0 t \u00a0words, we can compute an\u00a0 \u00a0bag-of-word feature matrix. For the\u00a0 m \u00a0users, we can have an\u00a0 m x m \u00a0adjacency matrix\u00a0 , where\u00a0 \u00a0is 1 if\u00a0 i \u00a0and\u00a0 j \u00a0are friends, and 0 otherwise. We also know which users have shared which news pieces, this is encoded in a matrix\u00a0 . The matrix\u00a0 \u00a0similarly encodes which publishers have published which news pieces. For some publishers, we can know their partisan bias. In this work, bias ratings from\u00a0 mediabiasfactcheck.com \u00a0are used, taking just the \u2018Left-Bias\u2019, \u2018Least-Bias\u2019 (neutral) and \u2018Right-Bias\u2019 values (ignoring the intermediate left-center and right-center values) and encoding these as -1, 0, and 1 respectively in a publisher partisan label vector,\u00a0 . Not every publisher will have a bias rating available. We\u2019d like to put \u2018-\u2019 in the entry for that publisher in\u00a0 \u00a0but since we can\u2019t do that, the separate vector\u00a0 \u00a0encodes whether or not we have a bias rating available for publisher\u00a0 p . There\u2019s one last thing at our disposal: a labelled dataset for news articles telling us whether they are fake or not. (Here we have just the news article content, not the social context). \u00a0 The Tri-relationship embedding framework \u00a0 TriFN takes all of those inputs and combines them with a fake news binary classifier. Given lots of users and lots of news articles, we can expect some of the raw inputs to be pretty big, so the authors make heavy use of dimensionality reduction using non-negative matrix factorisation to learn latent space embeddings (more on that in a minute!) TriFN combines: A news content embedding A user embedding A user-news interaction embedding A publisher-news interaction embedding, and The prediction made by a linear classifier trained on the labelled fake news dataset Pictorially it looks like this (with apologies for the poor resolution, which is an artefact of the original): News content embedding Let\u2019s take a closer look at non-negative matrix factorisation (NMF) to see how this works to reduce dimensionality. Remember the bag-of-words sketch for news articles? That\u2019s an\u00a0 n x t \u00a0matrix where\u00a0 n \u00a0is the number of news articles and\u00a0 t \u00a0is the number of words in the vocabulary. NMF tries to learn a latent embedding that captures the information in the matrix in a much smaller space. In the general form NMF seeks to factor a (non-negative) matrix\u00a0 M \u00a0into the product of two (non-negative) matrices\u00a0 W \u00a0and\u00a0 H \u00a0(or\u00a0 D \u00a0and\u00a0 V \u00a0as used in this paper). How does that help us? We can pick some dimension\u00a0 d \u00a0(controlling the size of the latent space) and break down the\u00a0 \u00a0matrix into a d-dimension representation of news articles\u00a0 , and a d-dimension representation of words in the vocabulary,\u00a0 . That means that\u00a0 \u00a0has shape\u00a0 \u00a0and so\u00a0 \u00a0ends up with the desired shape\u00a0 . Once we\u2019ve learned a good representation of news articles,\u00a0 we can use those as the news content embeddings within TriFN. We\u2019d like to get\u00a0 \u00a0as close to\u00a0 \u00a0as we can, and at the same time keep\u00a0 \u00a0and\u00a0 \u2018sensible\u2019 to avoid over-fitting. We can do that with a regularisation term. So the overall optimisation problem looks like this: User embedding For the user embedding there\u2019s a similar application of NMF, but in this case we\u2019re splitting the adjacency matrix\u00a0 \u00a0into a user latent matrix\u00a0 , and a user correlation matrix\u00a0 . So in this case we\u2019re using NMF to learn\u00a0 which has shape\u00a0 mxd \u00a0.\u00a0 dxd \u00a0.\u00a0 dxm , resulting in the desired\u00a0 mxm \u00a0shape. There\u2019s also a user-user relation matrix\u00a0 \u00a0which controls the contribution of\u00a0 . The basic idea is that any given user will only share a small fraction of news articles, so a positive case (having shared an article) should have more weight than a negative case (not having shared). User-news interaction embedding For the user-news interaction embedding we want to capture the relationship between user features and the labels of news items. The intuition is that users with low credibility are more likely to spread fake news. So how do we get user credibility? Following \u2018 Measuring user credibility in social media \u2019 the authors base this on similarity to other users. First users are clustered into groups such that members of the same cluster all tend to share the same news stories. Then each cluster is given a credibility score based on its relative size. Users take on the credibility score of the cluster they belong to. It all seems rather vulnerable to the creation of large numbers of fake bot accounts that collaborate to spread fake news if you ask me. Nevertheless, assuming we have reliable credibility scores then we want to set things up such that the latent features of high-credibility users are close to true news, and the latent features of low-credibility users are close to fake news. Publisher-news embeddings Recall we have the matrix\u00a0 \u00a0encoding which publishers have published which news pieces. Let\u00a0 \u00a0be the normalised version of the same. We want to find\u00a0 , a weighting matrix mapping news publisher\u2019s latent features to the corresponding partisan label vector\u00a0 . It looks like this: Semi-supervised linear classifier Using the labelled data available, we also learn a weighting matrix\u00a0 \u00a0mapping news latent features to fake news labels. Putting it all together The overall objective becomes to find matrices\u00a0 \u00a0using a weighted combination of each of the above embedding formulae, and a regularisation term combining all of the learned matrices. It looks like this: and it\u2019s trained like this: \u00a0 Evaluation \u00a0 TriFN is evaluated against several state of the art fake news detection methods using the FakeNewsNet BuzzFeed and PolitiFact datasets. It gives the best performance on both of them: ( Enlarge ) \u00a0 Original . Reposted with permission. Related: A Quick Guide to Fake News Detection on Social Media Beware of Two Data Obfuscation Tactics It\u2019s Getting Hot In Here: Data Science vs Fake News", "title_html": "<h1 id=\"title\">Beyond news contents: the role of social context for fake news detection</h1> ", "url": "https://www.kdnuggets.com/2019/03/beyond-news-contents-role-of-social-context-for-fake-news-detection.html", "tfidf": {"tfidf": {"base": 2.2925631769, "relat": 4.95003507676, "label": 31.340101522869997, "vulner": 8.869273743019999, "art": 1.9994962216599999, "who": 1.06279287723, "collabor": 4.45454545455, "hot": 4.6178010471199995, "onc": 1.4974533106999999, "this": 13.049317147230001, "leftbia": 1323.0, "here": 7.26923076924, "dispos": 10.4378698225, "heavi": 2.88707037643, "form": 1.12755681818, "factor": 5.78255326898, "lowcred": 1323.0, "space": 7.19456193354, "through": 1.07074930869, "comput": 7.855517070760001, "surpris": 4.36633663366, "engag": 2.6926729986400004, "much": 1.1942229577299999, "bagofword": 2646.0, "evalu": 13.901926444839999, "than": 2.0655737705, "belong": 3.5, "dataset": 580.829268294, "problem": 3.53349655018, "articl": 20.1805008262, "intent": 3.19372359686, "obfusc": 182.482758621, "optimis": 131.20661157, "context": 17.03890528576, "smaller": 2.59369384088, "just": 4.00740429111, "product": 1.62264922322, "accel": 1323.0, "otherwis": 3.72151898734, "creation": 3.0601387818, "rightcent": 1323.0, "binari": 32.4, "permiss": 6.280063291139999, "classifi": 21.1750583528, "know": 5.1865403463, "credibl": 125.2544378696, "should": 3.3286508019800003, "dxd": 1323.0, "contribut": 1.9255306246200001, "usernew": 3969.0, "seek": 2.83753351206, "where": 3.20145190563, "rememb": 4.88793103448, "measur": 2.41093394077, "instead": 1.59461631177, "their": 1.01547908405, "weight": 19.515673017839998, "among": 1.25670862028, "rightbia": 1323.0, "intuit": 55.4136125654, "how": 6.41001312204, "deliber": 6.280063291139999, "sketch": 10.956521739100001, "news": 95.76396538147999, "guid": 2.49113447356, "fraction": 13.9753521127, "matric": 290.4146341464, "that": 18.0717131475, "latent": 531.4142259416001, "keep": 2.04245465071, "represent": 17.784914115, "end": 1.10680423871, "they": 3.09051975861, "correl": 13.1860465116, "word": 5.3896118592299995, "raw": 10.6478873239, "social": 19.904714142400003, "effect": 2.7926121372000003, "will": 2.44962197192, "true": 10.22279459112, "the": 83.0, "consid": 2.4794627518400003, "shape": 12.81355932204, "see": 1.27242125511, "those": 2.39096385542, "buzzfe": 1134.0, "encod": 145.1188299815, "normalis": 217.479452055, "seem": 4.58247943426, "number": 3.30428749827, "clue": 30.4137931034, "repost": 933.882352941, "linear": 27.7552447552, "regularis": 962.1818181819999, "perform": 1.5313977042500002, "but": 2.03264835798, "our": 4.71517671518, "there": 3.12273800157, "friend": 2.20194174757, "colyer": 1323.0, "object": 2.3488681757700003, "inform": 3.1506251240400003, "expect": 2.20011086475, "matrix": 384.4615384618, "user": 192.76347741625, "applic": 3.42672134686, "semisupervis": 1323.0, "best": 3.1657028913200005, "exampl": 3.00966824644, "big": 2.7400759406299997, "has": 2.0872995004, "given": 4.06278256419, "mislead": 45.2307692308, "knowledg": 3.3981164383599998, "take": 4.55846672888, "reduct": 6.320063694269999, "use": 10.296387573799999, "follow": 1.04640126549, "tri": 1.8544562551099997, "artefact": 49.7680250784, "then": 2.17315721032, "out": 1.06016694491, "with": 6.007189253939998, "interact": 17.6743668244, "desir": 6.00340328984, "good": 1.51981619759, "basic": 2.7301805675, "enlarg": 11.3806451613, "publish": 21.90170719088, "financi": 2.60860992442, "break": 2.42863698944, "ddimens": 2646.0, "also": 4.05906040268, "politifact": 1323.0, "time": 2.02254920696, "member": 1.32068879461, "pictori": 40.5, "mean": 1.44906900329, "vector": 77.696574225, "partisan": 56.971291866, "not": 6.09404388714, "someth": 6.56304257958, "method": 2.5714285714300003, "major": 1.14852058164, "mxm": 1323.0, "adrian": 19.5517241379, "therefor": 2.33401940606, "respect": 1.6443293630200002, "becom": 1.12492028626, "stori": 2.02396736359, "quick": 2.205, "angl": 8.934158694430002, "perhap": 3.14812611541, "score": 12.865478119950001, "intermedi": 11.4380403458, "said": 3.09503850278, "captur": 5.76052249638, "exist": 1.4647107666799999, "scienc": 4.63939216832, "separ": 1.6012102874399998, "system": 1.38739840951, "shu": 129.073170732, "howev": 1.0945191313299998, "leftcent": 1323.0, "let": 6.97233201582, "although": 1.14968498805, "piec": 12.96529195592, "work": 4.46080359652, "minut": 6.22466183102, "role": 1.55327267391, "which": 10.051918449999999, "featur": 10.68988072334, "them": 2.19752231988, "item": 5.07869481766, "bewar": 131.20661157, "tactic": 6.432739059969999, "other": 1.00992366412, "introduct": 2.7808723068799996, "togeth": 1.58095996813, "algorithm": 27.9507042254, "one": 1.00627495722, "valu": 4.555523672880001, "two": 2.0275862069, "lot": 8.81755068036, "factoris": 2646.0, "develop": 1.1955719557200002, "entri": 3.9909502262400003, "such": 2.12302754748, "becaus": 1.1495184997499999, "sever": 2.14482572278, "mxd": 1323.0, "resolut": 5.73762197326, "get": 5.35687774155, "network": 7.781081522639999, "like": 10.342671009750001, "neutral": 6.981530343010001, "abov": 1.90382539873, "some": 4.16146788992, "beyond": 2.54586273252, "small": 1.3594793629, "control": 2.93918356012, "both": 1.05215720061, "tell": 3.36142282448, "detect": 37.890214797119995, "result": 1.14611608432, "put": 3.31613577024, "set": 1.18707940781, "origin": 2.27449856734, "partner": 4.173501577290001, "includ": 1.0190641247799999, "content": 31.8795180723, "reliabl": 6.681818181819999, "correspond": 3.32481675393, "rate": 6.421464203849999, "term": 2.79040337464, "leastbia": 1323.0, "media": 5.18738768176, "pick": 4.939639079030001, "ani": 1.13383802314, "pretti": 15.75, "and": 30.0018897639, "from": 2.00113442994, "account": 3.8892699657, "similar": 4.12542226071, "ignor": 4.58446433728, "apolog": 13.9141104294, "num": 6.00189024006, "embed": 269.37009544, "same": 4.47431832592, "turn": 1.3838912133899999, "mediabiasfactcheckcom": 1323.0, "forget": 16.9978586724, "idea": 2.0930784443, "between": 2.06907337416, "low": 2.13072070863, "what": 2.50686878256, "for": 13.00409552013, "predict": 5.18484650555, "highcred": 1323.0, "all": 5.05733944955, "version": 2.0083491461099996, "closer": 5.5666199158500005, "ventur": 7.73684210526, "today": 1.74961428257, "split": 3.4709226060300002, "written": 3.9146837627999997, "assum": 2.9575260804799997, "are": 10.299059357800001, "poor": 2.42196796339, "case": 5.93994949024, "onion": 46.557184750699996, "author": 4.268889486419999, "section": 2.1284354471099998, "look": 15.269055061279998, "spread": 14.172469201950001, "trifn": 6615.0, "cluster": 50.0031496064, "public": 1.22424429365, "more": 5.085853408499999, "improv": 2.04376930999, "overfit": 1323.0, "fake": 347.51612903139994, "discuss": 2.19676214197, "vocabulari": 69.8357771262, "these": 1.07415426252, "want": 5.99094339624, "negat": 3.75852272727, "combin": 6.79041916168, "posit": 1.37252528746, "sourc": 1.69760479042, "general": 3.3654607122600004, "made": 1.07038834951, "overal": 6.088590604019999, "focus": 2.01012914662, "comment": 3.05954904606, "tend": 3.3735656608599998, "state": 1.0477133240899998, "close": 3.8546455163399997, "map": 8.145715751660001, "group": 1.20996875238, "doe": 5.11743848715, "can": 11.7626139142, "avail": 5.1865403463, "littl": 1.5499365420299998, "give": 1.3653250774, "make": 1.0762660158600001, "nevertheless": 4.1988891827599994, "sensibl": 24.164383561599998, "onli": 1.0256476516600002, "each": 2.37949640288, "size": 4.9877474081, "train": 3.8731397901999998, "often": 1.29452054795, "fakenewsnet": 1323.0, "formula": 8.64235166032, "avoid": 2.45986984816, "thing": 4.813096862219999, "read": 2.3149606299200003, "framework": 8.200413223139998, "bot": 341.419354838, "ask": 2.1744966443, "data": 10.12930667802, "reduc": 1.98698372966, "userus": 1323.0, "adjac": 12.481132075480001, "rather": 1.55692850838, "whether": 4.41367806506, "into": 4.06009845916, "paper": 5.325729620940001, "bias": 54.9342560552, "might": 2.1561863370900003, "dimens": 8.25585023401, "dxm": 1323.0, "learn": 16.259253840550002, "sinc": 1.08368600683, "dimension": 108.3686006826, "nonneg": 2540.16, "mimick": 131.2066115702, "last": 1.2117234010100002, "import": 1.3401992233700002, "first": 2.01523229246, "everi": 1.47917637194, "input": 36.6087624903, "share": 9.28312478075, "have": 13.193632934819998, "relationship": 2.39132399458, "guess": 25.0410094637, "against": 1.2902072328299998, "publishernew": 2646.0, "help": 1.39962972759, "trirelationship": 3969.0, "larg": 1.18574949585, "find": 5.188235294129999, "within": 1.2369302688, "recal": 5.30614973262, "down": 1.35889754344, "inde": 4.43092380687, "retweet": 1323.0}, "logtfidf": {"base": 0.27304660457400004, "relat": 0.8524012066159999, "label": 10.49291829089, "vulner": 2.18259291507, "art": 0.6928952596619999, "who": 0.0609002329859, "collabor": 1.4939250253100003, "hot": 1.52991862796, "onc": 0.403765872355, "this": 0.0492238376825, "leftbia": 7.18765716411, "here": 2.6551145651100003, "dispos": 2.34544052164, "heavi": 1.0602422774, "form": 0.120053184191, "factor": 2.12339629324, "lowcred": 7.18765716411, "space": 2.624139494916, "through": 0.0683586918849, "comput": 2.73613783188, "surpris": 1.47392435861, "engag": 0.990534380034, "much": 0.17749572930100002, "bagofword": 14.37531432822, "evalu": 3.8777604862599997, "than": 0.0645217244364, "belong": 1.2527629685, "dataset": 15.79753369992, "problem": 1.138281448546, "articl": 7.02131739574, "intent": 1.16118750781, "obfusc": 5.206655695249999, "optimis": 4.87677326831, "context": 5.79681965768, "smaller": 0.9530830530519999, "just": 0.868594302327, "product": 0.484060136536, "accel": 7.18765716411, "otherwis": 1.3141319148700001, "creation": 1.11846026847, "rightcent": 7.18765716411, "binari": 3.4781584227999995, "permiss": 1.8373800586400002, "classifi": 6.666118540599999, "know": 1.905839388796, "credibl": 22.007245038, "should": 1.018839753516, "dxd": 7.18765716411, "contribut": 0.655201578909, "usernew": 21.56297149233, "seek": 1.04293519316, "where": 0.19497641623710002, "rememb": 1.5867691126199999, "measur": 0.880014199726, "instead": 0.46663315041500003, "their": 0.015360505122700001, "weight": 6.33969410448, "among": 0.228496097073, "rightbia": 7.18765716411, "intuit": 6.643356194380001, "how": 1.8862678277200002, "deliber": 1.8373800586400002, "sketch": 2.39393487158, "news": 33.72927338031, "guid": 0.912738218589, "fraction": 2.63729521462, "matric": 13.718092158240001, "that": 0.07157067083351999, "latent": 33.56880209576, "keep": 0.7141523446729999, "represent": 5.33921486295, "end": 0.101476798618, "they": 0.0891809843028, "correl": 2.57915918803, "word": 1.757583247155, "raw": 2.36536149914, "social": 6.88371502261, "effect": 0.667660454316, "will": 0.40557306983, "true": 3.753302518536, "the": 0.0, "consid": 0.429789447648, "shape": 4.6568382846, "see": 0.240921585492, "those": 0.35709878174599996, "buzzfe": 7.033506484289999, "encod": 16.8405750574, "normalis": 5.38210437275, "seem": 1.658186064552, "number": 0.2898257352558, "clue": 3.41489622602, "repost": 6.83935046985, "linear": 5.26055528392, "regularis": 12.35211250488, "perform": 0.42618085058, "but": 0.0323847441438, "our": 1.7152784283640001, "there": 0.12029367877649999, "friend": 0.7893395836239999, "colyer": 7.18765716411, "object": 0.853933584803, "inform": 0.908907409324, "expect": 0.78850775216, "matrix": 53.016716967959994, "user": 51.064702671999996, "applic": 1.23160392849, "semisupervis": 7.18765716411, "best": 0.918455865894, "exampl": 0.8173653499979999, "big": 1.00798563557, "has": 0.0854478897096, "given": 0.9097674324930001, "mislead": 6.2372608197599995, "knowledg": 1.2232212893899999, "take": 0.522767848788, "reduct": 1.8437292863099999, "use": 0.292080197316, "follow": 0.045356911094199995, "tri": 0.61759152916, "artefact": 3.90737271112, "then": 0.16606773046179998, "out": 0.0584263909193, "with": 0.00718495028034, "interact": 5.943284107159999, "desir": 2.1983586856799997, "good": 0.418589404907, "basic": 1.00436774895, "enlarg": 2.43191411965, "publish": 5.023613847472, "financi": 0.958817483446, "break": 0.88733019029, "ddimens": 14.37531432822, "also": 0.0586286312, "politifact": 7.18765716411, "time": 0.0224230377252, "member": 0.278153414599, "pictori": 3.70130197411, "mean": 0.37092128352, "vector": 9.76259663391, "partisan": 8.831805602460001, "not": 0.093314478045, "someth": 2.37661424546, "method": 0.944461608841, "major": 0.138474663439, "mxm": 7.18765716411, "adrian": 2.97306347374, "therefor": 0.847591848336, "respect": 0.49733261904, "becom": 0.11771217648900001, "stori": 0.705059626587, "quick": 0.790727508899, "angl": 2.18988198575, "perhap": 1.14680739183, "score": 4.367805962310001, "intermedi": 2.43694467284, "said": 0.87330633163, "captur": 2.1157620024200003, "exist": 0.38165779408699996, "scienc": 1.682872357782, "separ": 0.470759772949, "system": 0.327430345585, "shu": 4.860379458530001, "howev": 0.0903151173475, "leftcent": 7.18765716411, "let": 2.4976051345599997, "although": 0.139487981418, "piec": 4.70392630556, "work": 0.436138269092, "minut": 2.2707438719599997, "role": 0.44036410757399996, "which": 0.0517841384543, "featur": 2.9637119269939998, "them": 0.1883666538186, "item": 1.62505430292, "bewar": 4.87677326831, "tactic": 1.86140042888, "other": 0.00987474791976, "introduct": 1.02276465794, "togeth": 0.458032237308, "algorithm": 3.33044239518, "one": 0.0062553516455, "valu": 1.646386620296, "two": 0.0273976887164, "lot": 2.9671939005000003, "factoris": 14.37531432822, "develop": 0.178624694913, "entri": 1.38402935449, "such": 0.119391955612, "becaus": 0.139343158825, "sever": 0.13982224079379998, "mxd": 7.18765716411, "resolut": 1.74704483412, "get": 1.739307017346, "network": 2.8592491591559996, "like": 1.251482188905, "neutral": 1.9432681395900002, "abov": 0.643865229816, "some": 0.158294036258, "beyond": 0.934469583725, "small": 0.307101805059, "control": 0.7699693231720001, "both": 0.050842533389300004, "tell": 1.21236434401, "detect": 11.82147921451, "result": 0.136378908381, "put": 1.011305999708, "set": 0.171496011289, "origin": 0.257224875174, "partner": 1.4287553902399999, "includ": 0.0188846813905, "content": 11.382652435859999, "reliabl": 1.89939013342, "correspond": 1.20141456099, "rate": 2.283101616498, "term": 0.6660779670920001, "leastbia": 7.18765716411, "media": 1.9061661061039998, "pick": 1.59729226761, "ani": 0.125608358366, "pretti": 2.75684036527, "and": 0.001889704261908, "from": 0.001134108337732, "account": 1.330148579946, "similar": 0.9556682763419999, "ignor": 1.5226732694999998, "apolog": 2.63290346404, "num": 0.0018899423723820002, "embed": 45.17596050032, "same": 0.448238598416, "turn": 0.324899251064, "mediabiasfactcheckcom": 7.18765716411, "forget": 2.8330873756700004, "idea": 0.73863592212, "between": 0.06790736233059999, "low": 0.7564602833490001, "what": 0.451774593654, "for": 0.004094875140161, "predict": 1.6457402376899999, "highcred": 7.18765716411, "all": 0.057013160488999994, "version": 0.697313064259, "closer": 1.7167880323700002, "ventur": 2.04599360761, "today": 0.559395353679, "split": 1.24442043932, "written": 1.343174739666, "assum": 1.08435313525, "are": 0.294674735827, "poor": 0.8845804177050001, "case": 1.581625075556, "onion": 3.8406813366199994, "author": 1.05822429393, "section": 0.755387177948, "look": 5.1710935488, "spread": 5.20931690845, "trifn": 35.93828582055, "cluster": 10.1031665378, "public": 0.20232375048700002, "more": 0.08512465799999999, "improv": 0.7147958039319999, "overfit": 7.18765716411, "fake": 55.221069885560006, "discuss": 0.78698452262, "vocabulari": 9.442602468179999, "these": 0.0715336194008, "want": 2.0749098187649997, "negat": 1.32402598852, "combin": 2.116873243004, "posit": 0.316652318608, "sourc": 0.529218310751, "general": 0.344857734189, "made": 0.0680215260973, "overal": 2.2265388929400003, "focus": 0.6981989720559999, "comment": 1.11826753454, "tend": 1.21597024462, "state": 0.0466100027668, "close": 0.752000279592, "map": 2.80868986768, "group": 0.190594534797, "doe": 1.6021251891509998, "can": 1.6234109639399998, "avail": 1.642363758867, "littl": 0.438213989466, "give": 0.311392552224, "make": 0.07349765782289999, "nevertheless": 1.4348200100100001, "sensibl": 3.18487979542, "onli": 0.025324268329099998, "each": 0.347483378608, "size": 1.8276744121219999, "train": 1.321836625678, "often": 0.258140393351, "fakenewsnet": 7.18765716411, "formula": 2.15667472869, "avoid": 0.900108441291, "thing": 1.7563870693599999, "read": 0.83939268088, "framework": 2.10418454607, "bot": 10.2799286415, "ask": 0.776797209847, "data": 3.6504617544, "reduc": 0.686617775143, "userus": 7.18765716411, "adjac": 3.66214177888, "rather": 0.442714975539, "whether": 1.583122379294, "into": 0.0596514529148, "paper": 1.95880507933, "bias": 10.47937105868, "might": 0.7683410765340001, "dimens": 2.11092206831, "dxm": 7.18765716411, "learn": 5.899264453215, "sinc": 0.0803681994577, "dimension": 7.98478240978, "nonneg": 25.81475195612, "mimick": 8.367252175499999, "last": 0.19204364461100001, "import": 0.292818277066, "first": 0.015174579624319999, "everi": 0.391485427421, "input": 7.50502600617, "share": 3.093801498735, "have": 0.1922050304356, "relationship": 0.871847185184, "guess": 3.22051485947, "against": 0.254802851078, "publishernew": 14.37531432822, "help": 0.336207721344, "trirelationship": 21.56297149233, "larg": 0.17037506060600002, "find": 1.643343990864, "within": 0.21263272059799998, "recal": 1.6688664748100002, "down": 0.306673741186, "inde": 1.4886080966, "retweet": 7.18765716411}, "logidf": {"base": 0.13652330228700002, "relat": 0.21310030165399999, "label": 1.49898832727, "vulner": 2.18259291507, "art": 0.6928952596619999, "who": 0.0609002329859, "collabor": 1.4939250253100003, "hot": 1.52991862796, "onc": 0.403765872355, "this": 0.0037864490525, "leftbia": 7.18765716411, "here": 0.8850381883700001, "dispos": 2.34544052164, "heavi": 1.0602422774, "form": 0.120053184191, "factor": 1.06169814662, "lowcred": 7.18765716411, "space": 0.874713164972, "through": 0.0683586918849, "comput": 1.36806891594, "surpris": 1.47392435861, "engag": 0.990534380034, "much": 0.17749572930100002, "bagofword": 7.18765716411, "evalu": 1.9388802431299998, "than": 0.0322608622182, "belong": 1.2527629685, "dataset": 5.26584456664, "problem": 0.569140724273, "articl": 0.702131739574, "intent": 1.16118750781, "obfusc": 5.206655695249999, "optimis": 4.87677326831, "context": 1.44920491442, "smaller": 0.9530830530519999, "just": 0.289531434109, "product": 0.484060136536, "accel": 7.18765716411, "otherwis": 1.3141319148700001, "creation": 1.11846026847, "rightcent": 7.18765716411, "binari": 3.4781584227999995, "permiss": 1.8373800586400002, "classifi": 1.6665296351499999, "know": 0.952919694398, "credibl": 2.75090562975, "should": 0.509419876758, "dxd": 7.18765716411, "contribut": 0.655201578909, "usernew": 7.18765716411, "seek": 1.04293519316, "where": 0.0649921387457, "rememb": 1.5867691126199999, "measur": 0.880014199726, "instead": 0.46663315041500003, "their": 0.015360505122700001, "weight": 1.58492352612, "among": 0.228496097073, "rightbia": 7.18765716411, "intuit": 3.3216780971900004, "how": 0.47156695693000006, "deliber": 1.8373800586400002, "sketch": 2.39393487158, "news": 0.733245073485, "guid": 0.912738218589, "fraction": 2.63729521462, "matric": 4.572697386080001, "that": 0.00397614837964, "latent": 4.19610026197, "keep": 0.7141523446729999, "represent": 1.7797382876499999, "end": 0.101476798618, "they": 0.0297269947676, "correl": 2.57915918803, "word": 0.585861082385, "raw": 2.36536149914, "social": 0.688371502261, "effect": 0.333830227158, "will": 0.202786534915, "true": 0.938325629634, "the": 0.0, "consid": 0.214894723824, "shape": 1.16420957115, "see": 0.240921585492, "those": 0.17854939087299998, "buzzfe": 7.033506484289999, "encod": 3.36811501148, "normalis": 5.38210437275, "seem": 0.829093032276, "number": 0.0966085784186, "clue": 3.41489622602, "repost": 6.83935046985, "linear": 2.63027764196, "regularis": 6.17605625244, "perform": 0.42618085058, "but": 0.0161923720719, "our": 0.8576392141820001, "there": 0.0400978929255, "friend": 0.7893395836239999, "colyer": 7.18765716411, "object": 0.853933584803, "inform": 0.454453704662, "expect": 0.78850775216, "matrix": 3.1186304098799997, "user": 2.04258810688, "applic": 1.23160392849, "semisupervis": 7.18765716411, "best": 0.459227932947, "exampl": 0.40868267499899996, "big": 1.00798563557, "has": 0.0427239448548, "given": 0.303255810831, "mislead": 3.1186304098799997, "knowledg": 1.2232212893899999, "take": 0.130691962197, "reduct": 1.8437292863099999, "use": 0.0292080197316, "follow": 0.045356911094199995, "tri": 0.61759152916, "artefact": 3.90737271112, "then": 0.08303386523089999, "out": 0.0584263909193, "with": 0.00119749171339, "interact": 1.4858210267899998, "desir": 1.0991793428399999, "good": 0.418589404907, "basic": 1.00436774895, "enlarg": 2.43191411965, "publish": 0.313975865467, "financi": 0.958817483446, "break": 0.88733019029, "ddimens": 7.18765716411, "also": 0.0146571578, "politifact": 7.18765716411, "time": 0.0112115188626, "member": 0.278153414599, "pictori": 3.70130197411, "mean": 0.37092128352, "vector": 3.25419887797, "partisan": 2.9439352008200004, "not": 0.0155524130075, "someth": 1.18830712273, "method": 0.944461608841, "major": 0.138474663439, "mxm": 7.18765716411, "adrian": 2.97306347374, "therefor": 0.847591848336, "respect": 0.49733261904, "becom": 0.11771217648900001, "stori": 0.705059626587, "quick": 0.790727508899, "angl": 2.18988198575, "perhap": 1.14680739183, "score": 1.4559353207700003, "intermedi": 2.43694467284, "said": 0.436653165815, "captur": 1.0578810012100002, "exist": 0.38165779408699996, "scienc": 0.841436178891, "separ": 0.470759772949, "system": 0.327430345585, "shu": 4.860379458530001, "howev": 0.0903151173475, "leftcent": 7.18765716411, "let": 1.2488025672799998, "although": 0.139487981418, "piec": 1.17598157639, "work": 0.109034567273, "minut": 1.1353719359799999, "role": 0.44036410757399996, "which": 0.00517841384543, "featur": 0.423387418142, "them": 0.0941833269093, "item": 1.62505430292, "bewar": 4.87677326831, "tactic": 1.86140042888, "other": 0.00987474791976, "introduct": 1.02276465794, "togeth": 0.458032237308, "algorithm": 3.33044239518, "one": 0.0062553516455, "valu": 0.823193310148, "two": 0.0136988443582, "lot": 1.4835969502500002, "factoris": 7.18765716411, "develop": 0.178624694913, "entri": 1.38402935449, "such": 0.059695977806, "becaus": 0.139343158825, "sever": 0.06991112039689999, "mxd": 7.18765716411, "resolut": 1.74704483412, "get": 0.579769005782, "network": 0.9530830530519999, "like": 0.139053576545, "neutral": 1.9432681395900002, "abov": 0.643865229816, "some": 0.0395735090645, "beyond": 0.934469583725, "small": 0.307101805059, "control": 0.38498466158600003, "both": 0.050842533389300004, "tell": 1.21236434401, "detect": 1.68878274493, "result": 0.136378908381, "put": 0.505652999854, "set": 0.171496011289, "origin": 0.128612437587, "partner": 1.4287553902399999, "includ": 0.0188846813905, "content": 1.26473915954, "reliabl": 1.89939013342, "correspond": 1.20141456099, "rate": 0.761033872166, "term": 0.33303898354600003, "leastbia": 7.18765716411, "media": 0.9530830530519999, "pick": 1.59729226761, "ani": 0.125608358366, "pretti": 2.75684036527, "and": 6.29901420636e-05, "from": 0.000567054168866, "account": 0.665074289973, "similar": 0.318556092114, "ignor": 1.5226732694999998, "apolog": 2.63290346404, "num": 0.00031499039539700004, "embed": 2.82349753127, "same": 0.112059649604, "turn": 0.324899251064, "mediabiasfactcheckcom": 7.18765716411, "forget": 2.8330873756700004, "idea": 0.73863592212, "between": 0.033953681165299995, "low": 0.7564602833490001, "what": 0.225887296827, "for": 0.00031499039539700004, "predict": 1.6457402376899999, "highcred": 7.18765716411, "all": 0.011402632097799998, "version": 0.697313064259, "closer": 1.7167880323700002, "ventur": 2.04599360761, "today": 0.559395353679, "split": 1.24442043932, "written": 0.671587369833, "assum": 1.08435313525, "are": 0.0294674735827, "poor": 0.8845804177050001, "case": 0.395406268889, "onion": 3.8406813366199994, "author": 0.35274143130999996, "section": 0.755387177948, "look": 0.6463866936, "spread": 1.04186338169, "trifn": 7.18765716411, "cluster": 2.52579163445, "public": 0.20232375048700002, "more": 0.017024931599999998, "improv": 0.7147958039319999, "overfit": 7.18765716411, "fake": 2.9063720992400004, "discuss": 0.78698452262, "vocabulari": 3.14753415606, "these": 0.0715336194008, "want": 0.6916366062549999, "negat": 1.32402598852, "combin": 0.529218310751, "posit": 0.316652318608, "sourc": 0.529218310751, "general": 0.114952578063, "made": 0.0680215260973, "overal": 1.1132694464700001, "focus": 0.6981989720559999, "comment": 1.11826753454, "tend": 1.21597024462, "state": 0.0466100027668, "close": 0.250666759864, "map": 1.40434493384, "group": 0.190594534797, "doe": 0.5340417297169999, "can": 0.162341096394, "avail": 0.547454586289, "littl": 0.438213989466, "give": 0.311392552224, "make": 0.07349765782289999, "nevertheless": 1.4348200100100001, "sensibl": 3.18487979542, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "train": 0.660918312839, "often": 0.258140393351, "fakenewsnet": 7.18765716411, "formula": 2.15667472869, "avoid": 0.900108441291, "thing": 0.8781935346799999, "read": 0.83939268088, "framework": 2.10418454607, "bot": 5.13996432075, "ask": 0.776797209847, "data": 1.2168205848, "reduc": 0.686617775143, "userus": 7.18765716411, "adjac": 1.83107088944, "rather": 0.442714975539, "whether": 0.791561189647, "into": 0.0149128632287, "paper": 0.979402539665, "bias": 2.61984276467, "might": 0.7683410765340001, "dimens": 2.11092206831, "dxm": 7.18765716411, "learn": 0.842752064745, "sinc": 0.0803681994577, "dimension": 3.99239120489, "nonneg": 6.45368798903, "mimick": 4.1836260877499996, "last": 0.19204364461100001, "import": 0.292818277066, "first": 0.0075872898121599995, "everi": 0.391485427421, "input": 2.50167533539, "share": 0.618760299747, "have": 0.0147850023412, "relationship": 0.871847185184, "guess": 3.22051485947, "against": 0.254802851078, "publishernew": 7.18765716411, "help": 0.336207721344, "trirelationship": 7.18765716411, "larg": 0.17037506060600002, "find": 0.547781330288, "within": 0.21263272059799998, "recal": 1.6688664748100002, "down": 0.306673741186, "inde": 1.4886080966, "retweet": 7.18765716411}, "freq": {"base": 2, "relat": 4, "label": 7, "vulner": 1, "art": 1, "who": 1, "collabor": 1, "hot": 1, "onc": 1, "this": 13, "leftbia": 1, "here": 3, "dispos": 1, "heavi": 1, "form": 1, "factor": 2, "lowcred": 1, "space": 3, "through": 1, "comput": 2, "surpris": 1, "engag": 1, "much": 1, "bagofword": 2, "evalu": 2, "than": 2, "belong": 1, "dataset": 3, "problem": 2, "articl": 10, "intent": 1, "obfusc": 1, "optimis": 1, "context": 4, "smaller": 1, "just": 3, "product": 1, "accel": 1, "otherwis": 1, "creation": 1, "rightcent": 1, "binari": 1, "permiss": 1, "classifi": 4, "know": 2, "credibl": 8, "should": 2, "dxd": 1, "contribut": 1, "usernew": 3, "seek": 1, "where": 3, "rememb": 1, "measur": 1, "instead": 1, "their": 1, "weight": 4, "among": 1, "rightbia": 1, "intuit": 2, "how": 4, "deliber": 1, "sketch": 1, "news": 46, "guid": 1, "fraction": 1, "matric": 3, "that": 18, "latent": 8, "keep": 1, "represent": 3, "end": 1, "they": 3, "correl": 1, "word": 3, "raw": 1, "social": 10, "effect": 2, "will": 2, "true": 4, "the": 83, "consid": 2, "shape": 4, "see": 1, "those": 2, "buzzfe": 1, "encod": 5, "normalis": 1, "seem": 2, "number": 3, "clue": 1, "repost": 1, "linear": 2, "regularis": 2, "perform": 1, "but": 2, "our": 2, "there": 3, "friend": 1, "colyer": 1, "object": 1, "inform": 2, "expect": 1, "matrix": 17, "user": 25, "applic": 1, "semisupervis": 1, "best": 2, "exampl": 2, "big": 1, "has": 2, "given": 3, "mislead": 2, "knowledg": 1, "take": 4, "reduct": 1, "use": 10, "follow": 1, "tri": 1, "artefact": 1, "then": 2, "out": 1, "with": 6, "interact": 4, "desir": 2, "good": 1, "basic": 1, "enlarg": 1, "publish": 16, "financi": 1, "break": 1, "ddimens": 2, "also": 4, "politifact": 1, "time": 2, "member": 1, "pictori": 1, "mean": 1, "vector": 3, "partisan": 3, "not": 6, "someth": 2, "method": 1, "major": 1, "mxm": 1, "adrian": 1, "therefor": 1, "respect": 1, "becom": 1, "stori": 1, "quick": 1, "angl": 1, "perhap": 1, "score": 3, "intermedi": 1, "said": 2, "captur": 2, "exist": 1, "scienc": 2, "separ": 1, "system": 1, "shu": 1, "howev": 1, "leftcent": 1, "let": 2, "although": 1, "piec": 4, "work": 4, "minut": 2, "role": 1, "which": 10, "featur": 7, "them": 2, "item": 1, "bewar": 1, "tactic": 1, "other": 1, "introduct": 1, "togeth": 1, "algorithm": 1, "one": 1, "valu": 2, "two": 2, "lot": 2, "factoris": 2, "develop": 1, "entri": 1, "such": 2, "becaus": 1, "sever": 2, "mxd": 1, "resolut": 1, "get": 3, "network": 3, "like": 9, "neutral": 1, "abov": 1, "some": 4, "beyond": 1, "small": 1, "control": 2, "both": 1, "tell": 1, "detect": 7, "result": 1, "put": 2, "set": 1, "origin": 2, "partner": 1, "includ": 1, "content": 9, "reliabl": 1, "correspond": 1, "rate": 3, "term": 2, "leastbia": 1, "media": 2, "pick": 1, "ani": 1, "pretti": 1, "and": 30, "from": 2, "account": 2, "similar": 3, "ignor": 1, "apolog": 1, "num": 6, "embed": 16, "same": 4, "turn": 1, "mediabiasfactcheckcom": 1, "forget": 1, "idea": 1, "between": 2, "low": 1, "what": 2, "for": 13, "predict": 1, "highcred": 1, "all": 5, "version": 1, "closer": 1, "ventur": 1, "today": 1, "split": 1, "written": 2, "assum": 1, "are": 10, "poor": 1, "case": 4, "onion": 1, "author": 3, "section": 1, "look": 8, "spread": 5, "trifn": 5, "cluster": 4, "public": 1, "more": 5, "improv": 1, "overfit": 1, "fake": 19, "discuss": 1, "vocabulari": 3, "these": 1, "want": 3, "negat": 1, "combin": 4, "posit": 1, "sourc": 1, "general": 3, "made": 1, "overal": 2, "focus": 1, "comment": 1, "tend": 1, "state": 1, "close": 3, "map": 2, "group": 1, "doe": 3, "can": 10, "avail": 3, "littl": 1, "give": 1, "make": 1, "nevertheless": 1, "sensibl": 1, "onli": 1, "each": 2, "size": 2, "train": 2, "often": 1, "fakenewsnet": 1, "formula": 1, "avoid": 1, "thing": 2, "read": 1, "framework": 1, "bot": 2, "ask": 1, "data": 3, "reduc": 1, "userus": 1, "adjac": 2, "rather": 1, "whether": 2, "into": 4, "paper": 2, "bias": 4, "might": 1, "dimens": 1, "dxm": 1, "learn": 7, "sinc": 1, "dimension": 2, "nonneg": 4, "mimick": 2, "last": 1, "import": 1, "first": 2, "everi": 1, "input": 3, "share": 5, "have": 13, "relationship": 1, "guess": 1, "against": 1, "publishernew": 2, "help": 1, "trirelationship": 3, "larg": 1, "find": 3, "within": 1, "recal": 1, "down": 1, "inde": 1, "retweet": 1}, "idf": {"base": 1.14628158845, "relat": 1.23750876919, "label": 4.47715736041, "vulner": 8.869273743019999, "art": 1.9994962216599999, "who": 1.06279287723, "collabor": 4.45454545455, "hot": 4.6178010471199995, "onc": 1.4974533106999999, "this": 1.00379362671, "leftbia": 1323.0, "here": 2.42307692308, "dispos": 10.4378698225, "heavi": 2.88707037643, "form": 1.12755681818, "factor": 2.89127663449, "lowcred": 1323.0, "space": 2.39818731118, "through": 1.07074930869, "comput": 3.9277585353800006, "surpris": 4.36633663366, "engag": 2.6926729986400004, "much": 1.1942229577299999, "bagofword": 1323.0, "evalu": 6.9509632224199995, "than": 1.03278688525, "belong": 3.5, "dataset": 193.609756098, "problem": 1.76674827509, "articl": 2.01805008262, "intent": 3.19372359686, "obfusc": 182.482758621, "optimis": 131.20661157, "context": 4.25972632144, "smaller": 2.59369384088, "just": 1.33580143037, "product": 1.62264922322, "accel": 1323.0, "otherwis": 3.72151898734, "creation": 3.0601387818, "rightcent": 1323.0, "binari": 32.4, "permiss": 6.280063291139999, "classifi": 5.2937645882, "know": 2.59327017315, "credibl": 15.6568047337, "should": 1.6643254009900001, "dxd": 1323.0, "contribut": 1.9255306246200001, "usernew": 1323.0, "seek": 2.83753351206, "where": 1.06715063521, "rememb": 4.88793103448, "measur": 2.41093394077, "instead": 1.59461631177, "their": 1.01547908405, "weight": 4.878918254459999, "among": 1.25670862028, "rightbia": 1323.0, "intuit": 27.7068062827, "how": 1.60250328051, "deliber": 6.280063291139999, "sketch": 10.956521739100001, "news": 2.08182533438, "guid": 2.49113447356, "fraction": 13.9753521127, "matric": 96.80487804879999, "that": 1.00398406375, "latent": 66.42677824270001, "keep": 2.04245465071, "represent": 5.928304705, "end": 1.10680423871, "they": 1.03017325287, "correl": 13.1860465116, "word": 1.7965372864099998, "raw": 10.6478873239, "social": 1.9904714142400002, "effect": 1.3963060686000002, "will": 1.22481098596, "true": 2.55569864778, "the": 1.0, "consid": 1.2397313759200002, "shape": 3.20338983051, "see": 1.27242125511, "those": 1.19548192771, "buzzfe": 1134.0, "encod": 29.0237659963, "normalis": 217.479452055, "seem": 2.29123971713, "number": 1.10142916609, "clue": 30.4137931034, "repost": 933.882352941, "linear": 13.8776223776, "regularis": 481.09090909099996, "perform": 1.5313977042500002, "but": 1.01632417899, "our": 2.35758835759, "there": 1.04091266719, "friend": 2.20194174757, "colyer": 1323.0, "object": 2.3488681757700003, "inform": 1.5753125620200001, "expect": 2.20011086475, "matrix": 22.6153846154, "user": 7.71053909665, "applic": 3.42672134686, "semisupervis": 1323.0, "best": 1.5828514456600002, "exampl": 1.50483412322, "big": 2.7400759406299997, "has": 1.0436497502, "given": 1.35426085473, "mislead": 22.6153846154, "knowledg": 3.3981164383599998, "take": 1.13961668222, "reduct": 6.320063694269999, "use": 1.0296387573799999, "follow": 1.04640126549, "tri": 1.8544562551099997, "artefact": 49.7680250784, "then": 1.08657860516, "out": 1.06016694491, "with": 1.0011982089899998, "interact": 4.4185917061, "desir": 3.00170164492, "good": 1.51981619759, "basic": 2.7301805675, "enlarg": 11.3806451613, "publish": 1.36885669943, "financi": 2.60860992442, "break": 2.42863698944, "ddimens": 1323.0, "also": 1.01476510067, "politifact": 1323.0, "time": 1.01127460348, "member": 1.32068879461, "pictori": 40.5, "mean": 1.44906900329, "vector": 25.898858075, "partisan": 18.990430622, "not": 1.01567398119, "someth": 3.28152128979, "method": 2.5714285714300003, "major": 1.14852058164, "mxm": 1323.0, "adrian": 19.5517241379, "therefor": 2.33401940606, "respect": 1.6443293630200002, "becom": 1.12492028626, "stori": 2.02396736359, "quick": 2.205, "angl": 8.934158694430002, "perhap": 3.14812611541, "score": 4.2884927066500005, "intermedi": 11.4380403458, "said": 1.54751925139, "captur": 2.88026124819, "exist": 1.4647107666799999, "scienc": 2.31969608416, "separ": 1.6012102874399998, "system": 1.38739840951, "shu": 129.073170732, "howev": 1.0945191313299998, "leftcent": 1323.0, "let": 3.48616600791, "although": 1.14968498805, "piec": 3.24132298898, "work": 1.11520089913, "minut": 3.11233091551, "role": 1.55327267391, "which": 1.005191845, "featur": 1.52712581762, "them": 1.09876115994, "item": 5.07869481766, "bewar": 131.20661157, "tactic": 6.432739059969999, "other": 1.00992366412, "introduct": 2.7808723068799996, "togeth": 1.58095996813, "algorithm": 27.9507042254, "one": 1.00627495722, "valu": 2.2777618364400003, "two": 1.01379310345, "lot": 4.40877534018, "factoris": 1323.0, "develop": 1.1955719557200002, "entri": 3.9909502262400003, "such": 1.06151377374, "becaus": 1.1495184997499999, "sever": 1.07241286139, "mxd": 1323.0, "resolut": 5.73762197326, "get": 1.78562591385, "network": 2.59369384088, "like": 1.14918566775, "neutral": 6.981530343010001, "abov": 1.90382539873, "some": 1.04036697248, "beyond": 2.54586273252, "small": 1.3594793629, "control": 1.46959178006, "both": 1.05215720061, "tell": 3.36142282448, "detect": 5.41288782816, "result": 1.14611608432, "put": 1.65806788512, "set": 1.18707940781, "origin": 1.13724928367, "partner": 4.173501577290001, "includ": 1.0190641247799999, "content": 3.5421686747, "reliabl": 6.681818181819999, "correspond": 3.32481675393, "rate": 2.14048806795, "term": 1.39520168732, "leastbia": 1323.0, "media": 2.59369384088, "pick": 4.939639079030001, "ani": 1.13383802314, "pretti": 15.75, "and": 1.00006299213, "from": 1.00056721497, "account": 1.94463498285, "similar": 1.37514075357, "ignor": 4.58446433728, "apolog": 13.9141104294, "num": 1.00031504001, "embed": 16.835630965, "same": 1.11857958148, "turn": 1.3838912133899999, "mediabiasfactcheckcom": 1323.0, "forget": 16.9978586724, "idea": 2.0930784443, "between": 1.03453668708, "low": 2.13072070863, "what": 1.25343439128, "for": 1.00031504001, "predict": 5.18484650555, "highcred": 1323.0, "all": 1.01146788991, "version": 2.0083491461099996, "closer": 5.5666199158500005, "ventur": 7.73684210526, "today": 1.74961428257, "split": 3.4709226060300002, "written": 1.9573418813999999, "assum": 2.9575260804799997, "are": 1.02990593578, "poor": 2.42196796339, "case": 1.48498737256, "onion": 46.557184750699996, "author": 1.4229631621399998, "section": 2.1284354471099998, "look": 1.9086318826599997, "spread": 2.8344938403900004, "trifn": 1323.0, "cluster": 12.5007874016, "public": 1.22424429365, "more": 1.0171706817, "improv": 2.04376930999, "overfit": 1323.0, "fake": 18.290322580599998, "discuss": 2.19676214197, "vocabulari": 23.2785923754, "these": 1.07415426252, "want": 1.99698113208, "negat": 3.75852272727, "combin": 1.69760479042, "posit": 1.37252528746, "sourc": 1.69760479042, "general": 1.1218202374200001, "made": 1.07038834951, "overal": 3.0442953020099996, "focus": 2.01012914662, "comment": 3.05954904606, "tend": 3.3735656608599998, "state": 1.0477133240899998, "close": 1.2848818387799998, "map": 4.0728578758300005, "group": 1.20996875238, "doe": 1.70581282905, "can": 1.17626139142, "avail": 1.7288467821, "littl": 1.5499365420299998, "give": 1.3653250774, "make": 1.0762660158600001, "nevertheless": 4.1988891827599994, "sensibl": 24.164383561599998, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "train": 1.9365698950999999, "often": 1.29452054795, "fakenewsnet": 1323.0, "formula": 8.64235166032, "avoid": 2.45986984816, "thing": 2.4065484311099996, "read": 2.3149606299200003, "framework": 8.200413223139998, "bot": 170.709677419, "ask": 2.1744966443, "data": 3.37643555934, "reduc": 1.98698372966, "userus": 1323.0, "adjac": 6.240566037740001, "rather": 1.55692850838, "whether": 2.20683903253, "into": 1.01502461479, "paper": 2.6628648104700003, "bias": 13.7335640138, "might": 2.1561863370900003, "dimens": 8.25585023401, "dxm": 1323.0, "learn": 2.32275054865, "sinc": 1.08368600683, "dimension": 54.1843003413, "nonneg": 635.04, "mimick": 65.6033057851, "last": 1.2117234010100002, "import": 1.3401992233700002, "first": 1.00761614623, "everi": 1.47917637194, "input": 12.2029208301, "share": 1.8566249561500001, "have": 1.0148948411399998, "relationship": 2.39132399458, "guess": 25.0410094637, "against": 1.2902072328299998, "publishernew": 1323.0, "help": 1.39962972759, "trirelationship": 1323.0, "larg": 1.18574949585, "find": 1.7294117647099998, "within": 1.2369302688, "recal": 5.30614973262, "down": 1.35889754344, "inde": 4.43092380687, "retweet": 1323.0}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Beyond news contents: the role of social context for fake news detection</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/beyond-news-contents-role-of-social-context-for-fake-news-detection.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Beyond news contents: the role of social context for fake news detection Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/19/03-07-intuit-sr-data-scientist-business-analyst.html\" rel=\"prev\" title=\"Intuit: Sr Data Scientist, Business Analytics [Mountain View, CA]\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/neural-networks-numpy-absolute-beginners-part-2-linear-regression.html\" rel=\"next\" title=\"Neural Networks with Numpy for Absolute Beginners\u200a\u2014\u200aPart 2: Linear Regression\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/03/beyond-news-contents-role-of-social-context-for-fake-news-detection.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=91238\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/beyond-news-contents-role-of-social-context-for-fake-news-detection.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-91238 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 7-Mar, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/opinions.html\">Opinions</a> \u00bb Beyond news contents: the role of social context for fake news detection (\u00a0<a href=\"/2019/n11.html\">19:n11</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Beyond news contents: the role of social context for fake news detection</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/19/03-07-intuit-sr-data-scientist-business-analyst.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/neural-networks-numpy-absolute-beginners-part-2-linear-regression.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/fake-news\" rel=\"tag\">Fake News</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/social-media\" rel=\"tag\">Social Media</a></div>\n<br/>\n<p class=\"excerpt\">\n     Today we\u2019re looking at a more general fake news problem: detecting fake news that is being spread on a social network. This is a summary of a recent paper which demonstrates why we should also look at the social context: the publishers and the users spreading the information!\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/adrian-colyer\" rel=\"author\" title=\"Posts by Adrian Colyer\">Adrian Colyer</a>, Venture Partner, Accel.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><a href=\"http://www.public.asu.edu/~skai2/files/wsdm_2019_fake_news.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Beyond news contents: the role of social context for fake news detection</a>\u00a0Shu et al.,\u00a0<em>WSDM\u201919</em></p>\n<p>Today we\u2019re looking at a more general fake news problem: detecting fake news that is being spread on a social network. Forgetting the computer science angle for a minute, it seems intuitive to me that some important factors here might be:</p>\n<ul>\n<li><em>what</em>\u00a0is being said (the content of the news), and perhaps\u00a0<em>how</em>\u00a0it is being said (although fake news can be deliberately written to mislead users by mimicking true news)\n<li><em>where</em>\u00a0it was published (the credibility / authority of the source publication). For example, something in the Financial Times is more likely to be true than something in The Onion!\n<li><em>who</em>\u00a0is spreading the news (the credibility of the user accounts retweeting it for example \u2013 are they bots??)\n</li></li></li></ul>\n<p>Therefore I\u2019m a little surprised to read in the introduction that:</p>\n<blockquote><p>The majority of existing detection algorithms focus on finding clues from the news\u00a0<strong>content</strong>, which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news.</p></blockquote>\n<p>(The related work section does however discuss several works that include social context.).</p>\n<p>So instead of just looking at the content, we should also look at the social context: the publishers and the users spreading the information! The fake news detection system developed in this paper, TriFN considers tri-relationships between news pieces, publishers, and social network users.</p>\n<blockquote><p>\u2026 we are to our best knowledge the first to classify fake news by learning the effective news features through the tri-relationship embedding among publishers, news contents, and social engagements.</p></blockquote>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-fig-1.jpeg?w=480\"/></p>\n<p>And guess what, considering publishers and users does indeed turn out to improve fake news detection!</p>\n<p>\u00a0</p>\n<h3>Inputs</h3>\n<p>\u00a0<br>\nWe have\u00a0<img alt=\"l\" src=\"https://s0.wp.com/latex.php?latex=l&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0publishers,\u00a0<img alt=\"m\" src=\"https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0social network users, and\u00a0<img alt=\"n\" src=\"https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0news articles. Using a vocabulary of\u00a0<em>t</em>\u00a0words, we can compute an\u00a0<img alt=\"\\mathbf{X} \\in \\mathbb{R}^{n \\times t}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bn+%5Ctimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0bag-of-word feature matrix.<br>\n<img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-bag-of-words.jpeg?w=480\"/><br>\nFor the\u00a0<em>m</em>\u00a0users, we can have an\u00a0<em>m x m</em>\u00a0adjacency matrix\u00a0<img alt=\"\\mathbf{A} \\in \\{0,1\\}^{m \\times m}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bm+%5Ctimes+m%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, where\u00a0<img alt=\"\\mathbf{A}_{ij}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0is 1 if\u00a0<em>i</em>\u00a0and\u00a0<em>j</em>\u00a0are friends, and 0 otherwise.</br></br></br></p>\n<p>We also know which users have shared which news pieces, this is encoded in a matrix\u00a0<img alt=\"\\mathbf{W} \\in \\{0,1\\}^{m \\times n}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>.<br>\n<img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-bow.jpeg?w=480\"/><br/>\nThe matrix\u00a0<img alt=\"\\mathbf{B} \\in \\{0,1\\}^{l \\times n}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BB%7D+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bl+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0similarly encodes which publishers have published which news pieces.</br></p>\n<p>For some publishers, we can know their partisan bias. In this work, bias ratings from\u00a0<a href=\"https://mediabiasfactcheck.com/\" rel=\"noopener noreferrer\" target=\"_blank\">mediabiasfactcheck.com</a>\u00a0are used, taking just the \u2018Left-Bias\u2019, \u2018Least-Bias\u2019 (neutral) and \u2018Right-Bias\u2019 values (ignoring the intermediate left-center and right-center values) and encoding these as -1, 0, and 1 respectively in a publisher partisan label vector,\u00a0<img alt=\"\\mathbf{o}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bo%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. Not every publisher will have a bias rating available. We\u2019d like to put \u2018-\u2019 in the entry for that publisher in\u00a0<img alt=\"\\mathbf{o}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bo%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0but since we can\u2019t do that, the separate vector\u00a0<img alt=\"\\mathbf{e} \\in \\{0,1\\}^l\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Be%7D+%5Cin+%5C%7B0%2C1%5C%7D%5El&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0encodes whether or not we have a bias rating available for publisher\u00a0<em>p</em>.</p>\n<p>There\u2019s one last thing at our disposal: a labelled dataset for news articles telling us whether they are fake or not. (Here we have just the news article content, not the social context).</p>\n<p>\u00a0</p>\n<h3>The Tri-relationship embedding framework</h3>\n<p>\u00a0<br/>\nTriFN takes all of those inputs and combines them with a fake news binary classifier. Given lots of users and lots of news articles, we can expect some of the raw inputs to be pretty big, so the authors make heavy use of dimensionality reduction using non-negative matrix factorisation to learn latent space embeddings (more on that in a minute!) TriFN combines:</p>\n<ul>\n<li>A news content embedding\n<li>A user embedding\n<li>A user-news interaction embedding\n<li>A publisher-news interaction embedding, and\n<li>The prediction made by a linear classifier trained on the labelled fake news dataset\n</li></li></li></li></li></ul>\n<p>Pictorially it looks like this (with apologies for the poor resolution, which is an artefact of the original):</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-fig-2.jpeg?w=520\"/></p>\n<p><b>News content embedding</b></p>\n<p>Let\u2019s take a closer look at non-negative matrix factorisation (NMF) to see how this works to reduce dimensionality. Remember the bag-of-words sketch for news articles? That\u2019s an\u00a0<em>n x t</em>\u00a0matrix where\u00a0<em>n</em>\u00a0is the number of news articles and\u00a0<em>t</em>\u00a0is the number of words in the vocabulary. NMF tries to learn a latent embedding that captures the information in the matrix in a much smaller space. In the general form NMF seeks to factor a (non-negative) matrix\u00a0<em>M</em>\u00a0into the product of two (non-negative) matrices\u00a0<em>W</em>\u00a0and\u00a0<em>H</em>\u00a0(or\u00a0<em>D</em>\u00a0and\u00a0<em>V</em>\u00a0as used in this paper). How does that help us? We can pick some dimension\u00a0<em>d</em>\u00a0(controlling the size of the latent space) and break down the\u00a0<img alt=\"\\mathbf{X} \\in \\mathbb{R}^{n \\times t}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bn+%5Ctimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0matrix into a d-dimension representation of news articles\u00a0<img alt=\"\\mathbf{D} \\in \\mathbb{R}^{n \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bn+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, and a d-dimension representation of words in the vocabulary,\u00a0<img alt=\"\\mathbf{V} \\in \\mathbb{R}^{t \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BV%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bt+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. That means that\u00a0<img alt=\"\\mathbf{V}^T\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BV%7D%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0has shape\u00a0<img alt=\"d \\times t\" src=\"https://s0.wp.com/latex.php?latex=d+%5Ctimes+t&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0and so\u00a0<img alt=\"DV^T\" src=\"https://s0.wp.com/latex.php?latex=DV%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0ends up with the desired shape\u00a0<img alt=\"n \\times t\" src=\"https://s0.wp.com/latex.php?latex=n+%5Ctimes+t&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. Once we\u2019ve learned a good representation of news articles,\u00a0<img alt=\"\\mathbf{D}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>we can use those as the news content embeddings within TriFN.</p>\n<p>We\u2019d like to get\u00a0<img alt=\"\\mathbf{DV}^T\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BDV%7D%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0as close to\u00a0<img alt=\"\\mathbf{X}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0as we can, and at the same time keep\u00a0<img alt=\"\\mathbf{D}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0and\u00a0<img alt=\"\\mathbf{T}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u2018sensible\u2019 to avoid over-fitting. We can do that with a regularisation term. So the overall optimisation problem looks like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-1.jpeg?w=520\"/></p>\n<p><b>User embedding</b></p>\n<p>For the user embedding there\u2019s a similar application of NMF, but in this case we\u2019re splitting the adjacency matrix\u00a0<img alt=\"\\mathbf{A}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0into a user latent matrix\u00a0<img alt=\"\\mathbf{U} \\in \\mathbb{R}^{m \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BU%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bm+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, and a user correlation matrix\u00a0<img alt=\"\\mathbf{T} \\in \\mathbb{R}^{d \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BT%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. So in this case we\u2019re using NMF to learn\u00a0<img alt=\"\\mathbf{UTU^T}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BUTU%5ET%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>which has shape\u00a0<em>mxd</em>\u00a0.\u00a0<em>dxd</em>\u00a0.\u00a0<em>dxm</em>, resulting in the desired\u00a0<em>mxm</em>\u00a0shape. There\u2019s also a user-user relation matrix\u00a0<img alt=\"\\mathbf{Y}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BY%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0which controls the contribution of\u00a0<img alt=\"\\mathbf{A}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. The basic idea is that any given user will only share a small fraction of news articles, so a positive case (having shared an article) should have more weight than a negative case (not having shared).</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-2-1.jpeg?w=480\"/></p>\n<p><b>User-news interaction embedding</b></p>\n<p>For the user-news interaction embedding we want to capture the relationship between user features and the labels of news items. The intuition is that users with low credibility are more likely to spread fake news. So how do we get user credibility? Following \u2018<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.448.6408&amp;rep=rep1&amp;type=pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Measuring user credibility in social media</a>\u2019 the authors base this on similarity to other users. First users are clustered into groups such that members of the same cluster all tend to share the same news stories. Then each cluster is given a credibility score based on its relative size. Users take on the credibility score of the cluster they belong to. It all seems rather vulnerable to the creation of large numbers of fake bot accounts that collaborate to spread fake news if you ask me. Nevertheless, assuming we have reliable credibility scores then we want to set things up such that the latent features of high-credibility users are close to true news, and the latent features of low-credibility users are close to fake news.</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-2.jpeg?w=640\"/></p>\n<p><b>Publisher-news embeddings</b></p>\n<p>Recall we have the matrix\u00a0<img alt=\"\\mathbf{B}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0encoding which publishers have published which news pieces. Let\u00a0<img alt=\"\\bar{\\mathbf{B}}\" src=\"https://s0.wp.com/latex.php?latex=%5Cbar%7B%5Cmathbf%7BB%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0be the normalised version of the same. We want to find\u00a0<img alt=\"\\mathbf{q}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, a weighting matrix mapping news publisher\u2019s latent features to the corresponding partisan label vector\u00a0<img alt=\"\\mathbf{o}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bo%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. It looks like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-9.jpeg?w=640\"/></p>\n<p><b>Semi-supervised linear classifier</b></p>\n<p>Using the labelled data available, we also learn a weighting matrix\u00a0<img alt=\"\\mathbf{p}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0mapping news latent features to fake news labels.</p>\n<p><b>Putting it all together</b></p>\n<p>The overall objective becomes to find matrices\u00a0<img alt=\"\\mathbf{D,U,V,T,p,q}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%2CU%2CV%2CT%2Cp%2Cq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0using a weighted combination of each of the above embedding formulae, and a regularisation term combining all of the learned matrices.</p>\n<p>It looks like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-11.jpeg?w=640\"/></p>\n<p>and it\u2019s trained like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-alg-1.jpeg?w=480\"/></p>\n<p>\u00a0</p>\n<h3>Evaluation</h3>\n<p>\u00a0<br/>\nTriFN is evaluated against several state of the art fake news detection methods using the FakeNewsNet BuzzFeed and PolitiFact datasets.</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-table-1.jpeg?w=480\"/></p>\n<p>It gives the best performance on both of them:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-table-2.jpeg?w=640\"/></p>\n<p>(<a href=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-table-2.jpeg\" rel=\"noopener noreferrer\" target=\"_blank\">Enlarge</a>)</p>\n<p>\u00a0<br/>\n<a href=\"https://blog.acolyer.org/2019/02/13/beyond-news-contents-the-role-of-social-context-for-fake-news-detection/\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/10/guide-fake-news-detection-social-media.html\">A Quick Guide to Fake News Detection on Social Media</a>\n<li><a href=\"/2017/04/beware-two-data-obfuscation-tactics.html\">Beware of Two Data Obfuscation Tactics</a>\n<li><a href=\"/2017/03/getting-hot-here-data-science-vs-fake-news.html\">It\u2019s Getting Hot In Here: Data Science vs Fake News</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/19/03-07-intuit-sr-data-scientist-business-analyst.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/neural-networks-numpy-absolute-beginners-part-2-linear-regression.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/opinions.html\">Opinions</a> \u00bb Beyond news contents: the role of social context for fake news detection (\u00a0<a href=\"/2019/n11.html\">19:n11</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556326995\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.631 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 21:03:15 -->\n<!-- Compression = gzip -->", "content_tokenized": ["adrian", "colyer", "ventur", "partner", "accel", "comment", "beyond", "news", "content", "the", "role", "social", "context", "for", "fake", "news", "detect", "shu", "num", "today", "look", "more", "general", "fake", "news", "problem", "detect", "fake", "news", "that", "spread", "social", "network", "forget", "the", "comput", "scienc", "angl", "for", "minut", "seem", "intuit", "that", "some", "import", "factor", "here", "might", "what", "said", "the", "content", "the", "news", "and", "perhap", "how", "said", "although", "fake", "news", "can", "deliber", "written", "mislead", "user", "mimick", "true", "news", "where", "publish", "the", "credibl", "author", "the", "sourc", "public", "for", "exampl", "someth", "the", "financi", "time", "more", "like", "true", "than", "someth", "the", "onion", "who", "spread", "the", "news", "the", "credibl", "the", "user", "account", "retweet", "for", "exampl", "are", "they", "bot", "therefor", "littl", "surpris", "read", "the", "introduct", "that", "the", "major", "exist", "detect", "algorithm", "focus", "find", "clue", "from", "the", "news", "content", "which", "are", "general", "not", "effect", "becaus", "fake", "news", "often", "intent", "written", "mislead", "user", "mimick", "true", "news", "the", "relat", "work", "section", "doe", "howev", "discuss", "sever", "work", "that", "includ", "social", "context", "instead", "just", "look", "the", "content", "should", "also", "look", "the", "social", "context", "the", "publish", "and", "the", "user", "spread", "the", "inform", "the", "fake", "news", "detect", "system", "develop", "this", "paper", "trifn", "consid", "trirelationship", "between", "news", "piec", "publish", "and", "social", "network", "user", "are", "our", "best", "knowledg", "the", "first", "classifi", "fake", "news", "learn", "the", "effect", "news", "featur", "through", "the", "trirelationship", "embed", "among", "publish", "news", "content", "and", "social", "engag", "and", "guess", "what", "consid", "publish", "and", "user", "doe", "inde", "turn", "out", "improv", "fake", "news", "detect", "input", "have", "publish", "social", "network", "user", "and", "news", "articl", "use", "vocabulari", "word", "can", "comput", "bagofword", "featur", "matrix", "for", "the", "user", "can", "have", "adjac", "matrix", "where", "num", "and", "are", "friend", "and", "num", "otherwis", "also", "know", "which", "user", "have", "share", "which", "news", "piec", "this", "encod", "matrix", "the", "matrix", "similar", "encod", "which", "publish", "have", "publish", "which", "news", "piec", "for", "some", "publish", "can", "know", "their", "partisan", "bias", "this", "work", "bias", "rate", "from", "mediabiasfactcheckcom", "are", "use", "take", "just", "the", "leftbia", "leastbia", "neutral", "and", "rightbia", "valu", "ignor", "the", "intermedi", "leftcent", "and", "rightcent", "valu", "and", "encod", "these", "num", "num", "and", "num", "respect", "publish", "partisan", "label", "vector", "not", "everi", "publish", "will", "have", "bias", "rate", "avail", "like", "put", "the", "entri", "for", "that", "publish", "but", "sinc", "can", "that", "the", "separ", "vector", "encod", "whether", "not", "have", "bias", "rate", "avail", "for", "publish", "there", "one", "last", "thing", "our", "dispos", "label", "dataset", "for", "news", "articl", "tell", "whether", "they", "are", "fake", "not", "here", "have", "just", "the", "news", "articl", "content", "not", "the", "social", "context", "the", "trirelationship", "embed", "framework", "trifn", "take", "all", "those", "input", "and", "combin", "them", "with", "fake", "news", "binari", "classifi", "given", "lot", "user", "and", "lot", "news", "articl", "can", "expect", "some", "the", "raw", "input", "pretti", "big", "the", "author", "make", "heavi", "use", "dimension", "reduct", "use", "nonneg", "matrix", "factoris", "learn", "latent", "space", "embed", "more", "that", "minut", "trifn", "combin", "news", "content", "embed", "user", "embed", "usernew", "interact", "embed", "publishernew", "interact", "embed", "and", "the", "predict", "made", "linear", "classifi", "train", "the", "label", "fake", "news", "dataset", "pictori", "look", "like", "this", "with", "apolog", "for", "the", "poor", "resolut", "which", "artefact", "the", "origin", "news", "content", "embed", "let", "take", "closer", "look", "nonneg", "matrix", "factoris", "see", "how", "this", "work", "reduc", "dimension", "rememb", "the", "bagofword", "sketch", "for", "news", "articl", "that", "matrix", "where", "the", "number", "news", "articl", "and", "the", "number", "word", "the", "vocabulari", "tri", "learn", "latent", "embed", "that", "captur", "the", "inform", "the", "matrix", "much", "smaller", "space", "the", "general", "form", "seek", "factor", "nonneg", "matrix", "into", "the", "product", "two", "nonneg", "matric", "and", "and", "use", "this", "paper", "how", "doe", "that", "help", "can", "pick", "some", "dimens", "control", "the", "size", "the", "latent", "space", "and", "break", "down", "the", "matrix", "into", "ddimens", "represent", "news", "articl", "and", "ddimens", "represent", "word", "the", "vocabulari", "that", "mean", "that", "has", "shape", "and", "end", "with", "the", "desir", "shape", "onc", "learn", "good", "represent", "news", "articl", "can", "use", "those", "the", "news", "content", "embed", "within", "trifn", "like", "get", "close", "can", "and", "the", "same", "time", "keep", "and", "sensibl", "avoid", "overfit", "can", "that", "with", "regularis", "term", "the", "overal", "optimis", "problem", "look", "like", "this", "user", "embed", "for", "the", "user", "embed", "there", "similar", "applic", "but", "this", "case", "split", "the", "adjac", "matrix", "into", "user", "latent", "matrix", "and", "user", "correl", "matrix", "this", "case", "use", "learn", "which", "has", "shape", "mxd", "dxd", "dxm", "result", "the", "desir", "mxm", "shape", "there", "also", "userus", "relat", "matrix", "which", "control", "the", "contribut", "the", "basic", "idea", "that", "ani", "given", "user", "will", "onli", "share", "small", "fraction", "news", "articl", "posit", "case", "have", "share", "articl", "should", "have", "more", "weight", "than", "negat", "case", "not", "have", "share", "usernew", "interact", "embed", "for", "the", "usernew", "interact", "embed", "want", "captur", "the", "relationship", "between", "user", "featur", "and", "the", "label", "news", "item", "the", "intuit", "that", "user", "with", "low", "credibl", "are", "more", "like", "spread", "fake", "news", "how", "get", "user", "credibl", "follow", "measur", "user", "credibl", "social", "media", "the", "author", "base", "this", "similar", "other", "user", "first", "user", "are", "cluster", "into", "group", "such", "that", "member", "the", "same", "cluster", "all", "tend", "share", "the", "same", "news", "stori", "then", "each", "cluster", "given", "credibl", "score", "base", "relat", "size", "user", "take", "the", "credibl", "score", "the", "cluster", "they", "belong", "all", "seem", "rather", "vulner", "the", "creation", "larg", "number", "fake", "bot", "account", "that", "collabor", "spread", "fake", "news", "ask", "nevertheless", "assum", "have", "reliabl", "credibl", "score", "then", "want", "set", "thing", "such", "that", "the", "latent", "featur", "highcred", "user", "are", "close", "true", "news", "and", "the", "latent", "featur", "lowcred", "user", "are", "close", "fake", "news", "publishernew", "embed", "recal", "have", "the", "matrix", "encod", "which", "publish", "have", "publish", "which", "news", "piec", "let", "the", "normalis", "version", "the", "same", "want", "find", "weight", "matrix", "map", "news", "publish", "latent", "featur", "the", "correspond", "partisan", "label", "vector", "look", "like", "this", "semisupervis", "linear", "classifi", "use", "the", "label", "data", "avail", "also", "learn", "weight", "matrix", "map", "news", "latent", "featur", "fake", "news", "label", "put", "all", "togeth", "the", "overal", "object", "becom", "find", "matric", "use", "weight", "combin", "each", "the", "abov", "embed", "formula", "and", "regularis", "term", "combin", "all", "the", "learn", "matric", "look", "like", "this", "and", "train", "like", "this", "evalu", "trifn", "evalu", "against", "sever", "state", "the", "art", "fake", "news", "detect", "method", "use", "the", "fakenewsnet", "buzzfe", "and", "politifact", "dataset", "give", "the", "best", "perform", "both", "them", "enlarg", "origin", "repost", "with", "permiss", "relat", "quick", "guid", "fake", "news", "detect", "social", "media", "bewar", "two", "data", "obfusc", "tactic", "get", "hot", "here", "data", "scienc", "fake", "news"], "timestamp_scraper": 1556362686.644697, "title": "Beyond news contents: the role of social context for fake news detection", "read_time": 385.2, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/adrian-colyer\" rel=\"author\" title=\"Posts by Adrian Colyer\">Adrian Colyer</a>, Venture Partner, Accel.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><a href=\"http://www.public.asu.edu/~skai2/files/wsdm_2019_fake_news.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Beyond news contents: the role of social context for fake news detection</a>\u00a0Shu et al.,\u00a0<em>WSDM\u201919</em></p>\n<p>Today we\u2019re looking at a more general fake news problem: detecting fake news that is being spread on a social network. Forgetting the computer science angle for a minute, it seems intuitive to me that some important factors here might be:</p>\n<ul>\n<li><em>what</em>\u00a0is being said (the content of the news), and perhaps\u00a0<em>how</em>\u00a0it is being said (although fake news can be deliberately written to mislead users by mimicking true news)\n<li><em>where</em>\u00a0it was published (the credibility / authority of the source publication). For example, something in the Financial Times is more likely to be true than something in The Onion!\n<li><em>who</em>\u00a0is spreading the news (the credibility of the user accounts retweeting it for example \u2013 are they bots??)\n</li></li></li></ul>\n<p>Therefore I\u2019m a little surprised to read in the introduction that:</p>\n<blockquote><p>The majority of existing detection algorithms focus on finding clues from the news\u00a0<strong>content</strong>, which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news.</p></blockquote>\n<p>(The related work section does however discuss several works that include social context.).</p>\n<p>So instead of just looking at the content, we should also look at the social context: the publishers and the users spreading the information! The fake news detection system developed in this paper, TriFN considers tri-relationships between news pieces, publishers, and social network users.</p>\n<blockquote><p>\u2026 we are to our best knowledge the first to classify fake news by learning the effective news features through the tri-relationship embedding among publishers, news contents, and social engagements.</p></blockquote>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-fig-1.jpeg?w=480\"/></p>\n<p>And guess what, considering publishers and users does indeed turn out to improve fake news detection!</p>\n<p>\u00a0</p>\n<h3>Inputs</h3>\n<p>\u00a0<br>\nWe have\u00a0<img alt=\"l\" src=\"https://s0.wp.com/latex.php?latex=l&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0publishers,\u00a0<img alt=\"m\" src=\"https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0social network users, and\u00a0<img alt=\"n\" src=\"https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0news articles. Using a vocabulary of\u00a0<em>t</em>\u00a0words, we can compute an\u00a0<img alt=\"\\mathbf{X} \\in \\mathbb{R}^{n \\times t}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bn+%5Ctimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0bag-of-word feature matrix.<br>\n<img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-bag-of-words.jpeg?w=480\"/><br>\nFor the\u00a0<em>m</em>\u00a0users, we can have an\u00a0<em>m x m</em>\u00a0adjacency matrix\u00a0<img alt=\"\\mathbf{A} \\in \\{0,1\\}^{m \\times m}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bm+%5Ctimes+m%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, where\u00a0<img alt=\"\\mathbf{A}_{ij}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0is 1 if\u00a0<em>i</em>\u00a0and\u00a0<em>j</em>\u00a0are friends, and 0 otherwise.</br></br></br></p>\n<p>We also know which users have shared which news pieces, this is encoded in a matrix\u00a0<img alt=\"\\mathbf{W} \\in \\{0,1\\}^{m \\times n}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BW%7D+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>.<br>\n<img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-bow.jpeg?w=480\"/><br/>\nThe matrix\u00a0<img alt=\"\\mathbf{B} \\in \\{0,1\\}^{l \\times n}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BB%7D+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bl+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0similarly encodes which publishers have published which news pieces.</br></p>\n<p>For some publishers, we can know their partisan bias. In this work, bias ratings from\u00a0<a href=\"https://mediabiasfactcheck.com/\" rel=\"noopener noreferrer\" target=\"_blank\">mediabiasfactcheck.com</a>\u00a0are used, taking just the \u2018Left-Bias\u2019, \u2018Least-Bias\u2019 (neutral) and \u2018Right-Bias\u2019 values (ignoring the intermediate left-center and right-center values) and encoding these as -1, 0, and 1 respectively in a publisher partisan label vector,\u00a0<img alt=\"\\mathbf{o}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bo%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. Not every publisher will have a bias rating available. We\u2019d like to put \u2018-\u2019 in the entry for that publisher in\u00a0<img alt=\"\\mathbf{o}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bo%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0but since we can\u2019t do that, the separate vector\u00a0<img alt=\"\\mathbf{e} \\in \\{0,1\\}^l\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Be%7D+%5Cin+%5C%7B0%2C1%5C%7D%5El&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0encodes whether or not we have a bias rating available for publisher\u00a0<em>p</em>.</p>\n<p>There\u2019s one last thing at our disposal: a labelled dataset for news articles telling us whether they are fake or not. (Here we have just the news article content, not the social context).</p>\n<p>\u00a0</p>\n<h3>The Tri-relationship embedding framework</h3>\n<p>\u00a0<br/>\nTriFN takes all of those inputs and combines them with a fake news binary classifier. Given lots of users and lots of news articles, we can expect some of the raw inputs to be pretty big, so the authors make heavy use of dimensionality reduction using non-negative matrix factorisation to learn latent space embeddings (more on that in a minute!) TriFN combines:</p>\n<ul>\n<li>A news content embedding\n<li>A user embedding\n<li>A user-news interaction embedding\n<li>A publisher-news interaction embedding, and\n<li>The prediction made by a linear classifier trained on the labelled fake news dataset\n</li></li></li></li></li></ul>\n<p>Pictorially it looks like this (with apologies for the poor resolution, which is an artefact of the original):</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-fig-2.jpeg?w=520\"/></p>\n<p><b>News content embedding</b></p>\n<p>Let\u2019s take a closer look at non-negative matrix factorisation (NMF) to see how this works to reduce dimensionality. Remember the bag-of-words sketch for news articles? That\u2019s an\u00a0<em>n x t</em>\u00a0matrix where\u00a0<em>n</em>\u00a0is the number of news articles and\u00a0<em>t</em>\u00a0is the number of words in the vocabulary. NMF tries to learn a latent embedding that captures the information in the matrix in a much smaller space. In the general form NMF seeks to factor a (non-negative) matrix\u00a0<em>M</em>\u00a0into the product of two (non-negative) matrices\u00a0<em>W</em>\u00a0and\u00a0<em>H</em>\u00a0(or\u00a0<em>D</em>\u00a0and\u00a0<em>V</em>\u00a0as used in this paper). How does that help us? We can pick some dimension\u00a0<em>d</em>\u00a0(controlling the size of the latent space) and break down the\u00a0<img alt=\"\\mathbf{X} \\in \\mathbb{R}^{n \\times t}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bn+%5Ctimes+t%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0matrix into a d-dimension representation of news articles\u00a0<img alt=\"\\mathbf{D} \\in \\mathbb{R}^{n \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bn+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, and a d-dimension representation of words in the vocabulary,\u00a0<img alt=\"\\mathbf{V} \\in \\mathbb{R}^{t \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BV%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bt+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. That means that\u00a0<img alt=\"\\mathbf{V}^T\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BV%7D%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0has shape\u00a0<img alt=\"d \\times t\" src=\"https://s0.wp.com/latex.php?latex=d+%5Ctimes+t&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0and so\u00a0<img alt=\"DV^T\" src=\"https://s0.wp.com/latex.php?latex=DV%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0ends up with the desired shape\u00a0<img alt=\"n \\times t\" src=\"https://s0.wp.com/latex.php?latex=n+%5Ctimes+t&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. Once we\u2019ve learned a good representation of news articles,\u00a0<img alt=\"\\mathbf{D}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>we can use those as the news content embeddings within TriFN.</p>\n<p>We\u2019d like to get\u00a0<img alt=\"\\mathbf{DV}^T\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BDV%7D%5ET&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0as close to\u00a0<img alt=\"\\mathbf{X}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BX%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0as we can, and at the same time keep\u00a0<img alt=\"\\mathbf{D}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0and\u00a0<img alt=\"\\mathbf{T}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BT%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u2018sensible\u2019 to avoid over-fitting. We can do that with a regularisation term. So the overall optimisation problem looks like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-1.jpeg?w=520\"/></p>\n<p><b>User embedding</b></p>\n<p>For the user embedding there\u2019s a similar application of NMF, but in this case we\u2019re splitting the adjacency matrix\u00a0<img alt=\"\\mathbf{A}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0into a user latent matrix\u00a0<img alt=\"\\mathbf{U} \\in \\mathbb{R}^{m \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BU%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bm+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, and a user correlation matrix\u00a0<img alt=\"\\mathbf{T} \\in \\mathbb{R}^{d \\times d}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BT%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bd+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. So in this case we\u2019re using NMF to learn\u00a0<img alt=\"\\mathbf{UTU^T}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BUTU%5ET%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>which has shape\u00a0<em>mxd</em>\u00a0.\u00a0<em>dxd</em>\u00a0.\u00a0<em>dxm</em>, resulting in the desired\u00a0<em>mxm</em>\u00a0shape. There\u2019s also a user-user relation matrix\u00a0<img alt=\"\\mathbf{Y}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BY%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0which controls the contribution of\u00a0<img alt=\"\\mathbf{A}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. The basic idea is that any given user will only share a small fraction of news articles, so a positive case (having shared an article) should have more weight than a negative case (not having shared).</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-2-1.jpeg?w=480\"/></p>\n<p><b>User-news interaction embedding</b></p>\n<p>For the user-news interaction embedding we want to capture the relationship between user features and the labels of news items. The intuition is that users with low credibility are more likely to spread fake news. So how do we get user credibility? Following \u2018<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.448.6408&amp;rep=rep1&amp;type=pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Measuring user credibility in social media</a>\u2019 the authors base this on similarity to other users. First users are clustered into groups such that members of the same cluster all tend to share the same news stories. Then each cluster is given a credibility score based on its relative size. Users take on the credibility score of the cluster they belong to. It all seems rather vulnerable to the creation of large numbers of fake bot accounts that collaborate to spread fake news if you ask me. Nevertheless, assuming we have reliable credibility scores then we want to set things up such that the latent features of high-credibility users are close to true news, and the latent features of low-credibility users are close to fake news.</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-2.jpeg?w=640\"/></p>\n<p><b>Publisher-news embeddings</b></p>\n<p>Recall we have the matrix\u00a0<img alt=\"\\mathbf{B}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BB%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0encoding which publishers have published which news pieces. Let\u00a0<img alt=\"\\bar{\\mathbf{B}}\" src=\"https://s0.wp.com/latex.php?latex=%5Cbar%7B%5Cmathbf%7BB%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0be the normalised version of the same. We want to find\u00a0<img alt=\"\\mathbf{q}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>, a weighting matrix mapping news publisher\u2019s latent features to the corresponding partisan label vector\u00a0<img alt=\"\\mathbf{o}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bo%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>. It looks like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-9.jpeg?w=640\"/></p>\n<p><b>Semi-supervised linear classifier</b></p>\n<p>Using the labelled data available, we also learn a weighting matrix\u00a0<img alt=\"\\mathbf{p}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7Bp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0mapping news latent features to fake news labels.</p>\n<p><b>Putting it all together</b></p>\n<p>The overall objective becomes to find matrices\u00a0<img alt=\"\\mathbf{D,U,V,T,p,q}\" src=\"https://s0.wp.com/latex.php?latex=%5Cmathbf%7BD%2CU%2CV%2CT%2Cp%2Cq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0\"/>\u00a0using a weighted combination of each of the above embedding formulae, and a regularisation term combining all of the learned matrices.</p>\n<p>It looks like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-eqn-11.jpeg?w=640\"/></p>\n<p>and it\u2019s trained like this:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-alg-1.jpeg?w=480\"/></p>\n<p>\u00a0</p>\n<h3>Evaluation</h3>\n<p>\u00a0<br/>\nTriFN is evaluated against several state of the art fake news detection methods using the FakeNewsNet BuzzFeed and PolitiFact datasets.</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-table-1.jpeg?w=480\"/></p>\n<p>It gives the best performance on both of them:</p>\n<p><img alt=\"\" src=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-table-2.jpeg?w=640\"/></p>\n<p>(<a href=\"https://adriancolyer.files.wordpress.com/2019/02/beyond-news-content-table-2.jpeg\" rel=\"noopener noreferrer\" target=\"_blank\">Enlarge</a>)</p>\n<p>\u00a0<br/>\n<a href=\"https://blog.acolyer.org/2019/02/13/beyond-news-contents-the-role-of-social-context-for-fake-news-detection/\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/10/guide-fake-news-detection-social-media.html\">A Quick Guide to Fake News Detection on Social Media</a>\n<li><a href=\"/2017/04/beware-two-data-obfuscation-tactics.html\">Beware of Two Data Obfuscation Tactics</a>\n<li><a href=\"/2017/03/getting-hot-here-data-science-vs-fake-news.html\">It\u2019s Getting Hot In Here: Data Science vs Fake News</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}