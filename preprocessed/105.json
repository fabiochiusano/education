{"content": "comments By Joyce Xu , Stanford . Over the past few years, much of the progress in deep learning for computer vision can be boiled down to just a handful of neural network architectures. Setting aside all the math, the code, and the implementation details, I wanted to explore one simple question: how and why do these models work? At the time of writing, Keras ships with six of these pre-trained models\u00a0 already built into the library : VGG16 VGG19 ResNet50 Inception v3 Xception MobileNet The VGG networks, along with the earlier AlexNet from 2012, follow the now archetypal layout of basic conv nets: a series of convolutional, max-pooling, and activation layers before some fully-connected classification layers at the end. MobileNet is essentially a streamlined version of the Xception architecture optimized for mobile applications. The remaining three, however, truly redefine the way we look at neural networks. This rest of this post will focus on the intuition behind the ResNet, Inception, and Xception architectures, and why they have become building blocks for so many subsequent works in computer vision. ResNet ResNet was born from a beautifully simple observation:\u00a0 why do very deep nets perform worse as you keep adding layers ? Intuitively, deeper nets should perform no worse than their shallower counterparts, at least at train time (when there is no risk of overfitting). As a thought experiment, let\u2019s say we\u2019ve built a net with\u00a0 n \u00a0layers that achieves a certain accuracy. At minimum, a net with\u00a0 n+1 \u00a0layers should be able to achieve the exact same accuracy, if only by copying over the same first\u00a0 n layers and performing an identity mapping for the last layer. Similarly, nets of\u00a0 n+2 ,\u00a0 n+3 , and\u00a0 n+4 \u00a0layers could all continue performing identity mappings and achieve the same accuracy. In practice, however, these deeper nets almost always degrade in performance. The authors of ResNet boiled these problems down to a single hypothesis:\u00a0 direct mappings are hard to learn . And they proposed a fix: instead of trying to learn an underlying mapping from x to , learn the\u00a0 difference \u00a0between the two, or the \u201cresidual.\u201d Then, to calculate , we can just add the residual to the input. Say the residual is =-x. Now, instead of trying to learn  directly, our nets are trying to learn +x. This gives rise to the famous ResNet (or \u201cresidual network\u201d) block you\u2019ve probably seen: Each \u201cblock\u201d in ResNet consists of a series of layers and a \u201cshortcut\u201d connection adding the input of the block to its output. The \u201cadd\u201d operation is performed element-wise, and if the input and output are of different sizes, zero-padding or projections (via 1\u00d71 convolutions) can be used to create matching dimensions. If we go back to our thought experiment, this simplifies our construction of identity layers greatly. Intuitively, it\u2019s much easier to learn to push  to 0 and leave the output as x than to learn an identity transformation from scratch. In general, ResNet gives layers a \u201creference\u201d point\u200a\u2014\u200ax\u200a\u2014\u200ato start learning from. This idea works astoundingly well in practice. Previously, deep neural nets often suffered from the problem of\u00a0 vanishing gradients , in which gradient signals from the error function decreased exponentially as they backpropogated to earlier layers. In essence, by the time the error signals traveled all the way back to the early layers, they were so small that the net couldn\u2019t learn. However, because the gradient signal in ResNets could travel back directly to early layers via shortcut connections, we could suddenly build 50-layer, 101-layer, 152-layer, and even (apparently) 1000+ layer nets that still performed well. At the time, this was a\u00a0 huge \u00a0leap forward from the previous state-of-the-art, which won the ILSVRC 2014 challenge with 22 layers. ResNet is one of my personal favorite developments in the neural network world. So many deep learning papers come out with minor improvements from hacking away at the math, the optimizations, and the training process without thought to the underlying task of the model. ResNet fundamentally changed the way we understand neural networks and how they learn. Fun facts: The 1000+ layer net is open-source! I would not\u00a0 really \u00a0recommend you try re-training it,\u00a0 but\u2026 If you\u2019re feeling functional and a little frisky, I recently ported ResNet50 to the open-source Clojure ML library\u00a0 Cortex . Try it out and see how it compares to Keras! Inception If ResNet was all about going deeper, the Inception Family\u2122 is all about going wider. In particular, the authors of Inception were interested in the computational efficiency of training larger nets. In other words:\u00a0 how can we scale up neural nets without increasing computational cost? The original paper focused on a new building block for deep nets, a block now known as the \u201cInception module.\u201d At its core, this module is the product of two key insights. The first insight relates to layer operations. In a traditional conv net, each layer extracts information from the previous layer in order to transform the input data into a more useful representation. However, each layer type extracts a different kind of information. The output of a 5\u00d75 convolutional kernel tells us something different from the output of a 3\u00d73 convolutional kernel, which tells us something different from the output of a max-pooling kernel, and so on and so on. At any given layer, how do we know what transformation provides the most \u201cuseful\u201d information? Insight #1: why not let the model choose? An Inception module computes\u00a0 multiple different transformations \u00a0over the same input map \u00a0 in parallel, concatenating their results into a single output. In other words, for each layer, Inception does a 5\u00d75 convolutional transformation,\u00a0 and \u00a0a 3\u00d73,\u00a0 and \u00a0a max-pool. And the next layer of the model gets to decide if (and how) to use each piece of information. The increased information density of this model architecture comes with one glaring problem: we\u2019ve drastically increased computational costs. Not only are large (e.g. 5\u00d75) convolutional filters inherently expensive to compute, stacking multiple different filters side by side greatly increases the number of feature maps per layer. And this increase becomes a deadly bottleneck in our model. Think about it this way. For each additional filter added, we have to convolve over\u00a0 all \u00a0the input maps to calculate a single output. See the image below: creating one output map from a single filter involves computing over\u00a0 every single map \u00a0from the previous layer.", "title_html": "<h1 id=\"title\">An Intuitive Guide to Deep Network Architectures</h1> ", "url": "https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html", "tfidf": {"tfidf": {"hand": 1.6152202665600002, "friski": 1443.27272727, "data": 3.37643555934, "signal": 15.37378954164, "kind": 2.5806241872599998, "addit": 1.24634950542, "achiev": 5.61650943396, "would": 1.0828729281799998, "number": 1.10142916609, "tradit": 1.60802187785, "conv": 2886.54545454, "decreas": 4.5230769230800005, "function": 4.99088337, "earlier": 3.73552941176, "progress": 2.44697903822, "ship": 3.14812611541, "thought": 5.95647823911, "resnet": 15875.99999997, "well": 2.1311497416, "product": 1.62264922322, "work": 3.34560269739, "author": 2.8459263242799997, "previous": 5.71387439264, "essenc": 14.659279778399998, "know": 2.59327017315, "their": 2.0309581681, "scale": 3.7469907953699995, "won": 2.31732593782, "stack": 19.6485148515, "particular": 1.3814827706200001, "instead": 3.18923262354, "creat": 2.4985835694, "multipl": 5.49627834516, "how": 9.61501968306, "stanford": 12.6, "numlay": 4329.81818181, "represent": 5.928304705, "increas": 6.60124740125, "end": 1.10680423871, "given": 1.35426085473, "word": 3.5930745728199995, "vnum": 29.291512915100004, "interest": 1.60331246213, "deep": 18.1398537477, "will": 1.22481098596, "asid": 6.69873417722, "write": 2.0575427682700003, "cortex": 81.83505154640001, "new": 1.0178880554, "below": 2.25607503197, "perform": 10.719783929750001, "along": 1.2973768080399999, "certain": 1.8077886586200003, "our": 9.43035343036, "classif": 8.067073170730001, "cost": 4.63871439006, "fix": 4.4346368715099995, "point": 1.25990000794, "applic": 3.42672134686, "port": 3.9443478260900005, "inher": 10.7706919946, "experi": 3.74125132556, "optim": 23.0755813954, "famous": 2.28201811125, "out": 2.12033388982, "model": 14.6341848828, "suffer": 2.16117615029, "alway": 2.06745670009, "family\u2122": 1443.27272727, "clojur": 1443.27272727, "much": 2.3884459154599997, "under": 2.1563327674, "huge": 4.38927287808, "risk": 4.095975232200001, "forward": 3.66566612792, "not": 3.04702194357, "archetyp": 35.837471783299996, "involv": 1.4498630137000001, "via": 4.595744680859999, "dead": 2.9608355091400003, "counterpart": 7.76332518337, "then": 1.08657860516, "they": 5.15086626435, "core": 4.623179965059999, "last": 1.2117234010100002, "choos": 4.17899447223, "world": 1.11340206186, "minimum": 6.02962400304, "degrad": 15.5190615836, "larger": 2.2407904022599996, "construct": 1.9320920043799998, "away": 1.85142857143, "glare": 92.8421052632, "featur": 1.52712581762, "wider": 6.710059171599999, "practic": 3.40869565218, "simpl": 6.7962328767199995, "that": 3.01195219125, "fun": 12.8863636364, "provid": 1.21552714187, "develop": 1.1955719557200002, "observ": 2.22446406053, "accuraci": 38.2861736334, "six": 1.5552507837, "streamlin": 34.4381778742, "network": 15.562163045279998, "math": 44.1613351878, "three": 1.06621893889, "some": 1.04036697248, "small": 1.3594793629, "should": 3.3286508019800003, "add": 9.22486926206, "result": 1.14611608432, "version": 2.0083491461099996, "filter": 67.5574468084, "set": 1.18707940781, "ani": 1.13383802314, "question": 2.20408163265, "nnum": 159.5577889448, "from": 14.00794100958, "detail": 2.26186066391, "num": 7.00220528007, "idea": 2.0930784443, "for": 7.00220528007, "num\u00d7num": 8659.63636362, "output": 69.09284332692, "match": 3.5676404494400002, "seen": 1.61079545455, "simplifi": 12.109839816900001, "with": 7.008387462929998, "alexnet": 1443.27272727, "are": 4.11962374312, "look": 1.9086318826599997, "subsequ": 1.7534791252500002, "veri": 1.25880114177, "extract": 15.406113537120001, "think": 2.90715986083, "net": 111.41052631584, "focus": 4.02025829324, "boil": 47.461883408, "compar": 1.8662278123900002, "map": 36.65572088247001, "and": 25.001574803249998, "drastic": 14.0620017715, "even": 1.16461267606, "convolv": 1443.27272727, "zeropad": 1443.27272727, "littl": 1.5499365420299998, "give": 2.7306501548, "retrain": 180.409090909, "side": 3.1979051264, "train": 5.8097096853, "great": 2.53185551392, "shallow": 16.0363636364, "scratch": 25.8146341463, "error": 12.08219178082, "continu": 1.13928955867, "type": 2.0281042411900003, "probabl": 2.64555907349, "just": 2.67160286074, "into": 3.04507384437, "paper": 5.325729620940001, "maxpool": 4329.81818181, "what": 1.25343439128, "tell": 6.72284564896, "exponenti": 39.2, "overfit": 1443.27272727, "larg": 1.18574949585, "propos": 1.9902218879299998, "doe": 1.70581282905, "least": 1.6165359943000002, "relat": 1.23750876919, "fact": 1.73375559681, "decid": 1.9257641921400002, "post": 2.23826307627, "shortcut": 254.016, "layer": 211.68000000004, "parallel": 4.57917507932, "about": 3.19458045477, "problem": 5.30024482527, "neural": 356.7640449438, "sudden": 5.78993435449, "joyc": 27.9507042254, "beauti": 4.79347826087, "mobil": 4.89697717458, "expens": 3.5453327378300004, "recommend": 3.9142011834300003, "rest": 1.9573418813999999, "let": 6.97233201582, "start": 1.26673581744, "intuit": 83.1204188481, "appar": 3.16696588869, "insight": 35.4111524163, "seri": 2.93023255814, "alreadi": 1.9551724137900002, "keep": 2.04245465071, "singl": 8.04744525545, "kernel": 211.68, "whi": 13.026461538480001, "abl": 1.8208510150200001, "mani": 2.08853515754, "over": 5.1262512108500005, "deeper": 45.2307692307, "build": 4.9025218734000005, "backpropog": 1443.27272727, "calcul": 12.25945945946, "mobilenet": 2886.54545454, "consist": 1.4901445466499998, "earli": 2.24936242562, "order": 1.24625166811, "couldn": 1443.27272727, "exact": 3.46864758575, "there": 1.04091266719, "connect": 3.7687833827800006, "inform": 7.876562810100001, "say": 3.5088960106, "origin": 1.13724928367, "but\u2026": 1443.27272727, "follow": 1.04640126549, "now": 3.4823426189999998, "tri": 9.272281275549998, "code": 3.8807137619199996, "hard": 2.73253012048, "per": 1.9597580545599997, "than": 2.0655737705, "basic": 2.7301805675, "realli": 4.7476076555, "xception": 4329.81818181, "feel": 3.1356903021900004, "incept": 134.8280254776, "person": 1.40520446097, "hypothesi": 13.580838323399998, "task": 3.88641370869, "minor": 2.23071518898, "the": 75.0, "becom": 2.24984057252, "past": 2.01702452039, "challeng": 2.55816951337, "concaten": 193.609756098, "want": 1.99698113208, "explor": 3.39593582888, "vanish": 18.6556991774, "behind": 2.0845588235299997, "howev": 4.378076525319999, "essenti": 2.9280708225700005, "piec": 3.24132298898, "easier": 7.84, "comment": 3.05954904606, "were": 2.04917715392, "which": 3.015575535, "bottleneck": 90.72, "activ": 1.46403541129, "ident": 11.23169437568, "fullyconnect": 1443.27272727, "other": 2.01984732824, "refer": 1.30024570025, "without": 2.59094247246, "one": 4.02509982888, "known": 1.0859097127200001, "dimens": 8.25585023401, "see": 2.54484251022, "becaus": 1.1495184997499999, "imag": 2.70137825421, "get": 1.78562591385, "still": 1.1866357724799999, "implement": 3.57648118946, "push": 3.75141776938, "opensourc": 2886.54545454, "process": 1.69524826482, "transform": 17.1003877639, "recent": 1.54405757635, "next": 1.4950560316400001, "born": 2.21762816036, "kera": 1671.1578947360001, "stateoftheart": 1443.27272727, "this": 10.037936267100001, "elementwis": 1443.27272727, "residu": 97.5483870968, "back": 3.7821011673299996, "chang": 1.1808985421, "similar": 1.37514075357, "project": 1.7534791252500002, "differ": 8.65581431575, "same": 4.47431832592, "most": 1.02096463023, "between": 1.03453668708, "hack": 43.3770491803, "copi": 3.8375634517800004, "vision": 9.76083615124, "all": 6.06880733946, "someth": 6.56304257958, "gradient": 125.66754617400001, "layout": 15.034090909100001, "almost": 1.53584212054, "use": 4.1185550295199995, "architectur": 20.51162790696, "built": 3.98894472362, "more": 1.0171706817, "improv": 2.04376930999, "leap": 19.6242274413, "travel": 3.9311625603600002, "these": 4.29661705008, "general": 1.1218202374200001, "could": 3.6131087846999996, "befor": 1.10036041031, "librari": 5.3653261237, "wors": 19.17391304348, "can": 4.70504556568, "comput": 31.422068283040005, "fundament": 5.32930513595, "way": 4.8762957844, "astound": 81.83505154640001, "onli": 2.0512953033200003, "each": 7.13848920864, "size": 2.49387370405, "few": 1.31729173581, "key": 2.28005170185, "resnetnum": 2886.54545454, "rise": 2.02940048575, "pretrain": 1443.27272727, "two": 2.0275862069, "remain": 1.16598119859, "block": 19.21646156952, "oper": 3.10958769954, "favorit": 8.116564417180001, "convolut": 606.726114648, "come": 2.65662650602, "time": 4.04509841392, "understand": 2.96858638743, "modul": 50.8303094985, "direct": 3.66679498038, "first": 2.01523229246, "everi": 1.47917637194, "leav": 1.6615384615399997, "input": 73.2175249806, "have": 2.0297896822799997, "year": 1.0485436893200002, "truli": 9.405213270139999, "often": 1.29452054795, "effici": 5.09335899904, "down": 2.71779508688, "learn": 27.873006583800002, "when": 1.02076769755, "densiti": 7.3465987968499995, "redefin": 34.4381778742}, "logtfidf": {"hand": 0.479471335336, "friski": 7.2746685411000005, "data": 1.2168205848, "signal": 4.902155378789999, "kind": 0.948031302717, "addit": 0.220218882972, "achiev": 1.881294255351, "would": 0.0796176279647, "number": 0.0966085784186, "tradit": 0.47500477629199994, "conv": 14.549337082200001, "decreas": 1.50919249744, "function": 1.828931483188, "earlier": 1.24948474285, "progress": 0.894854218108, "ship": 1.14680739183, "thought": 2.057601354849, "resnet": 80.0213539521, "well": 0.1270288766312, "product": 0.484060136536, "work": 0.327103701819, "author": 0.7054828626199999, "previous": 1.426411840252, "essenc": 2.6850735669, "know": 0.952919694398, "their": 0.030721010245400002, "scale": 1.32095306328, "won": 0.8404139079, "stack": 2.97800175538, "particular": 0.323157393804, "instead": 0.9332663008300001, "creat": 0.445153637028, "multipl": 2.02184803624, "how": 2.8294017415800004, "stanford": 2.53369681396, "numlay": 21.824005623300003, "represent": 1.7797382876499999, "increas": 1.389103594645, "end": 0.101476798618, "given": 0.303255810831, "word": 1.17172216477, "vnum": 3.3772978124599997, "interest": 0.47207177798199995, "deep": 6.443367349, "will": 0.202786534915, "asid": 1.90191857977, "write": 0.721512439877, "cortex": 4.40470565484, "new": 0.0177299468511, "below": 0.813626591936, "perform": 2.98326595406, "along": 0.260344385917, "certain": 0.592104362781, "our": 3.4305568567280003, "classif": 2.08779073629, "cost": 1.68258015236, "fix": 1.48944573451, "point": 0.23103235903299998, "applic": 1.23160392849, "port": 1.37228362405, "inher": 2.37682874115, "experi": 1.252545907866, "optim": 4.891255590819999, "famous": 0.825060187979, "out": 0.1168527818386, "model": 5.162150511777001, "suffer": 0.7706525875229999, "alway": 0.726319204572, "family\u2122": 7.2746685411000005, "clojur": 7.2746685411000005, "much": 0.35499145860200004, "under": 0.15052361076639997, "huge": 1.47916358195, "risk": 1.4100048408899999, "forward": 1.29901007269, "not": 0.0466572390225, "archetyp": 3.57899404386, "involv": 0.371469078658, "via": 1.663967250828, "dead": 1.0854714951100002, "counterpart": 2.04941074543, "then": 0.08303386523089999, "they": 0.148634973838, "core": 1.53108277245, "last": 0.19204364461100001, "choos": 1.43007066072, "world": 0.107420248621, "minimum": 1.79668465441, "degrad": 2.7420690479500003, "larger": 0.806828661778, "construct": 0.658603355972, "away": 0.615957541869, "glare": 4.5309002574, "featur": 0.423387418142, "wider": 1.90360776936, "practic": 1.066365061734, "simpl": 2.4464425787799997, "that": 0.01192844513892, "fun": 2.5561696698099996, "provid": 0.19517784432500002, "develop": 0.178624694913, "observ": 0.7995160149320001, "accuraci": 7.6394296218, "six": 0.441636808318, "streamlin": 3.5391657709099995, "network": 5.718498318311999, "math": 6.18940491236, "three": 0.06411868822490001, "some": 0.0395735090645, "small": 0.307101805059, "should": 1.018839753516, "add": 3.05751167426, "result": 0.136378908381, "version": 0.697313064259, "filter": 11.30673575456, "set": 0.171496011289, "ani": 0.125608358366, "question": 0.790310929014, "nnum": 14.744447234479999, "from": 0.007938758364123999, "detail": 0.816187777173, "num": 0.0022049327677790003, "idea": 0.73863592212, "for": 0.0022049327677790003, "num\u00d7num": 43.64801124660001, "output": 18.34403920443, "match": 1.27190443874, "seen": 0.47672812813, "simplifi": 2.4940183301400003, "with": 0.00838244199373, "alexnet": 7.2746685411000005, "are": 0.1178698943308, "look": 0.6463866936, "subsequ": 0.561601885907, "veri": 0.230159793238, "extract": 4.08323446602, "think": 1.06717661175, "net": 31.050129471199998, "focus": 1.3963979441119998, "boil": 6.33355950754, "compar": 0.6239191809269999, "map": 12.639104404560001, "and": 0.00157475355159, "drastic": 2.64347624975, "even": 0.152388564834, "convolv": 7.2746685411000005, "zeropad": 7.2746685411000005, "littl": 0.438213989466, "give": 0.622785104448, "retrain": 5.19522699942, "side": 0.9386975337379999, "train": 1.982754938517, "great": 0.471610516158, "shallow": 2.77485887077, "scratch": 3.2509415461, "error": 3.5971708686, "continu": 0.13040487398700001, "type": 0.707101485387, "probabl": 0.972882412913, "just": 0.579062868218, "into": 0.0447385896861, "paper": 1.95880507933, "maxpool": 21.824005623300003, "what": 0.225887296827, "tell": 2.42472868802, "exponenti": 3.6686767468, "overfit": 7.2746685411000005, "larg": 0.17037506060600002, "propos": 0.6882461339920001, "doe": 0.5340417297169999, "least": 0.480285584745, "relat": 0.21310030165399999, "fact": 0.5502899207949999, "decid": 0.655322871893, "post": 0.8057001527009999, "shortcut": 9.6885001532, "layer": 54.521458221100005, "parallel": 1.52151886822, "about": 0.18853043242380002, "problem": 1.707422172819, "neural": 24.511890933, "sudden": 1.75612095378, "joyc": 3.33044239518, "beauti": 1.5672562984, "mobil": 1.5886181116100002, "expens": 1.26563201674, "recommend": 1.36461126863, "rest": 0.671587369833, "let": 2.4976051345599997, "start": 0.236443369291, "intuit": 9.965034291570001, "appar": 1.15277399664, "insight": 7.40524356561, "seri": 0.7638692213959999, "alreadi": 0.670478380747, "keep": 0.7141523446729999, "singl": 2.379583845295, "kernel": 12.769390235100001, "whi": 4.72275372188, "abl": 0.599303982475, "mani": 0.0866315162442, "over": 0.1246836074785, "deeper": 8.13949590531, "build": 1.4734123562730002, "backpropog": 7.2746685411000005, "calcul": 3.6263013184199995, "mobilenet": 14.549337082200001, "consist": 0.398873126426, "earli": 0.234999258216, "order": 0.22014038079300002, "couldn": 7.2746685411000005, "exact": 1.2437647732500001, "there": 0.0400978929255, "connect": 1.267210117364, "inform": 2.27226852331, "say": 1.124308561104, "origin": 0.128612437587, "but\u2026": 7.2746685411000005, "follow": 0.045356911094199995, "now": 0.44727883506300004, "tri": 3.0879576458000004, "code": 1.35601909597, "hard": 1.00522796406, "per": 0.672821024072, "than": 0.0645217244364, "basic": 1.00436774895, "realli": 1.5576408397, "xception": 21.824005623300003, "feel": 1.1428493419299999, "incept": 22.59646831464, "person": 0.34018281601800004, "hypothesi": 2.60865985243, "task": 1.35748680661, "minor": 0.802322246604, "the": 0.0, "becom": 0.23542435297800002, "past": 0.7016234157610001, "challeng": 0.9392919688950001, "concaten": 5.26584456664, "want": 0.6916366062549999, "explor": 1.22257937218, "vanish": 2.92615168533, "behind": 0.7345572374320001, "howev": 0.36126046939, "essenti": 1.07434378384, "piec": 1.17598157639, "easier": 2.05923883436, "comment": 1.11826753454, "were": 0.048582287362199994, "which": 0.01553524153629, "bottleneck": 4.50777783998, "activ": 0.381196603284, "ident": 4.1297811026, "fullyconnect": 7.2746685411000005, "other": 0.01974949583952, "refer": 0.262553246798, "without": 0.517749035882, "one": 0.025021406582, "known": 0.0824180805992, "dimens": 2.11092206831, "see": 0.481843170984, "becaus": 0.139343158825, "imag": 0.99376210729, "get": 0.579769005782, "still": 0.17112222142900002, "implement": 1.27437940907, "push": 1.32213384036, "opensourc": 14.549337082200001, "process": 0.527829199025, "transform": 6.148316135350001, "recent": 0.434413741288, "next": 0.402163685499, "born": 0.7964382285070001, "kera": 13.45624966948, "stateoftheart": 7.2746685411000005, "this": 0.037864490525, "elementwis": 7.2746685411000005, "residu": 12.776216686760002, "back": 0.695002292691, "chang": 0.166275625058, "similar": 0.318556092114, "project": 0.561601885907, "differ": 1.486247849184, "same": 0.448238598416, "most": 0.020747896295599998, "between": 0.033953681165299995, "hack": 3.7699304805000002, "copi": 1.34483764744, "vision": 3.17046177486, "all": 0.06841579258679999, "someth": 2.37661424546, "gradient": 11.20508282646, "layout": 2.71032034964, "almost": 0.42907884333400004, "use": 0.1168320789264, "architectur": 6.53879031676, "built": 1.38075907013, "more": 0.017024931599999998, "improv": 0.7147958039319999, "leap": 2.9767648968400002, "travel": 1.351576036922, "these": 0.2861344776032, "general": 0.114952578063, "could": 0.5578688168700001, "befor": 0.0956377718795, "librari": 1.973619961886, "wors": 4.52080695792, "can": 0.649364385576, "comput": 10.94455132752, "fundament": 1.67322086119, "way": 0.7923660397400001, "astound": 4.40470565484, "onli": 0.050648536658199995, "each": 1.042450135824, "size": 0.9138372060609999, "few": 0.275577913653, "key": 0.82419811896, "resnetnum": 14.549337082200001, "rise": 0.707740422218, "pretrain": 7.2746685411000005, "two": 0.0273976887164, "remain": 0.15356296309, "block": 6.9840468952800006, "oper": 0.882685928694, "favorit": 2.09390696331, "convolut": 27.697908051300004, "come": 0.5678198130600001, "time": 0.0448460754504, "understand": 1.0880858756799998, "modul": 8.48964159498, "direct": 0.6021170684880001, "first": 0.015174579624319999, "everi": 0.391485427421, "leav": 0.507743957229, "input": 15.01005201234, "have": 0.0295700046824, "year": 0.047402238894600005, "truli": 2.24126413875, "often": 0.258140393351, "effici": 1.62793753414, "down": 0.613347482372, "learn": 10.11302477694, "when": 0.0205549888584, "densiti": 1.9942374574000001, "redefin": 3.5391657709099995}, "logidf": {"hand": 0.479471335336, "friski": 7.2746685411000005, "data": 1.2168205848, "signal": 1.6340517929299998, "kind": 0.948031302717, "addit": 0.220218882972, "achiev": 0.6270980851169999, "would": 0.0796176279647, "number": 0.0966085784186, "tradit": 0.47500477629199994, "conv": 7.2746685411000005, "decreas": 1.50919249744, "function": 0.914465741594, "earlier": 0.624742371425, "progress": 0.894854218108, "ship": 1.14680739183, "thought": 0.685867118283, "resnet": 7.2746685411000005, "well": 0.0635144383156, "product": 0.484060136536, "work": 0.109034567273, "author": 0.35274143130999996, "previous": 0.356602960063, "essenc": 2.6850735669, "know": 0.952919694398, "their": 0.015360505122700001, "scale": 1.32095306328, "won": 0.8404139079, "stack": 2.97800175538, "particular": 0.323157393804, "instead": 0.46663315041500003, "creat": 0.222576818514, "multipl": 1.01092401812, "how": 0.47156695693000006, "stanford": 2.53369681396, "numlay": 7.2746685411000005, "represent": 1.7797382876499999, "increas": 0.277820718929, "end": 0.101476798618, "given": 0.303255810831, "word": 0.585861082385, "vnum": 3.3772978124599997, "interest": 0.47207177798199995, "deep": 1.2886734698, "will": 0.202786534915, "asid": 1.90191857977, "write": 0.721512439877, "cortex": 4.40470565484, "new": 0.0177299468511, "below": 0.813626591936, "perform": 0.42618085058, "along": 0.260344385917, "certain": 0.592104362781, "our": 0.8576392141820001, "classif": 2.08779073629, "cost": 0.84129007618, "fix": 1.48944573451, "point": 0.23103235903299998, "applic": 1.23160392849, "port": 1.37228362405, "inher": 2.37682874115, "experi": 0.626272953933, "optim": 2.4456277954099996, "famous": 0.825060187979, "out": 0.0584263909193, "model": 0.7374500731110001, "suffer": 0.7706525875229999, "alway": 0.726319204572, "family\u2122": 7.2746685411000005, "clojur": 7.2746685411000005, "much": 0.17749572930100002, "under": 0.07526180538319999, "huge": 1.47916358195, "risk": 1.4100048408899999, "forward": 1.29901007269, "not": 0.0155524130075, "archetyp": 3.57899404386, "involv": 0.371469078658, "via": 0.831983625414, "dead": 1.0854714951100002, "counterpart": 2.04941074543, "then": 0.08303386523089999, "they": 0.0297269947676, "core": 1.53108277245, "last": 0.19204364461100001, "choos": 1.43007066072, "world": 0.107420248621, "minimum": 1.79668465441, "degrad": 2.7420690479500003, "larger": 0.806828661778, "construct": 0.658603355972, "away": 0.615957541869, "glare": 4.5309002574, "featur": 0.423387418142, "wider": 1.90360776936, "practic": 0.533182530867, "simpl": 1.2232212893899999, "that": 0.00397614837964, "fun": 2.5561696698099996, "provid": 0.19517784432500002, "develop": 0.178624694913, "observ": 0.7995160149320001, "accuraci": 2.5464765406, "six": 0.441636808318, "streamlin": 3.5391657709099995, "network": 0.9530830530519999, "math": 3.09470245618, "three": 0.06411868822490001, "some": 0.0395735090645, "small": 0.307101805059, "should": 0.509419876758, "add": 1.52875583713, "result": 0.136378908381, "version": 0.697313064259, "filter": 2.82668393864, "set": 0.171496011289, "ani": 0.125608358366, "question": 0.790310929014, "nnum": 3.6861118086199998, "from": 0.000567054168866, "detail": 0.816187777173, "num": 0.00031499039539700004, "idea": 0.73863592212, "for": 0.00031499039539700004, "num\u00d7num": 7.2746685411000005, "output": 2.03822657827, "match": 1.27190443874, "seen": 0.47672812813, "simplifi": 2.4940183301400003, "with": 0.00119749171339, "alexnet": 7.2746685411000005, "are": 0.0294674735827, "look": 0.6463866936, "subsequ": 0.561601885907, "veri": 0.230159793238, "extract": 2.04161723301, "think": 1.06717661175, "net": 1.9406330919499999, "focus": 0.6981989720559999, "boil": 3.16677975377, "compar": 0.6239191809269999, "map": 1.40434493384, "and": 6.29901420636e-05, "drastic": 2.64347624975, "even": 0.152388564834, "convolv": 7.2746685411000005, "zeropad": 7.2746685411000005, "littl": 0.438213989466, "give": 0.311392552224, "retrain": 5.19522699942, "side": 0.46934876686899996, "train": 0.660918312839, "great": 0.235805258079, "shallow": 2.77485887077, "scratch": 3.2509415461, "error": 1.7985854343, "continu": 0.13040487398700001, "type": 0.707101485387, "probabl": 0.972882412913, "just": 0.289531434109, "into": 0.0149128632287, "paper": 0.979402539665, "maxpool": 7.2746685411000005, "what": 0.225887296827, "tell": 1.21236434401, "exponenti": 3.6686767468, "overfit": 7.2746685411000005, "larg": 0.17037506060600002, "propos": 0.6882461339920001, "doe": 0.5340417297169999, "least": 0.480285584745, "relat": 0.21310030165399999, "fact": 0.5502899207949999, "decid": 0.655322871893, "post": 0.8057001527009999, "shortcut": 4.8442500766, "layer": 2.0969791623500003, "parallel": 1.52151886822, "about": 0.0628434774746, "problem": 0.569140724273, "neural": 4.0853151555, "sudden": 1.75612095378, "joyc": 3.33044239518, "beauti": 1.5672562984, "mobil": 1.5886181116100002, "expens": 1.26563201674, "recommend": 1.36461126863, "rest": 0.671587369833, "let": 1.2488025672799998, "start": 0.236443369291, "intuit": 3.3216780971900004, "appar": 1.15277399664, "insight": 2.46841452187, "seri": 0.38193461069799994, "alreadi": 0.670478380747, "keep": 0.7141523446729999, "singl": 0.475916769059, "kernel": 4.2564634117, "whi": 1.18068843047, "abl": 0.599303982475, "mani": 0.0433157581221, "over": 0.0249367214957, "deeper": 2.7131653017699997, "build": 0.491137452091, "backpropog": 7.2746685411000005, "calcul": 1.8131506592099997, "mobilenet": 7.2746685411000005, "consist": 0.398873126426, "earli": 0.117499629108, "order": 0.22014038079300002, "couldn": 7.2746685411000005, "exact": 1.2437647732500001, "there": 0.0400978929255, "connect": 0.633605058682, "inform": 0.454453704662, "say": 0.562154280552, "origin": 0.128612437587, "but\u2026": 7.2746685411000005, "follow": 0.045356911094199995, "now": 0.149092945021, "tri": 0.61759152916, "code": 1.35601909597, "hard": 1.00522796406, "per": 0.672821024072, "than": 0.0322608622182, "basic": 1.00436774895, "realli": 1.5576408397, "xception": 7.2746685411000005, "feel": 1.1428493419299999, "incept": 2.82455853933, "person": 0.34018281601800004, "hypothesi": 2.60865985243, "task": 1.35748680661, "minor": 0.802322246604, "the": 0.0, "becom": 0.11771217648900001, "past": 0.7016234157610001, "challeng": 0.9392919688950001, "concaten": 5.26584456664, "want": 0.6916366062549999, "explor": 1.22257937218, "vanish": 2.92615168533, "behind": 0.7345572374320001, "howev": 0.0903151173475, "essenti": 1.07434378384, "piec": 1.17598157639, "easier": 2.05923883436, "comment": 1.11826753454, "were": 0.024291143681099997, "which": 0.00517841384543, "bottleneck": 4.50777783998, "activ": 0.381196603284, "ident": 1.03244527565, "fullyconnect": 7.2746685411000005, "other": 0.00987474791976, "refer": 0.262553246798, "without": 0.258874517941, "one": 0.0062553516455, "known": 0.0824180805992, "dimens": 2.11092206831, "see": 0.240921585492, "becaus": 0.139343158825, "imag": 0.99376210729, "get": 0.579769005782, "still": 0.17112222142900002, "implement": 1.27437940907, "push": 1.32213384036, "opensourc": 7.2746685411000005, "process": 0.527829199025, "transform": 1.22966322707, "recent": 0.434413741288, "next": 0.402163685499, "born": 0.7964382285070001, "kera": 6.72812483474, "stateoftheart": 7.2746685411000005, "this": 0.0037864490525, "elementwis": 7.2746685411000005, "residu": 3.1940541716900004, "back": 0.23166743089699998, "chang": 0.166275625058, "similar": 0.318556092114, "project": 0.561601885907, "differ": 0.212321121312, "same": 0.112059649604, "most": 0.020747896295599998, "between": 0.033953681165299995, "hack": 3.7699304805000002, "copi": 1.34483764744, "vision": 1.58523088743, "all": 0.011402632097799998, "someth": 1.18830712273, "gradient": 3.73502760882, "layout": 2.71032034964, "almost": 0.42907884333400004, "use": 0.0292080197316, "architectur": 1.63469757919, "built": 0.690379535065, "more": 0.017024931599999998, "improv": 0.7147958039319999, "leap": 2.9767648968400002, "travel": 0.675788018461, "these": 0.0715336194008, "general": 0.114952578063, "could": 0.18595627229000003, "befor": 0.0956377718795, "librari": 0.986809980943, "wors": 2.26040347896, "can": 0.162341096394, "comput": 1.36806891594, "fundament": 1.67322086119, "way": 0.19809150993500002, "astound": 4.40470565484, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "few": 0.275577913653, "key": 0.82419811896, "resnetnum": 7.2746685411000005, "rise": 0.707740422218, "pretrain": 7.2746685411000005, "two": 0.0136988443582, "remain": 0.15356296309, "block": 1.16400781588, "oper": 0.441342964347, "favorit": 2.09390696331, "convolut": 4.61631800855, "come": 0.28390990653000003, "time": 0.0112115188626, "understand": 1.0880858756799998, "modul": 2.82988053166, "direct": 0.200705689496, "first": 0.0075872898121599995, "everi": 0.391485427421, "leav": 0.507743957229, "input": 2.50167533539, "have": 0.0147850023412, "year": 0.047402238894600005, "truli": 2.24126413875, "often": 0.258140393351, "effici": 1.62793753414, "down": 0.306673741186, "learn": 0.842752064745, "when": 0.0205549888584, "densiti": 1.9942374574000001, "redefin": 3.5391657709099995}, "freq": {"hand": 1, "friski": 1, "data": 1, "signal": 3, "kind": 1, "addit": 1, "achiev": 3, "would": 1, "number": 1, "tradit": 1, "conv": 2, "decreas": 1, "function": 2, "earlier": 2, "progress": 1, "ship": 1, "thought": 3, "resnet": 11, "well": 2, "product": 1, "work": 3, "author": 2, "previous": 4, "essenc": 1, "know": 1, "their": 2, "scale": 1, "won": 1, "stack": 1, "particular": 1, "instead": 2, "creat": 2, "multipl": 2, "how": 6, "stanford": 1, "numlay": 3, "represent": 1, "increas": 5, "end": 1, "given": 1, "word": 2, "vnum": 1, "interest": 1, "deep": 5, "will": 1, "asid": 1, "write": 1, "cortex": 1, "new": 1, "below": 1, "perform": 7, "along": 1, "certain": 1, "our": 4, "classif": 1, "cost": 2, "fix": 1, "point": 1, "applic": 1, "port": 1, "inher": 1, "experi": 2, "optim": 2, "famous": 1, "out": 2, "model": 7, "suffer": 1, "alway": 1, "family\u2122": 1, "clojur": 1, "much": 2, "under": 2, "huge": 1, "risk": 1, "forward": 1, "not": 3, "archetyp": 1, "involv": 1, "via": 2, "dead": 1, "counterpart": 1, "then": 1, "they": 5, "core": 1, "last": 1, "choos": 1, "world": 1, "minimum": 1, "degrad": 1, "larger": 1, "construct": 1, "away": 1, "glare": 1, "featur": 1, "wider": 1, "practic": 2, "simpl": 2, "that": 3, "fun": 1, "provid": 1, "develop": 1, "observ": 1, "accuraci": 3, "six": 1, "streamlin": 1, "network": 6, "math": 2, "three": 1, "some": 1, "small": 1, "should": 2, "add": 2, "result": 1, "version": 1, "filter": 4, "set": 1, "ani": 1, "question": 1, "nnum": 4, "from": 14, "detail": 1, "num": 7, "idea": 1, "for": 7, "num\u00d7num": 6, "output": 9, "match": 1, "seen": 1, "simplifi": 1, "with": 7, "alexnet": 1, "are": 4, "look": 1, "subsequ": 1, "veri": 1, "extract": 2, "think": 1, "net": 16, "focus": 2, "boil": 2, "compar": 1, "map": 9, "and": 25, "drastic": 1, "even": 1, "convolv": 1, "zeropad": 1, "littl": 1, "give": 2, "retrain": 1, "side": 2, "train": 3, "great": 2, "shallow": 1, "scratch": 1, "error": 2, "continu": 1, "type": 1, "probabl": 1, "just": 2, "into": 3, "paper": 2, "maxpool": 3, "what": 1, "tell": 2, "exponenti": 1, "overfit": 1, "larg": 1, "propos": 1, "doe": 1, "least": 1, "relat": 1, "fact": 1, "decid": 1, "post": 1, "shortcut": 2, "layer": 26, "parallel": 1, "about": 3, "problem": 3, "neural": 6, "sudden": 1, "joyc": 1, "beauti": 1, "mobil": 1, "expens": 1, "recommend": 1, "rest": 1, "let": 2, "start": 1, "intuit": 3, "appar": 1, "insight": 3, "seri": 2, "alreadi": 1, "keep": 1, "singl": 5, "kernel": 3, "whi": 4, "abl": 1, "mani": 2, "over": 5, "deeper": 3, "build": 3, "backpropog": 1, "calcul": 2, "mobilenet": 2, "consist": 1, "earli": 2, "order": 1, "couldn": 1, "exact": 1, "there": 1, "connect": 2, "inform": 5, "say": 2, "origin": 1, "but\u2026": 1, "follow": 1, "now": 3, "tri": 5, "code": 1, "hard": 1, "per": 1, "than": 2, "basic": 1, "realli": 1, "xception": 3, "feel": 1, "incept": 8, "person": 1, "hypothesi": 1, "task": 1, "minor": 1, "the": 75, "becom": 2, "past": 1, "challeng": 1, "concaten": 1, "want": 1, "explor": 1, "vanish": 1, "behind": 1, "howev": 4, "essenti": 1, "piec": 1, "easier": 1, "comment": 1, "were": 2, "which": 3, "bottleneck": 1, "activ": 1, "ident": 4, "fullyconnect": 1, "other": 2, "refer": 1, "without": 2, "one": 4, "known": 1, "dimens": 1, "see": 2, "becaus": 1, "imag": 1, "get": 1, "still": 1, "implement": 1, "push": 1, "opensourc": 2, "process": 1, "transform": 5, "recent": 1, "next": 1, "born": 1, "kera": 2, "stateoftheart": 1, "this": 10, "elementwis": 1, "residu": 4, "back": 3, "chang": 1, "similar": 1, "project": 1, "differ": 7, "same": 4, "most": 1, "between": 1, "hack": 1, "copi": 1, "vision": 2, "all": 6, "someth": 2, "gradient": 3, "layout": 1, "almost": 1, "use": 4, "architectur": 4, "built": 2, "more": 1, "improv": 1, "leap": 1, "travel": 2, "these": 4, "general": 1, "could": 3, "befor": 1, "librari": 2, "wors": 2, "can": 4, "comput": 8, "fundament": 1, "way": 4, "astound": 1, "onli": 2, "each": 6, "size": 1, "few": 1, "key": 1, "resnetnum": 2, "rise": 1, "pretrain": 1, "two": 2, "remain": 1, "block": 6, "oper": 2, "favorit": 1, "convolut": 6, "come": 2, "time": 4, "understand": 1, "modul": 3, "direct": 3, "first": 2, "everi": 1, "leav": 1, "input": 6, "have": 2, "year": 1, "truli": 1, "often": 1, "effici": 1, "down": 2, "learn": 12, "when": 1, "densiti": 1, "redefin": 1}, "idf": {"hand": 1.6152202665600002, "friski": 1443.27272727, "data": 3.37643555934, "signal": 5.12459651388, "kind": 2.5806241872599998, "addit": 1.24634950542, "achiev": 1.87216981132, "would": 1.0828729281799998, "number": 1.10142916609, "tradit": 1.60802187785, "conv": 1443.27272727, "decreas": 4.5230769230800005, "function": 2.495441685, "earlier": 1.86776470588, "progress": 2.44697903822, "ship": 3.14812611541, "thought": 1.9854927463699998, "resnet": 1443.27272727, "well": 1.0655748708, "product": 1.62264922322, "work": 1.11520089913, "author": 1.4229631621399998, "previous": 1.42846859816, "essenc": 14.659279778399998, "know": 2.59327017315, "their": 1.01547908405, "scale": 3.7469907953699995, "won": 2.31732593782, "stack": 19.6485148515, "particular": 1.3814827706200001, "instead": 1.59461631177, "creat": 1.2492917847, "multipl": 2.74813917258, "how": 1.60250328051, "stanford": 12.6, "numlay": 1443.27272727, "represent": 5.928304705, "increas": 1.32024948025, "end": 1.10680423871, "given": 1.35426085473, "word": 1.7965372864099998, "vnum": 29.291512915100004, "interest": 1.60331246213, "deep": 3.6279707495399998, "will": 1.22481098596, "asid": 6.69873417722, "write": 2.0575427682700003, "cortex": 81.83505154640001, "new": 1.0178880554, "below": 2.25607503197, "perform": 1.5313977042500002, "along": 1.2973768080399999, "certain": 1.8077886586200003, "our": 2.35758835759, "classif": 8.067073170730001, "cost": 2.31935719503, "fix": 4.4346368715099995, "point": 1.25990000794, "applic": 3.42672134686, "port": 3.9443478260900005, "inher": 10.7706919946, "experi": 1.87062566278, "optim": 11.5377906977, "famous": 2.28201811125, "out": 1.06016694491, "model": 2.0905978404, "suffer": 2.16117615029, "alway": 2.06745670009, "family\u2122": 1443.27272727, "clojur": 1443.27272727, "much": 1.1942229577299999, "under": 1.0781663837, "huge": 4.38927287808, "risk": 4.095975232200001, "forward": 3.66566612792, "not": 1.01567398119, "archetyp": 35.837471783299996, "involv": 1.4498630137000001, "via": 2.2978723404299997, "dead": 2.9608355091400003, "counterpart": 7.76332518337, "then": 1.08657860516, "they": 1.03017325287, "core": 4.623179965059999, "last": 1.2117234010100002, "choos": 4.17899447223, "world": 1.11340206186, "minimum": 6.02962400304, "degrad": 15.5190615836, "larger": 2.2407904022599996, "construct": 1.9320920043799998, "away": 1.85142857143, "glare": 92.8421052632, "featur": 1.52712581762, "wider": 6.710059171599999, "practic": 1.70434782609, "simpl": 3.3981164383599998, "that": 1.00398406375, "fun": 12.8863636364, "provid": 1.21552714187, "develop": 1.1955719557200002, "observ": 2.22446406053, "accuraci": 12.7620578778, "six": 1.5552507837, "streamlin": 34.4381778742, "network": 2.59369384088, "math": 22.0806675939, "three": 1.06621893889, "some": 1.04036697248, "small": 1.3594793629, "should": 1.6643254009900001, "add": 4.61243463103, "result": 1.14611608432, "version": 2.0083491461099996, "filter": 16.8893617021, "set": 1.18707940781, "ani": 1.13383802314, "question": 2.20408163265, "nnum": 39.8894472362, "from": 1.00056721497, "detail": 2.26186066391, "num": 1.00031504001, "idea": 2.0930784443, "for": 1.00031504001, "num\u00d7num": 1443.27272727, "output": 7.676982591880001, "match": 3.5676404494400002, "seen": 1.61079545455, "simplifi": 12.109839816900001, "with": 1.0011982089899998, "alexnet": 1443.27272727, "are": 1.02990593578, "look": 1.9086318826599997, "subsequ": 1.7534791252500002, "veri": 1.25880114177, "extract": 7.703056768560001, "think": 2.90715986083, "net": 6.96315789474, "focus": 2.01012914662, "boil": 23.730941704, "compar": 1.8662278123900002, "map": 4.0728578758300005, "and": 1.00006299213, "drastic": 14.0620017715, "even": 1.16461267606, "convolv": 1443.27272727, "zeropad": 1443.27272727, "littl": 1.5499365420299998, "give": 1.3653250774, "retrain": 180.409090909, "side": 1.5989525632, "train": 1.9365698950999999, "great": 1.26592775696, "shallow": 16.0363636364, "scratch": 25.8146341463, "error": 6.04109589041, "continu": 1.13928955867, "type": 2.0281042411900003, "probabl": 2.64555907349, "just": 1.33580143037, "into": 1.01502461479, "paper": 2.6628648104700003, "maxpool": 1443.27272727, "what": 1.25343439128, "tell": 3.36142282448, "exponenti": 39.2, "overfit": 1443.27272727, "larg": 1.18574949585, "propos": 1.9902218879299998, "doe": 1.70581282905, "least": 1.6165359943000002, "relat": 1.23750876919, "fact": 1.73375559681, "decid": 1.9257641921400002, "post": 2.23826307627, "shortcut": 127.008, "layer": 8.14153846154, "parallel": 4.57917507932, "about": 1.06486015159, "problem": 1.76674827509, "neural": 59.4606741573, "sudden": 5.78993435449, "joyc": 27.9507042254, "beauti": 4.79347826087, "mobil": 4.89697717458, "expens": 3.5453327378300004, "recommend": 3.9142011834300003, "rest": 1.9573418813999999, "let": 3.48616600791, "start": 1.26673581744, "intuit": 27.7068062827, "appar": 3.16696588869, "insight": 11.8037174721, "seri": 1.46511627907, "alreadi": 1.9551724137900002, "keep": 2.04245465071, "singl": 1.60948905109, "kernel": 70.56, "whi": 3.2566153846200003, "abl": 1.8208510150200001, "mani": 1.04426757877, "over": 1.02525024217, "deeper": 15.0769230769, "build": 1.6341739578, "backpropog": 1443.27272727, "calcul": 6.12972972973, "mobilenet": 1443.27272727, "consist": 1.4901445466499998, "earli": 1.12468121281, "order": 1.24625166811, "couldn": 1443.27272727, "exact": 3.46864758575, "there": 1.04091266719, "connect": 1.8843916913900003, "inform": 1.5753125620200001, "say": 1.7544480053, "origin": 1.13724928367, "but\u2026": 1443.27272727, "follow": 1.04640126549, "now": 1.160780873, "tri": 1.8544562551099997, "code": 3.8807137619199996, "hard": 2.73253012048, "per": 1.9597580545599997, "than": 1.03278688525, "basic": 2.7301805675, "realli": 4.7476076555, "xception": 1443.27272727, "feel": 3.1356903021900004, "incept": 16.8535031847, "person": 1.40520446097, "hypothesi": 13.580838323399998, "task": 3.88641370869, "minor": 2.23071518898, "the": 1.0, "becom": 1.12492028626, "past": 2.01702452039, "challeng": 2.55816951337, "concaten": 193.609756098, "want": 1.99698113208, "explor": 3.39593582888, "vanish": 18.6556991774, "behind": 2.0845588235299997, "howev": 1.0945191313299998, "essenti": 2.9280708225700005, "piec": 3.24132298898, "easier": 7.84, "comment": 3.05954904606, "were": 1.02458857696, "which": 1.005191845, "bottleneck": 90.72, "activ": 1.46403541129, "ident": 2.80792359392, "fullyconnect": 1443.27272727, "other": 1.00992366412, "refer": 1.30024570025, "without": 1.29547123623, "one": 1.00627495722, "known": 1.0859097127200001, "dimens": 8.25585023401, "see": 1.27242125511, "becaus": 1.1495184997499999, "imag": 2.70137825421, "get": 1.78562591385, "still": 1.1866357724799999, "implement": 3.57648118946, "push": 3.75141776938, "opensourc": 1443.27272727, "process": 1.69524826482, "transform": 3.42007755278, "recent": 1.54405757635, "next": 1.4950560316400001, "born": 2.21762816036, "kera": 835.5789473680001, "stateoftheart": 1443.27272727, "this": 1.00379362671, "elementwis": 1443.27272727, "residu": 24.3870967742, "back": 1.26070038911, "chang": 1.1808985421, "similar": 1.37514075357, "project": 1.7534791252500002, "differ": 1.23654490225, "same": 1.11857958148, "most": 1.02096463023, "between": 1.03453668708, "hack": 43.3770491803, "copi": 3.8375634517800004, "vision": 4.88041807562, "all": 1.01146788991, "someth": 3.28152128979, "gradient": 41.889182058, "layout": 15.034090909100001, "almost": 1.53584212054, "use": 1.0296387573799999, "architectur": 5.12790697674, "built": 1.99447236181, "more": 1.0171706817, "improv": 2.04376930999, "leap": 19.6242274413, "travel": 1.9655812801800001, "these": 1.07415426252, "general": 1.1218202374200001, "could": 1.2043695949, "befor": 1.10036041031, "librari": 2.68266306185, "wors": 9.58695652174, "can": 1.17626139142, "comput": 3.9277585353800006, "fundament": 5.32930513595, "way": 1.2190739461, "astound": 81.83505154640001, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "few": 1.31729173581, "key": 2.28005170185, "resnetnum": 1443.27272727, "rise": 2.02940048575, "pretrain": 1443.27272727, "two": 1.01379310345, "remain": 1.16598119859, "block": 3.20274359492, "oper": 1.55479384977, "favorit": 8.116564417180001, "convolut": 101.121019108, "come": 1.32831325301, "time": 1.01127460348, "understand": 2.96858638743, "modul": 16.9434364995, "direct": 1.22226499346, "first": 1.00761614623, "everi": 1.47917637194, "leav": 1.6615384615399997, "input": 12.2029208301, "have": 1.0148948411399998, "year": 1.0485436893200002, "truli": 9.405213270139999, "often": 1.29452054795, "effici": 5.09335899904, "down": 1.35889754344, "learn": 2.32275054865, "when": 1.02076769755, "densiti": 7.3465987968499995, "redefin": 34.4381778742}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  An Intuitive Guide to Deep Network Architectures</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb An Intuitive Guide to Deep Network Architectures Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/top-news-week-0821-0827.html\" rel=\"prev\" title=\"Top Stories, Aug 21-27: 42 Steps to Mastering Data Science; Deep Learning is not the AI future\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/python-overtakes-r-leader-analytics-data-science.html\" rel=\"next\" title=\"Python overtakes R, becomes the leader in Data Science, Machine Learning platforms\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=70654\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-70654 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 28-Aug, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/index.html\">Aug</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/opinions-interviews.html\">Opinions, Interviews</a> \u00bb An Intuitive Guide to Deep Network Architectures (\u00a0<a href=\"/2017/n33.html\">17:n33</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">An Intuitive Guide to Deep Network Architectures</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/08/top-news-week-0821-0827.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/08/python-overtakes-r-leader-analytics-data-science.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 233</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/keras\" rel=\"tag\">Keras</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a></div>\n<br/>\n<p class=\"excerpt\">\n     How and why do different Deep Learning models work?  We provide an intuitive explanation for 3 very popular DL models: Resnet, Inception, and Xception. \n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"/2017/08/intuitive-guide-deep-network-architectures.html/2#comments\">comments</a></div>\n<p><b>By <a href=\"https://medium.com/@joycex99\">Joyce Xu</a>, Stanford</b>.</p>\n<p><img class=\"size-full\" src=\"https://cdn-images-1.medium.com/max/2000/1*_rCyzi7fQzc_Q1gCqSLM1g.png\" width=\"95%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"504e\">Over the past few years, much of the progress in deep learning for computer vision can be boiled down to just a handful of neural network architectures. Setting aside all the math, the code, and the implementation details, I wanted to explore one simple question: how and why do these models work?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"bb1c\">At the time of writing, Keras ships with six of these pre-trained models\u00a0<a class=\"markup--anchor markup--p-anchor\" data-href=\"https://keras.io/applications/\" href=\"https://keras.io/applications/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">already built into the library</a>:</p>\n<ul class=\"postList\">\n<li class=\"graf graf--li graf-after--p\" id=\"f8ec\">VGG16</li>\n<li class=\"graf graf--li graf-after--li\" id=\"8ce4\">VGG19</li>\n<li class=\"graf graf--li graf-after--li\" id=\"6968\">ResNet50</li>\n<li class=\"graf graf--li graf-after--li\" id=\"0c7a\">Inception v3</li>\n<li class=\"graf graf--li graf-after--li\" id=\"da74\">Xception</li>\n<li class=\"graf graf--li graf-after--li\" id=\"c7e1\">MobileNet</li>\n</ul>\n<p class=\"graf graf--p graf-after--li\" id=\"9688\">The VGG networks, along with the earlier AlexNet from 2012, follow the now archetypal layout of basic conv nets: a series of convolutional, max-pooling, and activation layers before some fully-connected classification layers at the end. MobileNet is essentially a streamlined version of the Xception architecture optimized for mobile applications. The remaining three, however, truly redefine the way we look at neural networks.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"4d1c\">This rest of this post will focus on the intuition behind the ResNet, Inception, and Xception architectures, and why they have become building blocks for so many subsequent works in computer vision.</p>\n<h3 class=\"graf graf--h3 graf-after--p\" id=\"4a32\">ResNet</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"6c51\">ResNet was born from a beautifully simple observation:\u00a0<em class=\"markup--em markup--p-em\">why do very deep nets perform worse as you keep adding layers</em>?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"a6cc\">Intuitively, deeper nets should perform no worse than their shallower counterparts, at least at train time (when there is no risk of overfitting). As a thought experiment, let\u2019s say we\u2019ve built a net with\u00a0<em class=\"markup--em markup--p-em\">n</em>\u00a0layers that achieves a certain accuracy. At minimum, a net with\u00a0<em class=\"markup--em markup--p-em\">n+1</em>\u00a0layers should be able to achieve the exact same accuracy, if only by copying over the same first\u00a0<em class=\"markup--em markup--p-em\">n</em>layers and performing an identity mapping for the last layer. Similarly, nets of\u00a0<em class=\"markup--em markup--p-em\">n+2</em>,\u00a0<em class=\"markup--em markup--p-em\">n+3</em>, and\u00a0<em class=\"markup--em markup--p-em\">n+4</em>\u00a0layers could all continue performing identity mappings and achieve the same accuracy. In practice, however, these deeper nets almost always degrade in performance.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"5d2d\">The authors of ResNet boiled these problems down to a single hypothesis:\u00a0<em class=\"markup--em markup--p-em\">direct mappings are hard to learn</em>. And they proposed a fix: instead of trying to learn an underlying mapping from x to H(x), learn the\u00a0<em class=\"markup--em markup--p-em\">difference</em>\u00a0between the two, or the \u201cresidual.\u201d Then, to calculate H(x), we can just add the residual to the input.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"648b\">Say the residual is F(x)=H(x)-x. Now, instead of trying to learn H(x) directly, our nets are trying to learn F(x)+x.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"1aea\">This gives rise to the famous ResNet (or \u201cresidual network\u201d) block you\u2019ve probably seen:</p>\n<p><img class=\"size-full\" src=\"https://cdn-images-1.medium.com/max/1600/1*5zSgo2L71FJos8XendgCvQ.jpeg\" width=\"95%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"86bd\">Each \u201cblock\u201d in ResNet consists of a series of layers and a \u201cshortcut\u201d connection adding the input of the block to its output. The \u201cadd\u201d operation is performed element-wise, and if the input and output are of different sizes, zero-padding or projections (via 1\u00d71 convolutions) can be used to create matching dimensions.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"8fac\">If we go back to our thought experiment, this simplifies our construction of identity layers greatly. Intuitively, it\u2019s much easier to learn to push F(x) to 0 and leave the output as x than to learn an identity transformation from scratch. In general, ResNet gives layers a \u201creference\u201d point\u200a\u2014\u200ax\u200a\u2014\u200ato start learning from.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"076d\">This idea works astoundingly well in practice. Previously, deep neural nets often suffered from the problem of\u00a0<a class=\"markup--anchor markup--p-anchor\" data-href=\"https://en.wikipedia.org/wiki/Vanishing_gradient_problem\" href=\"https://en.wikipedia.org/wiki/Vanishing_gradient_problem\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">vanishing gradients</a>, in which gradient signals from the error function decreased exponentially as they backpropogated to earlier layers. In essence, by the time the error signals traveled all the way back to the early layers, they were so small that the net couldn\u2019t learn. However, because the gradient signal in ResNets could travel back directly to early layers via shortcut connections, we could suddenly build 50-layer, 101-layer, 152-layer, and even (apparently) 1000+ layer nets that still performed well. At the time, this was a\u00a0<em class=\"markup--em markup--p-em\">huge</em>\u00a0leap forward from the previous state-of-the-art, which won the ILSVRC 2014 challenge with 22 layers.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"fa13\">ResNet is one of my personal favorite developments in the neural network world. So many deep learning papers come out with minor improvements from hacking away at the math, the optimizations, and the training process without thought to the underlying task of the model. ResNet fundamentally changed the way we understand neural networks and how they learn.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"db26\">Fun facts:</p>\n<ul class=\"postList\">\n<li class=\"graf graf--li graf-after--p\" id=\"e9b7\">The 1000+ layer net is open-source! I would not\u00a0<em class=\"markup--em markup--li-em\">really</em>\u00a0recommend you try re-training it,\u00a0<a class=\"markup--anchor markup--li-anchor\" data-href=\"https://github.com/KaimingHe/resnet-1k-layers\" href=\"https://github.com/KaimingHe/resnet-1k-layers\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">but\u2026</a></li>\n<li class=\"graf graf--li graf-after--li\" id=\"34d8\">If you\u2019re feeling functional and a little frisky, I recently ported ResNet50 to the open-source Clojure ML library\u00a0<a class=\"markup--anchor markup--li-anchor\" data-href=\"https://github.com/thinktopic/cortex\" href=\"https://github.com/thinktopic/cortex\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Cortex</a>. Try it out and see how it compares to Keras!</li>\n</ul>\n<h3 class=\"graf graf--h3 graf-after--li\" id=\"013b\">Inception</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"7042\">If ResNet was all about going deeper, the Inception Family\u2122 is all about going wider. In particular, the authors of Inception were interested in the computational efficiency of training larger nets. In other words:\u00a0<em class=\"markup--em markup--p-em\">how can we scale up neural nets without increasing computational cost?</em></p>\n<p class=\"graf graf--p graf-after--p\" id=\"e9b0\">The original paper focused on a new building block for deep nets, a block now known as the \u201cInception module.\u201d At its core, this module is the product of two key insights.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"2858\">The first insight relates to layer operations. In a traditional conv net, each layer extracts information from the previous layer in order to transform the input data into a more useful representation. However, each layer type extracts a different kind of information. The output of a 5\u00d75 convolutional kernel tells us something different from the output of a 3\u00d73 convolutional kernel, which tells us something different from the output of a max-pooling kernel, and so on and so on. At any given layer, how do we know what transformation provides the most \u201cuseful\u201d information?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"c1e2\">Insight #1: why not let the model choose?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"3d08\">An Inception module computes\u00a0<em class=\"markup--em markup--p-em\">multiple different transformations</em>\u00a0over the same input map<em class=\"markup--em markup--p-em\">\u00a0</em>in parallel, concatenating their results into a single output. In other words, for each layer, Inception does a 5\u00d75 convolutional transformation,\u00a0<em class=\"markup--em markup--p-em\">and</em>\u00a0a 3\u00d73,\u00a0<em class=\"markup--em markup--p-em\">and</em>\u00a0a max-pool. And the next layer of the model gets to decide if (and how) to use each piece of information.</p>\n<p class=\"graf graf--p graf-after--p\"><img class=\"aligncenter size-full\" src=\"https://cdn-images-1.medium.com/max/1600/1*RuR5VAe4WaODcQFrxU6vWw.jpeg\" width=\"95%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"d91d\">The increased information density of this model architecture comes with one glaring problem: we\u2019ve drastically increased computational costs. Not only are large (e.g. 5\u00d75) convolutional filters inherently expensive to compute, stacking multiple different filters side by side greatly increases the number of feature maps per layer. And this increase becomes a deadly bottleneck in our model.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"64a6\">Think about it this way. For each additional filter added, we have to convolve over\u00a0<em class=\"markup--em markup--p-em\">all</em>\u00a0the input maps to calculate a single output. See the image below: creating one output map from a single filter involves computing over\u00a0<em class=\"markup--em markup--p-em\">every single map</em>\u00a0from the previous layer.</p>\n<p class=\"graf graf--p graf-after--p\"><img class=\"aligncenter size-full\" src=\"https://cdn-images-1.medium.com/max/1600/1*lGm8_2SBMkAyechJeznyAQ.png\" width=\"95%\"/></p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/08/top-news-week-0821-0827.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/08/python-overtakes-r-leader-analytics-data-science.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/index.html\">Aug</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/opinions-interviews.html\">Opinions, Interviews</a> \u00bb An Intuitive Guide to Deep Network Architectures (\u00a0<a href=\"/2017/n33.html\">17:n33</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556373888\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.708 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 10:04:48 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "joyc", "stanford", "over", "the", "past", "few", "year", "much", "the", "progress", "deep", "learn", "for", "comput", "vision", "can", "boil", "down", "just", "hand", "neural", "network", "architectur", "set", "asid", "all", "the", "math", "the", "code", "and", "the", "implement", "detail", "want", "explor", "one", "simpl", "question", "how", "and", "whi", "these", "model", "work", "the", "time", "write", "kera", "ship", "with", "six", "these", "pretrain", "model", "alreadi", "built", "into", "the", "librari", "resnetnum", "incept", "vnum", "xception", "mobilenet", "the", "network", "along", "with", "the", "earlier", "alexnet", "from", "num", "follow", "the", "now", "archetyp", "layout", "basic", "conv", "net", "seri", "convolut", "maxpool", "and", "activ", "layer", "befor", "some", "fullyconnect", "classif", "layer", "the", "end", "mobilenet", "essenti", "streamlin", "version", "the", "xception", "architectur", "optim", "for", "mobil", "applic", "the", "remain", "three", "howev", "truli", "redefin", "the", "way", "look", "neural", "network", "this", "rest", "this", "post", "will", "focus", "the", "intuit", "behind", "the", "resnet", "incept", "and", "xception", "architectur", "and", "whi", "they", "have", "becom", "build", "block", "for", "mani", "subsequ", "work", "comput", "vision", "resnet", "resnet", "born", "from", "beauti", "simpl", "observ", "whi", "veri", "deep", "net", "perform", "wors", "keep", "layer", "intuit", "deeper", "net", "should", "perform", "wors", "than", "their", "shallow", "counterpart", "least", "train", "time", "when", "there", "risk", "overfit", "thought", "experi", "let", "say", "built", "net", "with", "layer", "that", "achiev", "certain", "accuraci", "minimum", "net", "with", "nnum", "layer", "should", "abl", "achiev", "the", "exact", "same", "accuraci", "onli", "copi", "over", "the", "same", "first", "layer", "and", "perform", "ident", "map", "for", "the", "last", "layer", "similar", "net", "nnum", "nnum", "and", "nnum", "layer", "could", "all", "continu", "perform", "ident", "map", "and", "achiev", "the", "same", "accuraci", "practic", "howev", "these", "deeper", "net", "almost", "alway", "degrad", "perform", "the", "author", "resnet", "boil", "these", "problem", "down", "singl", "hypothesi", "direct", "map", "are", "hard", "learn", "and", "they", "propos", "fix", "instead", "tri", "learn", "under", "map", "from", "learn", "the", "differ", "between", "the", "two", "the", "residu", "then", "calcul", "can", "just", "add", "the", "residu", "the", "input", "say", "the", "residu", "now", "instead", "tri", "learn", "direct", "our", "net", "are", "tri", "learn", "this", "give", "rise", "the", "famous", "resnet", "residu", "network", "block", "probabl", "seen", "each", "block", "resnet", "consist", "seri", "layer", "and", "shortcut", "connect", "the", "input", "the", "block", "output", "the", "add", "oper", "perform", "elementwis", "and", "the", "input", "and", "output", "are", "differ", "size", "zeropad", "project", "via", "num\u00d7num", "convolut", "can", "use", "creat", "match", "dimens", "back", "our", "thought", "experi", "this", "simplifi", "our", "construct", "ident", "layer", "great", "intuit", "much", "easier", "learn", "push", "num", "and", "leav", "the", "output", "than", "learn", "ident", "transform", "from", "scratch", "general", "resnet", "give", "layer", "refer", "point", "start", "learn", "from", "this", "idea", "work", "astound", "well", "practic", "previous", "deep", "neural", "net", "often", "suffer", "from", "the", "problem", "vanish", "gradient", "which", "gradient", "signal", "from", "the", "error", "function", "decreas", "exponenti", "they", "backpropog", "earlier", "layer", "essenc", "the", "time", "the", "error", "signal", "travel", "all", "the", "way", "back", "the", "earli", "layer", "they", "were", "small", "that", "the", "net", "couldn", "learn", "howev", "becaus", "the", "gradient", "signal", "resnet", "could", "travel", "back", "direct", "earli", "layer", "via", "shortcut", "connect", "could", "sudden", "build", "numlay", "numlay", "numlay", "and", "even", "appar", "num", "layer", "net", "that", "still", "perform", "well", "the", "time", "this", "huge", "leap", "forward", "from", "the", "previous", "stateoftheart", "which", "won", "the", "num", "challeng", "with", "num", "layer", "resnet", "one", "person", "favorit", "develop", "the", "neural", "network", "world", "mani", "deep", "learn", "paper", "come", "out", "with", "minor", "improv", "from", "hack", "away", "the", "math", "the", "optim", "and", "the", "train", "process", "without", "thought", "the", "under", "task", "the", "model", "resnet", "fundament", "chang", "the", "way", "understand", "neural", "network", "and", "how", "they", "learn", "fun", "fact", "the", "num", "layer", "net", "opensourc", "would", "not", "realli", "recommend", "tri", "retrain", "but\u2026", "feel", "function", "and", "littl", "friski", "recent", "port", "resnetnum", "the", "opensourc", "clojur", "librari", "cortex", "tri", "out", "and", "see", "how", "compar", "kera", "incept", "resnet", "all", "about", "deeper", "the", "incept", "family\u2122", "all", "about", "wider", "particular", "the", "author", "incept", "were", "interest", "the", "comput", "effici", "train", "larger", "net", "other", "word", "how", "can", "scale", "neural", "net", "without", "increas", "comput", "cost", "the", "origin", "paper", "focus", "new", "build", "block", "for", "deep", "net", "block", "now", "known", "the", "incept", "modul", "core", "this", "modul", "the", "product", "two", "key", "insight", "the", "first", "insight", "relat", "layer", "oper", "tradit", "conv", "net", "each", "layer", "extract", "inform", "from", "the", "previous", "layer", "order", "transform", "the", "input", "data", "into", "more", "use", "represent", "howev", "each", "layer", "type", "extract", "differ", "kind", "inform", "the", "output", "num\u00d7num", "convolut", "kernel", "tell", "someth", "differ", "from", "the", "output", "num\u00d7num", "convolut", "kernel", "which", "tell", "someth", "differ", "from", "the", "output", "maxpool", "kernel", "and", "and", "ani", "given", "layer", "how", "know", "what", "transform", "provid", "the", "most", "use", "inform", "insight", "num", "whi", "not", "let", "the", "model", "choos", "incept", "modul", "comput", "multipl", "differ", "transform", "over", "the", "same", "input", "map", "parallel", "concaten", "their", "result", "into", "singl", "output", "other", "word", "for", "each", "layer", "incept", "doe", "num\u00d7num", "convolut", "transform", "and", "num\u00d7num", "and", "maxpool", "and", "the", "next", "layer", "the", "model", "get", "decid", "and", "how", "use", "each", "piec", "inform", "the", "increas", "inform", "densiti", "this", "model", "architectur", "come", "with", "one", "glare", "problem", "drastic", "increas", "comput", "cost", "not", "onli", "are", "larg", "num\u00d7num", "convolut", "filter", "inher", "expens", "comput", "stack", "multipl", "differ", "filter", "side", "side", "great", "increas", "the", "number", "featur", "map", "per", "layer", "and", "this", "increas", "becom", "dead", "bottleneck", "our", "model", "think", "about", "this", "way", "for", "each", "addit", "filter", "have", "convolv", "over", "all", "the", "input", "map", "calcul", "singl", "output", "see", "the", "imag", "below", "creat", "one", "output", "map", "from", "singl", "filter", "involv", "comput", "over", "everi", "singl", "map", "from", "the", "previous", "layer"], "timestamp_scraper": 1556373889.533567, "title": "An Intuitive Guide to Deep Network Architectures", "read_time": 320.7, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"/2017/08/intuitive-guide-deep-network-architectures.html/2#comments\">comments</a></div>\n<p><b>By <a href=\"https://medium.com/@joycex99\">Joyce Xu</a>, Stanford</b>.</p>\n<p><img class=\"size-full\" src=\"https://cdn-images-1.medium.com/max/2000/1*_rCyzi7fQzc_Q1gCqSLM1g.png\" width=\"95%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"504e\">Over the past few years, much of the progress in deep learning for computer vision can be boiled down to just a handful of neural network architectures. Setting aside all the math, the code, and the implementation details, I wanted to explore one simple question: how and why do these models work?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"bb1c\">At the time of writing, Keras ships with six of these pre-trained models\u00a0<a class=\"markup--anchor markup--p-anchor\" data-href=\"https://keras.io/applications/\" href=\"https://keras.io/applications/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">already built into the library</a>:</p>\n<ul class=\"postList\">\n<li class=\"graf graf--li graf-after--p\" id=\"f8ec\">VGG16</li>\n<li class=\"graf graf--li graf-after--li\" id=\"8ce4\">VGG19</li>\n<li class=\"graf graf--li graf-after--li\" id=\"6968\">ResNet50</li>\n<li class=\"graf graf--li graf-after--li\" id=\"0c7a\">Inception v3</li>\n<li class=\"graf graf--li graf-after--li\" id=\"da74\">Xception</li>\n<li class=\"graf graf--li graf-after--li\" id=\"c7e1\">MobileNet</li>\n</ul>\n<p class=\"graf graf--p graf-after--li\" id=\"9688\">The VGG networks, along with the earlier AlexNet from 2012, follow the now archetypal layout of basic conv nets: a series of convolutional, max-pooling, and activation layers before some fully-connected classification layers at the end. MobileNet is essentially a streamlined version of the Xception architecture optimized for mobile applications. The remaining three, however, truly redefine the way we look at neural networks.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"4d1c\">This rest of this post will focus on the intuition behind the ResNet, Inception, and Xception architectures, and why they have become building blocks for so many subsequent works in computer vision.</p>\n<h3 class=\"graf graf--h3 graf-after--p\" id=\"4a32\">ResNet</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"6c51\">ResNet was born from a beautifully simple observation:\u00a0<em class=\"markup--em markup--p-em\">why do very deep nets perform worse as you keep adding layers</em>?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"a6cc\">Intuitively, deeper nets should perform no worse than their shallower counterparts, at least at train time (when there is no risk of overfitting). As a thought experiment, let\u2019s say we\u2019ve built a net with\u00a0<em class=\"markup--em markup--p-em\">n</em>\u00a0layers that achieves a certain accuracy. At minimum, a net with\u00a0<em class=\"markup--em markup--p-em\">n+1</em>\u00a0layers should be able to achieve the exact same accuracy, if only by copying over the same first\u00a0<em class=\"markup--em markup--p-em\">n</em>layers and performing an identity mapping for the last layer. Similarly, nets of\u00a0<em class=\"markup--em markup--p-em\">n+2</em>,\u00a0<em class=\"markup--em markup--p-em\">n+3</em>, and\u00a0<em class=\"markup--em markup--p-em\">n+4</em>\u00a0layers could all continue performing identity mappings and achieve the same accuracy. In practice, however, these deeper nets almost always degrade in performance.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"5d2d\">The authors of ResNet boiled these problems down to a single hypothesis:\u00a0<em class=\"markup--em markup--p-em\">direct mappings are hard to learn</em>. And they proposed a fix: instead of trying to learn an underlying mapping from x to H(x), learn the\u00a0<em class=\"markup--em markup--p-em\">difference</em>\u00a0between the two, or the \u201cresidual.\u201d Then, to calculate H(x), we can just add the residual to the input.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"648b\">Say the residual is F(x)=H(x)-x. Now, instead of trying to learn H(x) directly, our nets are trying to learn F(x)+x.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"1aea\">This gives rise to the famous ResNet (or \u201cresidual network\u201d) block you\u2019ve probably seen:</p>\n<p><img class=\"size-full\" src=\"https://cdn-images-1.medium.com/max/1600/1*5zSgo2L71FJos8XendgCvQ.jpeg\" width=\"95%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"86bd\">Each \u201cblock\u201d in ResNet consists of a series of layers and a \u201cshortcut\u201d connection adding the input of the block to its output. The \u201cadd\u201d operation is performed element-wise, and if the input and output are of different sizes, zero-padding or projections (via 1\u00d71 convolutions) can be used to create matching dimensions.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"8fac\">If we go back to our thought experiment, this simplifies our construction of identity layers greatly. Intuitively, it\u2019s much easier to learn to push F(x) to 0 and leave the output as x than to learn an identity transformation from scratch. In general, ResNet gives layers a \u201creference\u201d point\u200a\u2014\u200ax\u200a\u2014\u200ato start learning from.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"076d\">This idea works astoundingly well in practice. Previously, deep neural nets often suffered from the problem of\u00a0<a class=\"markup--anchor markup--p-anchor\" data-href=\"https://en.wikipedia.org/wiki/Vanishing_gradient_problem\" href=\"https://en.wikipedia.org/wiki/Vanishing_gradient_problem\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">vanishing gradients</a>, in which gradient signals from the error function decreased exponentially as they backpropogated to earlier layers. In essence, by the time the error signals traveled all the way back to the early layers, they were so small that the net couldn\u2019t learn. However, because the gradient signal in ResNets could travel back directly to early layers via shortcut connections, we could suddenly build 50-layer, 101-layer, 152-layer, and even (apparently) 1000+ layer nets that still performed well. At the time, this was a\u00a0<em class=\"markup--em markup--p-em\">huge</em>\u00a0leap forward from the previous state-of-the-art, which won the ILSVRC 2014 challenge with 22 layers.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"fa13\">ResNet is one of my personal favorite developments in the neural network world. So many deep learning papers come out with minor improvements from hacking away at the math, the optimizations, and the training process without thought to the underlying task of the model. ResNet fundamentally changed the way we understand neural networks and how they learn.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"db26\">Fun facts:</p>\n<ul class=\"postList\">\n<li class=\"graf graf--li graf-after--p\" id=\"e9b7\">The 1000+ layer net is open-source! I would not\u00a0<em class=\"markup--em markup--li-em\">really</em>\u00a0recommend you try re-training it,\u00a0<a class=\"markup--anchor markup--li-anchor\" data-href=\"https://github.com/KaimingHe/resnet-1k-layers\" href=\"https://github.com/KaimingHe/resnet-1k-layers\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">but\u2026</a></li>\n<li class=\"graf graf--li graf-after--li\" id=\"34d8\">If you\u2019re feeling functional and a little frisky, I recently ported ResNet50 to the open-source Clojure ML library\u00a0<a class=\"markup--anchor markup--li-anchor\" data-href=\"https://github.com/thinktopic/cortex\" href=\"https://github.com/thinktopic/cortex\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Cortex</a>. Try it out and see how it compares to Keras!</li>\n</ul>\n<h3 class=\"graf graf--h3 graf-after--li\" id=\"013b\">Inception</h3>\n<p class=\"graf graf--p graf-after--h3\" id=\"7042\">If ResNet was all about going deeper, the Inception Family\u2122 is all about going wider. In particular, the authors of Inception were interested in the computational efficiency of training larger nets. In other words:\u00a0<em class=\"markup--em markup--p-em\">how can we scale up neural nets without increasing computational cost?</em></p>\n<p class=\"graf graf--p graf-after--p\" id=\"e9b0\">The original paper focused on a new building block for deep nets, a block now known as the \u201cInception module.\u201d At its core, this module is the product of two key insights.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"2858\">The first insight relates to layer operations. In a traditional conv net, each layer extracts information from the previous layer in order to transform the input data into a more useful representation. However, each layer type extracts a different kind of information. The output of a 5\u00d75 convolutional kernel tells us something different from the output of a 3\u00d73 convolutional kernel, which tells us something different from the output of a max-pooling kernel, and so on and so on. At any given layer, how do we know what transformation provides the most \u201cuseful\u201d information?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"c1e2\">Insight #1: why not let the model choose?</p>\n<p class=\"graf graf--p graf-after--p\" id=\"3d08\">An Inception module computes\u00a0<em class=\"markup--em markup--p-em\">multiple different transformations</em>\u00a0over the same input map<em class=\"markup--em markup--p-em\">\u00a0</em>in parallel, concatenating their results into a single output. In other words, for each layer, Inception does a 5\u00d75 convolutional transformation,\u00a0<em class=\"markup--em markup--p-em\">and</em>\u00a0a 3\u00d73,\u00a0<em class=\"markup--em markup--p-em\">and</em>\u00a0a max-pool. And the next layer of the model gets to decide if (and how) to use each piece of information.</p>\n<p class=\"graf graf--p graf-after--p\"><img class=\"aligncenter size-full\" src=\"https://cdn-images-1.medium.com/max/1600/1*RuR5VAe4WaODcQFrxU6vWw.jpeg\" width=\"95%\"/></p>\n<p class=\"graf graf--p graf-after--figure\" id=\"d91d\">The increased information density of this model architecture comes with one glaring problem: we\u2019ve drastically increased computational costs. Not only are large (e.g. 5\u00d75) convolutional filters inherently expensive to compute, stacking multiple different filters side by side greatly increases the number of feature maps per layer. And this increase becomes a deadly bottleneck in our model.</p>\n<p class=\"graf graf--p graf-after--p\" id=\"64a6\">Think about it this way. For each additional filter added, we have to convolve over\u00a0<em class=\"markup--em markup--p-em\">all</em>\u00a0the input maps to calculate a single output. See the image below: creating one output map from a single filter involves computing over\u00a0<em class=\"markup--em markup--p-em\">every single map</em>\u00a0from the previous layer.</p>\n<p class=\"graf graf--p graf-after--p\"><img class=\"aligncenter size-full\" src=\"https://cdn-images-1.medium.com/max/1600/1*lGm8_2SBMkAyechJeznyAQ.png\" width=\"95%\"/></p>\n</div> ", "website": "kdnuggets"}