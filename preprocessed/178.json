{"content": "By Francesco Corea , Decision Scientist and Data Strategist. comments Image Credit: andruxevich/Shutterstock There has been a lot of talk over the past months about AI being our best or worst invention ever. The chance of robots taking over and the following catastrophic sci-fi scenario makes the ethical and purposeful design of machines and algorithms not simply important but necessary. But the problems do not end here. Incorporating ethical principles into our technology development process should not just be a way to prevent human race extinction but also a way to understand how to use the power coming from that technology responsibly. This article does not want to be a guide for ethics for AI or setting the guidelines for building ethical technologies. It is simply a stream of consciousness on questions and problems I have been thinking and asking myself, and hopefully, it will stimulate some discussion. Now, let\u2019s go down the rabbit-hole... Image Credit:\u00a0 phloxii/Shutterstock \u00a0 I. Data and biases \u00a0 The first problem everyone raises when speaking about ethics in AI is, of course, about data. Most of the data we produce (if we exclude the ones coming from observation of natural phenomena) are artificial creations of our minds and actions (e.g., stock prices, smartphone activity, etc.). As such, \u00a0data inherit the same biases we have as humans . First of all, what is a cognitive bias? The (maybe controversial) way I look at it is that a cognitive bias is a\u00a0 shortcut of our brain that translates into behaviors which required less energy and thought to be implemented . So, a bias is a good thing to me, at least in principle. The reason why it becomes a bad thing is that the external environment and our internal capacity to think do not proceed\u00a0 pari passu.\u00a0 Our brain gets trapped into heuristics and shortcuts which could have resulted into competitive advantages 100 years ago but is not that\u00a0 plastic \u00a0to quickly adapt to the change of the external environment (I am not talking about a single brain but rather on a species level). In other words,\u00a0 the systematic deviation from a standard of rationality or good judgment\u00a0 (this is how bias is defined in psychology) is nothing more for me than a simple\u00a0 evolutionary lag of our brain. Why all this\u00a0 excursus ? Well, because I think that most of the biases data embed comes from our own cognitive biases (at least for data resulting from human and not natural activities). There is, of course, another block of biases which stems from pure statistical reasons ( the expected value is different from the true underlying estimated parameter ). Kris Hammond of Narrative Science merged those two views and identified\u00a0 at least five different biases \u00a0in AI. In his words: Data-driven bias \u00a0(bias that depends on the input data used); Bias through interaction ; Similarity bias \u00a0(it is simply the product of systems doing what they were designed to do); Conflicting goals bias \u00a0(systems designed for very specific business purposes end up having biases that are real but completely unforeseen); Emergent bias \u00a0(decisions made by systems aimed at personalization will end up creating bias \u201cbubbles\u201d around us). But let\u2019s go back to the problem. How would you solve the biased data issue then? Simple solution: you can try to remove any data that could bias your engine\u00a0 ex-ante . Great solution, it will require some effort at the beginning, but it might be feasible. However, let\u2019s look at the problem from a different angle. I was educated as an economist, so allow me to start my argument with this statement:\u00a0 let\u2019s assume we have the perfect dataset . It is not only omni-comprehensive but also clean, consistent and deep both longitudinally and temporally speaking. Even in this case,\u00a0 we have no guarantee AI won\u2019t learn the same bias autonomously as we did . In other words, removing biases by hand or by construction is not a guarantee of those biases to not come out again spontaneously. We have no guarantee AI won\u2019t learn the same bias autonomously as we\u00a0did. This possibility also raises another (philosophical) question: we are building this argument from the assumption that\u00a0 biases are bad \u00a0(mostly). So let\u2019s say the machines come up with a result we see as biased, and therefore we reset them and start again the analysis with new data. But the machines come up with a similarly \u2018biased result\u2019. Would we then be open to accepting that as true and revision what we consider to be biased? This is basically a\u00a0 cultural and philosophical clash between two different species . In other words, I believe that two of the reasons why embedding ethics into machine designing is extremely hard is that i)\u00a0 we don\u2019t really know unanimously what ethics is , and ii) we should be open to admit that our values or ethics might not be completely right and that what we consider to be biased is not the exception but rather the norm. Developing a (general) AI is making us think about those problems and\u00a0 it will change\u00a0 (if it hasn\u2019t already started)\u00a0 our values system . And perhaps, who knows, we will end up learning something from\u00a0 machines\u2019 ethics\u00a0 as well. Image Credit:\u00a0 Notre Dame of Maryland University Online \u00a0 II. Accountability and trust \u00a0 Well, now you might think the previous one is a purely philosophical issue and that you probably shouldn\u2019t care about it. But the other side of the matter is about how much you\u00a0 trust your algorithms . Let me give you a different perspective to practically looking at this problem. Let\u2019s assume you are a medical doctor and you use one of the many algorithms out there to help you diagnose a specific disease or to assist you in a patient treatment. In the 99.99% of the time the computer gets it right\u200a\u2014\u200aand it never gets tired, it analyzed billions of records, it sees patterns that a human eye can\u2019t perceive, we all know this story, right? But what if in the remaining o.o1% of the case your instinct tells you something opposite to the machine result and you end up to be right? What if you decide to follow the advice the machine spit out instead of yours and the patient dies? Who is liable in this case? But even worse: let\u2019s say in that case you follow your gut feeling (we know is not gut feeling though, but simply your ability to recognize at a glance something you know to be the right disease or treatment) and you save a patient. The following time (and patient), you have another conflict with the machine results but strong of the recent past experience (because of an\u00a0 hot-hand fallacy \u00a0or an\u00a0 overconfidence\u00a0 bias) you think to be right again and decide to disregard what the artificial engine tells you. Then the patient dies. Who is liable now? The question is quite delicate indeed and the scenarios in my head are: a) a scenario where the doctor is only human with no machine assistance. The payoff here is that liability stay with him, he gets it right 70% of the time, but the things are quite clear and sometimes he gets right something extremely hard (the lucky guy out of 10,000 patients); b) a scenario where a machine decides and gets it right 99.99% of the time. The negative side of it is an unfortunate patient out of 10,000 is going to die because of a machine error and the liability is not assigned to either the machine or the human; c) a scenario the doctor is assisted but has the final call to decide whether to follow the advice. The payoff here is completely randomized and not clear to me at all. As a former economist, I have been trained to be heartless and reason in terms of expected values and big numbers (basically a\u00a0 Utilitarian ), therefore scenario\u00a0 b) \u00a0looks the only possible to me because it saves the greatest number of people. But we all know is not that simple (and of course doesn\u2019t feel right for the unlucky guy of our example): think about the case, for instance, of autonomous vehicles that lose controls and need to decide if killing the driver or five random pedestrians (the famous\u00a0 Trolley Problem ). Based on that principles I\u2019d save the pedestrians, right? But what about all those five are criminals and the driver is a pregnant woman? Does your judgement change in that case? And again, what if the vehicle could instantly use cameras and visual sensors to recognize pedestrians\u2019 faces, connect to a central database and match them with health records finding out that they all have some type of terminal disease? You see, the line is blurring... The final doubt that remains is then not simply about liability (and the choice between pure outcomes and ways to achieve them) but rather on trusting the algorithm (and I know that for someone who studied 12 years to become doctor might not be that easy to give that up). In fact,\u00a0 algorithm adversion \u00a0is becoming a real problem for algorithms-assisted tasks and it looks that people want to have an (even if incredibly small) degree of control over algorithms (Dietvorst et al., 2015; 2016). But above all:\u00a0 are we allowed to deviate from the advice we get from accurate algorithms?\u00a0 And if so, in what circumstances and to what extent? Are we allowed to deviate from the advice we get from accurate algorithms? If an AI would decide on the matter, it will also probably go for scenario\u00a0 b) \u00a0but we as humans would like to find a compromise between those scenarios because we \u2018 ethically \u2019 don\u2019t feel any of those to be right. We can rephrase then this issue under the\u00a0 \u2018alignment problem\u2019\u00a0 lens, which means that the goals and behaviors an AI have need to be aligned with human values\u200a\u2014\u200aan AI needs to think as a human in certain cases (but of course the question here is how do you discriminate? And what\u2019s the advantage of having an AI then? Let\u2019s therefore simply stick to the traditional human activities). In this situation, the work done by the Future of Life Institute with the\u00a0 Asilomar Principles \u00a0 becomes extremely relevant. The alignment problem, in fact, also known as \u2018 King Midas problem \u2019, arises from the idea that no matter how we tune our algorithms to achieve a specific objective, we are not able to specify and frame those objectives well enough to prevent the machines to pursue undesirable ways to reach them. Of course, a theoretically viable solution would be to let the machine maximizing for our true objective without setting it\u00a0 ex-ante , making therefore the algorithm itself free to observe us and understand what we really want (as a species and not as individuals, which might entail also the possibility of switching itself off if needed). Sounds too good to be true? Well, maybe it is. I indeed totally agree with Nicholas Davis and Thomas Philbeck from WEF that in the\u00a0 Global Risks Report 2017 \u00a0wrote: \u201cThere are complications: humans are irrational, inconsistent, weak-willed, computationally limited and heterogeneous, all of which conspire to make learning about human values from human behaviour a difficult (and perhaps not totally desirable) enterprise\u201d. What the previous section implicitly suggested is that not all AI applications are the same and that\u00a0 error rates \u00a0apply differently to different industries. Under this assumption, it might be hard to draw a line and design an accountability framework that does not penalize applications with weak impact (e.g., a recommendation engine) and at the same time do not underestimate the impact of other applications (e.g,., healthcare or AVs). We might end up then designing\u00a0 multiple accountability frameworks\u00a0 to justify algorithmic decision-making and mitigate negative biases. Certainly, the most straightforward solution to understand who owns the liability for a certain AI tool is thinking about the following threefold classification: We should hold the AI system itself as responsible for any misbehavior (does it make any sense?); We should hold the designers of the AI as responsible for the malfunctioning and bad outcome \u00a0 (but it might be hard because usually AI teams might count hundred of people and this preventative measure could discourage many from entering the field); We should hold accountable the organization running the system\u00a0 (to me it sounds the most reasonable between the three options, but I am not sure about the implications of it. And then what company should be liable in the AI value chain? The final provider? The company who built the system in the first place? The consulting business which recommended it?). There is not an easy answer and much more is required to tackle this issue, but I believe a good starting point has been provided by\u00a0 Sorelle Friedler and Nicholas Diakopoulos . They suggest to consider accountability through the lens of five core principles: Responsibility : a person should be identified to deal with unexpected outcomes, not in terms of legal responsibility but rather as a single point of contact; Explainability : a decision process should be explainable not technically but rather in an accessible form to anyone; Accuracy :\u00a0 garbage in, garbage out \u00a0is likely to be the most common reason for the lack of accuracy in a model. The data and error sources need then to be identified, logged, and benchmarked; Auditability : third parties should be able to probe and review the behavior of an algorithm; Fairness : algorithms should be evaluated for discriminatory effects. Image Credit:\u00a0 mcmurryjulie/Pixabay", "title_html": "<h1 id=\"title\">Machine Ethics and Artificial Moral Agents</h1> ", "url": "https://www.kdnuggets.com/2017/11/machine-ethics-artificial-moral-agents.html", "tfidf": {"tfidf": {"hand": 1.6152202665600002, "real": 4.56206896552, "plastic": 11.0326615705, "audit": 15.12, "gut": 70.7171492204, "implic": 7.632692307689999, "patient": 66.82621767892, "too": 1.81585268215, "shouldn": 1443.27272727, "take": 1.13961668222, "built": 1.99447236181, "five": 5.50963040084, "form": 1.12755681818, "weakwil": 1443.27272727, "new": 1.0178880554, "assign": 3.83663605607, "viabl": 16.1834862385, "conflict": 5.3707713125800005, "organ": 1.6387283237, "veri": 1.25880114177, "heurist": 115.043478261, "lucki": 24.0181543116, "number": 2.20285833218, "previous": 2.85693719632, "been": 4.095711060959999, "etc": 4.2066772655, "dataset": 193.609756098, "andruxevichshutterstock": 1443.27272727, "exant": 2886.54545454, "pregnant": 16.4518134715, "enter": 1.75813953488, "draw": 2.97247706422, "assist": 6.51902545854, "log": 13.6744186047, "driver": 13.5982869379, "thought": 1.9854927463699998, "unexpect": 9.88542963885, "well": 5.3278743539999995, "product": 1.62264922322, "done": 2.3302509907499998, "never": 1.55769230769, "creation": 3.0601387818, "complet": 3.72064682448, "technic": 3.1400316455699997, "vehicl": 9.385752290860001, "stream": 6.5118949959000005, "know": 18.15289121205, "psycholog": 6.6846315789499995, "out": 7.42116861437, "advic": 28.32471008028, "legal": 2.6000655093400002, "thoma": 2.39673913043, "translat": 2.85745140389, "measur": 2.41093394077, "ever": 1.9697270471500001, "creat": 1.2492917847, "multipl": 2.74813917258, "probe": 18.7438016529, "how": 9.61501968306, "billion": 4.8669527897, "fair": 3.20533010297, "inconsist": 14.3934723481, "discrimin": 10.6981132075, "quit": 5.769943667100001, "stimul": 11.1960507757, "hundr": 2.4698195395099996, "end": 6.640825432260001, "die": 4.9961187454200005, "word": 7.186149145639999, "rabbithol": 1443.27272727, "heterogen": 52.0524590164, "guarante": 19.71357615894, "deep": 3.6279707495399998, "depend": 2.2411067193700003, "will": 7.34886591576, "true": 10.22279459112, "scenario": 123.1891367608, "datadriven": 1443.27272727, "consid": 3.7191941277600007, "contact": 3.2196309065099995, "excursus": 1443.27272727, "purpos": 4.46833661694, "incorpor": 2.62847682119, "dame": 18.6556991774, "lag": 33.3529411765, "similar": 2.75028150714, "healthcar": 18.7659574468, "inherit": 6.4932515337400005, "certain": 5.423365975860001, "need": 7.186311787049999, "our": 30.64864864867, "classif": 8.067073170730001, "sure": 7.453521126760001, "final": 4.02025829325, "trolley": 57.1079136691, "issu": 5.75686701116, "entail": 21.2530120482, "dietvorst": 1443.27272727, "record": 2.84669176976, "applic": 10.28016404058, "review": 2.2099109131400003, "prevent": 6.483528450870001, "level": 1.6544393497299998, "robot": 20.0201765448, "has": 3.1309492505999996, "enough": 2.2319696330700003, "object": 7.04660452731, "ration": 9.6159903089, "advantag": 6.64824120604, "termin": 4.86397058824, "experi": 1.87062566278, "famous": 2.28201811125, "sound": 6.22588235294, "conspir": 23.1091703057, "instinct": 26.198019801999997, "model": 2.0905978404, "onlin": 2.6051854282900004, "economist": 20.903225806400002, "good": 6.07926479036, "risk": 4.095975232200001, "rephras": 529.2, "admit": 4.03046458492, "under": 3.2344991510999996, "cours": 10.754640292649999, "tradit": 1.60802187785, "count": 3.48157894737, "field": 1.7790228597, "situat": 2.06611140031, "global": 3.30612244898, "tire": 12.5106382979, "unanim": 12.7008, "process": 3.39049652964, "not": 29.454545454509997, "strong": 1.6439888163999998, "asilomar": 1443.27272727, "recogn": 5.09908463144, "view": 1.6407606448899998, "are": 14.41868310092, "such": 1.06151377374, "less": 1.46904783936, "aim": 2.8960233491400005, "stori": 2.02396736359, "specif": 5.615847187829999, "quick": 2.205, "easi": 10.5875291764, "philbeck": 1443.27272727, "solv": 7.26923076923, "though": 1.36076112111, "problem": 21.20097930108, "complic": 5.6478121664900005, "they": 3.09051975861, "design": 10.20777073575, "anoth": 3.40930565496, "core": 4.623179965059999, "reach": 1.49801849406, "consult": 5.21721984883, "effect": 1.3963060686000002, "allow": 3.8148177813300004, "scienc": 2.31969608416, "outcom": 22.46603773584, "opposit": 2.4663663197099996, "eye": 3.39375801625, "section": 2.1284354471099998, "construct": 1.9320920043799998, "feasibl": 17.8181818182, "stem": 7.453521126760001, "behavior": 16.58934169278, "heartless": 305.307692308, "davi": 5.2137931034500005, "practic": 1.70434782609, "respons": 7.53345354465, "lack": 1.9271667880599999, "alreadi": 1.9551724137900002, "itself": 5.23672347444, "algorithm": 363.35915493019996, "valu": 15.944332855080003, "two": 3.04137931035, "either": 1.5830092731099998, "develop": 2.3911439114400004, "len": 41.505882353000004, "discriminatori": 53.6351351351, "observ": 4.44892812106, "accuraci": 25.5241157556, "conscious": 8.10413476263, "agre": 2.22946215419, "more": 2.0343413634, "stay": 2.6986231514499996, "suggest": 3.5143331488599996, "three": 1.06621893889, "lot": 4.40877534018, "some": 3.1211009174399997, "sourc": 1.69760479042, "small": 1.3594793629, "control": 2.93918356012, "both": 1.05215720061, "third": 1.4195278969999998, "aris": 7.54921540656, "result": 6.87669650592, "off": 1.5121440137200002, "judgment": 10.911340206199998, "produc": 1.36932896326, "guidelin": 13.580838323399998, "use": 4.1185550295199995, "set": 2.37415881562, "ethic": 89.3918918919, "ani": 4.53535209256, "king": 2.0281042411900003, "philosoph": 16.96758104739, "from": 18.01020986946, "account": 9.72317491425, "answer": 4.64890190337, "limit": 1.5186531471200002, "longitudin": 46.557184750699996, "num": 10.003150400100001, "clash": 8.34261692065, "instanc": 3.2572835453400004, "idea": 2.0930784443, "free": 1.71818181818, "environ": 6.87123999134, "studi": 1.53184098804, "incred": 18.227324913900002, "exclud": 5.31859296482, "for": 17.005355680170002, "difficult": 2.48957189901, "match": 3.5676404494400002, "with": 13.015576716869997, "misbehavior": 429.081081081, "competit": 3.06960556845, "judgement": 21.4251012146, "assum": 5.915052160959999, "reset": 65.3333333333, "merg": 5.28319467554, "solut": 18.9112567004, "controversi": 2.62543409955, "compani": 3.1047227926, "effort": 1.89247824532, "month": 1.5079787234, "sens": 2.8365195640499996, "team": 2.2748244734200003, "look": 9.543159413299998, "stock": 5.01611374408, "option": 4.04896710023, "passu": 1443.27272727, "woman": 3.47852760736, "chanc": 4.2449197861000005, "intern": 1.30355530011, "ago": 6.05954198473, "extern": 10.48266754704, "negat": 7.51704545454, "align": 24.31240428789, "educ": 2.00733341763, "tell": 6.72284564896, "artifici": 16.63279203772, "disregard": 21.9889196676, "remov": 4.011623499680001, "penal": 28.35, "doe": 6.8232513162, "even": 3.49383802818, "underestim": 45.36, "glanc": 46.285714285699996, "give": 2.7306501548, "total": 3.0920245398799997, "side": 3.1979051264, "place": 1.1004366812200002, "great": 1.26592775696, "deviat": 57.4523522316, "assumpt": 18.43902439024, "goal": 6.56304257958, "capac": 3.86842105263, "error": 18.123287671230003, "framework": 16.400826446279996, "extrem": 7.09806259314, "his": 1.0943682360200002, "ask": 2.1744966443, "type": 2.0281042411900003, "omnicomprehens": 1443.27272727, "invent": 4.604408352669999, "switch": 4.97368421053, "matter": 7.34320074006, "accept": 1.7377408056, "thing": 7.219645293329998, "analyz": 9.68639414277, "scientist": 4.69426374926, "machin": 56.340684410639994, "into": 5.0751230739499995, "medic": 3.27542809986, "bias": 425.7404844278, "extinct": 13.627467811199999, "notr": 33.9230769231, "hasn": 1443.27272727, "justifi": 7.578042959430001, "cultur": 1.86075949367, "where": 2.13430127042, "doctor": 15.757816377160001, "bubbl": 23.075581395300002, "face": 1.80327124035, "spit": 51.5454545455, "implicit": 21.1962616822, "let": 34.8616600791, "spontan": 16.1834862385, "head": 1.57781753131, "help": 1.39962972759, "believ": 3.2900217594, "find": 3.4588235294199996, "point": 2.51980001588, "francesco": 31.3136094675, "instead": 1.59461631177, "line": 2.8365195640599996, "brain": 35.716535433080004, "tempor": 21.897931034499997, "least": 4.8496079829, "base": 1.14628158845, "natur": 3.0785340314200003, "deal": 2.18346857379, "fact": 3.46751119362, "pari": 3.80810745982, "decid": 11.554585152840001, "univers": 1.24889867841, "compromis": 7.542042755339999, "hold": 4.9653878231999995, "payoff": 345.13043478199995, "here": 9.69230769232, "camera": 8.989807474520001, "report": 1.3634489866, "shortcut": 254.016, "pursu": 4.15384615385, "clean": 6.86975335353, "decisionmak": 1323.0, "paramet": 17.256521739100002, "human": 24.655118862789998, "liabil": 108.553846154, "much": 2.3884459154599997, "evalu": 6.9509632224199995, "than": 1.03278688525, "care": 2.49426551453, "about": 13.84318197067, "norm": 11.299644128099999, "run": 1.55692850838, "say": 3.5088960106, "diakopoulo": 1443.27272727, "mind": 3.5918552036199998, "discourag": 12.4811320755, "narrat": 6.002268431, "just": 1.33580143037, "perspect": 5.03520456708, "adapt": 3.32272917539, "understand": 8.90575916229, "won": 4.63465187564, "speci": 19.944723618090002, "price": 3.4838709677399997, "him": 1.63434218653, "simpli": 15.115201523340001, "statement": 3.42228928648, "systemat": 8.338235294119999, "would": 5.414364640899999, "them": 4.39504463976, "defin": 2.72830383227, "perceiv": 4.92279069767, "recommend": 7.828402366860001, "term": 2.79040337464, "friedler": 1443.27272727, "train": 1.9365698950999999, "save": 8.453674121399999, "tool": 4.99716713881, "start": 5.06694326976, "phloxiishutterstock": 1443.27272727, "power": 1.3396337861799998, "noth": 3.46410648047, "articl": 2.01805008262, "guid": 2.49113447356, "catastroph": 16.4859813084, "simpl": 10.19434931508, "trust": 14.68640148012, "bad": 10.18345093008, "energi": 3.66566612792, "explain": 5.20098280098, "speak": 5.78255326898, "singl": 3.21897810218, "lose": 3.0851146521599997, "central": 1.6121039805000001, "health": 2.71570304482, "abl": 3.6417020300400003, "tune": 10.4173228346, "mani": 2.08853515754, "diseas": 15.636244254749998, "over": 3.07575072651, "theoret": 7.83613030602, "perhap": 6.29625223082, "build": 3.2683479156, "analysi": 3.47852760736, "mida": 273.724137931, "liabl": 117.31034482769999, "provid": 2.43105428374, "wrote": 2.10473286491, "sorell": 1443.27272727, "pattern": 3.79173632673, "one": 3.01882487166, "unfortun": 9.966101694919999, "same": 5.592897907399999, "there": 5.20456333595, "connect": 1.8843916913900003, "stick": 11.5377906977, "fallaci": 65.3333333333, "possibl": 4.2521203464, "industri": 2.02319357716, "frame": 6.280063291139999, "delic": 27.0921501706, "exampl": 1.50483412322, "big": 2.7400759406299997, "crimin": 5.38717339667, "pure": 14.14973262033, "think": 26.16443874747, "enterpris": 6.414545454550001, "again": 6.03535449536, "visual": 5.22752716497, "follow": 6.278407592939999, "block": 3.20274359492, "tri": 1.8544562551099997, "then": 9.77920744644, "advers": 14.0994671403, "hard": 10.93012048192, "usual": 1.72508964468, "interact": 4.4185917061, "desir": 3.00170164492, "irrat": 55.7052631579, "basic": 5.460361135, "benchmark": 51.8823529412, "realli": 9.495215311, "abil": 2.70875277256, "feel": 12.542761208760002, "algorithmsassist": 1443.27272727, "also": 6.08859060402, "specifi": 6.920662598080001, "person": 2.81040892194, "around": 1.21394708671, "mean": 1.44906900329, "race": 2.93023255814, "treatment": 7.74250182882, "task": 3.88641370869, "system": 9.71178886657, "phenomena": 16.5202913632, "therefor": 9.33607762424, "the": 131.0, "becom": 4.49968114504, "probabl": 5.29111814698, "past": 4.03404904078, "peopl": 3.6396148555800005, "angl": 8.934158694430002, "open": 2.49113447356, "those": 8.36837349397, "want": 5.99094339624, "someon": 4.9350326391, "talk": 6.0606986066, "strategist": 55.5104895105, "argument": 10.18671799808, "individu": 1.8004082558400003, "evolutionari": 21.168000000000003, "howev": 1.0945191313299998, "kill": 2.09916699722, "pedestrian": 75.12302839110001, "cognit": 64.36216216230001, "smartphon": 77.443902439, "work": 1.11520089913, "could": 4.8174783796, "maxim": 12.928338762200001, "were": 1.02458857696, "which": 7.036342915, "databas": 8.24727272727, "random": 14.3804347826, "weak": 4.70539419087, "relev": 6.938811188810001, "activ": 4.39210623387, "estim": 2.34991119005, "other": 5.0496183206000005, "appli": 2.2972073506, "myself": 14.5517873511, "consist": 1.4901445466499998, "known": 1.0859097127200001, "impact": 5.95052473764, "hope": 2.50884955752, "begin": 1.3305397251100002, "rais": 3.9467992542, "see": 3.81726376533, "becaus": 6.897110998499999, "imag": 10.80551301684, "trap": 7.4570220760899995, "nichola": 17.92885375494, "mayb": 42.1114058356, "get": 14.2850073108, "like": 2.2983713355, "implement": 3.57648118946, "abov": 1.90382539873, "sensor": 28.8654545455, "should": 16.6432540099, "technolog": 7.8104296490700005, "except": 1.71948445792, "autonom": 33.259776536400004, "kris": 67.5574468085, "mitig": 22.8103448276, "undesir": 31.3754940711, "recent": 1.54405757635, "requir": 4.58534706846, "anyon": 5.37440758294, "straightforward": 27.7552447552, "access": 1.8734953976900002, "this": 16.06069802736, "choic": 3.1319786940200003, "principl": 17.260273972599997, "instant": 11.504347826099998, "time": 5.0563730174, "through": 2.14149861738, "engin": 7.414072229129999, "back": 1.26070038911, "chang": 3.5426956263, "scifi": 1221.23076923, "differ": 8.65581431575, "embed": 16.835630965, "but": 29.47340119071, "institut": 1.7792222346700002, "statist": 4.24265098878, "decis": 6.48, "malfunct": 41.778947368400004, "most": 6.12578778138, "between": 4.13814674832, "what": 20.05495026048, "who": 6.37675726338, "credit": 12.17251293848, "overconfid": 220.5, "all": 10.1146788991, "everyon": 6.3964544722, "busi": 4.11082340756, "action": 1.81855670103, "behaviour": 9.879278158060002, "reason": 10.34042553192, "someth": 13.12608515916, "unlucki": 178.38202247200002, "former": 1.36111111111, "degre": 2.4852849092, "case": 10.394911607920001, "hammond": 39.8894472362, "that": 35.13944223125, "garbag": 87.9556786704, "call": 1.0676529926, "revis": 4.32117583016, "blur": 29.7303370787, "futur": 1.8577112099200002, "and": 72.00453543335999, "year": 2.0970873786400004, "discuss": 2.19676214197, "achiev": 3.74433962264, "greatest": 3.00738776283, "life": 1.37051104972, "oonum": 1443.27272727, "worst": 6.653813914500001, "general": 1.1218202374200001, "made": 1.07038834951, "expect": 4.4002217295, "emerg": 2.1131372288, "question": 8.8163265306, "comment": 3.05954904606, "doubt": 5.31325301205, "corea": 453.6, "wors": 9.58695652174, "standard": 1.8915763135900003, "can": 3.52878417426, "comput": 7.855517070760001, "make": 5.3813300793000005, "way": 6.0953697305, "now": 3.4823426189999998, "onli": 3.0769429549800007, "hothand": 1443.27272727, "circumst": 5.28671328671, "clear": 3.70847932726, "diagnos": 16.283076923099998, "tackl": 19.8698372966, "utilitarian": 66.7058823529, "necessari": 2.8421052631599997, "accur": 11.537790697680002, "emb": 186.776470588, "remain": 2.33196239718, "common": 1.4025974025999999, "chain": 5.17639387023, "maryland": 12.335664335699999, "data": 40.51722671208, "threefold": 95.6385542169, "guy": 15.34654422426, "perfect": 4.48601299802, "rather": 7.7846425419, "whether": 2.20683903253, "best": 1.5828514456600002, "sometim": 1.7126213592200001, "come": 7.969879518059999, "might": 19.40567703381, "learn": 9.2910021946, "right": 16.86543909348, "identifi": 6.90561113529, "import": 1.3401992233700002, "first": 3.0228484386899996, "proceed": 3.4333910034599997, "input": 12.2029208301, "extent": 4.09491875161, "have": 13.193632934819998, "rate": 2.14048806795, "unforeseen": 120.27272727299999, "without": 1.29547123623, "whi": 9.769846153860001, "mcmurryjuliepixabay": 1443.27272727, "down": 1.35889754344, "inde": 8.86184761374, "own": 2.35688836104, "when": 1.02076769755, "parti": 2.06369426752}, "logtfidf": {"hand": 0.479471335336, "real": 1.649258121148, "plastic": 2.40086010702, "audit": 2.71601837075, "gut": 7.13108185232, "implic": 2.03244064121, "patient": 15.79329734297, "too": 0.5965551547219999, "shouldn": 7.2746685411000005, "take": 0.130691962197, "built": 0.690379535065, "five": 1.280812727624, "form": 0.120053184191, "weakwil": 7.2746685411000005, "new": 0.0177299468511, "assign": 1.3445959556, "viabl": 2.7839913543400003, "conflict": 1.97564870255, "organ": 0.49392052866999997, "veri": 0.230159793238, "heurist": 4.74531012875, "lucki": 3.1788099740499995, "number": 0.1932171568372, "previous": 0.713205920126, "been": 0.09458392947360002, "etc": 1.4366730879700003, "dataset": 5.26584456664, "andruxevichshutterstock": 7.2746685411000005, "exant": 14.549337082200001, "pregnant": 2.8004357125599997, "enter": 0.564256167492, "draw": 1.0893956335600001, "assist": 2.328337819644, "log": 2.61552683221, "driver": 3.8335932876, "thought": 0.685867118283, "unexpect": 2.2910619194, "well": 0.317572191578, "product": 0.484060136536, "done": 0.845975983129, "never": 0.443205436091, "creation": 1.11846026847, "complet": 0.6458557261410001, "technic": 1.14423287808, "vehicl": 3.09209129024, "stream": 1.8736305038599999, "know": 6.6704378607859995, "psycholog": 1.89981109743, "out": 0.40898473643509997, "advic": 7.829760841080001, "legal": 0.955536640608, "thoma": 0.874109117838, "translat": 1.0499301100299998, "measur": 0.880014199726, "ever": 0.6778949784020001, "creat": 0.222576818514, "multipl": 1.01092401812, "probe": 2.93086311925, "how": 2.8294017415800004, "billion": 1.5824680307199999, "fair": 1.16481508131, "inconsist": 2.6667747946500002, "discrimin": 2.37006739018, "quit": 2.11903027368, "stimul": 2.41556110681, "hundr": 0.904145087046, "end": 0.608860791708, "die": 1.530147214227, "word": 2.34344432954, "rabbithol": 7.2746685411000005, "heterogen": 3.9522520373, "guarante": 5.64808576455, "deep": 1.2886734698, "depend": 0.806969815, "will": 1.2167192094900001, "true": 3.753302518536, "scenario": 21.87423463912, "datadriven": 7.2746685411000005, "consid": 0.644684171472, "contact": 1.16926672768, "excursus": 7.2746685411000005, "purpos": 1.607738074644, "incorpor": 0.9664045229739999, "dame": 2.92615168533, "lag": 3.5071459596699994, "similar": 0.637112184228, "healthcar": 2.9320444543, "inherit": 1.87076341199, "certain": 1.776313088343, "need": 1.81370081721, "our": 11.149309784366, "classif": 2.08779073629, "sure": 2.0086865552, "final": 0.878201591844, "trolley": 4.04494270021, "issu": 1.456396175736, "entail": 3.0564986287700004, "dietvorst": 7.2746685411000005, "record": 0.706020713906, "applic": 3.6948117854699998, "review": 0.7929522039210001, "prevent": 2.3119577625689995, "level": 0.503462189943, "robot": 2.99674059227, "has": 0.1281718345644, "enough": 0.802884439169, "object": 2.561800754409, "ration": 2.26342736998, "advantag": 2.40241031766, "termin": 1.5818550978200001, "experi": 0.626272953933, "famous": 0.825060187979, "sound": 2.27113599038, "conspir": 3.14022952168, "instinct": 3.2656838278299998, "model": 0.7374500731110001, "onlin": 0.957503854357, "economist": 4.693512622619999, "good": 1.674357619628, "risk": 1.4100048408899999, "rephras": 6.27136643224, "admit": 1.39388165093, "under": 0.22578541614959996, "cours": 3.829497020665, "tradit": 0.47500477629199994, "count": 1.24748591139, "field": 0.5760642583510001, "situat": 0.725668290015, "global": 1.1957760371200001, "tire": 2.52657934619, "unanim": 2.5416649836099996, "process": 1.05565839805, "not": 0.4510199772175, "strong": 0.49712549393600003, "asilomar": 7.2746685411000005, "recogn": 1.871827718062, "view": 0.49515994217299997, "are": 0.4125446301578, "such": 0.059695977806, "less": 0.3846144626, "aim": 1.06333853704, "stori": 0.705059626587, "specif": 1.8809405026230002, "quick": 0.790727508899, "easi": 3.3330592702999997, "philbeck": 7.2746685411000005, "solv": 1.9836504770400003, "though": 0.308044191079, "problem": 6.829688691276, "complic": 1.7312682430000002, "they": 0.0891809843028, "design": 2.640673826154, "anoth": 0.38368908495599996, "core": 1.53108277245, "reach": 0.40414323085000003, "consult": 1.6519646640099999, "effect": 0.333830227158, "allow": 0.720841833567, "scienc": 0.841436178891, "outcom": 6.04017733872, "opposit": 0.90274594185, "eye": 1.22193786676, "section": 0.755387177948, "construct": 0.658603355972, "feasibl": 2.88021938643, "stem": 2.0086865552, "behavior": 5.13044440134, "heartless": 5.721320095319999, "davi": 1.6513076337600001, "practic": 0.533182530867, "respons": 2.049578311515, "lack": 0.656050938907, "alreadi": 0.670478380747, "itself": 1.6712511688530003, "algorithm": 43.29575113734, "valu": 5.7623531710360005, "two": 0.041096533074600004, "either": 0.459327638815, "develop": 0.357249389826, "len": 6.06537596016, "discriminatori": 3.98220435958, "observ": 1.5990320298640002, "accuraci": 5.0929530812, "conscious": 2.09237439596, "agre": 0.801760369921, "more": 0.034049863199999995, "stay": 0.9927416990379999, "suggest": 1.127405221754, "three": 0.06411868822490001, "lot": 1.4835969502500002, "some": 0.11872052719350001, "sourc": 0.529218310751, "small": 0.307101805059, "control": 0.7699693231720001, "both": 0.050842533389300004, "third": 0.35032434942900004, "aris": 2.0214436382, "result": 0.8182734502860001, "off": 0.41352852038800003, "judgment": 2.3898026343, "produc": 0.314320812003, "guidelin": 2.60865985243, "use": 0.1168320789264, "set": 0.342992022578, "ethic": 21.904448903499997, "ani": 0.502433433464, "king": 0.707101485387, "philosoph": 5.19807671262, "from": 0.010206975039588, "account": 3.325371449865, "answer": 1.5366310419, "limit": 0.41782385463, "longitudin": 3.8406813366199994, "num": 0.0031499039539700006, "clash": 2.12137694661, "instanc": 1.18089357972, "idea": 0.73863592212, "free": 0.5412666492670001, "environ": 2.4683948060599996, "studi": 0.426470272221, "incred": 2.9029218370499996, "exclud": 1.67120878808, "for": 0.005354836721749001, "difficult": 0.912110767588, "match": 1.27190443874, "with": 0.01556739227407, "misbehavior": 6.0616459012599995, "competit": 1.12154907401, "judgement": 3.06456318861, "assum": 2.1687062705, "reset": 4.17950237056, "merg": 1.66453096693, "solut": 6.21385190508, "controversi": 0.9652462536299999, "compani": 0.879554506194, "effort": 0.637887211057, "month": 0.410770160338, "sens": 1.04257779501, "team": 0.821902894886, "look": 3.2319334680000003, "stock": 1.61265547932, "option": 1.39846181161, "passu": 7.2746685411000005, "woman": 1.2466091029200002, "chanc": 1.44572292349, "intern": 0.265095377816, "ago": 1.80163421715, "extern": 3.3131520057599997, "negat": 2.64805197704, "align": 6.277123187879999, "educ": 0.696807183384, "tell": 2.42472868802, "artifici": 4.23645798036, "disregard": 3.09053867501, "remov": 1.3920976831760001, "penal": 3.3446270301700003, "doe": 2.1361669188679997, "even": 0.45716569450200006, "underestim": 3.8146306594199997, "glanc": 3.8348333667400003, "give": 0.622785104448, "total": 0.8713577734100001, "side": 0.9386975337379999, "place": 0.0957070839572, "great": 0.235805258079, "deviat": 8.85703097631, "assumpt": 4.4426442578400005, "goal": 2.37661424546, "capac": 1.35284642705, "error": 5.395756302900001, "framework": 4.20836909214, "extrem": 2.583628751811, "his": 0.0901772433641, "ask": 0.776797209847, "type": 0.707101485387, "omnicomprehens": 7.2746685411000005, "invent": 1.52701418212, "switch": 1.60416085533, "matter": 2.685487581108, "accept": 0.552585882007, "thing": 2.63458060404, "analyz": 2.2707222351599996, "scientist": 1.54634128444, "machin": 19.49303412868, "into": 0.0745643161435, "medic": 1.18644857806, "bias": 81.21512570477, "extinct": 2.6120874479, "notr": 3.52409551799, "hasn": 7.2746685411000005, "justifi": 2.02525498155, "cultur": 0.620984734312, "where": 0.1299842774914, "doctor": 5.48416863584, "bubbl": 3.13877497597, "face": 0.589602371257, "spit": 3.9424640309300005, "implicit": 3.0538248303900004, "let": 12.4880256728, "spontan": 2.7839913543400003, "head": 0.456042582852, "help": 0.336207721344, "believ": 0.995493995992, "find": 1.095562660576, "point": 0.46206471806599997, "francesco": 3.4440528103099997, "instead": 0.46663315041500003, "line": 0.698861228904, "brain": 8.75727759132, "tempor": 3.08639215905, "least": 1.440856754235, "base": 0.13652330228700002, "natur": 0.862612678584, "deal": 0.780914701253, "fact": 1.1005798415899999, "pari": 1.33713233602, "decid": 3.931937231358, "univers": 0.222262105686, "compromis": 2.02049306779, "hold": 1.511637351588, "payoff": 10.3015504737, "here": 3.5401527534800006, "camera": 2.1960914327400003, "report": 0.31001750903700004, "shortcut": 9.6885001532, "pursu": 1.4240346891, "clean": 1.9271282036300001, "decisionmak": 7.18765716411, "paramet": 2.8481901438599997, "human": 8.320457382159, "liabil": 13.20380786668, "much": 0.35499145860200004, "evalu": 1.9388802431299998, "than": 0.0322608622182, "care": 0.9139943029109999, "about": 0.8169652071698001, "norm": 2.4247712321400003, "run": 0.442714975539, "say": 1.124308561104, "diakopoulo": 7.2746685411000005, "mind": 1.2786688388299998, "discourag": 2.52421807, "narrat": 1.7921374696099999, "just": 0.289531434109, "perspect": 1.61645415436, "adapt": 1.2007864860200002, "understand": 3.264257627039999, "won": 1.6808278158, "speci": 5.68305701817, "price": 1.24814402264, "him": 0.49124039099699995, "simpli": 5.543648949516, "statement": 1.2303097091500002, "systemat": 2.12085159855, "would": 0.3980881398235, "them": 0.3767333076372, "defin": 1.00368010925, "perceiv": 1.5938755846700001, "recommend": 2.72922253726, "term": 0.6660779670920001, "friedler": 7.2746685411000005, "train": 0.660918312839, "save": 3.10796659641, "tool": 1.60887117963, "start": 0.945773477164, "phloxiishutterstock": 7.2746685411000005, "power": 0.292396282715, "noth": 1.24245472939, "articl": 0.702131739574, "guid": 0.912738218589, "catastroph": 2.8025104021, "simpl": 3.66966386817, "trust": 4.7649291228, "bad": 3.6664549685399996, "energi": 1.29901007269, "explain": 1.911400854716, "speak": 2.12339629324, "singl": 0.951833538118, "lose": 1.1265888210600001, "central": 0.477540146039, "health": 0.9990508682320001, "abl": 1.19860796495, "tune": 2.3434700776599997, "mani": 0.0866315162442, "diseas": 4.95293784135, "over": 0.0748101644871, "theoret": 2.05874512909, "perhap": 2.29361478366, "build": 0.982274904182, "analysi": 1.2466091029200002, "mida": 5.61212080336, "liabl": 10.9986319629, "provid": 0.39035568865000003, "wrote": 0.744188554049, "sorell": 7.2746685411000005, "pattern": 1.33282404788, "one": 0.0187660549365, "unfortun": 2.29918950399, "same": 0.5602982480200001, "there": 0.2004894646275, "connect": 0.633605058682, "stick": 2.4456277954099996, "fallaci": 4.17950237056, "possibl": 1.0464164246730001, "industri": 0.7046772417749999, "frame": 1.8373800586400002, "delic": 3.2992440243299996, "exampl": 0.40868267499899996, "big": 1.00798563557, "crimin": 1.6840208311700002, "pure": 4.6532503174499995, "think": 9.604589505749999, "enterpris": 1.8585681389, "again": 1.645360926448, "visual": 1.6539383488600001, "follow": 0.2721414665652, "block": 1.16400781588, "tri": 0.61759152916, "then": 0.7473047870780999, "advers": 2.6461370052, "hard": 4.02091185624, "usual": 0.545279017064, "interact": 1.4858210267899998, "desir": 1.0991793428399999, "irrat": 4.02007463363, "basic": 2.0087354979, "benchmark": 3.9489787119499997, "realli": 3.1152816794, "abil": 0.996488297427, "feel": 4.5713973677199995, "algorithmsassist": 7.2746685411000005, "also": 0.0879429468, "specifi": 1.93451151621, "person": 0.6803656320360001, "around": 0.19387710578200001, "mean": 0.37092128352, "race": 1.07508179126, "treatment": 2.7071553770200003, "task": 1.35748680661, "system": 2.292012419095, "phenomena": 2.8045894049299998, "therefor": 3.390367393344, "the": 0.0, "becom": 0.47084870595600004, "probabl": 1.945764825826, "past": 1.4032468315220001, "peopl": 0.579796735419, "angl": 2.18988198575, "open": 0.439182076058, "those": 1.2498457361109998, "want": 2.0749098187649997, "someon": 1.59635928666, "talk": 2.21735578898, "strategist": 4.01657200308, "argument": 3.25587506828, "individu": 0.588013447985, "evolutionari": 3.0524906073699998, "howev": 0.0903151173475, "kill": 0.741540598047, "pedestrian": 9.66154457841, "cognit": 9.1977408831, "smartphon": 4.34955383476, "work": 0.109034567273, "could": 0.7438250891600001, "maxim": 2.5594217052, "were": 0.024291143681099997, "which": 0.036248896918010004, "databas": 2.10988256718, "random": 3.9454428130199997, "weak": 1.5487095508000002, "relev": 1.9371304613999998, "activ": 1.143589809852, "estim": 0.854377535975, "other": 0.0493737395988, "appli": 0.8316941898119999, "myself": 2.67771382807, "consist": 0.398873126426, "known": 0.0824180805992, "impact": 2.18066445262, "hope": 0.919824304455, "begin": 0.285584668268, "rais": 1.3595155089520001, "see": 0.722764756476, "becaus": 0.83605895295, "imag": 3.97504842916, "trap": 2.00915614901, "nichola": 4.38652835224, "mayb": 6.094342891779999, "get": 4.638152046256, "like": 0.27810715309, "implement": 1.27437940907, "abov": 0.643865229816, "sensor": 3.36264553568, "should": 5.09419876758, "technolog": 2.8705430590649996, "except": 0.54202451213, "autonom": 7.217209399139999, "kris": 4.2129782997600005, "mitig": 3.1272141535699998, "undesir": 3.4460271446199995, "recent": 0.434413741288, "requir": 1.272760532025, "anyon": 1.68164835081, "straightforward": 3.3234248225200003, "access": 0.627805882716, "this": 0.06058318484, "choic": 1.14166497543, "principl": 6.194848231800001, "instant": 2.4427250357499997, "time": 0.056057594313, "through": 0.1367173837698, "engin": 2.7143026748279997, "back": 0.23166743089699998, "chang": 0.49882687517400004, "scifi": 7.1076144564399995, "differ": 1.486247849184, "embed": 2.82349753127, "but": 0.4695787900851, "institut": 0.576176322003, "statist": 1.4451883070700002, "decis": 2.310324665088, "malfunct": 3.73239256118, "most": 0.12448737777359999, "between": 0.13581472466119998, "what": 3.614196749232, "who": 0.3654013979154, "credit": 4.45154404352, "overconfid": 5.3958976948899995, "all": 0.11402632097799999, "everyon": 1.8557438481400002, "busi": 1.44095234071, "action": 0.598043165069, "behaviour": 2.29043944817, "reason": 3.265809317772, "someth": 4.75322849092, "unlucki": 5.18392744417, "former": 0.308301359655, "degre": 0.910387304568, "case": 2.767843882223, "hammond": 3.6861118086199998, "that": 0.13916519328739999, "garbag": 7.56737171114, "call": 0.0654627744488, "revis": 1.4635275481299999, "blur": 3.39216797494, "futur": 0.619345197699, "and": 0.0045352902285792, "year": 0.09480447778920001, "discuss": 0.78698452262, "achiev": 1.2541961702339999, "greatest": 1.10107184908, "life": 0.315183699277, "oonum": 7.2746685411000005, "worst": 1.89519021125, "general": 0.114952578063, "made": 0.0680215260973, "expect": 1.57701550432, "emerg": 0.748173681534, "question": 3.161243716056, "comment": 1.11826753454, "doubt": 1.67020426765, "corea": 6.117215752409999, "wors": 2.26040347896, "standard": 0.63741050982, "can": 0.487023289182, "comput": 2.73613783188, "make": 0.36748828911449993, "way": 0.9904575496750001, "now": 0.44727883506300004, "onli": 0.0759728049873, "hothand": 7.2746685411000005, "circumst": 1.66519674592, "clear": 1.234949454396, "diagnos": 2.7901263429100003, "tackl": 2.98920286814, "utilitarian": 4.20029314023, "necessari": 1.0445450673999999, "accur": 3.5049612297, "emb": 5.22991255741, "remain": 0.30712592618, "common": 0.338325805271, "chain": 1.64410864979, "maryland": 2.5124946063099998, "data": 14.6018470176, "threefold": 4.56057602555, "guy": 4.07548627232, "perfect": 1.50096433356, "rather": 2.213574877695, "whether": 0.791561189647, "best": 0.459227932947, "sometim": 0.538025155343, "come": 1.7034594391800002, "might": 6.915069688806001, "learn": 3.37100825898, "right": 4.08431825004, "identifi": 2.5011660014159998, "import": 0.292818277066, "first": 0.02276186943648, "proceed": 1.23354840355, "input": 2.50167533539, "extent": 1.40974687623, "have": 0.1922050304356, "rate": 0.761033872166, "unforeseen": 4.7897618913199995, "without": 0.258874517941, "whi": 3.54206529141, "mcmurryjuliepixabay": 7.2746685411000005, "down": 0.306673741186, "inde": 2.9772161932, "own": 0.328390154842, "when": 0.0205549888584, "parti": 0.724497710444}, "logidf": {"hand": 0.479471335336, "real": 0.824629060574, "plastic": 2.40086010702, "audit": 2.71601837075, "gut": 3.56554092616, "implic": 2.03244064121, "patient": 2.25618533471, "too": 0.5965551547219999, "shouldn": 7.2746685411000005, "take": 0.130691962197, "built": 0.690379535065, "five": 0.320203181906, "form": 0.120053184191, "weakwil": 7.2746685411000005, "new": 0.0177299468511, "assign": 1.3445959556, "viabl": 2.7839913543400003, "conflict": 0.987824351275, "organ": 0.49392052866999997, "veri": 0.230159793238, "heurist": 4.74531012875, "lucki": 3.1788099740499995, "number": 0.0966085784186, "previous": 0.356602960063, "been": 0.023645982368400004, "etc": 1.4366730879700003, "dataset": 5.26584456664, "andruxevichshutterstock": 7.2746685411000005, "exant": 7.2746685411000005, "pregnant": 2.8004357125599997, "enter": 0.564256167492, "draw": 1.0893956335600001, "assist": 0.776112606548, "log": 2.61552683221, "driver": 1.9167966438, "thought": 0.685867118283, "unexpect": 2.2910619194, "well": 0.0635144383156, "product": 0.484060136536, "done": 0.845975983129, "never": 0.443205436091, "creation": 1.11846026847, "complet": 0.215285242047, "technic": 1.14423287808, "vehicl": 1.54604564512, "stream": 1.8736305038599999, "know": 0.952919694398, "psycholog": 1.89981109743, "out": 0.0584263909193, "advic": 1.9574402102700001, "legal": 0.955536640608, "thoma": 0.874109117838, "translat": 1.0499301100299998, "measur": 0.880014199726, "ever": 0.6778949784020001, "creat": 0.222576818514, "multipl": 1.01092401812, "probe": 2.93086311925, "how": 0.47156695693000006, "billion": 1.5824680307199999, "fair": 1.16481508131, "inconsist": 2.6667747946500002, "discrimin": 2.37006739018, "quit": 1.05951513684, "stimul": 2.41556110681, "hundr": 0.904145087046, "end": 0.101476798618, "die": 0.510049071409, "word": 0.585861082385, "rabbithol": 7.2746685411000005, "heterogen": 3.9522520373, "guarante": 1.8826952548500002, "deep": 1.2886734698, "depend": 0.806969815, "will": 0.202786534915, "true": 0.938325629634, "scenario": 2.73427932989, "datadriven": 7.2746685411000005, "consid": 0.214894723824, "contact": 1.16926672768, "excursus": 7.2746685411000005, "purpos": 0.803869037322, "incorpor": 0.9664045229739999, "dame": 2.92615168533, "lag": 3.5071459596699994, "similar": 0.318556092114, "healthcar": 2.9320444543, "inherit": 1.87076341199, "certain": 0.592104362781, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "sure": 2.0086865552, "final": 0.292733863948, "trolley": 4.04494270021, "issu": 0.364099043934, "entail": 3.0564986287700004, "dietvorst": 7.2746685411000005, "record": 0.353010356953, "applic": 1.23160392849, "review": 0.7929522039210001, "prevent": 0.7706525875229999, "level": 0.503462189943, "robot": 2.99674059227, "has": 0.0427239448548, "enough": 0.802884439169, "object": 0.853933584803, "ration": 2.26342736998, "advantag": 1.20120515883, "termin": 1.5818550978200001, "experi": 0.626272953933, "famous": 0.825060187979, "sound": 1.13556799519, "conspir": 3.14022952168, "instinct": 3.2656838278299998, "model": 0.7374500731110001, "onlin": 0.957503854357, "economist": 2.3467563113099996, "good": 0.418589404907, "risk": 1.4100048408899999, "rephras": 6.27136643224, "admit": 1.39388165093, "under": 0.07526180538319999, "cours": 0.765899404133, "tradit": 0.47500477629199994, "count": 1.24748591139, "field": 0.5760642583510001, "situat": 0.725668290015, "global": 1.1957760371200001, "tire": 2.52657934619, "unanim": 2.5416649836099996, "process": 0.527829199025, "not": 0.0155524130075, "strong": 0.49712549393600003, "asilomar": 7.2746685411000005, "recogn": 0.935913859031, "view": 0.49515994217299997, "are": 0.0294674735827, "such": 0.059695977806, "less": 0.3846144626, "aim": 1.06333853704, "stori": 0.705059626587, "specif": 0.626980167541, "quick": 0.790727508899, "easi": 1.6665296351499999, "philbeck": 7.2746685411000005, "solv": 1.9836504770400003, "though": 0.308044191079, "problem": 0.569140724273, "complic": 1.7312682430000002, "they": 0.0297269947676, "design": 0.377239118022, "anoth": 0.127896361652, "core": 1.53108277245, "reach": 0.40414323085000003, "consult": 1.6519646640099999, "effect": 0.333830227158, "allow": 0.24028061118900002, "scienc": 0.841436178891, "outcom": 2.01339244624, "opposit": 0.90274594185, "eye": 1.22193786676, "section": 0.755387177948, "construct": 0.658603355972, "feasibl": 2.88021938643, "stem": 2.0086865552, "behavior": 1.71014813378, "heartless": 5.721320095319999, "davi": 1.6513076337600001, "practic": 0.533182530867, "respons": 0.40991566230300003, "lack": 0.656050938907, "alreadi": 0.670478380747, "itself": 0.5570837229510001, "algorithm": 3.33044239518, "valu": 0.823193310148, "two": 0.0136988443582, "either": 0.459327638815, "develop": 0.178624694913, "len": 3.03268798008, "discriminatori": 3.98220435958, "observ": 0.7995160149320001, "accuraci": 2.5464765406, "conscious": 2.09237439596, "agre": 0.801760369921, "more": 0.017024931599999998, "stay": 0.9927416990379999, "suggest": 0.563702610877, "three": 0.06411868822490001, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "small": 0.307101805059, "control": 0.38498466158600003, "both": 0.050842533389300004, "third": 0.35032434942900004, "aris": 2.0214436382, "result": 0.136378908381, "off": 0.41352852038800003, "judgment": 2.3898026343, "produc": 0.314320812003, "guidelin": 2.60865985243, "use": 0.0292080197316, "set": 0.171496011289, "ethic": 2.19044489035, "ani": 0.125608358366, "king": 0.707101485387, "philosoph": 1.73269223754, "from": 0.000567054168866, "account": 0.665074289973, "answer": 1.5366310419, "limit": 0.41782385463, "longitudin": 3.8406813366199994, "num": 0.00031499039539700004, "clash": 2.12137694661, "instanc": 1.18089357972, "idea": 0.73863592212, "free": 0.5412666492670001, "environ": 1.2341974030299998, "studi": 0.426470272221, "incred": 2.9029218370499996, "exclud": 1.67120878808, "for": 0.00031499039539700004, "difficult": 0.912110767588, "match": 1.27190443874, "with": 0.00119749171339, "misbehavior": 6.0616459012599995, "competit": 1.12154907401, "judgement": 3.06456318861, "assum": 1.08435313525, "reset": 4.17950237056, "merg": 1.66453096693, "solut": 1.55346297627, "controversi": 0.9652462536299999, "compani": 0.439777253097, "effort": 0.637887211057, "month": 0.410770160338, "sens": 1.04257779501, "team": 0.821902894886, "look": 0.6463866936, "stock": 1.61265547932, "option": 1.39846181161, "passu": 7.2746685411000005, "woman": 1.2466091029200002, "chanc": 1.44572292349, "intern": 0.265095377816, "ago": 1.80163421715, "extern": 1.6565760028799998, "negat": 1.32402598852, "align": 2.09237439596, "educ": 0.696807183384, "tell": 1.21236434401, "artifici": 2.11822899018, "disregard": 3.09053867501, "remov": 0.6960488415880001, "penal": 3.3446270301700003, "doe": 0.5340417297169999, "even": 0.152388564834, "underestim": 3.8146306594199997, "glanc": 3.8348333667400003, "give": 0.311392552224, "total": 0.43567888670500005, "side": 0.46934876686899996, "place": 0.0957070839572, "great": 0.235805258079, "deviat": 2.9523436587700003, "assumpt": 2.2213221289200002, "goal": 1.18830712273, "capac": 1.35284642705, "error": 1.7985854343, "framework": 2.10418454607, "extrem": 0.8612095839370001, "his": 0.0901772433641, "ask": 0.776797209847, "type": 0.707101485387, "omnicomprehens": 7.2746685411000005, "invent": 1.52701418212, "switch": 1.60416085533, "matter": 0.8951625270360001, "accept": 0.552585882007, "thing": 0.8781935346799999, "analyz": 2.2707222351599996, "scientist": 1.54634128444, "machin": 1.39235958062, "into": 0.0149128632287, "medic": 1.18644857806, "bias": 2.61984276467, "extinct": 2.6120874479, "notr": 3.52409551799, "hasn": 7.2746685411000005, "justifi": 2.02525498155, "cultur": 0.620984734312, "where": 0.0649921387457, "doctor": 1.37104215896, "bubbl": 3.13877497597, "face": 0.589602371257, "spit": 3.9424640309300005, "implicit": 3.0538248303900004, "let": 1.2488025672799998, "spontan": 2.7839913543400003, "head": 0.456042582852, "help": 0.336207721344, "believ": 0.497746997996, "find": 0.547781330288, "point": 0.23103235903299998, "francesco": 3.4440528103099997, "instead": 0.46663315041500003, "line": 0.349430614452, "brain": 2.18931939783, "tempor": 3.08639215905, "least": 0.480285584745, "base": 0.13652330228700002, "natur": 0.431306339292, "deal": 0.780914701253, "fact": 0.5502899207949999, "pari": 1.33713233602, "decid": 0.655322871893, "univers": 0.222262105686, "compromis": 2.02049306779, "hold": 0.503879117196, "payoff": 5.15077523685, "here": 0.8850381883700001, "camera": 2.1960914327400003, "report": 0.31001750903700004, "shortcut": 4.8442500766, "pursu": 1.4240346891, "clean": 1.9271282036300001, "decisionmak": 7.18765716411, "paramet": 2.8481901438599997, "human": 0.640035183243, "liabil": 3.30095196667, "much": 0.17749572930100002, "evalu": 1.9388802431299998, "than": 0.0322608622182, "care": 0.9139943029109999, "about": 0.0628434774746, "norm": 2.4247712321400003, "run": 0.442714975539, "say": 0.562154280552, "diakopoulo": 7.2746685411000005, "mind": 1.2786688388299998, "discourag": 2.52421807, "narrat": 1.7921374696099999, "just": 0.289531434109, "perspect": 1.61645415436, "adapt": 1.2007864860200002, "understand": 1.0880858756799998, "won": 0.8404139079, "speci": 1.8943523393900001, "price": 1.24814402264, "him": 0.49124039099699995, "simpli": 0.923941491586, "statement": 1.2303097091500002, "systemat": 2.12085159855, "would": 0.0796176279647, "them": 0.0941833269093, "defin": 1.00368010925, "perceiv": 1.5938755846700001, "recommend": 1.36461126863, "term": 0.33303898354600003, "friedler": 7.2746685411000005, "train": 0.660918312839, "save": 1.03598886547, "tool": 1.60887117963, "start": 0.236443369291, "phloxiishutterstock": 7.2746685411000005, "power": 0.292396282715, "noth": 1.24245472939, "articl": 0.702131739574, "guid": 0.912738218589, "catastroph": 2.8025104021, "simpl": 1.2232212893899999, "trust": 1.5883097076, "bad": 1.2221516561799999, "energi": 1.29901007269, "explain": 0.955700427358, "speak": 1.06169814662, "singl": 0.475916769059, "lose": 1.1265888210600001, "central": 0.477540146039, "health": 0.9990508682320001, "abl": 0.599303982475, "tune": 2.3434700776599997, "mani": 0.0433157581221, "diseas": 1.6509792804499999, "over": 0.0249367214957, "theoret": 2.05874512909, "perhap": 1.14680739183, "build": 0.491137452091, "analysi": 1.2466091029200002, "mida": 5.61212080336, "liabl": 3.6662106543, "provid": 0.19517784432500002, "wrote": 0.744188554049, "sorell": 7.2746685411000005, "pattern": 1.33282404788, "one": 0.0062553516455, "unfortun": 2.29918950399, "same": 0.112059649604, "there": 0.0400978929255, "connect": 0.633605058682, "stick": 2.4456277954099996, "fallaci": 4.17950237056, "possibl": 0.348805474891, "industri": 0.7046772417749999, "frame": 1.8373800586400002, "delic": 3.2992440243299996, "exampl": 0.40868267499899996, "big": 1.00798563557, "crimin": 1.6840208311700002, "pure": 1.55108343915, "think": 1.06717661175, "enterpris": 1.8585681389, "again": 0.411340231612, "visual": 1.6539383488600001, "follow": 0.045356911094199995, "block": 1.16400781588, "tri": 0.61759152916, "then": 0.08303386523089999, "advers": 2.6461370052, "hard": 1.00522796406, "usual": 0.545279017064, "interact": 1.4858210267899998, "desir": 1.0991793428399999, "irrat": 4.02007463363, "basic": 1.00436774895, "benchmark": 3.9489787119499997, "realli": 1.5576408397, "abil": 0.996488297427, "feel": 1.1428493419299999, "algorithmsassist": 7.2746685411000005, "also": 0.0146571578, "specifi": 1.93451151621, "person": 0.34018281601800004, "around": 0.19387710578200001, "mean": 0.37092128352, "race": 1.07508179126, "treatment": 1.3535776885100002, "task": 1.35748680661, "system": 0.327430345585, "phenomena": 2.8045894049299998, "therefor": 0.847591848336, "the": 0.0, "becom": 0.11771217648900001, "probabl": 0.972882412913, "past": 0.7016234157610001, "peopl": 0.193265578473, "angl": 2.18988198575, "open": 0.219591038029, "those": 0.17854939087299998, "want": 0.6916366062549999, "someon": 1.59635928666, "talk": 1.10867789449, "strategist": 4.01657200308, "argument": 1.62793753414, "individu": 0.588013447985, "evolutionari": 3.0524906073699998, "howev": 0.0903151173475, "kill": 0.741540598047, "pedestrian": 3.22051485947, "cognit": 3.0659136276999996, "smartphon": 4.34955383476, "work": 0.109034567273, "could": 0.18595627229000003, "maxim": 2.5594217052, "were": 0.024291143681099997, "which": 0.00517841384543, "databas": 2.10988256718, "random": 1.9727214065099998, "weak": 1.5487095508000002, "relev": 1.9371304613999998, "activ": 0.381196603284, "estim": 0.854377535975, "other": 0.00987474791976, "appli": 0.8316941898119999, "myself": 2.67771382807, "consist": 0.398873126426, "known": 0.0824180805992, "impact": 1.09033222631, "hope": 0.919824304455, "begin": 0.285584668268, "rais": 0.6797577544760001, "see": 0.240921585492, "becaus": 0.139343158825, "imag": 0.99376210729, "trap": 2.00915614901, "nichola": 2.19326417612, "mayb": 3.0471714458899997, "get": 0.579769005782, "like": 0.139053576545, "implement": 1.27437940907, "abov": 0.643865229816, "sensor": 3.36264553568, "should": 0.509419876758, "technolog": 0.956847686355, "except": 0.54202451213, "autonom": 2.4057364663799996, "kris": 4.2129782997600005, "mitig": 3.1272141535699998, "undesir": 3.4460271446199995, "recent": 0.434413741288, "requir": 0.424253510675, "anyon": 1.68164835081, "straightforward": 3.3234248225200003, "access": 0.627805882716, "this": 0.0037864490525, "choic": 1.14166497543, "principl": 1.2389696463600002, "instant": 2.4427250357499997, "time": 0.0112115188626, "through": 0.0683586918849, "engin": 0.904767558276, "back": 0.23166743089699998, "chang": 0.166275625058, "scifi": 7.1076144564399995, "differ": 0.212321121312, "embed": 2.82349753127, "but": 0.0161923720719, "institut": 0.576176322003, "statist": 1.4451883070700002, "decis": 0.7701082216959999, "malfunct": 3.73239256118, "most": 0.020747896295599998, "between": 0.033953681165299995, "what": 0.225887296827, "who": 0.0609002329859, "credit": 1.11288601088, "overconfid": 5.3958976948899995, "all": 0.011402632097799998, "everyon": 1.8557438481400002, "busi": 0.720476170355, "action": 0.598043165069, "behaviour": 2.29043944817, "reason": 0.544301552962, "someth": 1.18830712273, "unlucki": 5.18392744417, "former": 0.308301359655, "degre": 0.910387304568, "case": 0.395406268889, "hammond": 3.6861118086199998, "that": 0.00397614837964, "garbag": 3.78368585557, "call": 0.0654627744488, "revis": 1.4635275481299999, "blur": 3.39216797494, "futur": 0.619345197699, "and": 6.29901420636e-05, "year": 0.047402238894600005, "discuss": 0.78698452262, "achiev": 0.6270980851169999, "greatest": 1.10107184908, "life": 0.315183699277, "oonum": 7.2746685411000005, "worst": 1.89519021125, "general": 0.114952578063, "made": 0.0680215260973, "expect": 0.78850775216, "emerg": 0.748173681534, "question": 0.790310929014, "comment": 1.11826753454, "doubt": 1.67020426765, "corea": 6.117215752409999, "wors": 2.26040347896, "standard": 0.63741050982, "can": 0.162341096394, "comput": 1.36806891594, "make": 0.07349765782289999, "way": 0.19809150993500002, "now": 0.149092945021, "onli": 0.025324268329099998, "hothand": 7.2746685411000005, "circumst": 1.66519674592, "clear": 0.617474727198, "diagnos": 2.7901263429100003, "tackl": 2.98920286814, "utilitarian": 4.20029314023, "necessari": 1.0445450673999999, "accur": 1.75248061485, "emb": 5.22991255741, "remain": 0.15356296309, "common": 0.338325805271, "chain": 1.64410864979, "maryland": 2.5124946063099998, "data": 1.2168205848, "threefold": 4.56057602555, "guy": 2.03774313616, "perfect": 1.50096433356, "rather": 0.442714975539, "whether": 0.791561189647, "best": 0.459227932947, "sometim": 0.538025155343, "come": 0.28390990653000003, "might": 0.7683410765340001, "learn": 0.842752064745, "right": 0.34035985417, "identifi": 0.833722000472, "import": 0.292818277066, "first": 0.0075872898121599995, "proceed": 1.23354840355, "input": 2.50167533539, "extent": 1.40974687623, "have": 0.0147850023412, "rate": 0.761033872166, "unforeseen": 4.7897618913199995, "without": 0.258874517941, "whi": 1.18068843047, "mcmurryjuliepixabay": 7.2746685411000005, "down": 0.306673741186, "inde": 1.4886080966, "own": 0.164195077421, "when": 0.0205549888584, "parti": 0.724497710444}, "freq": {"hand": 1, "real": 2, "plastic": 1, "audit": 1, "gut": 2, "implic": 1, "patient": 7, "too": 1, "shouldn": 1, "take": 1, "built": 1, "five": 4, "form": 1, "weakwil": 1, "new": 1, "assign": 1, "viabl": 1, "conflict": 2, "organ": 1, "veri": 1, "heurist": 1, "lucki": 1, "number": 2, "previous": 2, "been": 4, "etc": 1, "dataset": 1, "andruxevichshutterstock": 1, "exant": 2, "pregnant": 1, "enter": 1, "draw": 1, "assist": 3, "log": 1, "driver": 2, "thought": 1, "unexpect": 1, "well": 5, "product": 1, "done": 1, "never": 1, "creation": 1, "complet": 3, "technic": 1, "vehicl": 2, "stream": 1, "know": 7, "psycholog": 1, "out": 7, "advic": 4, "legal": 1, "thoma": 1, "translat": 1, "measur": 1, "ever": 1, "creat": 1, "multipl": 1, "probe": 1, "how": 6, "billion": 1, "fair": 1, "inconsist": 1, "discrimin": 1, "quit": 2, "stimul": 1, "hundr": 1, "end": 6, "die": 3, "word": 4, "rabbithol": 1, "heterogen": 1, "guarante": 3, "deep": 1, "depend": 1, "will": 6, "true": 4, "scenario": 8, "datadriven": 1, "consid": 3, "contact": 1, "excursus": 1, "purpos": 2, "incorpor": 1, "dame": 1, "lag": 1, "similar": 2, "healthcar": 1, "inherit": 1, "certain": 3, "need": 5, "our": 13, "classif": 1, "sure": 1, "final": 3, "trolley": 1, "issu": 4, "entail": 1, "dietvorst": 1, "record": 2, "applic": 3, "review": 1, "prevent": 3, "level": 1, "robot": 1, "has": 3, "enough": 1, "object": 3, "ration": 1, "advantag": 2, "termin": 1, "experi": 1, "famous": 1, "sound": 2, "conspir": 1, "instinct": 1, "model": 1, "onlin": 1, "economist": 2, "good": 4, "risk": 1, "rephras": 1, "admit": 1, "under": 3, "cours": 5, "tradit": 1, "count": 1, "field": 1, "situat": 1, "global": 1, "tire": 1, "unanim": 1, "process": 2, "not": 29, "strong": 1, "asilomar": 1, "recogn": 2, "view": 1, "are": 14, "such": 1, "less": 1, "aim": 1, "stori": 1, "specif": 3, "quick": 1, "easi": 2, "philbeck": 1, "solv": 1, "though": 1, "problem": 12, "complic": 1, "they": 3, "design": 7, "anoth": 3, "core": 1, "reach": 1, "consult": 1, "effect": 1, "allow": 3, "scienc": 1, "outcom": 3, "opposit": 1, "eye": 1, "section": 1, "construct": 1, "feasibl": 1, "stem": 1, "behavior": 3, "heartless": 1, "davi": 1, "practic": 1, "respons": 5, "lack": 1, "alreadi": 1, "itself": 3, "algorithm": 13, "valu": 7, "two": 3, "either": 1, "develop": 2, "len": 2, "discriminatori": 1, "observ": 2, "accuraci": 2, "conscious": 1, "agre": 1, "more": 2, "stay": 1, "suggest": 2, "three": 1, "lot": 1, "some": 3, "sourc": 1, "small": 1, "control": 2, "both": 1, "third": 1, "aris": 1, "result": 6, "off": 1, "judgment": 1, "produc": 1, "guidelin": 1, "use": 4, "set": 2, "ethic": 10, "ani": 4, "king": 1, "philosoph": 3, "from": 18, "account": 5, "answer": 1, "limit": 1, "longitudin": 1, "num": 10, "clash": 1, "instanc": 1, "idea": 1, "free": 1, "environ": 2, "studi": 1, "incred": 1, "exclud": 1, "for": 17, "difficult": 1, "match": 1, "with": 13, "misbehavior": 1, "competit": 1, "judgement": 1, "assum": 2, "reset": 1, "merg": 1, "solut": 4, "controversi": 1, "compani": 2, "effort": 1, "month": 1, "sens": 1, "team": 1, "look": 5, "stock": 1, "option": 1, "passu": 1, "woman": 1, "chanc": 1, "intern": 1, "ago": 1, "extern": 2, "negat": 2, "align": 3, "educ": 1, "tell": 2, "artifici": 2, "disregard": 1, "remov": 2, "penal": 1, "doe": 4, "even": 3, "underestim": 1, "glanc": 1, "give": 2, "total": 2, "side": 2, "place": 1, "great": 1, "deviat": 3, "assumpt": 2, "goal": 2, "capac": 1, "error": 3, "framework": 2, "extrem": 3, "his": 1, "ask": 1, "type": 1, "omnicomprehens": 1, "invent": 1, "switch": 1, "matter": 3, "accept": 1, "thing": 3, "analyz": 1, "scientist": 1, "machin": 14, "into": 5, "medic": 1, "bias": 31, "extinct": 1, "notr": 1, "hasn": 1, "justifi": 1, "cultur": 1, "where": 2, "doctor": 4, "bubbl": 1, "face": 1, "spit": 1, "implicit": 1, "let": 10, "spontan": 1, "head": 1, "help": 1, "believ": 2, "find": 2, "point": 2, "francesco": 1, "instead": 1, "line": 2, "brain": 4, "tempor": 1, "least": 3, "base": 1, "natur": 2, "deal": 1, "fact": 2, "pari": 1, "decid": 6, "univers": 1, "compromis": 1, "hold": 3, "payoff": 2, "here": 4, "camera": 1, "report": 1, "shortcut": 2, "pursu": 1, "clean": 1, "decisionmak": 1, "paramet": 1, "human": 13, "liabil": 4, "much": 2, "evalu": 1, "than": 1, "care": 1, "about": 13, "norm": 1, "run": 1, "say": 2, "diakopoulo": 1, "mind": 1, "discourag": 1, "narrat": 1, "just": 1, "perspect": 1, "adapt": 1, "understand": 3, "won": 2, "speci": 3, "price": 1, "him": 1, "simpli": 6, "statement": 1, "systemat": 1, "would": 5, "them": 4, "defin": 1, "perceiv": 1, "recommend": 2, "term": 2, "friedler": 1, "train": 1, "save": 3, "tool": 1, "start": 4, "phloxiishutterstock": 1, "power": 1, "noth": 1, "articl": 1, "guid": 1, "catastroph": 1, "simpl": 3, "trust": 3, "bad": 3, "energi": 1, "explain": 2, "speak": 2, "singl": 2, "lose": 1, "central": 1, "health": 1, "abl": 2, "tune": 1, "mani": 2, "diseas": 3, "over": 3, "theoret": 1, "perhap": 2, "build": 2, "analysi": 1, "mida": 1, "liabl": 3, "provid": 2, "wrote": 1, "sorell": 1, "pattern": 1, "one": 3, "unfortun": 1, "same": 5, "there": 5, "connect": 1, "stick": 1, "fallaci": 1, "possibl": 3, "industri": 1, "frame": 1, "delic": 1, "exampl": 1, "big": 1, "crimin": 1, "pure": 3, "think": 9, "enterpris": 1, "again": 4, "visual": 1, "follow": 6, "block": 1, "tri": 1, "then": 9, "advers": 1, "hard": 4, "usual": 1, "interact": 1, "desir": 1, "irrat": 1, "basic": 2, "benchmark": 1, "realli": 2, "abil": 1, "feel": 4, "algorithmsassist": 1, "also": 6, "specifi": 1, "person": 2, "around": 1, "mean": 1, "race": 1, "treatment": 2, "task": 1, "system": 7, "phenomena": 1, "therefor": 4, "the": 131, "becom": 4, "probabl": 2, "past": 2, "peopl": 3, "angl": 1, "open": 2, "those": 7, "want": 3, "someon": 1, "talk": 2, "strategist": 1, "argument": 2, "individu": 1, "evolutionari": 1, "howev": 1, "kill": 1, "pedestrian": 3, "cognit": 3, "smartphon": 1, "work": 1, "could": 4, "maxim": 1, "were": 1, "which": 7, "databas": 1, "random": 2, "weak": 1, "relev": 1, "activ": 3, "estim": 1, "other": 5, "appli": 1, "myself": 1, "consist": 1, "known": 1, "impact": 2, "hope": 1, "begin": 1, "rais": 2, "see": 3, "becaus": 6, "imag": 4, "trap": 1, "nichola": 2, "mayb": 2, "get": 8, "like": 2, "implement": 1, "abov": 1, "sensor": 1, "should": 10, "technolog": 3, "except": 1, "autonom": 3, "kris": 1, "mitig": 1, "undesir": 1, "recent": 1, "requir": 3, "anyon": 1, "straightforward": 1, "access": 1, "this": 16, "choic": 1, "principl": 5, "instant": 1, "time": 5, "through": 2, "engin": 3, "back": 1, "chang": 3, "scifi": 1, "differ": 7, "embed": 1, "but": 29, "institut": 1, "statist": 1, "decis": 3, "malfunct": 1, "most": 6, "between": 4, "what": 16, "who": 6, "credit": 4, "overconfid": 1, "all": 10, "everyon": 1, "busi": 2, "action": 1, "behaviour": 1, "reason": 6, "someth": 4, "unlucki": 1, "former": 1, "degre": 1, "case": 7, "hammond": 1, "that": 35, "garbag": 2, "call": 1, "revis": 1, "blur": 1, "futur": 1, "and": 72, "year": 2, "discuss": 1, "achiev": 2, "greatest": 1, "life": 1, "oonum": 1, "worst": 1, "general": 1, "made": 1, "expect": 2, "emerg": 1, "question": 4, "comment": 1, "doubt": 1, "corea": 1, "wors": 1, "standard": 1, "can": 3, "comput": 2, "make": 5, "way": 5, "now": 3, "onli": 3, "hothand": 1, "circumst": 1, "clear": 2, "diagnos": 1, "tackl": 1, "utilitarian": 1, "necessari": 1, "accur": 2, "emb": 1, "remain": 2, "common": 1, "chain": 1, "maryland": 1, "data": 12, "threefold": 1, "guy": 2, "perfect": 1, "rather": 5, "whether": 1, "best": 1, "sometim": 1, "come": 6, "might": 9, "learn": 4, "right": 12, "identifi": 3, "import": 1, "first": 3, "proceed": 1, "input": 1, "extent": 1, "have": 13, "rate": 1, "unforeseen": 1, "without": 1, "whi": 3, "mcmurryjuliepixabay": 1, "down": 1, "inde": 2, "own": 2, "when": 1, "parti": 1}, "idf": {"hand": 1.6152202665600002, "real": 2.28103448276, "plastic": 11.0326615705, "audit": 15.12, "gut": 35.3585746102, "implic": 7.632692307689999, "patient": 9.54660252556, "too": 1.81585268215, "shouldn": 1443.27272727, "take": 1.13961668222, "built": 1.99447236181, "five": 1.37740760021, "form": 1.12755681818, "weakwil": 1443.27272727, "new": 1.0178880554, "assign": 3.83663605607, "viabl": 16.1834862385, "conflict": 2.6853856562900003, "organ": 1.6387283237, "veri": 1.25880114177, "heurist": 115.043478261, "lucki": 24.0181543116, "number": 1.10142916609, "previous": 1.42846859816, "been": 1.0239277652399998, "etc": 4.2066772655, "dataset": 193.609756098, "andruxevichshutterstock": 1443.27272727, "exant": 1443.27272727, "pregnant": 16.4518134715, "enter": 1.75813953488, "draw": 2.97247706422, "assist": 2.17300848618, "log": 13.6744186047, "driver": 6.79914346895, "thought": 1.9854927463699998, "unexpect": 9.88542963885, "well": 1.0655748708, "product": 1.62264922322, "done": 2.3302509907499998, "never": 1.55769230769, "creation": 3.0601387818, "complet": 1.24021560816, "technic": 3.1400316455699997, "vehicl": 4.6928761454300005, "stream": 6.5118949959000005, "know": 2.59327017315, "psycholog": 6.6846315789499995, "out": 1.06016694491, "advic": 7.08117752007, "legal": 2.6000655093400002, "thoma": 2.39673913043, "translat": 2.85745140389, "measur": 2.41093394077, "ever": 1.9697270471500001, "creat": 1.2492917847, "multipl": 2.74813917258, "probe": 18.7438016529, "how": 1.60250328051, "billion": 4.8669527897, "fair": 3.20533010297, "inconsist": 14.3934723481, "discrimin": 10.6981132075, "quit": 2.8849718335500003, "stimul": 11.1960507757, "hundr": 2.4698195395099996, "end": 1.10680423871, "die": 1.66537291514, "word": 1.7965372864099998, "rabbithol": 1443.27272727, "heterogen": 52.0524590164, "guarante": 6.57119205298, "deep": 3.6279707495399998, "depend": 2.2411067193700003, "will": 1.22481098596, "true": 2.55569864778, "scenario": 15.3986420951, "datadriven": 1443.27272727, "consid": 1.2397313759200002, "contact": 3.2196309065099995, "excursus": 1443.27272727, "purpos": 2.23416830847, "incorpor": 2.62847682119, "dame": 18.6556991774, "lag": 33.3529411765, "similar": 1.37514075357, "healthcar": 18.7659574468, "inherit": 6.4932515337400005, "certain": 1.8077886586200003, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "sure": 7.453521126760001, "final": 1.34008609775, "trolley": 57.1079136691, "issu": 1.43921675279, "entail": 21.2530120482, "dietvorst": 1443.27272727, "record": 1.42334588488, "applic": 3.42672134686, "review": 2.2099109131400003, "prevent": 2.16117615029, "level": 1.6544393497299998, "robot": 20.0201765448, "has": 1.0436497502, "enough": 2.2319696330700003, "object": 2.3488681757700003, "ration": 9.6159903089, "advantag": 3.32412060302, "termin": 4.86397058824, "experi": 1.87062566278, "famous": 2.28201811125, "sound": 3.11294117647, "conspir": 23.1091703057, "instinct": 26.198019801999997, "model": 2.0905978404, "onlin": 2.6051854282900004, "economist": 10.451612903200001, "good": 1.51981619759, "risk": 4.095975232200001, "rephras": 529.2, "admit": 4.03046458492, "under": 1.0781663837, "cours": 2.15092805853, "tradit": 1.60802187785, "count": 3.48157894737, "field": 1.7790228597, "situat": 2.06611140031, "global": 3.30612244898, "tire": 12.5106382979, "unanim": 12.7008, "process": 1.69524826482, "not": 1.01567398119, "strong": 1.6439888163999998, "asilomar": 1443.27272727, "recogn": 2.54954231572, "view": 1.6407606448899998, "are": 1.02990593578, "such": 1.06151377374, "less": 1.46904783936, "aim": 2.8960233491400005, "stori": 2.02396736359, "specif": 1.8719490626099997, "quick": 2.205, "easi": 5.2937645882, "philbeck": 1443.27272727, "solv": 7.26923076923, "though": 1.36076112111, "problem": 1.76674827509, "complic": 5.6478121664900005, "they": 1.03017325287, "design": 1.45825296225, "anoth": 1.13643521832, "core": 4.623179965059999, "reach": 1.49801849406, "consult": 5.21721984883, "effect": 1.3963060686000002, "allow": 1.2716059271100002, "scienc": 2.31969608416, "outcom": 7.48867924528, "opposit": 2.4663663197099996, "eye": 3.39375801625, "section": 2.1284354471099998, "construct": 1.9320920043799998, "feasibl": 17.8181818182, "stem": 7.453521126760001, "behavior": 5.52978056426, "heartless": 305.307692308, "davi": 5.2137931034500005, "practic": 1.70434782609, "respons": 1.5066907089300001, "lack": 1.9271667880599999, "alreadi": 1.9551724137900002, "itself": 1.74557449148, "algorithm": 27.9507042254, "valu": 2.2777618364400003, "two": 1.01379310345, "either": 1.5830092731099998, "develop": 1.1955719557200002, "len": 20.752941176500002, "discriminatori": 53.6351351351, "observ": 2.22446406053, "accuraci": 12.7620578778, "conscious": 8.10413476263, "agre": 2.22946215419, "more": 1.0171706817, "stay": 2.6986231514499996, "suggest": 1.7571665744299998, "three": 1.06621893889, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "small": 1.3594793629, "control": 1.46959178006, "both": 1.05215720061, "third": 1.4195278969999998, "aris": 7.54921540656, "result": 1.14611608432, "off": 1.5121440137200002, "judgment": 10.911340206199998, "produc": 1.36932896326, "guidelin": 13.580838323399998, "use": 1.0296387573799999, "set": 1.18707940781, "ethic": 8.93918918919, "ani": 1.13383802314, "king": 2.0281042411900003, "philosoph": 5.65586034913, "from": 1.00056721497, "account": 1.94463498285, "answer": 4.64890190337, "limit": 1.5186531471200002, "longitudin": 46.557184750699996, "num": 1.00031504001, "clash": 8.34261692065, "instanc": 3.2572835453400004, "idea": 2.0930784443, "free": 1.71818181818, "environ": 3.43561999567, "studi": 1.53184098804, "incred": 18.227324913900002, "exclud": 5.31859296482, "for": 1.00031504001, "difficult": 2.48957189901, "match": 3.5676404494400002, "with": 1.0011982089899998, "misbehavior": 429.081081081, "competit": 3.06960556845, "judgement": 21.4251012146, "assum": 2.9575260804799997, "reset": 65.3333333333, "merg": 5.28319467554, "solut": 4.7278141751, "controversi": 2.62543409955, "compani": 1.5523613963, "effort": 1.89247824532, "month": 1.5079787234, "sens": 2.8365195640499996, "team": 2.2748244734200003, "look": 1.9086318826599997, "stock": 5.01611374408, "option": 4.04896710023, "passu": 1443.27272727, "woman": 3.47852760736, "chanc": 4.2449197861000005, "intern": 1.30355530011, "ago": 6.05954198473, "extern": 5.24133377352, "negat": 3.75852272727, "align": 8.10413476263, "educ": 2.00733341763, "tell": 3.36142282448, "artifici": 8.31639601886, "disregard": 21.9889196676, "remov": 2.0058117498400003, "penal": 28.35, "doe": 1.70581282905, "even": 1.16461267606, "underestim": 45.36, "glanc": 46.285714285699996, "give": 1.3653250774, "total": 1.5460122699399999, "side": 1.5989525632, "place": 1.1004366812200002, "great": 1.26592775696, "deviat": 19.1507840772, "assumpt": 9.21951219512, "goal": 3.28152128979, "capac": 3.86842105263, "error": 6.04109589041, "framework": 8.200413223139998, "extrem": 2.36602086438, "his": 1.0943682360200002, "ask": 2.1744966443, "type": 2.0281042411900003, "omnicomprehens": 1443.27272727, "invent": 4.604408352669999, "switch": 4.97368421053, "matter": 2.44773358002, "accept": 1.7377408056, "thing": 2.4065484311099996, "analyz": 9.68639414277, "scientist": 4.69426374926, "machin": 4.02433460076, "into": 1.01502461479, "medic": 3.27542809986, "bias": 13.7335640138, "extinct": 13.627467811199999, "notr": 33.9230769231, "hasn": 1443.27272727, "justifi": 7.578042959430001, "cultur": 1.86075949367, "where": 1.06715063521, "doctor": 3.9394540942900003, "bubbl": 23.075581395300002, "face": 1.80327124035, "spit": 51.5454545455, "implicit": 21.1962616822, "let": 3.48616600791, "spontan": 16.1834862385, "head": 1.57781753131, "help": 1.39962972759, "believ": 1.6450108797, "find": 1.7294117647099998, "point": 1.25990000794, "francesco": 31.3136094675, "instead": 1.59461631177, "line": 1.4182597820299998, "brain": 8.929133858270001, "tempor": 21.897931034499997, "least": 1.6165359943000002, "base": 1.14628158845, "natur": 1.5392670157100001, "deal": 2.18346857379, "fact": 1.73375559681, "pari": 3.80810745982, "decid": 1.9257641921400002, "univers": 1.24889867841, "compromis": 7.542042755339999, "hold": 1.6551292744, "payoff": 172.56521739099998, "here": 2.42307692308, "camera": 8.989807474520001, "report": 1.3634489866, "shortcut": 127.008, "pursu": 4.15384615385, "clean": 6.86975335353, "decisionmak": 1323.0, "paramet": 17.256521739100002, "human": 1.8965476048299998, "liabil": 27.1384615385, "much": 1.1942229577299999, "evalu": 6.9509632224199995, "than": 1.03278688525, "care": 2.49426551453, "about": 1.06486015159, "norm": 11.299644128099999, "run": 1.55692850838, "say": 1.7544480053, "diakopoulo": 1443.27272727, "mind": 3.5918552036199998, "discourag": 12.4811320755, "narrat": 6.002268431, "just": 1.33580143037, "perspect": 5.03520456708, "adapt": 3.32272917539, "understand": 2.96858638743, "won": 2.31732593782, "speci": 6.648241206030001, "price": 3.4838709677399997, "him": 1.63434218653, "simpli": 2.5192002538900002, "statement": 3.42228928648, "systemat": 8.338235294119999, "would": 1.0828729281799998, "them": 1.09876115994, "defin": 2.72830383227, "perceiv": 4.92279069767, "recommend": 3.9142011834300003, "term": 1.39520168732, "friedler": 1443.27272727, "train": 1.9365698950999999, "save": 2.8178913737999998, "tool": 4.99716713881, "start": 1.26673581744, "phloxiishutterstock": 1443.27272727, "power": 1.3396337861799998, "noth": 3.46410648047, "articl": 2.01805008262, "guid": 2.49113447356, "catastroph": 16.4859813084, "simpl": 3.3981164383599998, "trust": 4.89546716004, "bad": 3.3944836433599996, "energi": 3.66566612792, "explain": 2.60049140049, "speak": 2.89127663449, "singl": 1.60948905109, "lose": 3.0851146521599997, "central": 1.6121039805000001, "health": 2.71570304482, "abl": 1.8208510150200001, "tune": 10.4173228346, "mani": 1.04426757877, "diseas": 5.2120814182499995, "over": 1.02525024217, "theoret": 7.83613030602, "perhap": 3.14812611541, "build": 1.6341739578, "analysi": 3.47852760736, "mida": 273.724137931, "liabl": 39.1034482759, "provid": 1.21552714187, "wrote": 2.10473286491, "sorell": 1443.27272727, "pattern": 3.79173632673, "one": 1.00627495722, "unfortun": 9.966101694919999, "same": 1.11857958148, "there": 1.04091266719, "connect": 1.8843916913900003, "stick": 11.5377906977, "fallaci": 65.3333333333, "possibl": 1.4173734488, "industri": 2.02319357716, "frame": 6.280063291139999, "delic": 27.0921501706, "exampl": 1.50483412322, "big": 2.7400759406299997, "crimin": 5.38717339667, "pure": 4.716577540109999, "think": 2.90715986083, "enterpris": 6.414545454550001, "again": 1.50883862384, "visual": 5.22752716497, "follow": 1.04640126549, "block": 3.20274359492, "tri": 1.8544562551099997, "then": 1.08657860516, "advers": 14.0994671403, "hard": 2.73253012048, "usual": 1.72508964468, "interact": 4.4185917061, "desir": 3.00170164492, "irrat": 55.7052631579, "basic": 2.7301805675, "benchmark": 51.8823529412, "realli": 4.7476076555, "abil": 2.70875277256, "feel": 3.1356903021900004, "algorithmsassist": 1443.27272727, "also": 1.01476510067, "specifi": 6.920662598080001, "person": 1.40520446097, "around": 1.21394708671, "mean": 1.44906900329, "race": 2.93023255814, "treatment": 3.87125091441, "task": 3.88641370869, "system": 1.38739840951, "phenomena": 16.5202913632, "therefor": 2.33401940606, "the": 1.0, "becom": 1.12492028626, "probabl": 2.64555907349, "past": 2.01702452039, "peopl": 1.21320495186, "angl": 8.934158694430002, "open": 1.24556723678, "those": 1.19548192771, "want": 1.99698113208, "someon": 4.9350326391, "talk": 3.0303493033, "strategist": 55.5104895105, "argument": 5.09335899904, "individu": 1.8004082558400003, "evolutionari": 21.168000000000003, "howev": 1.0945191313299998, "kill": 2.09916699722, "pedestrian": 25.0410094637, "cognit": 21.454054054100002, "smartphon": 77.443902439, "work": 1.11520089913, "could": 1.2043695949, "maxim": 12.928338762200001, "were": 1.02458857696, "which": 1.005191845, "databas": 8.24727272727, "random": 7.1902173913, "weak": 4.70539419087, "relev": 6.938811188810001, "activ": 1.46403541129, "estim": 2.34991119005, "other": 1.00992366412, "appli": 2.2972073506, "myself": 14.5517873511, "consist": 1.4901445466499998, "known": 1.0859097127200001, "impact": 2.97526236882, "hope": 2.50884955752, "begin": 1.3305397251100002, "rais": 1.9733996271, "see": 1.27242125511, "becaus": 1.1495184997499999, "imag": 2.70137825421, "trap": 7.4570220760899995, "nichola": 8.96442687747, "mayb": 21.0557029178, "get": 1.78562591385, "like": 1.14918566775, "implement": 3.57648118946, "abov": 1.90382539873, "sensor": 28.8654545455, "should": 1.6643254009900001, "technolog": 2.6034765496900003, "except": 1.71948445792, "autonom": 11.086592178800002, "kris": 67.5574468085, "mitig": 22.8103448276, "undesir": 31.3754940711, "recent": 1.54405757635, "requir": 1.52844902282, "anyon": 5.37440758294, "straightforward": 27.7552447552, "access": 1.8734953976900002, "this": 1.00379362671, "choic": 3.1319786940200003, "principl": 3.4520547945199995, "instant": 11.504347826099998, "time": 1.01127460348, "through": 1.07074930869, "engin": 2.47135740971, "back": 1.26070038911, "chang": 1.1808985421, "scifi": 1221.23076923, "differ": 1.23654490225, "embed": 16.835630965, "but": 1.01632417899, "institut": 1.7792222346700002, "statist": 4.24265098878, "decis": 2.16, "malfunct": 41.778947368400004, "most": 1.02096463023, "between": 1.03453668708, "what": 1.25343439128, "who": 1.06279287723, "credit": 3.04312823462, "overconfid": 220.5, "all": 1.01146788991, "everyon": 6.3964544722, "busi": 2.05541170378, "action": 1.81855670103, "behaviour": 9.879278158060002, "reason": 1.72340425532, "someth": 3.28152128979, "unlucki": 178.38202247200002, "former": 1.36111111111, "degre": 2.4852849092, "case": 1.48498737256, "hammond": 39.8894472362, "that": 1.00398406375, "garbag": 43.9778393352, "call": 1.0676529926, "revis": 4.32117583016, "blur": 29.7303370787, "futur": 1.8577112099200002, "and": 1.00006299213, "year": 1.0485436893200002, "discuss": 2.19676214197, "achiev": 1.87216981132, "greatest": 3.00738776283, "life": 1.37051104972, "oonum": 1443.27272727, "worst": 6.653813914500001, "general": 1.1218202374200001, "made": 1.07038834951, "expect": 2.20011086475, "emerg": 2.1131372288, "question": 2.20408163265, "comment": 3.05954904606, "doubt": 5.31325301205, "corea": 453.6, "wors": 9.58695652174, "standard": 1.8915763135900003, "can": 1.17626139142, "comput": 3.9277585353800006, "make": 1.0762660158600001, "way": 1.2190739461, "now": 1.160780873, "onli": 1.0256476516600002, "hothand": 1443.27272727, "circumst": 5.28671328671, "clear": 1.85423966363, "diagnos": 16.283076923099998, "tackl": 19.8698372966, "utilitarian": 66.7058823529, "necessari": 2.8421052631599997, "accur": 5.768895348840001, "emb": 186.776470588, "remain": 1.16598119859, "common": 1.4025974025999999, "chain": 5.17639387023, "maryland": 12.335664335699999, "data": 3.37643555934, "threefold": 95.6385542169, "guy": 7.67327211213, "perfect": 4.48601299802, "rather": 1.55692850838, "whether": 2.20683903253, "best": 1.5828514456600002, "sometim": 1.7126213592200001, "come": 1.32831325301, "might": 2.1561863370900003, "learn": 2.32275054865, "right": 1.4054532577899999, "identifi": 2.30187037843, "import": 1.3401992233700002, "first": 1.00761614623, "proceed": 3.4333910034599997, "input": 12.2029208301, "extent": 4.09491875161, "have": 1.0148948411399998, "rate": 2.14048806795, "unforeseen": 120.27272727299999, "without": 1.29547123623, "whi": 3.2566153846200003, "mcmurryjuliepixabay": 1443.27272727, "down": 1.35889754344, "inde": 4.43092380687, "own": 1.17844418052, "when": 1.02076769755, "parti": 2.06369426752}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Machine Ethics and Artificial Moral Agents</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/machine-ethics-artificial-moral-agents.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Machine Ethics and Artificial Moral Agents Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/chang-advice-new-junior-data-scientists.html\" rel=\"prev\" title=\"Advice For New and Junior Data Scientists\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html\" rel=\"next\" title=\"Process Mining with R: Introduction\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/11/machine-ethics-artificial-moral-agents.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=73977\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/machine-ethics-artificial-moral-agents.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-73977 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 2-Nov, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/opinions-interviews.html\">Opinions, Interviews</a> \u00bb Machine Ethics and Artificial Moral Agents (\u00a0<a href=\"/2017/n43.html\">17:n43</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Machine Ethics and Artificial Moral Agents</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/11/chang-advice-new-junior-data-scientists.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/ai\" rel=\"tag\">AI</a>, <a href=\"https://www.kdnuggets.com/tag/bias\" rel=\"tag\">Bias</a>, <a href=\"https://www.kdnuggets.com/tag/ethics\" rel=\"tag\">Ethics</a>, <a href=\"https://www.kdnuggets.com/tag/machine-intelligence\" rel=\"tag\">Machine Intelligence</a></div>\n<br/>\n<p class=\"excerpt\">\n     This article is simply a stream of consciousness on questions and problems I have been thinking and asking myself, and hopefully, it will stimulate some discussion.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/francesco-corea\" rel=\"author\" title=\"Posts by Francesco Corea\">Francesco Corea</a>, Decision Scientist and Data Strategist.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2017/11/machine-ethics-artificial-moral-agents.html?page=2#comments\">comments</a></div>\n<p><center><img alt=\"Header image\" src=\"https://cdn-images-1.medium.com/max/2000/1*Z5eUqo8-HZXV7079K5oqkQ.jpeg\" width=\"99%\"><br>\n<font size=\"-1\">Image Credit: <a href=\"https://www.shutterstock.com/g/andruxevich\" rel=\"noopener\" target=\"_blank\">andruxevich/Shutterstock</a></font></br></img></center></p>\n<p>There has been a lot of talk over the past months about AI being our best or worst invention ever. The chance of robots taking over and the following catastrophic sci-fi scenario makes the ethical and purposeful design of machines and algorithms not simply important but necessary.</p>\n<p>But the problems do not end here. Incorporating ethical principles into our technology development process should not just be a way to prevent human race extinction but also a way to understand how to use the power coming from that technology responsibly.</p>\n<p>This article does not want to be a guide for ethics for AI or setting the guidelines for building ethical technologies. It is simply a stream of consciousness on questions and problems I have been thinking and asking myself, and hopefully, it will stimulate some discussion.</p>\n<p>Now, let\u2019s go down the rabbit-hole...</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*yZTD00JgXFz9_5A6hg34YA.jpeg\" width=\"99%\"/><br>\n<font size=\"-1\">Image Credit:\u00a0<a href=\"https://www.shutterstock.com/g/phloxii\" target=\"_blank\">phloxii/Shutterstock</a></font></br></center></p>\n<p>\u00a0</p>\n<h3>I. Data and biases</h3>\n<p>\u00a0<br>\nThe first problem everyone raises when speaking about ethics in AI is, of course, about data. Most of the data we produce (if we exclude the ones coming from observation of natural phenomena) are artificial creations of our minds and actions (e.g., stock prices, smartphone activity, etc.). As such,<strong>\u00a0data inherit the same biases we have as humans</strong>.</br></p>\n<p>First of all, what is a cognitive bias? The (maybe controversial) way I look at it is that a cognitive bias is a\u00a0<strong>shortcut of our brain that translates into behaviors which required less energy and thought to be implemented</strong>. So, a bias is a good thing to me, at least in principle. The reason why it becomes a bad thing is that the external environment and our internal capacity to think do not proceed\u00a0<em>pari passu.\u00a0</em>Our brain gets trapped into heuristics and shortcuts which could have resulted into competitive advantages 100 years ago but is not that\u00a0<em>plastic</em>\u00a0to quickly adapt to the change of the external environment (I am not talking about a single brain but rather on a species level).</p>\n<p>In other words,\u00a0<em>the systematic deviation from a standard of rationality or good judgment\u00a0</em>(this is how bias is defined in psychology) is nothing more for me than a simple\u00a0<strong>evolutionary lag of our brain.</strong></p>\n<p>Why all this\u00a0<em>excursus</em>? Well, because I think that most of the biases data embed comes from our own cognitive biases (at least for data resulting from human and not natural activities). There is, of course, another block of biases which stems from pure statistical reasons (<em>the expected value is different from the true underlying estimated parameter</em>). Kris Hammond of Narrative Science merged those two views and identified\u00a0<a href=\"https://techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/\" target=\"_blank\">at least five different biases</a>\u00a0in AI. In his words:</p>\n<ul>\n<li><strong>Data-driven bias</strong>\u00a0(bias that depends on the input data used);\n<li><strong>Bias through interaction</strong>;\n<li><strong>Similarity bias</strong>\u00a0(it is simply the product of systems doing what they were designed to do);\n<li><strong>Conflicting goals bias</strong>\u00a0(systems designed for very specific business purposes end up having biases that are real but completely unforeseen);\n<li><strong>Emergent bias</strong>\u00a0(decisions made by systems aimed at personalization will end up creating bias \u201cbubbles\u201d around us).\n</li></li></li></li></li></ul>\n<p>But let\u2019s go back to the problem. How would you solve the biased data issue then?</p>\n<p>Simple solution: you can try to remove any data that could bias your engine\u00a0<em>ex-ante</em>. Great solution, it will require some effort at the beginning, but it might be feasible.</p>\n<p>However, let\u2019s look at the problem from a different angle. I was educated as an economist, so allow me to start my argument with this statement:\u00a0<strong>let\u2019s assume we have the perfect dataset</strong>. It is not only omni-comprehensive but also clean, consistent and deep both longitudinally and temporally speaking.</p>\n<p>Even in this case,\u00a0<strong>we have no guarantee AI won\u2019t learn the same bias autonomously as we did</strong>. In other words, removing biases by hand or by construction is not a guarantee of those biases to not come out again spontaneously.</p>\n<blockquote><p>We have no guarantee AI won\u2019t learn the same bias autonomously as we\u00a0did.</p></blockquote>\n<p>This possibility also raises another (philosophical) question: we are building this argument from the assumption that\u00a0<em>biases are bad</em>\u00a0(mostly). So let\u2019s say the machines come up with a result we see as biased, and therefore we reset them and start again the analysis with new data. But the machines come up with a similarly \u2018biased result\u2019. Would we then be open to accepting that as true and revision what we consider to be biased?</p>\n<p>This is basically a\u00a0<strong><em>cultural and philosophical clash between two different species</em></strong>.</p>\n<p>In other words, I believe that two of the reasons why embedding ethics into machine designing is extremely hard is that i)\u00a0<strong><em>we don\u2019t really know unanimously what ethics is</em></strong>, and ii) we should be open to admit that our values or ethics might not be completely right and that what we consider to be biased is not the exception but rather the norm.</p>\n<p>Developing a (general) AI is making us think about those problems and\u00a0<strong>it will change\u00a0</strong>(if it hasn\u2019t already started)\u00a0<strong>our values system</strong>. And perhaps, who knows, we will end up learning something from\u00a0<em>machines\u2019 ethics\u00a0</em>as well.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*pY_Q63GmcoRYViR5i11yyQ.jpeg\" width=\"99%\"/><br>\n<font size=\"-1\">Image Credit:\u00a0<a href=\"https://online.ndm.edu/\" target=\"_blank\">Notre Dame of Maryland University Online</a></font></br></center></p>\n<p>\u00a0</p>\n<h3>II. Accountability and trust</h3>\n<p>\u00a0<br/>\nWell, now you might think the previous one is a purely philosophical issue and that you probably shouldn\u2019t care about it. But the other side of the matter is about how much you\u00a0<strong>trust your algorithms</strong>. Let me give you a different perspective to practically looking at this problem.</p>\n<p>Let\u2019s assume you are a medical doctor and you use one of the many algorithms out there to help you diagnose a specific disease or to assist you in a patient treatment. In the 99.99% of the time the computer gets it right\u200a\u2014\u200aand it never gets tired, it analyzed billions of records, it sees patterns that a human eye can\u2019t perceive, we all know this story, right? But what if in the remaining o.o1% of the case your instinct tells you something opposite to the machine result and you end up to be right? What if you decide to follow the advice the machine spit out instead of yours and the patient dies? Who is liable in this case?</p>\n<p>But even worse: let\u2019s say in that case you follow your gut feeling (we know is not gut feeling though, but simply your ability to recognize at a glance something you know to be the right disease or treatment) and you save a patient. The following time (and patient), you have another conflict with the machine results but strong of the recent past experience (because of an\u00a0<em>hot-hand fallacy</em>\u00a0or an\u00a0<em>overconfidence\u00a0</em>bias) you think to be right again and decide to disregard what the artificial engine tells you. Then the patient dies. Who is liable now?</p>\n<p>The question is quite delicate indeed and the scenarios in my head are:</p>\n<p>a) a scenario where the doctor is only human with no machine assistance. The payoff here is that liability stay with him, he gets it right 70% of the time, but the things are quite clear and sometimes he gets right something extremely hard (the lucky guy out of 10,000 patients);<br/>\nb) a scenario where a machine decides and gets it right 99.99% of the time. The negative side of it is an unfortunate patient out of 10,000 is going to die because of a machine error and the liability is not assigned to either the machine or the human;<br/>\nc) a scenario the doctor is assisted but has the final call to decide whether to follow the advice. The payoff here is completely randomized and not clear to me at all.</p>\n<p>As a former economist, I have been trained to be heartless and reason in terms of expected values and big numbers (basically a\u00a0<strong>Utilitarian</strong>), therefore scenario\u00a0<em>b)</em>\u00a0looks the only possible to me because it saves the greatest number of people. But we all know is not that simple (and of course doesn\u2019t feel right for the unlucky guy of our example): think about the case, for instance, of autonomous vehicles that lose controls and need to decide if killing the driver or five random pedestrians (the famous\u00a0<strong><em>Trolley Problem</em></strong>). Based on that principles I\u2019d save the pedestrians, right? But what about all those five are criminals and the driver is a pregnant woman? Does your judgement change in that case? And again, what if the vehicle could instantly use cameras and visual sensors to recognize pedestrians\u2019 faces, connect to a central database and match them with health records finding out that they all have some type of terminal disease? You see, the line is blurring...</p>\n<p>The final doubt that remains is then not simply about liability (and the choice between pure outcomes and ways to achieve them) but rather on trusting the algorithm (and I know that for someone who studied 12 years to become doctor might not be that easy to give that up). In fact,\u00a0<a href=\"http://knowledge.wharton.upenn.edu/article/how-to-convince-people-to-trust-algorithms/\" target=\"_blank\"><strong>algorithm adversion</strong></a>\u00a0is becoming a real problem for algorithms-assisted tasks and it looks that people want to have an (even if incredibly small) degree of control over algorithms (Dietvorst et al., 2015; 2016).</p>\n<p>But above all:\u00a0<strong>are we allowed to deviate from the advice we get from accurate algorithms?\u00a0</strong>And if so, in what circumstances and to what extent?</p>\n<blockquote><p>Are we allowed to deviate from the advice we get from accurate algorithms?</p></blockquote>\n<p>If an AI would decide on the matter, it will also probably go for scenario\u00a0<em>b)</em>\u00a0but we as humans would like to find a compromise between those scenarios because we \u2018<em>ethically</em>\u2019 don\u2019t feel any of those to be right. We can rephrase then this issue under the\u00a0<strong>\u2018alignment problem\u2019\u00a0</strong>lens, which means that the goals and behaviors an AI have need to be aligned with human values\u200a\u2014\u200aan AI needs to think as a human in certain cases (but of course the question here is how do you discriminate? And what\u2019s the advantage of having an AI then? Let\u2019s therefore simply stick to the traditional human activities).</p>\n<p>In this situation, the work done by the Future of Life Institute with the\u00a0<a href=\"https://futureoflife.org/ai-principles/\" target=\"_blank\"><strong>Asilomar Principles</strong></a><strong>\u00a0</strong>becomes extremely relevant.</p>\n<p>The alignment problem, in fact, also known as \u2018<strong><em>King Midas problem</em></strong>\u2019, arises from the idea that no matter how we tune our algorithms to achieve a specific objective, we are not able to specify and frame those objectives well enough to prevent the machines to pursue undesirable ways to reach them. Of course, a theoretically viable solution would be to let the machine maximizing for our true objective without setting it\u00a0<em>ex-ante</em>, making therefore the algorithm itself free to observe us and understand what we really want (as a species and not as individuals, which might entail also the possibility of switching itself off if needed).</p>\n<p>Sounds too good to be true? Well, maybe it is. I indeed totally agree with Nicholas Davis and Thomas Philbeck from WEF that in the\u00a0<a href=\"http://reports.weforum.org/global-risks-2017/?doing_wp_cron=1499346241.9620978832244873046875\" target=\"_blank\">Global Risks Report 2017</a>\u00a0wrote:</p>\n<blockquote><p>\u201cThere are complications: humans are irrational, inconsistent, weak-willed, computationally limited and heterogeneous, all of which conspire to make learning about human values from human behaviour a difficult (and perhaps not totally desirable) enterprise\u201d.</p></blockquote>\n<p>What the previous section implicitly suggested is that not all AI applications are the same and that\u00a0<em>error rates</em>\u00a0apply differently to different industries. Under this assumption, it might be hard to draw a line and design an accountability framework that does not penalize applications with weak impact (e.g., a recommendation engine) and at the same time do not underestimate the impact of other applications (e.g,., healthcare or AVs).</p>\n<p>We might end up then designing\u00a0<strong>multiple accountability frameworks\u00a0</strong>to justify algorithmic decision-making and mitigate negative biases.</p>\n<p>Certainly, the most straightforward solution to understand who owns the liability for a certain AI tool is thinking about the following threefold classification:</p>\n<ul>\n<li><strong><em>We should hold the AI system itself as responsible for any misbehavior</em></strong>(does it make any sense?);\n<li><strong><em>We should hold the designers of the AI as responsible for the malfunctioning and bad outcome</em></strong><em>\u00a0</em>(but it might be hard because usually AI teams might count hundred of people and this preventative measure could discourage many from entering the field);\n<li><strong><em>We should hold accountable the organization running the system\u00a0</em></strong>(to me it sounds the most reasonable between the three options, but I am not sure about the implications of it. And then what company should be liable in the AI value chain? The final provider? The company who built the system in the first place? The consulting business which recommended it?).\n</li></li></li></ul>\n<p>There is not an easy answer and much more is required to tackle this issue, but I believe a good starting point has been provided by\u00a0<a href=\"https://www.technologyreview.com/s/602933/how-to-hold-algorithms-accountable/\" target=\"_blank\">Sorelle Friedler and Nicholas Diakopoulos</a>. They suggest to consider accountability through the lens of five core principles:</p>\n<ul>\n<li><strong>Responsibility</strong>: a person should be identified to deal with unexpected outcomes, not in terms of legal responsibility but rather as a single point of contact;\n<li><strong>Explainability</strong>: a decision process should be explainable not technically but rather in an accessible form to anyone;\n<li><strong>Accuracy</strong>:\u00a0<em>garbage in, garbage out</em>\u00a0is likely to be the most common reason for the lack of accuracy in a model. The data and error sources need then to be identified, logged, and benchmarked;\n<li><strong>Auditability</strong>: third parties should be able to probe and review the behavior of an algorithm;\n<li><strong>Fairness</strong>: algorithms should be evaluated for discriminatory effects.\n</li></li></li></li></li></ul>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*woLZ01BOYwj77cB_PxMjLQ.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Image Credit:\u00a0<a href=\"https://pixabay.com/en/ehr-emr-electronic-medical-record-1476525/\" target=\"_blank\">mcmurryjulie/Pixabay</a></font></center></p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2017/11/machine-ethics-artificial-moral-agents.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/11/chang-advice-new-junior-data-scientists.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/opinions-interviews.html\">Opinions, Interviews</a> \u00bb Machine Ethics and Artificial Moral Agents (\u00a0<a href=\"/2017/n43.html\">17:n43</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556379550\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.682 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 11:39:10 -->\n<!-- Compression = gzip -->", "content_tokenized": ["francesco", "corea", "decis", "scientist", "and", "data", "strategist", "comment", "imag", "credit", "andruxevichshutterstock", "there", "has", "been", "lot", "talk", "over", "the", "past", "month", "about", "our", "best", "worst", "invent", "ever", "the", "chanc", "robot", "take", "over", "and", "the", "follow", "catastroph", "scifi", "scenario", "make", "the", "ethic", "and", "purpos", "design", "machin", "and", "algorithm", "not", "simpli", "import", "but", "necessari", "but", "the", "problem", "not", "end", "here", "incorpor", "ethic", "principl", "into", "our", "technolog", "develop", "process", "should", "not", "just", "way", "prevent", "human", "race", "extinct", "but", "also", "way", "understand", "how", "use", "the", "power", "come", "from", "that", "technolog", "respons", "this", "articl", "doe", "not", "want", "guid", "for", "ethic", "for", "set", "the", "guidelin", "for", "build", "ethic", "technolog", "simpli", "stream", "conscious", "question", "and", "problem", "have", "been", "think", "and", "ask", "myself", "and", "hope", "will", "stimul", "some", "discuss", "now", "let", "down", "the", "rabbithol", "imag", "credit", "phloxiishutterstock", "data", "and", "bias", "the", "first", "problem", "everyon", "rais", "when", "speak", "about", "ethic", "cours", "about", "data", "most", "the", "data", "produc", "exclud", "the", "one", "come", "from", "observ", "natur", "phenomena", "are", "artifici", "creation", "our", "mind", "and", "action", "stock", "price", "smartphon", "activ", "etc", "such", "data", "inherit", "the", "same", "bias", "have", "human", "first", "all", "what", "cognit", "bias", "the", "mayb", "controversi", "way", "look", "that", "cognit", "bias", "shortcut", "our", "brain", "that", "translat", "into", "behavior", "which", "requir", "less", "energi", "and", "thought", "implement", "bias", "good", "thing", "least", "principl", "the", "reason", "whi", "becom", "bad", "thing", "that", "the", "extern", "environ", "and", "our", "intern", "capac", "think", "not", "proceed", "pari", "passu", "our", "brain", "get", "trap", "into", "heurist", "and", "shortcut", "which", "could", "have", "result", "into", "competit", "advantag", "num", "year", "ago", "but", "not", "that", "plastic", "quick", "adapt", "the", "chang", "the", "extern", "environ", "not", "talk", "about", "singl", "brain", "but", "rather", "speci", "level", "other", "word", "the", "systemat", "deviat", "from", "standard", "ration", "good", "judgment", "this", "how", "bias", "defin", "psycholog", "noth", "more", "for", "than", "simpl", "evolutionari", "lag", "our", "brain", "whi", "all", "this", "excursus", "well", "becaus", "think", "that", "most", "the", "bias", "data", "emb", "come", "from", "our", "own", "cognit", "bias", "least", "for", "data", "result", "from", "human", "and", "not", "natur", "activ", "there", "cours", "anoth", "block", "bias", "which", "stem", "from", "pure", "statist", "reason", "the", "expect", "valu", "differ", "from", "the", "true", "under", "estim", "paramet", "kris", "hammond", "narrat", "scienc", "merg", "those", "two", "view", "and", "identifi", "least", "five", "differ", "bias", "his", "word", "datadriven", "bias", "bias", "that", "depend", "the", "input", "data", "use", "bias", "through", "interact", "similar", "bias", "simpli", "the", "product", "system", "what", "they", "were", "design", "conflict", "goal", "bias", "system", "design", "for", "veri", "specif", "busi", "purpos", "end", "have", "bias", "that", "are", "real", "but", "complet", "unforeseen", "emerg", "bias", "decis", "made", "system", "aim", "person", "will", "end", "creat", "bias", "bubbl", "around", "but", "let", "back", "the", "problem", "how", "would", "solv", "the", "bias", "data", "issu", "then", "simpl", "solut", "can", "tri", "remov", "ani", "data", "that", "could", "bias", "engin", "exant", "great", "solut", "will", "requir", "some", "effort", "the", "begin", "but", "might", "feasibl", "howev", "let", "look", "the", "problem", "from", "differ", "angl", "educ", "economist", "allow", "start", "argument", "with", "this", "statement", "let", "assum", "have", "the", "perfect", "dataset", "not", "onli", "omnicomprehens", "but", "also", "clean", "consist", "and", "deep", "both", "longitudin", "and", "tempor", "speak", "even", "this", "case", "have", "guarante", "won", "learn", "the", "same", "bias", "autonom", "other", "word", "remov", "bias", "hand", "construct", "not", "guarante", "those", "bias", "not", "come", "out", "again", "spontan", "have", "guarante", "won", "learn", "the", "same", "bias", "autonom", "this", "possibl", "also", "rais", "anoth", "philosoph", "question", "are", "build", "this", "argument", "from", "the", "assumpt", "that", "bias", "are", "bad", "most", "let", "say", "the", "machin", "come", "with", "result", "see", "bias", "and", "therefor", "reset", "them", "and", "start", "again", "the", "analysi", "with", "new", "data", "but", "the", "machin", "come", "with", "similar", "bias", "result", "would", "then", "open", "accept", "that", "true", "and", "revis", "what", "consid", "bias", "this", "basic", "cultur", "and", "philosoph", "clash", "between", "two", "differ", "speci", "other", "word", "believ", "that", "two", "the", "reason", "whi", "embed", "ethic", "into", "machin", "design", "extrem", "hard", "that", "realli", "know", "unanim", "what", "ethic", "and", "should", "open", "admit", "that", "our", "valu", "ethic", "might", "not", "complet", "right", "and", "that", "what", "consid", "bias", "not", "the", "except", "but", "rather", "the", "norm", "develop", "general", "make", "think", "about", "those", "problem", "and", "will", "chang", "hasn", "alreadi", "start", "our", "valu", "system", "and", "perhap", "who", "know", "will", "end", "learn", "someth", "from", "machin", "ethic", "well", "imag", "credit", "notr", "dame", "maryland", "univers", "onlin", "account", "and", "trust", "well", "now", "might", "think", "the", "previous", "one", "pure", "philosoph", "issu", "and", "that", "probabl", "shouldn", "care", "about", "but", "the", "other", "side", "the", "matter", "about", "how", "much", "trust", "algorithm", "let", "give", "differ", "perspect", "practic", "look", "this", "problem", "let", "assum", "are", "medic", "doctor", "and", "use", "one", "the", "mani", "algorithm", "out", "there", "help", "diagnos", "specif", "diseas", "assist", "patient", "treatment", "the", "num", "the", "time", "the", "comput", "get", "right", "and", "never", "get", "tire", "analyz", "billion", "record", "see", "pattern", "that", "human", "eye", "can", "perceiv", "all", "know", "this", "stori", "right", "but", "what", "the", "remain", "oonum", "the", "case", "instinct", "tell", "someth", "opposit", "the", "machin", "result", "and", "end", "right", "what", "decid", "follow", "the", "advic", "the", "machin", "spit", "out", "instead", "and", "the", "patient", "die", "who", "liabl", "this", "case", "but", "even", "wors", "let", "say", "that", "case", "follow", "gut", "feel", "know", "not", "gut", "feel", "though", "but", "simpli", "abil", "recogn", "glanc", "someth", "know", "the", "right", "diseas", "treatment", "and", "save", "patient", "the", "follow", "time", "and", "patient", "have", "anoth", "conflict", "with", "the", "machin", "result", "but", "strong", "the", "recent", "past", "experi", "becaus", "hothand", "fallaci", "overconfid", "bias", "think", "right", "again", "and", "decid", "disregard", "what", "the", "artifici", "engin", "tell", "then", "the", "patient", "die", "who", "liabl", "now", "the", "question", "quit", "delic", "inde", "and", "the", "scenario", "head", "are", "scenario", "where", "the", "doctor", "onli", "human", "with", "machin", "assist", "the", "payoff", "here", "that", "liabil", "stay", "with", "him", "get", "right", "num", "the", "time", "but", "the", "thing", "are", "quit", "clear", "and", "sometim", "get", "right", "someth", "extrem", "hard", "the", "lucki", "guy", "out", "num", "patient", "scenario", "where", "machin", "decid", "and", "get", "right", "num", "the", "time", "the", "negat", "side", "unfortun", "patient", "out", "num", "die", "becaus", "machin", "error", "and", "the", "liabil", "not", "assign", "either", "the", "machin", "the", "human", "scenario", "the", "doctor", "assist", "but", "has", "the", "final", "call", "decid", "whether", "follow", "the", "advic", "the", "payoff", "here", "complet", "random", "and", "not", "clear", "all", "former", "economist", "have", "been", "train", "heartless", "and", "reason", "term", "expect", "valu", "and", "big", "number", "basic", "utilitarian", "therefor", "scenario", "look", "the", "onli", "possibl", "becaus", "save", "the", "greatest", "number", "peopl", "but", "all", "know", "not", "that", "simpl", "and", "cours", "feel", "right", "for", "the", "unlucki", "guy", "our", "exampl", "think", "about", "the", "case", "for", "instanc", "autonom", "vehicl", "that", "lose", "control", "and", "need", "decid", "kill", "the", "driver", "five", "random", "pedestrian", "the", "famous", "trolley", "problem", "base", "that", "principl", "save", "the", "pedestrian", "right", "but", "what", "about", "all", "those", "five", "are", "crimin", "and", "the", "driver", "pregnant", "woman", "doe", "judgement", "chang", "that", "case", "and", "again", "what", "the", "vehicl", "could", "instant", "use", "camera", "and", "visual", "sensor", "recogn", "pedestrian", "face", "connect", "central", "databas", "and", "match", "them", "with", "health", "record", "find", "out", "that", "they", "all", "have", "some", "type", "termin", "diseas", "see", "the", "line", "blur", "the", "final", "doubt", "that", "remain", "then", "not", "simpli", "about", "liabil", "and", "the", "choic", "between", "pure", "outcom", "and", "way", "achiev", "them", "but", "rather", "trust", "the", "algorithm", "and", "know", "that", "for", "someon", "who", "studi", "num", "year", "becom", "doctor", "might", "not", "that", "easi", "give", "that", "fact", "algorithm", "advers", "becom", "real", "problem", "for", "algorithmsassist", "task", "and", "look", "that", "peopl", "want", "have", "even", "incred", "small", "degre", "control", "over", "algorithm", "dietvorst", "num", "num", "but", "abov", "all", "are", "allow", "deviat", "from", "the", "advic", "get", "from", "accur", "algorithm", "and", "what", "circumst", "and", "what", "extent", "are", "allow", "deviat", "from", "the", "advic", "get", "from", "accur", "algorithm", "would", "decid", "the", "matter", "will", "also", "probabl", "for", "scenario", "but", "human", "would", "like", "find", "compromis", "between", "those", "scenario", "becaus", "ethic", "feel", "ani", "those", "right", "can", "rephras", "then", "this", "issu", "under", "the", "align", "problem", "len", "which", "mean", "that", "the", "goal", "and", "behavior", "have", "need", "align", "with", "human", "valu", "need", "think", "human", "certain", "case", "but", "cours", "the", "question", "here", "how", "discrimin", "and", "what", "the", "advantag", "have", "then", "let", "therefor", "simpli", "stick", "the", "tradit", "human", "activ", "this", "situat", "the", "work", "done", "the", "futur", "life", "institut", "with", "the", "asilomar", "principl", "becom", "extrem", "relev", "the", "align", "problem", "fact", "also", "known", "king", "mida", "problem", "aris", "from", "the", "idea", "that", "matter", "how", "tune", "our", "algorithm", "achiev", "specif", "object", "are", "not", "abl", "specifi", "and", "frame", "those", "object", "well", "enough", "prevent", "the", "machin", "pursu", "undesir", "way", "reach", "them", "cours", "theoret", "viabl", "solut", "would", "let", "the", "machin", "maxim", "for", "our", "true", "object", "without", "set", "exant", "make", "therefor", "the", "algorithm", "itself", "free", "observ", "and", "understand", "what", "realli", "want", "speci", "and", "not", "individu", "which", "might", "entail", "also", "the", "possibl", "switch", "itself", "off", "need", "sound", "too", "good", "true", "well", "mayb", "inde", "total", "agre", "with", "nichola", "davi", "and", "thoma", "philbeck", "from", "that", "the", "global", "risk", "report", "num", "wrote", "there", "are", "complic", "human", "are", "irrat", "inconsist", "weakwil", "comput", "limit", "and", "heterogen", "all", "which", "conspir", "make", "learn", "about", "human", "valu", "from", "human", "behaviour", "difficult", "and", "perhap", "not", "total", "desir", "enterpris", "what", "the", "previous", "section", "implicit", "suggest", "that", "not", "all", "applic", "are", "the", "same", "and", "that", "error", "rate", "appli", "differ", "differ", "industri", "under", "this", "assumpt", "might", "hard", "draw", "line", "and", "design", "account", "framework", "that", "doe", "not", "penal", "applic", "with", "weak", "impact", "recommend", "engin", "and", "the", "same", "time", "not", "underestim", "the", "impact", "other", "applic", "healthcar", "might", "end", "then", "design", "multipl", "account", "framework", "justifi", "algorithm", "decisionmak", "and", "mitig", "negat", "bias", "certain", "the", "most", "straightforward", "solut", "understand", "who", "own", "the", "liabil", "for", "certain", "tool", "think", "about", "the", "follow", "threefold", "classif", "should", "hold", "the", "system", "itself", "respons", "for", "ani", "misbehavior", "doe", "make", "ani", "sens", "should", "hold", "the", "design", "the", "respons", "for", "the", "malfunct", "and", "bad", "outcom", "but", "might", "hard", "becaus", "usual", "team", "might", "count", "hundr", "peopl", "and", "this", "prevent", "measur", "could", "discourag", "mani", "from", "enter", "the", "field", "should", "hold", "account", "the", "organ", "run", "the", "system", "sound", "the", "most", "reason", "between", "the", "three", "option", "but", "not", "sure", "about", "the", "implic", "and", "then", "what", "compani", "should", "liabl", "the", "valu", "chain", "the", "final", "provid", "the", "compani", "who", "built", "the", "system", "the", "first", "place", "the", "consult", "busi", "which", "recommend", "there", "not", "easi", "answer", "and", "much", "more", "requir", "tackl", "this", "issu", "but", "believ", "good", "start", "point", "has", "been", "provid", "sorell", "friedler", "and", "nichola", "diakopoulo", "they", "suggest", "consid", "account", "through", "the", "len", "five", "core", "principl", "respons", "person", "should", "identifi", "deal", "with", "unexpect", "outcom", "not", "term", "legal", "respons", "but", "rather", "singl", "point", "contact", "explain", "decis", "process", "should", "explain", "not", "technic", "but", "rather", "access", "form", "anyon", "accuraci", "garbag", "garbag", "out", "like", "the", "most", "common", "reason", "for", "the", "lack", "accuraci", "model", "the", "data", "and", "error", "sourc", "need", "then", "identifi", "log", "and", "benchmark", "audit", "third", "parti", "should", "abl", "probe", "and", "review", "the", "behavior", "algorithm", "fair", "algorithm", "should", "evalu", "for", "discriminatori", "effect", "imag", "credit", "mcmurryjuliepixabay"], "timestamp_scraper": 1556379551.315838, "title": "Machine Ethics and Artificial Moral Agents", "read_time": 681.6, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/francesco-corea\" rel=\"author\" title=\"Posts by Francesco Corea\">Francesco Corea</a>, Decision Scientist and Data Strategist.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2017/11/machine-ethics-artificial-moral-agents.html?page=2#comments\">comments</a></div>\n<p><center><img alt=\"Header image\" src=\"https://cdn-images-1.medium.com/max/2000/1*Z5eUqo8-HZXV7079K5oqkQ.jpeg\" width=\"99%\"><br>\n<font size=\"-1\">Image Credit: <a href=\"https://www.shutterstock.com/g/andruxevich\" rel=\"noopener\" target=\"_blank\">andruxevich/Shutterstock</a></font></br></img></center></p>\n<p>There has been a lot of talk over the past months about AI being our best or worst invention ever. The chance of robots taking over and the following catastrophic sci-fi scenario makes the ethical and purposeful design of machines and algorithms not simply important but necessary.</p>\n<p>But the problems do not end here. Incorporating ethical principles into our technology development process should not just be a way to prevent human race extinction but also a way to understand how to use the power coming from that technology responsibly.</p>\n<p>This article does not want to be a guide for ethics for AI or setting the guidelines for building ethical technologies. It is simply a stream of consciousness on questions and problems I have been thinking and asking myself, and hopefully, it will stimulate some discussion.</p>\n<p>Now, let\u2019s go down the rabbit-hole...</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*yZTD00JgXFz9_5A6hg34YA.jpeg\" width=\"99%\"/><br>\n<font size=\"-1\">Image Credit:\u00a0<a href=\"https://www.shutterstock.com/g/phloxii\" target=\"_blank\">phloxii/Shutterstock</a></font></br></center></p>\n<p>\u00a0</p>\n<h3>I. Data and biases</h3>\n<p>\u00a0<br>\nThe first problem everyone raises when speaking about ethics in AI is, of course, about data. Most of the data we produce (if we exclude the ones coming from observation of natural phenomena) are artificial creations of our minds and actions (e.g., stock prices, smartphone activity, etc.). As such,<strong>\u00a0data inherit the same biases we have as humans</strong>.</br></p>\n<p>First of all, what is a cognitive bias? The (maybe controversial) way I look at it is that a cognitive bias is a\u00a0<strong>shortcut of our brain that translates into behaviors which required less energy and thought to be implemented</strong>. So, a bias is a good thing to me, at least in principle. The reason why it becomes a bad thing is that the external environment and our internal capacity to think do not proceed\u00a0<em>pari passu.\u00a0</em>Our brain gets trapped into heuristics and shortcuts which could have resulted into competitive advantages 100 years ago but is not that\u00a0<em>plastic</em>\u00a0to quickly adapt to the change of the external environment (I am not talking about a single brain but rather on a species level).</p>\n<p>In other words,\u00a0<em>the systematic deviation from a standard of rationality or good judgment\u00a0</em>(this is how bias is defined in psychology) is nothing more for me than a simple\u00a0<strong>evolutionary lag of our brain.</strong></p>\n<p>Why all this\u00a0<em>excursus</em>? Well, because I think that most of the biases data embed comes from our own cognitive biases (at least for data resulting from human and not natural activities). There is, of course, another block of biases which stems from pure statistical reasons (<em>the expected value is different from the true underlying estimated parameter</em>). Kris Hammond of Narrative Science merged those two views and identified\u00a0<a href=\"https://techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/\" target=\"_blank\">at least five different biases</a>\u00a0in AI. In his words:</p>\n<ul>\n<li><strong>Data-driven bias</strong>\u00a0(bias that depends on the input data used);\n<li><strong>Bias through interaction</strong>;\n<li><strong>Similarity bias</strong>\u00a0(it is simply the product of systems doing what they were designed to do);\n<li><strong>Conflicting goals bias</strong>\u00a0(systems designed for very specific business purposes end up having biases that are real but completely unforeseen);\n<li><strong>Emergent bias</strong>\u00a0(decisions made by systems aimed at personalization will end up creating bias \u201cbubbles\u201d around us).\n</li></li></li></li></li></ul>\n<p>But let\u2019s go back to the problem. How would you solve the biased data issue then?</p>\n<p>Simple solution: you can try to remove any data that could bias your engine\u00a0<em>ex-ante</em>. Great solution, it will require some effort at the beginning, but it might be feasible.</p>\n<p>However, let\u2019s look at the problem from a different angle. I was educated as an economist, so allow me to start my argument with this statement:\u00a0<strong>let\u2019s assume we have the perfect dataset</strong>. It is not only omni-comprehensive but also clean, consistent and deep both longitudinally and temporally speaking.</p>\n<p>Even in this case,\u00a0<strong>we have no guarantee AI won\u2019t learn the same bias autonomously as we did</strong>. In other words, removing biases by hand or by construction is not a guarantee of those biases to not come out again spontaneously.</p>\n<blockquote><p>We have no guarantee AI won\u2019t learn the same bias autonomously as we\u00a0did.</p></blockquote>\n<p>This possibility also raises another (philosophical) question: we are building this argument from the assumption that\u00a0<em>biases are bad</em>\u00a0(mostly). So let\u2019s say the machines come up with a result we see as biased, and therefore we reset them and start again the analysis with new data. But the machines come up with a similarly \u2018biased result\u2019. Would we then be open to accepting that as true and revision what we consider to be biased?</p>\n<p>This is basically a\u00a0<strong><em>cultural and philosophical clash between two different species</em></strong>.</p>\n<p>In other words, I believe that two of the reasons why embedding ethics into machine designing is extremely hard is that i)\u00a0<strong><em>we don\u2019t really know unanimously what ethics is</em></strong>, and ii) we should be open to admit that our values or ethics might not be completely right and that what we consider to be biased is not the exception but rather the norm.</p>\n<p>Developing a (general) AI is making us think about those problems and\u00a0<strong>it will change\u00a0</strong>(if it hasn\u2019t already started)\u00a0<strong>our values system</strong>. And perhaps, who knows, we will end up learning something from\u00a0<em>machines\u2019 ethics\u00a0</em>as well.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*pY_Q63GmcoRYViR5i11yyQ.jpeg\" width=\"99%\"/><br>\n<font size=\"-1\">Image Credit:\u00a0<a href=\"https://online.ndm.edu/\" target=\"_blank\">Notre Dame of Maryland University Online</a></font></br></center></p>\n<p>\u00a0</p>\n<h3>II. Accountability and trust</h3>\n<p>\u00a0<br/>\nWell, now you might think the previous one is a purely philosophical issue and that you probably shouldn\u2019t care about it. But the other side of the matter is about how much you\u00a0<strong>trust your algorithms</strong>. Let me give you a different perspective to practically looking at this problem.</p>\n<p>Let\u2019s assume you are a medical doctor and you use one of the many algorithms out there to help you diagnose a specific disease or to assist you in a patient treatment. In the 99.99% of the time the computer gets it right\u200a\u2014\u200aand it never gets tired, it analyzed billions of records, it sees patterns that a human eye can\u2019t perceive, we all know this story, right? But what if in the remaining o.o1% of the case your instinct tells you something opposite to the machine result and you end up to be right? What if you decide to follow the advice the machine spit out instead of yours and the patient dies? Who is liable in this case?</p>\n<p>But even worse: let\u2019s say in that case you follow your gut feeling (we know is not gut feeling though, but simply your ability to recognize at a glance something you know to be the right disease or treatment) and you save a patient. The following time (and patient), you have another conflict with the machine results but strong of the recent past experience (because of an\u00a0<em>hot-hand fallacy</em>\u00a0or an\u00a0<em>overconfidence\u00a0</em>bias) you think to be right again and decide to disregard what the artificial engine tells you. Then the patient dies. Who is liable now?</p>\n<p>The question is quite delicate indeed and the scenarios in my head are:</p>\n<p>a) a scenario where the doctor is only human with no machine assistance. The payoff here is that liability stay with him, he gets it right 70% of the time, but the things are quite clear and sometimes he gets right something extremely hard (the lucky guy out of 10,000 patients);<br/>\nb) a scenario where a machine decides and gets it right 99.99% of the time. The negative side of it is an unfortunate patient out of 10,000 is going to die because of a machine error and the liability is not assigned to either the machine or the human;<br/>\nc) a scenario the doctor is assisted but has the final call to decide whether to follow the advice. The payoff here is completely randomized and not clear to me at all.</p>\n<p>As a former economist, I have been trained to be heartless and reason in terms of expected values and big numbers (basically a\u00a0<strong>Utilitarian</strong>), therefore scenario\u00a0<em>b)</em>\u00a0looks the only possible to me because it saves the greatest number of people. But we all know is not that simple (and of course doesn\u2019t feel right for the unlucky guy of our example): think about the case, for instance, of autonomous vehicles that lose controls and need to decide if killing the driver or five random pedestrians (the famous\u00a0<strong><em>Trolley Problem</em></strong>). Based on that principles I\u2019d save the pedestrians, right? But what about all those five are criminals and the driver is a pregnant woman? Does your judgement change in that case? And again, what if the vehicle could instantly use cameras and visual sensors to recognize pedestrians\u2019 faces, connect to a central database and match them with health records finding out that they all have some type of terminal disease? You see, the line is blurring...</p>\n<p>The final doubt that remains is then not simply about liability (and the choice between pure outcomes and ways to achieve them) but rather on trusting the algorithm (and I know that for someone who studied 12 years to become doctor might not be that easy to give that up). In fact,\u00a0<a href=\"http://knowledge.wharton.upenn.edu/article/how-to-convince-people-to-trust-algorithms/\" target=\"_blank\"><strong>algorithm adversion</strong></a>\u00a0is becoming a real problem for algorithms-assisted tasks and it looks that people want to have an (even if incredibly small) degree of control over algorithms (Dietvorst et al., 2015; 2016).</p>\n<p>But above all:\u00a0<strong>are we allowed to deviate from the advice we get from accurate algorithms?\u00a0</strong>And if so, in what circumstances and to what extent?</p>\n<blockquote><p>Are we allowed to deviate from the advice we get from accurate algorithms?</p></blockquote>\n<p>If an AI would decide on the matter, it will also probably go for scenario\u00a0<em>b)</em>\u00a0but we as humans would like to find a compromise between those scenarios because we \u2018<em>ethically</em>\u2019 don\u2019t feel any of those to be right. We can rephrase then this issue under the\u00a0<strong>\u2018alignment problem\u2019\u00a0</strong>lens, which means that the goals and behaviors an AI have need to be aligned with human values\u200a\u2014\u200aan AI needs to think as a human in certain cases (but of course the question here is how do you discriminate? And what\u2019s the advantage of having an AI then? Let\u2019s therefore simply stick to the traditional human activities).</p>\n<p>In this situation, the work done by the Future of Life Institute with the\u00a0<a href=\"https://futureoflife.org/ai-principles/\" target=\"_blank\"><strong>Asilomar Principles</strong></a><strong>\u00a0</strong>becomes extremely relevant.</p>\n<p>The alignment problem, in fact, also known as \u2018<strong><em>King Midas problem</em></strong>\u2019, arises from the idea that no matter how we tune our algorithms to achieve a specific objective, we are not able to specify and frame those objectives well enough to prevent the machines to pursue undesirable ways to reach them. Of course, a theoretically viable solution would be to let the machine maximizing for our true objective without setting it\u00a0<em>ex-ante</em>, making therefore the algorithm itself free to observe us and understand what we really want (as a species and not as individuals, which might entail also the possibility of switching itself off if needed).</p>\n<p>Sounds too good to be true? Well, maybe it is. I indeed totally agree with Nicholas Davis and Thomas Philbeck from WEF that in the\u00a0<a href=\"http://reports.weforum.org/global-risks-2017/?doing_wp_cron=1499346241.9620978832244873046875\" target=\"_blank\">Global Risks Report 2017</a>\u00a0wrote:</p>\n<blockquote><p>\u201cThere are complications: humans are irrational, inconsistent, weak-willed, computationally limited and heterogeneous, all of which conspire to make learning about human values from human behaviour a difficult (and perhaps not totally desirable) enterprise\u201d.</p></blockquote>\n<p>What the previous section implicitly suggested is that not all AI applications are the same and that\u00a0<em>error rates</em>\u00a0apply differently to different industries. Under this assumption, it might be hard to draw a line and design an accountability framework that does not penalize applications with weak impact (e.g., a recommendation engine) and at the same time do not underestimate the impact of other applications (e.g,., healthcare or AVs).</p>\n<p>We might end up then designing\u00a0<strong>multiple accountability frameworks\u00a0</strong>to justify algorithmic decision-making and mitigate negative biases.</p>\n<p>Certainly, the most straightforward solution to understand who owns the liability for a certain AI tool is thinking about the following threefold classification:</p>\n<ul>\n<li><strong><em>We should hold the AI system itself as responsible for any misbehavior</em></strong>(does it make any sense?);\n<li><strong><em>We should hold the designers of the AI as responsible for the malfunctioning and bad outcome</em></strong><em>\u00a0</em>(but it might be hard because usually AI teams might count hundred of people and this preventative measure could discourage many from entering the field);\n<li><strong><em>We should hold accountable the organization running the system\u00a0</em></strong>(to me it sounds the most reasonable between the three options, but I am not sure about the implications of it. And then what company should be liable in the AI value chain? The final provider? The company who built the system in the first place? The consulting business which recommended it?).\n</li></li></li></ul>\n<p>There is not an easy answer and much more is required to tackle this issue, but I believe a good starting point has been provided by\u00a0<a href=\"https://www.technologyreview.com/s/602933/how-to-hold-algorithms-accountable/\" target=\"_blank\">Sorelle Friedler and Nicholas Diakopoulos</a>. They suggest to consider accountability through the lens of five core principles:</p>\n<ul>\n<li><strong>Responsibility</strong>: a person should be identified to deal with unexpected outcomes, not in terms of legal responsibility but rather as a single point of contact;\n<li><strong>Explainability</strong>: a decision process should be explainable not technically but rather in an accessible form to anyone;\n<li><strong>Accuracy</strong>:\u00a0<em>garbage in, garbage out</em>\u00a0is likely to be the most common reason for the lack of accuracy in a model. The data and error sources need then to be identified, logged, and benchmarked;\n<li><strong>Auditability</strong>: third parties should be able to probe and review the behavior of an algorithm;\n<li><strong>Fairness</strong>: algorithms should be evaluated for discriminatory effects.\n</li></li></li></li></li></ul>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*woLZ01BOYwj77cB_PxMjLQ.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Image Credit:\u00a0<a href=\"https://pixabay.com/en/ehr-emr-electronic-medical-record-1476525/\" target=\"_blank\">mcmurryjulie/Pixabay</a></font></center></p>\n</div> ", "website": "kdnuggets"}