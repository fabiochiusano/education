{"content": "comments By Hamel Husain \u00a0&\u00a0 Ho-Hsiang Wu , GitHub A picture of\u00a0 Hubot . \u00a0 Motivation: \u00a0 The power of modern search engines is undeniable: you can summon knowledge from the internet at a moment\u2019s notice. Unfortunately, this superpower isn\u2019t omnipresent. There are many situations where search is relegated to strict keyword search, or when the objects aren\u2019t text, search may not be available. Furthermore, strict keyword search doesn\u2019t allow the user to\u00a0 search semantically , which means information is not as discoverable. Today, we share a reproducible, minimally viable product that illustrates how you can enable\u00a0 semantic search \u00a0for arbitrary objects! Concretely, we will show you how to create a system that searches python code semantically\u200a\u2014\u200abut this approach can be generalized to other entities (such as pictures or sound clips). Why is semantic search so exciting? Consider the below example: Semantic search at work on python code. *See Disclaimer section\u00a0below. The search query presented is \u201c Ping \u00a0 REST api \u00a0and return results\u201d. However, the search returns reasonable results even though the code & comments found do not contain the words\u00a0 Ping, REST \u00a0or\u00a0 api. This illustrates the\u00a0 power of\u00a0 semantic search : we can search content for its meaning\u00a0 in addition to keywords , and maximize the chances the user will find the information they are looking for. The implications of semantic search are profound\u200a\u2014\u200afor example, such a procedure would allow developers to search for code in repositories even if they are not familiar with the syntax or fail to anticipate the right keywords. More importantly, you can generalize this approach to objects such as pictures, audio and other things that we haven\u2019t thought of yet. If this is not exciting enough,\u00a0 here is a live demonstration of what you will be able to build by the end of this tutorial : Sometimes I use Jupyter notebooks and\u00a0 custom magic functions \u00a0to create demonstrations when I cannot build a pretty website. it can be a quick way to interactively demonstrate your\u00a0work! \u00a0 Intuition\u00a0: Construct a Shared Vector-Space \u00a0 Before diving into the technical details, it is useful to provide you with a high-level intuition of how we will accomplish semantic search. The central idea is to represent both text and the object we want to search (code) in a shared vector space, as illustrated below: Example: Text 2 \u00a0and the\u00a0 code \u00a0should be represented by similar vectors since they are directly\u00a0related. The goal is to map code into the vector space of natural language, such that (text, code) pairs that describe the same concept are close neighbors, whereas unrelated (text, code) pairs are further apart, measured by\u00a0 cosine similarity . There are many ways to accomplish this goal, however, we will demonstrate the approach of taking a pre-trained model that extracts features from code and\u00a0 fine-tuning \u00a0this model to project latent code features into a vector space of natural language. One warning: We use the term\u00a0 vector \u00a0and\u00a0 embedding interchangeably \u00a0 throughout this tutorial. \u00a0 Prerequisites \u00a0 We recommend familiarity with the following items prior to reading this tutorial: Sequence-to-sequence models: \u00a0It will be helpful to review the information presented\u00a0 in a previous tutorial . Peruse\u00a0 this paper \u00a0at a high level and understand the intuition of the approach presented. We draw on similar concepts for what we present here. \u00a0 Overview: \u00a0 This tutorial will be broken into 5 concrete steps. These steps are illustrated below and will be a useful reference as you progress throughout the tutorial. After completing the tutorial, it will be useful to revisit this diagram to reinforce how all the steps fit together. A mind map of this tutorial. Hi-res version available\u00a0 here . Each step 1\u20135 corresponds to a Jupyter notebook\u00a0 here . We will explore each step in more detail below. \u00a0 Part 1\u200a\u2014\u200aAcquire and Parse\u00a0Data: \u00a0 Part 1 notebook The folks at Google collect and store data from open-source GitHub repositories on\u00a0 BigQuery . This is a great open dataset for all kinds of interesting data-science projects, including this one! When you sign up for a Google Cloud account, they give you $300 which is more than enough to query the data for this exercise. Getting this data is super convenient, as you can use SQL queries to select what type of files you are looking for as well as other meta-data about repos such as commits, stars, etc. The steps to acquire this data are outlined in this\u00a0 notebook . Luckily,\u00a0 some awesome people on the Kubeflow team at Google \u00a0have gone through these steps and have graciously hosted the data for this exercise, which is also described in this\u00a0 notebook . After collecting this data, we need to parse these files into (code,\u00a0 docstring ) pairs. For this tutorial, one unit of code will be either a\u00a0 top-level function \u00a0or a method. We want to gather these pairs as training data for a model that will summarize code (more on that later). We also want to strip the code of all comments and only retain the code. This might seem like a daunting task, however, there is an amazing library called\u00a0 ast \u00a0in Python\u2019s standard library that can be used to extract functions, methods and, docstrings. We can remove comments from code by converting code into an\u00a0 AST \u00a0and then back from that representation to code, using the\u00a0 Astor \u00a0package. Understanding of ASTs or how these tools work is not required for this tutorial, but are very interesting topics! For more context of how this code is used, see this\u00a0 notebook . To prepare this data for modeling, we separate the data into train, validation and test sets. We also maintain files (which we name \u201clineage\u201d) to keep track of the original source of each (code, docstring) pair. Finally, we apply the same transforms to code that does not contain a docstring and save that separately, as we will want the ability to search this code as well! \u00a0 Part 2\u200a\u2014\u200aBuild a Code Summarizer Using a Seq2Seq\u00a0Model: \u00a0 Part 2 notebook Conceptually, building a sequence-to-sequence model to summarize code is identical to the\u00a0 GitHub issue summarizer \u00a0we presented previously\u200a\u2014\u200ainstead of issue bodies we use python code, and instead of issue titles, we use docstrings. However, unlike GitHub issue text, code is not natural language. To fully exploit the information within code, we could introduce domain-specific optimizations like\u00a0 tree-based LSTMs \u00a0and syntax-aware tokenization. For this tutorial, we are going to keep things simple and treat code like natural language (and still get reasonable results). Building a function summarizer is a very cool project on its own, but we aren\u2019t going to spend too much time focusing on this (but we encourage you to do so!). The entire end-to-end training procedure for this model is described in\u00a0 this notebook . We do not discuss the pre-processing or architecture for this model as it is identical to the\u00a0 issue summarizer . Our motivation for training this model is not to use it for the task of summarizing code, but rather as a general purpose feature extractor for code. Technically speaking, this step is optional as we are only going through these steps to initialize the model weights for a related downstream task. In a later step, we will extract the encoder from this model and\u00a0 fine tune \u00a0it for another task. Below is a screenshot of some example outputs of this model: Sample results from function summarizer on a test set. See notebook\u00a0 here . We can see that while the results aren\u2019t perfect, there is strong evidence that the model has learned to extract some semantic meaning from code, which is our main goal for this task. We can evaluate these models quantitatively using the\u00a0 BLEU metric , which is also discussed in this\u00a0 notebook . It should be noted that training a seq2seq model to summarize code is not the only technique you can use to build a feature extractor for code. For example, you could also train a\u00a0 GAN \u00a0and\u00a0 use the discriminator as a feature extractor . However, these other approaches are outside the scope of this tutorial.", "title_html": "<h1 id=\"title\">How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning</h1> ", "url": "https://www.kdnuggets.com/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html", "tfidf": {"tfidf": {"after": 2.04140414042, "semant": 351.9310344831, "googl": 34.166427546600005, "implic": 7.632692307689999, "unlik": 2.42529789184, "too": 1.81585268215, "relat": 2.47501753838, "fit": 3.37070063694, "vector": 129.494290375, "domainspecif": 1587.6, "repo": 369.209302326, "kind": 2.5806241872599998, "vectorspac": 1587.6, "space": 7.19456193354, "addit": 1.24634950542, "would": 1.0828729281799998, "follow": 1.04640126549, "screenshot": 396.9, "etc": 4.2066772655, "dataset": 193.609756098, "sequencetosequ": 3175.2, "function": 12.477208424999999, "draw": 2.97247706422, "progress": 2.44697903822, "python": 225.1914893616, "thought": 1.9854927463699998, "well": 2.1311497416, "product": 1.62264922322, "work": 3.34560269739, "complet": 1.24021560816, "approach": 10.37782716695, "technic": 6.280063291139999, "retain": 2.74956702459, "motiv": 10.03222748816, "summon": 14.4327272727, "cosin": 193.609756098, "creat": 2.4985835694, "summar": 135.9505233108, "how": 9.61501968306, "test": 5.31414225942, "strip": 5.50485436893, "present": 6.27758007115, "discrimin": 10.6981132075, "origin": 1.13724928367, "high": 1.14777327935, "initi": 1.35, "end": 1.10680423871, "found": 1.11387076405, "word": 1.7965372864099998, "interest": 3.20662492426, "tutori": 713.5280898876, "will": 17.14735380344, "exploit": 5.79416058394, "consid": 1.2397313759200002, "hubot": 1587.6, "lineag": 19.7462686567, "purpos": 2.23416830847, "below": 13.53645019182, "similar": 4.12542226071, "but": 5.0816208949499995, "demonstr": 10.59989984976, "need": 1.4372623574099999, "our": 4.71517671518, "commit": 2.8860207235, "final": 1.34008609775, "unrel": 15.7813121272, "tune": 10.4173228346, "amaz": 15.250720461099998, "review": 2.2099109131400003, "level": 1.6544393497299998, "has": 1.0436497502, "have": 2.0297896822799997, "also": 5.07382550335, "use": 16.474220118079998, "sound": 3.11294117647, "model": 33.4495654464, "wherea": 4.13868613139, "treat": 3.59023066486, "excit": 19.636363636360002, "concept": 5.31414225942, "titl": 1.87261146497, "introduc": 1.7258397651900002, "undeni": 95.6385542169, "bigqueri": 1587.6, "optim": 11.5377906977, "warn": 4.334152334150001, "daunt": 102.425806452, "store": 3.44680851064, "audio": 9.05647461495, "not": 12.18808777428, "arbitrari": 17.8181818182, "version": 2.0083491461099996, "perus": 387.219512195, "superpow": 49.457943925200006, "minim": 6.10850327049, "quick": 2.205, "jupyt": 3175.2, "metric": 22.235294117600002, "than": 1.03278688525, "then": 1.08657860516, "separ": 3.2024205748799996, "they": 4.12069301148, "anoth": 1.13643521832, "techniqu": 3.7293868921800004, "revisit": 19.5276752768, "section": 2.1284354471099998, "construct": 1.9320920043799998, "clip": 15.1344137274, "internet": 4.98461538462, "item": 5.07869481766, "simpl": 3.3981164383599998, "provid": 1.21552714187, "downstream": 41.889182058, "either": 1.5830092731099998, "develop": 1.1955719557200002, "such": 5.3075688687, "explor": 3.39593582888, "conveni": 9.85474860335, "some": 3.1211009174399997, "sourc": 1.69760479042, "should": 3.3286508019800003, "both": 1.05215720061, "super": 7.380753138080001, "result": 5.7305804216, "gracious": 88.2, "content": 3.5421686747, "repositori": 89.94900849860001, "languag": 9.17953165656, "set": 2.37415881562, "from": 8.00453771976, "awesom": 108.0, "dive": 16.085106383, "detail": 4.52372132782, "num": 7.00220528007, "veri": 2.51760228354, "aren": 1443.2727272729999, "idea": 2.0930784443, "acquir": 6.21126760564, "for": 27.008506080270003, "broken": 4.46959459459, "output": 7.676982591880001, "fulli": 2.79015817223, "with": 3.003594626969999, "are": 15.4485890367, "speak": 2.89127663449, "viabl": 16.1834862385, "folk": 7.6658619024600005, "preprocess": 1221.23076923, "look": 3.8172637653199994, "hohsiang": 1587.6, "option": 4.04896710023, "account": 1.94463498285, "furthermor": 5.50294627383, "chanc": 4.2449197861000005, "extract": 30.812227074240003, "num\u2013num": 1587.6, "pars": 291.302752294, "later": 2.17300848618, "focus": 2.01012914662, "familiar": 13.72762645914, "remov": 2.0058117498400003, "map": 8.145715751660001, "doe": 1.70581282905, "even": 2.32922535212, "give": 1.3653250774, "valid": 6.61224489796, "scope": 10.3494132986, "part": 4.17322731156, "train": 11.6194193706, "great": 1.26592775696, "hamel": 311.294117647, "bodi": 1.8618505922400002, "step": 28.279301745599994, "comment": 12.23819618424, "note": 1.42449528937, "reinforc": 6.453658536590001, "thing": 4.813096862219999, "notebook": 401.924050633, "reproduc": 12.6805111821, "paper": 2.6628648104700003, "prior": 2.17807655371, "hire": 4.95815115553, "through": 2.14149861738, "lstms": 1587.6, "requir": 1.52844902282, "what": 3.7603031738399997, "allow": 2.5432118542200004, "fine": 4.02229541424, "help": 1.39962972759, "main": 1.25303867403, "measur": 2.41093394077, "find": 1.7294117647099998, "instead": 3.18923262354, "abil": 2.70875277256, "astor": 101.121019108, "moment": 4.262013422819999, "own": 1.17844418052, "though": 1.36076112111, "natur": 6.1570680628400005, "pictur": 10.486129458390002, "here": 12.1153846154, "quantit": 27.803852889699996, "github": 6350.4, "apart": 3.1032056294, "docstr": 7938.0, "much": 1.1942229577299999, "evalu": 6.9509632224199995, "contain": 3.19629555064, "about": 1.06486015159, "evid": 2.24872521246, "mind": 3.5918552036199998, "context": 4.25972632144, "extractor": 898.641509433, "entir": 1.59365589239, "anticip": 7.793814432989999, "featur": 7.6356290881, "topic": 5.457545548300001, "type": 2.0281042411900003, "exercis": 9.47255369928, "finetun": 1587.6, "recommend": 3.9142011834300003, "where": 1.06715063521, "live": 1.30591428806, "save": 2.8178913737999998, "tool": 4.99716713881, "intuit": 83.1204188481, "enabl": 3.5421686747, "ping": 220.5, "latent": 66.42677824270001, "keep": 4.08490930142, "maintain": 1.77306231852, "standard": 1.8915763135900003, "prerequisit": 50.5605095541, "central": 1.6121039805000001, "track": 3.1276595744700004, "abl": 1.8208510150200001, "mani": 2.08853515754, "appli": 2.2972073506, "the": 59.0, "goal": 9.84456386937, "build": 9.805043746800001, "seem": 2.29123971713, "pretrain": 1587.6, "select": 2.02345144022, "team": 2.2748244734200003, "unfortun": 9.966101694919999, "neighbor": 5.781500364169999, "same": 2.23715916296, "throughout": 3.0434199175599996, "togeth": 1.58095996813, "there": 4.16365066876, "endtoend": 1587.6, "inform": 6.301250248080001, "repres": 2.93945565636, "right": 1.4054532577899999, "spend": 4.15928739848, "illustr": 14.645756457560001, "star": 2.4450947173900004, "knowledg": 3.3981164383599998, "take": 1.13961668222, "previous": 2.85693719632, "profound": 11.219787985899998, "might": 2.1561863370900003, "further": 1.3618116315, "name": 1.10211732037, "code": 131.94426790528, "strict": 9.4471883368, "interact": 4.4185917061, "represent": 5.928304705, "haven": 12.690647482000001, "unit": 1.15394679459, "power": 2.6792675723599997, "issu": 7.19608376395, "cloud": 10.6193979933, "modern": 1.5319888063299998, "mean": 4.34720700987, "into": 7.10517230353, "notic": 4.36994219653, "task": 19.43206854345, "accomplish": 10.34604105572, "overview": 12.6805111821, "may": 1.05201775893, "discover": 77.443902439, "peopl": 1.21320495186, "datasci": 1587.6, "open": 1.24556723678, "encourag": 2.7975330396499998, "want": 7.98792452832, "convert": 3.2740771293099997, "concret": 20.0201765448, "system": 1.38739840951, "howev": 5.4725956566499985, "share": 5.56987486845, "gone": 5.22408687068, "token": 33.7070063694, "disclaim": 98.6086956522, "maxim": 12.928338762200001, "entiti": 6.89361702128, "which": 6.03115107, "term": 1.39520168732, "ident": 5.61584718784, "other": 4.03969465648, "refer": 1.30024570025, "procedur": 11.738262476900001, "one": 3.01882487166, "show": 1.26703910615, "custom": 3.6346153846199996, "see": 5.08968502044, "diagram": 22.1731843575, "whi": 3.2566153846200003, "highlevel": 1587.6, "get": 3.5712518277, "still": 1.1866357724799999, "like": 3.44755700325, "outsid": 1.67450690855, "collect": 3.28219971056, "file": 11.313064133009998, "opensourc": 1587.6, "kubeflow": 1587.6, "transform": 3.42007755278, "yet": 2.1258703802900003, "outlin": 6.38102893891, "includ": 1.0190641247799999, "sign": 1.7606742819099999, "cool": 6.8578833693300005, "omnipres": 129.073170732, "gather": 3.78631051753, "this": 42.15933232182, "pretti": 15.75, "sampl": 7.23280182232, "time": 1.01127460348, "api": 168.89361702120001, "engin": 2.47135740971, "back": 1.26070038911, "conceptu": 17.6792873051, "project": 5.2604373757500005, "embed": 16.835630965, "syntaxawar": 1587.6, "interchang": 13.793223284100002, "releg": 24.3870967742, "magic": 7.9063745019899985, "return": 2.79064862014, "fail": 1.9281029876099998, "all": 3.03440366973, "syntax": 45.6206896552, "today": 1.74961428257, "situat": 2.06611140031, "strong": 1.6439888163999998, "metadata": 211.68, "that": 15.059760956249999, "pair": 21.84369840395, "weight": 4.878918254459999, "architectur": 5.12790697674, "call": 1.0676529926, "object": 9.395472703080001, "more": 5.085853408499999, "and": 24.001511811119997, "correspond": 3.32481675393, "ast": 214.54054054, "discuss": 4.39352428394, "these": 8.59323410016, "prepar": 2.43012398592, "keyword": 557.05263158, "general": 3.3654607122600004, "websit": 2.52160101652, "could": 2.4087391898, "befor": 1.10036041031, "librari": 5.3653261237, "close": 1.2848818387799998, "can": 15.29139808846, "avail": 3.4576935642, "describ": 4.41081681792, "encod": 29.0237659963, "queri": 168.8936170212, "way": 2.4381478922, "search": 61.82496413196999, "onli": 3.0769429549800007, "each": 3.56924460432, "read": 2.3149606299200003, "packag": 7.828402366860001, "data": 33.7643555934, "method": 5.1428571428600005, "perfect": 4.48601299802, "rather": 1.55692850838, "sinc": 1.08368600683, "sometim": 1.7126213592200001, "exampl": 7.5241706161, "husain": 248.0625, "toplevel": 1587.6, "text": 18.769655172420002, "understand": 5.93717277486, "treebas": 1587.6, "direct": 1.22226499346, "import": 1.3401992233700002, "luckili": 191.277108434, "enough": 4.463939266140001, "while": 1.0441988950299999, "host": 2.7092150170599996, "reason": 3.44680851064, "user": 15.4210781933, "within": 1.2369302688, "learn": 2.32275054865, "when": 3.0623030926499997, "seqnumseq": 3175.2}, "logtfidf": {"after": 0.040981389296199995, "semant": 32.9958958887, "googl": 7.29789366774, "implic": 2.03244064121, "unlik": 0.885954358842, "too": 0.5965551547219999, "relat": 0.42620060330799997, "fit": 1.2151206268899999, "vector": 16.27099438985, "domainspecif": 7.369978720910001, "repo": 5.91136369821, "kind": 0.948031302717, "vectorspac": 7.369978720910001, "space": 2.624139494916, "addit": 0.220218882972, "would": 0.0796176279647, "follow": 0.045356911094199995, "screenshot": 5.98368435979, "etc": 1.4366730879700003, "dataset": 5.26584456664, "sequencetosequ": 14.739957441820001, "function": 4.57232870797, "draw": 1.0893956335600001, "progress": 0.894854218108, "python": 16.12262697184, "thought": 0.685867118283, "well": 0.1270288766312, "product": 0.484060136536, "work": 0.327103701819, "complet": 0.215285242047, "approach": 3.6511680729050005, "technic": 2.28846575616, "retain": 1.0114434536799999, "motiv": 3.22531095864, "summon": 2.66949835512, "cosin": 5.26584456664, "creat": 0.445153637028, "summar": 24.435597987269997, "how": 2.8294017415800004, "test": 1.954448874206, "strip": 1.7056303155, "present": 1.137733273995, "discrimin": 2.37006739018, "origin": 0.128612437587, "high": 0.13782378654000002, "initi": 0.30010459245, "end": 0.101476798618, "found": 0.107841124048, "word": 0.585861082385, "interest": 0.9441435559639999, "tutori": 49.023781866, "will": 2.83901148881, "exploit": 1.7568506145200002, "consid": 0.214894723824, "hubot": 7.369978720910001, "lineag": 2.98296454472, "purpos": 0.803869037322, "below": 4.881759551616, "similar": 0.9556682763419999, "but": 0.0809618603595, "demonstr": 3.8982007672759997, "need": 0.362740163442, "our": 1.7152784283640001, "commit": 1.0598786410299998, "final": 0.292733863948, "unrel": 2.75882646324, "tune": 2.3434700776599997, "amaz": 2.7246267452900006, "review": 0.7929522039210001, "level": 0.503462189943, "has": 0.0427239448548, "have": 0.0295700046824, "also": 0.073285789, "use": 0.4673283157056, "sound": 1.13556799519, "model": 11.799201169776001, "wherea": 1.4203783778999999, "treat": 1.27821645249, "excit": 4.56847190866, "concept": 1.954448874206, "titl": 0.6273339619899999, "introduc": 0.5457137524260001, "undeni": 4.56057602555, "bigqueri": 7.369978720910001, "optim": 2.4456277954099996, "warn": 1.4665260511200002, "daunt": 4.62913869698, "store": 1.2374487335200002, "audio": 2.2034799289800002, "not": 0.18662895609, "arbitrari": 2.88021938643, "version": 0.697313064259, "perus": 5.958991747200001, "superpow": 3.9011226907699994, "minim": 1.80968177926, "quick": 0.790727508899, "jupyt": 14.739957441820001, "metric": 3.1016808515599994, "than": 0.0322608622182, "then": 0.08303386523089999, "separ": 0.941519545898, "they": 0.1189079790704, "anoth": 0.127896361652, "techniqu": 1.31624384807, "revisit": 2.9718327043599997, "section": 0.755387177948, "construct": 0.658603355972, "clip": 2.71697120551, "internet": 1.6063562459, "item": 1.62505430292, "simpl": 1.2232212893899999, "provid": 0.19517784432500002, "downstream": 3.73502760882, "either": 0.459327638815, "develop": 0.178624694913, "such": 0.29847988903, "explor": 1.22257937218, "conveni": 2.28795343073, "some": 0.11872052719350001, "sourc": 0.529218310751, "should": 1.018839753516, "both": 0.050842533389300004, "super": 1.9988756846400002, "result": 0.681894541905, "gracious": 4.47960696301, "content": 1.26473915954, "repositori": 7.612191513939999, "languag": 3.3227272976239997, "set": 0.342992022578, "from": 0.004536433350928, "awesom": 4.682131227119999, "dive": 2.7778937744700003, "detail": 1.632375554346, "num": 0.0022049327677790003, "veri": 0.460319586476, "aren": 18.52816875732, "idea": 0.73863592212, "acquir": 2.2664356356999997, "for": 0.008504740675719002, "broken": 1.49729770979, "output": 2.03822657827, "fulli": 1.02609828678, "with": 0.00359247514017, "are": 0.4420121037405, "speak": 1.06169814662, "viabl": 2.7839913543400003, "folk": 2.03677695251, "preprocess": 7.1076144564399995, "look": 1.2927733872, "hohsiang": 7.369978720910001, "option": 1.39846181161, "account": 0.665074289973, "furthermor": 1.70528363496, "chanc": 1.44572292349, "extract": 8.16646893204, "num\u2013num": 7.369978720910001, "pars": 9.962431863339999, "later": 0.1659308519756, "focus": 0.6981989720559999, "familiar": 3.85252630334, "remov": 0.6960488415880001, "map": 2.80868986768, "doe": 0.5340417297169999, "even": 0.304777129668, "give": 0.311392552224, "valid": 1.8889232176800002, "scope": 2.33692983198, "part": 0.16958124393120003, "train": 3.965509877034, "great": 0.235805258079, "hamel": 5.74073818118, "bodi": 0.6215709351609999, "step": 10.3954505698, "comment": 4.47307013816, "note": 0.353817568083, "reinforc": 1.86464718498, "thing": 1.7563870693599999, "notebook": 36.93678049, "reproduc": 2.54006626224, "paper": 0.979402539665, "prior": 0.778442172521, "hire": 1.60103292035, "through": 0.1367173837698, "lstms": 7.369978720910001, "requir": 0.424253510675, "what": 0.677661890481, "allow": 0.48056122237800003, "fine": 1.39185273824, "help": 0.336207721344, "main": 0.225571540588, "measur": 0.880014199726, "find": 0.547781330288, "instead": 0.9332663008300001, "abil": 0.996488297427, "astor": 4.61631800855, "moment": 1.4497416830899998, "own": 0.164195077421, "though": 0.308044191079, "natur": 1.725225357168, "pictur": 3.75432327372, "here": 4.42519094185, "quantit": 3.3251746042500003, "github": 29.479914883640003, "apart": 1.1324356512, "docstr": 36.849893604550005, "much": 0.17749572930100002, "evalu": 1.9388802431299998, "contain": 0.937690636472, "about": 0.0628434774746, "evid": 0.8103634834160001, "mind": 1.2786688388299998, "context": 1.44920491442, "extractor": 17.10681570105, "entir": 0.46603068026999994, "anticip": 2.05333039768, "featur": 2.11693709071, "topic": 1.6969991554100001, "type": 0.707101485387, "exercis": 3.1105027046, "finetun": 7.369978720910001, "recommend": 1.36461126863, "where": 0.0649921387457, "live": 0.266903399347, "save": 1.03598886547, "tool": 1.60887117963, "intuit": 9.965034291570001, "enabl": 1.26473915954, "ping": 9.40550102866, "latent": 4.19610026197, "keep": 1.4283046893459999, "maintain": 0.572708175102, "standard": 0.63741050982, "prerequisit": 3.9231708279900004, "central": 0.477540146039, "track": 1.14028498507, "abl": 0.599303982475, "mani": 0.0866315162442, "appli": 0.8316941898119999, "the": 0.0, "goal": 3.56492136819, "build": 2.9468247125460003, "seem": 0.829093032276, "pretrain": 7.369978720910001, "select": 0.704804687133, "team": 0.821902894886, "unfortun": 2.29918950399, "neighbor": 1.7546632275799998, "same": 0.224119299208, "throughout": 0.8396693508699999, "togeth": 0.458032237308, "there": 0.160391571702, "endtoend": 7.369978720910001, "inform": 1.817814818648, "repres": 0.7701544655, "right": 0.34035985417, "spend": 1.42534376116, "illustr": 5.1914250831199995, "star": 0.8940838613940001, "knowledg": 1.2232212893899999, "take": 0.130691962197, "previous": 0.713205920126, "profound": 2.41767900383, "might": 0.7683410765340001, "further": 0.308815895297, "name": 0.09723316638430002, "code": 46.104649262980004, "strict": 3.10513997236, "interact": 1.4858210267899998, "represent": 1.7797382876499999, "haven": 2.54086530344, "unit": 0.143188061817, "power": 0.58479256543, "issu": 1.82049521967, "cloud": 2.36268232808, "modern": 0.426566764719, "mean": 1.11276385056, "into": 0.1043900426009, "notic": 1.47474978168, "task": 6.78743403305, "accomplish": 3.28691351856, "overview": 2.54006626224, "may": 0.050709995284400004, "discover": 4.34955383476, "peopl": 0.193265578473, "datasci": 7.369978720910001, "open": 0.219591038029, "encourag": 1.02873797155, "want": 2.7665464250199996, "convert": 1.1860360368, "concret": 4.607186823419999, "system": 0.327430345585, "howev": 0.4515755867375, "share": 1.8562808992409998, "gone": 1.65328002099, "token": 3.5177057198900004, "disclaim": 4.591159448919999, "maxim": 2.5594217052, "entiti": 1.93059591408, "which": 0.03107048307258, "term": 0.33303898354600003, "ident": 2.0648905513, "other": 0.03949899167904, "refer": 0.262553246798, "procedur": 3.53941324524, "one": 0.0187660549365, "show": 0.236682766013, "custom": 1.2905032964799998, "see": 0.963686341968, "diagram": 3.09888364694, "whi": 1.18068843047, "highlevel": 7.369978720910001, "get": 1.159538011564, "still": 0.17112222142900002, "like": 0.417160729635, "outsid": 0.515518738985, "collect": 0.99073332104, "file": 3.9820376616899997, "opensourc": 7.369978720910001, "kubeflow": 7.369978720910001, "transform": 1.22966322707, "yet": 0.754181309241, "outlin": 1.85332936004, "includ": 0.0188846813905, "sign": 0.565696850403, "cool": 1.9253988473800001, "omnipres": 4.860379458530001, "gather": 1.3313920667299999, "this": 0.15903086020499999, "pretti": 2.75684036527, "sampl": 1.9786264883900002, "time": 0.0112115188626, "api": 8.87224370214, "engin": 0.904767558276, "back": 0.23166743089699998, "conceptu": 2.8723937456, "project": 1.684805657721, "embed": 2.82349753127, "syntaxawar": 7.369978720910001, "interchang": 2.62417740518, "releg": 3.1940541716900004, "magic": 2.06766933309, "return": 0.666253737184, "fail": 0.656536611573, "all": 0.03420789629339999, "syntax": 3.8203613341300007, "today": 0.559395353679, "situat": 0.725668290015, "strong": 0.49712549393600003, "metadata": 5.35507570037, "that": 0.059642225694599996, "pair": 7.37237282475, "weight": 1.58492352612, "architectur": 1.63469757919, "call": 0.0654627744488, "object": 3.415734339212, "more": 0.08512465799999999, "and": 0.0015117634095264, "correspond": 1.20141456099, "ast": 9.35070308028, "discuss": 1.57396904524, "these": 0.5722689552064, "prepar": 0.8879422790620001, "keyword": 19.74546146204, "general": 0.344857734189, "websit": 0.924894023806, "could": 0.37191254458000006, "befor": 0.0956377718795, "librari": 1.973619961886, "close": 0.250666759864, "can": 2.110434253122, "avail": 1.094909172578, "describ": 1.156342809375, "encod": 3.36811501148, "queri": 12.09197022888, "way": 0.39618301987000004, "search": 22.417496827709996, "onli": 0.0759728049873, "each": 0.521225067912, "read": 0.83939268088, "packag": 2.0577584491900005, "data": 12.168205848, "method": 1.888923217682, "perfect": 1.50096433356, "rather": 0.442714975539, "sinc": 0.0803681994577, "sometim": 0.538025155343, "exampl": 2.0434133749949996, "husain": 5.51368073054, "toplevel": 7.369978720910001, "text": 6.84289205994, "understand": 2.1761717513599996, "treebas": 7.369978720910001, "direct": 0.200705689496, "import": 0.292818277066, "luckili": 5.25372320611, "enough": 1.605768878338, "while": 0.04324998379380001, "host": 0.996658931332, "reason": 1.088603105924, "user": 4.08517621376, "within": 0.21263272059799998, "learn": 0.842752064745, "when": 0.0616649665752, "seqnumseq": 14.739957441820001}, "logidf": {"after": 0.020490694648099998, "semant": 3.6662106543, "googl": 2.43263122258, "implic": 2.03244064121, "unlik": 0.885954358842, "too": 0.5965551547219999, "relat": 0.21310030165399999, "fit": 1.2151206268899999, "vector": 3.25419887797, "domainspecif": 7.369978720910001, "repo": 5.91136369821, "kind": 0.948031302717, "vectorspac": 7.369978720910001, "space": 0.874713164972, "addit": 0.220218882972, "would": 0.0796176279647, "follow": 0.045356911094199995, "screenshot": 5.98368435979, "etc": 1.4366730879700003, "dataset": 5.26584456664, "sequencetosequ": 7.369978720910001, "function": 0.914465741594, "draw": 1.0893956335600001, "progress": 0.894854218108, "python": 4.03065674296, "thought": 0.685867118283, "well": 0.0635144383156, "product": 0.484060136536, "work": 0.109034567273, "complet": 0.215285242047, "approach": 0.7302336145810001, "technic": 1.14423287808, "retain": 1.0114434536799999, "motiv": 1.61265547932, "summon": 2.66949835512, "cosin": 5.26584456664, "creat": 0.222576818514, "summar": 2.7150664430299996, "how": 0.47156695693000006, "test": 0.977224437103, "strip": 1.7056303155, "present": 0.227546654799, "discrimin": 2.37006739018, "origin": 0.128612437587, "high": 0.13782378654000002, "initi": 0.30010459245, "end": 0.101476798618, "found": 0.107841124048, "word": 0.585861082385, "interest": 0.47207177798199995, "tutori": 4.0853151555, "will": 0.202786534915, "exploit": 1.7568506145200002, "consid": 0.214894723824, "hubot": 7.369978720910001, "lineag": 2.98296454472, "purpos": 0.803869037322, "below": 0.813626591936, "similar": 0.318556092114, "but": 0.0161923720719, "demonstr": 0.9745501918189999, "need": 0.362740163442, "our": 0.8576392141820001, "commit": 1.0598786410299998, "final": 0.292733863948, "unrel": 2.75882646324, "tune": 2.3434700776599997, "amaz": 2.7246267452900006, "review": 0.7929522039210001, "level": 0.503462189943, "has": 0.0427239448548, "have": 0.0147850023412, "also": 0.0146571578, "use": 0.0292080197316, "sound": 1.13556799519, "model": 0.7374500731110001, "wherea": 1.4203783778999999, "treat": 1.27821645249, "excit": 2.28423595433, "concept": 0.977224437103, "titl": 0.6273339619899999, "introduc": 0.5457137524260001, "undeni": 4.56057602555, "bigqueri": 7.369978720910001, "optim": 2.4456277954099996, "warn": 1.4665260511200002, "daunt": 4.62913869698, "store": 1.2374487335200002, "audio": 2.2034799289800002, "not": 0.0155524130075, "arbitrari": 2.88021938643, "version": 0.697313064259, "perus": 5.958991747200001, "superpow": 3.9011226907699994, "minim": 1.80968177926, "quick": 0.790727508899, "jupyt": 7.369978720910001, "metric": 3.1016808515599994, "than": 0.0322608622182, "then": 0.08303386523089999, "separ": 0.470759772949, "they": 0.0297269947676, "anoth": 0.127896361652, "techniqu": 1.31624384807, "revisit": 2.9718327043599997, "section": 0.755387177948, "construct": 0.658603355972, "clip": 2.71697120551, "internet": 1.6063562459, "item": 1.62505430292, "simpl": 1.2232212893899999, "provid": 0.19517784432500002, "downstream": 3.73502760882, "either": 0.459327638815, "develop": 0.178624694913, "such": 0.059695977806, "explor": 1.22257937218, "conveni": 2.28795343073, "some": 0.0395735090645, "sourc": 0.529218310751, "should": 0.509419876758, "both": 0.050842533389300004, "super": 1.9988756846400002, "result": 0.136378908381, "gracious": 4.47960696301, "content": 1.26473915954, "repositori": 3.8060957569699996, "languag": 0.8306818244059999, "set": 0.171496011289, "from": 0.000567054168866, "awesom": 4.682131227119999, "dive": 2.7778937744700003, "detail": 0.816187777173, "num": 0.00031499039539700004, "veri": 0.230159793238, "aren": 6.17605625244, "idea": 0.73863592212, "acquir": 1.1332178178499999, "for": 0.00031499039539700004, "broken": 1.49729770979, "output": 2.03822657827, "fulli": 1.02609828678, "with": 0.00119749171339, "are": 0.0294674735827, "speak": 1.06169814662, "viabl": 2.7839913543400003, "folk": 2.03677695251, "preprocess": 7.1076144564399995, "look": 0.6463866936, "hohsiang": 7.369978720910001, "option": 1.39846181161, "account": 0.665074289973, "furthermor": 1.70528363496, "chanc": 1.44572292349, "extract": 2.04161723301, "num\u2013num": 7.369978720910001, "pars": 4.9812159316699995, "later": 0.0829654259878, "focus": 0.6981989720559999, "familiar": 1.92626315167, "remov": 0.6960488415880001, "map": 1.40434493384, "doe": 0.5340417297169999, "even": 0.152388564834, "give": 0.311392552224, "valid": 1.8889232176800002, "scope": 2.33692983198, "part": 0.04239531098280001, "train": 0.660918312839, "great": 0.235805258079, "hamel": 5.74073818118, "bodi": 0.6215709351609999, "step": 1.03954505698, "comment": 1.11826753454, "note": 0.353817568083, "reinforc": 1.86464718498, "thing": 0.8781935346799999, "notebook": 3.693678049, "reproduc": 2.54006626224, "paper": 0.979402539665, "prior": 0.778442172521, "hire": 1.60103292035, "through": 0.0683586918849, "lstms": 7.369978720910001, "requir": 0.424253510675, "what": 0.225887296827, "allow": 0.24028061118900002, "fine": 1.39185273824, "help": 0.336207721344, "main": 0.225571540588, "measur": 0.880014199726, "find": 0.547781330288, "instead": 0.46663315041500003, "abil": 0.996488297427, "astor": 4.61631800855, "moment": 1.4497416830899998, "own": 0.164195077421, "though": 0.308044191079, "natur": 0.431306339292, "pictur": 1.25144109124, "here": 0.8850381883700001, "quantit": 3.3251746042500003, "github": 7.369978720910001, "apart": 1.1324356512, "docstr": 7.369978720910001, "much": 0.17749572930100002, "evalu": 1.9388802431299998, "contain": 0.468845318236, "about": 0.0628434774746, "evid": 0.8103634834160001, "mind": 1.2786688388299998, "context": 1.44920491442, "extractor": 5.7022719003499995, "entir": 0.46603068026999994, "anticip": 2.05333039768, "featur": 0.423387418142, "topic": 1.6969991554100001, "type": 0.707101485387, "exercis": 1.5552513523, "finetun": 7.369978720910001, "recommend": 1.36461126863, "where": 0.0649921387457, "live": 0.266903399347, "save": 1.03598886547, "tool": 1.60887117963, "intuit": 3.3216780971900004, "enabl": 1.26473915954, "ping": 4.70275051433, "latent": 4.19610026197, "keep": 0.7141523446729999, "maintain": 0.572708175102, "standard": 0.63741050982, "prerequisit": 3.9231708279900004, "central": 0.477540146039, "track": 1.14028498507, "abl": 0.599303982475, "mani": 0.0433157581221, "appli": 0.8316941898119999, "the": 0.0, "goal": 1.18830712273, "build": 0.491137452091, "seem": 0.829093032276, "pretrain": 7.369978720910001, "select": 0.704804687133, "team": 0.821902894886, "unfortun": 2.29918950399, "neighbor": 1.7546632275799998, "same": 0.112059649604, "throughout": 0.41983467543499997, "togeth": 0.458032237308, "there": 0.0400978929255, "endtoend": 7.369978720910001, "inform": 0.454453704662, "repres": 0.38507723275, "right": 0.34035985417, "spend": 1.42534376116, "illustr": 1.2978562707799999, "star": 0.8940838613940001, "knowledg": 1.2232212893899999, "take": 0.130691962197, "previous": 0.356602960063, "profound": 2.41767900383, "might": 0.7683410765340001, "further": 0.308815895297, "name": 0.09723316638430002, "code": 1.35601909597, "strict": 1.55256998618, "interact": 1.4858210267899998, "represent": 1.7797382876499999, "haven": 2.54086530344, "unit": 0.143188061817, "power": 0.292396282715, "issu": 0.364099043934, "cloud": 2.36268232808, "modern": 0.426566764719, "mean": 0.37092128352, "into": 0.0149128632287, "notic": 1.47474978168, "task": 1.35748680661, "accomplish": 1.64345675928, "overview": 2.54006626224, "may": 0.050709995284400004, "discover": 4.34955383476, "peopl": 0.193265578473, "datasci": 7.369978720910001, "open": 0.219591038029, "encourag": 1.02873797155, "want": 0.6916366062549999, "convert": 1.1860360368, "concret": 2.3035934117099996, "system": 0.327430345585, "howev": 0.0903151173475, "share": 0.618760299747, "gone": 1.65328002099, "token": 3.5177057198900004, "disclaim": 4.591159448919999, "maxim": 2.5594217052, "entiti": 1.93059591408, "which": 0.00517841384543, "term": 0.33303898354600003, "ident": 1.03244527565, "other": 0.00987474791976, "refer": 0.262553246798, "procedur": 1.76970662262, "one": 0.0062553516455, "show": 0.236682766013, "custom": 1.2905032964799998, "see": 0.240921585492, "diagram": 3.09888364694, "whi": 1.18068843047, "highlevel": 7.369978720910001, "get": 0.579769005782, "still": 0.17112222142900002, "like": 0.139053576545, "outsid": 0.515518738985, "collect": 0.49536666052, "file": 1.32734588723, "opensourc": 7.369978720910001, "kubeflow": 7.369978720910001, "transform": 1.22966322707, "yet": 0.754181309241, "outlin": 1.85332936004, "includ": 0.0188846813905, "sign": 0.565696850403, "cool": 1.9253988473800001, "omnipres": 4.860379458530001, "gather": 1.3313920667299999, "this": 0.0037864490525, "pretti": 2.75684036527, "sampl": 1.9786264883900002, "time": 0.0112115188626, "api": 4.43612185107, "engin": 0.904767558276, "back": 0.23166743089699998, "conceptu": 2.8723937456, "project": 0.561601885907, "embed": 2.82349753127, "syntaxawar": 7.369978720910001, "interchang": 2.62417740518, "releg": 3.1940541716900004, "magic": 2.06766933309, "return": 0.333126868592, "fail": 0.656536611573, "all": 0.011402632097799998, "syntax": 3.8203613341300007, "today": 0.559395353679, "situat": 0.725668290015, "strong": 0.49712549393600003, "metadata": 5.35507570037, "that": 0.00397614837964, "pair": 1.47447456495, "weight": 1.58492352612, "architectur": 1.63469757919, "call": 0.0654627744488, "object": 0.853933584803, "more": 0.017024931599999998, "and": 6.29901420636e-05, "correspond": 1.20141456099, "ast": 4.67535154014, "discuss": 0.78698452262, "these": 0.0715336194008, "prepar": 0.8879422790620001, "keyword": 4.93636536551, "general": 0.114952578063, "websit": 0.924894023806, "could": 0.18595627229000003, "befor": 0.0956377718795, "librari": 0.986809980943, "close": 0.250666759864, "can": 0.162341096394, "avail": 0.547454586289, "describ": 0.385447603125, "encod": 3.36811501148, "queri": 4.03065674296, "way": 0.19809150993500002, "search": 1.1798682540899998, "onli": 0.025324268329099998, "each": 0.173741689304, "read": 0.83939268088, "packag": 2.0577584491900005, "data": 1.2168205848, "method": 0.944461608841, "perfect": 1.50096433356, "rather": 0.442714975539, "sinc": 0.0803681994577, "sometim": 0.538025155343, "exampl": 0.40868267499899996, "husain": 5.51368073054, "toplevel": 7.369978720910001, "text": 1.14048200999, "understand": 1.0880858756799998, "treebas": 7.369978720910001, "direct": 0.200705689496, "import": 0.292818277066, "luckili": 5.25372320611, "enough": 0.802884439169, "while": 0.04324998379380001, "host": 0.996658931332, "reason": 0.544301552962, "user": 2.04258810688, "within": 0.21263272059799998, "learn": 0.842752064745, "when": 0.0205549888584, "seqnumseq": 7.369978720910001}, "freq": {"after": 2, "semant": 9, "googl": 3, "implic": 1, "unlik": 1, "too": 1, "relat": 2, "fit": 1, "vector": 5, "domainspecif": 1, "repo": 1, "kind": 1, "vectorspac": 1, "space": 3, "addit": 1, "would": 1, "follow": 1, "screenshot": 1, "etc": 1, "dataset": 1, "sequencetosequ": 2, "function": 5, "draw": 1, "progress": 1, "python": 4, "thought": 1, "well": 2, "product": 1, "work": 3, "complet": 1, "approach": 5, "technic": 2, "retain": 1, "motiv": 2, "summon": 1, "cosin": 1, "creat": 2, "summar": 9, "how": 6, "test": 2, "strip": 1, "present": 5, "discrimin": 1, "origin": 1, "high": 1, "initi": 1, "end": 1, "found": 1, "word": 1, "interest": 2, "tutori": 12, "will": 14, "exploit": 1, "consid": 1, "hubot": 1, "lineag": 1, "purpos": 1, "below": 6, "similar": 3, "but": 5, "demonstr": 4, "need": 1, "our": 2, "commit": 1, "final": 1, "unrel": 1, "tune": 1, "amaz": 1, "review": 1, "level": 1, "has": 1, "have": 2, "also": 5, "use": 16, "sound": 1, "model": 16, "wherea": 1, "treat": 1, "excit": 2, "concept": 2, "titl": 1, "introduc": 1, "undeni": 1, "bigqueri": 1, "optim": 1, "warn": 1, "daunt": 1, "store": 1, "audio": 1, "not": 12, "arbitrari": 1, "version": 1, "perus": 1, "superpow": 1, "minim": 1, "quick": 1, "jupyt": 2, "metric": 1, "than": 1, "then": 1, "separ": 2, "they": 4, "anoth": 1, "techniqu": 1, "revisit": 1, "section": 1, "construct": 1, "clip": 1, "internet": 1, "item": 1, "simpl": 1, "provid": 1, "downstream": 1, "either": 1, "develop": 1, "such": 5, "explor": 1, "conveni": 1, "some": 3, "sourc": 1, "should": 2, "both": 1, "super": 1, "result": 5, "gracious": 1, "content": 1, "repositori": 2, "languag": 4, "set": 2, "from": 8, "awesom": 1, "dive": 1, "detail": 2, "num": 7, "veri": 2, "aren": 3, "idea": 1, "acquir": 2, "for": 27, "broken": 1, "output": 1, "fulli": 1, "with": 3, "are": 15, "speak": 1, "viabl": 1, "folk": 1, "preprocess": 1, "look": 2, "hohsiang": 1, "option": 1, "account": 1, "furthermor": 1, "chanc": 1, "extract": 4, "num\u2013num": 1, "pars": 2, "later": 2, "focus": 1, "familiar": 2, "remov": 1, "map": 2, "doe": 1, "even": 2, "give": 1, "valid": 1, "scope": 1, "part": 4, "train": 6, "great": 1, "hamel": 1, "bodi": 1, "step": 10, "comment": 4, "note": 1, "reinforc": 1, "thing": 2, "notebook": 10, "reproduc": 1, "paper": 1, "prior": 1, "hire": 1, "through": 2, "lstms": 1, "requir": 1, "what": 3, "allow": 2, "fine": 1, "help": 1, "main": 1, "measur": 1, "find": 1, "instead": 2, "abil": 1, "astor": 1, "moment": 1, "own": 1, "though": 1, "natur": 4, "pictur": 3, "here": 5, "quantit": 1, "github": 4, "apart": 1, "docstr": 5, "much": 1, "evalu": 1, "contain": 2, "about": 1, "evid": 1, "mind": 1, "context": 1, "extractor": 3, "entir": 1, "anticip": 1, "featur": 5, "topic": 1, "type": 1, "exercis": 2, "finetun": 1, "recommend": 1, "where": 1, "live": 1, "save": 1, "tool": 1, "intuit": 3, "enabl": 1, "ping": 2, "latent": 1, "keep": 2, "maintain": 1, "standard": 1, "prerequisit": 1, "central": 1, "track": 1, "abl": 1, "mani": 2, "appli": 1, "the": 59, "goal": 3, "build": 6, "seem": 1, "pretrain": 1, "select": 1, "team": 1, "unfortun": 1, "neighbor": 1, "same": 2, "throughout": 2, "togeth": 1, "there": 4, "endtoend": 1, "inform": 4, "repres": 2, "right": 1, "spend": 1, "illustr": 4, "star": 1, "knowledg": 1, "take": 1, "previous": 2, "profound": 1, "might": 1, "further": 1, "name": 1, "code": 34, "strict": 2, "interact": 1, "represent": 1, "haven": 1, "unit": 1, "power": 2, "issu": 5, "cloud": 1, "modern": 1, "mean": 3, "into": 7, "notic": 1, "task": 5, "accomplish": 2, "overview": 1, "may": 1, "discover": 1, "peopl": 1, "datasci": 1, "open": 1, "encourag": 1, "want": 4, "convert": 1, "concret": 2, "system": 1, "howev": 5, "share": 3, "gone": 1, "token": 1, "disclaim": 1, "maxim": 1, "entiti": 1, "which": 6, "term": 1, "ident": 2, "other": 4, "refer": 1, "procedur": 2, "one": 3, "show": 1, "custom": 1, "see": 4, "diagram": 1, "whi": 1, "highlevel": 1, "get": 2, "still": 1, "like": 3, "outsid": 1, "collect": 2, "file": 3, "opensourc": 1, "kubeflow": 1, "transform": 1, "yet": 1, "outlin": 1, "includ": 1, "sign": 1, "cool": 1, "omnipres": 1, "gather": 1, "this": 42, "pretti": 1, "sampl": 1, "time": 1, "api": 2, "engin": 1, "back": 1, "conceptu": 1, "project": 3, "embed": 1, "syntaxawar": 1, "interchang": 1, "releg": 1, "magic": 1, "return": 2, "fail": 1, "all": 3, "syntax": 1, "today": 1, "situat": 1, "strong": 1, "metadata": 1, "that": 15, "pair": 5, "weight": 1, "architectur": 1, "call": 1, "object": 4, "more": 5, "and": 24, "correspond": 1, "ast": 2, "discuss": 2, "these": 8, "prepar": 1, "keyword": 4, "general": 3, "websit": 1, "could": 2, "befor": 1, "librari": 2, "close": 1, "can": 13, "avail": 2, "describ": 3, "encod": 1, "queri": 3, "way": 2, "search": 19, "onli": 3, "each": 3, "read": 1, "packag": 1, "data": 10, "method": 2, "perfect": 1, "rather": 1, "sinc": 1, "sometim": 1, "exampl": 5, "husain": 1, "toplevel": 1, "text": 6, "understand": 2, "treebas": 1, "direct": 1, "import": 1, "luckili": 1, "enough": 2, "while": 1, "host": 1, "reason": 2, "user": 2, "within": 1, "learn": 1, "when": 3, "seqnumseq": 2}, "idf": {"after": 1.02070207021, "semant": 39.1034482759, "googl": 11.388809182200001, "implic": 7.632692307689999, "unlik": 2.42529789184, "too": 1.81585268215, "relat": 1.23750876919, "fit": 3.37070063694, "vector": 25.898858075, "domainspecif": 1587.6, "repo": 369.209302326, "kind": 2.5806241872599998, "vectorspac": 1587.6, "space": 2.39818731118, "addit": 1.24634950542, "would": 1.0828729281799998, "follow": 1.04640126549, "screenshot": 396.9, "etc": 4.2066772655, "dataset": 193.609756098, "sequencetosequ": 1587.6, "function": 2.495441685, "draw": 2.97247706422, "progress": 2.44697903822, "python": 56.2978723404, "thought": 1.9854927463699998, "well": 1.0655748708, "product": 1.62264922322, "work": 1.11520089913, "complet": 1.24021560816, "approach": 2.07556543339, "technic": 3.1400316455699997, "retain": 2.74956702459, "motiv": 5.01611374408, "summon": 14.4327272727, "cosin": 193.609756098, "creat": 1.2492917847, "summar": 15.1056137012, "how": 1.60250328051, "test": 2.65707112971, "strip": 5.50485436893, "present": 1.25551601423, "discrimin": 10.6981132075, "origin": 1.13724928367, "high": 1.14777327935, "initi": 1.35, "end": 1.10680423871, "found": 1.11387076405, "word": 1.7965372864099998, "interest": 1.60331246213, "tutori": 59.4606741573, "will": 1.22481098596, "exploit": 5.79416058394, "consid": 1.2397313759200002, "hubot": 1587.6, "lineag": 19.7462686567, "purpos": 2.23416830847, "below": 2.25607503197, "similar": 1.37514075357, "but": 1.01632417899, "demonstr": 2.64997496244, "need": 1.4372623574099999, "our": 2.35758835759, "commit": 2.8860207235, "final": 1.34008609775, "unrel": 15.7813121272, "tune": 10.4173228346, "amaz": 15.250720461099998, "review": 2.2099109131400003, "level": 1.6544393497299998, "has": 1.0436497502, "have": 1.0148948411399998, "also": 1.01476510067, "use": 1.0296387573799999, "sound": 3.11294117647, "model": 2.0905978404, "wherea": 4.13868613139, "treat": 3.59023066486, "excit": 9.818181818180001, "concept": 2.65707112971, "titl": 1.87261146497, "introduc": 1.7258397651900002, "undeni": 95.6385542169, "bigqueri": 1587.6, "optim": 11.5377906977, "warn": 4.334152334150001, "daunt": 102.425806452, "store": 3.44680851064, "audio": 9.05647461495, "not": 1.01567398119, "arbitrari": 17.8181818182, "version": 2.0083491461099996, "perus": 387.219512195, "superpow": 49.457943925200006, "minim": 6.10850327049, "quick": 2.205, "jupyt": 1587.6, "metric": 22.235294117600002, "than": 1.03278688525, "then": 1.08657860516, "separ": 1.6012102874399998, "they": 1.03017325287, "anoth": 1.13643521832, "techniqu": 3.7293868921800004, "revisit": 19.5276752768, "section": 2.1284354471099998, "construct": 1.9320920043799998, "clip": 15.1344137274, "internet": 4.98461538462, "item": 5.07869481766, "simpl": 3.3981164383599998, "provid": 1.21552714187, "downstream": 41.889182058, "either": 1.5830092731099998, "develop": 1.1955719557200002, "such": 1.06151377374, "explor": 3.39593582888, "conveni": 9.85474860335, "some": 1.04036697248, "sourc": 1.69760479042, "should": 1.6643254009900001, "both": 1.05215720061, "super": 7.380753138080001, "result": 1.14611608432, "gracious": 88.2, "content": 3.5421686747, "repositori": 44.974504249300004, "languag": 2.29488291414, "set": 1.18707940781, "from": 1.00056721497, "awesom": 108.0, "dive": 16.085106383, "detail": 2.26186066391, "num": 1.00031504001, "veri": 1.25880114177, "aren": 481.09090909099996, "idea": 2.0930784443, "acquir": 3.10563380282, "for": 1.00031504001, "broken": 4.46959459459, "output": 7.676982591880001, "fulli": 2.79015817223, "with": 1.0011982089899998, "are": 1.02990593578, "speak": 2.89127663449, "viabl": 16.1834862385, "folk": 7.6658619024600005, "preprocess": 1221.23076923, "look": 1.9086318826599997, "hohsiang": 1587.6, "option": 4.04896710023, "account": 1.94463498285, "furthermor": 5.50294627383, "chanc": 4.2449197861000005, "extract": 7.703056768560001, "num\u2013num": 1587.6, "pars": 145.651376147, "later": 1.08650424309, "focus": 2.01012914662, "familiar": 6.86381322957, "remov": 2.0058117498400003, "map": 4.0728578758300005, "doe": 1.70581282905, "even": 1.16461267606, "give": 1.3653250774, "valid": 6.61224489796, "scope": 10.3494132986, "part": 1.04330682789, "train": 1.9365698950999999, "great": 1.26592775696, "hamel": 311.294117647, "bodi": 1.8618505922400002, "step": 2.8279301745599996, "comment": 3.05954904606, "note": 1.42449528937, "reinforc": 6.453658536590001, "thing": 2.4065484311099996, "notebook": 40.1924050633, "reproduc": 12.6805111821, "paper": 2.6628648104700003, "prior": 2.17807655371, "hire": 4.95815115553, "through": 1.07074930869, "lstms": 1587.6, "requir": 1.52844902282, "what": 1.25343439128, "allow": 1.2716059271100002, "fine": 4.02229541424, "help": 1.39962972759, "main": 1.25303867403, "measur": 2.41093394077, "find": 1.7294117647099998, "instead": 1.59461631177, "abil": 2.70875277256, "astor": 101.121019108, "moment": 4.262013422819999, "own": 1.17844418052, "though": 1.36076112111, "natur": 1.5392670157100001, "pictur": 3.4953764861300005, "here": 2.42307692308, "quantit": 27.803852889699996, "github": 1587.6, "apart": 3.1032056294, "docstr": 1587.6, "much": 1.1942229577299999, "evalu": 6.9509632224199995, "contain": 1.59814777532, "about": 1.06486015159, "evid": 2.24872521246, "mind": 3.5918552036199998, "context": 4.25972632144, "extractor": 299.547169811, "entir": 1.59365589239, "anticip": 7.793814432989999, "featur": 1.52712581762, "topic": 5.457545548300001, "type": 2.0281042411900003, "exercis": 4.73627684964, "finetun": 1587.6, "recommend": 3.9142011834300003, "where": 1.06715063521, "live": 1.30591428806, "save": 2.8178913737999998, "tool": 4.99716713881, "intuit": 27.7068062827, "enabl": 3.5421686747, "ping": 110.25, "latent": 66.42677824270001, "keep": 2.04245465071, "maintain": 1.77306231852, "standard": 1.8915763135900003, "prerequisit": 50.5605095541, "central": 1.6121039805000001, "track": 3.1276595744700004, "abl": 1.8208510150200001, "mani": 1.04426757877, "appli": 2.2972073506, "the": 1.0, "goal": 3.28152128979, "build": 1.6341739578, "seem": 2.29123971713, "pretrain": 1587.6, "select": 2.02345144022, "team": 2.2748244734200003, "unfortun": 9.966101694919999, "neighbor": 5.781500364169999, "same": 1.11857958148, "throughout": 1.5217099587799998, "togeth": 1.58095996813, "there": 1.04091266719, "endtoend": 1587.6, "inform": 1.5753125620200001, "repres": 1.46972782818, "right": 1.4054532577899999, "spend": 4.15928739848, "illustr": 3.6614391143900002, "star": 2.4450947173900004, "knowledg": 3.3981164383599998, "take": 1.13961668222, "previous": 1.42846859816, "profound": 11.219787985899998, "might": 2.1561863370900003, "further": 1.3618116315, "name": 1.10211732037, "code": 3.8807137619199996, "strict": 4.7235941684, "interact": 4.4185917061, "represent": 5.928304705, "haven": 12.690647482000001, "unit": 1.15394679459, "power": 1.3396337861799998, "issu": 1.43921675279, "cloud": 10.6193979933, "modern": 1.5319888063299998, "mean": 1.44906900329, "into": 1.01502461479, "notic": 4.36994219653, "task": 3.88641370869, "accomplish": 5.17302052786, "overview": 12.6805111821, "may": 1.05201775893, "discover": 77.443902439, "peopl": 1.21320495186, "datasci": 1587.6, "open": 1.24556723678, "encourag": 2.7975330396499998, "want": 1.99698113208, "convert": 3.2740771293099997, "concret": 10.0100882724, "system": 1.38739840951, "howev": 1.0945191313299998, "share": 1.8566249561500001, "gone": 5.22408687068, "token": 33.7070063694, "disclaim": 98.6086956522, "maxim": 12.928338762200001, "entiti": 6.89361702128, "which": 1.005191845, "term": 1.39520168732, "ident": 2.80792359392, "other": 1.00992366412, "refer": 1.30024570025, "procedur": 5.8691312384500005, "one": 1.00627495722, "show": 1.26703910615, "custom": 3.6346153846199996, "see": 1.27242125511, "diagram": 22.1731843575, "whi": 3.2566153846200003, "highlevel": 1587.6, "get": 1.78562591385, "still": 1.1866357724799999, "like": 1.14918566775, "outsid": 1.67450690855, "collect": 1.64109985528, "file": 3.7710213776699995, "opensourc": 1587.6, "kubeflow": 1587.6, "transform": 3.42007755278, "yet": 2.1258703802900003, "outlin": 6.38102893891, "includ": 1.0190641247799999, "sign": 1.7606742819099999, "cool": 6.8578833693300005, "omnipres": 129.073170732, "gather": 3.78631051753, "this": 1.00379362671, "pretti": 15.75, "sampl": 7.23280182232, "time": 1.01127460348, "api": 84.44680851060001, "engin": 2.47135740971, "back": 1.26070038911, "conceptu": 17.6792873051, "project": 1.7534791252500002, "embed": 16.835630965, "syntaxawar": 1587.6, "interchang": 13.793223284100002, "releg": 24.3870967742, "magic": 7.9063745019899985, "return": 1.39532431007, "fail": 1.9281029876099998, "all": 1.01146788991, "syntax": 45.6206896552, "today": 1.74961428257, "situat": 2.06611140031, "strong": 1.6439888163999998, "metadata": 211.68, "that": 1.00398406375, "pair": 4.36873968079, "weight": 4.878918254459999, "architectur": 5.12790697674, "call": 1.0676529926, "object": 2.3488681757700003, "more": 1.0171706817, "and": 1.00006299213, "correspond": 3.32481675393, "ast": 107.27027027, "discuss": 2.19676214197, "these": 1.07415426252, "prepar": 2.43012398592, "keyword": 139.263157895, "general": 1.1218202374200001, "websit": 2.52160101652, "could": 1.2043695949, "befor": 1.10036041031, "librari": 2.68266306185, "close": 1.2848818387799998, "can": 1.17626139142, "avail": 1.7288467821, "describ": 1.47027227264, "encod": 29.0237659963, "queri": 56.2978723404, "way": 1.2190739461, "search": 3.2539454806299997, "onli": 1.0256476516600002, "each": 1.18974820144, "read": 2.3149606299200003, "packag": 7.828402366860001, "data": 3.37643555934, "method": 2.5714285714300003, "perfect": 4.48601299802, "rather": 1.55692850838, "sinc": 1.08368600683, "sometim": 1.7126213592200001, "exampl": 1.50483412322, "husain": 248.0625, "toplevel": 1587.6, "text": 3.12827586207, "understand": 2.96858638743, "treebas": 1587.6, "direct": 1.22226499346, "import": 1.3401992233700002, "luckili": 191.277108434, "enough": 2.2319696330700003, "while": 1.0441988950299999, "host": 2.7092150170599996, "reason": 1.72340425532, "user": 7.71053909665, "within": 1.2369302688, "learn": 2.32275054865, "when": 1.02076769755, "seqnumseq": 1587.6}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/n23.html\" rel=\"prev\" title=\"KDnuggets\u2122 News 18:n23, Jun 13: Did Python declare victory over R?; Master the Netflix Interview; Deep Learning Projects DIY Style\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/advice-applying-data-science-jobs.html\" rel=\"next\" title=\"Advice For Applying To Data Science Jobs\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=81769\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-81769 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 13-Jun, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/tutorials.html\">Tutorials, Overviews</a> \u00bb How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning (\u00a0<a href=\"/2018/n24.html\">18:n24</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/n23.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/06/advice-applying-data-science-jobs.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/github\" rel=\"tag\">GitHub</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/semantic-analysis\" rel=\"tag\">Semantic Analysis</a></div>\n<br/>\n<p class=\"excerpt\">\n     An end-to-end example of how to build a system that can search objects semantically.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html?page=2#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/hamelhusain/\" rel=\"noopener noreferrer\" target=\"_blank\">Hamel Husain</a>\u00a0&amp;\u00a0<a href=\"https://www.linkedin.com/in/hohsiangwu/\" rel=\"noopener noreferrer\" target=\"_blank\">Ho-Hsiang Wu</a>, GitHub</b></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/0*jmN0ix92GC1QfJNF.jpg\" width=\"65%\"><br>\n<font size=\"-1\">A picture of\u00a0<a href=\"https://hubot.github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Hubot</a>.</font></br></img></center></p>\n<p>\u00a0</p>\n<h3>Motivation:</h3>\n<p>\u00a0<br>\nThe power of modern search engines is undeniable: you can summon knowledge from the internet at a moment\u2019s notice. Unfortunately, this superpower isn\u2019t omnipresent. There are many situations where search is relegated to strict keyword search, or when the objects aren\u2019t text, search may not be available. Furthermore, strict keyword search doesn\u2019t allow the user to\u00a0<a href=\"https://en.wikipedia.org/wiki/Semantic_search\" rel=\"noopener noreferrer\" target=\"_blank\">search semantically</a>, which means information is not as discoverable.</br></p>\n<p>Today, we share a reproducible, minimally viable product that illustrates how you can enable\u00a0<a href=\"https://en.wikipedia.org/wiki/Semantic_search\" rel=\"noopener noreferrer\" target=\"_blank\">semantic search</a>\u00a0for arbitrary objects! Concretely, we will show you how to create a system that searches python code semantically\u200a\u2014\u200abut this approach can be generalized to other entities (such as pictures or sound clips).</p>\n<p>Why is semantic search so exciting? Consider the below example:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*TIOajbCx7KDdcaBxNxmjXg.gif\" width=\"90%\"/><br>\n<font size=\"-1\">Semantic search at work on python code. *See Disclaimer section\u00a0below.</font></br></center></p>\n<p>The search query presented is \u201c<strong>Ping</strong>\u00a0<strong>REST api</strong>\u00a0and return results\u201d. However, the search returns reasonable results even though the code &amp; comments found do not contain the words\u00a0<strong>Ping, REST</strong>\u00a0or\u00a0<strong>api.</strong></p>\n<p>This illustrates the\u00a0<strong>power of\u00a0</strong><a href=\"https://en.wikipedia.org/wiki/Semantic_search\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>semantic search</strong></a><strong>: we can search content for its<em>meaning\u00a0</em>in addition to keywords</strong>, and maximize the chances the user will find the information they are looking for. The implications of semantic search are profound\u200a\u2014\u200afor example, such a procedure would allow developers to search for code in repositories even if they are not familiar with the syntax or fail to anticipate the right keywords. More importantly, you can generalize this approach to objects such as pictures, audio and other things that we haven\u2019t thought of yet.</p>\n<p>If this is not exciting enough,\u00a0<strong>here is a live demonstration of what you will be able to build by the end of this tutorial</strong>:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*nT198cL_AOK6XTfEfuBDYw.gif\" width=\"99%\"/><br>\n<font size=\"-1\">Sometimes I use Jupyter notebooks and\u00a0<a href=\"https://ipython.org/ipython-doc/3/config/custommagics.html\" rel=\"noopener noreferrer\" target=\"_blank\">custom magic functions</a>\u00a0to create demonstrations when I cannot build a pretty website. it can be a quick way to interactively demonstrate your\u00a0work!</font></br></center></p>\n<p>\u00a0</p>\n<h3>Intuition\u00a0: Construct a Shared Vector-Space</h3>\n<p>\u00a0<br/>\nBefore diving into the technical details, it is useful to provide you with a high-level intuition of how we will accomplish semantic search. The central idea is to represent both text and the object we want to search (code) in a shared vector space, as illustrated below:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*zhLXNHK8ILaYV8tT-jDlOQ.png\" width=\"99%\"/><br/>\n<font size=\"-1\"><strong>Example: Text 2</strong>\u00a0and the\u00a0<strong>code</strong>\u00a0should be represented by similar vectors since they are directly\u00a0related.<br/>\n</font></center></p>\n<p>The goal is to map code into the vector space of natural language, such that (text, code) pairs that describe the same concept are close neighbors, whereas unrelated (text, code) pairs are further apart, measured by\u00a0<a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\" rel=\"noopener noreferrer\" target=\"_blank\">cosine similarity</a>.</p>\n<p>There are many ways to accomplish this goal, however, we will demonstrate the approach of taking a pre-trained model that extracts features from code and\u00a0<a href=\"https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html\" rel=\"noopener noreferrer\" target=\"_blank\">fine-tuning</a>\u00a0this model to project latent code features into a vector space of natural language. One warning: We use the term\u00a0<strong><em>vector</em></strong>\u00a0and\u00a0<strong><em>embedding</em></strong>interchangeably<strong><em>\u00a0</em></strong>throughout this tutorial.</p>\n<p>\u00a0</p>\n<h3>Prerequisites</h3>\n<p>\u00a0<br/>\nWe recommend familiarity with the following items prior to reading this tutorial:</p>\n<ul>\n<li><em>Sequence-to-sequence models:</em>\u00a0It will be helpful to review the information presented\u00a0<a href=\"https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\" rel=\"noopener noreferrer\" target=\"_blank\">in a previous tutorial</a>.\n<li>Peruse\u00a0<a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">this paper</a>\u00a0at a high level and understand the intuition of the approach presented. We draw on similar concepts for what we present here.\n</li></li></ul>\n<p>\u00a0</p>\n<h3>Overview:</h3>\n<p>\u00a0<br/>\nThis tutorial will be broken into 5 concrete steps. These steps are illustrated below and will be a useful reference as you progress throughout the tutorial. After completing the tutorial, it will be useful to revisit this diagram to reinforce how all the steps fit together.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*HxrVL3bDLD8G0elzF5cp4w.png\" width=\"99%\"/><br/>\n<font size=\"-1\">A mind map of this tutorial. Hi-res version available\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/diagram/Diagram.png\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>.</font></center></p>\n<p>Each step 1\u20135 corresponds to a Jupyter notebook\u00a0<a href=\"https://github.com/hamelsmu/code_search/tree/master/notebooks\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>. We will explore each step in more detail below.</p>\n<p>\u00a0</p>\n<h3><strong>Part 1\u200a\u2014\u200aAcquire and Parse\u00a0Data:</strong></h3>\n<p>\u00a0<br/>\n<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Part 1 notebook</em></a></p>\n<p>The folks at Google collect and store data from open-source GitHub repositories on\u00a0<a href=\"https://cloud.google.com/bigquery/\" rel=\"noopener noreferrer\" target=\"_blank\">BigQuery</a>. This is a great open dataset for all kinds of interesting data-science projects, including this one! When you sign up for a Google Cloud account, they give you $300 which is more than enough to query the data for this exercise. Getting this data is super convenient, as you can use SQL queries to select what type of files you are looking for as well as other meta-data about repos such as commits, stars, etc.</p>\n<p>The steps to acquire this data are outlined in this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>. Luckily,\u00a0<a href=\"https://kubernetes.io/blog/2017/12/introducing-kubeflow-composable/\" rel=\"noopener noreferrer\" target=\"_blank\">some awesome people on the Kubeflow team at Google</a>\u00a0have gone through these steps and have graciously hosted the data for this exercise, which is also described in this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>.</p>\n<p>After collecting this data, we need to parse these files into (code,\u00a0<a href=\"http://www.pythonforbeginners.com/basics/python-docstrings\" rel=\"noopener noreferrer\" target=\"_blank\">docstring</a>) pairs. For this tutorial, one unit of code will be either a\u00a0<a href=\"https://stackoverflow.com/questions/18138166/what-is-a-top-level-statement-in-python\" rel=\"noopener noreferrer\" target=\"_blank\">top-level function</a>\u00a0or a method. We want to gather these pairs as training data for a model that will summarize code (more on that later). We also want to strip the code of all comments and only retain the code. This might seem like a daunting task, however, there is an amazing library called\u00a0<a href=\"https://docs.python.org/3/library/ast.html\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>ast</strong>\u00a0in Python\u2019s standard library</a>that can be used to extract functions, methods and, docstrings. We can remove comments from code by converting code into an\u00a0<a href=\"https://en.wikipedia.org/wiki/Abstract_syntax_tree\" rel=\"noopener noreferrer\" target=\"_blank\">AST</a>\u00a0and then back from that representation to code, using the\u00a0<a href=\"https://pypi.org/project/astor/\" rel=\"noopener noreferrer\" target=\"_blank\">Astor</a>\u00a0package. Understanding of ASTs or how these tools work is not required for this tutorial, but are very interesting topics!</p>\n<p><center><script src=\"https://gist.github.com/hamelsmu/7439b131dd9b37d246cdab71b5c898ac.js\"></script><br/>\n<font size=\"-1\">For more context of how this code is used, see this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>.<br/>\n</font></center></p>\n<p>To prepare this data for modeling, we separate the data into train, validation and test sets. We also maintain files (which we name \u201clineage\u201d) to keep track of the original source of each (code, docstring) pair. Finally, we apply the same transforms to code that does not contain a docstring and save that separately, as we will want the ability to search this code as well!</p>\n<p>\u00a0</p>\n<h3>Part 2\u200a\u2014\u200aBuild a Code Summarizer Using a Seq2Seq\u00a0Model:</h3>\n<p>\u00a0<br/>\n<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Part 2 notebook</em></a></p>\n<p>Conceptually, building a sequence-to-sequence model to summarize code is identical to the\u00a0<a href=\"https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub issue summarizer</a>\u00a0we presented previously\u200a\u2014\u200ainstead of issue bodies we use python code, and instead of issue titles, we use docstrings.</p>\n<p>However, unlike GitHub issue text, code is not natural language. To fully exploit the information within code, we could introduce domain-specific optimizations like\u00a0<a href=\"https://arxiv.org/pdf/1802.00921.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">tree-based LSTMs</a>\u00a0and syntax-aware tokenization. For this tutorial, we are going to keep things simple and treat code like natural language (and still get reasonable results).</p>\n<p>Building a function summarizer is a very cool project on its own, but we aren\u2019t going to spend too much time focusing on this (but we encourage you to do so!). The entire end-to-end training procedure for this model is described in\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">this notebook</a>. We do not discuss the pre-processing or architecture for this model as it is identical to the\u00a0<a href=\"https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\" rel=\"noopener noreferrer\" target=\"_blank\">issue summarizer</a>.</p>\n<p>Our motivation for training this model is not to use it for the task of summarizing code, but rather as a general purpose feature extractor for code. Technically speaking, this step is optional as we are only going through these steps to initialize the model weights for a related downstream task. In a later step, we will extract the encoder from this model and\u00a0<a href=\"https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html\" rel=\"noopener noreferrer\" target=\"_blank\">fine tune</a>\u00a0it for another task. Below is a screenshot of some example outputs of this model:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*k1iE9QFgfF2K7BGE_4KIFg.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Sample results from function summarizer on a test set. See notebook\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>.</font></center></p>\n<p>We can see that while the results aren\u2019t perfect, there is strong evidence that the model has learned to extract some semantic meaning from code, which is our main goal for this task. We can evaluate these models quantitatively using the\u00a0<a href=\"https://en.wikipedia.org/wiki/BLEU\" rel=\"noopener noreferrer\" target=\"_blank\">BLEU metric</a>, which is also discussed in this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>.<br/>\nIt should be noted that training a seq2seq model to summarize code is not the only technique you can use to build a feature extractor for code. For example, you could also train a\u00a0<a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"noopener noreferrer\" target=\"_blank\">GAN</a>\u00a0and\u00a0<a href=\"https://arxiv.org/pdf/1511.06434.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">use the discriminator as a feature extractor</a>. However, these other approaches are outside the scope of this tutorial.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/n23.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/06/advice-applying-data-science-jobs.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/tutorials.html\">Tutorials, Overviews</a> \u00bb How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning (\u00a0<a href=\"/2018/n24.html\">18:n24</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556461384\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.728 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-28 10:23:04 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "hamel", "husain", "hohsiang", "github", "pictur", "hubot", "motiv", "the", "power", "modern", "search", "engin", "undeni", "can", "summon", "knowledg", "from", "the", "internet", "moment", "notic", "unfortun", "this", "superpow", "omnipres", "there", "are", "mani", "situat", "where", "search", "releg", "strict", "keyword", "search", "when", "the", "object", "aren", "text", "search", "may", "not", "avail", "furthermor", "strict", "keyword", "search", "allow", "the", "user", "search", "semant", "which", "mean", "inform", "not", "discover", "today", "share", "reproduc", "minim", "viabl", "product", "that", "illustr", "how", "can", "enabl", "semant", "search", "for", "arbitrari", "object", "concret", "will", "show", "how", "creat", "system", "that", "search", "python", "code", "semant", "but", "this", "approach", "can", "general", "other", "entiti", "such", "pictur", "sound", "clip", "whi", "semant", "search", "excit", "consid", "the", "below", "exampl", "semant", "search", "work", "python", "code", "see", "disclaim", "section", "below", "the", "search", "queri", "present", "ping", "api", "and", "return", "result", "howev", "the", "search", "return", "reason", "result", "even", "though", "the", "code", "comment", "found", "not", "contain", "the", "word", "ping", "api", "this", "illustr", "the", "power", "semant", "search", "can", "search", "content", "for", "mean", "addit", "keyword", "and", "maxim", "the", "chanc", "the", "user", "will", "find", "the", "inform", "they", "are", "look", "for", "the", "implic", "semant", "search", "are", "profound", "for", "exampl", "such", "procedur", "would", "allow", "develop", "search", "for", "code", "repositori", "even", "they", "are", "not", "familiar", "with", "the", "syntax", "fail", "anticip", "the", "right", "keyword", "more", "import", "can", "general", "this", "approach", "object", "such", "pictur", "audio", "and", "other", "thing", "that", "haven", "thought", "yet", "this", "not", "excit", "enough", "here", "live", "demonstr", "what", "will", "abl", "build", "the", "end", "this", "tutori", "sometim", "use", "jupyt", "notebook", "and", "custom", "magic", "function", "creat", "demonstr", "when", "can", "not", "build", "pretti", "websit", "can", "quick", "way", "interact", "demonstr", "work", "intuit", "construct", "share", "vectorspac", "befor", "dive", "into", "the", "technic", "detail", "use", "provid", "with", "highlevel", "intuit", "how", "will", "accomplish", "semant", "search", "the", "central", "idea", "repres", "both", "text", "and", "the", "object", "want", "search", "code", "share", "vector", "space", "illustr", "below", "exampl", "text", "num", "and", "the", "code", "should", "repres", "similar", "vector", "sinc", "they", "are", "direct", "relat", "the", "goal", "map", "code", "into", "the", "vector", "space", "natur", "languag", "such", "that", "text", "code", "pair", "that", "describ", "the", "same", "concept", "are", "close", "neighbor", "wherea", "unrel", "text", "code", "pair", "are", "further", "apart", "measur", "cosin", "similar", "there", "are", "mani", "way", "accomplish", "this", "goal", "howev", "will", "demonstr", "the", "approach", "take", "pretrain", "model", "that", "extract", "featur", "from", "code", "and", "finetun", "this", "model", "project", "latent", "code", "featur", "into", "vector", "space", "natur", "languag", "one", "warn", "use", "the", "term", "vector", "and", "embed", "interchang", "throughout", "this", "tutori", "prerequisit", "recommend", "familiar", "with", "the", "follow", "item", "prior", "read", "this", "tutori", "sequencetosequ", "model", "will", "help", "review", "the", "inform", "present", "previous", "tutori", "perus", "this", "paper", "high", "level", "and", "understand", "the", "intuit", "the", "approach", "present", "draw", "similar", "concept", "for", "what", "present", "here", "overview", "this", "tutori", "will", "broken", "into", "num", "concret", "step", "these", "step", "are", "illustr", "below", "and", "will", "use", "refer", "progress", "throughout", "the", "tutori", "after", "complet", "the", "tutori", "will", "use", "revisit", "this", "diagram", "reinforc", "how", "all", "the", "step", "fit", "togeth", "mind", "map", "this", "tutori", "hire", "version", "avail", "here", "each", "step", "num\u2013num", "correspond", "jupyt", "notebook", "here", "will", "explor", "each", "step", "more", "detail", "below", "part", "num", "acquir", "and", "pars", "data", "part", "num", "notebook", "the", "folk", "googl", "collect", "and", "store", "data", "from", "opensourc", "github", "repositori", "bigqueri", "this", "great", "open", "dataset", "for", "all", "kind", "interest", "datasci", "project", "includ", "this", "one", "when", "sign", "for", "googl", "cloud", "account", "they", "give", "num", "which", "more", "than", "enough", "queri", "the", "data", "for", "this", "exercis", "get", "this", "data", "super", "conveni", "can", "use", "queri", "select", "what", "type", "file", "are", "look", "for", "well", "other", "metadata", "about", "repo", "such", "commit", "star", "etc", "the", "step", "acquir", "this", "data", "are", "outlin", "this", "notebook", "luckili", "some", "awesom", "peopl", "the", "kubeflow", "team", "googl", "have", "gone", "through", "these", "step", "and", "have", "gracious", "host", "the", "data", "for", "this", "exercis", "which", "also", "describ", "this", "notebook", "after", "collect", "this", "data", "need", "pars", "these", "file", "into", "code", "docstr", "pair", "for", "this", "tutori", "one", "unit", "code", "will", "either", "toplevel", "function", "method", "want", "gather", "these", "pair", "train", "data", "for", "model", "that", "will", "summar", "code", "more", "that", "later", "also", "want", "strip", "the", "code", "all", "comment", "and", "onli", "retain", "the", "code", "this", "might", "seem", "like", "daunt", "task", "howev", "there", "amaz", "librari", "call", "ast", "python", "standard", "librari", "that", "can", "use", "extract", "function", "method", "and", "docstr", "can", "remov", "comment", "from", "code", "convert", "code", "into", "and", "then", "back", "from", "that", "represent", "code", "use", "the", "astor", "packag", "understand", "ast", "how", "these", "tool", "work", "not", "requir", "for", "this", "tutori", "but", "are", "veri", "interest", "topic", "for", "more", "context", "how", "this", "code", "use", "see", "this", "notebook", "prepar", "this", "data", "for", "model", "separ", "the", "data", "into", "train", "valid", "and", "test", "set", "also", "maintain", "file", "which", "name", "lineag", "keep", "track", "the", "origin", "sourc", "each", "code", "docstr", "pair", "final", "appli", "the", "same", "transform", "code", "that", "doe", "not", "contain", "docstr", "and", "save", "that", "separ", "will", "want", "the", "abil", "search", "this", "code", "well", "part", "num", "build", "code", "summar", "use", "seqnumseq", "model", "part", "num", "notebook", "conceptu", "build", "sequencetosequ", "model", "summar", "code", "ident", "the", "github", "issu", "summar", "present", "previous", "instead", "issu", "bodi", "use", "python", "code", "and", "instead", "issu", "titl", "use", "docstr", "howev", "unlik", "github", "issu", "text", "code", "not", "natur", "languag", "fulli", "exploit", "the", "inform", "within", "code", "could", "introduc", "domainspecif", "optim", "like", "treebas", "lstms", "and", "syntaxawar", "token", "for", "this", "tutori", "are", "keep", "thing", "simpl", "and", "treat", "code", "like", "natur", "languag", "and", "still", "get", "reason", "result", "build", "function", "summar", "veri", "cool", "project", "own", "but", "aren", "spend", "too", "much", "time", "focus", "this", "but", "encourag", "the", "entir", "endtoend", "train", "procedur", "for", "this", "model", "describ", "this", "notebook", "not", "discuss", "the", "preprocess", "architectur", "for", "this", "model", "ident", "the", "issu", "summar", "our", "motiv", "for", "train", "this", "model", "not", "use", "for", "the", "task", "summar", "code", "but", "rather", "general", "purpos", "featur", "extractor", "for", "code", "technic", "speak", "this", "step", "option", "are", "onli", "through", "these", "step", "initi", "the", "model", "weight", "for", "relat", "downstream", "task", "later", "step", "will", "extract", "the", "encod", "from", "this", "model", "and", "fine", "tune", "for", "anoth", "task", "below", "screenshot", "some", "exampl", "output", "this", "model", "sampl", "result", "from", "function", "summar", "test", "set", "see", "notebook", "here", "can", "see", "that", "while", "the", "result", "aren", "perfect", "there", "strong", "evid", "that", "the", "model", "has", "learn", "extract", "some", "semant", "mean", "from", "code", "which", "our", "main", "goal", "for", "this", "task", "can", "evalu", "these", "model", "quantit", "use", "the", "metric", "which", "also", "discuss", "this", "notebook", "should", "note", "that", "train", "seqnumseq", "model", "summar", "code", "not", "the", "onli", "techniqu", "can", "use", "build", "featur", "extractor", "for", "code", "for", "exampl", "could", "also", "train", "and", "use", "the", "discrimin", "featur", "extractor", "howev", "these", "other", "approach", "are", "outsid", "the", "scope", "this", "tutori"], "timestamp_scraper": 1556479552.022787, "title": "How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning", "read_time": 405.59999999999997, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2018/06/natural-language-semantic-search-arbitrary-objects-deep-learning.html?page=2#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/hamelhusain/\" rel=\"noopener noreferrer\" target=\"_blank\">Hamel Husain</a>\u00a0&amp;\u00a0<a href=\"https://www.linkedin.com/in/hohsiangwu/\" rel=\"noopener noreferrer\" target=\"_blank\">Ho-Hsiang Wu</a>, GitHub</b></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/0*jmN0ix92GC1QfJNF.jpg\" width=\"65%\"><br>\n<font size=\"-1\">A picture of\u00a0<a href=\"https://hubot.github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Hubot</a>.</font></br></img></center></p>\n<p>\u00a0</p>\n<h3>Motivation:</h3>\n<p>\u00a0<br>\nThe power of modern search engines is undeniable: you can summon knowledge from the internet at a moment\u2019s notice. Unfortunately, this superpower isn\u2019t omnipresent. There are many situations where search is relegated to strict keyword search, or when the objects aren\u2019t text, search may not be available. Furthermore, strict keyword search doesn\u2019t allow the user to\u00a0<a href=\"https://en.wikipedia.org/wiki/Semantic_search\" rel=\"noopener noreferrer\" target=\"_blank\">search semantically</a>, which means information is not as discoverable.</br></p>\n<p>Today, we share a reproducible, minimally viable product that illustrates how you can enable\u00a0<a href=\"https://en.wikipedia.org/wiki/Semantic_search\" rel=\"noopener noreferrer\" target=\"_blank\">semantic search</a>\u00a0for arbitrary objects! Concretely, we will show you how to create a system that searches python code semantically\u200a\u2014\u200abut this approach can be generalized to other entities (such as pictures or sound clips).</p>\n<p>Why is semantic search so exciting? Consider the below example:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*TIOajbCx7KDdcaBxNxmjXg.gif\" width=\"90%\"/><br>\n<font size=\"-1\">Semantic search at work on python code. *See Disclaimer section\u00a0below.</font></br></center></p>\n<p>The search query presented is \u201c<strong>Ping</strong>\u00a0<strong>REST api</strong>\u00a0and return results\u201d. However, the search returns reasonable results even though the code &amp; comments found do not contain the words\u00a0<strong>Ping, REST</strong>\u00a0or\u00a0<strong>api.</strong></p>\n<p>This illustrates the\u00a0<strong>power of\u00a0</strong><a href=\"https://en.wikipedia.org/wiki/Semantic_search\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>semantic search</strong></a><strong>: we can search content for its<em>meaning\u00a0</em>in addition to keywords</strong>, and maximize the chances the user will find the information they are looking for. The implications of semantic search are profound\u200a\u2014\u200afor example, such a procedure would allow developers to search for code in repositories even if they are not familiar with the syntax or fail to anticipate the right keywords. More importantly, you can generalize this approach to objects such as pictures, audio and other things that we haven\u2019t thought of yet.</p>\n<p>If this is not exciting enough,\u00a0<strong>here is a live demonstration of what you will be able to build by the end of this tutorial</strong>:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*nT198cL_AOK6XTfEfuBDYw.gif\" width=\"99%\"/><br>\n<font size=\"-1\">Sometimes I use Jupyter notebooks and\u00a0<a href=\"https://ipython.org/ipython-doc/3/config/custommagics.html\" rel=\"noopener noreferrer\" target=\"_blank\">custom magic functions</a>\u00a0to create demonstrations when I cannot build a pretty website. it can be a quick way to interactively demonstrate your\u00a0work!</font></br></center></p>\n<p>\u00a0</p>\n<h3>Intuition\u00a0: Construct a Shared Vector-Space</h3>\n<p>\u00a0<br/>\nBefore diving into the technical details, it is useful to provide you with a high-level intuition of how we will accomplish semantic search. The central idea is to represent both text and the object we want to search (code) in a shared vector space, as illustrated below:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*zhLXNHK8ILaYV8tT-jDlOQ.png\" width=\"99%\"/><br/>\n<font size=\"-1\"><strong>Example: Text 2</strong>\u00a0and the\u00a0<strong>code</strong>\u00a0should be represented by similar vectors since they are directly\u00a0related.<br/>\n</font></center></p>\n<p>The goal is to map code into the vector space of natural language, such that (text, code) pairs that describe the same concept are close neighbors, whereas unrelated (text, code) pairs are further apart, measured by\u00a0<a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\" rel=\"noopener noreferrer\" target=\"_blank\">cosine similarity</a>.</p>\n<p>There are many ways to accomplish this goal, however, we will demonstrate the approach of taking a pre-trained model that extracts features from code and\u00a0<a href=\"https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html\" rel=\"noopener noreferrer\" target=\"_blank\">fine-tuning</a>\u00a0this model to project latent code features into a vector space of natural language. One warning: We use the term\u00a0<strong><em>vector</em></strong>\u00a0and\u00a0<strong><em>embedding</em></strong>interchangeably<strong><em>\u00a0</em></strong>throughout this tutorial.</p>\n<p>\u00a0</p>\n<h3>Prerequisites</h3>\n<p>\u00a0<br/>\nWe recommend familiarity with the following items prior to reading this tutorial:</p>\n<ul>\n<li><em>Sequence-to-sequence models:</em>\u00a0It will be helpful to review the information presented\u00a0<a href=\"https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\" rel=\"noopener noreferrer\" target=\"_blank\">in a previous tutorial</a>.\n<li>Peruse\u00a0<a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41869.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">this paper</a>\u00a0at a high level and understand the intuition of the approach presented. We draw on similar concepts for what we present here.\n</li></li></ul>\n<p>\u00a0</p>\n<h3>Overview:</h3>\n<p>\u00a0<br/>\nThis tutorial will be broken into 5 concrete steps. These steps are illustrated below and will be a useful reference as you progress throughout the tutorial. After completing the tutorial, it will be useful to revisit this diagram to reinforce how all the steps fit together.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*HxrVL3bDLD8G0elzF5cp4w.png\" width=\"99%\"/><br/>\n<font size=\"-1\">A mind map of this tutorial. Hi-res version available\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/diagram/Diagram.png\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>.</font></center></p>\n<p>Each step 1\u20135 corresponds to a Jupyter notebook\u00a0<a href=\"https://github.com/hamelsmu/code_search/tree/master/notebooks\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>. We will explore each step in more detail below.</p>\n<p>\u00a0</p>\n<h3><strong>Part 1\u200a\u2014\u200aAcquire and Parse\u00a0Data:</strong></h3>\n<p>\u00a0<br/>\n<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Part 1 notebook</em></a></p>\n<p>The folks at Google collect and store data from open-source GitHub repositories on\u00a0<a href=\"https://cloud.google.com/bigquery/\" rel=\"noopener noreferrer\" target=\"_blank\">BigQuery</a>. This is a great open dataset for all kinds of interesting data-science projects, including this one! When you sign up for a Google Cloud account, they give you $300 which is more than enough to query the data for this exercise. Getting this data is super convenient, as you can use SQL queries to select what type of files you are looking for as well as other meta-data about repos such as commits, stars, etc.</p>\n<p>The steps to acquire this data are outlined in this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>. Luckily,\u00a0<a href=\"https://kubernetes.io/blog/2017/12/introducing-kubeflow-composable/\" rel=\"noopener noreferrer\" target=\"_blank\">some awesome people on the Kubeflow team at Google</a>\u00a0have gone through these steps and have graciously hosted the data for this exercise, which is also described in this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>.</p>\n<p>After collecting this data, we need to parse these files into (code,\u00a0<a href=\"http://www.pythonforbeginners.com/basics/python-docstrings\" rel=\"noopener noreferrer\" target=\"_blank\">docstring</a>) pairs. For this tutorial, one unit of code will be either a\u00a0<a href=\"https://stackoverflow.com/questions/18138166/what-is-a-top-level-statement-in-python\" rel=\"noopener noreferrer\" target=\"_blank\">top-level function</a>\u00a0or a method. We want to gather these pairs as training data for a model that will summarize code (more on that later). We also want to strip the code of all comments and only retain the code. This might seem like a daunting task, however, there is an amazing library called\u00a0<a href=\"https://docs.python.org/3/library/ast.html\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>ast</strong>\u00a0in Python\u2019s standard library</a>that can be used to extract functions, methods and, docstrings. We can remove comments from code by converting code into an\u00a0<a href=\"https://en.wikipedia.org/wiki/Abstract_syntax_tree\" rel=\"noopener noreferrer\" target=\"_blank\">AST</a>\u00a0and then back from that representation to code, using the\u00a0<a href=\"https://pypi.org/project/astor/\" rel=\"noopener noreferrer\" target=\"_blank\">Astor</a>\u00a0package. Understanding of ASTs or how these tools work is not required for this tutorial, but are very interesting topics!</p>\n<p><center><script src=\"https://gist.github.com/hamelsmu/7439b131dd9b37d246cdab71b5c898ac.js\"></script><br/>\n<font size=\"-1\">For more context of how this code is used, see this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/1%20-%20Preprocess%20Data.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>.<br/>\n</font></center></p>\n<p>To prepare this data for modeling, we separate the data into train, validation and test sets. We also maintain files (which we name \u201clineage\u201d) to keep track of the original source of each (code, docstring) pair. Finally, we apply the same transforms to code that does not contain a docstring and save that separately, as we will want the ability to search this code as well!</p>\n<p>\u00a0</p>\n<h3>Part 2\u200a\u2014\u200aBuild a Code Summarizer Using a Seq2Seq\u00a0Model:</h3>\n<p>\u00a0<br/>\n<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Part 2 notebook</em></a></p>\n<p>Conceptually, building a sequence-to-sequence model to summarize code is identical to the\u00a0<a href=\"https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub issue summarizer</a>\u00a0we presented previously\u200a\u2014\u200ainstead of issue bodies we use python code, and instead of issue titles, we use docstrings.</p>\n<p>However, unlike GitHub issue text, code is not natural language. To fully exploit the information within code, we could introduce domain-specific optimizations like\u00a0<a href=\"https://arxiv.org/pdf/1802.00921.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">tree-based LSTMs</a>\u00a0and syntax-aware tokenization. For this tutorial, we are going to keep things simple and treat code like natural language (and still get reasonable results).</p>\n<p>Building a function summarizer is a very cool project on its own, but we aren\u2019t going to spend too much time focusing on this (but we encourage you to do so!). The entire end-to-end training procedure for this model is described in\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">this notebook</a>. We do not discuss the pre-processing or architecture for this model as it is identical to the\u00a0<a href=\"https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8\" rel=\"noopener noreferrer\" target=\"_blank\">issue summarizer</a>.</p>\n<p>Our motivation for training this model is not to use it for the task of summarizing code, but rather as a general purpose feature extractor for code. Technically speaking, this step is optional as we are only going through these steps to initialize the model weights for a related downstream task. In a later step, we will extract the encoder from this model and\u00a0<a href=\"https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html\" rel=\"noopener noreferrer\" target=\"_blank\">fine tune</a>\u00a0it for another task. Below is a screenshot of some example outputs of this model:</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*k1iE9QFgfF2K7BGE_4KIFg.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Sample results from function summarizer on a test set. See notebook\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">here</a>.</font></center></p>\n<p>We can see that while the results aren\u2019t perfect, there is strong evidence that the model has learned to extract some semantic meaning from code, which is our main goal for this task. We can evaluate these models quantitatively using the\u00a0<a href=\"https://en.wikipedia.org/wiki/BLEU\" rel=\"noopener noreferrer\" target=\"_blank\">BLEU metric</a>, which is also discussed in this\u00a0<a href=\"https://github.com/hamelsmu/code_search/blob/master/notebooks/2%20-%20Train%20Function%20Summarizer%20With%20Keras%20%2B%20TF.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\">notebook</a>.<br/>\nIt should be noted that training a seq2seq model to summarize code is not the only technique you can use to build a feature extractor for code. For example, you could also train a\u00a0<a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"noopener noreferrer\" target=\"_blank\">GAN</a>\u00a0and\u00a0<a href=\"https://arxiv.org/pdf/1511.06434.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">use the discriminator as a feature extractor</a>. However, these other approaches are outside the scope of this tutorial.</p>\n</div> ", "website": "kdnuggets"}