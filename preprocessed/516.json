{"content": "By Zachary Chase Lipton , UCSD. comments \r \r What is the best way to quantify the quality of your classification algorithm?\r As we strive for better algorithms,\r we often fail to think critically about what it means for predictions to be \"good\".\r Evaluation methodology and decision theory are tightly linked.\r Often a classifier outputs numerical scores but a performance metric takes binary predictions.\r In these cases, any such metric specifies an optimal decision rule to convert scores to predictions.\r \r Thus in many settings, it would seem data scientists should consider\r how a system should behave when choosing a performance metric.\r Last September, at ECML in Nancy,\r I presented \r a paper exploring some surprising properties of F1 score. (full pdf) \r In this post, I'll explore some of the deep problems\r our community faces as regards evaluation methodology.", "title_html": "<h1 id=\"title\">Failing Optimally \u2013 Data Science\u2019s Measurement Problem</h1> ", "url": "https://www.kdnuggets.com/2015/03/data-science-measurement-problem-accuracy-auroc-f1.html", "tfidf": {"tfidf": {"seem": 2.29123971713, "this": 1.00379362671, "behav": 15.6413793103, "quantifi": 41.669291338600004, "such": 1.06151377374, "these": 1.07415426252, "and": 1.00006299213, "perform": 3.0627954085000004, "but": 1.01632417899, "our": 2.35758835759, "classif": 8.067073170730001, "algorithm": 55.9014084508, "tight": 10.0100882724, "post": 2.23826307627, "would": 1.0828729281799998, "surpris": 4.36633663366, "full": 1.66729678639, "comment": 3.05954904606, "evalu": 13.901926444839999, "best": 1.5828514456600002, "chase": 8.989807474520001, "about": 1.06486015159, "explor": 6.79187165776, "think": 2.90715986083, "communiti": 1.96121062384, "take": 1.13961668222, "some": 2.08073394496, "data": 3.37643555934, "way": 1.2190739461, "should": 3.3286508019800003, "metric": 66.7058823528, "lipton": 230.086956522, "system": 1.38739840951, "good": 1.51981619759, "specifi": 6.920662598080001, "zachari": 75.961722488, "rule": 1.7415533128599998, "link": 2.15151104486, "classifi": 5.2937645882, "numer": 1.83325635104, "septemb": 1.45638014861, "optim": 11.5377906977, "ani": 1.13383802314, "critic": 1.67010309278, "mean": 1.44906900329, "scientist": 4.69426374926, "the": 3.0, "paper": 2.6628648104700003, "set": 1.18707940781, "methodolog": 35.797068771199996, "theori": 3.02745995423, "thus": 1.6463756092500001, "how": 1.60250328051, "decis": 4.32, "binari": 32.4, "present": 1.25551601423, "regard": 1.78944995491, "face": 1.80327124035, "what": 2.50686878256, "for": 2.00063008002, "consid": 1.2397313759200002, "predict": 15.554539516650001, "nanci": 15.2800769971, "fail": 1.9281029876099998, "score": 12.865478119950001, "output": 7.676982591880001, "properti": 2.5949656750599996, "convert": 3.2740771293099997, "problem": 1.76674827509, "when": 1.02076769755, "strive": 21.9585062241, "often": 2.5890410959, "deep": 3.6279707495399998, "mani": 1.04426757877, "qualiti": 2.9329392204, "are": 1.02990593578, "last": 1.2117234010100002, "choos": 4.17899447223, "better": 2.0065722952500002, "pdf": 10.8665297741, "case": 1.48498737256}, "logtfidf": {"seem": 0.829093032276, "this": 0.0037864490525, "behav": 2.7499199224299997, "quantifi": 3.72976443878, "such": 0.059695977806, "these": 0.0715336194008, "and": 6.29901420636e-05, "perform": 0.85236170116, "but": 0.0161923720719, "our": 0.8576392141820001, "classif": 2.08779073629, "algorithm": 6.66088479036, "tight": 2.3035934117099996, "post": 0.8057001527009999, "would": 0.0796176279647, "surpris": 1.47392435861, "full": 0.511203624148, "comment": 1.11826753454, "evalu": 3.8777604862599997, "best": 0.459227932947, "chase": 2.1960914327400003, "about": 0.0628434774746, "explor": 2.44515874436, "think": 1.06717661175, "communiti": 0.673561947791, "take": 0.130691962197, "some": 0.079147018129, "data": 1.2168205848, "way": 0.19809150993500002, "should": 1.018839753516, "metric": 9.305042554679998, "lipton": 5.43845730931, "system": 0.327430345585, "good": 0.418589404907, "specifi": 1.93451151621, "zachari": 4.33022956194, "rule": 0.554777423537, "link": 0.7661704068449999, "classifi": 1.6665296351499999, "numer": 0.606093812346, "septemb": 0.375954006775, "optim": 2.4456277954099996, "ani": 0.125608358366, "critic": 0.512885356729, "mean": 0.37092128352, "scientist": 1.54634128444, "the": 0.0, "paper": 0.979402539665, "set": 0.171496011289, "methodolog": 5.769437663180001, "theori": 1.10772396902, "thus": 0.49857627139300004, "how": 0.47156695693000006, "decis": 1.5402164433919998, "binari": 3.4781584227999995, "present": 0.227546654799, "regard": 0.5819082848730001, "face": 0.589602371257, "what": 0.451774593654, "for": 0.0006299807907940001, "consid": 0.214894723824, "predict": 4.937220713069999, "nanci": 2.7265498227999996, "fail": 0.656536611573, "score": 4.367805962310001, "output": 2.03822657827, "properti": 0.953573289192, "convert": 1.1860360368, "problem": 0.569140724273, "when": 0.0205549888584, "strive": 3.0891545917400003, "often": 0.516280786702, "deep": 1.2886734698, "mani": 0.0433157581221, "qualiti": 1.07600506711, "are": 0.0294674735827, "last": 0.19204364461100001, "choos": 1.43007066072, "better": 0.6964279406, "pdf": 2.38568740215, "case": 0.395406268889}, "logidf": {"seem": 0.829093032276, "this": 0.0037864490525, "behav": 2.7499199224299997, "quantifi": 3.72976443878, "such": 0.059695977806, "these": 0.0715336194008, "and": 6.29901420636e-05, "perform": 0.42618085058, "but": 0.0161923720719, "our": 0.8576392141820001, "classif": 2.08779073629, "algorithm": 3.33044239518, "tight": 2.3035934117099996, "post": 0.8057001527009999, "would": 0.0796176279647, "surpris": 1.47392435861, "full": 0.511203624148, "comment": 1.11826753454, "evalu": 1.9388802431299998, "best": 0.459227932947, "chase": 2.1960914327400003, "about": 0.0628434774746, "explor": 1.22257937218, "think": 1.06717661175, "communiti": 0.673561947791, "take": 0.130691962197, "some": 0.0395735090645, "data": 1.2168205848, "way": 0.19809150993500002, "should": 0.509419876758, "metric": 3.1016808515599994, "lipton": 5.43845730931, "system": 0.327430345585, "good": 0.418589404907, "specifi": 1.93451151621, "zachari": 4.33022956194, "rule": 0.554777423537, "link": 0.7661704068449999, "classifi": 1.6665296351499999, "numer": 0.606093812346, "septemb": 0.375954006775, "optim": 2.4456277954099996, "ani": 0.125608358366, "critic": 0.512885356729, "mean": 0.37092128352, "scientist": 1.54634128444, "the": 0.0, "paper": 0.979402539665, "set": 0.171496011289, "methodolog": 2.8847188315900003, "theori": 1.10772396902, "thus": 0.49857627139300004, "how": 0.47156695693000006, "decis": 0.7701082216959999, "binari": 3.4781584227999995, "present": 0.227546654799, "regard": 0.5819082848730001, "face": 0.589602371257, "what": 0.225887296827, "for": 0.00031499039539700004, "consid": 0.214894723824, "predict": 1.6457402376899999, "nanci": 2.7265498227999996, "fail": 0.656536611573, "score": 1.4559353207700003, "output": 2.03822657827, "properti": 0.953573289192, "convert": 1.1860360368, "problem": 0.569140724273, "when": 0.0205549888584, "strive": 3.0891545917400003, "often": 0.258140393351, "deep": 1.2886734698, "mani": 0.0433157581221, "qualiti": 1.07600506711, "are": 0.0294674735827, "last": 0.19204364461100001, "choos": 1.43007066072, "better": 0.6964279406, "pdf": 2.38568740215, "case": 0.395406268889}, "freq": {"seem": 1, "this": 1, "behav": 1, "quantifi": 1, "such": 1, "these": 1, "and": 1, "perform": 2, "but": 1, "our": 1, "classif": 1, "algorithm": 2, "tight": 1, "post": 1, "would": 1, "surpris": 1, "full": 1, "comment": 1, "evalu": 2, "best": 1, "chase": 1, "about": 1, "explor": 2, "think": 1, "communiti": 1, "take": 1, "some": 2, "data": 1, "way": 1, "should": 2, "metric": 3, "lipton": 1, "system": 1, "good": 1, "specifi": 1, "zachari": 1, "rule": 1, "link": 1, "classifi": 1, "numer": 1, "septemb": 1, "optim": 1, "ani": 1, "critic": 1, "mean": 1, "scientist": 1, "the": 3, "paper": 1, "set": 1, "methodolog": 2, "theori": 1, "thus": 1, "how": 1, "decis": 2, "binari": 1, "present": 1, "regard": 1, "face": 1, "what": 2, "for": 2, "consid": 1, "predict": 3, "nanci": 1, "fail": 1, "score": 3, "output": 1, "properti": 1, "convert": 1, "problem": 1, "when": 1, "strive": 1, "often": 2, "deep": 1, "mani": 1, "qualiti": 1, "are": 1, "last": 1, "choos": 1, "better": 1, "pdf": 1, "case": 1}, "idf": {"seem": 2.29123971713, "this": 1.00379362671, "behav": 15.6413793103, "quantifi": 41.669291338600004, "such": 1.06151377374, "these": 1.07415426252, "and": 1.00006299213, "perform": 1.5313977042500002, "but": 1.01632417899, "our": 2.35758835759, "classif": 8.067073170730001, "algorithm": 27.9507042254, "tight": 10.0100882724, "post": 2.23826307627, "would": 1.0828729281799998, "surpris": 4.36633663366, "full": 1.66729678639, "comment": 3.05954904606, "evalu": 6.9509632224199995, "best": 1.5828514456600002, "chase": 8.989807474520001, "about": 1.06486015159, "explor": 3.39593582888, "think": 2.90715986083, "communiti": 1.96121062384, "take": 1.13961668222, "some": 1.04036697248, "data": 3.37643555934, "way": 1.2190739461, "should": 1.6643254009900001, "metric": 22.235294117600002, "lipton": 230.086956522, "system": 1.38739840951, "good": 1.51981619759, "specifi": 6.920662598080001, "zachari": 75.961722488, "rule": 1.7415533128599998, "link": 2.15151104486, "classifi": 5.2937645882, "numer": 1.83325635104, "septemb": 1.45638014861, "optim": 11.5377906977, "ani": 1.13383802314, "critic": 1.67010309278, "mean": 1.44906900329, "scientist": 4.69426374926, "the": 1.0, "paper": 2.6628648104700003, "set": 1.18707940781, "methodolog": 17.898534385599998, "theori": 3.02745995423, "thus": 1.6463756092500001, "how": 1.60250328051, "decis": 2.16, "binari": 32.4, "present": 1.25551601423, "regard": 1.78944995491, "face": 1.80327124035, "what": 1.25343439128, "for": 1.00031504001, "consid": 1.2397313759200002, "predict": 5.18484650555, "nanci": 15.2800769971, "fail": 1.9281029876099998, "score": 4.2884927066500005, "output": 7.676982591880001, "properti": 2.5949656750599996, "convert": 3.2740771293099997, "problem": 1.76674827509, "when": 1.02076769755, "strive": 21.9585062241, "often": 1.29452054795, "deep": 3.6279707495399998, "mani": 1.04426757877, "qualiti": 2.9329392204, "are": 1.02990593578, "last": 1.2117234010100002, "choos": 4.17899447223, "better": 2.0065722952500002, "pdf": 10.8665297741, "case": 1.48498737256}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Failing Optimally \u2013 Data Science\u2019s Measurement Problem</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2015/03/data-science-measurement-problem-accuracy-auroc-f1.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Failing Optimally \u2013 Data Science\u2019s Measurement Problem Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2015/n07.html\" rel=\"prev\" title=\"KDnuggets\u2122 News 15:n07, Mar 4: Analytics/Data Science Salaries; Machine Learning Flaws; Strata Highlights\"/>\n<link href=\"https://www.kdnuggets.com/2015/03/jtleek-elements-data-analytic-style.html\" rel=\"next\" title=\"The Elements of Data Analytic Style \u2013 checklist\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2015/03/data-science-measurement-problem-accuracy-auroc-f1.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=30283\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2015/03/data-science-measurement-problem-accuracy-auroc-f1.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-30283 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 4-Mar, 2015  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2015/index.html\">2015</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/03/opinions-interviews.html\">Opinions, Interviews, Reports</a> \u00bb Failing Optimally \u2013 Data Science\u2019s Measurement Problem (\u00a0<a href=\"/2015/n08.html\">15:n08</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Failing Optimally \u2013 Data Science\u2019s Measurement Problem</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2015/n07.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2015/03/jtleek-elements-data-analytic-style.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/accuracy\" rel=\"tag\">Accuracy</a>, <a href=\"https://www.kdnuggets.com/tag/competition\" rel=\"tag\">Competition</a>, <a href=\"https://www.kdnuggets.com/tag/model-performance\" rel=\"tag\">Model Performance</a>, <a href=\"https://www.kdnuggets.com/tag/zachary-lipton\" rel=\"tag\">Zachary Lipton</a></div>\n<br/>\n<p class=\"excerpt\">\n     Data science has a measurement problem. Simple metrics may not address complex situations. But complex metrics present myriad problems.  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/zlipton\" rel=\"author\" title=\"Posts by Zachary Chase Lipton\">Zachary Chase Lipton</a>, UCSD.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\r\n\r\nWhat is the best way to quantify the quality of your classification algorithm?\r\nAs we strive for better algorithms,\r\nwe often fail to think critically about what it means for predictions to be \"good\".\r\nEvaluation methodology and decision theory are tightly linked.\r\nOften a classifier outputs numerical scores but a performance metric takes binary predictions.\r\nIn these cases, any such metric specifies an optimal decision rule to convert scores to predictions.\r\n\r\nThus in many settings, it would seem data scientists should consider\r\nhow a system should behave when choosing a performance metric.\r\nLast September, at ECML in Nancy,\r\nI presented <a \"http:=\"\" ecmldraft.pdf\"=\"\" href=\"\" media=\"\" papers=\"\" zacklipton.com=\"\">\r\na paper exploring some surprising properties of F1 score. (full pdf)</a>\r\nIn this post, I'll explore some of the deep problems\r\nour community faces as regards evaluation methodology.\r\n</div></div></div></div></div></body></html>\n<p>\r\nImagine you want to classify documents with binary labels.\r\nPerhaps you are trying to classify emails as spam/not spam.\r\nOr perhaps you have a collection of documents\r\nand a vocabulary of tags (as in a blog post like this)\r\nand want to apply the appropriate tags for each document.\r\nFormally, we call the spam detection problem <em>binary classification</em>\r\nand the autotagging problem <em>multilabel classification.</em>\n</p>\n<p>\r\nSo you choose your favorite classification algorithm,\r\nfor instance logistic regression or a support vector machine.\r\nYou regularize to maximize performance on holdout data.\r\nFor simplicity, assume that in the multilabel case,\r\na separate classifier is trained for each label.\r\nFinally, you have a model that can attach real valued scores to documents.\r\nYou might think you're done! But some glaring questions remain.\r\n</p>\n<p><strong>What do you do with these scores? </strong><br>\n<strong>What does it mean for a system to output \"good\" scores?</strong><br>\n<strong>How can you compare the performance of logistic regression,\r\nwhich minimizes log loss, against a support vector machine,\r\nwhich minimizes hinge loss?</strong><br>\n<strong>Should a performance metric operate on real valued scores or binary predictions?</strong><br>\n<strong>How does class balance influence the choice of performance metric?</strong><br/>\n<strong>If the dataset is multilabel, how do you aggregate scores across labels?</strong></br></br></br></br></p>\n<p>\r\nIn both the research community and data science practice,\r\na lot of thought goes into designing and optimizing algorithms,\r\nbut too often evaluation methodology is an afterthought.\r\n</p>\n<p><strong>Evaluating Rankings vs. Predictions</strong></p>\n<p>\r\nA primary consideration is whether an evaluation metric\r\nshould take as input ordinal rankings or binary predictions.\r\nIn either case, it may be useful to first formalize a few terms.\r\nWhen the ground truth label is positive, we call this an actual positive.\r\nWhen the predicted label is positive, we call this a predicted positive.\r\nAs indicated in the following <em>confusion matrix (Figure 1)</em>,\r\nFalse positives and false negatives occur\r\nwhen the predicted label and ground truth disagree.\r\n</p>\n<img alt=\"Confusion matrix for binary classification\" src=\"/wp-content/uploads/confusion-matrix.png\"><br/><br/>\n<p>\r\nIn an information theoretic sense, rankings are clearly more expressive than binary outputs.\r\nGiven rankings, a user could impose their own cost-sensitivity (relative costs of false positive and false negative)\r\nand craft their own decision theory.\r\nFurther, several established performance metrics exist which operate on rankings as inputs.\r\nArea under the ROC curve (AUROC) is one common metric\r\nthat operates on fully specified rankings.\r\nAUROC plots the true positive rate against the false positive rate.\r\nA system that predicts all actual positives ahead of all actual negatives achieves the maximum AUROC score of 1.\r\nA system outputting completely random rankings would be expected to achieve an AUROC of .5.\r\n(An example AUROC taken from Wikipedia is shown below.)\r\n<img src=\"/wp-content/uploads/auroc.png\" width=\"450\"/>\n</p>\n<p>\r\nOn the other hand, such a method requires dense predictions\r\nin order to evaluate their comparative worth.\r\nTo evaluate the performance of a system on a multilabel dataset,\r\none would need to submit as many predictions as there are examples times labels.\r\nAnother drawback to evaluating performance based on rankings\r\nis that it may bias the evaluation against algorithms such as decision trees,\r\nwhich output 0/1 classifications but not rankings.\r\n</p>\n<p><strong>Binary Metrics - Accuracy</strong></p>\n<p>\r\nThe most widely known metrics operate on binary predictions.\r\nIn other words, if the model outputs numerical values, \r\nthese must be thresholded to produce binary (positive/negative) predictions.\r\n\r\nAmong the binary metrics, accuracy is the simplest.\r\nExpressible as (tp + tn) / N, where N is the total number of predictions,\r\naccuracy has several charming properties.\r\nFor example, given scores which are calibrated probabilities,\r\nthe threshold to maximize accuracy is simply .5.\r\nWe'll postpone a serious conversation on calibration for another post.\r\nBut suffice it to say that a calibrated probability behaves like a real probability.\r\nIf 1000 examples receive a score of .5 each, we expect roughly 500 of them to be positive.\r\nAnother nice property of accuracy emerges in the multilabel case. \r\nThe accuracy as calculated on the total confusion matrix across many labels\r\nis identical to averaging the accuracy calculated separately on each label.\r\n\r\n</p>\n<p>\r\nOne might reasonably wonder under what conditions\r\nwe would ever want an alternative metric,\r\ngiven accuracy's useful properties.\r\nHowever, class imbalance presents such a scenario.\r\nIn many information retrieval tasks,\r\nthe <em>positive</em> class is much rarer than the <em>negative</em> class.\r\nIn these cases, when nearly all examples are <em>actually</em> negative,\r\na trivial classifier that always predicts negative\r\nwould get a great score, despite adding no information.\r\n</p>\n<p><strong>Binary Metrics - F1 </strong></p>\n<p>\r\nFor this reason, many researchers and data scientists\r\nreport F1 score when working with unbalanced datasets.\r\nF1 score is the harmonic mean (a kind of average) of precision and recall.\r\nPrecision, which can be expressed as tp / (tp + fp)\r\nis the percentage of all positive predictions that are in fact actual positives.\r\nRecall can be expressed as tp/(tp + fn)\r\nand captures the fraction of all actual positives that are predicted positive.\r\nF1 can then be expressed as 2tp / (2tp + fp + fn)\r\nand requires both high recall and high precision to yield a high score.\r\nThis all might intuitively reasonable.\r\nWhat could possibly go wrong?\r\n</p>\n<p><strong>F1's Definition Problem</strong></p>\n<p>\r\nFirst, it might have occurred when vieweing\r\nthe definitions of precision and recall\r\nthat recall is undefined when the number of actual positives is 0.\r\nSimilarly precision is undefined when the number of positive predictions is 0.\r\nFurther, when there are no actual positives and no examples are predicted positive,\r\neven the reduced expression of F1 is undefined.\r\nIt's unlikely that a test set for a single label binary classification will contain 0 actual positives.\r\nBut when working with a large multilabel problem,\r\nsuch as autotagging news articles according to specific categories,\r\nsome subset of categories may not be present in a test set.\r\nI know of no agreed upon convention which specifies the F1 score in these scenarios.\r\nThus, on multilabel datasets, when the reported F1 score is the average F1 score across labels,\r\nIt may be impossible to properly compare the self-reported scores from two different groups of researchers.\r\nLikely, many implementations set the undefined value to 1.\r\nConsider a classifier which predicts all examples to be negative.\r\nOn a shuffle of the data with no actual positives, it may get an F1 Score of 1.\r\nBut were there a single actual positive, it would get a score of 0!\r\n</p>\n<p><strong>F1's Thresholding Problem</strong></p>\n<p>\r\nRecall the straight-forwardness of thresholding probabilistic output to maximize accuracy.\r\nNow consider F1.\r\nAs we showed in <a \"http:=\"\" ecmldraft.pdf\"=\"\" href=\"\" media=\"\" papers=\"\" zacklipton.com=\"\">our paper</a>,\r\nthe optimal threshold to convert real-valued scores to F1-optimal binary predictions is not straightforward.\r\nThis is further evidenced by the considerable body of papers\r\nthat address the task of choosing the optimal threshold.\r\nMost systems rely upon a \"plug-in rule.\"\r\nThis means that first they learn a normal classifier\r\nand then feed the probabilistic predictions\r\ninto an algorithm which decides the threshold.\r\n</p>\n<p>\r\nWhile clearly many people optimize predictions before reporting F1 score, \r\nthere is no reason to believe that everyone who reports F1 score optimizes their predictions.\r\nIt is plausible that many researchers threshold at .5,\r\nreporting several metrics using those predictions,\r\nwhile other researchers separately threshold to maximize performance on each metric.\r\nTaken together, the definitional ambiguity and thresholding difficulty associated with F1\r\npresent formidable obstacles to comparing the results of competing systems.\r\n</p>\n<p>\n<strong>Some important questions arise:</strong>\n</p>\n<p>\n<strong>Does the system with the better score\r\nhave a stronger underlying algorithm or simply cleverer thresholding?</strong>\n</p>\n<p>\n<strong>While great F1 requires a great underlying classifier,\r\nhow suitable are the decisions which maximize F1 for any real-world task?</strong>\n</p>\n<p>\n<strong>What happens in the case when the underlying classifier is not so great?</strong>\n</p>\n<p>\r\nIn our paper we identified some simple but perhaps common pathological cases.\r\nOne curious behavior is that regardless of how rare a label is,\r\nif the classifier is completely uninformative (predicts the same low score for every example),\r\nthe way to maximize F1 is to predict every example to be positive!\r\nWe encountered just such a problem on a large multilabel document classification task,\r\nwhen the only predictive feature for a rare label was lost to feature selection.\r\nAs a result, our system tagged a large percentage of articles with the very rare label \"platypus\".\r\nThis appeared to be a bug, but was actually the optimal behavior given our poor classifier!\r\n</p>\n<p><strong>F1's Multilabel Problem</strong></p>\n<p>\r\nRemember that one nice property of accuracy is that\r\nit is identical to calculate accuracy on a confusion matrix collected across all labels\r\nor to average the accuracy as separately calculated across all labels.\r\nUnfortunately, this is not the case for F1.\r\nCollecting a confusion matrix across all labels is called micro-F1,\r\nand results in one threshold across all labels.\r\nMacro-F1, on the other hand which averages F1 scores across labels\r\nresults in setting a separate threshold for each label.\r\nAveraging F1 scores calculated separately on each example represents a third approach.\r\n</p>\n<p><strong>Addressing Cost Sensitivity</strong></p>\n<p>\r\nIn a sense, any threshold implies a cost-sensitive setting.\r\nThe optimal threshold to maximize F1 is always less than or equal to .5.\r\nInformally, we can say this means that when we use F1, \r\nwe care more about false negatives than false positives.\r\nBy using F1 score, we outsource the responsibility of choosing \"how much more\".\r\nHowever, we could explicitly chose our relative costs,\r\nperhaps by looking to the problem domain for some intrinsic cost ratio.\r\nIn these cases we could craft a weighted version of accuracy, \r\nsalvaging the benefits of a linear performance metric.\r\n</p>\n<p><strong>Wrap-up</strong></p>\n<p>\r\nEvaluating machine learning algorithms in the setting of class imbalance\r\nis a deep problem, which is complicated further in the multilabel setting.\r\nWhen, like F1, a metric has definitional ambiguity,\r\ncomparing self-reported performance across different systems \r\ncan be impossible even when researchers are honest and well-intentioned.\r\nFurther, when a metric is difficult to threshold optimally,\r\nit may be difficult to determine\r\nwhich system produced the most informative scores\r\nand which went about thresholding more meticulously.\r\nBecause data-mining research papers often don't decribe thresholding strategy,\r\nthis problem is even more confounding.\r\nWhile algorithms may be more exciting than evaluation methodology,\r\nit behooves the data science community\r\nto think critically about how machine learning systems will be used\r\nand to choose evaluation metrics which imply appropriate decision theory.\r\n</p>\n<img align=\"right\" alt=\"Zachary Chase Lipton\" src=\"/wp-content/uploads/zackliptonprofile.jpg\" width=\"113\"/>\n<strong><a href=\"http://zacklipton.com\">Zachary Chase Lipton</a></strong> is a PhD student in the Computer Science Engineering department at the University of California, San Diego. Funded by the <a href=\"http://healthsciences.ucsd.edu/som/medicine/divisions/dbmi/pages/default.aspx\">Division of Biomedical Informatics</a>, he is interested in both theoretical foundations and applications of machine learning. In addition to his work at UCSD, he has interned at Microsoft Research Labs.\r\n\r\n<br/><br/>\n<b>Related:</b>\n<ul class=\"three_ul\">\n<li><a href=\"/2015/01/deep-learning-flaws-universal-machine-learning.html\">(Deep Learning's Deep Flaws)'s Deep Flaws</a></li>\n<li><a href=\"/2015/02/data-science-confusing-jargon-abused.html\">Data Science\u2019s Most Used, Confused, and Abused Jargon</a></li>\n<li><a href=\"/2014/12/ibm-watson-analytics-microsoft-azure-machine-learning-p1.html\">IBM Watson Analytics vs. Microsoft Azure Machine Learning (Part 1)</a></li>\n<li><a href=\"/2015/01/differential-privacy-data-mining-compatible.html\">Differential Privacy: How to make Privacy and Data Mining Compatible</a></li>\n<li><a href=\"/2014/12/geoff-hinton-ama-neural-networks-brain-machine-learning.html\">Geoff Hinton AMA: Neural Networks, the Brain, and Machine Learning</a></li>\n<li><a href=\"/faq/precision-recall.html\">FAQ: How Are Precision and Recall Calculated?</a></li>\n</ul>\n<a name=\"comments\"></a>\n<div id=\"disqus_thread\"></div>\n<script>\r\n var disqus_shortname = 'kdnuggets';\r\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\r\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\r\n</script> </img>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2015/n07.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2015/03/jtleek-elements-data-analytic-style.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end-->\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning Experts</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2015/index.html\">2015</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2015/03/opinions-interviews.html\">Opinions, Interviews, Reports</a> \u00bb Failing Optimally \u2013 Data Science\u2019s Measurement Problem (\u00a0<a href=\"/2015/n08.html\">15:n08</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end-->\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556422089\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper-->\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.722 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 23:28:09 -->\n<!-- Compression = gzip -->", "content_tokenized": ["zachari", "chase", "lipton", "comment", "what", "the", "best", "way", "quantifi", "the", "qualiti", "classif", "algorithm", "strive", "for", "better", "algorithm", "often", "fail", "think", "critic", "about", "what", "mean", "for", "predict", "good", "evalu", "methodolog", "and", "decis", "theori", "are", "tight", "link", "often", "classifi", "output", "numer", "score", "but", "perform", "metric", "take", "binari", "predict", "these", "case", "ani", "such", "metric", "specifi", "optim", "decis", "rule", "convert", "score", "predict", "thus", "mani", "set", "would", "seem", "data", "scientist", "should", "consid", "how", "system", "should", "behav", "when", "choos", "perform", "metric", "last", "septemb", "nanci", "present", "paper", "explor", "some", "surpris", "properti", "score", "full", "pdf", "this", "post", "explor", "some", "the", "deep", "problem", "our", "communiti", "face", "regard", "evalu", "methodolog"], "timestamp_scraper": 1556482096.349258, "title": "Failing Optimally \u2013 Data Science\u2019s Measurement Problem", "read_time": 42.0, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/zlipton\" rel=\"author\" title=\"Posts by Zachary Chase Lipton\">Zachary Chase Lipton</a>, UCSD.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\r\n\r\nWhat is the best way to quantify the quality of your classification algorithm?\r\nAs we strive for better algorithms,\r\nwe often fail to think critically about what it means for predictions to be \"good\".\r\nEvaluation methodology and decision theory are tightly linked.\r\nOften a classifier outputs numerical scores but a performance metric takes binary predictions.\r\nIn these cases, any such metric specifies an optimal decision rule to convert scores to predictions.\r\n\r\nThus in many settings, it would seem data scientists should consider\r\nhow a system should behave when choosing a performance metric.\r\nLast September, at ECML in Nancy,\r\nI presented <a \"http:=\"\" ecmldraft.pdf\"=\"\" href=\"\" media=\"\" papers=\"\" zacklipton.com=\"\">\r\na paper exploring some surprising properties of F1 score. (full pdf)</a>\r\nIn this post, I'll explore some of the deep problems\r\nour community faces as regards evaluation methodology.\r\n</div> ", "website": "kdnuggets"}