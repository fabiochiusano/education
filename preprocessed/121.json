{"content": "comments By Dipanjan Sarkar , Intel Editor's note: This post is only one part of a far more thorough and in-depth original, found here , which covers much more than what is included here. Let\u2019s look at some of the popular word embedding models now and engineering features from our corpora! \u00a0 The Word2Vec\u00a0Model \u00a0 This model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity. Essentially these are unsupervised models which can take in massive textual corpora, create a vocabulary of possible words and generate dense word embeddings for each word in the vector space representing that vocabulary. Usually you can specify the size of the word embedding vectors and the total number of vectors are essentially the size of the vocabulary. This makes the dimensionality of this dense vector space much lower than the high-dimensional sparse vector space built using traditional Bag of Words models. There are two different model architectures which can be leveraged by Word2Vec to create these word embedding representations. These include, The Continuous Bag of Words (CBOW) Model The Skip-gram Model There were originally introduced by Mikolov et al. and I recommend interested readers to read up on the original papers around these models which include,\u00a0 \u2018Distributed Representations of Words and Phrases and their Compositionality\u2019 \u00a0by Mikolov et al. \u00a0and\u00a0 \u2018Efficient Estimation of Word Representations in Vector Space\u2019 \u00a0by Mikolov et al. \u00a0to gain some good in-depth perspective. \u00a0 The Continuous Bag of Words (CBOW)\u00a0Model \u00a0 The CBOW model architecture tries to predict the current target word (the center word) based on the source context words (surrounding words). Considering a simple sentence,\u00a0 \u201cthe quick brown fox jumps over the lazy dog\u201d , this can be pairs of\u00a0 (context_window, target_word) \u00a0where if we consider a context window of size 2, we have examples like\u00a0 ([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0 and so on. Thus the model tries to predict the\u00a0 target_word \u00a0based on the\u00a0 context_window \u00a0words. The CBOW model architecture (Source:\u00a0 /pdf/1301.3781.pdf \u00a0Mikolov el\u00a0al.) While the Word2Vec family of models are unsupervised, what this means is that you can just give it a corpus without additional labels or information and it can construct dense word embeddings from the corpus. But you will still need to leverage a supervised, classification methodology once you have this corpus to get to these embeddings. But we will do that from within the corpus itself, without any auxiliary information. We can model this CBOW architecture now as a deep learning classification model such that we take in the\u00a0 context words as our input, X \u00a0and try to predict the\u00a0 target word, Y . In fact building this architecture is simpler than the skip-gram model where we try to predict a whole bunch of context words from a source target word. \u00a0 Implementing the Continuous Bag of Words (CBOW)\u00a0Model \u00a0 While it\u2019s excellent to use robust frameworks which have the Word2Vec model like gensim, let\u2019s try and implement this from scratch to gain some perspective on how things really work behind the scenes. We will leverage our\u00a0 Bible corpus \u00a0contained in the\u00a0 norm_bible \u00a0variable for training our model. The implementation will focus on four parts Build the corpus vocabulary Build a CBOW (context, target) generator Build the CBOW model architecture Train the Model Get Word Embeddings Without further delay, let\u2019s get started! Build the corpus vocabulary To start off, we will first build our corpus vocabulary where we extract out each unique word from our vocabulary and map a unique numeric identifier to it. Output\r ------ \r \r Vocabulary Size: 12425\r Vocabulary Sample: [('perceived', 1460), ('flagon', 7287), ('gardener', 11641), ('named', 973), ('remain', 732), ('sticketh', 10622), ('abstinence', 11848), ('rufus', 8190), ('adversary', 2018), ('jehoiachin', 3189)] Thus you can see that we have created a vocabulary of unique words in our corpus and also ways to map a word to its unique identifier and vice versa. The\u00a0 PAD \u00a0term is typically used to pad context words to a fixed length if needed. Build a CBOW (context, target) generator We need pairs which consist of a target centre word and surround context words. In our implementation, a\u00a0 target word \u00a0is of length 1 and surrounding context", "title_html": "<h1 id=\"title\">Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW)</h1> ", "url": "https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html", "tfidf": {"tfidf": {"base": 3.43884476535, "label": 4.47715736041, "fact": 1.73375559681, "googl": 11.388809182200001, "unsupervis": 690.2608695660001, "pdfnumpdf": 481.09090909099996, "onc": 1.4974533106999999, "post": 2.23826307627, "here": 4.84615384616, "lower": 2.10055570257, "good": 1.51981619759, "delay": 4.23247134098, "vice": 5.19162851537, "space": 9.59274924472, "addit": 1.24634950542, "auxiliari": 16.4518134715, "much": 2.3884459154599997, "tradit": 1.60802187785, "contain": 1.59814777532, "four": 1.20950784702, "scene": 3.45055422734, "dog": 12.52544378698, "thing": 2.4065484311099996, "sentenc": 5.84536082474, "just": 1.33580143037, "perspect": 10.07040913416, "further": 1.3618116315, "fox": 13.06129164952, "name": 1.10211732037, "contextwindow": 962.1818181819999, "their": 1.01547908405, "recommend": 3.9142011834300003, "where": 3.20145190563, "origin": 3.4117478510100003, "creat": 4.9971671388, "massiv": 4.22571200426, "methodolog": 17.898534385599998, "vector": 181.292006525, "how": 1.60250328051, "sarkar": 369.209302326, "perceiv": 4.92279069767, "bunch": 40.5, "abstin": 120.27272727299999, "spars": 21.0, "represent": 23.71321882, "distribut": 5.479206212259999, "famili": 1.48804948917, "for": 2.00063008002, "word": 55.69265587870999, "interest": 1.60331246213, "deep": 7.2559414990799995, "rufus": 57.3140794224, "will": 6.1240549298, "over": 1.02525024217, "consid": 2.4794627518400003, "build": 11.4392177046, "total": 1.5460122699399999, "adversari": 26.328358209, "flagon": 481.09090909099996, "similar": 1.37514075357, "but": 2.03264835798, "thorough": 10.956521739100001, "need": 4.31178707223, "our": 18.86070686072, "classif": 16.134146341460003, "off": 1.5121440137200002, "inform": 3.1506251240400003, "fix": 4.4346368715099995, "num": 14.00441056014, "found": 1.11387076405, "repres": 1.46972782818, "continu": 4.55715823468, "targetword": 962.1818181819999, "have": 4.059579364559999, "take": 2.27923336444, "use": 3.0889162721399996, "now": 2.321561746, "robust": 19.9447236181, "reader": 6.437956204380001, "out": 1.06016694491, "model": 48.0837503292, "high": 1.14777327935, "possibl": 1.4173734488, "realli": 4.7476076555, "number": 1.10142916609, "leverag": 107.2702702704, "note": 1.42449528937, "brown": 9.664772727270002, "numer": 1.83325635104, "also": 1.01476510067, "typic": 2.2541530597799997, "specifi": 6.920662598080001, "target": 22.532846715330002, "around": 1.21394708671, "mean": 1.44906900329, "textual": 41.4516971279, "one": 1.00627495722, "far": 1.71022298826, "tri": 9.272281275549998, "length": 7.38246919322, "window": 5.86479497599, "the": 42.0, "whole": 2.29488291414, "comput": 3.9277585353800006, "quick": 6.615, "skipgram": 962.1818181819999, "captur": 2.88026124819, "than": 3.0983606557499996, "behind": 2.0845588235299997, "semant": 39.1034482759, "jump": 8.07117437722, "essenti": 5.856141645140001, "let": 10.45849802373, "normbibl": 481.09090909099996, "still": 1.1866357724799999, "construct": 1.9320920043799998, "which": 7.036342915, "featur": 1.52712581762, "versa": 23.381443299, "term": 1.39520168732, "thus": 3.2927512185000003, "estim": 2.34991119005, "simpl": 3.3981164383599998, "variabl": 8.747107438019999, "uniqu": 12.06382978724, "itself": 1.74557449148, "consist": 1.4901445466499998, "see": 1.27242125511, "such": 1.06151377374, "architectur": 30.76744186044, "corpus": 216.819423369, "get": 5.35687774155, "centr": 2.97080838323, "like": 2.2983713355, "implement": 14.30592475784, "some": 3.1211009174399997, "sourc": 5.09281437126, "part": 2.08661365578, "supervis": 7.74061433447, "includ": 3.0571923743399996, "were": 1.02458857696, "vocabulari": 232.78592375399998, "dipanjan": 481.09090909099996, "introduc": 1.7258397651900002, "phrase": 6.18465134398, "ani": 1.13383802314, "two": 1.01379310345, "sampl": 7.23280182232, "from": 6.00340328982, "engin": 2.47135740971, "jehoiachin": 481.09090909099996, "lazi": 97.1009174312, "work": 1.11520089913, "differ": 1.23654490225, "embed": 117.849416755, "editor": 4.33060556465, "sticketh": 481.09090909099996, "extract": 7.703056768560001, "start": 2.53347163488, "excel": 4.84467500763, "predict": 25.92423252775, "output": 7.676982591880001, "usual": 1.72508964468, "garden": 4.294292669730001, "there": 2.08182533438, "are": 4.11962374312, "surround": 7.49575070823, "intel": 54.5567010309, "current": 1.5325803649, "that": 5.01992031875, "pair": 8.73747936158, "look": 1.9086318826599997, "popular": 1.50769230769, "highdimension": 481.09090909099996, "built": 1.99447236181, "bag": 63.4405594404, "more": 2.0343413634, "and": 21.001322834729997, "indepth": 962.1818181819999, "these": 5.3707713126000005, "center": 1.7423178226499998, "pad": 24.652173913000002, "gain": 3.6963911525, "focus": 2.01012914662, "comment": 3.05954904606, "map": 8.145715751660001, "can": 9.41009113136, "bibl": 9.461263408819999, "give": 1.3653250774, "make": 1.0762660158600001, "simpler": 17.9187358916, "way": 1.2190739461, "onli": 1.0256476516600002, "each": 2.37949640288, "size": 9.9754948162, "train": 3.8731397901999998, "wordnumvec": 1924.3636363639998, "this": 10.037936267100001, "scratch": 25.8146341463, "read": 2.3149606299200003, "framework": 8.200413223139998, "remain": 1.16598119859, "mikolov": 1924.3636363639998, "gensim": 481.09090909099996, "qualiti": 2.9329392204, "composit": 4.629921259840001, "paper": 2.6628648104700003, "exampl": 1.50483412322, "corpora": 962.1818181819999, "dimension": 54.1843003413, "identifi": 4.60374075686, "contextu": 76.6956521739, "first": 1.00761614623, "what": 2.50686878256, "input": 12.2029208301, "generat": 8.21101629168, "while": 2.0883977900599997, "without": 3.88641370869, "context": 38.337536892959996, "within": 1.2369302688, "learn": 4.6455010973, "cover": 1.69380134429, "dens": 41.6692913384, "effici": 5.09335899904}, "logtfidf": {"base": 0.40956990686100003, "label": 1.49898832727, "fact": 0.5502899207949999, "googl": 2.43263122258, "unsupervis": 11.687844834819998, "pdfnumpdf": 6.17605625244, "onc": 0.403765872355, "post": 0.8057001527009999, "here": 1.7700763767400003, "lower": 0.742201929994, "good": 0.418589404907, "delay": 1.44278606382, "vice": 1.64704742741, "space": 3.498852659888, "addit": 0.220218882972, "auxiliari": 2.8004357125599997, "much": 0.35499145860200004, "tradit": 0.47500477629199994, "contain": 0.468845318236, "four": 0.190213538869, "scene": 1.23853486375, "dog": 3.6692297957599997, "thing": 0.8781935346799999, "sentenc": 1.7656483252200001, "just": 0.289531434109, "perspect": 3.23290830872, "further": 0.308815895297, "fox": 3.7530116791800006, "name": 0.09723316638430002, "contextwindow": 12.35211250488, "their": 0.015360505122700001, "recommend": 1.36461126863, "where": 0.19497641623710002, "origin": 0.385837312761, "creat": 0.890307274056, "massiv": 1.44118776833, "methodolog": 2.8847188315900003, "vector": 22.77939214579, "how": 0.47156695693000006, "sarkar": 5.91136369821, "perceiv": 1.5938755846700001, "bunch": 3.70130197411, "abstin": 4.7897618913199995, "spars": 3.04452243772, "represent": 7.1189531505999994, "distribut": 2.01562611626, "famili": 0.39746619471100003, "for": 0.0006299807907940001, "word": 18.161693553935, "interest": 0.47207177798199995, "deep": 2.5773469396, "rufus": 4.04854630772, "will": 1.0139326745750001, "over": 0.0249367214957, "consid": 0.429789447648, "build": 3.437962164637, "total": 0.43567888670500005, "adversari": 3.27064661718, "flagon": 6.17605625244, "similar": 0.318556092114, "but": 0.0323847441438, "thorough": 2.39393487158, "need": 1.088220490326, "our": 6.8611137134560005, "classif": 4.17558147258, "off": 0.41352852038800003, "inform": 0.908907409324, "fix": 1.48944573451, "num": 0.0044098655355580005, "found": 0.107841124048, "repres": 0.38507723275, "continu": 0.5216194959480001, "targetword": 12.35211250488, "have": 0.0591400093648, "take": 0.261383924394, "use": 0.0876240591948, "now": 0.298185890042, "robust": 2.9929646280599997, "reader": 1.8622111301800002, "out": 0.0584263909193, "model": 16.961351681553, "high": 0.13782378654000002, "possibl": 0.348805474891, "realli": 1.5576408397, "number": 0.0966085784186, "leverag": 10.730217754409999, "note": 0.353817568083, "brown": 3.50962592607, "numer": 0.606093812346, "also": 0.0146571578, "typic": 0.812774319158, "specifi": 1.93451151621, "target": 8.183447647340001, "around": 0.19387710578200001, "mean": 0.37092128352, "textual": 3.7245288247199992, "one": 0.0062553516455, "far": 0.536623764503, "tri": 3.0879576458000004, "length": 2.6119219622400003, "window": 1.7689675242900003, "the": 0.0, "whole": 0.8306818244059999, "comput": 1.36806891594, "quick": 2.3721825266970002, "skipgram": 12.35211250488, "captur": 1.0578810012100002, "than": 0.0967825866546, "behind": 0.7345572374320001, "semant": 3.6662106543, "jump": 2.08829899551, "essenti": 2.14868756768, "let": 3.7464077018399995, "normbibl": 6.17605625244, "still": 0.17112222142900002, "construct": 0.658603355972, "which": 0.036248896918010004, "featur": 0.423387418142, "versa": 3.15194268634, "term": 0.33303898354600003, "thus": 0.9971525427860001, "estim": 0.854377535975, "simpl": 1.2232212893899999, "variabl": 2.1687230672, "uniqu": 4.4156693636, "itself": 0.5570837229510001, "consist": 0.398873126426, "see": 0.240921585492, "such": 0.059695977806, "architectur": 9.80818547514, "corpus": 28.636562514599998, "get": 1.739307017346, "centr": 1.08883409869, "like": 0.27810715309, "implement": 5.09751763628, "some": 0.11872052719350001, "sourc": 1.587654932253, "part": 0.08479062196560001, "supervis": 2.04648105583, "includ": 0.0566540441715, "were": 0.024291143681099997, "vocabulari": 31.4753415606, "dipanjan": 6.17605625244, "introduc": 0.5457137524260001, "phrase": 1.82207063303, "ani": 0.125608358366, "two": 0.0136988443582, "sampl": 1.9786264883900002, "from": 0.0034023250131959997, "engin": 0.904767558276, "jehoiachin": 6.17605625244, "lazi": 7.76520728602, "work": 0.109034567273, "differ": 0.212321121312, "embed": 19.76448271889, "editor": 1.4657073855, "sticketh": 6.17605625244, "extract": 2.04161723301, "start": 0.472886738582, "excel": 1.5778801652, "predict": 8.22870118845, "output": 2.03822657827, "usual": 0.545279017064, "garden": 1.45728685497, "there": 0.080195785851, "are": 0.1178698943308, "surround": 2.7471719972189996, "intel": 3.9992405467300003, "current": 0.42695282784500005, "that": 0.019880741898199997, "pair": 2.9489491299, "look": 0.6463866936, "popular": 0.41058020877499996, "highdimension": 6.17605625244, "built": 0.690379535065, "bag": 11.05523613836, "more": 0.034049863199999995, "and": 0.0013227929833356, "indepth": 12.35211250488, "these": 0.357668097004, "center": 0.555216308776, "pad": 3.2048650877999996, "gain": 1.2284195978499999, "focus": 0.6981989720559999, "comment": 1.11826753454, "map": 2.80868986768, "can": 1.298728771152, "bibl": 2.24720592688, "give": 0.311392552224, "make": 0.07349765782289999, "simpler": 2.8858468633, "way": 0.19809150993500002, "onli": 0.025324268329099998, "each": 0.347483378608, "size": 3.6553488242439998, "train": 1.321836625678, "wordnumvec": 24.70422500976, "this": 0.037864490525, "scratch": 3.2509415461, "read": 0.83939268088, "framework": 2.10418454607, "remain": 0.15356296309, "mikolov": 24.70422500976, "gensim": 6.17605625244, "qualiti": 1.07600506711, "composit": 1.5325398614399999, "paper": 0.979402539665, "exampl": 0.40868267499899996, "corpora": 12.35211250488, "dimension": 3.99239120489, "identifi": 1.667444000944, "contextu": 4.33984502064, "first": 0.0075872898121599995, "what": 0.451774593654, "input": 2.50167533539, "generat": 2.876729366944, "while": 0.08649996758760002, "without": 0.7766235538230001, "context": 13.042844229780002, "within": 0.21263272059799998, "learn": 1.68550412949, "cover": 0.526975319156, "dens": 9.373880310639999, "effici": 1.62793753414}, "logidf": {"base": 0.13652330228700002, "label": 1.49898832727, "fact": 0.5502899207949999, "googl": 2.43263122258, "unsupervis": 5.843922417409999, "pdfnumpdf": 6.17605625244, "onc": 0.403765872355, "post": 0.8057001527009999, "here": 0.8850381883700001, "lower": 0.742201929994, "good": 0.418589404907, "delay": 1.44278606382, "vice": 1.64704742741, "space": 0.874713164972, "addit": 0.220218882972, "auxiliari": 2.8004357125599997, "much": 0.17749572930100002, "tradit": 0.47500477629199994, "contain": 0.468845318236, "four": 0.190213538869, "scene": 1.23853486375, "dog": 1.8346148978799999, "thing": 0.8781935346799999, "sentenc": 1.7656483252200001, "just": 0.289531434109, "perspect": 1.61645415436, "further": 0.308815895297, "fox": 1.8765058395900003, "name": 0.09723316638430002, "contextwindow": 6.17605625244, "their": 0.015360505122700001, "recommend": 1.36461126863, "where": 0.0649921387457, "origin": 0.128612437587, "creat": 0.222576818514, "massiv": 1.44118776833, "methodolog": 2.8847188315900003, "vector": 3.25419887797, "how": 0.47156695693000006, "sarkar": 5.91136369821, "perceiv": 1.5938755846700001, "bunch": 3.70130197411, "abstin": 4.7897618913199995, "spars": 3.04452243772, "represent": 1.7797382876499999, "distribut": 1.00781305813, "famili": 0.39746619471100003, "for": 0.00031499039539700004, "word": 0.585861082385, "interest": 0.47207177798199995, "deep": 1.2886734698, "rufus": 4.04854630772, "will": 0.202786534915, "over": 0.0249367214957, "consid": 0.214894723824, "build": 0.491137452091, "total": 0.43567888670500005, "adversari": 3.27064661718, "flagon": 6.17605625244, "similar": 0.318556092114, "but": 0.0161923720719, "thorough": 2.39393487158, "need": 0.362740163442, "our": 0.8576392141820001, "classif": 2.08779073629, "off": 0.41352852038800003, "inform": 0.454453704662, "fix": 1.48944573451, "num": 0.00031499039539700004, "found": 0.107841124048, "repres": 0.38507723275, "continu": 0.13040487398700001, "targetword": 6.17605625244, "have": 0.0147850023412, "take": 0.130691962197, "use": 0.0292080197316, "now": 0.149092945021, "robust": 2.9929646280599997, "reader": 1.8622111301800002, "out": 0.0584263909193, "model": 0.7374500731110001, "high": 0.13782378654000002, "possibl": 0.348805474891, "realli": 1.5576408397, "number": 0.0966085784186, "leverag": 3.5767392514699994, "note": 0.353817568083, "brown": 1.16987530869, "numer": 0.606093812346, "also": 0.0146571578, "typic": 0.812774319158, "specifi": 1.93451151621, "target": 1.1690639496200002, "around": 0.19387710578200001, "mean": 0.37092128352, "textual": 3.7245288247199992, "one": 0.0062553516455, "far": 0.536623764503, "tri": 0.61759152916, "length": 1.3059609811200001, "window": 1.7689675242900003, "the": 0.0, "whole": 0.8306818244059999, "comput": 1.36806891594, "quick": 0.790727508899, "skipgram": 6.17605625244, "captur": 1.0578810012100002, "than": 0.0322608622182, "behind": 0.7345572374320001, "semant": 3.6662106543, "jump": 2.08829899551, "essenti": 1.07434378384, "let": 1.2488025672799998, "normbibl": 6.17605625244, "still": 0.17112222142900002, "construct": 0.658603355972, "which": 0.00517841384543, "featur": 0.423387418142, "versa": 3.15194268634, "term": 0.33303898354600003, "thus": 0.49857627139300004, "estim": 0.854377535975, "simpl": 1.2232212893899999, "variabl": 2.1687230672, "uniqu": 1.1039173409, "itself": 0.5570837229510001, "consist": 0.398873126426, "see": 0.240921585492, "such": 0.059695977806, "architectur": 1.63469757919, "corpus": 3.1818402794, "get": 0.579769005782, "centr": 1.08883409869, "like": 0.139053576545, "implement": 1.27437940907, "some": 0.0395735090645, "sourc": 0.529218310751, "part": 0.04239531098280001, "supervis": 2.04648105583, "includ": 0.0188846813905, "were": 0.024291143681099997, "vocabulari": 3.14753415606, "dipanjan": 6.17605625244, "introduc": 0.5457137524260001, "phrase": 1.82207063303, "ani": 0.125608358366, "two": 0.0136988443582, "sampl": 1.9786264883900002, "from": 0.000567054168866, "engin": 0.904767558276, "jehoiachin": 6.17605625244, "lazi": 3.88260364301, "work": 0.109034567273, "differ": 0.212321121312, "embed": 2.82349753127, "editor": 1.4657073855, "sticketh": 6.17605625244, "extract": 2.04161723301, "start": 0.236443369291, "excel": 1.5778801652, "predict": 1.6457402376899999, "output": 2.03822657827, "usual": 0.545279017064, "garden": 1.45728685497, "there": 0.0400978929255, "are": 0.0294674735827, "surround": 0.915723999073, "intel": 3.9992405467300003, "current": 0.42695282784500005, "that": 0.00397614837964, "pair": 1.47447456495, "look": 0.6463866936, "popular": 0.41058020877499996, "highdimension": 6.17605625244, "built": 0.690379535065, "bag": 2.76380903459, "more": 0.017024931599999998, "and": 6.29901420636e-05, "indepth": 6.17605625244, "these": 0.0715336194008, "center": 0.555216308776, "pad": 3.2048650877999996, "gain": 0.6142097989249999, "focus": 0.6981989720559999, "comment": 1.11826753454, "map": 1.40434493384, "can": 0.162341096394, "bibl": 2.24720592688, "give": 0.311392552224, "make": 0.07349765782289999, "simpler": 2.8858468633, "way": 0.19809150993500002, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "train": 0.660918312839, "wordnumvec": 6.17605625244, "this": 0.0037864490525, "scratch": 3.2509415461, "read": 0.83939268088, "framework": 2.10418454607, "remain": 0.15356296309, "mikolov": 6.17605625244, "gensim": 6.17605625244, "qualiti": 1.07600506711, "composit": 1.5325398614399999, "paper": 0.979402539665, "exampl": 0.40868267499899996, "corpora": 6.17605625244, "dimension": 3.99239120489, "identifi": 0.833722000472, "contextu": 4.33984502064, "first": 0.0075872898121599995, "what": 0.225887296827, "input": 2.50167533539, "generat": 0.719182341736, "while": 0.04324998379380001, "without": 0.258874517941, "context": 1.44920491442, "within": 0.21263272059799998, "learn": 0.842752064745, "cover": 0.526975319156, "dens": 2.3434700776599997, "effici": 1.62793753414}, "freq": {"base": 3, "label": 1, "fact": 1, "googl": 1, "unsupervis": 2, "pdfnumpdf": 1, "onc": 1, "post": 1, "here": 2, "lower": 1, "good": 1, "delay": 1, "vice": 1, "space": 4, "addit": 1, "auxiliari": 1, "much": 2, "tradit": 1, "contain": 1, "four": 1, "scene": 1, "dog": 2, "thing": 1, "sentenc": 1, "just": 1, "perspect": 2, "further": 1, "fox": 2, "name": 1, "contextwindow": 2, "their": 1, "recommend": 1, "where": 3, "origin": 3, "creat": 4, "massiv": 1, "methodolog": 1, "vector": 7, "how": 1, "sarkar": 1, "perceiv": 1, "bunch": 1, "abstin": 1, "spars": 1, "represent": 4, "distribut": 2, "famili": 1, "for": 2, "word": 31, "interest": 1, "deep": 2, "rufus": 1, "will": 5, "over": 1, "consid": 2, "build": 7, "total": 1, "adversari": 1, "flagon": 1, "similar": 1, "but": 2, "thorough": 1, "need": 3, "our": 8, "classif": 2, "off": 1, "inform": 2, "fix": 1, "num": 14, "found": 1, "repres": 1, "continu": 4, "targetword": 2, "have": 4, "take": 2, "use": 3, "now": 2, "robust": 1, "reader": 1, "out": 1, "model": 23, "high": 1, "possibl": 1, "realli": 1, "number": 1, "leverag": 3, "note": 1, "brown": 3, "numer": 1, "also": 1, "typic": 1, "specifi": 1, "target": 7, "around": 1, "mean": 1, "textual": 1, "one": 1, "far": 1, "tri": 5, "length": 2, "window": 1, "the": 42, "whole": 1, "comput": 1, "quick": 3, "skipgram": 2, "captur": 1, "than": 3, "behind": 1, "semant": 1, "jump": 1, "essenti": 2, "let": 3, "normbibl": 1, "still": 1, "construct": 1, "which": 7, "featur": 1, "versa": 1, "term": 1, "thus": 2, "estim": 1, "simpl": 1, "variabl": 1, "uniqu": 4, "itself": 1, "consist": 1, "see": 1, "such": 1, "architectur": 6, "corpus": 9, "get": 3, "centr": 1, "like": 2, "implement": 4, "some": 3, "sourc": 3, "part": 2, "supervis": 1, "includ": 3, "were": 1, "vocabulari": 10, "dipanjan": 1, "introduc": 1, "phrase": 1, "ani": 1, "two": 1, "sampl": 1, "from": 6, "engin": 1, "jehoiachin": 1, "lazi": 2, "work": 1, "differ": 1, "embed": 7, "editor": 1, "sticketh": 1, "extract": 1, "start": 2, "excel": 1, "predict": 5, "output": 1, "usual": 1, "garden": 1, "there": 2, "are": 4, "surround": 3, "intel": 1, "current": 1, "that": 5, "pair": 2, "look": 1, "popular": 1, "highdimension": 1, "built": 1, "bag": 4, "more": 2, "and": 21, "indepth": 2, "these": 5, "center": 1, "pad": 1, "gain": 2, "focus": 1, "comment": 1, "map": 2, "can": 8, "bibl": 1, "give": 1, "make": 1, "simpler": 1, "way": 1, "onli": 1, "each": 2, "size": 4, "train": 2, "wordnumvec": 4, "this": 10, "scratch": 1, "read": 1, "framework": 1, "remain": 1, "mikolov": 4, "gensim": 1, "qualiti": 1, "composit": 1, "paper": 1, "exampl": 1, "corpora": 2, "dimension": 1, "identifi": 2, "contextu": 1, "first": 1, "what": 2, "input": 1, "generat": 4, "while": 2, "without": 3, "context": 9, "within": 1, "learn": 2, "cover": 1, "dens": 4, "effici": 1}, "idf": {"base": 1.14628158845, "label": 4.47715736041, "fact": 1.73375559681, "googl": 11.388809182200001, "unsupervis": 345.13043478300006, "pdfnumpdf": 481.09090909099996, "onc": 1.4974533106999999, "post": 2.23826307627, "here": 2.42307692308, "lower": 2.10055570257, "good": 1.51981619759, "delay": 4.23247134098, "vice": 5.19162851537, "space": 2.39818731118, "addit": 1.24634950542, "auxiliari": 16.4518134715, "much": 1.1942229577299999, "tradit": 1.60802187785, "contain": 1.59814777532, "four": 1.20950784702, "scene": 3.45055422734, "dog": 6.26272189349, "thing": 2.4065484311099996, "sentenc": 5.84536082474, "just": 1.33580143037, "perspect": 5.03520456708, "further": 1.3618116315, "fox": 6.53064582476, "name": 1.10211732037, "contextwindow": 481.09090909099996, "their": 1.01547908405, "recommend": 3.9142011834300003, "where": 1.06715063521, "origin": 1.13724928367, "creat": 1.2492917847, "massiv": 4.22571200426, "methodolog": 17.898534385599998, "vector": 25.898858075, "how": 1.60250328051, "sarkar": 369.209302326, "perceiv": 4.92279069767, "bunch": 40.5, "abstin": 120.27272727299999, "spars": 21.0, "represent": 5.928304705, "distribut": 2.7396031061299997, "famili": 1.48804948917, "for": 1.00031504001, "word": 1.7965372864099998, "interest": 1.60331246213, "deep": 3.6279707495399998, "rufus": 57.3140794224, "will": 1.22481098596, "over": 1.02525024217, "consid": 1.2397313759200002, "build": 1.6341739578, "total": 1.5460122699399999, "adversari": 26.328358209, "flagon": 481.09090909099996, "similar": 1.37514075357, "but": 1.01632417899, "thorough": 10.956521739100001, "need": 1.4372623574099999, "our": 2.35758835759, "classif": 8.067073170730001, "off": 1.5121440137200002, "inform": 1.5753125620200001, "fix": 4.4346368715099995, "num": 1.00031504001, "found": 1.11387076405, "repres": 1.46972782818, "continu": 1.13928955867, "targetword": 481.09090909099996, "have": 1.0148948411399998, "take": 1.13961668222, "use": 1.0296387573799999, "now": 1.160780873, "robust": 19.9447236181, "reader": 6.437956204380001, "out": 1.06016694491, "model": 2.0905978404, "high": 1.14777327935, "possibl": 1.4173734488, "realli": 4.7476076555, "number": 1.10142916609, "leverag": 35.7567567568, "note": 1.42449528937, "brown": 3.2215909090900006, "numer": 1.83325635104, "also": 1.01476510067, "typic": 2.2541530597799997, "specifi": 6.920662598080001, "target": 3.2189781021900004, "around": 1.21394708671, "mean": 1.44906900329, "textual": 41.4516971279, "one": 1.00627495722, "far": 1.71022298826, "tri": 1.8544562551099997, "length": 3.69123459661, "window": 5.86479497599, "the": 1.0, "whole": 2.29488291414, "comput": 3.9277585353800006, "quick": 2.205, "skipgram": 481.09090909099996, "captur": 2.88026124819, "than": 1.03278688525, "behind": 2.0845588235299997, "semant": 39.1034482759, "jump": 8.07117437722, "essenti": 2.9280708225700005, "let": 3.48616600791, "normbibl": 481.09090909099996, "still": 1.1866357724799999, "construct": 1.9320920043799998, "which": 1.005191845, "featur": 1.52712581762, "versa": 23.381443299, "term": 1.39520168732, "thus": 1.6463756092500001, "estim": 2.34991119005, "simpl": 3.3981164383599998, "variabl": 8.747107438019999, "uniqu": 3.01595744681, "itself": 1.74557449148, "consist": 1.4901445466499998, "see": 1.27242125511, "such": 1.06151377374, "architectur": 5.12790697674, "corpus": 24.091047041, "get": 1.78562591385, "centr": 2.97080838323, "like": 1.14918566775, "implement": 3.57648118946, "some": 1.04036697248, "sourc": 1.69760479042, "part": 1.04330682789, "supervis": 7.74061433447, "includ": 1.0190641247799999, "were": 1.02458857696, "vocabulari": 23.2785923754, "dipanjan": 481.09090909099996, "introduc": 1.7258397651900002, "phrase": 6.18465134398, "ani": 1.13383802314, "two": 1.01379310345, "sampl": 7.23280182232, "from": 1.00056721497, "engin": 2.47135740971, "jehoiachin": 481.09090909099996, "lazi": 48.5504587156, "work": 1.11520089913, "differ": 1.23654490225, "embed": 16.835630965, "editor": 4.33060556465, "sticketh": 481.09090909099996, "extract": 7.703056768560001, "start": 1.26673581744, "excel": 4.84467500763, "predict": 5.18484650555, "output": 7.676982591880001, "usual": 1.72508964468, "garden": 4.294292669730001, "there": 1.04091266719, "are": 1.02990593578, "surround": 2.49858356941, "intel": 54.5567010309, "current": 1.5325803649, "that": 1.00398406375, "pair": 4.36873968079, "look": 1.9086318826599997, "popular": 1.50769230769, "highdimension": 481.09090909099996, "built": 1.99447236181, "bag": 15.8601398601, "more": 1.0171706817, "and": 1.00006299213, "indepth": 481.09090909099996, "these": 1.07415426252, "center": 1.7423178226499998, "pad": 24.652173913000002, "gain": 1.84819557625, "focus": 2.01012914662, "comment": 3.05954904606, "map": 4.0728578758300005, "can": 1.17626139142, "bibl": 9.461263408819999, "give": 1.3653250774, "make": 1.0762660158600001, "simpler": 17.9187358916, "way": 1.2190739461, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "train": 1.9365698950999999, "wordnumvec": 481.09090909099996, "this": 1.00379362671, "scratch": 25.8146341463, "read": 2.3149606299200003, "framework": 8.200413223139998, "remain": 1.16598119859, "mikolov": 481.09090909099996, "gensim": 481.09090909099996, "qualiti": 2.9329392204, "composit": 4.629921259840001, "paper": 2.6628648104700003, "exampl": 1.50483412322, "corpora": 481.09090909099996, "dimension": 54.1843003413, "identifi": 2.30187037843, "contextu": 76.6956521739, "first": 1.00761614623, "what": 1.25343439128, "input": 12.2029208301, "generat": 2.05275407292, "while": 1.0441988950299999, "without": 1.29547123623, "context": 4.25972632144, "within": 1.2369302688, "learn": 2.32275054865, "cover": 1.69380134429, "dens": 10.4173228346, "effici": 5.09335899904}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW)</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW) Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/18/04-03-foot-locker-architect-data-engineering.html\" rel=\"prev\" title=\"Foot Locker: Sr Architect \u2013 Data Engineering\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/start-using-npy-files-more-often.html\" rel=\"next\" title=\"Why You Should Start Using .npy Files More Often\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=79451\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-79451 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 3-Apr, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW) (\u00a0<a href=\"/2018/n14.html\">18:n14</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW)</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/18/04-03-foot-locker-architect-data-engineering.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/04/start-using-npy-files-more-often.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/word2vec\" rel=\"tag\">word2vec</a></div>\n<br/>\n<p class=\"excerpt\">\n     The CBOW model architecture tries to predict the current target word (the center word) based on the source context words (surrounding words).\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a>, Intel</b></p>\n<blockquote><p>\n<b>Editor's note:</b> This post is only one part of a far more thorough and in-depth original, <a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener\" target=\"_blank\">found here</a>, which covers much more than what is included here.\n</p></blockquote>\n<p>Let\u2019s look at some of the popular word embedding models now and engineering features from our corpora!</p>\n<p>\u00a0</p>\n<h3>The Word2Vec\u00a0Model</h3>\n<p>\u00a0<br>\nThis model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity. Essentially these are unsupervised models which can take in massive textual corpora, create a vocabulary of possible words and generate dense word embeddings for each word in the vector space representing that vocabulary. Usually you can specify the size of the word embedding vectors and the total number of vectors are essentially the size of the vocabulary. This makes the dimensionality of this dense vector space much lower than the high-dimensional sparse vector space built using traditional Bag of Words models.</br></p>\n<p>There are two different model architectures which can be leveraged by Word2Vec to create these word embedding representations. These include,</p>\n<ul>\n<li><strong>The Continuous Bag of Words (CBOW) Model</strong>\n<li><strong>The Skip-gram Model</strong>\n</li></li></ul>\n<p>There were originally introduced by Mikolov et al. and I recommend interested readers to read up on the original papers around these models which include,\u00a0<a href=\"https://arxiv.org/pdf/1310.4546.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"><em>\u2018Distributed Representations of Words and Phrases and their Compositionality\u2019</em>\u00a0by Mikolov et al.</a>\u00a0and\u00a0<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"><em>\u2018Efficient Estimation of Word Representations in Vector Space\u2019</em>\u00a0by Mikolov et al.</a>\u00a0to gain some good in-depth perspective.</p>\n<p>\u00a0</p>\n<h3>The Continuous Bag of Words (CBOW)\u00a0Model</h3>\n<p>\u00a0<br>\nThe CBOW model architecture tries to predict the current target word (the center word) based on the source context words (surrounding words). Considering a simple sentence,\u00a0<strong><em>\u201cthe quick brown fox jumps over the lazy dog\u201d</em></strong>, this can be pairs of\u00a0<strong><em>(context_window, target_word)</em></strong>\u00a0where if we consider a context window of size 2, we have examples like\u00a0<strong><em>([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0</em></strong>and so on. Thus the model tries to predict the\u00a0<code>target_word</code>\u00a0based on the\u00a0<code>context_window</code>\u00a0words.</br></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*UVe8b6CWYykcxbBOR6uCfg.png\" width=\"50%\"><br>\n<font size=\"-1\">The CBOW model architecture (Source:\u00a0<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">https://arxiv.org/pdf/1301.3781.pdf</a>\u00a0Mikolov el\u00a0al.)</font></br></img></center></p>\n<p>While the Word2Vec family of models are unsupervised, what this means is that you can just give it a corpus without additional labels or information and it can construct dense word embeddings from the corpus. But you will still need to leverage a supervised, classification methodology once you have this corpus to get to these embeddings. But we will do that from within the corpus itself, without any auxiliary information. We can model this CBOW architecture now as a deep learning classification model such that we take in the\u00a0<strong><em>context words as our input, X</em></strong>\u00a0and try to predict the\u00a0<strong><em>target word, Y</em></strong>. In fact building this architecture is simpler than the skip-gram model where we try to predict a whole bunch of context words from a source target word.</p>\n<p>\u00a0</p>\n<h3>Implementing the Continuous Bag of Words (CBOW)\u00a0Model</h3>\n<p>\u00a0<br>\nWhile it\u2019s excellent to use robust frameworks which have the Word2Vec model like gensim, let\u2019s try and implement this from scratch to gain some perspective on how things really work behind the scenes. We will leverage our\u00a0<strong><em>Bible corpus</em></strong>\u00a0contained in the\u00a0<code>norm_bible</code>\u00a0variable for training our model. The implementation will focus on four parts</br></p>\n<ul>\n<li><strong>Build the corpus vocabulary</strong>\n<li><strong>Build a CBOW (context, target) generator</strong>\n<li><strong>Build the CBOW model architecture</strong>\n<li><strong>Train the Model</strong>\n<li><strong>Get Word Embeddings</strong>\n</li></li></li></li></li></ul>\n<p>Without further delay, let\u2019s get started!</p>\n<p><b><strong>Build the corpus vocabulary</strong></b></p>\n<p>To start off, we will first build our corpus vocabulary where we extract out each unique word from our vocabulary and map a unique numeric identifier to it.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/a39b18004827596638a9cc9bec4510c0.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre><strong>Output\r\n------</strong>\r\n\r\nVocabulary Size: 12425\r\nVocabulary Sample: [('perceived', 1460), ('flagon', 7287), ('gardener', 11641), ('named', 973), ('remain', 732), ('sticketh', 10622), ('abstinence', 11848), ('rufus', 8190), ('adversary', 2018), ('jehoiachin', 3189)]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Thus you can see that we have created a vocabulary of unique words in our corpus and also ways to map a word to its unique identifier and vice versa. The\u00a0<code><strong>PAD</strong></code>\u00a0term is typically used to pad context words to a fixed length if needed.</p>\n<p><b>Build a CBOW (context, target) generator</b></p>\n<p>We need pairs which consist of a target centre word and surround context words. In our implementation, a\u00a0<strong><em>target word</em></strong>\u00a0is of length <code><strong>1</strong></code> and <strong <em=\"\">surrounding context</strong></p></div></div></div></div></div></body></html> is of length <code><strong>2 x window_size</strong></code> where we take <code><strong>window_size</strong></code><strong> </strong>words before and after the target word in our corpus. This will become clearer with the following example.\n<p><script src=\"https://gist.github.com/dipanjanS/a2fbca3939774c07e9dd817dc75b5472.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre><strong>Context (X): ['old','testament','james','bible'] -&gt; Target (Y): king\r\nContext (X): ['first','book','called','genesis'] -&gt; Target(Y): moses\r\nContext(X):['beginning','god','heaven','earth'] -&gt; Target(Y):created\r\nContext (X):['earth','without','void','darkness'] -&gt; Target(Y): form\r\nContext (X): ['without','form','darkness','upon'] -&gt; Target(Y): void\r\nContext (X): ['form', 'void', 'upon', 'face'] -&gt; Target(Y): darkness\r\nContext (X): ['void', 'darkness', 'face', 'deep'] -&gt; Target(Y): upon\r\nContext (X): ['spirit', 'god', 'upon', 'face'] -&gt; Target (Y): moved\r\nContext (X): ['god', 'moved', 'face', 'waters'] -&gt; Target (Y): upon\r\nContext (X): ['god', 'said', 'light', 'light'] -&gt; Target (Y): let\r\nContext (X): ['god', 'saw', 'good', 'god'] -&gt; Target (Y): light</strong></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The preceding output should give you some more perspective of how\u00a0<strong><em>X</em></strong>\u00a0forms our context words and we are trying to predict the target center word\u00a0<strong><em>Y</em></strong>\u00a0based on this context. For example, if the original text was\u00a0<em>\u2018in the beginning god created heaven and earth\u2019</em>\u00a0which after pre-processing and removal of stopwords became\u00a0<em>\u2018beginning god\u00a0</em><strong><em>created\u00a0</em></strong><em>heaven earth\u2019</em>\u00a0and for us, what we are trying to achieve is that. Given\u00a0<em>[beginning, god, heaven, earth]</em>\u00a0as the context, what the target center word is, which is \u2018<strong><em>created\u2019</em></strong>\u00a0in this case.</p>\n<p><b>Build the CBOW model architecture</b></p>\n<p>We now leverage\u00a0<code>keras</code>\u00a0on top of\u00a0<code>tensorflow</code>\u00a0to build our deep learning architecture for the CBOW model. For this our inputs will be our context words which are passed to an embedding layer (initialized with random weights). The word embeddings are propagated to a lambda layer where we average out the word embeddings\u00a0<strong><em>(hence called CBOW because we don\u2019t really consider the order or sequence in the context words when averaged)</em></strong>and then we pass this averaged context embedding to a dense softmax layer which predicts our target word. We match this with the actual target word, compute the loss by leveraging the\u00a0<code>categorical_crossentropy</code>\u00a0loss and perform backpropagation with each epoch to update the embedding layer in the process. Following code shows us our model architecture.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/660fdfdb767a28264cf21cbc116e0c35.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*X_Ri3Nz-gFDDBJ1qgHOrHQ.png\" width=\"99%\"/><br/>\n<font size=\"-1\">CBOW model summary and architecture</font></center></p>\n<p>In case you still have difficulty in visualizing the above deep learning model, I would recommend you to read through the papers I mentioned earlier. I will try to summarize the core concepts of this model in simple terms. We have\u00a0<strong><em>input context words</em></strong>\u00a0of dimensions\u00a0<code><strong>(2 x window_size)</strong></code>, we will pass them to an\u00a0<strong><em>embedding layer</em></strong>\u00a0of size\u00a0<code><strong>(vocab_size x embed_size)</strong></code>\u00a0which will give us\u00a0<strong><em>dense word embeddings</em></strong>\u00a0for each of these context words\u00a0<code><strong>(1 x embed_size for each word)</strong></code>. Next up we use a\u00a0<strong><em>lambda layer</em></strong>\u00a0to average out these embeddings and get an\u00a0<strong><em>average dense embedding</em></strong>\u00a0<code><strong>(1 x embed_size)</strong></code>\u00a0which is sent to the\u00a0<strong><em>dense softmax layer</em></strong>\u00a0which outputs the most likely target word. We compare this with the actual target word, compute the loss, backpropagate the errors to adjust the weights (in the embedding layer) and repeat this process for all\u00a0<em>(context, target)</em>\u00a0pairs for multiple epochs. The following figure tries to explain the same.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*d66FyqIMWtDCtOuJ_GcqAg.png\" width=\"70%\"/><br/>\n<font size=\"-1\">Visual depiction of the CBOW deep learning\u00a0model</font></center></p>\n<p>We are now ready to train this model on our corpus using our data generator to feed in\u00a0<strong><em>(context, target_word)</em></strong>\u00a0pairs.</p>\n<p><b>Train the\u00a0Model</b></p>\n<p>Running the model on our complete corpus takes a fair bit of time, so I just ran it for 5 epochs. You can leverage the following code and increase it for more epochs if necessary.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/df0e15725727497d9c2fd165c6cc3359.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>Epoch: 1 \tLoss: 4257900.60084\r\nEpoch: 2 \tLoss: 4256209.59646\r\nEpoch: 3 \tLoss: 4247990.90456\r\nEpoch: 4 \tLoss: 4225663.18927\r\nEpoch: 5 \tLoss: 4104501.48929</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<blockquote><p><strong>Note:</strong>\u00a0Running this model is computationally expensive and works better if trained using a GPU. I trained this on an AWS\u00a0<code><strong>p2.x</strong></code>\u00a0instance with a Tesla K80 GPU and it took me close to 1.5 hours for just 5 epochs!</p></blockquote>\n<p>Once this model is trained, similar words should have similar weights based off the embedding layer and we can test out the same.</p>\n<p><b>Get Word Embeddings</b></p>\n<p>To get word embeddings for our entire vocabulary, we can extract out the same from our embedding layer by leveraging the following code. We don\u2019t take the embedding at position 0 since it belongs to the padding\u00a0<code><strong>(PAD)</strong></code>\u00a0term which is not really a word of interest.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/11bd6e4821f7261283da9266a3d9010f.js\"></script></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*wEBDYFSnMa-hdBMPTIwI5g.png\" width=\"99%\"/><br/>\n<font size=\"-1\">Word Embeddings for our vocabulary based on the CBOW\u00a0model</font></center></p>\n<p>Thus you can clearly see that each word has a dense embedding of size\u00a0<code><strong>(1x100)</strong></code>\u00a0as depicted in the preceding output. Let\u2019s try and find out some contextually similar words for specific words of interest based on these embeddings. For this, we build out a pairwise distance matrix amongst all the words in our vocabulary based on the dense embedding vectors and then find out the n-nearest neighbors of each word of interest based on the shortest (euclidean) distance.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/e3d7f6ad02dfde49d6571261a55b1b2c.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre><strong>(12424, 12424)</strong>\r\n\r\n<strong>{'egypt': ['destroy', 'none', 'whole', 'jacob', 'sea'],\r\n 'famine': ['wickedness', 'sore', 'countries', 'cease', 'portion'],\r\n 'god': ['therefore', 'heard', 'may', 'behold', 'heaven'],\r\n 'gospel': ['church', 'fowls', 'churches', 'preached', 'doctrine'],\r\n 'jesus': ['law', 'heard', 'world', 'many', 'dead'],\r\n 'john': ['dream', 'bones', 'held', 'present', 'alive'],\r\n 'moses': ['pharaoh', 'gate', 'jews', 'departed', 'lifted'],\r\n 'noah': ['abram', 'plagues', 'hananiah', 'korah', 'sarah']}</strong></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>You can clearly see that some of these make sense contextually\u00a0<strong><em>(god, heaven)</em></strong>,\u00a0<strong><em>(gospel, church)</em></strong>\u00a0and so on and some may not. Training for more epochs usually ends up giving better results. We will now explore the skip-gram architecture which often gives better results as compared to CBOW.</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a></b> is a Data Scientist @Intel, an author, a mentor @Springboard, a writer, and a sports and sitcom addict.</p>\n<p><a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/03/text-data-preprocessing-walkthrough-python.html\">Text Data Preprocessing: A Walkthrough in Python</a>\n<li><a href=\"/2017/12/general-approach-preprocessing-text-data.html\">A General Approach to Preprocessing Text Data</a>\n<li><a href=\"/2017/11/framework-approaching-textual-data-tasks.html\">A Framework for Approaching Textual Data Science Tasks<br/>\n</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/18/04-03-foot-locker-architect-data-engineering.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/04/start-using-npy-files-more-often.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end-->\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/kdnuggets-editor.html\">Looking for a KDnuggets Editor</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n<div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/04/tutorials.html\">Tutorials, Overviews</a> \u00bb Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW) (\u00a0<a href=\"/2018/n14.html\">18:n14</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end-->\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<div>\n<br/><span style=\"font-size:9px\">By subscribing, you agree to KDnuggets <a href=\"https://www.kdnuggets.com/news/privacy-policy.html\">privacy policy</a></span>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556410936\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper-->\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.648 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 20:22:16 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "dipanjan", "sarkar", "intel", "editor", "note", "this", "post", "onli", "one", "part", "far", "more", "thorough", "and", "indepth", "origin", "found", "here", "which", "cover", "much", "more", "than", "what", "includ", "here", "let", "look", "some", "the", "popular", "word", "embed", "model", "now", "and", "engin", "featur", "from", "our", "corpora", "the", "wordnumvec", "model", "this", "model", "creat", "googl", "num", "and", "predict", "deep", "learn", "base", "model", "comput", "and", "generat", "high", "qualiti", "distribut", "and", "continu", "dens", "vector", "represent", "word", "which", "captur", "contextu", "and", "semant", "similar", "essenti", "these", "are", "unsupervis", "model", "which", "can", "take", "massiv", "textual", "corpora", "creat", "vocabulari", "possibl", "word", "and", "generat", "dens", "word", "embed", "for", "each", "word", "the", "vector", "space", "repres", "that", "vocabulari", "usual", "can", "specifi", "the", "size", "the", "word", "embed", "vector", "and", "the", "total", "number", "vector", "are", "essenti", "the", "size", "the", "vocabulari", "this", "make", "the", "dimension", "this", "dens", "vector", "space", "much", "lower", "than", "the", "highdimension", "spars", "vector", "space", "built", "use", "tradit", "bag", "word", "model", "there", "are", "two", "differ", "model", "architectur", "which", "can", "leverag", "wordnumvec", "creat", "these", "word", "embed", "represent", "these", "includ", "the", "continu", "bag", "word", "model", "the", "skipgram", "model", "there", "were", "origin", "introduc", "mikolov", "and", "recommend", "interest", "reader", "read", "the", "origin", "paper", "around", "these", "model", "which", "includ", "distribut", "represent", "word", "and", "phrase", "and", "their", "composit", "mikolov", "and", "effici", "estim", "word", "represent", "vector", "space", "mikolov", "gain", "some", "good", "indepth", "perspect", "the", "continu", "bag", "word", "model", "the", "model", "architectur", "tri", "predict", "the", "current", "target", "word", "the", "center", "word", "base", "the", "sourc", "context", "word", "surround", "word", "consid", "simpl", "sentenc", "the", "quick", "brown", "fox", "jump", "over", "the", "lazi", "dog", "this", "can", "pair", "contextwindow", "targetword", "where", "consid", "context", "window", "size", "num", "have", "exampl", "like", "quick", "fox", "brown", "the", "brown", "quick", "the", "dog", "lazi", "and", "thus", "the", "model", "tri", "predict", "the", "targetword", "base", "the", "contextwindow", "word", "the", "model", "architectur", "sourc", "pdfnumpdf", "mikolov", "while", "the", "wordnumvec", "famili", "model", "are", "unsupervis", "what", "this", "mean", "that", "can", "just", "give", "corpus", "without", "addit", "label", "inform", "and", "can", "construct", "dens", "word", "embed", "from", "the", "corpus", "but", "will", "still", "need", "leverag", "supervis", "classif", "methodolog", "onc", "have", "this", "corpus", "get", "these", "embed", "but", "will", "that", "from", "within", "the", "corpus", "itself", "without", "ani", "auxiliari", "inform", "can", "model", "this", "architectur", "now", "deep", "learn", "classif", "model", "such", "that", "take", "the", "context", "word", "our", "input", "and", "tri", "predict", "the", "target", "word", "fact", "build", "this", "architectur", "simpler", "than", "the", "skipgram", "model", "where", "tri", "predict", "whole", "bunch", "context", "word", "from", "sourc", "target", "word", "implement", "the", "continu", "bag", "word", "model", "while", "excel", "use", "robust", "framework", "which", "have", "the", "wordnumvec", "model", "like", "gensim", "let", "tri", "and", "implement", "this", "from", "scratch", "gain", "some", "perspect", "how", "thing", "realli", "work", "behind", "the", "scene", "will", "leverag", "our", "bibl", "corpus", "contain", "the", "normbibl", "variabl", "for", "train", "our", "model", "the", "implement", "will", "focus", "four", "part", "build", "the", "corpus", "vocabulari", "build", "context", "target", "generat", "build", "the", "model", "architectur", "train", "the", "model", "get", "word", "embed", "without", "further", "delay", "let", "get", "start", "build", "the", "corpus", "vocabulari", "start", "off", "will", "first", "build", "our", "corpus", "vocabulari", "where", "extract", "out", "each", "uniqu", "word", "from", "our", "vocabulari", "and", "map", "uniqu", "numer", "identifi", "output", "vocabulari", "size", "num", "vocabulari", "sampl", "perceiv", "num", "flagon", "num", "garden", "num", "name", "num", "remain", "num", "sticketh", "num", "abstin", "num", "rufus", "num", "adversari", "num", "jehoiachin", "num", "thus", "can", "see", "that", "have", "creat", "vocabulari", "uniqu", "word", "our", "corpus", "and", "also", "way", "map", "word", "uniqu", "identifi", "and", "vice", "versa", "the", "term", "typic", "use", "pad", "context", "word", "fix", "length", "need", "build", "context", "target", "generat", "need", "pair", "which", "consist", "target", "centr", "word", "and", "surround", "context", "word", "our", "implement", "target", "word", "length", "num", "and", "surround", "context"], "timestamp_scraper": 1556482486.803808, "title": "Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW)", "read_time": 215.7, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/dipanzan\" rel=\"noopener noreferrer\" target=\"_blank\">Dipanjan Sarkar</a>, Intel</b></p>\n<blockquote><p>\n<b>Editor's note:</b> This post is only one part of a far more thorough and in-depth original, <a href=\"https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\" rel=\"noopener\" target=\"_blank\">found here</a>, which covers much more than what is included here.\n</p></blockquote>\n<p>Let\u2019s look at some of the popular word embedding models now and engineering features from our corpora!</p>\n<p>\u00a0</p>\n<h3>The Word2Vec\u00a0Model</h3>\n<p>\u00a0<br>\nThis model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity. Essentially these are unsupervised models which can take in massive textual corpora, create a vocabulary of possible words and generate dense word embeddings for each word in the vector space representing that vocabulary. Usually you can specify the size of the word embedding vectors and the total number of vectors are essentially the size of the vocabulary. This makes the dimensionality of this dense vector space much lower than the high-dimensional sparse vector space built using traditional Bag of Words models.</br></p>\n<p>There are two different model architectures which can be leveraged by Word2Vec to create these word embedding representations. These include,</p>\n<ul>\n<li><strong>The Continuous Bag of Words (CBOW) Model</strong>\n<li><strong>The Skip-gram Model</strong>\n</li></li></ul>\n<p>There were originally introduced by Mikolov et al. and I recommend interested readers to read up on the original papers around these models which include,\u00a0<a href=\"https://arxiv.org/pdf/1310.4546.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"><em>\u2018Distributed Representations of Words and Phrases and their Compositionality\u2019</em>\u00a0by Mikolov et al.</a>\u00a0and\u00a0<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"><em>\u2018Efficient Estimation of Word Representations in Vector Space\u2019</em>\u00a0by Mikolov et al.</a>\u00a0to gain some good in-depth perspective.</p>\n<p>\u00a0</p>\n<h3>The Continuous Bag of Words (CBOW)\u00a0Model</h3>\n<p>\u00a0<br>\nThe CBOW model architecture tries to predict the current target word (the center word) based on the source context words (surrounding words). Considering a simple sentence,\u00a0<strong><em>\u201cthe quick brown fox jumps over the lazy dog\u201d</em></strong>, this can be pairs of\u00a0<strong><em>(context_window, target_word)</em></strong>\u00a0where if we consider a context window of size 2, we have examples like\u00a0<strong><em>([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0</em></strong>and so on. Thus the model tries to predict the\u00a0<code>target_word</code>\u00a0based on the\u00a0<code>context_window</code>\u00a0words.</br></p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*UVe8b6CWYykcxbBOR6uCfg.png\" width=\"50%\"><br>\n<font size=\"-1\">The CBOW model architecture (Source:\u00a0<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">https://arxiv.org/pdf/1301.3781.pdf</a>\u00a0Mikolov el\u00a0al.)</font></br></img></center></p>\n<p>While the Word2Vec family of models are unsupervised, what this means is that you can just give it a corpus without additional labels or information and it can construct dense word embeddings from the corpus. But you will still need to leverage a supervised, classification methodology once you have this corpus to get to these embeddings. But we will do that from within the corpus itself, without any auxiliary information. We can model this CBOW architecture now as a deep learning classification model such that we take in the\u00a0<strong><em>context words as our input, X</em></strong>\u00a0and try to predict the\u00a0<strong><em>target word, Y</em></strong>. In fact building this architecture is simpler than the skip-gram model where we try to predict a whole bunch of context words from a source target word.</p>\n<p>\u00a0</p>\n<h3>Implementing the Continuous Bag of Words (CBOW)\u00a0Model</h3>\n<p>\u00a0<br>\nWhile it\u2019s excellent to use robust frameworks which have the Word2Vec model like gensim, let\u2019s try and implement this from scratch to gain some perspective on how things really work behind the scenes. We will leverage our\u00a0<strong><em>Bible corpus</em></strong>\u00a0contained in the\u00a0<code>norm_bible</code>\u00a0variable for training our model. The implementation will focus on four parts</br></p>\n<ul>\n<li><strong>Build the corpus vocabulary</strong>\n<li><strong>Build a CBOW (context, target) generator</strong>\n<li><strong>Build the CBOW model architecture</strong>\n<li><strong>Train the Model</strong>\n<li><strong>Get Word Embeddings</strong>\n</li></li></li></li></li></ul>\n<p>Without further delay, let\u2019s get started!</p>\n<p><b><strong>Build the corpus vocabulary</strong></b></p>\n<p>To start off, we will first build our corpus vocabulary where we extract out each unique word from our vocabulary and map a unique numeric identifier to it.</p>\n<p><script src=\"https://gist.github.com/dipanjanS/a39b18004827596638a9cc9bec4510c0.js\"></script></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre><strong>Output\r\n------</strong>\r\n\r\nVocabulary Size: 12425\r\nVocabulary Sample: [('perceived', 1460), ('flagon', 7287), ('gardener', 11641), ('named', 973), ('remain', 732), ('sticketh', 10622), ('abstinence', 11848), ('rufus', 8190), ('adversary', 2018), ('jehoiachin', 3189)]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Thus you can see that we have created a vocabulary of unique words in our corpus and also ways to map a word to its unique identifier and vice versa. The\u00a0<code><strong>PAD</strong></code>\u00a0term is typically used to pad context words to a fixed length if needed.</p>\n<p><b>Build a CBOW (context, target) generator</b></p>\n<p>We need pairs which consist of a target centre word and surround context words. In our implementation, a\u00a0<strong><em>target word</em></strong>\u00a0is of length <code><strong>1</strong></code> and <strong <em=\"\">surrounding context</strong></p></div> ", "website": "kdnuggets"}