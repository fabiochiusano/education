{"content": "By Abhijit Annaldas , Microsoft. I was planning agenda for my one hour talk. Conveying the learning paths, setting up the environment and explaining the important machine learning concepts finally made it to agenda after a lot of contemplation and thought. I initially thought about various ways this talk could have been done including - hands on python with linear regression, explaining linear regression in detail, or just sharing my learning journey that I went through past 18 months almost. But I wanted to start something that leaves the audience with lots of new information and questions to work on. Create curiosity and interest in them. And I guess I was able to do that to a decent level. Basically, to get them started with Machine Learning. That\u2019s how this guide ended up being called\u00a0 Getting Started with Machine Learning in one hour . The notes for the talk were great for an introductory learning path, but were structured only for myself to help with the talk. Hence I wrote a machine learning getting started guide out of it and here it is. I\u2019m very happy the way this ended up taking shape and I\u2019m excited to share this! There are two main approaches to learn Machine Learning. Theoretical Machine Learning approach and Applied Machine Learning approach. I\u2019ve written about it in my earlier\u00a0 blog post . \u00a0 Theoretical Machine Learning \u00a0 Below are the subjects that you can start with (ordered as I think they are appropriate). For theoretical approach of learning Machine Learning, below subjects should be studied with great rigor and in depths. Linear Algebra -\u00a0 MIT ,\u00a0 IISc. Bangalore Calculus -\u00a0 Basics, Coursera ,\u00a0 Advanced, Coursera Probability and Statistics -\u00a0 MIT Statistical Learning Theory -\u00a0 MIT ,\u00a0 Stanford Machine Learning -\u00a0 Coursera ,\u00a0 Caltech Programming language to implement machine learning research ideas. The way forward could be reading research papers, implementing research work/new algorithms, developing expertise and picking a specialization further on to the research path. \u00a0 Applied Machine Learning \u00a0 Good understanding of the basics of above subjects (1 to 4). Machine Learning (imp concepts explained below):\u00a0 Coursera ,\u00a0 Caltech Python \u00a0or R Programming Language, as per your preference. Learn to use popular machine learning, data manipulation and visualization libraries in the chosen programming language. I personally use Python programming language, hence I\u2019ll elaborate on that below. Must know Python Libraries:\u00a0 numpy ,\u00a0 pandas ,\u00a0 scikit-learn ,\u00a0 matplotlib Other popular python libraries:\u00a0 LightGBM ,\u00a0 XGBoost ,\u00a0 CatBoost \u00a0 Quick Start Option \u00a0 If you want to get a taste of what is Machine Learning about and what it could be like. You can start this way for experimenting, getting quick hands on. Not an ideal way if you want to get serious about Data Science in long run. Know Machine Learning Concepts Overview (below) Learn Python or R Understand and learn to use popular libraries in your language of choice \u00a0 Python Environment setup \u00a0 Python Python.org\u00a0 Download ,\u00a0 Learn \u00a0OR Anaconda\u00a0 Download ,\u00a0 Learn Code Editor / IDE Visual Studio Code (Search and install python extension, pick the most downloaded one) Notepad++ Jupyter \u00a0(Installs with Anaconda) Installing python packages Managing packages with pip, python\u2019s native tool :\u00a0 pip install Managing packages with anaconda :\u00a0 conda install Managing Python (native) virtual environments (if multiple environments are needed) Create virtual environment:\u00a0 python -m venv c:\\path\\to\\env\\folder Command help:\u00a0 python -m venv -h Switch environments:\u00a0 activate.bat \u00a0script located in the virtual environment folder Python (native) virtual environments\u00a0 documentation Managing Anaconda virtual environments (if multiple environments are needed) Default conda environment -\u00a0 root List available environments -\u00a0 conda env list Create new environment -\u00a0 conda create --name environment_name Switch to environment -\u00a0 activate environment_name \u00a0or\u00a0 source activate environment_name Anaconda virtual environments\u00a0 documentation \u00a0 Machine Learning Concepts Overview \u00a0 Machine Learning : Is an approach to find patterns from a large set of data through a function\u00a0  \u00a0which effectively generalizes to unseen\u00a0 x \u00a0to find learned patterns in unseen data and make the inferences the Machine Learning Model was trained for. Dataset : Data being used to apply machine learning and find patterns from. For supervised type of machine learning applications, the dataset contains both\u00a0 x \u00a0(input/attributes/independent variables) and\u00a0 y \u00a0(target/labels/dependent variables) data. For unsupervised data it\u2019s just\u00a0 x , input and the output of the data is some sort of learned patterns (like clusters, groups, etc.) Train set : A subset of\u00a0 Dataset \u00a0fed to (train) machine learning algorithm to learn patterns Evaluation / Validation / Cross Validation Set : Subset of\u00a0 Dataset \u00a0not in\u00a0 Train set \u00a0used to evaluate how the machine learning algorithm is doing. Test set :\u00a0 Dataset \u00a0to predict learned insights for. For supervised problems, target/label\u00a0 y \u00a0like in\u00a0 train set \u00a0is to be predicted and hence it isn\u2019t a part of\u00a0 train set . For unsupervised,\u00a0 train \u00a0and\u00a0 test \u00a0sets can be identical. Types : Supervised : In supervised problems, the historical data includes the labels (target attribute, outcomes) that need to be predicted for future/unseen data. For example, for housing price prediction we have data about house (area, # of bedrooms, location, etc.) and price. Here the after training a machine learning model with given data (X - data) and price (Y - labels), in future, price (Y) will be predicted for new/unseen data (X). Unsupervised : In unsupervised learning, there is no label or target attribute. A typical example would be clustering data based on learned patterns. Like for a dataset of house details (area, location, price, # of bedrooms, # of floors, built date, etc.) the algorithm needs to find if there is any hidden patterns. For example some houses are very expensive while some others are of usual price. Some houses are very big while some houses are of usual size. With these patterns, records/data is clustered into groups like Luxury-Homes, Non-Luxury Homes, Bunglows, Apartment, etc. Reinforcement : In Reinforcement Learning, an \u2018Agent\u2019 acts in an \u2018Environment\u2019 and receives positive or negative feedback. Positive feedback tells an agent that it has done well, and agent proceeds on similar plan/action. Negative feedback tells an agent that it has done something wrong, and should change it\u2019s course of action. The agent and the environment are software/programmed implementations. The core of reinforcement learning is building an agent (or agent\u2019s behaviour in some way) that learns to successfully accomplish a specific task in an environment. Popular Algorithms :\u00a0 Linear Regression ,\u00a0 Logistic Regression ,\u00a0 Support Vector Machines ,\u00a0 K-Nearest-Neighbors ,\u00a0 Decision Trees ,\u00a0 Random Forest ,\u00a0 Gradient Boosting ,\u00a0 Ensemble Learning Preprocessing : In real world scenario data is rarely clean and neat in a state that Machine Learning algorithms can be directly applied on. Preprocessing is a process of cleaning data to feed to machine learning algorithm. Some of the common preprocessing steps are\u2026 Missing Value : When some of the values are missing, they are usually dealt by adding median/mean values or deleting corresponding row, or using the value from the previous row, etc. There are many ways of doing this. What exactly needs to be done depends on the kind of data, problem being solved and business goals. Categorical Variables : Discrete finite set of values. Like \u2018car type\u2019, \u2018department\u2019, etc. These values are converted either into numbers or vectors. Conversion to vectors is known as\u00a0 One-Hot \u00a0Encoding. There are numerous ways of doing this in python. Some machine learning algorithms/libraries themselves handle categorical columns by encoding internally. One way of encoding is using\u00a0 sklearn.preprocessing.OneHotEncoder \u00a0in scikit-learn. Scaling : Proportionately reducing values in columns into a common scale like 0 to 1. Having values in all columns in a common range might improve accuracy and training speed to some extent. Text : Text needs to be processed using Natural Language Processing techniques (out of scope of this guide), when it isn\u2019t preprocessed, it is usually excluded from the training data that is fed to a machine learning algorithm. Imbalanced datasets : The data shouldn\u2019t be biased, skewed. For e.g., consider a classification task where an algorithm classifies data into 3 different classes - A, B and C. If the dataset has very few/high records of one class w.r.t. others it is said to be biased/imbalanced. Usually data is oversampled in such cases by synthetically generating more random data from existing data. Some machine learning algorithms/libraries allow providing weights or some parameter to balance out the skew internally without us doing the heavy lifting of fixing a skewed dataset. For example,\u00a0 SVM: Separating hyperplane for unbalanced classes \u00a0in scikit-learn. Outliers : Outliers need to be dealt with on a case by case basis based on the problem and business case. Data Transformation : When a column/attribute in a dataset doesn\u2019t have an inherent pattern, it is transformed into something like , , etc. where the transformed values might have interesting pattern/uniformity that can be learned. This is again, obviously case by case basis and needs data exploration to find a right fit. Feature Engineering : Feature Engineering is a process of deriving hidden insights from existing data. Consider a housing price prediction dataset which has columns \u2018plot-width\u2019, \u2018plot-length\u2019, \u2018number of bedrooms\u2019 and \u2018price\u2019. Here we see a key attribute area of the house is missing, but can be calculated based on \u2018plot-width\u2019 and \u2018plot-length\u2019. So a calculated column, \u2018area\u2019 is added to the dataset. This is known as feature engineering. Feature Engineering might be of different difficulty level, sometimes a derived attribute is right in front of sight like here, sometimes it\u2019s really hidden and needs lot of thinking. Training : This is a main step where the machine learning algorithm is trained on the given data to find generalized patterns to be applied on unseen data. Below are some important nitty-gritty details of this phase\u2026 Feature Selection : Not all features/columns contribute to the learning. These are the columns where the data in them don\u2019t affect the outcome. Such features are removed from the dataset. What features to train on and what features to exclude is decided based on feature importance given by a machine learning algorithm being applied. Most of the modern algorithms do provide the feature importances. If an algorithm doesn\u2019t provide, scikit-learn has\u00a0 capabilities \u00a0which can help in feature selection. Also correlated features are removed. Dimensionality Reduction :\u00a0 Dimentionality reduction \u00a0also aims to find the most important features of all the features, aiming to reduce the\u00a0 dimensionality \u00a0of the data. The main difference w.r.t. feature importance based feature selection is that, in Dimensionality Reduction, a subset of features and/or derived features are selected. In other words, we may not be able to map the extracted features to the original features. You can find more about dimensionality reduction in scikit-learn\u00a0 here . Feature Selection vs Dimensionality Reduction : In my opinion, one of the two ways should solve the purpose. If we do both feature selection based on feature importance and dimensionality reduction, we should first do based on feature importances. And then introduce dimensionality reduction. It goes without saying that we should evaluate the performance at every step to understand what\u2019s working and what\u2019s not. Feature selection based on feature importance is easy to interpret as the selected features are subset of all, which isn\u2019t a case with dimensionality reduction. Evaluation Metric : Evaluation metric is a metric used to evaluate predictions for their correctness. A machine learning algorithm while training uses an evaluation metric to evaluate, compute cost and optimize on the cost convex function. Though each algorithm has a default evaluation metric, it is recommended to specify the exact evaluation metric as per the business case/problem. Like some problems can afford false positives, but cannot afford any false negatives. By specifying the evaluation metric, these nitty gritty details of the model can be controlled. Parameter tuning : Though most of the today\u2019s state of the art algorithms have sensible default values for the parameters, it always helps to tune the parameters to control the accuracy of a model and improve overall predictions. Parameter tuning can be done on a trial and error basis by repeatedly changing and assessing the accuracy. Alternatively a set of parameter values can be provided to try all/different permutations of those parameters and find the best parameter combination. This can be done using some helper functions called\u00a0 Hyper-parameter Optimizers in scikit-learn . Overfitting (Bias) : Overfitting is a state where the machine learning model almost memorizes all the training data and predicts almost accurately on data that\u2019s already in training set. This is a state where the model fails to generalize and predict on unseen data. This is also known as model having high bias. Overfitting can be dealt with using Regularization, tuning hyperparameters if configured inappropriately, holding off partial dataset to use correct cross validation (1) (2) \u00a0strategy. Underfitting (Variance) : Underfitting is a state where the machine learning model\u2019s predictions don\u2019t do well even when predicting on data already in the training set. This is also known as model having high variance. Underfitting can be dealt with adding more data, adding/removing features, trying different machine learning algorithm, etc. Bias and Variance trade-off (sweet spot) : The goal of model training is to find a sweet spot where the model cross validation error is minimum. Initially both cross validation and train error are high (Underfitting/high variance). As the model is training, the error keeps dropping to a certain point where cross validation is minimum and also close to train error (sweet spot). This is optimal spot. After this point, if the model further keeps reducing error (on train set), it almost memorizes the train set ends up overfitting which means higher error on unseen data. Regularization : At some point when the model is trying to learn further (reducing error, tending towards overfitting), regularization helps in countering the overfitting effects. Regularization is usually a parameter that\u2019s added during cost/error calculation. Machine learning algorithms may not always provide regularization parameter explictly. In such case, usually there are other parameters that can be tuned to introduce regularization to the extent required. Prediction : To make predictions with trained machine learning model, the prediction method of the model is called by providing the test dataset as parameter. The test dataset should be preprocessed exactly the way it was done on the training dataset. In other words, in the same format of training data which was fed to the machine learning model for training. Other terminologies : Model Stacking : When single machine learning algorithm doesn\u2019t do well, multiple machine learning algorithms are used to make predictions and the predictions are combined together in different ways. Most simplest being a weighted predictions. Sometimes, other machine learning model (meta-model) is used on top of the predictions of the first level models. This could go to any level of complexity and can have different pipelines. \u00a0 Deep Learning \u00a0 Fun fact is that a majority (over 90% I guess) of all the machine learning problems solved today are solved using just Random Forests, Gradient Boosted Decision Trees, SVM, KNN, Linear Regression, Logistic Regression. But, there are some set of problems that cannot be solved using above techniques. Problems like image classification, image recognition, natural language processing, audio processing, etc. are solved using a technique called Deep Learning. Before starting deep learning, I believe it\u2019s essential to master all of the above concepts first. Good Deep Learning resources\u2026 Fast.ai \u00a0\u2013 thanks for the suggestion\u00a0 Pranay Tiwari ! neuralnetworksanddeeplearning.com - an online book, stresses on theory and fundamentals Deep Learning Specialization at Coursera by Andrew Ng deeplearningbook.org - an online book If you know deep learning concepts and want to get your hands dirty, some popular Deep Learning Libraries are:\u00a0 Keras ,\u00a0 CNTK ,\u00a0 Tensorflow ,\u00a0 tflearn ,\u00a0 sonnet ,\u00a0 pytorch ,\u00a0 caffe ,\u00a0 Theano \u00a0 Practice \u00a0 Yes, practice is the most important thing and this guide would have been incomplete without mentioning about practicing machine learning. To practice and master your skills further, below are the things you can do\u2026 Get datasets from various online data sources. One such popular data source is\u00a0 UCI Machine Learning Repository . Additionally, you can\u00a0 search \u2018datasets for machine learning\u2019 . Participate in online machine learning/data science hackathons. Some of the popular ones are -\u00a0 Kaggle ,\u00a0 HackerEarth , etc. If you end up starting with something that\u2019s very difficult, try persisting a bit. If it still feels difficult, park it aside and find other. There\u2019s no need to be disappointed. Usually problems on online hackathon have some level of difficulty which may not always be suitable for beginners. Blog about what you learn! It\u2019ll help you solidify your understanding and thoughts about the subject. Follow Data Science, Machine Learning topics on Quora, lot of great advice and questions/answers to learn from. Start listening to podcasts (available on link below) Check out some useful links on my\u00a0 Data Science Learning Resources \u00a0page. \u00a0 Closing thoughts \u00a0 If you are considering the field of Machine Learning/Data Science seriously and you are thinking of making a career switch, think about the your motivations and why you\u2019d like to do it. If you are sure, I have one advice for you.\u00a0 Never ever ever give up or think if its all worth it . It\u2019s definitely worth it and I can say that as I have walked that path since last 18 months\u2026 almost every day, every weekend and every spare hour of my time (except when I was travelling or I was totally drowned by my day job commitments). The road ahead to master data science isn\u2019t easy. As they say,\u00a0 \u201cRome was not built in a day!\u201d . You\u2019ll need to learn lot of subjects. Juggle between different learning priorities. Even after learning a lot you\u2019ll still find new things that you have never thought/heard about before. New concepts/techniques that you keep discovering might make you feel that you still don\u2019t know a lot of things and there is a lot more ground to cover. This is common. Just stick with it. Set big goals, plan for small tasks and just focus on task at hand. If something new comes up, just scribble it down in your diary and get back to it later. \u00a0 Thank You! \u00a0 If you have been reading all the way till here, I appreciate your effort and the time you have invested. I hope this guide was useful to you and has made it little easier for you to get started on your own learning adventure. At some later point of time, if you think this guide has made some difference in your learning adventure, please please come back and leave a comment here. Or reach me at avannaldas .at. hotmail .dot. com. I\u2019d love to hear from you. It\u2019ll give me immense satisfaction to know that this has helped you, and my effort in putting this together was worthwhile. This was my biggest write up ever. I have spent many hours writing, editing and reviewing this. If you see any mistakes or things that can be improved, please let me know in comments or via email. I\u2019ll fix it the earliest I can and will attribute it to you. This will help everyone who reads this. Thanks Again! All the best! \u00a0 Bio: Abhijit Annaldas is a Software Engineer and a voracious learner who has acquired Machine Learning knowledge and expertise to a fair extent. He is improving expertise day by day by learning new stu\ufb00 and relentless practice, and has extensive experience building enterprise scale applications in di\ufb00erent Microsoft and Open Source technologies as a Software Engineer at Microsoft, India since June 2012. Original . Reposted with permission. Related: How to Learn Machine Learning in 10 Days The Guerrilla Guide to Machine Learning with Python Density Based Spatial Clustering of Applications with Noise (DBSCAN)", "title_html": "<h1 id=\"title\">Getting Started with Machine Learning in One Hour!</h1> ", "url": "https://www.kdnuggets.com/2017/11/getting-started-machine-learning-one-hour.html", "tfidf": {"tfidf": {"hand": 6.460881066240001, "art": 1.9994962216599999, "easier": 7.84, "shouldn": 1221.23076923, "heavi": 2.88707037643, "visual": 10.45505432994, "kind": 2.5806241872599998, "addit": 1.24634950542, "dirti": 18.2482758621, "june": 1.43414634146, "nois": 11.6907216495, "audio": 9.05647461495, "editor": 4.33060556465, "etc": 42.066772654999994, "specif": 1.8719490626099997, "class": 6.34955339289, "happi": 6.125, "lightgbm": 1221.23076923, "python": 957.0638297867999, "thought": 7.941970985479999, "onehot": 1221.23076923, "further": 5.447246526, "never": 3.11538461538, "path": 18.568421052639998, "toward": 1.6303142329, "their": 1.01547908405, "motiv": 5.01611374408, "scale": 11.240972386109998, "yes": 14.1876675603, "stack": 19.6485148515, "ever": 5.90918114145, "fit": 3.37070063694, "proportion": 81.4153846154, "special": 2.9763779527599996, "would": 2.1657458563599996, "oversampl": 1221.23076923, "end": 4.42721695484, "correl": 13.1860465116, "word": 3.5930745728199995, "deep": 25.395795246779997, "depend": 2.2411067193700003, "beginn": 53.4545454545, "open": 1.24556723678, "manipul": 9.145161290319999, "encod": 87.0712979889, "improv": 8.17507723996, "new": 6.1073283324, "perform": 1.5313977042500002, "but": 5.0816208949499995, "futureunseen": 1221.23076923, "certain": 1.8077886586200003, "classif": 16.134146341460003, "cost": 4.63871439006, "off": 1.5121440137200002, "fix": 8.869273743019999, "overal": 3.0442953020099996, "record": 1.42334588488, "bedroom": 82.4013840831, "walk": 3.56363636364, "immens": 12.7723250201, "has": 11.4801472522, "listen": 6.97846153846, "inappropri": 21.6, "default": 63.4194407457, "resourc": 2.9487369985100003, "thank": 18.02043132804, "out": 4.24066777964, "mistak": 8.71350164654, "model": 41.811956808000005, "format": 2.53125, "good": 3.03963239518, "alway": 6.2023701002700005, "concept": 15.94242677826, "number": 2.20285833218, "optim": 34.6133720931, "field": 1.7790228597, "when": 7.1453738828499995, "tri": 7.417825020439999, "iisc": 1221.23076923, "kaggl": 1221.23076923, "down": 1.35889754344, "altern": 2.1390460792200003, "logist": 28.1989342806, "do\u2026": 1221.23076923, "quick": 4.41, "pleas": 27.38815411155, "persist": 6.787516032490001, "metric": 155.6470588232, "handl": 3.9229058561900003, "phase\u2026": 1221.23076923, "contempl": 18.3114186851, "then": 1.08657860516, "separ": 1.6012102874399998, "they": 3.09051975861, "convex": 103.764705882, "bit": 8.33385826772, "instal": 18.9360687023, "effect": 2.7926121372000003, "techniqu": 11.18816067654, "voraci": 155.647058824, "featur": 42.75952289336, "feed": 7.77853993141, "practic": 8.52173913045, "alreadi": 3.9103448275800003, "algorithm": 559.014084508, "theori": 6.05491990846, "venv": 2442.46153846, "spatial": 24.4246153846, "either": 1.5830092731099998, "develop": 1.1955719557200002, "conceptstechniqu": 1221.23076923, "such": 4.24605509496, "accuraci": 38.2861736334, "rome": 6.615, "via": 2.2978723404299997, "without": 3.88641370869, "lot": 35.27020272144, "suitabl": 6.23811394892, "should": 9.98595240594, "invest": 4.16146788991, "india": 3.92387543253, "miss": 10.60993539765, "helper": 79.38, "ani": 4.53535209256, "two": 2.0275862069, "virtual": 24.677720207280004, "work": 2.23040179826, "detail": 9.04744265564, "newunseen": 1221.23076923, "depart": 1.99147014551, "partial": 3.6131087847099996, "idea": 2.0930784443, "environ": 61.84115992206, "for": 30.009451200300003, "difficult": 4.97914379802, "worknew": 1221.23076923, "output": 7.676982591880001, "with": 22.026360597779995, "inher": 10.7706919946, "nativ": 9.02216328849, "effort": 3.78495649064, "numpi": 1221.23076923, "veri": 6.29400570885, "extract": 7.703056768560001, "intern": 2.60711060022, "think": 17.442959164980003, "want": 7.98792452832, "negat": 11.27556818181, "combin": 3.39520958084, "later": 2.17300848618, "focus": 2.01012914662, "again": 3.01767724768, "group": 2.41993750476, "park": 2.4633048875099997, "convers": 3.3486606201200004, "hackerearth": 1221.23076923, "give": 2.7306501548, "valid": 39.67346938776, "scope": 10.3494132986, "train": 52.2873871677, "great": 3.79778327088, "step": 8.48379052368, "total": 1.5460122699399999, "stick": 11.5377906977, "big": 5.480151881259999, "fals": 12.43226311668, "reinforc": 19.36097560977, "probabl": 2.64555907349, "machin": 209.26539923951998, "into": 5.0751230739499995, "paper": 2.6628648104700003, "themselv": 2.05967825636, "abov": 5.7114761961900005, "what": 10.02747513024, "various": 2.6646525679799997, "knearestneighbor": 1221.23076923, "overfit": 7327.3846153800005, "help": 11.19703782072, "believ": 1.6450108797, "find": 20.752941176519997, "curios": 35.5964125561, "drown": 18.7659574468, "creat": 4.9971671388, "relat": 1.23750876919, "decid": 1.9257641921400002, "wrt": 2442.46153846, "incomplet": 14.8930581614, "speed": 3.8703071672400005, "infer": 21.1398135819, "paramet": 207.07826086920002, "script": 8.299006795610001, "togeth": 3.16191993626, "contain": 1.59814777532, "di\ufb00er": 1221.23076923, "about": 11.71346166749, "scikitlearn": 7327.3846153800005, "wrote": 2.10473286491, "thing": 12.032742155549998, "just": 8.01480858222, "xgboost": 1221.23076923, "price": 27.870967741919998, "repost": 933.882352941, "person": 1.40520446097, "earliest": 3.5991838585400004, "expens": 3.5453327378300004, "recommend": 3.9142011834300003, "ensembl": 16.746835443, "neat": 51.3786407767, "complex": 2.34021226415, "let": 3.48616600791, "spent": 3.00795755968, "start": 13.934093991840001, "featurescolumn": 1221.23076923, "abhijit": 2442.46153846, "run": 1.55692850838, "studi": 1.53184098804, "keep": 6.12736395213, "explain": 7.8014742014700005, "singl": 1.60948905109, "guerrilla": 19.5276752768, "usual": 13.80071715744, "abl": 3.6417020300400003, "diari": 11.6052631579, "mani": 2.08853515754, "coursera": 6106.15384615, "the": 114.0, "goal": 9.84456386937, "generat": 2.05275407292, "build": 3.2683479156, "error": 48.32876712328, "linear": 69.388111888, "underfittinghigh": 1221.23076923, "imp": 162.0, "unbalanc": 103.764705882, "exact": 10.40594275725, "command": 2.66689064337, "went": 1.8098495212, "assess": 5.24306472919, "say": 5.2633440159, "origin": 2.27449856734, "right": 2.8109065155799997, "introductori": 30.297709923699998, "knowledg": 3.3981164383599998, "take": 1.13961668222, "environmentnam": 3663.6923076900002, "follow": 1.04640126549, "catboost": 1221.23076923, "strategi": 4.44208170118, "discov": 2.52160101652, "goe": 4.251740760580001, "medianmean": 1221.23076923, "thoughtheard": 1221.23076923, "also": 5.07382550335, "dealt": 45.1022727272, "specifi": 13.841325196160001, "modern": 1.5319888063299998, "mean": 1.44906900329, "nitti": 547.448275862, "task": 15.54565483476, "each": 1.18974820144, "targetlabelsdepend": 1221.23076923, "scenario": 15.3986420951, "may": 3.15605327679, "consid": 3.7191941277600007, "podcast": 49.6125, "ground": 1.97610156833, "convert": 3.2740771293099997, "share": 3.7132499123000002, "still": 3.5599073174399996, "which": 7.036342915, "skill": 3.6989748369099997, "ident": 2.80792359392, "variabl": 26.241322314059996, "one": 9.05647461498, "terminolog": 17.6989966555, "hope": 2.50884955752, "pathtoenvfold": 1221.23076923, "synthet": 21.3674293405, "see": 2.54484251022, "hyperplan": 882.0, "explict": 1221.23076923, "prioriti": 8.623574144489998, "outlier": 538.169491526, "get": 17.8562591385, "random": 21.5706521739, "myself": 14.5517873511, "manag": 6.579361790319999, "dot": 18.8775267539, "cross": 11.6563876652, "agent": 29.81008583693, "transform": 10.26023265834, "opinion": 3.8044572250199997, "repeat": 2.8771293947099994, "everi": 5.91670548776, "kera": 835.5789473680001, "pick": 9.879278158060002, "road": 2.49819040126, "metamodel": 1221.23076923, "decent": 35.5964125561, "finit": 28.1989342806, "engin": 14.828144458259999, "back": 2.52140077822, "plotlength": 2442.46153846, "recognit": 4.40022172949, "permut": 102.425806452, "most": 6.12578778138, "fail": 1.9281029876099998, "all": 10.1146788991, "top": 1.8387769284200002, "costerror": 1221.23076923, "today": 3.49922856514, "behaviour": 9.879278158060002, "gradient": 83.778364116, "solv": 43.61538461538, "case": 11.87989898048, "underfit": 3663.6923076900002, "luxuryhom": 1221.23076923, "weight": 9.757836508919999, "tradeoff": 208.89473684200001, "cluster": 50.0031496064, "futur": 1.8577112099200002, "and": 77.00485039400999, "correspond": 3.32481675393, "home": 1.4599963215, "capabl": 3.6580645161300005, "general": 3.3654607122600004, "made": 3.21116504853, "librari": 13.41331530925, "everyon": 6.3964544722, "download": 43.937269372799996, "affect": 2.4794627518400003, "can": 28.23027339408, "avail": 3.4576935642, "studio": 4.9273743016800005, "counter": 6.77592829706, "onli": 1.0256476516600002, "convey": 12.297443842, "andrew": 3.82462057336, "key": 2.28005170185, "this": 29.11001517459, "link": 4.30302208972, "advanc": 1.9997480791, "review": 2.2099109131400003, "data": 145.18672905162, "questionsansw": 1221.23076923, "audienc": 4.4784203103, "method": 2.5714285714300003, "sinc": 2.16737201366, "will": 3.67443295788, "must": 1.9220338983099996, "worth": 10.420741713160002, "text": 6.25655172414, "solidifi": 33.006237006199996, "direct": 1.22226499346, "success": 1.32002993265, "proceed": 3.4333910034599997, "busi": 6.16623511134, "cover": 1.69380134429, "extent": 12.28475625483, "page": 2.03669018602, "unsupervis": 1380.5217391320002, "rare": 2.7259615384599996, "suggest": 1.7571665744299998, "own": 1.17844418052, "worthwhil": 86.28260869569999, "after": 4.08280828084, "real": 2.28103448276, "boost": 18.32198499712, "ahead": 5.625797306869999, "vector": 77.696574225, "basi": 7.26368766204, "pip": 271.384615384, "fastai": 1221.23076923, "panda": 111.802816901, "memor": 32.235532995, "dataset": 3678.585365862, "function": 7.486325055, "learner": 75.2417061611, "bangalor": 88.6927374302, "sonnet": 108.739726027, "hear": 4.17899447223, "well": 3.1967246123999997, "done": 16.31175693525, "floor": 5.2621809744800006, "approach": 10.37782716695, "higher": 2.1218925421, "pranay": 1221.23076923, "front": 2.32820061593, "know": 15.559621038900001, "fun": 12.8863636364, "calculus": 62.2588235294, "months\u2026": 1221.23076923, "multipl": 8.24441751774, "how": 4.80750984153, "test": 10.62828451884, "fair": 3.20533010297, "resources\u2026": 1221.23076923, "initi": 2.7, "sure": 7.453521126760001, "given": 4.06278256419, "lift": 6.37846524709, "interest": 3.20662492426, "simplest": 28.0494699647, "overview": 25.3610223642, "asid": 6.69873417722, "weekend": 8.79556786704, "difficulti": 7.671418216960001, "purpos": 2.23416830847, "below": 18.04860025576, "similar": 1.37514075357, "definit": 3.24, "need": 15.80988593151, "commit": 2.8860207235, "subject": 9.35753860665, "final": 1.34008609775, "algebra": 41.4516971279, "tune": 52.086614173, "point": 5.03960003176, "caff": 992.25, "applic": 10.28016404058, "hidden": 23.43897637794, "level": 8.27219674865, "hyperparamet": 2442.46153846, "have": 17.253212299379996, "long": 1.2657259028899999, "tensorflow": 1221.23076923, "reduct": 50.56050955415999, "experi": 3.74125132556, "forward": 3.66566612792, "excit": 9.818181818180001, "comment": 6.11909809212, "cours": 2.15092805853, "numer": 1.83325635104, "disappoint": 8.776119402989998, "sklearnpreprocessingonehotencod": 1221.23076923, "not": 10.1567398119, "elabor": 7.0591373944, "appreci": 8.11241696474, "aim": 5.792046698280001, "till": 11.563000728299999, "easi": 10.5875291764, "jupyt": 1221.23076923, "appropri": 4.31413043478, "though": 2.72152224222, "biggest": 5.2972972973, "conda": 4884.92307692, "core": 4.623179965059999, "reach": 1.49801849406, "gritti": 112.595744681, "tell": 6.72284564896, "world": 1.11340206186, "minimum": 12.05924800608, "outcom": 14.97735849056, "chosen": 3.59266802444, "pytorch": 1221.23076923, "blog": 28.3753351206, "caseproblem": 1221.23076923, "softwareprogram": 1221.23076923, "env": 1221.23076923, "that": 28.111553784999998, "calcul": 18.38918918919, "guid": 17.43794131492, "valu": 25.055380200840002, "softwar": 20.5248868778, "those": 1.19548192771, "explor": 3.39593582888, "stu\ufb00": 1221.23076923, "deriv": 8.35139400315, "some": 23.92844036704, "sourc": 6.79041916168, "small": 1.3594793629, "control": 2.93918356012, "both": 3.15647160183, "locat": 4.79299587402, "built": 3.98894472362, "com": 99.8490566038, "unseen": 204.06169665800002, "subset": 109.3012048192, "supervis": 30.96245733788, "repositori": 44.974504249300004, "use": 20.592775147599998, "introduc": 3.4516795303800003, "set": 20.18034993277, "question": 2.20408163265, "fed": 37.6208530806, "particip": 2.19828302409, "from": 10.0056721497, "targetlabel": 1221.23076923, "technolog": 2.6034765496900003, "leav": 3.3230769230799995, "advic": 14.16235504014, "acquir": 3.10563380282, "balanc": 4.45329593268, "predict": 98.51208360545, "quora": 1221.23076923, "spot": 18.11811697576, "book": 2.86829268292, "written": 1.9573418813999999, "theano": 1221.23076923, "are": 35.01680181652, "month": 1.5079787234, "inputattributesindepend": 1221.23076923, "preprocess": 6106.15384615, "feedback": 73.95652173900001, "popular": 10.55384615383, "option": 4.04896710023, "histor": 1.6755672823199999, "varianc": 205.5145631068, "root": 3.57809330629, "exclud": 10.63718592964, "said": 1.54751925139, "biasedimbalanc": 1221.23076923, "posit": 4.11757586238, "forest": 9.79093432008, "master": 9.45375148869, "column": 42.46812304950001, "bunglow": 1221.23076923, "tend": 3.3735656608599998, "caltech": 417.78947368400003, "remov": 4.011623499680001, "map": 4.0728578758300005, "wrong": 5.478260869570001, "even": 2.32922535212, "littl": 1.5499365420299998, "part": 1.04330682789, "skew": 214.5405405405, "edit": 1.99297012302, "hous": 11.699336772319999, "switch": 14.921052631590001, "note": 1.42449528937, "row": 11.098217406500002, "rigor": 17.8783783784, "bias": 54.9342560552, "hackathon": 2442.46153846, "through": 2.14149861738, "requir": 1.52844902282, "last": 1.2117234010100002, "earlier": 1.86776470588, "allow": 1.2716059271100002, "nittygritti": 1221.23076923, "guess": 50.0820189274, "interpret": 3.2150668286799995, "tast": 9.305978898010002, "main": 3.7591160220899997, "type": 6.084312723570001, "larg": 1.18574949585, "scienc": 13.918176504959998, "day": 7.10229645096, "agenda": 25.7727272728, "base": 10.31653429605, "natur": 3.0785340314200003, "label": 13.431472081229998, "fact": 1.73375559681, "hour": 9.03842869344, "who": 2.12558575446, "almost": 7.6792106026999996, "plotwidth": 2442.46153846, "hold": 1.6551292744, "email": 33.4936708861, "imbalanc": 567.0, "post": 2.23826307627, "here": 16.96153846156, "ideal": 4.65571847507, "microsoft": 74.5352112675, "were": 2.04917715392, "clean": 13.73950670706, "comput": 3.9277585353800006, "apart": 3.1032056294, "onlin": 13.025927141450001, "spare": 9.997481108310001, "evalu": 76.46059544661999, "henc": 16.172495755529997, "problem": 15.900734475810001, "job": 3.2539454806299997, "way": 15.8479612993, "adventur": 13.30205278592, "columnattribut": 1221.23076923, "correct": 7.3262574988399995, "topic": 5.457545548300001, "dure": 1.0503473370799998, "classifi": 5.2937645882, "tflearn": 1221.23076923, "check": 6.50655737705, "serious": 5.16796875, "contribut": 1.9255306246200001, "where": 9.60435571689, "categor": 30.0397350994, "love": 2.97303370787, "neuralnetworksanddeeplearningcom": 1221.23076923, "them": 3.29628347982, "insight": 23.6074349442, "whi": 3.2566153846200003, "planact": 1221.23076923, "support": 1.2685577307200002, "target": 6.437956204380001, "notepad": 756.0, "relentless": 41.889182058, "afford": 14.175, "date": 1.63081664099, "pythonorg": 1221.23076923, "depth": 8.24299065421, "provid": 7.29316285122, "are\u2026": 1221.23076923, "select": 16.18761152176, "scribbl": 256.064516129, "order": 1.24625166811, "there": 9.36821400471, "exist": 2.9294215333599998, "regular": 12.56509695288, "inform": 1.5753125620200001, "num": 12.00378048012, "best": 3.1657028913200005, "setup": 34.1419354839, "journey": 5.41843003413, "previous": 1.42846859816, "fewhigh": 1221.23076923, "configur": 11.504347826099998, "name": 1.10211732037, "code": 7.761427523839999, "per": 3.9195161091199995, "high": 3.44331983805, "basic": 8.190541702500001, "regress": 307.2774193548, "realli": 4.7476076555, "stress": 5.52978056426, "feel": 6.271380604380001, "typic": 2.2541530597799997, "hotmail": 1221.23076923, "pattern": 37.917363267300004, "nonluxuri": 1221.23076923, "patternuniform": 1221.23076923, "major": 1.14852058164, "research": 7.768073394480001, "plan": 3.0713871155000003, "accomplish": 5.17302052786, "over": 1.02525024217, "area": 5.5525050275600005, "theoret": 23.50839091806, "past": 2.01702452039, "sweet": 30.7079303676, "talk": 12.1213972132, "receiv": 1.3054847463200001, "act": 1.4318181818200002, "extens": 3.9834399699, "essenti": 2.9280708225700005, "trial": 4.04175152749, "attribut": 17.078313252999997, "come": 2.65662650602, "activ": 2.92807082258, "matplotlib": 1221.23076923, "other": 9.08931297708, "appli": 13.7832441036, "might": 8.624745348360001, "known": 4.343638850880001, "prefer": 3.0216977540900003, "andor": 690.260869565, "size": 2.49387370405, "imag": 5.40275650842, "fundament": 5.32930513595, "like": 13.790228013, "implement": 10.729443568379999, "alldiffer": 1221.23076923, "drop": 2.4594887684, "except": 1.71948445792, "process": 10.17148958892, "put": 1.65806788512, "includ": 2.0381282495599997, "structur": 2.0580762250499998, "travel": 1.9655812801800001, "choic": 3.1319786940200003, "rang": 1.7848229342299997, "time": 3.03382381044, "discret": 15.0056710775, "anaconda": 1118.028169015, "delet": 22.1731843575, "chang": 2.3617970842, "document": 5.0819462228, "juggl": 167.115789474, "differ": 9.892359218, "been": 3.0717832957199995, "statist": 8.48530197756, "first": 3.0228484386899996, "between": 1.03453668708, "tree": 8.255850234, "diment": 1221.23076923, "stanford": 12.6, "obvious": 6.44841592201, "action": 1.81855670103, "expertis": 60.060529634400005, "program": 8.08556149732, "someth": 16.407606448950002, "addingremov": 1221.23076923, "satisfact": 23.4159292035, "sort": 5.188235294119999, "call": 4.2706119704, "more": 4.0686827268, "algorithmslibrari": 2442.46153846, "list": 2.72642967542, "these": 4.29661705008, "tiwari": 721.636363636, "learningdata": 2442.46153846, "could": 4.8174783796, "car": 3.53743315508, "befor": 2.20072082062, "activatebat": 1221.23076923, "state": 5.238566620449999, "close": 2.5697636775599997, "languag": 16.06418039898, "make": 5.3813300793000005, "sensibl": 24.164383561599998, "search": 6.507890961259999, "folder": 168.893617021, "accur": 5.768895348840001, "permiss": 6.280063291139999, "read": 6.944881889760001, "packag": 23.485207100580002, "common": 5.6103896103999995, "enterpris": 6.414545454550001, "reduc": 7.94793491864, "deeplearningbookorg": 1221.23076923, "shape": 3.20338983051, "sometim": 5.137864077660001, "bio": 42.336000000000006, "avannalda": 1221.23076923, "exampl": 6.01933649288, "career": 2.98757997742, "dimension": 433.4744027304, "understand": 11.87434554972, "annalda": 2442.46153846, "import": 13.401992233700001, "decis": 4.32, "sight": 6.79914346895, "input": 12.2029208301, "pipelin": 32.1376518219, "tool": 4.99716713881, "while": 3.1325966850899993, "densiti": 7.3465987968499995, "write": 4.1150855365400005, "learn": 209.0475493785, "recordsdata": 1221.23076923, "same": 1.11857958148, "mention": 2.53894130817}, "logtfidf": {"hand": 1.917885341344, "art": 0.6928952596619999, "easier": 2.05923883436, "shouldn": 7.1076144564399995, "heavi": 1.0602422774, "visual": 3.3078766977200003, "kind": 0.948031302717, "addit": 0.220218882972, "dirti": 2.90407060225, "june": 0.3605697882, "nois": 2.45879550578, "audio": 2.2034799289800002, "editor": 1.4657073855, "etc": 14.366730879700002, "specif": 0.626980167541, "class": 2.2493165697990003, "happi": 1.81237875643, "lightgbm": 7.1076144564399995, "python": 68.52116463032, "thought": 2.743468473132, "onehot": 7.1076144564399995, "further": 1.235263581188, "never": 0.886410872182, "path": 6.1406719353999994, "toward": 0.48877277716000006, "their": 0.015360505122700001, "motiv": 1.61265547932, "scale": 3.9628591898399996, "yes": 2.65237310559, "stack": 2.97800175538, "ever": 2.0336849352060002, "fit": 1.2151206268899999, "proportion": 4.3995642553400005, "special": 0.7951198572020001, "would": 0.1592352559294, "oversampl": 7.1076144564399995, "end": 0.405907194472, "correl": 2.57915918803, "word": 1.17172216477, "deep": 9.0207142886, "depend": 0.806969815, "beginn": 3.9788316751, "open": 0.219591038029, "manipul": 2.21322491868, "encod": 10.10434503444, "improv": 2.8591832157279997, "new": 0.1063796811066, "perform": 0.42618085058, "but": 0.0809618603595, "futureunseen": 7.1076144564399995, "certain": 0.592104362781, "classif": 4.17558147258, "cost": 1.68258015236, "off": 0.41352852038800003, "fix": 2.97889146902, "overal": 1.1132694464700001, "record": 0.353010356953, "bedroom": 9.93896983569, "walk": 1.270781474, "immens": 2.54728072239, "has": 0.4699633934028, "listen": 1.94282848252, "inappropri": 3.0726933146900004, "default": 9.153474486419999, "resourc": 1.08137694258, "thank": 5.3786816979, "out": 0.2337055636772, "mistak": 2.1648737360799997, "model": 14.74900146222, "format": 0.9287132518729999, "good": 0.837178809814, "alway": 2.1789576137160003, "concept": 5.863346622618, "number": 0.1932171568372, "optim": 7.336883386229999, "field": 0.5760642583510001, "when": 0.1438849220088, "tri": 2.47036611664, "iisc": 7.1076144564399995, "kaggl": 7.1076144564399995, "down": 0.306673741186, "altern": 0.760359972282, "logist": 5.2922740104, "do\u2026": 7.1076144564399995, "quick": 1.581455017798, "pleas": 6.634494898650001, "persist": 1.9150850473199998, "metric": 21.711765960919998, "handl": 1.36683266903, "phase\u2026": 7.1076144564399995, "contempl": 2.90752483712, "then": 0.08303386523089999, "separ": 0.470759772949, "they": 0.0891809843028, "convex": 4.64212589251, "bit": 2.12032652634, "instal": 6.658152939500001, "effect": 0.667660454316, "techniqu": 3.94873154421, "voraci": 5.04759100062, "featur": 11.854847707975999, "feed": 2.05136865109, "practic": 2.665912654335, "alreadi": 1.340956761494, "algorithm": 66.6088479036, "theori": 2.21544793804, "venv": 14.215228912879999, "spatial": 3.1955914510100003, "either": 0.459327638815, "develop": 0.178624694913, "conceptstechniqu": 7.1076144564399995, "such": 0.238783911224, "accuraci": 7.6394296218, "rome": 1.88933979757, "via": 0.831983625414, "without": 0.7766235538230001, "lot": 11.868775602000001, "suitabl": 1.83067788492, "should": 3.0565192605480003, "invest": 1.42586787018, "india": 1.36707979618, "miss": 3.7895357253600004, "helper": 4.37424644735, "ani": 0.502433433464, "two": 0.0273976887164, "virtual": 8.48484810864, "work": 0.218069134546, "detail": 3.264751108692, "newunseen": 7.1076144564399995, "depart": 0.68887313257, "partial": 1.28456856096, "idea": 0.73863592212, "environ": 22.215553254539998, "for": 0.009449711861910001, "difficult": 1.824221535176, "worknew": 7.1076144564399995, "output": 2.03822657827, "with": 0.02634481769458, "inher": 2.37682874115, "nativ": 3.3032155472399998, "effort": 1.275774422114, "numpi": 7.1076144564399995, "veri": 1.15079896619, "extract": 2.04161723301, "intern": 0.530190755632, "think": 6.403059670499999, "want": 2.7665464250199996, "negat": 3.9720779655600005, "combin": 1.058436621502, "later": 0.1659308519756, "focus": 0.6981989720559999, "again": 0.822680463224, "group": 0.381189069594, "park": 0.9015038985299999, "convers": 1.2085604509999999, "hackerearth": 7.1076144564399995, "give": 0.622785104448, "valid": 11.33353930608, "scope": 2.33692983198, "train": 17.844794446653, "great": 0.707415774237, "step": 3.11863517094, "total": 0.43567888670500005, "stick": 2.4456277954099996, "big": 2.01597127114, "fals": 3.6542955546199996, "reinforc": 5.59394155494, "probabl": 0.972882412913, "machin": 72.40269819224, "into": 0.0745643161435, "paper": 0.979402539665, "themselv": 0.7225497843690001, "abov": 1.9315956894480002, "what": 1.807098374616, "various": 0.57385300014, "knearestneighbor": 7.1076144564399995, "overfit": 42.645686738639995, "help": 2.689661770752, "believ": 0.497746997996, "find": 6.573375963456, "curios": 3.5722448618800002, "drown": 2.9320444543, "creat": 0.890307274056, "relat": 0.21310030165399999, "decid": 0.655322871893, "wrt": 14.215228912879999, "incomplet": 2.70089520918, "speed": 1.3533338752700002, "infer": 3.0511581621399997, "paramet": 34.178281726319995, "script": 2.1161358444599996, "togeth": 0.916064474616, "contain": 0.468845318236, "di\ufb00er": 7.1076144564399995, "about": 0.6912782522206, "scikitlearn": 42.645686738639995, "wrote": 0.744188554049, "thing": 4.3909676734, "just": 1.737188604654, "xgboost": 7.1076144564399995, "price": 9.98515218112, "repost": 6.83935046985, "person": 0.34018281601800004, "earliest": 1.2807071138, "expens": 1.26563201674, "recommend": 1.36461126863, "ensembl": 2.81820931165, "neat": 3.9392225370099996, "complex": 0.8502416364309999, "let": 1.2488025672799998, "spent": 1.10126129684, "start": 2.600877062201, "featurescolumn": 7.1076144564399995, "abhijit": 14.215228912879999, "run": 0.442714975539, "studi": 0.426470272221, "keep": 2.142457034019, "explain": 2.867101282074, "singl": 0.475916769059, "guerrilla": 2.9718327043599997, "usual": 4.362232136512, "abl": 1.19860796495, "diari": 2.45145871572, "mani": 0.0866315162442, "coursera": 35.5380722822, "the": 0.0, "goal": 3.56492136819, "generat": 0.719182341736, "build": 0.982274904182, "error": 14.3886834744, "linear": 13.151388209799999, "underfittinghigh": 7.1076144564399995, "imp": 5.08759633523, "unbalanc": 4.64212589251, "exact": 3.7312943197500004, "command": 0.9809132407500001, "went": 0.593243704365, "assess": 1.65690619935, "say": 1.6864628416560001, "origin": 0.257224875174, "right": 0.68071970834, "introductori": 3.41107212958, "knowledg": 1.2232212893899999, "take": 0.130691962197, "environmentnam": 21.322843369319997, "follow": 0.045356911094199995, "catboost": 7.1076144564399995, "strategi": 1.49112311818, "discov": 0.924894023806, "goe": 1.4473284897999998, "medianmean": 7.1076144564399995, "thoughtheard": 7.1076144564399995, "also": 0.073285789, "dealt": 9.69055310872, "specifi": 3.86902303242, "modern": 0.426566764719, "mean": 0.37092128352, "nitti": 6.305267983919999, "task": 5.42994722644, "each": 0.173741689304, "targetlabelsdepend": 7.1076144564399995, "scenario": 2.73427932989, "may": 0.1521299858532, "consid": 0.644684171472, "podcast": 3.9042428181099997, "ground": 0.681125998984, "convert": 1.1860360368, "share": 1.237520599494, "still": 0.5133666642870001, "which": 0.036248896918010004, "skill": 1.30805571015, "ident": 1.03244527565, "variabl": 6.506169201600001, "one": 0.0562981648095, "terminolog": 2.87350795184, "hope": 0.919824304455, "pathtoenvfold": 7.1076144564399995, "synthet": 3.0618677691900005, "see": 0.481843170984, "hyperplan": 6.7821920560099995, "explict": 7.1076144564399995, "prioriti": 2.1544996326700003, "outlier": 11.19005274, "get": 5.79769005782, "random": 5.9181642195299995, "myself": 2.67771382807, "manag": 1.990573548632, "dot": 2.93797215393, "cross": 4.232082073795, "agent": 10.1425564667, "transform": 3.6889896812100003, "opinion": 1.33617333331, "repeat": 1.0567930591299999, "everi": 1.565941709684, "kera": 6.72812483474, "pick": 3.19458453522, "road": 0.915566630279, "metamodel": 7.1076144564399995, "decent": 3.5722448618800002, "finit": 3.33928418576, "engin": 5.428605349655999, "back": 0.46333486179399996, "plotlength": 14.215228912879999, "recognit": 1.4816549327200002, "permut": 4.62913869698, "most": 0.12448737777359999, "fail": 0.656536611573, "all": 0.11402632097799999, "top": 0.609100637788, "costerror": 7.1076144564399995, "today": 1.118790707358, "behaviour": 2.29043944817, "gradient": 7.47005521764, "solv": 11.901902862240002, "case": 3.163250151112, "underfit": 21.322843369319997, "luxuryhom": 7.1076144564399995, "weight": 3.16984705224, "tradeoff": 5.34183047362, "cluster": 10.1031665378, "futur": 0.619345197699, "and": 0.0048502409388972, "correspond": 1.20141456099, "home": 0.378433916197, "capabl": 1.2969341868100002, "general": 0.344857734189, "made": 0.2040645782919, "librari": 4.934049904715, "everyon": 1.8557438481400002, "download": 8.0524518957, "affect": 0.908041904384, "can": 3.896186313456, "avail": 1.094909172578, "studio": 1.5948062501700002, "counter": 1.9133763754, "onli": 0.025324268329099998, "convey": 2.50939142306, "andrew": 1.34145926585, "key": 0.82419811896, "this": 0.10980702252249999, "link": 1.5323408136899999, "advanc": 0.6930212121780001, "review": 0.7929522039210001, "data": 52.323285146399996, "questionsansw": 7.1076144564399995, "audienc": 1.4992703749399998, "method": 0.944461608841, "sinc": 0.1607363989154, "will": 0.6083596047450001, "must": 0.653383947388, "worth": 3.30130206984, "text": 2.28096401998, "solidifi": 3.4966965438, "direct": 0.200705689496, "success": 0.27765441259199997, "proceed": 1.23354840355, "busi": 2.161428511065, "cover": 0.526975319156, "extent": 4.22924062869, "page": 0.711326032411, "unsupervis": 23.375689669639996, "rare": 1.00282122403, "suggest": 0.563702610877, "own": 0.164195077421, "worthwhil": 4.45762805629, "after": 0.08196277859239999, "real": 0.824629060574, "boost": 4.429909048380001, "ahead": 1.7273626814900003, "vector": 9.76259663391, "basi": 2.652826060917, "pip": 9.82077975822, "fastai": 7.1076144564399995, "panda": 4.7167367562999996, "memor": 5.55984434546, "dataset": 100.05104676616, "function": 2.743397224782, "learner": 4.320705680430001, "bangalor": 4.48517800806, "sonnet": 4.68895719219, "hear": 1.43007066072, "well": 0.1905433149468, "done": 5.9218318819030005, "floor": 1.66054557474, "approach": 3.6511680729050005, "higher": 0.752308398995, "pranay": 7.1076144564399995, "front": 0.845095701382, "know": 5.7175181663879995, "fun": 2.5561696698099996, "calculus": 4.1313002687400004, "months\u2026": 7.1076144564399995, "multipl": 3.0327720543600005, "how": 1.4147008707900002, "test": 3.908897748412, "fair": 1.16481508131, "resources\u2026": 7.1076144564399995, "initi": 0.6002091849, "sure": 2.0086865552, "given": 0.9097674324930001, "lift": 1.8529275115400001, "interest": 0.9441435559639999, "simplest": 3.3339697356999998, "overview": 5.08013252448, "asid": 1.90191857977, "weekend": 2.17424794314, "difficulti": 2.6887086443, "purpos": 0.803869037322, "below": 6.509012735488, "similar": 0.318556092114, "definit": 1.1755733298, "need": 3.990141797862, "commit": 1.0598786410299998, "subject": 3.133721870475, "final": 0.292733863948, "algebra": 3.7245288247199992, "tune": 11.717350388299998, "point": 0.9241294361319999, "caff": 6.89997509166, "applic": 3.6948117854699998, "hidden": 6.1673640156000005, "level": 2.5173109497149997, "hyperparamet": 14.215228912879999, "have": 0.2513450398004, "long": 0.235645793878, "tensorflow": 7.1076144564399995, "reduct": 14.749834290479999, "experi": 1.252545907866, "forward": 1.29901007269, "excit": 2.28423595433, "comment": 2.23653506908, "cours": 0.765899404133, "numer": 0.606093812346, "disappoint": 2.1720343285099997, "sklearnpreprocessingonehotencod": 7.1076144564399995, "not": 0.155524130075, "elabor": 1.9543228619400002, "appreci": 2.09339584651, "aim": 2.12667707408, "till": 2.44781040813, "easi": 3.3330592702999997, "jupyt": 7.1076144564399995, "appropri": 1.4618957827399999, "though": 0.616088382158, "biggest": 1.6671967465900002, "conda": 28.430457825759998, "core": 1.53108277245, "reach": 0.40414323085000003, "gritti": 4.72380392352, "tell": 2.42472868802, "world": 0.107420248621, "minimum": 3.59336930882, "outcom": 4.02678489248, "chosen": 1.27889510877, "pytorch": 7.1076144564399995, "blog": 5.30474621118, "caseproblem": 7.1076144564399995, "softwareprogram": 7.1076144564399995, "env": 7.1076144564399995, "that": 0.11133215462992, "calcul": 5.439451977629999, "guid": 6.389167530122999, "valu": 9.055126411628, "softwar": 4.65698192666, "those": 0.17854939087299998, "explor": 1.22257937218, "stu\ufb00": 7.1076144564399995, "deriv": 3.0714485482500002, "some": 0.9101907084835, "sourc": 2.116873243004, "small": 0.307101805059, "control": 0.7699693231720001, "both": 0.1525276001679, "locat": 1.405630112016, "built": 1.38075907013, "com": 4.60365961168, "unseen": 18.544922351400004, "subset": 13.231252228199999, "supervis": 8.18592422332, "repositori": 3.8060957569699996, "use": 0.584160394632, "introduc": 1.0914275048520001, "set": 2.9154321919129997, "question": 0.790310929014, "fed": 7.5868386336, "particip": 0.7876766120659999, "from": 0.00567054168866, "targetlabel": 7.1076144564399995, "technolog": 0.956847686355, "leav": 1.015487914458, "advic": 3.9148804205400003, "acquir": 1.1332178178499999, "balanc": 1.4936444810499998, "predict": 31.26906451611, "quora": 7.1076144564399995, "spot": 6.0424720577199995, "book": 0.7211395764, "written": 0.671587369833, "theano": 7.1076144564399995, "are": 1.0018941018118, "month": 0.410770160338, "inputattributesindepend": 7.1076144564399995, "preprocess": 35.5380722822, "feedback": 9.614595263399998, "popular": 2.8740614614249997, "option": 1.39846181161, "histor": 0.516151783952, "varianc": 15.756890148039998, "root": 1.27483006252, "exclud": 3.34241757616, "said": 0.436653165815, "biasedimbalanc": 7.1076144564399995, "posit": 0.9499569558240001, "forest": 3.1766194152, "master": 3.44339807097, "column": 11.74196567628, "bunglow": 7.1076144564399995, "tend": 1.21597024462, "caltech": 10.68366094724, "remov": 1.3920976831760001, "map": 1.40434493384, "wrong": 1.70078769102, "even": 0.304777129668, "littl": 0.438213989466, "part": 0.04239531098280001, "skew": 12.80965929609, "edit": 0.6896260501610001, "hous": 3.0407248991039997, "switch": 4.81248256599, "note": 0.353817568083, "row": 3.4272746417, "rigor": 2.88359207091, "bias": 10.47937105868, "hackathon": 14.215228912879999, "through": 0.1367173837698, "requir": 0.424253510675, "last": 0.19204364461100001, "earlier": 0.624742371425, "allow": 0.24028061118900002, "nittygritti": 7.1076144564399995, "guess": 6.44102971894, "interpret": 1.1678481440000001, "tast": 2.23065708585, "main": 0.676714621764, "type": 2.121304456161, "larg": 0.17037506060600002, "scienc": 5.048617073346, "day": 1.0119522379020003, "agenda": 5.112339339619999, "base": 1.2287097205830002, "natur": 0.862612678584, "label": 4.49696498181, "fact": 0.5502899207949999, "hour": 3.260763924308, "who": 0.1218004659718, "almost": 2.14539421667, "plotwidth": 14.215228912879999, "hold": 0.503879117196, "email": 3.5113564922099996, "imbalanc": 6.340359303730001, "post": 0.8057001527009999, "here": 6.195267318590001, "ideal": 1.53809624363, "microsoft": 9.637978078589999, "were": 0.048582287362199994, "clean": 3.8542564072600003, "comput": 1.36806891594, "apart": 1.1324356512, "onlin": 4.787519271785, "spare": 2.3023331721, "evalu": 21.327682674429997, "henc": 5.05409915346, "problem": 5.122266518457, "job": 1.1798682540899998, "way": 2.575189629155, "adventur": 3.7895423751199995, "columnattribut": 7.1076144564399995, "correct": 2.59663526362, "topic": 1.6969991554100001, "dure": 0.0491209066894, "classifi": 1.6665296351499999, "tflearn": 7.1076144564399995, "check": 1.87281049562, "serious": 1.89866507815, "contribut": 0.655201578909, "where": 0.5849292487113, "categor": 5.41874765606, "love": 1.08958288195, "neuralnetworksanddeeplearningcom": 7.1076144564399995, "them": 0.2825499807279, "insight": 4.93682904374, "whi": 1.18068843047, "planact": 7.1076144564399995, "support": 0.237880610037, "target": 2.3381278992400003, "notepad": 6.6280413761800006, "relentless": 3.73502760882, "afford": 3.9166653381, "date": 0.489080896097, "pythonorg": 7.1076144564399995, "depth": 2.10936322154, "provid": 1.17106706595, "are\u2026": 7.1076144564399995, "select": 5.638437497064, "scribbl": 5.54542942886, "order": 0.22014038079300002, "there": 0.36088103632949997, "exist": 0.7633155881739999, "regular": 4.434980507082, "inform": 0.454453704662, "num": 0.0037798847447640003, "best": 0.918455865894, "setup": 3.5305264083199996, "journey": 1.68980611189, "previous": 0.356602960063, "fewhigh": 7.1076144564399995, "configur": 2.4427250357499997, "name": 0.09723316638430002, "code": 2.71203819194, "per": 1.345642048144, "high": 0.41347135962000003, "basic": 3.01310324685, "regress": 23.615949098519998, "realli": 1.5576408397, "stress": 1.71014813378, "feel": 2.2856986838599997, "typic": 0.812774319158, "hotmail": 7.1076144564399995, "pattern": 13.3282404788, "nonluxuri": 7.1076144564399995, "patternuniform": 7.1076144564399995, "major": 0.138474663439, "research": 2.654911272552, "plan": 0.857964216294, "accomplish": 1.64345675928, "over": 0.0249367214957, "area": 1.311819284488, "theoret": 6.17623538727, "past": 0.7016234157610001, "sweet": 6.977725952189999, "talk": 4.43471157796, "receiv": 0.266574424922, "act": 0.358945092473, "extens": 1.3779971589500002, "essenti": 1.07434378384, "trial": 1.3966781444299998, "attribut": 6.1418575768500006, "come": 0.5678198130600001, "activ": 0.762393206568, "matplotlib": 7.1076144564399995, "other": 0.08887273127784001, "appli": 4.990165138871999, "might": 3.0733643061360003, "known": 0.3296723223968, "prefer": 1.10581884366, "andor": 6.5370695979699995, "size": 0.9138372060609999, "imag": 1.98752421458, "fundament": 1.67322086119, "like": 1.66864291854, "implement": 3.8231382272100003, "alldiffer": 7.1076144564399995, "drop": 0.8999535106219999, "except": 0.54202451213, "process": 3.16697519415, "put": 0.505652999854, "includ": 0.037769362781, "structur": 0.7217716751350001, "travel": 0.675788018461, "choic": 1.14166497543, "rang": 0.579319213803, "time": 0.0336345565878, "discret": 2.70842820148, "anaconda": 27.0494196843, "delet": 3.09888364694, "chang": 0.332551250116, "document": 1.865094244766, "juggl": 5.1186869223, "differ": 1.698568970496, "been": 0.07093794710520002, "statist": 2.8903766141400005, "first": 0.02276186943648, "between": 0.033953681165299995, "tree": 2.8355497755, "diment": 7.1076144564399995, "stanford": 2.53369681396, "obvious": 1.86383450716, "action": 0.598043165069, "expertis": 8.99022177681, "program": 2.8151423150599997, "someth": 5.94153561365, "addingremov": 7.1076144564399995, "satisfact": 3.1534165259599996, "sort": 1.64639361896, "call": 0.2618510977952, "more": 0.06809972639999999, "algorithmslibrari": 14.215228912879999, "list": 0.619691523012, "these": 0.2861344776032, "tiwari": 6.58152136054, "learningdata": 14.215228912879999, "could": 0.7438250891600001, "car": 1.2634013667, "befor": 0.191275543759, "activatebat": 7.1076144564399995, "state": 0.233050013834, "close": 0.501333519728, "languag": 5.814772770842, "make": 0.36748828911449993, "sensibl": 3.18487979542, "search": 2.3597365081799997, "folder": 5.129269031630001, "accur": 1.75248061485, "permiss": 1.8373800586400002, "read": 2.51817804264, "packag": 6.1732753475700015, "common": 1.353303221084, "enterpris": 1.8585681389, "reduc": 2.746471100572, "deeplearningbookorg": 7.1076144564399995, "shape": 1.16420957115, "sometim": 1.614075466029, "bio": 3.7456377879300002, "avannalda": 7.1076144564399995, "exampl": 1.6347306999959998, "career": 1.0944636875799998, "dimension": 31.93912963912, "understand": 4.352343502719999, "annalda": 14.215228912879999, "import": 2.92818277066, "decis": 1.5402164433919998, "sight": 1.9167966438, "input": 2.50167533539, "pipelin": 3.47002829672, "tool": 1.60887117963, "while": 0.12974995138140002, "densiti": 1.9942374574000001, "write": 1.443024879754, "learn": 75.84768582705, "recordsdata": 7.1076144564399995, "same": 0.112059649604, "mention": 0.931747186336}, "logidf": {"hand": 0.479471335336, "art": 0.6928952596619999, "easier": 2.05923883436, "shouldn": 7.1076144564399995, "heavi": 1.0602422774, "visual": 1.6539383488600001, "kind": 0.948031302717, "addit": 0.220218882972, "dirti": 2.90407060225, "june": 0.3605697882, "nois": 2.45879550578, "audio": 2.2034799289800002, "editor": 1.4657073855, "etc": 1.4366730879700003, "specif": 0.626980167541, "class": 0.7497721899330001, "happi": 1.81237875643, "lightgbm": 7.1076144564399995, "python": 4.03065674296, "thought": 0.685867118283, "onehot": 7.1076144564399995, "further": 0.308815895297, "never": 0.443205436091, "path": 1.5351679838499999, "toward": 0.48877277716000006, "their": 0.015360505122700001, "motiv": 1.61265547932, "scale": 1.32095306328, "yes": 2.65237310559, "stack": 2.97800175538, "ever": 0.6778949784020001, "fit": 1.2151206268899999, "proportion": 4.3995642553400005, "special": 0.39755992860100003, "would": 0.0796176279647, "oversampl": 7.1076144564399995, "end": 0.101476798618, "correl": 2.57915918803, "word": 0.585861082385, "deep": 1.2886734698, "depend": 0.806969815, "beginn": 3.9788316751, "open": 0.219591038029, "manipul": 2.21322491868, "encod": 3.36811501148, "improv": 0.7147958039319999, "new": 0.0177299468511, "perform": 0.42618085058, "but": 0.0161923720719, "futureunseen": 7.1076144564399995, "certain": 0.592104362781, "classif": 2.08779073629, "cost": 0.84129007618, "off": 0.41352852038800003, "fix": 1.48944573451, "overal": 1.1132694464700001, "record": 0.353010356953, "bedroom": 3.31298994523, "walk": 1.270781474, "immens": 2.54728072239, "has": 0.0427239448548, "listen": 1.94282848252, "inappropri": 3.0726933146900004, "default": 3.0511581621399997, "resourc": 1.08137694258, "thank": 1.7928938993, "out": 0.0584263909193, "mistak": 2.1648737360799997, "model": 0.7374500731110001, "format": 0.9287132518729999, "good": 0.418589404907, "alway": 0.726319204572, "concept": 0.977224437103, "number": 0.0966085784186, "optim": 2.4456277954099996, "field": 0.5760642583510001, "when": 0.0205549888584, "tri": 0.61759152916, "iisc": 7.1076144564399995, "kaggl": 7.1076144564399995, "down": 0.306673741186, "altern": 0.760359972282, "logist": 2.6461370052, "do\u2026": 7.1076144564399995, "quick": 0.790727508899, "pleas": 2.21149829955, "persist": 1.9150850473199998, "metric": 3.1016808515599994, "handl": 1.36683266903, "phase\u2026": 7.1076144564399995, "contempl": 2.90752483712, "then": 0.08303386523089999, "separ": 0.470759772949, "they": 0.0297269947676, "convex": 4.64212589251, "bit": 2.12032652634, "instal": 1.3316305879, "effect": 0.333830227158, "techniqu": 1.31624384807, "voraci": 5.04759100062, "featur": 0.423387418142, "feed": 2.05136865109, "practic": 0.533182530867, "alreadi": 0.670478380747, "algorithm": 3.33044239518, "theori": 1.10772396902, "venv": 7.1076144564399995, "spatial": 3.1955914510100003, "either": 0.459327638815, "develop": 0.178624694913, "conceptstechniqu": 7.1076144564399995, "such": 0.059695977806, "accuraci": 2.5464765406, "rome": 1.88933979757, "via": 0.831983625414, "without": 0.258874517941, "lot": 1.4835969502500002, "suitabl": 1.83067788492, "should": 0.509419876758, "invest": 1.42586787018, "india": 1.36707979618, "miss": 1.2631785751200002, "helper": 4.37424644735, "ani": 0.125608358366, "two": 0.0136988443582, "virtual": 1.4141413514399999, "work": 0.109034567273, "detail": 0.816187777173, "newunseen": 7.1076144564399995, "depart": 0.68887313257, "partial": 1.28456856096, "idea": 0.73863592212, "environ": 1.2341974030299998, "for": 0.00031499039539700004, "difficult": 0.912110767588, "worknew": 7.1076144564399995, "output": 2.03822657827, "with": 0.00119749171339, "inher": 2.37682874115, "nativ": 1.10107184908, "effort": 0.637887211057, "numpi": 7.1076144564399995, "veri": 0.230159793238, "extract": 2.04161723301, "intern": 0.265095377816, "think": 1.06717661175, "want": 0.6916366062549999, "negat": 1.32402598852, "combin": 0.529218310751, "later": 0.0829654259878, "focus": 0.6981989720559999, "again": 0.411340231612, "group": 0.190594534797, "park": 0.9015038985299999, "convers": 1.2085604509999999, "hackerearth": 7.1076144564399995, "give": 0.311392552224, "valid": 1.8889232176800002, "scope": 2.33692983198, "train": 0.660918312839, "great": 0.235805258079, "step": 1.03954505698, "total": 0.43567888670500005, "stick": 2.4456277954099996, "big": 1.00798563557, "fals": 1.8271477773099998, "reinforc": 1.86464718498, "probabl": 0.972882412913, "machin": 1.39235958062, "into": 0.0149128632287, "paper": 0.979402539665, "themselv": 0.7225497843690001, "abov": 0.643865229816, "what": 0.225887296827, "various": 0.28692650007, "knearestneighbor": 7.1076144564399995, "overfit": 7.1076144564399995, "help": 0.336207721344, "believ": 0.497746997996, "find": 0.547781330288, "curios": 3.5722448618800002, "drown": 2.9320444543, "creat": 0.222576818514, "relat": 0.21310030165399999, "decid": 0.655322871893, "wrt": 7.1076144564399995, "incomplet": 2.70089520918, "speed": 1.3533338752700002, "infer": 3.0511581621399997, "paramet": 2.8481901438599997, "script": 2.1161358444599996, "togeth": 0.458032237308, "contain": 0.468845318236, "di\ufb00er": 7.1076144564399995, "about": 0.0628434774746, "scikitlearn": 7.1076144564399995, "wrote": 0.744188554049, "thing": 0.8781935346799999, "just": 0.289531434109, "xgboost": 7.1076144564399995, "price": 1.24814402264, "repost": 6.83935046985, "person": 0.34018281601800004, "earliest": 1.2807071138, "expens": 1.26563201674, "recommend": 1.36461126863, "ensembl": 2.81820931165, "neat": 3.9392225370099996, "complex": 0.8502416364309999, "let": 1.2488025672799998, "spent": 1.10126129684, "start": 0.236443369291, "featurescolumn": 7.1076144564399995, "abhijit": 7.1076144564399995, "run": 0.442714975539, "studi": 0.426470272221, "keep": 0.7141523446729999, "explain": 0.955700427358, "singl": 0.475916769059, "guerrilla": 2.9718327043599997, "usual": 0.545279017064, "abl": 0.599303982475, "diari": 2.45145871572, "mani": 0.0433157581221, "coursera": 7.1076144564399995, "the": 0.0, "goal": 1.18830712273, "generat": 0.719182341736, "build": 0.491137452091, "error": 1.7985854343, "linear": 2.63027764196, "underfittinghigh": 7.1076144564399995, "imp": 5.08759633523, "unbalanc": 4.64212589251, "exact": 1.2437647732500001, "command": 0.9809132407500001, "went": 0.593243704365, "assess": 1.65690619935, "say": 0.562154280552, "origin": 0.128612437587, "right": 0.34035985417, "introductori": 3.41107212958, "knowledg": 1.2232212893899999, "take": 0.130691962197, "environmentnam": 7.1076144564399995, "follow": 0.045356911094199995, "catboost": 7.1076144564399995, "strategi": 1.49112311818, "discov": 0.924894023806, "goe": 1.4473284897999998, "medianmean": 7.1076144564399995, "thoughtheard": 7.1076144564399995, "also": 0.0146571578, "dealt": 2.42263827718, "specifi": 1.93451151621, "modern": 0.426566764719, "mean": 0.37092128352, "nitti": 6.305267983919999, "task": 1.35748680661, "each": 0.173741689304, "targetlabelsdepend": 7.1076144564399995, "scenario": 2.73427932989, "may": 0.050709995284400004, "consid": 0.214894723824, "podcast": 3.9042428181099997, "ground": 0.681125998984, "convert": 1.1860360368, "share": 0.618760299747, "still": 0.17112222142900002, "which": 0.00517841384543, "skill": 1.30805571015, "ident": 1.03244527565, "variabl": 2.1687230672, "one": 0.0062553516455, "terminolog": 2.87350795184, "hope": 0.919824304455, "pathtoenvfold": 7.1076144564399995, "synthet": 3.0618677691900005, "see": 0.240921585492, "hyperplan": 6.7821920560099995, "explict": 7.1076144564399995, "prioriti": 2.1544996326700003, "outlier": 5.59502637, "get": 0.579769005782, "random": 1.9727214065099998, "myself": 2.67771382807, "manag": 0.497643387158, "dot": 2.93797215393, "cross": 0.846416414759, "agent": 1.4489366381, "transform": 1.22966322707, "opinion": 1.33617333331, "repeat": 1.0567930591299999, "everi": 0.391485427421, "kera": 6.72812483474, "pick": 1.59729226761, "road": 0.915566630279, "metamodel": 7.1076144564399995, "decent": 3.5722448618800002, "finit": 3.33928418576, "engin": 0.904767558276, "back": 0.23166743089699998, "plotlength": 7.1076144564399995, "recognit": 1.4816549327200002, "permut": 4.62913869698, "most": 0.020747896295599998, "fail": 0.656536611573, "all": 0.011402632097799998, "top": 0.609100637788, "costerror": 7.1076144564399995, "today": 0.559395353679, "behaviour": 2.29043944817, "gradient": 3.73502760882, "solv": 1.9836504770400003, "case": 0.395406268889, "underfit": 7.1076144564399995, "luxuryhom": 7.1076144564399995, "weight": 1.58492352612, "tradeoff": 5.34183047362, "cluster": 2.52579163445, "futur": 0.619345197699, "and": 6.29901420636e-05, "correspond": 1.20141456099, "home": 0.378433916197, "capabl": 1.2969341868100002, "general": 0.114952578063, "made": 0.0680215260973, "librari": 0.986809980943, "everyon": 1.8557438481400002, "download": 2.6841506319, "affect": 0.908041904384, "can": 0.162341096394, "avail": 0.547454586289, "studio": 1.5948062501700002, "counter": 1.9133763754, "onli": 0.025324268329099998, "convey": 2.50939142306, "andrew": 1.34145926585, "key": 0.82419811896, "this": 0.0037864490525, "link": 0.7661704068449999, "advanc": 0.6930212121780001, "review": 0.7929522039210001, "data": 1.2168205848, "questionsansw": 7.1076144564399995, "audienc": 1.4992703749399998, "method": 0.944461608841, "sinc": 0.0803681994577, "will": 0.202786534915, "must": 0.653383947388, "worth": 1.65065103492, "text": 1.14048200999, "solidifi": 3.4966965438, "direct": 0.200705689496, "success": 0.27765441259199997, "proceed": 1.23354840355, "busi": 0.720476170355, "cover": 0.526975319156, "extent": 1.40974687623, "page": 0.711326032411, "unsupervis": 5.843922417409999, "rare": 1.00282122403, "suggest": 0.563702610877, "own": 0.164195077421, "worthwhil": 4.45762805629, "after": 0.020490694648099998, "real": 0.824629060574, "boost": 2.2149545241900004, "ahead": 1.7273626814900003, "vector": 3.25419887797, "basi": 0.884275353639, "pip": 4.91038987911, "fastai": 7.1076144564399995, "panda": 4.7167367562999996, "memor": 2.77992217273, "dataset": 5.26584456664, "function": 0.914465741594, "learner": 4.320705680430001, "bangalor": 4.48517800806, "sonnet": 4.68895719219, "hear": 1.43007066072, "well": 0.0635144383156, "done": 0.845975983129, "floor": 1.66054557474, "approach": 0.7302336145810001, "higher": 0.752308398995, "pranay": 7.1076144564399995, "front": 0.845095701382, "know": 0.952919694398, "fun": 2.5561696698099996, "calculus": 4.1313002687400004, "months\u2026": 7.1076144564399995, "multipl": 1.01092401812, "how": 0.47156695693000006, "test": 0.977224437103, "fair": 1.16481508131, "resources\u2026": 7.1076144564399995, "initi": 0.30010459245, "sure": 2.0086865552, "given": 0.303255810831, "lift": 1.8529275115400001, "interest": 0.47207177798199995, "simplest": 3.3339697356999998, "overview": 2.54006626224, "asid": 1.90191857977, "weekend": 2.17424794314, "difficulti": 1.34435432215, "purpos": 0.803869037322, "below": 0.813626591936, "similar": 0.318556092114, "definit": 1.1755733298, "need": 0.362740163442, "commit": 1.0598786410299998, "subject": 0.6267443740950001, "final": 0.292733863948, "algebra": 3.7245288247199992, "tune": 2.3434700776599997, "point": 0.23103235903299998, "caff": 6.89997509166, "applic": 1.23160392849, "hidden": 2.0557880052, "level": 0.503462189943, "hyperparamet": 7.1076144564399995, "have": 0.0147850023412, "long": 0.235645793878, "tensorflow": 7.1076144564399995, "reduct": 1.8437292863099999, "experi": 0.626272953933, "forward": 1.29901007269, "excit": 2.28423595433, "comment": 1.11826753454, "cours": 0.765899404133, "numer": 0.606093812346, "disappoint": 2.1720343285099997, "sklearnpreprocessingonehotencod": 7.1076144564399995, "not": 0.0155524130075, "elabor": 1.9543228619400002, "appreci": 2.09339584651, "aim": 1.06333853704, "till": 2.44781040813, "easi": 1.6665296351499999, "jupyt": 7.1076144564399995, "appropri": 1.4618957827399999, "though": 0.308044191079, "biggest": 1.6671967465900002, "conda": 7.1076144564399995, "core": 1.53108277245, "reach": 0.40414323085000003, "gritti": 4.72380392352, "tell": 1.21236434401, "world": 0.107420248621, "minimum": 1.79668465441, "outcom": 2.01339244624, "chosen": 1.27889510877, "pytorch": 7.1076144564399995, "blog": 2.65237310559, "caseproblem": 7.1076144564399995, "softwareprogram": 7.1076144564399995, "env": 7.1076144564399995, "that": 0.00397614837964, "calcul": 1.8131506592099997, "guid": 0.912738218589, "valu": 0.823193310148, "softwar": 2.32849096333, "those": 0.17854939087299998, "explor": 1.22257937218, "stu\ufb00": 7.1076144564399995, "deriv": 1.02381618275, "some": 0.0395735090645, "sourc": 0.529218310751, "small": 0.307101805059, "control": 0.38498466158600003, "both": 0.050842533389300004, "locat": 0.46854337067199997, "built": 0.690379535065, "com": 4.60365961168, "unseen": 3.708984470280001, "subset": 3.3078130570499997, "supervis": 2.04648105583, "repositori": 3.8060957569699996, "use": 0.0292080197316, "introduc": 0.5457137524260001, "set": 0.171496011289, "question": 0.790310929014, "fed": 2.5289462112, "particip": 0.7876766120659999, "from": 0.000567054168866, "targetlabel": 7.1076144564399995, "technolog": 0.956847686355, "leav": 0.507743957229, "advic": 1.9574402102700001, "acquir": 1.1332178178499999, "balanc": 1.4936444810499998, "predict": 1.6457402376899999, "quora": 7.1076144564399995, "spot": 1.5106180144299999, "book": 0.3605697882, "written": 0.671587369833, "theano": 7.1076144564399995, "are": 0.0294674735827, "month": 0.410770160338, "inputattributesindepend": 7.1076144564399995, "preprocess": 7.1076144564399995, "feedback": 3.2048650877999996, "popular": 0.41058020877499996, "option": 1.39846181161, "histor": 0.516151783952, "varianc": 3.9392225370099996, "root": 1.27483006252, "exclud": 1.67120878808, "said": 0.436653165815, "biasedimbalanc": 7.1076144564399995, "posit": 0.316652318608, "forest": 1.5883097076, "master": 1.14779935699, "column": 1.95699427938, "bunglow": 7.1076144564399995, "tend": 1.21597024462, "caltech": 5.34183047362, "remov": 0.6960488415880001, "map": 1.40434493384, "wrong": 1.70078769102, "even": 0.152388564834, "littl": 0.438213989466, "part": 0.04239531098280001, "skew": 4.26988643203, "edit": 0.6896260501610001, "hous": 0.38009061238799996, "switch": 1.60416085533, "note": 0.353817568083, "row": 1.71363732085, "rigor": 2.88359207091, "bias": 2.61984276467, "hackathon": 7.1076144564399995, "through": 0.0683586918849, "requir": 0.424253510675, "last": 0.19204364461100001, "earlier": 0.624742371425, "allow": 0.24028061118900002, "nittygritti": 7.1076144564399995, "guess": 3.22051485947, "interpret": 1.1678481440000001, "tast": 2.23065708585, "main": 0.225571540588, "type": 0.707101485387, "larg": 0.17037506060600002, "scienc": 0.841436178891, "day": 0.16865870631700003, "agenda": 2.5561696698099996, "base": 0.13652330228700002, "natur": 0.431306339292, "label": 1.49898832727, "fact": 0.5502899207949999, "hour": 0.815190981077, "who": 0.0609002329859, "almost": 0.42907884333400004, "plotwidth": 7.1076144564399995, "hold": 0.503879117196, "email": 3.5113564922099996, "imbalanc": 6.340359303730001, "post": 0.8057001527009999, "here": 0.8850381883700001, "ideal": 1.53809624363, "microsoft": 3.21265935953, "were": 0.024291143681099997, "clean": 1.9271282036300001, "comput": 1.36806891594, "apart": 1.1324356512, "onlin": 0.957503854357, "spare": 2.3023331721, "evalu": 1.9388802431299998, "henc": 1.68469971782, "problem": 0.569140724273, "job": 1.1798682540899998, "way": 0.19809150993500002, "adventur": 1.8947711875599997, "columnattribut": 7.1076144564399995, "correct": 1.29831763181, "topic": 1.6969991554100001, "dure": 0.0491209066894, "classifi": 1.6665296351499999, "tflearn": 7.1076144564399995, "check": 1.87281049562, "serious": 0.949332539075, "contribut": 0.655201578909, "where": 0.0649921387457, "categor": 2.70937382803, "love": 1.08958288195, "neuralnetworksanddeeplearningcom": 7.1076144564399995, "them": 0.0941833269093, "insight": 2.46841452187, "whi": 1.18068843047, "planact": 7.1076144564399995, "support": 0.237880610037, "target": 1.1690639496200002, "notepad": 6.6280413761800006, "relentless": 3.73502760882, "afford": 1.95833266905, "date": 0.489080896097, "pythonorg": 7.1076144564399995, "depth": 2.10936322154, "provid": 0.19517784432500002, "are\u2026": 7.1076144564399995, "select": 0.704804687133, "scribbl": 5.54542942886, "order": 0.22014038079300002, "there": 0.0400978929255, "exist": 0.38165779408699996, "regular": 0.739163417847, "inform": 0.454453704662, "num": 0.00031499039539700004, "best": 0.459227932947, "setup": 3.5305264083199996, "journey": 1.68980611189, "previous": 0.356602960063, "fewhigh": 7.1076144564399995, "configur": 2.4427250357499997, "name": 0.09723316638430002, "code": 1.35601909597, "per": 0.672821024072, "high": 0.13782378654000002, "basic": 1.00436774895, "regress": 3.9359915164199997, "realli": 1.5576408397, "stress": 1.71014813378, "feel": 1.1428493419299999, "typic": 0.812774319158, "hotmail": 7.1076144564399995, "pattern": 1.33282404788, "nonluxuri": 7.1076144564399995, "patternuniform": 7.1076144564399995, "major": 0.138474663439, "research": 0.663727818138, "plan": 0.428982108147, "accomplish": 1.64345675928, "over": 0.0249367214957, "area": 0.327954821122, "theoret": 2.05874512909, "past": 0.7016234157610001, "sweet": 2.3259086507299997, "talk": 1.10867789449, "receiv": 0.266574424922, "act": 0.358945092473, "extens": 0.6889985794750001, "essenti": 1.07434378384, "trial": 1.3966781444299998, "attribut": 1.2283715153700001, "come": 0.28390990653000003, "activ": 0.381196603284, "matplotlib": 7.1076144564399995, "other": 0.00987474791976, "appli": 0.8316941898119999, "might": 0.7683410765340001, "known": 0.0824180805992, "prefer": 1.10581884366, "andor": 6.5370695979699995, "size": 0.9138372060609999, "imag": 0.99376210729, "fundament": 1.67322086119, "like": 0.139053576545, "implement": 1.27437940907, "alldiffer": 7.1076144564399995, "drop": 0.8999535106219999, "except": 0.54202451213, "process": 0.527829199025, "put": 0.505652999854, "includ": 0.0188846813905, "structur": 0.7217716751350001, "travel": 0.675788018461, "choic": 1.14166497543, "rang": 0.579319213803, "time": 0.0112115188626, "discret": 2.70842820148, "anaconda": 5.40988393686, "delet": 3.09888364694, "chang": 0.166275625058, "document": 0.932547122383, "juggl": 5.1186869223, "differ": 0.212321121312, "been": 0.023645982368400004, "statist": 1.4451883070700002, "first": 0.0075872898121599995, "between": 0.033953681165299995, "tree": 1.41777488775, "diment": 7.1076144564399995, "stanford": 2.53369681396, "obvious": 1.86383450716, "action": 0.598043165069, "expertis": 2.99674059227, "program": 0.7037855787649999, "someth": 1.18830712273, "addingremov": 7.1076144564399995, "satisfact": 3.1534165259599996, "sort": 1.64639361896, "call": 0.0654627744488, "more": 0.017024931599999998, "algorithmslibrari": 7.1076144564399995, "list": 0.309845761506, "these": 0.0715336194008, "tiwari": 6.58152136054, "learningdata": 7.1076144564399995, "could": 0.18595627229000003, "car": 1.2634013667, "befor": 0.0956377718795, "activatebat": 7.1076144564399995, "state": 0.0466100027668, "close": 0.250666759864, "languag": 0.8306818244059999, "make": 0.07349765782289999, "sensibl": 3.18487979542, "search": 1.1798682540899998, "folder": 5.129269031630001, "accur": 1.75248061485, "permiss": 1.8373800586400002, "read": 0.83939268088, "packag": 2.0577584491900005, "common": 0.338325805271, "enterpris": 1.8585681389, "reduc": 0.686617775143, "deeplearningbookorg": 7.1076144564399995, "shape": 1.16420957115, "sometim": 0.538025155343, "bio": 3.7456377879300002, "avannalda": 7.1076144564399995, "exampl": 0.40868267499899996, "career": 1.0944636875799998, "dimension": 3.99239120489, "understand": 1.0880858756799998, "annalda": 7.1076144564399995, "import": 0.292818277066, "decis": 0.7701082216959999, "sight": 1.9167966438, "input": 2.50167533539, "pipelin": 3.47002829672, "tool": 1.60887117963, "while": 0.04324998379380001, "densiti": 1.9942374574000001, "write": 0.721512439877, "learn": 0.842752064745, "recordsdata": 7.1076144564399995, "same": 0.112059649604, "mention": 0.931747186336}, "freq": {"hand": 4, "art": 1, "easier": 1, "shouldn": 1, "heavi": 1, "visual": 2, "kind": 1, "addit": 1, "dirti": 1, "june": 1, "nois": 1, "audio": 1, "editor": 1, "etc": 10, "specif": 1, "class": 3, "happi": 1, "lightgbm": 1, "python": 17, "thought": 4, "onehot": 1, "further": 4, "never": 2, "path": 4, "toward": 1, "their": 1, "motiv": 1, "scale": 3, "yes": 1, "stack": 1, "ever": 3, "fit": 1, "proportion": 1, "special": 2, "would": 2, "oversampl": 1, "end": 4, "correl": 1, "word": 2, "deep": 7, "depend": 1, "beginn": 1, "open": 1, "manipul": 1, "encod": 3, "improv": 4, "new": 6, "perform": 1, "but": 5, "futureunseen": 1, "certain": 1, "classif": 2, "cost": 2, "off": 1, "fix": 2, "overal": 1, "record": 1, "bedroom": 3, "walk": 1, "immens": 1, "has": 11, "listen": 1, "inappropri": 1, "default": 3, "resourc": 1, "thank": 3, "out": 4, "mistak": 1, "model": 20, "format": 1, "good": 2, "alway": 3, "concept": 6, "number": 2, "optim": 3, "field": 1, "when": 7, "tri": 4, "iisc": 1, "kaggl": 1, "down": 1, "altern": 1, "logist": 2, "do\u2026": 1, "quick": 2, "pleas": 3, "persist": 1, "metric": 7, "handl": 1, "phase\u2026": 1, "contempl": 1, "then": 1, "separ": 1, "they": 3, "convex": 1, "bit": 1, "instal": 5, "effect": 2, "techniqu": 3, "voraci": 1, "featur": 28, "feed": 1, "practic": 5, "alreadi": 2, "algorithm": 20, "theori": 2, "venv": 2, "spatial": 1, "either": 1, "develop": 1, "conceptstechniqu": 1, "such": 4, "accuraci": 3, "rome": 1, "via": 1, "without": 3, "lot": 8, "suitabl": 1, "should": 6, "invest": 1, "india": 1, "miss": 3, "helper": 1, "ani": 4, "two": 2, "virtual": 6, "work": 2, "detail": 4, "newunseen": 1, "depart": 1, "partial": 1, "idea": 1, "environ": 18, "for": 30, "difficult": 2, "worknew": 1, "output": 1, "with": 22, "inher": 1, "nativ": 3, "effort": 2, "numpi": 1, "veri": 5, "extract": 1, "intern": 2, "think": 6, "want": 4, "negat": 3, "combin": 2, "later": 2, "focus": 1, "again": 2, "group": 2, "park": 1, "convers": 1, "hackerearth": 1, "give": 2, "valid": 6, "scope": 1, "train": 27, "great": 3, "step": 3, "total": 1, "stick": 1, "big": 2, "fals": 2, "reinforc": 3, "probabl": 1, "machin": 52, "into": 5, "paper": 1, "themselv": 1, "abov": 3, "what": 8, "various": 2, "knearestneighbor": 1, "overfit": 6, "help": 8, "believ": 1, "find": 12, "curios": 1, "drown": 1, "creat": 4, "relat": 1, "decid": 1, "wrt": 2, "incomplet": 1, "speed": 1, "infer": 1, "paramet": 12, "script": 1, "togeth": 2, "contain": 1, "di\ufb00er": 1, "about": 11, "scikitlearn": 6, "wrote": 1, "thing": 5, "just": 6, "xgboost": 1, "price": 8, "repost": 1, "person": 1, "earliest": 1, "expens": 1, "recommend": 1, "ensembl": 1, "neat": 1, "complex": 1, "let": 1, "spent": 1, "start": 11, "featurescolumn": 1, "abhijit": 2, "run": 1, "studi": 1, "keep": 3, "explain": 3, "singl": 1, "guerrilla": 1, "usual": 8, "abl": 2, "diari": 1, "mani": 2, "coursera": 5, "the": 114, "goal": 3, "generat": 1, "build": 2, "error": 8, "linear": 5, "underfittinghigh": 1, "imp": 1, "unbalanc": 1, "exact": 3, "command": 1, "went": 1, "assess": 1, "say": 3, "origin": 2, "right": 2, "introductori": 1, "knowledg": 1, "take": 1, "environmentnam": 3, "follow": 1, "catboost": 1, "strategi": 1, "discov": 1, "goe": 1, "medianmean": 1, "thoughtheard": 1, "also": 5, "dealt": 4, "specifi": 2, "modern": 1, "mean": 1, "nitti": 1, "task": 4, "each": 1, "targetlabelsdepend": 1, "scenario": 1, "may": 3, "consid": 3, "podcast": 1, "ground": 1, "convert": 1, "share": 2, "still": 3, "which": 7, "skill": 1, "ident": 1, "variabl": 3, "one": 9, "terminolog": 1, "hope": 1, "pathtoenvfold": 1, "synthet": 1, "see": 2, "hyperplan": 1, "explict": 1, "prioriti": 1, "outlier": 2, "get": 10, "random": 3, "myself": 1, "manag": 4, "dot": 1, "cross": 5, "agent": 7, "transform": 3, "opinion": 1, "repeat": 1, "everi": 4, "kera": 1, "pick": 2, "road": 1, "metamodel": 1, "decent": 1, "finit": 1, "engin": 6, "back": 2, "plotlength": 2, "recognit": 1, "permut": 1, "most": 6, "fail": 1, "all": 10, "top": 1, "costerror": 1, "today": 2, "behaviour": 1, "gradient": 2, "solv": 6, "case": 8, "underfit": 3, "luxuryhom": 1, "weight": 2, "tradeoff": 1, "cluster": 4, "futur": 1, "and": 77, "correspond": 1, "home": 1, "capabl": 1, "general": 3, "made": 3, "librari": 5, "everyon": 1, "download": 3, "affect": 1, "can": 24, "avail": 2, "studio": 1, "counter": 1, "onli": 1, "convey": 1, "andrew": 1, "key": 1, "this": 29, "link": 2, "advanc": 1, "review": 1, "data": 43, "questionsansw": 1, "audienc": 1, "method": 1, "sinc": 2, "will": 3, "must": 1, "worth": 2, "text": 2, "solidifi": 1, "direct": 1, "success": 1, "proceed": 1, "busi": 3, "cover": 1, "extent": 3, "page": 1, "unsupervis": 4, "rare": 1, "suggest": 1, "own": 1, "worthwhil": 1, "after": 4, "real": 1, "boost": 2, "ahead": 1, "vector": 3, "basi": 3, "pip": 2, "fastai": 1, "panda": 1, "memor": 2, "dataset": 19, "function": 3, "learner": 1, "bangalor": 1, "sonnet": 1, "hear": 1, "well": 3, "done": 7, "floor": 1, "approach": 5, "higher": 1, "pranay": 1, "front": 1, "know": 6, "fun": 1, "calculus": 1, "months\u2026": 1, "multipl": 3, "how": 3, "test": 4, "fair": 1, "resources\u2026": 1, "initi": 2, "sure": 1, "given": 3, "lift": 1, "interest": 2, "simplest": 1, "overview": 2, "asid": 1, "weekend": 1, "difficulti": 2, "purpos": 1, "below": 8, "similar": 1, "definit": 1, "need": 11, "commit": 1, "subject": 5, "final": 1, "algebra": 1, "tune": 5, "point": 4, "caff": 1, "applic": 3, "hidden": 3, "level": 5, "hyperparamet": 2, "have": 17, "long": 1, "tensorflow": 1, "reduct": 8, "experi": 2, "forward": 1, "excit": 1, "comment": 2, "cours": 1, "numer": 1, "disappoint": 1, "sklearnpreprocessingonehotencod": 1, "not": 10, "elabor": 1, "appreci": 1, "aim": 2, "till": 1, "easi": 2, "jupyt": 1, "appropri": 1, "though": 2, "biggest": 1, "conda": 4, "core": 1, "reach": 1, "gritti": 1, "tell": 2, "world": 1, "minimum": 2, "outcom": 2, "chosen": 1, "pytorch": 1, "blog": 2, "caseproblem": 1, "softwareprogram": 1, "env": 1, "that": 28, "calcul": 3, "guid": 7, "valu": 11, "softwar": 2, "those": 1, "explor": 1, "stu\ufb00": 1, "deriv": 3, "some": 23, "sourc": 4, "small": 1, "control": 2, "both": 3, "locat": 3, "built": 2, "com": 1, "unseen": 5, "subset": 4, "supervis": 4, "repositori": 1, "use": 20, "introduc": 2, "set": 17, "question": 1, "fed": 3, "particip": 1, "from": 10, "targetlabel": 1, "technolog": 1, "leav": 2, "advic": 2, "acquir": 1, "balanc": 1, "predict": 19, "quora": 1, "spot": 4, "book": 2, "written": 1, "theano": 1, "are": 34, "month": 1, "inputattributesindepend": 1, "preprocess": 5, "feedback": 3, "popular": 7, "option": 1, "histor": 1, "varianc": 4, "root": 1, "exclud": 2, "said": 1, "biasedimbalanc": 1, "posit": 3, "forest": 2, "master": 3, "column": 6, "bunglow": 1, "tend": 1, "caltech": 2, "remov": 2, "map": 1, "wrong": 1, "even": 2, "littl": 1, "part": 1, "skew": 3, "edit": 1, "hous": 8, "switch": 3, "note": 1, "row": 2, "rigor": 1, "bias": 4, "hackathon": 2, "through": 2, "requir": 1, "last": 1, "earlier": 1, "allow": 1, "nittygritti": 1, "guess": 2, "interpret": 1, "tast": 1, "main": 3, "type": 3, "larg": 1, "scienc": 6, "day": 6, "agenda": 2, "base": 9, "natur": 2, "label": 3, "fact": 1, "hour": 4, "who": 2, "almost": 5, "plotwidth": 2, "hold": 1, "email": 1, "imbalanc": 1, "post": 1, "here": 7, "ideal": 1, "microsoft": 3, "were": 2, "clean": 2, "comput": 1, "apart": 1, "onlin": 5, "spare": 1, "evalu": 11, "henc": 3, "problem": 9, "job": 1, "way": 13, "adventur": 2, "columnattribut": 1, "correct": 2, "topic": 1, "dure": 1, "classifi": 1, "tflearn": 1, "check": 1, "serious": 2, "contribut": 1, "where": 9, "categor": 2, "love": 1, "neuralnetworksanddeeplearningcom": 1, "them": 3, "insight": 2, "whi": 1, "planact": 1, "support": 1, "target": 2, "notepad": 1, "relentless": 1, "afford": 2, "date": 1, "pythonorg": 1, "depth": 1, "provid": 6, "are\u2026": 1, "select": 8, "scribbl": 1, "order": 1, "there": 9, "exist": 2, "regular": 6, "inform": 1, "num": 12, "best": 2, "setup": 1, "journey": 1, "previous": 1, "fewhigh": 1, "configur": 1, "name": 1, "code": 2, "per": 2, "high": 3, "basic": 3, "regress": 6, "realli": 1, "stress": 1, "feel": 2, "typic": 1, "hotmail": 1, "pattern": 10, "nonluxuri": 1, "patternuniform": 1, "major": 1, "research": 4, "plan": 2, "accomplish": 1, "over": 1, "area": 4, "theoret": 3, "past": 1, "sweet": 3, "talk": 4, "receiv": 1, "act": 1, "extens": 2, "essenti": 1, "trial": 1, "attribut": 5, "come": 2, "activ": 2, "matplotlib": 1, "other": 9, "appli": 6, "might": 4, "known": 4, "prefer": 1, "andor": 1, "size": 1, "imag": 2, "fundament": 1, "like": 12, "implement": 3, "alldiffer": 1, "drop": 1, "except": 1, "process": 6, "put": 1, "includ": 2, "structur": 1, "travel": 1, "choic": 1, "rang": 1, "time": 3, "discret": 1, "anaconda": 5, "delet": 1, "chang": 2, "document": 2, "juggl": 1, "differ": 8, "been": 3, "statist": 2, "first": 3, "between": 1, "tree": 2, "diment": 1, "stanford": 1, "obvious": 1, "action": 1, "expertis": 3, "program": 4, "someth": 5, "addingremov": 1, "satisfact": 1, "sort": 1, "call": 4, "more": 4, "algorithmslibrari": 2, "list": 2, "these": 4, "tiwari": 1, "learningdata": 2, "could": 4, "car": 1, "befor": 2, "activatebat": 1, "state": 5, "close": 2, "languag": 7, "make": 5, "sensibl": 1, "search": 2, "folder": 1, "accur": 1, "permiss": 1, "read": 3, "packag": 3, "common": 4, "enterpris": 1, "reduc": 4, "deeplearningbookorg": 1, "shape": 1, "sometim": 3, "bio": 1, "avannalda": 1, "exampl": 4, "career": 1, "dimension": 8, "understand": 4, "annalda": 2, "import": 10, "decis": 2, "sight": 1, "input": 1, "pipelin": 1, "tool": 1, "while": 3, "densiti": 1, "write": 2, "learn": 90, "recordsdata": 1, "same": 1, "mention": 1}, "idf": {"hand": 1.6152202665600002, "art": 1.9994962216599999, "easier": 7.84, "shouldn": 1221.23076923, "heavi": 2.88707037643, "visual": 5.22752716497, "kind": 2.5806241872599998, "addit": 1.24634950542, "dirti": 18.2482758621, "june": 1.43414634146, "nois": 11.6907216495, "audio": 9.05647461495, "editor": 4.33060556465, "etc": 4.2066772655, "specif": 1.8719490626099997, "class": 2.11651779763, "happi": 6.125, "lightgbm": 1221.23076923, "python": 56.2978723404, "thought": 1.9854927463699998, "onehot": 1221.23076923, "further": 1.3618116315, "never": 1.55769230769, "path": 4.6421052631599995, "toward": 1.6303142329, "their": 1.01547908405, "motiv": 5.01611374408, "scale": 3.7469907953699995, "yes": 14.1876675603, "stack": 19.6485148515, "ever": 1.9697270471500001, "fit": 3.37070063694, "proportion": 81.4153846154, "special": 1.4881889763799998, "would": 1.0828729281799998, "oversampl": 1221.23076923, "end": 1.10680423871, "correl": 13.1860465116, "word": 1.7965372864099998, "deep": 3.6279707495399998, "depend": 2.2411067193700003, "beginn": 53.4545454545, "open": 1.24556723678, "manipul": 9.145161290319999, "encod": 29.0237659963, "improv": 2.04376930999, "new": 1.0178880554, "perform": 1.5313977042500002, "but": 1.01632417899, "futureunseen": 1221.23076923, "certain": 1.8077886586200003, "classif": 8.067073170730001, "cost": 2.31935719503, "off": 1.5121440137200002, "fix": 4.4346368715099995, "overal": 3.0442953020099996, "record": 1.42334588488, "bedroom": 27.4671280277, "walk": 3.56363636364, "immens": 12.7723250201, "has": 1.0436497502, "listen": 6.97846153846, "inappropri": 21.6, "default": 21.1398135819, "resourc": 2.9487369985100003, "thank": 6.00681044268, "out": 1.06016694491, "mistak": 8.71350164654, "model": 2.0905978404, "format": 2.53125, "good": 1.51981619759, "alway": 2.06745670009, "concept": 2.65707112971, "number": 1.10142916609, "optim": 11.5377906977, "field": 1.7790228597, "when": 1.02076769755, "tri": 1.8544562551099997, "iisc": 1221.23076923, "kaggl": 1221.23076923, "down": 1.35889754344, "altern": 2.1390460792200003, "logist": 14.0994671403, "do\u2026": 1221.23076923, "quick": 2.205, "pleas": 9.12938470385, "persist": 6.787516032490001, "metric": 22.235294117600002, "handl": 3.9229058561900003, "phase\u2026": 1221.23076923, "contempl": 18.3114186851, "then": 1.08657860516, "separ": 1.6012102874399998, "they": 1.03017325287, "convex": 103.764705882, "bit": 8.33385826772, "instal": 3.78721374046, "effect": 1.3963060686000002, "techniqu": 3.7293868921800004, "voraci": 155.647058824, "featur": 1.52712581762, "feed": 7.77853993141, "practic": 1.70434782609, "alreadi": 1.9551724137900002, "algorithm": 27.9507042254, "theori": 3.02745995423, "venv": 1221.23076923, "spatial": 24.4246153846, "either": 1.5830092731099998, "develop": 1.1955719557200002, "conceptstechniqu": 1221.23076923, "such": 1.06151377374, "accuraci": 12.7620578778, "rome": 6.615, "via": 2.2978723404299997, "without": 1.29547123623, "lot": 4.40877534018, "suitabl": 6.23811394892, "should": 1.6643254009900001, "invest": 4.16146788991, "india": 3.92387543253, "miss": 3.53664513255, "helper": 79.38, "ani": 1.13383802314, "two": 1.01379310345, "virtual": 4.11295336788, "work": 1.11520089913, "detail": 2.26186066391, "newunseen": 1221.23076923, "depart": 1.99147014551, "partial": 3.6131087847099996, "idea": 2.0930784443, "environ": 3.43561999567, "for": 1.00031504001, "difficult": 2.48957189901, "worknew": 1221.23076923, "output": 7.676982591880001, "with": 1.0011982089899998, "inher": 10.7706919946, "nativ": 3.00738776283, "effort": 1.89247824532, "numpi": 1221.23076923, "veri": 1.25880114177, "extract": 7.703056768560001, "intern": 1.30355530011, "think": 2.90715986083, "want": 1.99698113208, "negat": 3.75852272727, "combin": 1.69760479042, "later": 1.08650424309, "focus": 2.01012914662, "again": 1.50883862384, "group": 1.20996875238, "park": 2.4633048875099997, "convers": 3.3486606201200004, "hackerearth": 1221.23076923, "give": 1.3653250774, "valid": 6.61224489796, "scope": 10.3494132986, "train": 1.9365698950999999, "great": 1.26592775696, "step": 2.8279301745599996, "total": 1.5460122699399999, "stick": 11.5377906977, "big": 2.7400759406299997, "fals": 6.21613155834, "reinforc": 6.453658536590001, "probabl": 2.64555907349, "machin": 4.02433460076, "into": 1.01502461479, "paper": 2.6628648104700003, "themselv": 2.05967825636, "abov": 1.90382539873, "what": 1.25343439128, "various": 1.3323262839899999, "knearestneighbor": 1221.23076923, "overfit": 1221.23076923, "help": 1.39962972759, "believ": 1.6450108797, "find": 1.7294117647099998, "curios": 35.5964125561, "drown": 18.7659574468, "creat": 1.2492917847, "relat": 1.23750876919, "decid": 1.9257641921400002, "wrt": 1221.23076923, "incomplet": 14.8930581614, "speed": 3.8703071672400005, "infer": 21.1398135819, "paramet": 17.256521739100002, "script": 8.299006795610001, "togeth": 1.58095996813, "contain": 1.59814777532, "di\ufb00er": 1221.23076923, "about": 1.06486015159, "scikitlearn": 1221.23076923, "wrote": 2.10473286491, "thing": 2.4065484311099996, "just": 1.33580143037, "xgboost": 1221.23076923, "price": 3.4838709677399997, "repost": 933.882352941, "person": 1.40520446097, "earliest": 3.5991838585400004, "expens": 3.5453327378300004, "recommend": 3.9142011834300003, "ensembl": 16.746835443, "neat": 51.3786407767, "complex": 2.34021226415, "let": 3.48616600791, "spent": 3.00795755968, "start": 1.26673581744, "featurescolumn": 1221.23076923, "abhijit": 1221.23076923, "run": 1.55692850838, "studi": 1.53184098804, "keep": 2.04245465071, "explain": 2.60049140049, "singl": 1.60948905109, "guerrilla": 19.5276752768, "usual": 1.72508964468, "abl": 1.8208510150200001, "diari": 11.6052631579, "mani": 1.04426757877, "coursera": 1221.23076923, "the": 1.0, "goal": 3.28152128979, "generat": 2.05275407292, "build": 1.6341739578, "error": 6.04109589041, "linear": 13.8776223776, "underfittinghigh": 1221.23076923, "imp": 162.0, "unbalanc": 103.764705882, "exact": 3.46864758575, "command": 2.66689064337, "went": 1.8098495212, "assess": 5.24306472919, "say": 1.7544480053, "origin": 1.13724928367, "right": 1.4054532577899999, "introductori": 30.297709923699998, "knowledg": 3.3981164383599998, "take": 1.13961668222, "environmentnam": 1221.23076923, "follow": 1.04640126549, "catboost": 1221.23076923, "strategi": 4.44208170118, "discov": 2.52160101652, "goe": 4.251740760580001, "medianmean": 1221.23076923, "thoughtheard": 1221.23076923, "also": 1.01476510067, "dealt": 11.2755681818, "specifi": 6.920662598080001, "modern": 1.5319888063299998, "mean": 1.44906900329, "nitti": 547.448275862, "task": 3.88641370869, "each": 1.18974820144, "targetlabelsdepend": 1221.23076923, "scenario": 15.3986420951, "may": 1.05201775893, "consid": 1.2397313759200002, "podcast": 49.6125, "ground": 1.97610156833, "convert": 3.2740771293099997, "share": 1.8566249561500001, "still": 1.1866357724799999, "which": 1.005191845, "skill": 3.6989748369099997, "ident": 2.80792359392, "variabl": 8.747107438019999, "one": 1.00627495722, "terminolog": 17.6989966555, "hope": 2.50884955752, "pathtoenvfold": 1221.23076923, "synthet": 21.3674293405, "see": 1.27242125511, "hyperplan": 882.0, "explict": 1221.23076923, "prioriti": 8.623574144489998, "outlier": 269.084745763, "get": 1.78562591385, "random": 7.1902173913, "myself": 14.5517873511, "manag": 1.6448404475799998, "dot": 18.8775267539, "cross": 2.33127753304, "agent": 4.25858369099, "transform": 3.42007755278, "opinion": 3.8044572250199997, "repeat": 2.8771293947099994, "everi": 1.47917637194, "kera": 835.5789473680001, "pick": 4.939639079030001, "road": 2.49819040126, "metamodel": 1221.23076923, "decent": 35.5964125561, "finit": 28.1989342806, "engin": 2.47135740971, "back": 1.26070038911, "plotlength": 1221.23076923, "recognit": 4.40022172949, "permut": 102.425806452, "most": 1.02096463023, "fail": 1.9281029876099998, "all": 1.01146788991, "top": 1.8387769284200002, "costerror": 1221.23076923, "today": 1.74961428257, "behaviour": 9.879278158060002, "gradient": 41.889182058, "solv": 7.26923076923, "case": 1.48498737256, "underfit": 1221.23076923, "luxuryhom": 1221.23076923, "weight": 4.878918254459999, "tradeoff": 208.89473684200001, "cluster": 12.5007874016, "futur": 1.8577112099200002, "and": 1.00006299213, "correspond": 3.32481675393, "home": 1.4599963215, "capabl": 3.6580645161300005, "general": 1.1218202374200001, "made": 1.07038834951, "librari": 2.68266306185, "everyon": 6.3964544722, "download": 14.6457564576, "affect": 2.4794627518400003, "can": 1.17626139142, "avail": 1.7288467821, "studio": 4.9273743016800005, "counter": 6.77592829706, "onli": 1.0256476516600002, "convey": 12.297443842, "andrew": 3.82462057336, "key": 2.28005170185, "this": 1.00379362671, "link": 2.15151104486, "advanc": 1.9997480791, "review": 2.2099109131400003, "data": 3.37643555934, "questionsansw": 1221.23076923, "audienc": 4.4784203103, "method": 2.5714285714300003, "sinc": 1.08368600683, "will": 1.22481098596, "must": 1.9220338983099996, "worth": 5.210370856580001, "text": 3.12827586207, "solidifi": 33.006237006199996, "direct": 1.22226499346, "success": 1.32002993265, "proceed": 3.4333910034599997, "busi": 2.05541170378, "cover": 1.69380134429, "extent": 4.09491875161, "page": 2.03669018602, "unsupervis": 345.13043478300006, "rare": 2.7259615384599996, "suggest": 1.7571665744299998, "own": 1.17844418052, "worthwhil": 86.28260869569999, "after": 1.02070207021, "real": 2.28103448276, "boost": 9.16099249856, "ahead": 5.625797306869999, "vector": 25.898858075, "basi": 2.42122922068, "pip": 135.692307692, "fastai": 1221.23076923, "panda": 111.802816901, "memor": 16.1177664975, "dataset": 193.609756098, "function": 2.495441685, "learner": 75.2417061611, "bangalor": 88.6927374302, "sonnet": 108.739726027, "hear": 4.17899447223, "well": 1.0655748708, "done": 2.3302509907499998, "floor": 5.2621809744800006, "approach": 2.07556543339, "higher": 2.1218925421, "pranay": 1221.23076923, "front": 2.32820061593, "know": 2.59327017315, "fun": 12.8863636364, "calculus": 62.2588235294, "months\u2026": 1221.23076923, "multipl": 2.74813917258, "how": 1.60250328051, "test": 2.65707112971, "fair": 3.20533010297, "resources\u2026": 1221.23076923, "initi": 1.35, "sure": 7.453521126760001, "given": 1.35426085473, "lift": 6.37846524709, "interest": 1.60331246213, "simplest": 28.0494699647, "overview": 12.6805111821, "asid": 6.69873417722, "weekend": 8.79556786704, "difficulti": 3.8357091084800006, "purpos": 2.23416830847, "below": 2.25607503197, "similar": 1.37514075357, "definit": 3.24, "need": 1.4372623574099999, "commit": 2.8860207235, "subject": 1.8715077213299998, "final": 1.34008609775, "algebra": 41.4516971279, "tune": 10.4173228346, "point": 1.25990000794, "caff": 992.25, "applic": 3.42672134686, "hidden": 7.81299212598, "level": 1.6544393497299998, "hyperparamet": 1221.23076923, "have": 1.0148948411399998, "long": 1.2657259028899999, "tensorflow": 1221.23076923, "reduct": 6.320063694269999, "experi": 1.87062566278, "forward": 3.66566612792, "excit": 9.818181818180001, "comment": 3.05954904606, "cours": 2.15092805853, "numer": 1.83325635104, "disappoint": 8.776119402989998, "sklearnpreprocessingonehotencod": 1221.23076923, "not": 1.01567398119, "elabor": 7.0591373944, "appreci": 8.11241696474, "aim": 2.8960233491400005, "till": 11.563000728299999, "easi": 5.2937645882, "jupyt": 1221.23076923, "appropri": 4.31413043478, "though": 1.36076112111, "biggest": 5.2972972973, "conda": 1221.23076923, "core": 4.623179965059999, "reach": 1.49801849406, "gritti": 112.595744681, "tell": 3.36142282448, "world": 1.11340206186, "minimum": 6.02962400304, "outcom": 7.48867924528, "chosen": 3.59266802444, "pytorch": 1221.23076923, "blog": 14.1876675603, "caseproblem": 1221.23076923, "softwareprogram": 1221.23076923, "env": 1221.23076923, "that": 1.00398406375, "calcul": 6.12972972973, "guid": 2.49113447356, "valu": 2.2777618364400003, "softwar": 10.2624434389, "those": 1.19548192771, "explor": 3.39593582888, "stu\ufb00": 1221.23076923, "deriv": 2.78379800105, "some": 1.04036697248, "sourc": 1.69760479042, "small": 1.3594793629, "control": 1.46959178006, "both": 1.05215720061, "locat": 1.59766529134, "built": 1.99447236181, "com": 99.8490566038, "unseen": 40.8123393316, "subset": 27.3253012048, "supervis": 7.74061433447, "repositori": 44.974504249300004, "use": 1.0296387573799999, "introduc": 1.7258397651900002, "set": 1.18707940781, "question": 2.20408163265, "fed": 12.5402843602, "particip": 2.19828302409, "from": 1.00056721497, "targetlabel": 1221.23076923, "technolog": 2.6034765496900003, "leav": 1.6615384615399997, "advic": 7.08117752007, "acquir": 3.10563380282, "balanc": 4.45329593268, "predict": 5.18484650555, "quora": 1221.23076923, "spot": 4.52952924394, "book": 1.43414634146, "written": 1.9573418813999999, "theano": 1221.23076923, "are": 1.02990593578, "month": 1.5079787234, "inputattributesindepend": 1221.23076923, "preprocess": 1221.23076923, "feedback": 24.652173913000002, "popular": 1.50769230769, "option": 4.04896710023, "histor": 1.6755672823199999, "varianc": 51.3786407767, "root": 3.57809330629, "exclud": 5.31859296482, "said": 1.54751925139, "biasedimbalanc": 1221.23076923, "posit": 1.37252528746, "forest": 4.89546716004, "master": 3.15125049623, "column": 7.078020508250001, "bunglow": 1221.23076923, "tend": 3.3735656608599998, "caltech": 208.89473684200001, "remov": 2.0058117498400003, "map": 4.0728578758300005, "wrong": 5.478260869570001, "even": 1.16461267606, "littl": 1.5499365420299998, "part": 1.04330682789, "skew": 71.5135135135, "edit": 1.99297012302, "hous": 1.4624170965399999, "switch": 4.97368421053, "note": 1.42449528937, "row": 5.549108703250001, "rigor": 17.8783783784, "bias": 13.7335640138, "hackathon": 1221.23076923, "through": 1.07074930869, "requir": 1.52844902282, "last": 1.2117234010100002, "earlier": 1.86776470588, "allow": 1.2716059271100002, "nittygritti": 1221.23076923, "guess": 25.0410094637, "interpret": 3.2150668286799995, "tast": 9.305978898010002, "main": 1.25303867403, "type": 2.0281042411900003, "larg": 1.18574949585, "scienc": 2.31969608416, "day": 1.18371607516, "agenda": 12.8863636364, "base": 1.14628158845, "natur": 1.5392670157100001, "label": 4.47715736041, "fact": 1.73375559681, "hour": 2.25960717336, "who": 1.06279287723, "almost": 1.53584212054, "plotwidth": 1221.23076923, "hold": 1.6551292744, "email": 33.4936708861, "imbalanc": 567.0, "post": 2.23826307627, "here": 2.42307692308, "ideal": 4.65571847507, "microsoft": 24.8450704225, "were": 1.02458857696, "clean": 6.86975335353, "comput": 3.9277585353800006, "apart": 3.1032056294, "onlin": 2.6051854282900004, "spare": 9.997481108310001, "evalu": 6.9509632224199995, "henc": 5.390831918509999, "problem": 1.76674827509, "job": 3.2539454806299997, "way": 1.2190739461, "adventur": 6.65102639296, "columnattribut": 1221.23076923, "correct": 3.6631287494199998, "topic": 5.457545548300001, "dure": 1.0503473370799998, "classifi": 5.2937645882, "tflearn": 1221.23076923, "check": 6.50655737705, "serious": 2.583984375, "contribut": 1.9255306246200001, "where": 1.06715063521, "categor": 15.0198675497, "love": 2.97303370787, "neuralnetworksanddeeplearningcom": 1221.23076923, "them": 1.09876115994, "insight": 11.8037174721, "whi": 3.2566153846200003, "planact": 1221.23076923, "support": 1.2685577307200002, "target": 3.2189781021900004, "notepad": 756.0, "relentless": 41.889182058, "afford": 7.0875, "date": 1.63081664099, "pythonorg": 1221.23076923, "depth": 8.24299065421, "provid": 1.21552714187, "are\u2026": 1221.23076923, "select": 2.02345144022, "scribbl": 256.064516129, "order": 1.24625166811, "there": 1.04091266719, "exist": 1.4647107666799999, "regular": 2.09418282548, "inform": 1.5753125620200001, "num": 1.00031504001, "best": 1.5828514456600002, "setup": 34.1419354839, "journey": 5.41843003413, "previous": 1.42846859816, "fewhigh": 1221.23076923, "configur": 11.504347826099998, "name": 1.10211732037, "code": 3.8807137619199996, "per": 1.9597580545599997, "high": 1.14777327935, "basic": 2.7301805675, "regress": 51.2129032258, "realli": 4.7476076555, "stress": 5.52978056426, "feel": 3.1356903021900004, "typic": 2.2541530597799997, "hotmail": 1221.23076923, "pattern": 3.79173632673, "nonluxuri": 1221.23076923, "patternuniform": 1221.23076923, "major": 1.14852058164, "research": 1.9420183486200002, "plan": 1.5356935577500002, "accomplish": 5.17302052786, "over": 1.02525024217, "area": 1.3881262568900001, "theoret": 7.83613030602, "past": 2.01702452039, "sweet": 10.2359767892, "talk": 3.0303493033, "receiv": 1.3054847463200001, "act": 1.4318181818200002, "extens": 1.99171998495, "essenti": 2.9280708225700005, "trial": 4.04175152749, "attribut": 3.4156626506, "come": 1.32831325301, "activ": 1.46403541129, "matplotlib": 1221.23076923, "other": 1.00992366412, "appli": 2.2972073506, "might": 2.1561863370900003, "known": 1.0859097127200001, "prefer": 3.0216977540900003, "andor": 690.260869565, "size": 2.49387370405, "imag": 2.70137825421, "fundament": 5.32930513595, "like": 1.14918566775, "implement": 3.57648118946, "alldiffer": 1221.23076923, "drop": 2.4594887684, "except": 1.71948445792, "process": 1.69524826482, "put": 1.65806788512, "includ": 1.0190641247799999, "structur": 2.0580762250499998, "travel": 1.9655812801800001, "choic": 3.1319786940200003, "rang": 1.7848229342299997, "time": 1.01127460348, "discret": 15.0056710775, "anaconda": 223.605633803, "delet": 22.1731843575, "chang": 1.1808985421, "document": 2.5409731114, "juggl": 167.115789474, "differ": 1.23654490225, "been": 1.0239277652399998, "statist": 4.24265098878, "first": 1.00761614623, "between": 1.03453668708, "tree": 4.127925117, "diment": 1221.23076923, "stanford": 12.6, "obvious": 6.44841592201, "action": 1.81855670103, "expertis": 20.0201765448, "program": 2.02139037433, "someth": 3.28152128979, "addingremov": 1221.23076923, "satisfact": 23.4159292035, "sort": 5.188235294119999, "call": 1.0676529926, "more": 1.0171706817, "algorithmslibrari": 1221.23076923, "list": 1.36321483771, "these": 1.07415426252, "tiwari": 721.636363636, "learningdata": 1221.23076923, "could": 1.2043695949, "car": 3.53743315508, "befor": 1.10036041031, "activatebat": 1221.23076923, "state": 1.0477133240899998, "close": 1.2848818387799998, "languag": 2.29488291414, "make": 1.0762660158600001, "sensibl": 24.164383561599998, "search": 3.2539454806299997, "folder": 168.893617021, "accur": 5.768895348840001, "permiss": 6.280063291139999, "read": 2.3149606299200003, "packag": 7.828402366860001, "common": 1.4025974025999999, "enterpris": 6.414545454550001, "reduc": 1.98698372966, "deeplearningbookorg": 1221.23076923, "shape": 3.20338983051, "sometim": 1.7126213592200001, "bio": 42.336000000000006, "avannalda": 1221.23076923, "exampl": 1.50483412322, "career": 2.98757997742, "dimension": 54.1843003413, "understand": 2.96858638743, "annalda": 1221.23076923, "import": 1.3401992233700002, "decis": 2.16, "sight": 6.79914346895, "input": 12.2029208301, "pipelin": 32.1376518219, "tool": 4.99716713881, "while": 1.0441988950299999, "densiti": 7.3465987968499995, "write": 2.0575427682700003, "learn": 2.32275054865, "recordsdata": 1221.23076923, "same": 1.11857958148, "mention": 2.53894130817}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Getting Started with Machine Learning in One Hour!</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/getting-started-machine-learning-one-hour.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Getting Started with Machine Learning in One Hour! Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/n42.html\" rel=\"prev\" title=\"KDnuggets\u2122 News 17:n42, Nov 1: 7 Steps to Mastering Deep Learning with Keras; 6 Books Every Data Scientist Should Keep Nearby\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/conjoint-analysis-primer.html\" rel=\"next\" title=\"Conjoint Analysis: A Primer\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/11/getting-started-machine-learning-one-hour.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=73952\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/getting-started-machine-learning-one-hour.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-73952 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 1-Nov, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/tutorials.html\">Tutorials, Overviews</a> \u00bb Getting Started with Machine Learning in One Hour! (\u00a0<a href=\"/2017/n43.html\">17:n43</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Getting Started with Machine Learning in One Hour!</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/n42.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/11/conjoint-analysis-primer.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/beginners\" rel=\"tag\">Beginners</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a></div>\n<br/>\n<p class=\"excerpt\">\n     Here is a machine learning getting started guide which grew out of the author's notes for a one hour talk on the subject. Hopefully you find the path helpful.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By <a href=\"https://www.linkedin.com/in/avannaldas/\" rel=\"noopener\" target=\"_blank\">Abhijit Annaldas</a>, Microsoft.</b></p>\n<p>I was planning agenda for my one hour talk. Conveying the learning paths, setting up the environment and explaining the important machine learning concepts finally made it to agenda after a lot of contemplation and thought. I initially thought about various ways this talk could have been done including - hands on python with linear regression, explaining linear regression in detail, or just sharing my learning journey that I went through past 18 months almost. But I wanted to start something that leaves the audience with lots of new information and questions to work on. Create curiosity and interest in them. And I guess I was able to do that to a decent level. Basically, to get them started with Machine Learning. That\u2019s how this guide ended up being called\u00a0<em>Getting Started with Machine Learning in one hour</em>.</p>\n<p><img alt=\"Machine learning\" class=\"aligncenter\" src=\"/wp-content/uploads/machine-learning-wordcloud.jpg\" width=\"75%\"/></p>\n<p>The notes for the talk were great for an introductory learning path, but were structured only for myself to help with the talk. Hence I wrote a machine learning getting started guide out of it and here it is. I\u2019m very happy the way this ended up taking shape and I\u2019m excited to share this!</p>\n<p>There are two main approaches to learn Machine Learning. Theoretical Machine Learning approach and Applied Machine Learning approach. I\u2019ve written about it in my earlier\u00a0<a href=\"http://abhijitannaldas.com/applied-vs-theoretical-machine-learning.html\" target=\"_blank\">blog post</a>.<br>\n\u00a0</br></p>\n<h3>Theoretical Machine Learning</h3>\n<p>\u00a0<br>\nBelow are the subjects that you can start with (ordered as I think they are appropriate). For theoretical approach of learning Machine Learning, below subjects should be studied with great rigor and in depths.</br></p>\n<ol>\n<li>Linear Algebra -\u00a0<a href=\"https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/\" target=\"_blank\">MIT</a>,\u00a0<a href=\"http://nptel.ac.in/courses/111108066\" target=\"_blank\">IISc. Bangalore</a>\n<li>Calculus -\u00a0<a href=\"https://www.coursera.org/learn/calculus1\" target=\"_blank\">Basics, Coursera</a>,\u00a0<a href=\"https://www.coursera.org/learn/advanced-calculus\" target=\"_blank\">Advanced, Coursera</a>\n<li>Probability and Statistics -\u00a0<a href=\"https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/\" target=\"_blank\">MIT</a>\n<li>Statistical Learning Theory -\u00a0<a href=\"https://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-520-statistical-learning-theory-and-applications-spring-2003/\" target=\"_blank\">MIT</a>,\u00a0<a href=\"https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about\" target=\"_blank\">Stanford</a>\n<li>Machine Learning -\u00a0<a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\">Coursera</a>,\u00a0<a href=\"https://work.caltech.edu/telecourse\" target=\"_blank\">Caltech</a>\n<li>Programming language to implement machine learning research ideas.\n</li></li></li></li></li></li></ol>\n<p>The way forward could be reading research papers, implementing research work/new algorithms, developing expertise and picking a specialization further on to the research path.<br>\n\u00a0</br></p>\n<h3>Applied Machine Learning</h3>\n<p>\u00a0</p>\n<ol>\n<li>Good understanding of the basics of above subjects (1 to 4).\n<li>Machine Learning (imp concepts explained below):\u00a0<a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\">Coursera</a>,\u00a0<a href=\"https://work.caltech.edu/telecourse\" target=\"_blank\">Caltech</a>\n<li><a href=\"https://www.datacamp.com/courses/intro-to-python-for-data-science\" target=\"_blank\">Python</a>\u00a0or R Programming Language, as per your preference.\n<li>Learn to use popular machine learning, data manipulation and visualization libraries in the chosen programming language. I personally use Python programming language, hence I\u2019ll elaborate on that below.\n<li>Must know Python Libraries:\u00a0<a href=\"https://www.datacamp.com/community/tutorials/python-numpy-tutorial\" target=\"_blank\">numpy</a>,\u00a0<a href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\" target=\"_blank\">pandas</a>,\u00a0<a href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\" target=\"_blank\">scikit-learn</a>,\u00a0<a href=\"https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python\" target=\"_blank\">matplotlib</a>\n<li>Other popular python libraries:\u00a0<a href=\"https://github.com/Microsoft/LightGBM\" target=\"_blank\">LightGBM</a>,\u00a0<a href=\"https://github.com/dmlc/xgboost\" target=\"_blank\">XGBoost</a>,\u00a0<a href=\"https://catboost.yandex/\" target=\"_blank\">CatBoost</a>\n</li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Quick Start Option</h3>\n<p>\u00a0<br>\nIf you want to get a taste of what is Machine Learning about and what it could be like. You can start this way for experimenting, getting quick hands on. Not an ideal way if you want to get serious about Data Science in long run.</br></p>\n<ol>\n<li>Know Machine Learning Concepts Overview (below)\n<li>Learn Python or R\n<li>Understand and learn to use popular libraries in your language of choice\n</li></li></li></ol>\n<p>\u00a0</p>\n<h3>Python Environment setup</h3>\n<p>\u00a0</p>\n<ol>\n<li>Python\n<ul>\n<li>Python.org\u00a0<a href=\"https://www.python.org/downloads/\" target=\"_blank\">Download</a>,\u00a0<a href=\"https://www.datacamp.com/courses/intro-to-python-for-data-science\" target=\"_blank\">Learn</a>\u00a0OR\n<li>Anaconda\u00a0<a href=\"https://www.continuum.io/downloads\" target=\"_blank\">Download</a>,\u00a0<a href=\"https://docs.continuum.io/anaconda/\" target=\"_blank\">Learn</a>\n</li></li></ul>\n<li>Code Editor / IDE\n<ul>\n<li>Visual Studio Code (Search and install python extension, pick the most downloaded one)\n<li>Notepad++\n<li><a href=\"http://jupyter.readthedocs.io/en/latest/install.html\" target=\"_blank\">Jupyter</a>\u00a0(Installs with Anaconda)\n</li></li></li></ul>\n<li>Installing python packages\n<ul>\n<li><a href=\"https://docs.python.org/3/installing/index.html\" target=\"_blank\">Managing packages with pip, python\u2019s native tool</a>:\u00a0<code>pip install &lt;package-name&gt;</code>\n<li><a href=\"https://conda.io/docs/using/pkgs.html\" target=\"_blank\">Managing packages with anaconda</a>:\u00a0<code>conda install &lt;package-name&gt;</code>\n</li></li></ul>\n<li>Managing Python (native) virtual environments (if multiple environments are needed)\n<ul>\n<li>Create virtual environment:\u00a0<code>python -m venv c:\\path\\to\\env\\folder</code>\n<li>Command help:\u00a0<code>python -m venv -h</code>\n<li>Switch environments:\u00a0<code>activate.bat</code>\u00a0script located in the virtual environment folder\n<li>Python (native) virtual environments\u00a0<a href=\"https://docs.python.org/3/library/venv.html\" target=\"_blank\">documentation</a>\n</li></li></li></li></ul>\n<li>Managing Anaconda virtual environments (if multiple environments are needed)\n<ul>\n<li>Default conda environment -\u00a0<code>root</code>\n<li>List available environments -\u00a0<code>conda env list</code>\n<li>Create new environment -\u00a0<code>conda create --name environment_name</code>\n<li>Switch to environment -\u00a0<code>activate environment_name</code>\u00a0or\u00a0<code>source activate environment_name</code>\n<li>Anaconda virtual environments\u00a0<a href=\"https://conda.io/docs/using/envs.html\" target=\"_blank\">documentation</a>\n</li></li></li></li></li></ul>\n</li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Machine Learning Concepts Overview</h3>\n<p>\u00a0</p>\n<ul>\n<li><strong>Machine Learning</strong>: Is an approach to find patterns from a large set of data through a function\u00a0<em>f(x)</em>\u00a0which effectively generalizes to unseen\u00a0<em>x</em>\u00a0to find learned patterns in unseen data and make the inferences the Machine Learning Model was trained for.\n<li><strong>Dataset</strong>: Data being used to apply machine learning and find patterns from. For supervised type of machine learning applications, the dataset contains both\u00a0<em>x</em>\u00a0(input/attributes/independent variables) and\u00a0<em>y</em>\u00a0(target/labels/dependent variables) data. For unsupervised data it\u2019s just\u00a0<em>x</em>, input and the output of the data is some sort of learned patterns (like clusters, groups, etc.)\n<li><strong>Train set</strong>: A subset of\u00a0<em>Dataset</em>\u00a0fed to (train) machine learning algorithm to learn patterns\n<li><strong>Evaluation / Validation / Cross Validation Set</strong>: Subset of\u00a0<em>Dataset</em>\u00a0not in\u00a0<em>Train set</em>\u00a0used to evaluate how the machine learning algorithm is doing.\n<li><strong>Test set</strong>:\u00a0<em>Dataset</em>\u00a0to predict learned insights for. For supervised problems, target/label\u00a0<em>y</em>\u00a0like in\u00a0<em>train set</em>\u00a0is to be predicted and hence it isn\u2019t a part of\u00a0<em>train set</em>. For unsupervised,\u00a0<em>train</em>\u00a0and\u00a0<em>test</em>\u00a0sets can be identical.\n<li><strong>Types</strong>:\n<ul>\n<li><strong>Supervised</strong>: In supervised problems, the historical data includes the labels (target attribute, outcomes) that need to be predicted for future/unseen data. For example, for housing price prediction we have data about house (area, # of bedrooms, location, etc.) and price. Here the after training a machine learning model with given data (X - data) and price (Y - labels), in future, price (Y) will be predicted for new/unseen data (X).\n<li><strong>Unsupervised</strong>: In unsupervised learning, there is no label or target attribute. A typical example would be clustering data based on learned patterns. Like for a dataset of house details (area, location, price, # of bedrooms, # of floors, built date, etc.) the algorithm needs to find if there is any hidden patterns. For example some houses are very expensive while some others are of usual price. Some houses are very big while some houses are of usual size. With these patterns, records/data is clustered into groups like Luxury-Homes, Non-Luxury Homes, Bunglows, Apartment, etc.\n<li><strong>Reinforcement</strong>: In Reinforcement Learning, an \u2018Agent\u2019 acts in an \u2018Environment\u2019 and receives positive or negative feedback. Positive feedback tells an agent that it has done well, and agent proceeds on similar plan/action. Negative feedback tells an agent that it has done something wrong, and should change it\u2019s course of action. The agent and the environment are software/programmed implementations. The core of reinforcement learning is building an agent (or agent\u2019s behaviour in some way) that learns to successfully accomplish a specific task in an environment.\n</li></li></li></ul>\n<li><strong>Popular Algorithms</strong>:\u00a0<a href=\"https://en.wikipedia.org/wiki/Linear_regression\" target=\"_blank\">Linear Regression</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" target=\"_blank\">Logistic Regression</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Support_vector_machine\" target=\"_blank\">Support Vector Machines</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\" target=\"_blank\">K-Nearest-Neighbors</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Decision_tree\" target=\"_blank\">Decision Trees</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Random_forest\" target=\"_blank\">Random Forest</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Gradient_boosting\" target=\"_blank\">Gradient Boosting</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Ensemble_learning\" target=\"_blank\">Ensemble Learning</a>\n<li><strong>Preprocessing</strong>: In real world scenario data is rarely clean and neat in a state that Machine Learning algorithms can be directly applied on. Preprocessing is a process of cleaning data to feed to machine learning algorithm. Some of the common preprocessing steps are\u2026\n<ul>\n<li><strong>Missing Value</strong>: When some of the values are missing, they are usually dealt by adding median/mean values or deleting corresponding row, or using the value from the previous row, etc. There are many ways of doing this. What exactly needs to be done depends on the kind of data, problem being solved and business goals.\n<li><strong>Categorical Variables</strong>: Discrete finite set of values. Like \u2018car type\u2019, \u2018department\u2019, etc. These values are converted either into numbers or vectors. Conversion to vectors is known as\u00a0<a href=\"https://en.wikipedia.org/wiki/One-hot\" target=\"_blank\">One-Hot</a>\u00a0Encoding. There are numerous ways of doing this in python. Some machine learning algorithms/libraries themselves handle categorical columns by encoding internally. One way of encoding is using\u00a0<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" target=\"_blank\">sklearn.preprocessing.OneHotEncoder</a>\u00a0in scikit-learn.\n<li><strong>Scaling</strong>: Proportionately reducing values in columns into a common scale like 0 to 1. Having values in all columns in a common range might improve accuracy and training speed to some extent.\n<li><strong>Text</strong>: Text needs to be processed using Natural Language Processing techniques (out of scope of this guide), when it isn\u2019t preprocessed, it is usually excluded from the training data that is fed to a machine learning algorithm.\n<li><strong>Imbalanced datasets</strong>: The data shouldn\u2019t be biased, skewed. For e.g., consider a classification task where an algorithm classifies data into 3 different classes - A, B and C. If the dataset has very few/high records of one class w.r.t. others it is said to be biased/imbalanced. Usually data is oversampled in such cases by synthetically generating more random data from existing data. Some machine learning algorithms/libraries allow providing weights or some parameter to balance out the skew internally without us doing the heavy lifting of fixing a skewed dataset. For example,\u00a0<a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\" target=\"_blank\">SVM: Separating hyperplane for unbalanced classes</a>\u00a0in scikit-learn.\n<li><strong>Outliers</strong>: Outliers need to be dealt with on a case by case basis based on the problem and business case.\n</li></li></li></li></li></li></ul>\n<li><strong>Data Transformation</strong>: When a column/attribute in a dataset doesn\u2019t have an inherent pattern, it is transformed into something like log(values), sqrt(values), etc. where the transformed values might have interesting pattern/uniformity that can be learned. This is again, obviously case by case basis and needs data exploration to find a right fit.\n<li><strong>Feature Engineering</strong>: Feature Engineering is a process of deriving hidden insights from existing data. Consider a housing price prediction dataset which has columns \u2018plot-width\u2019, \u2018plot-length\u2019, \u2018number of bedrooms\u2019 and \u2018price\u2019. Here we see a key attribute area of the house is missing, but can be calculated based on \u2018plot-width\u2019 and \u2018plot-length\u2019. So a calculated column, \u2018area\u2019 is added to the dataset. This is known as feature engineering. Feature Engineering might be of different difficulty level, sometimes a derived attribute is right in front of sight like here, sometimes it\u2019s really hidden and needs lot of thinking.\n<li><strong>Training</strong>: This is a main step where the machine learning algorithm is trained on the given data to find generalized patterns to be applied on unseen data. Below are some important nitty-gritty details of this phase\u2026\n<ul>\n<li><strong>Feature Selection</strong>: Not all features/columns contribute to the learning. These are the columns where the data in them don\u2019t affect the outcome. Such features are removed from the dataset. What features to train on and what features to exclude is decided based on feature importance given by a machine learning algorithm being applied. Most of the modern algorithms do provide the feature importances. If an algorithm doesn\u2019t provide, scikit-learn has\u00a0<a href=\"http://scikit-learn.org/stable/modules/feature_selection.html\" target=\"_blank\">capabilities</a>\u00a0which can help in feature selection. Also correlated features are removed.\n<li><strong>Dimensionality Reduction</strong>:\u00a0<a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\" target=\"_blank\">Dimentionality reduction</a>\u00a0also aims to find the most important features of all the features, aiming to reduce the\u00a0<a href=\"https://en.wikipedia.org/wiki/Curse_of_dimensionality\" target=\"_blank\">dimensionality</a>\u00a0of the data. The main difference w.r.t. feature importance based feature selection is that, in Dimensionality Reduction, a subset of features and/or derived features are selected. In other words, we may not be able to map the extracted features to the original features. You can find more about dimensionality reduction in scikit-learn\u00a0<a href=\"http://scikit-learn.org/stable/modules/unsupervised_reduction.html#\" target=\"_blank\">here</a>.\n<li><strong>Feature Selection vs Dimensionality Reduction</strong>: In my opinion, one of the two ways should solve the purpose. If we do both feature selection based on feature importance and dimensionality reduction, we should first do based on feature importances. And then introduce dimensionality reduction. It goes without saying that we should evaluate the performance at every step to understand what\u2019s working and what\u2019s not. Feature selection based on feature importance is easy to interpret as the selected features are subset of all, which isn\u2019t a case with dimensionality reduction.\n<li><strong>Evaluation Metric</strong>: Evaluation metric is a metric used to evaluate predictions for their correctness. A machine learning algorithm while training uses an evaluation metric to evaluate, compute cost and optimize on the cost convex function. Though each algorithm has a default evaluation metric, it is recommended to specify the exact evaluation metric as per the business case/problem. Like some problems can afford false positives, but cannot afford any false negatives. By specifying the evaluation metric, these nitty gritty details of the model can be controlled.\n<li><strong>Parameter tuning</strong>: Though most of the today\u2019s state of the art algorithms have sensible default values for the parameters, it always helps to tune the parameters to control the accuracy of a model and improve overall predictions. Parameter tuning can be done on a trial and error basis by repeatedly changing and assessing the accuracy. Alternatively a set of parameter values can be provided to try all/different permutations of those parameters and find the best parameter combination. This can be done using some helper functions called\u00a0<a href=\"http://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers\" target=\"_blank\">Hyper-parameter Optimizers in scikit-learn</a>.\n<li><strong>Overfitting (Bias)</strong>: Overfitting is a state where the machine learning model almost memorizes all the training data and predicts almost accurately on data that\u2019s already in training set. This is a state where the model fails to generalize and predict on unseen data. This is also known as model having high bias. Overfitting can be dealt with using Regularization, tuning hyperparameters if configured inappropriately, holding off partial dataset to use correct cross validation<a href=\"http://scikit-learn.org/stable/modules/cross_validation.html\" target=\"_blank\">(1)</a><a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\" target=\"_blank\">(2)</a>\u00a0strategy.\n<li><strong>Underfitting (Variance)</strong>: Underfitting is a state where the machine learning model\u2019s predictions don\u2019t do well even when predicting on data already in the training set. This is also known as model having high variance. Underfitting can be dealt with adding more data, adding/removing features, trying different machine learning algorithm, etc.\n<li><strong>Bias and Variance trade-off (sweet spot)</strong>: The goal of model training is to find a sweet spot where the model cross validation error is minimum. Initially both cross validation and train error are high (Underfitting/high variance). As the model is training, the error keeps dropping to a certain point where cross validation is minimum and also close to train error (sweet spot). This is optimal spot. After this point, if the model further keeps reducing error (on train set), it almost memorizes the train set ends up overfitting which means higher error on unseen data.\n<li><strong>Regularization</strong>: At some point when the model is trying to learn further (reducing error, tending towards overfitting), regularization helps in countering the overfitting effects. Regularization is usually a parameter that\u2019s added during cost/error calculation. Machine learning algorithms may not always provide regularization parameter explictly. In such case, usually there are other parameters that can be tuned to introduce regularization to the extent required.\n</li></li></li></li></li></li></li></li></li></ul>\n<li><strong>Prediction</strong>: To make predictions with trained machine learning model, the prediction method of the model is called by providing the test dataset as parameter. The test dataset should be preprocessed exactly the way it was done on the training dataset. In other words, in the same format of training data which was fed to the machine learning model for training.\n<li><strong>Other terminologies</strong>:\n<ul>\n<li><strong>Model Stacking</strong>: When single machine learning algorithm doesn\u2019t do well, multiple machine learning algorithms are used to make predictions and the predictions are combined together in different ways. Most simplest being a weighted predictions. Sometimes, other machine learning model (meta-model) is used on top of the predictions of the first level models. This could go to any level of complexity and can have different pipelines.\n</li></ul>\n</li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n<p>\u00a0</p>\n<h3>Deep Learning</h3>\n<p>\u00a0<br/>\nFun fact is that a majority (over 90% I guess) of all the machine learning problems solved today are solved using just Random Forests, Gradient Boosted Decision Trees, SVM, KNN, Linear Regression, Logistic Regression.</p>\n<p>But, there are some set of problems that cannot be solved using above techniques. Problems like image classification, image recognition, natural language processing, audio processing, etc. are solved using a technique called Deep Learning. Before starting deep learning, I believe it\u2019s essential to master all of the above concepts first.</p>\n<p>Good Deep Learning resources\u2026</p>\n<ul>\n<li><a href=\"http://www.fast.ai/\" target=\"_blank\">Fast.ai</a>\u00a0\u2013 thanks for the suggestion\u00a0<a href=\"https://www.linkedin.com/in/pranay-tiwari-47a49048/\" target=\"_blank\">Pranay Tiwari</a>!\n<li><a href=\"http://neuralnetworksanddeeplearning.com/\" target=\"_blank\">neuralnetworksanddeeplearning.com - an online book, stresses on theory and fundamentals</a>\n<li><a href=\"https://www.coursera.org/specializations/deep-learning\" target=\"_blank\">Deep Learning Specialization at Coursera by Andrew Ng</a>\n<li><a href=\"http://www.deeplearningbook.org/\" target=\"_blank\">deeplearningbook.org - an online book</a>\n</li></li></li></li></ul>\n<p>If you know deep learning concepts and want to get your hands dirty, some popular Deep Learning Libraries are:\u00a0<a href=\"https://keras.io/\" target=\"_blank\">Keras</a>,\u00a0<a href=\"https://github.com/Microsoft/CNTK\" target=\"_blank\">CNTK</a>,\u00a0<a href=\"https://github.com/tensorflow/tensorflow\" target=\"_blank\">Tensorflow</a>,\u00a0<a href=\"https://github.com/tflearn/tflearn\" target=\"_blank\">tflearn</a>,\u00a0<a href=\"https://github.com/deepmind/sonnet\" target=\"_blank\">sonnet</a>,\u00a0<a href=\"https://github.com/pytorch/pytorch\" target=\"_blank\">pytorch</a>,\u00a0<a href=\"https://github.com/BVLC/caffe\" target=\"_blank\">caffe</a>,\u00a0<a href=\"https://github.com/Theano/Theano\" target=\"_blank\">Theano</a><br/>\n\u00a0</p>\n<h3>Practice</h3>\n<p>\u00a0<br/>\nYes, practice is the most important thing and this guide would have been incomplete without mentioning about practicing machine learning. To practice and master your skills further, below are the things you can do\u2026</p>\n<ol>\n<li>Get datasets from various online data sources. One such popular data source is\u00a0<a href=\"http://abhijitannaldas.com/getting-started-with-machine-learning-in-one-hour/archive.ics.uci.edu/ml/\" target=\"_blank\">UCI Machine Learning Repository</a>. Additionally, you can\u00a0<a href=\"http://google.com/search?q=datasets+for+machine+learning\" target=\"_blank\">search \u2018datasets for machine learning\u2019</a>.\n<li>Participate in online machine learning/data science hackathons. Some of the popular ones are -\u00a0<a href=\"http://kaggle.com/\" target=\"_blank\">Kaggle</a>,\u00a0<a href=\"http://www.hackerearth.com/\" target=\"_blank\">HackerEarth</a>, etc. If you end up starting with something that\u2019s very difficult, try persisting a bit. If it still feels difficult, park it aside and find other. There\u2019s no need to be disappointed. Usually problems on online hackathon have some level of difficulty which may not always be suitable for beginners.\n<li>Blog about what you learn! It\u2019ll help you solidify your understanding and thoughts about the subject.\n<li>Follow Data Science, Machine Learning topics on Quora, lot of great advice and questions/answers to learn from.\n<li>Start listening to podcasts (available on link below)\n<li>Check out some useful links on my\u00a0<a href=\"http://abhijitannaldas.com/useful-stuff/\" target=\"_blank\">Data Science Learning Resources</a>\u00a0page.\n</li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Closing thoughts</h3>\n<p>\u00a0<br/>\nIf you are considering the field of Machine Learning/Data Science seriously and you are thinking of making a career switch, think about the your motivations and why you\u2019d like to do it.</p>\n<p>If you are sure, I have one advice for you.\u00a0<strong><em>Never ever ever give up or think if its all worth it</em></strong>. It\u2019s definitely worth it and I can say that as I have walked that path since last 18 months\u2026 almost every day, every weekend and every spare hour of my time (except when I was travelling or I was totally drowned by my day job commitments). The road ahead to master data science isn\u2019t easy. As they say,\u00a0<em>\u201cRome was not built in a day!\u201d</em>. You\u2019ll need to learn lot of subjects. Juggle between different learning priorities. Even after learning a lot you\u2019ll still find new things that you have never thought/heard about before. New concepts/techniques that you keep discovering might make you feel that you still don\u2019t know a lot of things and there is a lot more ground to cover. This is common. Just stick with it. Set big goals, plan for small tasks and just focus on task at hand. If something new comes up, just scribble it down in your diary and get back to it later.<br/>\n\u00a0</p>\n<h3>Thank You!</h3>\n<p>\u00a0<br/>\nIf you have been reading all the way till here, I appreciate your effort and the time you have invested. I hope this guide was useful to you and has made it little easier for you to get started on your own learning adventure. At some later point of time, if you think this guide has made some difference in your learning adventure, please please come back and leave a comment here. Or reach me at avannaldas .at. hotmail .dot. com. I\u2019d love to hear from you. It\u2019ll give me immense satisfaction to know that this has helped you, and my effort in putting this together was worthwhile.</p>\n<p>This was my biggest write up ever. I have spent many hours writing, editing and reviewing this. If you see any mistakes or things that can be improved, please let me know in comments or via email. I\u2019ll fix it the earliest I can and will attribute it to you. This will help everyone who reads this.</p>\n<p>Thanks Again!</p>\n<p>All the best!</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/avannaldas/\" target=\"_blank\">Abhijit Annaldas</a></b> is a Software Engineer and a voracious learner who has acquired Machine Learning knowledge and expertise to a fair extent. He is improving expertise day by day by learning new stu\ufb00 and relentless practice, and has extensive experience building enterprise scale applications in di\ufb00erent Microsoft and Open Source technologies as a Software Engineer at Microsoft, India since June 2012.</p>\n<p><a href=\"http://abhijitannaldas.com/getting-started-with-machine-learning-in-one-hour/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/05/learn-machine-learning-10-days.html\">How to Learn Machine Learning in 10 Days</a>\n<li><a href=\"/2017/05/guerrilla-guide-machine-learning-python.html\">The Guerrilla Guide to Machine Learning with Python</a>\n<li><a href=\"/2017/10/density-based-spatial-clustering-applications-noise-dbscan.html\">Density Based Spatial Clustering of Applications with Noise (DBSCAN)</a>\n</li></li></li></ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/n42.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/11/conjoint-analysis-primer.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/tutorials.html\">Tutorials, Overviews</a> \u00bb Getting Started with Machine Learning in One Hour! (\u00a0<a href=\"/2017/n43.html\">17:n43</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556329440\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.714 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 21:44:00 -->\n<!-- Compression = gzip -->", "content_tokenized": ["abhijit", "annalda", "microsoft", "plan", "agenda", "for", "one", "hour", "talk", "convey", "the", "learn", "path", "set", "the", "environ", "and", "explain", "the", "import", "machin", "learn", "concept", "final", "made", "agenda", "after", "lot", "contempl", "and", "thought", "initi", "thought", "about", "various", "way", "this", "talk", "could", "have", "been", "done", "includ", "hand", "python", "with", "linear", "regress", "explain", "linear", "regress", "detail", "just", "share", "learn", "journey", "that", "went", "through", "past", "num", "month", "almost", "but", "want", "start", "someth", "that", "leav", "the", "audienc", "with", "lot", "new", "inform", "and", "question", "work", "creat", "curios", "and", "interest", "them", "and", "guess", "abl", "that", "decent", "level", "basic", "get", "them", "start", "with", "machin", "learn", "that", "how", "this", "guid", "end", "call", "get", "start", "with", "machin", "learn", "one", "hour", "the", "note", "for", "the", "talk", "were", "great", "for", "introductori", "learn", "path", "but", "were", "structur", "onli", "for", "myself", "help", "with", "the", "talk", "henc", "wrote", "machin", "learn", "get", "start", "guid", "out", "and", "here", "veri", "happi", "the", "way", "this", "end", "take", "shape", "and", "excit", "share", "this", "there", "are", "two", "main", "approach", "learn", "machin", "learn", "theoret", "machin", "learn", "approach", "and", "appli", "machin", "learn", "approach", "written", "about", "earlier", "blog", "post", "theoret", "machin", "learn", "below", "are", "the", "subject", "that", "can", "start", "with", "order", "think", "they", "are", "appropri", "for", "theoret", "approach", "learn", "machin", "learn", "below", "subject", "should", "studi", "with", "great", "rigor", "and", "depth", "linear", "algebra", "iisc", "bangalor", "calculus", "basic", "coursera", "advanc", "coursera", "probabl", "and", "statist", "statist", "learn", "theori", "stanford", "machin", "learn", "coursera", "caltech", "program", "languag", "implement", "machin", "learn", "research", "idea", "the", "way", "forward", "could", "read", "research", "paper", "implement", "research", "worknew", "algorithm", "develop", "expertis", "and", "pick", "special", "further", "the", "research", "path", "appli", "machin", "learn", "good", "understand", "the", "basic", "abov", "subject", "num", "num", "machin", "learn", "imp", "concept", "explain", "below", "coursera", "caltech", "python", "program", "languag", "per", "prefer", "learn", "use", "popular", "machin", "learn", "data", "manipul", "and", "visual", "librari", "the", "chosen", "program", "languag", "person", "use", "python", "program", "languag", "henc", "elabor", "that", "below", "must", "know", "python", "librari", "numpi", "panda", "scikitlearn", "matplotlib", "other", "popular", "python", "librari", "lightgbm", "xgboost", "catboost", "quick", "start", "option", "want", "get", "tast", "what", "machin", "learn", "about", "and", "what", "could", "like", "can", "start", "this", "way", "for", "experi", "get", "quick", "hand", "not", "ideal", "way", "want", "get", "serious", "about", "data", "scienc", "long", "run", "know", "machin", "learn", "concept", "overview", "below", "learn", "python", "understand", "and", "learn", "use", "popular", "librari", "languag", "choic", "python", "environ", "setup", "python", "pythonorg", "download", "learn", "anaconda", "download", "learn", "code", "editor", "visual", "studio", "code", "search", "and", "instal", "python", "extens", "pick", "the", "most", "download", "one", "notepad", "jupyt", "instal", "with", "anaconda", "instal", "python", "packag", "manag", "packag", "with", "pip", "python", "nativ", "tool", "pip", "instal", "manag", "packag", "with", "anaconda", "conda", "instal", "manag", "python", "nativ", "virtual", "environ", "multipl", "environ", "are", "need", "creat", "virtual", "environ", "python", "venv", "pathtoenvfold", "command", "help", "python", "venv", "switch", "environ", "activatebat", "script", "locat", "the", "virtual", "environ", "folder", "python", "nativ", "virtual", "environ", "document", "manag", "anaconda", "virtual", "environ", "multipl", "environ", "are", "need", "default", "conda", "environ", "root", "list", "avail", "environ", "conda", "env", "list", "creat", "new", "environ", "conda", "creat", "name", "environmentnam", "switch", "environ", "activ", "environmentnam", "sourc", "activ", "environmentnam", "anaconda", "virtual", "environ", "document", "machin", "learn", "concept", "overview", "machin", "learn", "approach", "find", "pattern", "from", "larg", "set", "data", "through", "function", "which", "effect", "general", "unseen", "find", "learn", "pattern", "unseen", "data", "and", "make", "the", "infer", "the", "machin", "learn", "model", "train", "for", "dataset", "data", "use", "appli", "machin", "learn", "and", "find", "pattern", "from", "for", "supervis", "type", "machin", "learn", "applic", "the", "dataset", "contain", "both", "inputattributesindepend", "variabl", "and", "targetlabelsdepend", "variabl", "data", "for", "unsupervis", "data", "just", "input", "and", "the", "output", "the", "data", "some", "sort", "learn", "pattern", "like", "cluster", "group", "etc", "train", "set", "subset", "dataset", "fed", "train", "machin", "learn", "algorithm", "learn", "pattern", "evalu", "valid", "cross", "valid", "set", "subset", "dataset", "not", "train", "set", "use", "evalu", "how", "the", "machin", "learn", "algorithm", "test", "set", "dataset", "predict", "learn", "insight", "for", "for", "supervis", "problem", "targetlabel", "like", "train", "set", "predict", "and", "henc", "part", "train", "set", "for", "unsupervis", "train", "and", "test", "set", "can", "ident", "type", "supervis", "supervis", "problem", "the", "histor", "data", "includ", "the", "label", "target", "attribut", "outcom", "that", "need", "predict", "for", "futureunseen", "data", "for", "exampl", "for", "hous", "price", "predict", "have", "data", "about", "hous", "area", "bedroom", "locat", "etc", "and", "price", "here", "the", "after", "train", "machin", "learn", "model", "with", "given", "data", "data", "and", "price", "label", "futur", "price", "will", "predict", "for", "newunseen", "data", "unsupervis", "unsupervis", "learn", "there", "label", "target", "attribut", "typic", "exampl", "would", "cluster", "data", "base", "learn", "pattern", "like", "for", "dataset", "hous", "detail", "area", "locat", "price", "bedroom", "floor", "built", "date", "etc", "the", "algorithm", "need", "find", "there", "ani", "hidden", "pattern", "for", "exampl", "some", "hous", "are", "veri", "expens", "while", "some", "other", "are", "usual", "price", "some", "hous", "are", "veri", "big", "while", "some", "hous", "are", "usual", "size", "with", "these", "pattern", "recordsdata", "cluster", "into", "group", "like", "luxuryhom", "nonluxuri", "home", "bunglow", "apart", "etc", "reinforc", "reinforc", "learn", "agent", "act", "environ", "and", "receiv", "posit", "negat", "feedback", "posit", "feedback", "tell", "agent", "that", "has", "done", "well", "and", "agent", "proceed", "similar", "planact", "negat", "feedback", "tell", "agent", "that", "has", "done", "someth", "wrong", "and", "should", "chang", "cours", "action", "the", "agent", "and", "the", "environ", "are", "softwareprogram", "implement", "the", "core", "reinforc", "learn", "build", "agent", "agent", "behaviour", "some", "way", "that", "learn", "success", "accomplish", "specif", "task", "environ", "popular", "algorithm", "linear", "regress", "logist", "regress", "support", "vector", "machin", "knearestneighbor", "decis", "tree", "random", "forest", "gradient", "boost", "ensembl", "learn", "preprocess", "real", "world", "scenario", "data", "rare", "clean", "and", "neat", "state", "that", "machin", "learn", "algorithm", "can", "direct", "appli", "preprocess", "process", "clean", "data", "feed", "machin", "learn", "algorithm", "some", "the", "common", "preprocess", "step", "are\u2026", "miss", "valu", "when", "some", "the", "valu", "are", "miss", "they", "are", "usual", "dealt", "medianmean", "valu", "delet", "correspond", "row", "use", "the", "valu", "from", "the", "previous", "row", "etc", "there", "are", "mani", "way", "this", "what", "exact", "need", "done", "depend", "the", "kind", "data", "problem", "solv", "and", "busi", "goal", "categor", "variabl", "discret", "finit", "set", "valu", "like", "car", "type", "depart", "etc", "these", "valu", "are", "convert", "either", "into", "number", "vector", "convers", "vector", "known", "onehot", "encod", "there", "are", "numer", "way", "this", "python", "some", "machin", "learn", "algorithmslibrari", "themselv", "handl", "categor", "column", "encod", "intern", "one", "way", "encod", "use", "sklearnpreprocessingonehotencod", "scikitlearn", "scale", "proportion", "reduc", "valu", "column", "into", "common", "scale", "like", "num", "num", "have", "valu", "all", "column", "common", "rang", "might", "improv", "accuraci", "and", "train", "speed", "some", "extent", "text", "text", "need", "process", "use", "natur", "languag", "process", "techniqu", "out", "scope", "this", "guid", "when", "preprocess", "usual", "exclud", "from", "the", "train", "data", "that", "fed", "machin", "learn", "algorithm", "imbalanc", "dataset", "the", "data", "shouldn", "bias", "skew", "for", "consid", "classif", "task", "where", "algorithm", "classifi", "data", "into", "num", "differ", "class", "and", "the", "dataset", "has", "veri", "fewhigh", "record", "one", "class", "wrt", "other", "said", "biasedimbalanc", "usual", "data", "oversampl", "such", "case", "synthet", "generat", "more", "random", "data", "from", "exist", "data", "some", "machin", "learn", "algorithmslibrari", "allow", "provid", "weight", "some", "paramet", "balanc", "out", "the", "skew", "intern", "without", "the", "heavi", "lift", "fix", "skew", "dataset", "for", "exampl", "separ", "hyperplan", "for", "unbalanc", "class", "scikitlearn", "outlier", "outlier", "need", "dealt", "with", "case", "case", "basi", "base", "the", "problem", "and", "busi", "case", "data", "transform", "when", "columnattribut", "dataset", "have", "inher", "pattern", "transform", "into", "someth", "like", "etc", "where", "the", "transform", "valu", "might", "have", "interest", "patternuniform", "that", "can", "learn", "this", "again", "obvious", "case", "case", "basi", "and", "need", "data", "explor", "find", "right", "fit", "featur", "engin", "featur", "engin", "process", "deriv", "hidden", "insight", "from", "exist", "data", "consid", "hous", "price", "predict", "dataset", "which", "has", "column", "plotwidth", "plotlength", "number", "bedroom", "and", "price", "here", "see", "key", "attribut", "area", "the", "hous", "miss", "but", "can", "calcul", "base", "plotwidth", "and", "plotlength", "calcul", "column", "area", "the", "dataset", "this", "known", "featur", "engin", "featur", "engin", "might", "differ", "difficulti", "level", "sometim", "deriv", "attribut", "right", "front", "sight", "like", "here", "sometim", "realli", "hidden", "and", "need", "lot", "think", "train", "this", "main", "step", "where", "the", "machin", "learn", "algorithm", "train", "the", "given", "data", "find", "general", "pattern", "appli", "unseen", "data", "below", "are", "some", "import", "nittygritti", "detail", "this", "phase\u2026", "featur", "select", "not", "all", "featurescolumn", "contribut", "the", "learn", "these", "are", "the", "column", "where", "the", "data", "them", "affect", "the", "outcom", "such", "featur", "are", "remov", "from", "the", "dataset", "what", "featur", "train", "and", "what", "featur", "exclud", "decid", "base", "featur", "import", "given", "machin", "learn", "algorithm", "appli", "most", "the", "modern", "algorithm", "provid", "the", "featur", "import", "algorithm", "provid", "scikitlearn", "has", "capabl", "which", "can", "help", "featur", "select", "also", "correl", "featur", "are", "remov", "dimension", "reduct", "diment", "reduct", "also", "aim", "find", "the", "most", "import", "featur", "all", "the", "featur", "aim", "reduc", "the", "dimension", "the", "data", "the", "main", "differ", "wrt", "featur", "import", "base", "featur", "select", "that", "dimension", "reduct", "subset", "featur", "andor", "deriv", "featur", "are", "select", "other", "word", "may", "not", "abl", "map", "the", "extract", "featur", "the", "origin", "featur", "can", "find", "more", "about", "dimension", "reduct", "scikitlearn", "here", "featur", "select", "dimension", "reduct", "opinion", "one", "the", "two", "way", "should", "solv", "the", "purpos", "both", "featur", "select", "base", "featur", "import", "and", "dimension", "reduct", "should", "first", "base", "featur", "import", "and", "then", "introduc", "dimension", "reduct", "goe", "without", "say", "that", "should", "evalu", "the", "perform", "everi", "step", "understand", "what", "work", "and", "what", "not", "featur", "select", "base", "featur", "import", "easi", "interpret", "the", "select", "featur", "are", "subset", "all", "which", "case", "with", "dimension", "reduct", "evalu", "metric", "evalu", "metric", "metric", "use", "evalu", "predict", "for", "their", "correct", "machin", "learn", "algorithm", "while", "train", "use", "evalu", "metric", "evalu", "comput", "cost", "and", "optim", "the", "cost", "convex", "function", "though", "each", "algorithm", "has", "default", "evalu", "metric", "recommend", "specifi", "the", "exact", "evalu", "metric", "per", "the", "busi", "caseproblem", "like", "some", "problem", "can", "afford", "fals", "posit", "but", "can", "not", "afford", "ani", "fals", "negat", "specifi", "the", "evalu", "metric", "these", "nitti", "gritti", "detail", "the", "model", "can", "control", "paramet", "tune", "though", "most", "the", "today", "state", "the", "art", "algorithm", "have", "sensibl", "default", "valu", "for", "the", "paramet", "alway", "help", "tune", "the", "paramet", "control", "the", "accuraci", "model", "and", "improv", "overal", "predict", "paramet", "tune", "can", "done", "trial", "and", "error", "basi", "repeat", "chang", "and", "assess", "the", "accuraci", "altern", "set", "paramet", "valu", "can", "provid", "tri", "alldiffer", "permut", "those", "paramet", "and", "find", "the", "best", "paramet", "combin", "this", "can", "done", "use", "some", "helper", "function", "call", "hyperparamet", "optim", "scikitlearn", "overfit", "bias", "overfit", "state", "where", "the", "machin", "learn", "model", "almost", "memor", "all", "the", "train", "data", "and", "predict", "almost", "accur", "data", "that", "alreadi", "train", "set", "this", "state", "where", "the", "model", "fail", "general", "and", "predict", "unseen", "data", "this", "also", "known", "model", "have", "high", "bias", "overfit", "can", "dealt", "with", "use", "regular", "tune", "hyperparamet", "configur", "inappropri", "hold", "off", "partial", "dataset", "use", "correct", "cross", "valid", "num", "num", "strategi", "underfit", "varianc", "underfit", "state", "where", "the", "machin", "learn", "model", "predict", "well", "even", "when", "predict", "data", "alreadi", "the", "train", "set", "this", "also", "known", "model", "have", "high", "varianc", "underfit", "can", "dealt", "with", "more", "data", "addingremov", "featur", "tri", "differ", "machin", "learn", "algorithm", "etc", "bias", "and", "varianc", "tradeoff", "sweet", "spot", "the", "goal", "model", "train", "find", "sweet", "spot", "where", "the", "model", "cross", "valid", "error", "minimum", "initi", "both", "cross", "valid", "and", "train", "error", "are", "high", "underfittinghigh", "varianc", "the", "model", "train", "the", "error", "keep", "drop", "certain", "point", "where", "cross", "valid", "minimum", "and", "also", "close", "train", "error", "sweet", "spot", "this", "optim", "spot", "after", "this", "point", "the", "model", "further", "keep", "reduc", "error", "train", "set", "almost", "memor", "the", "train", "set", "end", "overfit", "which", "mean", "higher", "error", "unseen", "data", "regular", "some", "point", "when", "the", "model", "tri", "learn", "further", "reduc", "error", "tend", "toward", "overfit", "regular", "help", "counter", "the", "overfit", "effect", "regular", "usual", "paramet", "that", "dure", "costerror", "calcul", "machin", "learn", "algorithm", "may", "not", "alway", "provid", "regular", "paramet", "explict", "such", "case", "usual", "there", "are", "other", "paramet", "that", "can", "tune", "introduc", "regular", "the", "extent", "requir", "predict", "make", "predict", "with", "train", "machin", "learn", "model", "the", "predict", "method", "the", "model", "call", "provid", "the", "test", "dataset", "paramet", "the", "test", "dataset", "should", "preprocess", "exact", "the", "way", "done", "the", "train", "dataset", "other", "word", "the", "same", "format", "train", "data", "which", "fed", "the", "machin", "learn", "model", "for", "train", "other", "terminolog", "model", "stack", "when", "singl", "machin", "learn", "algorithm", "well", "multipl", "machin", "learn", "algorithm", "are", "use", "make", "predict", "and", "the", "predict", "are", "combin", "togeth", "differ", "way", "most", "simplest", "weight", "predict", "sometim", "other", "machin", "learn", "model", "metamodel", "use", "top", "the", "predict", "the", "first", "level", "model", "this", "could", "ani", "level", "complex", "and", "can", "have", "differ", "pipelin", "deep", "learn", "fun", "fact", "that", "major", "over", "num", "guess", "all", "the", "machin", "learn", "problem", "solv", "today", "are", "solv", "use", "just", "random", "forest", "gradient", "boost", "decis", "tree", "linear", "regress", "logist", "regress", "but", "there", "are", "some", "set", "problem", "that", "can", "not", "solv", "use", "abov", "techniqu", "problem", "like", "imag", "classif", "imag", "recognit", "natur", "languag", "process", "audio", "process", "etc", "are", "solv", "use", "techniqu", "call", "deep", "learn", "befor", "start", "deep", "learn", "believ", "essenti", "master", "all", "the", "abov", "concept", "first", "good", "deep", "learn", "resources\u2026", "fastai", "thank", "for", "the", "suggest", "pranay", "tiwari", "neuralnetworksanddeeplearningcom", "onlin", "book", "stress", "theori", "and", "fundament", "deep", "learn", "special", "coursera", "andrew", "deeplearningbookorg", "onlin", "book", "know", "deep", "learn", "concept", "and", "want", "get", "hand", "dirti", "some", "popular", "deep", "learn", "librari", "are", "kera", "tensorflow", "tflearn", "sonnet", "pytorch", "caff", "theano", "practic", "yes", "practic", "the", "most", "import", "thing", "and", "this", "guid", "would", "have", "been", "incomplet", "without", "mention", "about", "practic", "machin", "learn", "practic", "and", "master", "skill", "further", "below", "are", "the", "thing", "can", "do\u2026", "get", "dataset", "from", "various", "onlin", "data", "sourc", "one", "such", "popular", "data", "sourc", "machin", "learn", "repositori", "addit", "can", "search", "dataset", "for", "machin", "learn", "particip", "onlin", "machin", "learningdata", "scienc", "hackathon", "some", "the", "popular", "one", "are", "kaggl", "hackerearth", "etc", "end", "start", "with", "someth", "that", "veri", "difficult", "tri", "persist", "bit", "still", "feel", "difficult", "park", "asid", "and", "find", "other", "there", "need", "disappoint", "usual", "problem", "onlin", "hackathon", "have", "some", "level", "difficulti", "which", "may", "not", "alway", "suitabl", "for", "beginn", "blog", "about", "what", "learn", "help", "solidifi", "understand", "and", "thought", "about", "the", "subject", "follow", "data", "scienc", "machin", "learn", "topic", "quora", "lot", "great", "advic", "and", "questionsansw", "learn", "from", "start", "listen", "podcast", "avail", "link", "below", "check", "out", "some", "use", "link", "data", "scienc", "learn", "resourc", "page", "close", "thought", "are", "consid", "the", "field", "machin", "learningdata", "scienc", "serious", "and", "are", "think", "make", "career", "switch", "think", "about", "the", "motiv", "and", "whi", "like", "are", "sure", "have", "one", "advic", "for", "never", "ever", "ever", "give", "think", "all", "worth", "definit", "worth", "and", "can", "say", "that", "have", "walk", "that", "path", "sinc", "last", "num", "months\u2026", "almost", "everi", "day", "everi", "weekend", "and", "everi", "spare", "hour", "time", "except", "when", "travel", "total", "drown", "day", "job", "commit", "the", "road", "ahead", "master", "data", "scienc", "easi", "they", "say", "rome", "not", "built", "day", "need", "learn", "lot", "subject", "juggl", "between", "differ", "learn", "prioriti", "even", "after", "learn", "lot", "still", "find", "new", "thing", "that", "have", "never", "thoughtheard", "about", "befor", "new", "conceptstechniqu", "that", "keep", "discov", "might", "make", "feel", "that", "still", "know", "lot", "thing", "and", "there", "lot", "more", "ground", "cover", "this", "common", "just", "stick", "with", "set", "big", "goal", "plan", "for", "small", "task", "and", "just", "focus", "task", "hand", "someth", "new", "come", "just", "scribbl", "down", "diari", "and", "get", "back", "later", "thank", "have", "been", "read", "all", "the", "way", "till", "here", "appreci", "effort", "and", "the", "time", "have", "invest", "hope", "this", "guid", "use", "and", "has", "made", "littl", "easier", "for", "get", "start", "own", "learn", "adventur", "some", "later", "point", "time", "think", "this", "guid", "has", "made", "some", "differ", "learn", "adventur", "pleas", "pleas", "come", "back", "and", "leav", "comment", "here", "reach", "avannalda", "hotmail", "dot", "com", "love", "hear", "from", "give", "immens", "satisfact", "know", "that", "this", "has", "help", "and", "effort", "put", "this", "togeth", "worthwhil", "this", "biggest", "write", "ever", "have", "spent", "mani", "hour", "write", "edit", "and", "review", "this", "see", "ani", "mistak", "thing", "that", "can", "improv", "pleas", "let", "know", "comment", "via", "email", "fix", "the", "earliest", "can", "and", "will", "attribut", "this", "will", "help", "everyon", "who", "read", "this", "thank", "again", "all", "the", "best", "bio", "abhijit", "annalda", "softwar", "engin", "and", "voraci", "learner", "who", "has", "acquir", "machin", "learn", "knowledg", "and", "expertis", "fair", "extent", "improv", "expertis", "day", "day", "learn", "new", "stu\ufb00", "and", "relentless", "practic", "and", "has", "extens", "experi", "build", "enterpris", "scale", "applic", "di\ufb00er", "microsoft", "and", "open", "sourc", "technolog", "softwar", "engin", "microsoft", "india", "sinc", "june", "num", "origin", "repost", "with", "permiss", "relat", "how", "learn", "machin", "learn", "num", "day", "the", "guerrilla", "guid", "machin", "learn", "with", "python", "densiti", "base", "spatial", "cluster", "applic", "with", "nois"], "timestamp_scraper": 1556379518.600653, "title": "Getting Started with Machine Learning in One Hour!", "read_time": 990.3, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By <a href=\"https://www.linkedin.com/in/avannaldas/\" rel=\"noopener\" target=\"_blank\">Abhijit Annaldas</a>, Microsoft.</b></p>\n<p>I was planning agenda for my one hour talk. Conveying the learning paths, setting up the environment and explaining the important machine learning concepts finally made it to agenda after a lot of contemplation and thought. I initially thought about various ways this talk could have been done including - hands on python with linear regression, explaining linear regression in detail, or just sharing my learning journey that I went through past 18 months almost. But I wanted to start something that leaves the audience with lots of new information and questions to work on. Create curiosity and interest in them. And I guess I was able to do that to a decent level. Basically, to get them started with Machine Learning. That\u2019s how this guide ended up being called\u00a0<em>Getting Started with Machine Learning in one hour</em>.</p>\n<p><img alt=\"Machine learning\" class=\"aligncenter\" src=\"/wp-content/uploads/machine-learning-wordcloud.jpg\" width=\"75%\"/></p>\n<p>The notes for the talk were great for an introductory learning path, but were structured only for myself to help with the talk. Hence I wrote a machine learning getting started guide out of it and here it is. I\u2019m very happy the way this ended up taking shape and I\u2019m excited to share this!</p>\n<p>There are two main approaches to learn Machine Learning. Theoretical Machine Learning approach and Applied Machine Learning approach. I\u2019ve written about it in my earlier\u00a0<a href=\"http://abhijitannaldas.com/applied-vs-theoretical-machine-learning.html\" target=\"_blank\">blog post</a>.<br>\n\u00a0</br></p>\n<h3>Theoretical Machine Learning</h3>\n<p>\u00a0<br>\nBelow are the subjects that you can start with (ordered as I think they are appropriate). For theoretical approach of learning Machine Learning, below subjects should be studied with great rigor and in depths.</br></p>\n<ol>\n<li>Linear Algebra -\u00a0<a href=\"https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/\" target=\"_blank\">MIT</a>,\u00a0<a href=\"http://nptel.ac.in/courses/111108066\" target=\"_blank\">IISc. Bangalore</a>\n<li>Calculus -\u00a0<a href=\"https://www.coursera.org/learn/calculus1\" target=\"_blank\">Basics, Coursera</a>,\u00a0<a href=\"https://www.coursera.org/learn/advanced-calculus\" target=\"_blank\">Advanced, Coursera</a>\n<li>Probability and Statistics -\u00a0<a href=\"https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/\" target=\"_blank\">MIT</a>\n<li>Statistical Learning Theory -\u00a0<a href=\"https://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-520-statistical-learning-theory-and-applications-spring-2003/\" target=\"_blank\">MIT</a>,\u00a0<a href=\"https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about\" target=\"_blank\">Stanford</a>\n<li>Machine Learning -\u00a0<a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\">Coursera</a>,\u00a0<a href=\"https://work.caltech.edu/telecourse\" target=\"_blank\">Caltech</a>\n<li>Programming language to implement machine learning research ideas.\n</li></li></li></li></li></li></ol>\n<p>The way forward could be reading research papers, implementing research work/new algorithms, developing expertise and picking a specialization further on to the research path.<br>\n\u00a0</br></p>\n<h3>Applied Machine Learning</h3>\n<p>\u00a0</p>\n<ol>\n<li>Good understanding of the basics of above subjects (1 to 4).\n<li>Machine Learning (imp concepts explained below):\u00a0<a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\">Coursera</a>,\u00a0<a href=\"https://work.caltech.edu/telecourse\" target=\"_blank\">Caltech</a>\n<li><a href=\"https://www.datacamp.com/courses/intro-to-python-for-data-science\" target=\"_blank\">Python</a>\u00a0or R Programming Language, as per your preference.\n<li>Learn to use popular machine learning, data manipulation and visualization libraries in the chosen programming language. I personally use Python programming language, hence I\u2019ll elaborate on that below.\n<li>Must know Python Libraries:\u00a0<a href=\"https://www.datacamp.com/community/tutorials/python-numpy-tutorial\" target=\"_blank\">numpy</a>,\u00a0<a href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\" target=\"_blank\">pandas</a>,\u00a0<a href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\" target=\"_blank\">scikit-learn</a>,\u00a0<a href=\"https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python\" target=\"_blank\">matplotlib</a>\n<li>Other popular python libraries:\u00a0<a href=\"https://github.com/Microsoft/LightGBM\" target=\"_blank\">LightGBM</a>,\u00a0<a href=\"https://github.com/dmlc/xgboost\" target=\"_blank\">XGBoost</a>,\u00a0<a href=\"https://catboost.yandex/\" target=\"_blank\">CatBoost</a>\n</li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Quick Start Option</h3>\n<p>\u00a0<br>\nIf you want to get a taste of what is Machine Learning about and what it could be like. You can start this way for experimenting, getting quick hands on. Not an ideal way if you want to get serious about Data Science in long run.</br></p>\n<ol>\n<li>Know Machine Learning Concepts Overview (below)\n<li>Learn Python or R\n<li>Understand and learn to use popular libraries in your language of choice\n</li></li></li></ol>\n<p>\u00a0</p>\n<h3>Python Environment setup</h3>\n<p>\u00a0</p>\n<ol>\n<li>Python\n<ul>\n<li>Python.org\u00a0<a href=\"https://www.python.org/downloads/\" target=\"_blank\">Download</a>,\u00a0<a href=\"https://www.datacamp.com/courses/intro-to-python-for-data-science\" target=\"_blank\">Learn</a>\u00a0OR\n<li>Anaconda\u00a0<a href=\"https://www.continuum.io/downloads\" target=\"_blank\">Download</a>,\u00a0<a href=\"https://docs.continuum.io/anaconda/\" target=\"_blank\">Learn</a>\n</li></li></ul>\n<li>Code Editor / IDE\n<ul>\n<li>Visual Studio Code (Search and install python extension, pick the most downloaded one)\n<li>Notepad++\n<li><a href=\"http://jupyter.readthedocs.io/en/latest/install.html\" target=\"_blank\">Jupyter</a>\u00a0(Installs with Anaconda)\n</li></li></li></ul>\n<li>Installing python packages\n<ul>\n<li><a href=\"https://docs.python.org/3/installing/index.html\" target=\"_blank\">Managing packages with pip, python\u2019s native tool</a>:\u00a0<code>pip install &lt;package-name&gt;</code>\n<li><a href=\"https://conda.io/docs/using/pkgs.html\" target=\"_blank\">Managing packages with anaconda</a>:\u00a0<code>conda install &lt;package-name&gt;</code>\n</li></li></ul>\n<li>Managing Python (native) virtual environments (if multiple environments are needed)\n<ul>\n<li>Create virtual environment:\u00a0<code>python -m venv c:\\path\\to\\env\\folder</code>\n<li>Command help:\u00a0<code>python -m venv -h</code>\n<li>Switch environments:\u00a0<code>activate.bat</code>\u00a0script located in the virtual environment folder\n<li>Python (native) virtual environments\u00a0<a href=\"https://docs.python.org/3/library/venv.html\" target=\"_blank\">documentation</a>\n</li></li></li></li></ul>\n<li>Managing Anaconda virtual environments (if multiple environments are needed)\n<ul>\n<li>Default conda environment -\u00a0<code>root</code>\n<li>List available environments -\u00a0<code>conda env list</code>\n<li>Create new environment -\u00a0<code>conda create --name environment_name</code>\n<li>Switch to environment -\u00a0<code>activate environment_name</code>\u00a0or\u00a0<code>source activate environment_name</code>\n<li>Anaconda virtual environments\u00a0<a href=\"https://conda.io/docs/using/envs.html\" target=\"_blank\">documentation</a>\n</li></li></li></li></li></ul>\n</li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Machine Learning Concepts Overview</h3>\n<p>\u00a0</p>\n<ul>\n<li><strong>Machine Learning</strong>: Is an approach to find patterns from a large set of data through a function\u00a0<em>f(x)</em>\u00a0which effectively generalizes to unseen\u00a0<em>x</em>\u00a0to find learned patterns in unseen data and make the inferences the Machine Learning Model was trained for.\n<li><strong>Dataset</strong>: Data being used to apply machine learning and find patterns from. For supervised type of machine learning applications, the dataset contains both\u00a0<em>x</em>\u00a0(input/attributes/independent variables) and\u00a0<em>y</em>\u00a0(target/labels/dependent variables) data. For unsupervised data it\u2019s just\u00a0<em>x</em>, input and the output of the data is some sort of learned patterns (like clusters, groups, etc.)\n<li><strong>Train set</strong>: A subset of\u00a0<em>Dataset</em>\u00a0fed to (train) machine learning algorithm to learn patterns\n<li><strong>Evaluation / Validation / Cross Validation Set</strong>: Subset of\u00a0<em>Dataset</em>\u00a0not in\u00a0<em>Train set</em>\u00a0used to evaluate how the machine learning algorithm is doing.\n<li><strong>Test set</strong>:\u00a0<em>Dataset</em>\u00a0to predict learned insights for. For supervised problems, target/label\u00a0<em>y</em>\u00a0like in\u00a0<em>train set</em>\u00a0is to be predicted and hence it isn\u2019t a part of\u00a0<em>train set</em>. For unsupervised,\u00a0<em>train</em>\u00a0and\u00a0<em>test</em>\u00a0sets can be identical.\n<li><strong>Types</strong>:\n<ul>\n<li><strong>Supervised</strong>: In supervised problems, the historical data includes the labels (target attribute, outcomes) that need to be predicted for future/unseen data. For example, for housing price prediction we have data about house (area, # of bedrooms, location, etc.) and price. Here the after training a machine learning model with given data (X - data) and price (Y - labels), in future, price (Y) will be predicted for new/unseen data (X).\n<li><strong>Unsupervised</strong>: In unsupervised learning, there is no label or target attribute. A typical example would be clustering data based on learned patterns. Like for a dataset of house details (area, location, price, # of bedrooms, # of floors, built date, etc.) the algorithm needs to find if there is any hidden patterns. For example some houses are very expensive while some others are of usual price. Some houses are very big while some houses are of usual size. With these patterns, records/data is clustered into groups like Luxury-Homes, Non-Luxury Homes, Bunglows, Apartment, etc.\n<li><strong>Reinforcement</strong>: In Reinforcement Learning, an \u2018Agent\u2019 acts in an \u2018Environment\u2019 and receives positive or negative feedback. Positive feedback tells an agent that it has done well, and agent proceeds on similar plan/action. Negative feedback tells an agent that it has done something wrong, and should change it\u2019s course of action. The agent and the environment are software/programmed implementations. The core of reinforcement learning is building an agent (or agent\u2019s behaviour in some way) that learns to successfully accomplish a specific task in an environment.\n</li></li></li></ul>\n<li><strong>Popular Algorithms</strong>:\u00a0<a href=\"https://en.wikipedia.org/wiki/Linear_regression\" target=\"_blank\">Linear Regression</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" target=\"_blank\">Logistic Regression</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Support_vector_machine\" target=\"_blank\">Support Vector Machines</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\" target=\"_blank\">K-Nearest-Neighbors</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Decision_tree\" target=\"_blank\">Decision Trees</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Random_forest\" target=\"_blank\">Random Forest</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Gradient_boosting\" target=\"_blank\">Gradient Boosting</a>,\u00a0<a href=\"https://en.wikipedia.org/wiki/Ensemble_learning\" target=\"_blank\">Ensemble Learning</a>\n<li><strong>Preprocessing</strong>: In real world scenario data is rarely clean and neat in a state that Machine Learning algorithms can be directly applied on. Preprocessing is a process of cleaning data to feed to machine learning algorithm. Some of the common preprocessing steps are\u2026\n<ul>\n<li><strong>Missing Value</strong>: When some of the values are missing, they are usually dealt by adding median/mean values or deleting corresponding row, or using the value from the previous row, etc. There are many ways of doing this. What exactly needs to be done depends on the kind of data, problem being solved and business goals.\n<li><strong>Categorical Variables</strong>: Discrete finite set of values. Like \u2018car type\u2019, \u2018department\u2019, etc. These values are converted either into numbers or vectors. Conversion to vectors is known as\u00a0<a href=\"https://en.wikipedia.org/wiki/One-hot\" target=\"_blank\">One-Hot</a>\u00a0Encoding. There are numerous ways of doing this in python. Some machine learning algorithms/libraries themselves handle categorical columns by encoding internally. One way of encoding is using\u00a0<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" target=\"_blank\">sklearn.preprocessing.OneHotEncoder</a>\u00a0in scikit-learn.\n<li><strong>Scaling</strong>: Proportionately reducing values in columns into a common scale like 0 to 1. Having values in all columns in a common range might improve accuracy and training speed to some extent.\n<li><strong>Text</strong>: Text needs to be processed using Natural Language Processing techniques (out of scope of this guide), when it isn\u2019t preprocessed, it is usually excluded from the training data that is fed to a machine learning algorithm.\n<li><strong>Imbalanced datasets</strong>: The data shouldn\u2019t be biased, skewed. For e.g., consider a classification task where an algorithm classifies data into 3 different classes - A, B and C. If the dataset has very few/high records of one class w.r.t. others it is said to be biased/imbalanced. Usually data is oversampled in such cases by synthetically generating more random data from existing data. Some machine learning algorithms/libraries allow providing weights or some parameter to balance out the skew internally without us doing the heavy lifting of fixing a skewed dataset. For example,\u00a0<a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\" target=\"_blank\">SVM: Separating hyperplane for unbalanced classes</a>\u00a0in scikit-learn.\n<li><strong>Outliers</strong>: Outliers need to be dealt with on a case by case basis based on the problem and business case.\n</li></li></li></li></li></li></ul>\n<li><strong>Data Transformation</strong>: When a column/attribute in a dataset doesn\u2019t have an inherent pattern, it is transformed into something like log(values), sqrt(values), etc. where the transformed values might have interesting pattern/uniformity that can be learned. This is again, obviously case by case basis and needs data exploration to find a right fit.\n<li><strong>Feature Engineering</strong>: Feature Engineering is a process of deriving hidden insights from existing data. Consider a housing price prediction dataset which has columns \u2018plot-width\u2019, \u2018plot-length\u2019, \u2018number of bedrooms\u2019 and \u2018price\u2019. Here we see a key attribute area of the house is missing, but can be calculated based on \u2018plot-width\u2019 and \u2018plot-length\u2019. So a calculated column, \u2018area\u2019 is added to the dataset. This is known as feature engineering. Feature Engineering might be of different difficulty level, sometimes a derived attribute is right in front of sight like here, sometimes it\u2019s really hidden and needs lot of thinking.\n<li><strong>Training</strong>: This is a main step where the machine learning algorithm is trained on the given data to find generalized patterns to be applied on unseen data. Below are some important nitty-gritty details of this phase\u2026\n<ul>\n<li><strong>Feature Selection</strong>: Not all features/columns contribute to the learning. These are the columns where the data in them don\u2019t affect the outcome. Such features are removed from the dataset. What features to train on and what features to exclude is decided based on feature importance given by a machine learning algorithm being applied. Most of the modern algorithms do provide the feature importances. If an algorithm doesn\u2019t provide, scikit-learn has\u00a0<a href=\"http://scikit-learn.org/stable/modules/feature_selection.html\" target=\"_blank\">capabilities</a>\u00a0which can help in feature selection. Also correlated features are removed.\n<li><strong>Dimensionality Reduction</strong>:\u00a0<a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\" target=\"_blank\">Dimentionality reduction</a>\u00a0also aims to find the most important features of all the features, aiming to reduce the\u00a0<a href=\"https://en.wikipedia.org/wiki/Curse_of_dimensionality\" target=\"_blank\">dimensionality</a>\u00a0of the data. The main difference w.r.t. feature importance based feature selection is that, in Dimensionality Reduction, a subset of features and/or derived features are selected. In other words, we may not be able to map the extracted features to the original features. You can find more about dimensionality reduction in scikit-learn\u00a0<a href=\"http://scikit-learn.org/stable/modules/unsupervised_reduction.html#\" target=\"_blank\">here</a>.\n<li><strong>Feature Selection vs Dimensionality Reduction</strong>: In my opinion, one of the two ways should solve the purpose. If we do both feature selection based on feature importance and dimensionality reduction, we should first do based on feature importances. And then introduce dimensionality reduction. It goes without saying that we should evaluate the performance at every step to understand what\u2019s working and what\u2019s not. Feature selection based on feature importance is easy to interpret as the selected features are subset of all, which isn\u2019t a case with dimensionality reduction.\n<li><strong>Evaluation Metric</strong>: Evaluation metric is a metric used to evaluate predictions for their correctness. A machine learning algorithm while training uses an evaluation metric to evaluate, compute cost and optimize on the cost convex function. Though each algorithm has a default evaluation metric, it is recommended to specify the exact evaluation metric as per the business case/problem. Like some problems can afford false positives, but cannot afford any false negatives. By specifying the evaluation metric, these nitty gritty details of the model can be controlled.\n<li><strong>Parameter tuning</strong>: Though most of the today\u2019s state of the art algorithms have sensible default values for the parameters, it always helps to tune the parameters to control the accuracy of a model and improve overall predictions. Parameter tuning can be done on a trial and error basis by repeatedly changing and assessing the accuracy. Alternatively a set of parameter values can be provided to try all/different permutations of those parameters and find the best parameter combination. This can be done using some helper functions called\u00a0<a href=\"http://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers\" target=\"_blank\">Hyper-parameter Optimizers in scikit-learn</a>.\n<li><strong>Overfitting (Bias)</strong>: Overfitting is a state where the machine learning model almost memorizes all the training data and predicts almost accurately on data that\u2019s already in training set. This is a state where the model fails to generalize and predict on unseen data. This is also known as model having high bias. Overfitting can be dealt with using Regularization, tuning hyperparameters if configured inappropriately, holding off partial dataset to use correct cross validation<a href=\"http://scikit-learn.org/stable/modules/cross_validation.html\" target=\"_blank\">(1)</a><a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\" target=\"_blank\">(2)</a>\u00a0strategy.\n<li><strong>Underfitting (Variance)</strong>: Underfitting is a state where the machine learning model\u2019s predictions don\u2019t do well even when predicting on data already in the training set. This is also known as model having high variance. Underfitting can be dealt with adding more data, adding/removing features, trying different machine learning algorithm, etc.\n<li><strong>Bias and Variance trade-off (sweet spot)</strong>: The goal of model training is to find a sweet spot where the model cross validation error is minimum. Initially both cross validation and train error are high (Underfitting/high variance). As the model is training, the error keeps dropping to a certain point where cross validation is minimum and also close to train error (sweet spot). This is optimal spot. After this point, if the model further keeps reducing error (on train set), it almost memorizes the train set ends up overfitting which means higher error on unseen data.\n<li><strong>Regularization</strong>: At some point when the model is trying to learn further (reducing error, tending towards overfitting), regularization helps in countering the overfitting effects. Regularization is usually a parameter that\u2019s added during cost/error calculation. Machine learning algorithms may not always provide regularization parameter explictly. In such case, usually there are other parameters that can be tuned to introduce regularization to the extent required.\n</li></li></li></li></li></li></li></li></li></ul>\n<li><strong>Prediction</strong>: To make predictions with trained machine learning model, the prediction method of the model is called by providing the test dataset as parameter. The test dataset should be preprocessed exactly the way it was done on the training dataset. In other words, in the same format of training data which was fed to the machine learning model for training.\n<li><strong>Other terminologies</strong>:\n<ul>\n<li><strong>Model Stacking</strong>: When single machine learning algorithm doesn\u2019t do well, multiple machine learning algorithms are used to make predictions and the predictions are combined together in different ways. Most simplest being a weighted predictions. Sometimes, other machine learning model (meta-model) is used on top of the predictions of the first level models. This could go to any level of complexity and can have different pipelines.\n</li></ul>\n</li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n<p>\u00a0</p>\n<h3>Deep Learning</h3>\n<p>\u00a0<br/>\nFun fact is that a majority (over 90% I guess) of all the machine learning problems solved today are solved using just Random Forests, Gradient Boosted Decision Trees, SVM, KNN, Linear Regression, Logistic Regression.</p>\n<p>But, there are some set of problems that cannot be solved using above techniques. Problems like image classification, image recognition, natural language processing, audio processing, etc. are solved using a technique called Deep Learning. Before starting deep learning, I believe it\u2019s essential to master all of the above concepts first.</p>\n<p>Good Deep Learning resources\u2026</p>\n<ul>\n<li><a href=\"http://www.fast.ai/\" target=\"_blank\">Fast.ai</a>\u00a0\u2013 thanks for the suggestion\u00a0<a href=\"https://www.linkedin.com/in/pranay-tiwari-47a49048/\" target=\"_blank\">Pranay Tiwari</a>!\n<li><a href=\"http://neuralnetworksanddeeplearning.com/\" target=\"_blank\">neuralnetworksanddeeplearning.com - an online book, stresses on theory and fundamentals</a>\n<li><a href=\"https://www.coursera.org/specializations/deep-learning\" target=\"_blank\">Deep Learning Specialization at Coursera by Andrew Ng</a>\n<li><a href=\"http://www.deeplearningbook.org/\" target=\"_blank\">deeplearningbook.org - an online book</a>\n</li></li></li></li></ul>\n<p>If you know deep learning concepts and want to get your hands dirty, some popular Deep Learning Libraries are:\u00a0<a href=\"https://keras.io/\" target=\"_blank\">Keras</a>,\u00a0<a href=\"https://github.com/Microsoft/CNTK\" target=\"_blank\">CNTK</a>,\u00a0<a href=\"https://github.com/tensorflow/tensorflow\" target=\"_blank\">Tensorflow</a>,\u00a0<a href=\"https://github.com/tflearn/tflearn\" target=\"_blank\">tflearn</a>,\u00a0<a href=\"https://github.com/deepmind/sonnet\" target=\"_blank\">sonnet</a>,\u00a0<a href=\"https://github.com/pytorch/pytorch\" target=\"_blank\">pytorch</a>,\u00a0<a href=\"https://github.com/BVLC/caffe\" target=\"_blank\">caffe</a>,\u00a0<a href=\"https://github.com/Theano/Theano\" target=\"_blank\">Theano</a><br/>\n\u00a0</p>\n<h3>Practice</h3>\n<p>\u00a0<br/>\nYes, practice is the most important thing and this guide would have been incomplete without mentioning about practicing machine learning. To practice and master your skills further, below are the things you can do\u2026</p>\n<ol>\n<li>Get datasets from various online data sources. One such popular data source is\u00a0<a href=\"http://abhijitannaldas.com/getting-started-with-machine-learning-in-one-hour/archive.ics.uci.edu/ml/\" target=\"_blank\">UCI Machine Learning Repository</a>. Additionally, you can\u00a0<a href=\"http://google.com/search?q=datasets+for+machine+learning\" target=\"_blank\">search \u2018datasets for machine learning\u2019</a>.\n<li>Participate in online machine learning/data science hackathons. Some of the popular ones are -\u00a0<a href=\"http://kaggle.com/\" target=\"_blank\">Kaggle</a>,\u00a0<a href=\"http://www.hackerearth.com/\" target=\"_blank\">HackerEarth</a>, etc. If you end up starting with something that\u2019s very difficult, try persisting a bit. If it still feels difficult, park it aside and find other. There\u2019s no need to be disappointed. Usually problems on online hackathon have some level of difficulty which may not always be suitable for beginners.\n<li>Blog about what you learn! It\u2019ll help you solidify your understanding and thoughts about the subject.\n<li>Follow Data Science, Machine Learning topics on Quora, lot of great advice and questions/answers to learn from.\n<li>Start listening to podcasts (available on link below)\n<li>Check out some useful links on my\u00a0<a href=\"http://abhijitannaldas.com/useful-stuff/\" target=\"_blank\">Data Science Learning Resources</a>\u00a0page.\n</li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Closing thoughts</h3>\n<p>\u00a0<br/>\nIf you are considering the field of Machine Learning/Data Science seriously and you are thinking of making a career switch, think about the your motivations and why you\u2019d like to do it.</p>\n<p>If you are sure, I have one advice for you.\u00a0<strong><em>Never ever ever give up or think if its all worth it</em></strong>. It\u2019s definitely worth it and I can say that as I have walked that path since last 18 months\u2026 almost every day, every weekend and every spare hour of my time (except when I was travelling or I was totally drowned by my day job commitments). The road ahead to master data science isn\u2019t easy. As they say,\u00a0<em>\u201cRome was not built in a day!\u201d</em>. You\u2019ll need to learn lot of subjects. Juggle between different learning priorities. Even after learning a lot you\u2019ll still find new things that you have never thought/heard about before. New concepts/techniques that you keep discovering might make you feel that you still don\u2019t know a lot of things and there is a lot more ground to cover. This is common. Just stick with it. Set big goals, plan for small tasks and just focus on task at hand. If something new comes up, just scribble it down in your diary and get back to it later.<br/>\n\u00a0</p>\n<h3>Thank You!</h3>\n<p>\u00a0<br/>\nIf you have been reading all the way till here, I appreciate your effort and the time you have invested. I hope this guide was useful to you and has made it little easier for you to get started on your own learning adventure. At some later point of time, if you think this guide has made some difference in your learning adventure, please please come back and leave a comment here. Or reach me at avannaldas .at. hotmail .dot. com. I\u2019d love to hear from you. It\u2019ll give me immense satisfaction to know that this has helped you, and my effort in putting this together was worthwhile.</p>\n<p>This was my biggest write up ever. I have spent many hours writing, editing and reviewing this. If you see any mistakes or things that can be improved, please let me know in comments or via email. I\u2019ll fix it the earliest I can and will attribute it to you. This will help everyone who reads this.</p>\n<p>Thanks Again!</p>\n<p>All the best!</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/avannaldas/\" target=\"_blank\">Abhijit Annaldas</a></b> is a Software Engineer and a voracious learner who has acquired Machine Learning knowledge and expertise to a fair extent. He is improving expertise day by day by learning new stu\ufb00 and relentless practice, and has extensive experience building enterprise scale applications in di\ufb00erent Microsoft and Open Source technologies as a Software Engineer at Microsoft, India since June 2012.</p>\n<p><a href=\"http://abhijitannaldas.com/getting-started-with-machine-learning-in-one-hour/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/05/learn-machine-learning-10-days.html\">How to Learn Machine Learning in 10 Days</a>\n<li><a href=\"/2017/05/guerrilla-guide-machine-learning-python.html\">The Guerrilla Guide to Machine Learning with Python</a>\n<li><a href=\"/2017/10/density-based-spatial-clustering-applications-noise-dbscan.html\">Density Based Spatial Clustering of Applications with Noise (DBSCAN)</a>\n</li></li></li></ul>\n</div> ", "website": "kdnuggets"}