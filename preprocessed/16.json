{"content": "By William Schmarzo , Hitachi Vantara. In the blog \u201c From Autonomous to Smart: Importance of Artificial Intelligence ,\u201d we laid out the artificial intelligence (AI) challenges in creating \u201csmart\u201d edge devices: Artificial Intelligence Challenge #1: How do the Artificial Intelligence algorithms handle the unexpected, such as flash flooding, terrorist attacks, earthquakes, tornadoes, police car chases, emergency vehicles, blown tires, a child chasing a ball into the street,\u00a0etc.? Artificial Intelligence Challenge #2: The more complex the problem state, the more data storage (to retain known state history) and CPU processing power (to find the optimal or best solution) is required in the edge devices in order to create \u201csmart.\u201d We also talked about how Moore\u2019s Law isn\u2019t going to bail us out of these challenges; that the growth of Internet of Things (IOT) data and the complexity of the problems that we are trying to address at the edge (think \u201csmart\u201d cars) is growing much faster than Moore\u2019s Law can accommodate. So we are going to use this blog to deep dive into the category of artificial intelligence called reinforcement learning. \u00a0We are going to see how reinforcement learning might help us to address these challenges; to work smarter at the edge when brute force technology advances will not suffice. \u00a0 Why Not Brute Force \u00a0 With the rapid increases in computing power, it\u2019s easy to get seduced into thinking that raw computing power can solve problems like smart edge devices (e.g., cars, trains, airplanes, wind turbines, jet engines, medical devices). But to understand the scope of the challenge, consider the following: Checkers has 500 billion billion (that\u2019s right, billion twice) possible board moves. That\u2019s 500,000,000,000,000,000,000 possible moves (that\u2019s 20 zeros). The number of possible moves in a game of chess is a minimum of 10 120 moves (that\u2019s 120 zeros). Look at the dramatic increase in the number of possible moves between checkers and chess even though the board layout is exactly the same . The only difference between checkers and chess is the types of moves that pieces can make. A checker has only two moves: forward diagonally and jump competitor\u2019s pieces diagonally (once a checker is \u201ckinged\u201d, then it can move diagonally both forward and backwards). In chess, the complexity of the chess piece only increases slightly (rooks can move forward and sideways a variable number of spaces, bishops can move diagonally a variable number of spaces, etc.), but the complexity of the potential solutions exploded (from 20 zeros to 120 zeros). And both checkers and chess operate in a deterministic environment, where all possible moves are known ahead of time and there are no surprises (unless your dog decides that he wants to play at the same time). Now think about the number and breadth of \u201cmoves\u201d or variables that need to be considered when driving a car in a nondeterministic (random) environment:\u00a0 weather (precipitation, snow, ice, black ice, wind), time of day (day time, twilight, night time, sun rise, sun set), road conditions (pot holes, bumpy, slick), traffic conditions (number of vehicles, types of vehicles, different speeds, different destinations). One can quickly see that the number of possible moves is staggering. We need a better answer than brute force. \u00a0 Reinforcement Learning to the Rescue \u00a0 Reinforcement Learning is for situations where you don\u2019t have data sets with explicit known outcomes, but you do have a way to telling whether you are getting closer to your goal ( reward function ). Reinforcement learning learns through trial-and-error how to map situations to actions so as to maximize rewards. Actions may affect immediate rewards but actions may also affect subsequent or longer-term rewards, so the full extent of rewards must be considered when evaluating the reinforcement learning effectiveness (i.e., balancing short-term rewards like optimizing fuel consumption while driving a car balanced against the long-term rewards of getting to your destination on time and safely). Reinforcement learning is used to address two general problems: Prediction: How much reward can be expected for every combination of possible future states (e.g., how much can we collect from delinquent accounts based on the following steps?) Control: By moving through all possible combinations of the environment (interacting with the environment or state space), find a combination of actions that maximizes reward and allows for optimal control (e.g., steering an autonomous vehicle, winning a game of chess). The children\u2019s game of \u201cHotter or Colder\u201d is a good illustration of reinforcement learning; rather than getting a specific \u201cright or wrong\u201d answer with each data action, you\u2019ll get a delayed reaction and only a hint of whether you\u2019re heading in the right direction (hotter or colder). \u00a0 Reinforcement Learning and Video Games \u00a0 Reinforcement learning needs lots and lots of data from which to learn and very powerful compute to support its \u201ctrial and error\u201d learning approach. Because it can take a considerable amount of time to gather enough data across enough scenarios in the real world, many of the advances in reinforcement learning are occurring from playing against video games. One such example is the MarI/O program (\u2018 MarI/O AI Program Learns To Play Super Mario World\u2019 ). MarI/O is an artificial intelligence application that has learned how to play the video game \u201cSuper Mario World\u201d (see Figure 1). Figure 1: MarI/O Playing \u201cSuper Mario World\u201d Video Game Some key points to learn from MarI/O: MarI/O uses random steps to start its exploration process and to re-start whenever it stalls. MarI/O takes inputs by sensing white boxes (safe landing areas) and black boxes (obstacles). Rewards (Fitness points in the case of Mario Brothers) and punishment (death) guide the learning process (try to maximize rewards while minimizing or eliminating punishments) Sometimes losing (failing) is the only way to learn. Figure 2 shows the progress that MarI/O made in learning the environment in order to maximize its fitness points and survive. Figure 2:\u00a0MarI/O Learning Curve But \u201cMario Super World\u201d is a deterministic or known environment where the gaming patterns repeat themselves. For example, the chart in Figure 2 doesn\u2019t show any regressions in performance, where the AI model hit a dead end and had to retreat and re-set itself. Retreating is a common behavior that the more advanced AI models must support. And the game playing strategy in this model is very simple \u2013 just survive. There is no strategy to maximize the number of coins captured, which is an equally important part of playing Super Mario World (or at least if you want bragging rights with your friends). So while the exercise is definitely educational, it\u2019s not terribly application for our smart car example. \u00a0 Grand Theft Auto to the Rescue! \u00a0 Applying reinforcement learning to teach a car to drive requires an unbelievably huge quantity of data. Having a bunch of autonomous car tooling around the \u2018hood just can\u2019t generate enough data fast enough to optimize the models necessary to safely drive a vehicle. However, autonomous car companies have discovered a much richer training environment \u2013 Grand Theft Auto! The virtual environment within the video game Grand Theft Auto is so realistic that it is being used to generate data that\u2019s nearly as good as that generated by using real-world imagery. The most current version of Grand Theft Auto has 262 types of vehicles, more than 1,000 different unpredictable pedestrians and animals, 14 weather conditions and countless bridges, traffic signals, tunnels and intersections. It\u2019s nearly impossible for an autonomous car manufacturer to operate enough vehicles in enough different situations to generate the amount of data that can be virtually gathered by playing against Grand Theft Auto. \u00a0 Reinforcement Learning Summary \u00a0 Ultimately, reinforcement learning model development is going to need to wrestle with real (not virtual) random obstacles that pop up in the normal driving of a vehicle. Grand Theft Auto might be great for teaching vehicles how to operate in an environment with hoodlums, robberies, heists and gratuitous car chases, but more real-world experience is going to be needed in order for autonomous cars to learn to handle the random, life-endangering threats, such as a child chasing a ball into the street, a new pothole caused by some (undocumented) construction or random debris falling off of truck beds. One recent technology development that might be the key to solving \u201cimpossible\u201d problems like autonomous driving is quantum computing. A future blog will explore how combining artificial intelligence with quantum computing might just help us solve the \u201cimpossible\u201d problems. \u00a0 Article Sources: Reinforcement Learning and the Internet of Things /2016/08/reinforcement-learning-internet-things.html", "title_html": "<h1 id=\"title\">Transforming from Autonomous to Smart: Reinforcement Learning Basics</h1> ", "url": "https://www.kdnuggets.com/2017/08/transforming-autonomous-smart-reinforcement-learning-basics.html", "tfidf": {"tfidf": {"real": 4.56206896552, "realist": 12.9494290375, "fall": 1.6945244956799999, "onc": 1.4974533106999999, "fit": 6.74140127388, "play": 11.71120331952, "signal": 5.12459651388, "immedi": 2.02862254025, "delay": 4.23247134098, "space": 7.19456193354, "grow": 2.27287043665, "number": 8.81143332872, "use": 5.148193786899999, "etc": 8.413354531, "specif": 1.8719490626099997, "function": 2.495441685, "retreat": 14.194009834600001, "dog": 6.26272189349, "unexpect": 9.88542963885, "whether": 4.41367806506, "terribl": 14.5517873511, "speed": 3.8703071672400005, "creat": 2.4985835694, "approach": 2.07556543339, "hint": 15.2068965517, "vehicl": 42.23588530887, "retain": 2.74956702459, "suffic": 64.5365853659, "equal": 2.542193755, "shortterm": 1323.0, "ahead": 5.625797306869999, "breadth": 49.9245283019, "polic": 3.15, "how": 14.422529524589999, "land": 1.7209756097599997, "reaction": 4.67904509284, "bunch": 40.5, "obstacl": 27.926121371999997, "children": 1.91484742492, "had": 1.0475750577399998, "increas": 3.9607484407499998, "surviv": 4.515358361780001, "end": 1.10680423871, "deep": 3.6279707495399998, "will": 2.44962197192, "bumpi": 305.307692308, "scenario": 15.3986420951, "consid": 3.7191941277600007, "determinist": 200.962025316, "pop": 7.33302540416, "terrorist": 12.7008, "new": 1.0178880554, "near": 2.57539135372, "but": 6.09794507394, "schmarzo": 1323.0, "definit": 3.24, "need": 7.186311787049999, "our": 2.35758835759, "precipit": 10.08, "off": 1.5121440137200002, "expect": 2.20011086475, "coin": 6.00681044268, "applic": 6.85344269372, "mario": 264.6, "richer": 47.25, "has": 4.1745990008, "have": 4.059579364559999, "realworld": 2646.0, "moor": 12.97588884348, "experi": 1.87062566278, "subsequ": 1.7534791252500002, "out": 2.12033388982, "model": 10.452989202000001, "good": 3.03963239518, "child": 6.41066020594, "rescu": 12.7313552526, "hoodlum": 635.04, "huge": 4.38927287808, "categori": 3.98194130926, "optim": 46.1511627908, "forward": 10.99699838376, "situat": 6.198334200930001, "attack": 1.97094972067, "tire": 12.5106382979, "not": 4.06269592476, "storag": 8.623574144489998, "growth": 3.15062512403, "minim": 6.10850327049, "condit": 5.774490785639999, "restart": 32.2682926829, "quick": 2.205, "easi": 5.2937645882, "handl": 7.845811712380001, "though": 1.36076112111, "then": 1.08657860516, "jet": 9.28964306612, "jump": 8.07117437722, "effect": 1.3963060686000002, "allow": 1.2716059271100002, "world": 6.68041237116, "minimum": 6.02962400304, "outcom": 7.48867924528, "blog": 42.5630026809, "construct": 1.9320920043799998, "internet": 9.96923076924, "wind": 9.76383763838, "twice": 3.7638691322900004, "progress": 2.44697903822, "simpl": 3.3981164383599998, "day": 2.36743215032, "itself": 1.74557449148, "algorithm": 27.9507042254, "longterm": 512.129032258, "develop": 2.3911439114400004, "intersect": 12.660287081300002, "pattern": 3.79173632673, "chase": 35.959229898080004, "explor": 6.79187165776, "brag": 130.131147541, "lot": 8.81755068036, "box": 8.25370418508, "sourc": 1.69760479042, "control": 2.93918356012, "both": 2.10431440122, "may": 2.10403551786, "punish": 12.283172147, "summari": 7.80147420147, "smart": 100.481012658, "theft": 118.92134831460001, "brute": 258.8478260871, "devic": 20.03280757096, "set": 2.37415881562, "caus": 1.38521943984, "ani": 1.13383802314, "king": 2.0281042411900003, "virtual": 12.338860103640002, "from": 6.00340328982, "slick": 65.6033057851, "account": 1.94463498285, "answer": 9.29780380674, "behavior": 5.52978056426, "dive": 16.085106383, "num": 18.00567072018, "technolog": 5.206953099380001, "william": 1.75483585719, "environ": 30.92057996103, "curv": 11.1098670399, "safe": 15.08169727677, "balanc": 8.90659186536, "for": 8.00252032008, "car": 42.44919786096, "predict": 5.18484650555, "chess": 192.6031195844, "friend": 2.20194174757, "closer": 5.5666199158500005, "with": 8.009585671919998, "teach": 7.9718804921, "forc": 3.9719789842499997, "steer": 18.0, "think": 8.721479582490002, "are": 7.20934155046, "solut": 9.4556283502, "better": 2.0065722952500002, "compani": 1.5523613963, "turbin": 35.0463576159, "current": 1.5325803649, "work": 1.11520089913, "sens": 2.8365195640499996, "look": 1.9086318826599997, "airplan": 17.6204217536, "video": 16.4859813084, "futur": 3.7154224198400003, "law": 3.5947016868599997, "longerterm": 1323.0, "veri": 2.51760228354, "variabl": 26.241322314059996, "reset": 65.3333333333, "want": 3.99396226416, "unless": 5.44818119423, "combin": 6.79041916168, "educ": 2.00733341763, "ice": 11.537790697680002, "general": 1.1218202374200001, "map": 4.0728578758300005, "bail": 33.4231578947, "wrong": 5.478260869570001, "even": 1.16461267606, "scope": 10.3494132986, "emerg": 2.1131372288, "train": 3.8731397901999998, "rook": 211.68, "goal": 3.28152128979, "death": 1.6253071253100002, "error": 6.04109589041, "chart": 8.45367412141, "trial": 4.04175152749, "debri": 28.1489361702, "reinforc": 96.80487804885001, "white": 1.86930413282, "anim": 2.8395635843299996, "into": 4.06009845916, "delinqu": 98.0, "medic": 3.27542809986, "lifeendang": 1323.0, "rapid": 2.62586834271, "requir": 3.05689804564, "where": 4.26860254084, "figur": 10.171706816999999, "bishop": 6.72997032641, "tell": 3.36142282448, "head": 1.57781753131, "against": 3.8706216984899995, "help": 2.79925945518, "affect": 4.958925503680001, "pot": 21.2530120482, "elimin": 3.67670217693, "potenti": 2.52080025405, "consider": 2.29920347574, "undocu": 106.55033557, "least": 1.6165359943000002, "base": 1.14628158845, "occur": 1.7453825857499998, "grand": 18.38918918916, "weather": 10.788990825680001, "decid": 1.9257641921400002, "start": 1.26673581744, "explod": 12.432263116700002, "unpredict": 32.2028397566, "black": 3.89834254144, "through": 2.14149861738, "surpris": 4.36633663366, "much": 4.7768918309199995, "evalu": 6.9509632224199995, "about": 2.12972030318, "problem": 10.60048965054, "imageri": 19.7955112219, "board": 4.96435272046, "thing": 4.813096862219999, "wrestl": 20.458762886600002, "just": 4.00740429111, "billion": 14.6008583691, "bridg": 3.7067476068199996, "bed": 7.6918604651199995, "exercis": 4.73627684964, "vantara": 1323.0, "competitor": 11.9818867925, "stagger": 31.3754940711, "ball": 13.27979924718, "across": 1.7318642958400001, "complex": 9.3608490566, "colder": 90.2045454546, "destin": 12.100609756099999, "tool": 4.99716713881, "great": 1.26592775696, "whenev": 11.622254758399999, "articl": 2.01805008262, "guid": 2.49113447356, "countless": 27.9015817223, "consumpt": 9.3608490566, "whi": 3.2566153846200003, "order": 3.7387550043299997, "lose": 3.0851146521599997, "support": 2.5371154614400004, "accommod": 5.70668583753, "mani": 1.04426757877, "appli": 2.2972073506, "the": 72.0, "step": 5.655860349119999, "manufactur": 3.3578680202999998, "flash": 12.6703910615, "same": 2.23715916296, "laid": 4.86993865031, "exact": 3.46864758575, "there": 2.08182533438, "move": 18.07759251732, "possibl": 11.3389875904, "best": 1.5828514456600002, "exampl": 4.51450236966, "right": 5.621813031159999, "illustr": 3.6614391143900002, "blown": 25.3610223642, "slight": 3.25327868852, "take": 2.27923336444, "follow": 2.09280253098, "now": 1.160780873, "hitachi": 189.0, "strategi": 8.88416340236, "tri": 3.7089125102199993, "discov": 2.52160101652, "twilight": 39.9899244332, "interact": 4.4185917061, "full": 1.66729678639, "than": 4.131147541, "regress": 51.2129032258, "power": 5.358535144719999, "edg": 22.285233015150002, "also": 2.02953020134, "around": 1.21394708671, "pothol": 360.818181818, "robberi": 26.592964824099997, "hole": 8.14153846154, "area": 1.3881262568900001, "gratuit": 203.53846153799998, "quantum": 57.8360655738, "smarter": 170.709677419, "zero": 35.00771775084, "challeng": 15.349017080220001, "snow": 8.64235166032, "captur": 2.88026124819, "talk": 3.0303493033, "street": 4.73415834204, "themselv": 2.05967825636, "howev": 1.0945191313299998, "intellig": 33.54675118856, "pedestrian": 25.0410094637, "earthquak": 12.3548638132, "piec": 9.72396896694, "nondeterminist": 1323.0, "win": 2.75290445639, "backward": 14.605335786600001, "histori": 1.20629131525, "maxim": 64.64169381100001, "which": 2.01038369, "like": 3.44755700325, "such": 3.18454132122, "tunnel": 11.323823109800001, "raw": 10.6478873239, "sideway": 76.6956521739, "one": 3.01882487166, "show": 2.5340782123, "known": 4.343638850880001, "fast": 4.8729281768, "ultim": 2.58524670249, "see": 3.81726376533, "some": 2.08073394496, "becaus": 1.1495184997499999, "auto": 91.857280617, "explicit": 5.819648093840001, "seduc": 49.3043478261, "sun": 8.77854575616, "get": 8.92812956925, "random": 35.9510869565, "brother": 2.58104373273, "diagon": 151.923444976, "collect": 1.64109985528, "autonom": 77.60614525160001, "process": 5.08574479446, "fuel": 5.59014084507, "that": 21.08366533875, "recent": 1.54405757635, "understand": 2.96858638743, "repeat": 2.8771293947099994, "gather": 7.57262103506, "road": 2.49819040126, "super": 36.90376569040001, "hotter": 175.4254143646, "numreinforcementlearninginternetthingshtml": 1323.0, "part": 1.04330682789, "hood": 19.1507840772, "perform": 1.5313977042500002, "differ": 6.182724511249999, "reward": 96.75124653744001, "most": 1.02096463023, "between": 2.06907337416, "game": 25.7978550536, "drive": 17.61064891848, "fail": 1.9281029876099998, "all": 2.02293577982, "version": 2.0083491461099996, "action": 9.092783505149999, "program": 4.04278074866, "layout": 15.034090909100001, "solv": 21.80769230769, "case": 1.48498737256, "normal": 2.61075481006, "unbeliev": 64.8, "call": 1.0676529926, "more": 5.085853408499999, "and": 30.0018897639, "stall": 14.907042253499998, "these": 2.14830852504, "amount": 4.54054054054, "artifici": 66.53116815088, "made": 1.07038834951, "faster": 7.61438848921, "night": 2.26670474015, "type": 6.084312723570001, "point": 3.7797000238200003, "state": 4.190853296359999, "trialanderror": 1323.0, "can": 14.11513669704, "comput": 19.638792676900003, "make": 1.0762660158600001, "truck": 10.3090909091, "way": 2.4381478922, "onli": 5.128238258300001, "each": 1.18974820144, "threat": 3.63045963869, "key": 4.5601034037, "this": 2.00758725342, "necessari": 2.8421052631599997, "find": 3.4588235294199996, "rise": 2.02940048575, "dead": 2.9608355091400003, "two": 2.0275862069, "advanc": 5.9992442373, "common": 1.4025974025999999, "imposs": 14.88375, "data": 33.7643555934, "flood": 6.94488188976, "oper": 4.66438154931, "address": 8.584715212679999, "tornado": 29.5642458101, "rather": 1.55692850838, "traffic": 11.90104947526, "sometim": 1.7126213592200001, "heist": 186.776470588, "must": 3.844067796619999, "might": 8.624745348360001, "time": 7.078922224359999, "enough": 13.391817798420002, "quantiti": 7.23280182232, "direct": 1.22226499346, "import": 2.6803984467400004, "everi": 1.47917637194, "engin": 2.47135740971, "input": 12.2029208301, "extent": 4.09491875161, "generat": 8.21101629168, "while": 3.1325966850899993, "checker": 535.146067416, "dramat": 3.9849397590400004, "hit": 3.1166077738499998, "within": 1.2369302688, "learn": 60.3915142649, "when": 3.0623030926499997}, "logtfidf": {"real": 1.649258121148, "realist": 2.56105169741, "fall": 0.527402167952, "onc": 0.403765872355, "fit": 2.4302412537799998, "play": 3.0488351251359997, "signal": 1.6340517929299998, "immedi": 0.707357011133, "delay": 1.44278606382, "space": 2.624139494916, "grow": 0.821043542212, "number": 0.7728686273488, "use": 0.146040098658, "etc": 2.8733461759400005, "specif": 0.626980167541, "function": 0.914465741594, "retreat": 3.91934570482, "dog": 1.8346148978799999, "unexpect": 2.2910619194, "whether": 1.583122379294, "terribl": 2.67771382807, "speed": 1.3533338752700002, "creat": 0.445153637028, "approach": 0.7302336145810001, "hint": 2.72174904546, "vehicl": 13.91441080608, "retain": 1.0114434536799999, "suffic": 4.16723227797, "equal": 0.933027391343, "shortterm": 7.18765716411, "ahead": 1.7273626814900003, "breadth": 3.91051243112, "polic": 1.14740245284, "how": 4.244102612370001, "land": 0.5428913449939999, "reaction": 1.54309404912, "bunch": 3.70130197411, "obstacl": 5.2728306403, "children": 0.649637945787, "had": 0.0464780244111, "increas": 0.833462156787, "surviv": 1.6286747490759999, "end": 0.101476798618, "deep": 1.2886734698, "will": 0.40557306983, "bumpi": 5.721320095319999, "scenario": 2.73427932989, "consid": 0.644684171472, "determinist": 9.219937561760002, "pop": 1.99238817347, "terrorist": 2.5416649836099996, "new": 0.0177299468511, "near": 0.505708648068, "but": 0.0971542324314, "schmarzo": 7.18765716411, "definit": 1.1755733298, "need": 1.81370081721, "our": 0.8576392141820001, "precipit": 2.3105532626400005, "off": 0.41352852038800003, "expect": 0.78850775216, "coin": 1.7928938993, "applic": 2.46320785698, "mario": 43.05253575869999, "richer": 3.85545265394, "has": 0.1708957794192, "have": 0.0591400093648, "realworld": 14.37531432822, "moor": 3.7398915009199993, "experi": 0.626272953933, "subsequ": 0.561601885907, "out": 0.1168527818386, "model": 3.687250365555, "good": 0.837178809814, "child": 2.32963016262, "rescu": 3.7018413753199995, "hoodlum": 6.45368798903, "huge": 1.47916358195, "categori": 1.38176946652, "optim": 9.782511181639999, "forward": 3.8970302180700003, "situat": 2.1770048700449998, "attack": 0.678515518292, "tire": 2.52657934619, "not": 0.06220965203, "storag": 2.1544996326700003, "growth": 1.1476008852200001, "minim": 1.80968177926, "condit": 1.964513364618, "restart": 3.47408509741, "quick": 0.790727508899, "easi": 1.6665296351499999, "handl": 2.73366533806, "though": 0.308044191079, "then": 0.08303386523089999, "jet": 2.22890013079, "jump": 2.08829899551, "effect": 0.333830227158, "allow": 0.24028061118900002, "world": 0.644521491726, "minimum": 1.79668465441, "outcom": 2.01339244624, "blog": 7.957119316770001, "construct": 0.658603355972, "internet": 3.2127124918, "wind": 3.17107668648, "twice": 1.32544745286, "progress": 0.894854218108, "simpl": 1.2232212893899999, "day": 0.33731741263400006, "itself": 0.5570837229510001, "algorithm": 3.33044239518, "longterm": 6.238576609419999, "develop": 0.357249389826, "intersect": 2.53847009271, "pattern": 1.33282404788, "chase": 8.784365730960001, "explor": 2.44515874436, "brag": 4.86854276917, "lot": 2.9671939005000003, "box": 2.8350298223, "sourc": 0.529218310751, "control": 0.7699693231720001, "both": 0.10168506677860001, "may": 0.10141999056880001, "punish": 3.6301660539199996, "summari": 2.0543127160299997, "smart": 16.9092558699, "theft": 17.920217200979998, "brute": 13.37288416887, "devic": 6.444307788119999, "set": 0.342992022578, "caus": 0.325858567406, "ani": 0.125608358366, "king": 0.707101485387, "virtual": 4.24242405432, "from": 0.0034023250131959997, "slick": 4.1836260877499996, "account": 0.665074289973, "answer": 3.0732620838, "behavior": 1.71014813378, "dive": 2.7778937744700003, "num": 0.005669827117146001, "technolog": 1.91369537271, "william": 0.562375323877, "environ": 11.107776627269999, "curv": 2.40783363597, "safe": 4.84460885727, "balanc": 2.9872889620999996, "for": 0.0025199231631760004, "car": 15.160816400399998, "predict": 1.6457402376899999, "chess": 23.20305083173, "friend": 0.7893395836239999, "closer": 1.7167880323700002, "with": 0.00957993370712, "teach": 2.76554646144, "forc": 0.8419564995719999, "steer": 2.8903717579, "think": 3.2015298352499997, "are": 0.2062723150789, "solut": 3.10692595254, "better": 0.6964279406, "compani": 0.439777253097, "turbin": 3.5566716884199994, "current": 0.42695282784500005, "work": 0.109034567273, "sens": 1.04257779501, "look": 0.6463866936, "airplan": 2.86905855629, "video": 5.96536244835, "futur": 1.238690395398, "law": 1.1726276543160001, "longerterm": 7.18765716411, "veri": 0.460319586476, "variabl": 6.506169201600001, "reset": 4.17950237056, "want": 1.3832732125099998, "unless": 1.69528182715, "combin": 2.116873243004, "educ": 0.696807183384, "ice": 3.5049612297, "general": 0.114952578063, "map": 1.40434493384, "bail": 3.50924900987, "wrong": 1.70078769102, "even": 0.152388564834, "scope": 2.33692983198, "emerg": 0.748173681534, "train": 1.321836625678, "rook": 5.35507570037, "goal": 1.18830712273, "death": 0.485696798112, "error": 1.7985854343, "chart": 2.13460115413, "trial": 1.3966781444299998, "debri": 3.3375095624, "reinforc": 27.969707774699998, "white": 0.625566240123, "anim": 1.04365037288, "into": 0.0596514529148, "delinqu": 4.584967478669999, "medic": 1.18644857806, "lifeendang": 7.18765716411, "rapid": 0.965411638564, "requir": 0.84850702135, "where": 0.2599685549828, "figur": 3.5508605608000003, "bishop": 1.9065707344999998, "tell": 1.21236434401, "head": 0.456042582852, "against": 0.7644085532339999, "help": 0.672415442688, "affect": 1.816083808768, "pot": 3.0564986287700004, "elimin": 1.30201620283, "potenti": 0.9245764122419999, "consider": 0.8325627480600001, "undocu": 4.66861750796, "least": 0.480285584745, "base": 0.13652330228700002, "occur": 0.556973778473, "grand": 6.720020871899999, "weather": 3.37075813134, "decid": 0.655322871893, "start": 0.236443369291, "explod": 2.52029495787, "unpredict": 3.47205463986, "black": 1.334808585734, "through": 0.1367173837698, "surpris": 1.47392435861, "much": 0.7099829172040001, "evalu": 1.9388802431299998, "about": 0.1256869549492, "problem": 3.414844345638, "imageri": 2.98545520604, "board": 1.818271479898, "thing": 1.7563870693599999, "wrestl": 3.01841129372, "just": 0.868594302327, "billion": 4.74740409216, "bridg": 1.31015483629, "bed": 2.0401626873, "exercis": 1.5552513523, "vantara": 7.18765716411, "competitor": 2.48339607548, "stagger": 3.4460271446199995, "ball": 3.7861936928800004, "across": 0.549198455941, "complex": 3.4009665457239997, "colder": 7.6178652766, "destin": 3.6002173276800002, "tool": 1.60887117963, "great": 0.235805258079, "whenev": 2.45292177377, "articl": 0.702131739574, "guid": 0.912738218589, "countless": 3.3286833797799997, "consumpt": 2.23653599755, "whi": 1.18068843047, "order": 0.6604211423790001, "lose": 1.1265888210600001, "support": 0.475761220074, "accommod": 1.7416384414200001, "mani": 0.0433157581221, "appli": 0.8316941898119999, "the": 0.0, "step": 2.07909011396, "manufactur": 1.21130625482, "flash": 2.5392678590099997, "same": 0.224119299208, "laid": 1.5830813395399999, "exact": 1.2437647732500001, "there": 0.080195785851, "move": 3.578622029542, "possibl": 2.790443799128, "best": 0.459227932947, "exampl": 1.2260480249969998, "right": 1.36143941668, "illustr": 1.2978562707799999, "blown": 3.2332134428, "slight": 1.17966331506, "take": 0.261383924394, "follow": 0.09071382218839999, "now": 0.149092945021, "hitachi": 5.24174701506, "strategi": 2.98224623636, "tri": 1.23518305832, "discov": 0.924894023806, "twilight": 3.6886275332199996, "interact": 1.4858210267899998, "full": 0.511203624148, "than": 0.1290434488728, "regress": 3.9359915164199997, "power": 1.16958513086, "edg": 7.472431750249999, "also": 0.0293143156, "around": 0.19387710578200001, "pothol": 5.8883741799800005, "robberi": 3.28064670051, "hole": 2.0969791623500003, "area": 0.327954821122, "gratuit": 5.31585498721, "quantum": 6.72893074478, "smarter": 5.13996432075, "zero": 8.677096732919999, "challeng": 5.635751813370001, "snow": 2.15667472869, "captur": 1.0578810012100002, "talk": 1.10867789449, "street": 1.7233135556060002, "themselv": 0.7225497843690001, "howev": 0.0903151173475, "intellig": 11.46798785704, "pedestrian": 3.22051485947, "earthquak": 2.51404981657, "piec": 3.5279447291699997, "nondeterminist": 7.18765716411, "win": 1.01265652029, "backward": 2.68138692678, "histori": 0.187550624069, "maxim": 12.797108526, "which": 0.01035682769086, "like": 0.417160729635, "such": 0.179087933418, "tunnel": 2.4269087463099996, "raw": 2.36536149914, "sideway": 4.33984502064, "one": 0.0187660549365, "show": 0.473365532026, "known": 0.3296723223968, "fast": 1.5836950247400001, "ultim": 0.9498209395739999, "see": 0.722764756476, "some": 0.079147018129, "becaus": 0.139343158825, "auto": 16.370859634020004, "explicit": 1.7612397949400003, "seduc": 3.8980122683599996, "sun": 2.9583271639, "get": 2.89884502891, "random": 9.86360703255, "brother": 0.948193864695, "diagon": 14.54832952552, "collect": 0.49536666052, "autonom": 16.840155264659998, "process": 1.583487597075, "fuel": 1.72100448275, "that": 0.08349911597243999, "recent": 0.434413741288, "understand": 1.0880858756799998, "repeat": 1.0567930591299999, "gather": 2.6627841334599998, "road": 0.915566630279, "super": 9.9943784232, "hotter": 8.94813356528, "numreinforcementlearninginternetthingshtml": 7.18765716411, "part": 0.04239531098280001, "hood": 2.9523436587700003, "perform": 0.42618085058, "differ": 1.0616056065600001, "reward": 23.916727374540002, "most": 0.020747896295599998, "between": 0.06790736233059999, "game": 9.477062580210001, "drive": 6.460465812180001, "fail": 0.656536611573, "all": 0.022805264195599997, "version": 0.697313064259, "action": 2.990215825345, "program": 1.4075711575299998, "layout": 2.71032034964, "solv": 5.950951431120001, "case": 0.395406268889, "normal": 0.959639378783, "unbeliev": 4.17130560336, "call": 0.0654627744488, "more": 0.08512465799999999, "and": 0.001889704261908, "stall": 2.7018337357599997, "these": 0.1430672388016, "amount": 1.639797772398, "artifici": 16.94583192144, "made": 0.0680215260973, "faster": 2.03003967967, "night": 0.8183271204970001, "type": 2.121304456161, "point": 0.6930970770989999, "state": 0.1864400110672, "trialanderror": 7.18765716411, "can": 1.948093156728, "comput": 6.8403445797, "make": 0.07349765782289999, "truck": 2.3330261185, "way": 0.39618301987000004, "onli": 0.12662134164549999, "each": 0.173741689304, "threat": 1.2893592624899999, "key": 1.64839623792, "this": 0.007572898105, "necessari": 1.0445450673999999, "find": 1.095562660576, "rise": 0.707740422218, "dead": 1.0854714951100002, "two": 0.0273976887164, "advanc": 2.0790636365340003, "common": 0.338325805271, "imposs": 4.80497317536, "data": 12.168205848, "flood": 1.9380049695500001, "oper": 1.324028893041, "address": 3.1541130974100002, "tornado": 3.38656571939, "rather": 0.442714975539, "traffic": 3.5669588137400003, "sometim": 0.538025155343, "heist": 5.22991255741, "must": 1.306767894776, "might": 3.0733643061360003, "time": 0.07848063203820001, "enough": 4.817306635014, "quantiti": 1.9786264883900002, "direct": 0.200705689496, "import": 0.585636554132, "everi": 0.391485427421, "engin": 0.904767558276, "input": 2.50167533539, "extent": 1.40974687623, "generat": 2.876729366944, "while": 0.12974995138140002, "checker": 26.94468158166, "dramat": 1.3825221952000002, "hit": 1.1367451583600001, "within": 0.21263272059799998, "learn": 21.91155368337, "when": 0.0616649665752}, "logidf": {"real": 0.824629060574, "realist": 2.56105169741, "fall": 0.527402167952, "onc": 0.403765872355, "fit": 1.2151206268899999, "play": 0.38110439064199997, "signal": 1.6340517929299998, "immedi": 0.707357011133, "delay": 1.44278606382, "space": 0.874713164972, "grow": 0.821043542212, "number": 0.0966085784186, "use": 0.0292080197316, "etc": 1.4366730879700003, "specif": 0.626980167541, "function": 0.914465741594, "retreat": 1.95967285241, "dog": 1.8346148978799999, "unexpect": 2.2910619194, "whether": 0.791561189647, "terribl": 2.67771382807, "speed": 1.3533338752700002, "creat": 0.222576818514, "approach": 0.7302336145810001, "hint": 2.72174904546, "vehicl": 1.54604564512, "retain": 1.0114434536799999, "suffic": 4.16723227797, "equal": 0.933027391343, "shortterm": 7.18765716411, "ahead": 1.7273626814900003, "breadth": 3.91051243112, "polic": 1.14740245284, "how": 0.47156695693000006, "land": 0.5428913449939999, "reaction": 1.54309404912, "bunch": 3.70130197411, "obstacl": 2.63641532015, "children": 0.649637945787, "had": 0.0464780244111, "increas": 0.277820718929, "surviv": 0.8143373745379999, "end": 0.101476798618, "deep": 1.2886734698, "will": 0.202786534915, "bumpi": 5.721320095319999, "scenario": 2.73427932989, "consid": 0.214894723824, "determinist": 4.609968780880001, "pop": 1.99238817347, "terrorist": 2.5416649836099996, "new": 0.0177299468511, "near": 0.252854324034, "but": 0.0161923720719, "schmarzo": 7.18765716411, "definit": 1.1755733298, "need": 0.362740163442, "our": 0.8576392141820001, "precipit": 2.3105532626400005, "off": 0.41352852038800003, "expect": 0.78850775216, "coin": 1.7928938993, "applic": 1.23160392849, "mario": 2.8701690505799995, "richer": 3.85545265394, "has": 0.0427239448548, "have": 0.0147850023412, "realworld": 7.18765716411, "moor": 1.8699457504599997, "experi": 0.626272953933, "subsequ": 0.561601885907, "out": 0.0584263909193, "model": 0.7374500731110001, "good": 0.418589404907, "child": 1.16481508131, "rescu": 1.8509206876599997, "hoodlum": 6.45368798903, "huge": 1.47916358195, "categori": 1.38176946652, "optim": 2.4456277954099996, "forward": 1.29901007269, "situat": 0.725668290015, "attack": 0.678515518292, "tire": 2.52657934619, "not": 0.0155524130075, "storag": 2.1544996326700003, "growth": 1.1476008852200001, "minim": 1.80968177926, "condit": 0.654837788206, "restart": 3.47408509741, "quick": 0.790727508899, "easi": 1.6665296351499999, "handl": 1.36683266903, "though": 0.308044191079, "then": 0.08303386523089999, "jet": 2.22890013079, "jump": 2.08829899551, "effect": 0.333830227158, "allow": 0.24028061118900002, "world": 0.107420248621, "minimum": 1.79668465441, "outcom": 2.01339244624, "blog": 2.65237310559, "construct": 0.658603355972, "internet": 1.6063562459, "wind": 1.58553834324, "twice": 1.32544745286, "progress": 0.894854218108, "simpl": 1.2232212893899999, "day": 0.16865870631700003, "itself": 0.5570837229510001, "algorithm": 3.33044239518, "longterm": 6.238576609419999, "develop": 0.178624694913, "intersect": 2.53847009271, "pattern": 1.33282404788, "chase": 2.1960914327400003, "explor": 1.22257937218, "brag": 4.86854276917, "lot": 1.4835969502500002, "box": 1.41751491115, "sourc": 0.529218310751, "control": 0.38498466158600003, "both": 0.050842533389300004, "may": 0.050709995284400004, "punish": 1.8150830269599998, "summari": 2.0543127160299997, "smart": 2.81820931165, "theft": 2.9867028668299995, "brute": 4.45762805629, "devic": 1.6110769470299997, "set": 0.171496011289, "caus": 0.325858567406, "ani": 0.125608358366, "king": 0.707101485387, "virtual": 1.4141413514399999, "from": 0.000567054168866, "slick": 4.1836260877499996, "account": 0.665074289973, "answer": 1.5366310419, "behavior": 1.71014813378, "dive": 2.7778937744700003, "num": 0.00031499039539700004, "technolog": 0.956847686355, "william": 0.562375323877, "environ": 1.2341974030299998, "curv": 2.40783363597, "safe": 1.61486961909, "balanc": 1.4936444810499998, "for": 0.00031499039539700004, "car": 1.2634013667, "predict": 1.6457402376899999, "chess": 3.31472154739, "friend": 0.7893395836239999, "closer": 1.7167880323700002, "with": 0.00119749171339, "teach": 1.38277323072, "forc": 0.280652166524, "steer": 2.8903717579, "think": 1.06717661175, "are": 0.0294674735827, "solut": 1.55346297627, "better": 0.6964279406, "compani": 0.439777253097, "turbin": 3.5566716884199994, "current": 0.42695282784500005, "work": 0.109034567273, "sens": 1.04257779501, "look": 0.6463866936, "airplan": 2.86905855629, "video": 1.19307248967, "futur": 0.619345197699, "law": 0.5863138271580001, "longerterm": 7.18765716411, "veri": 0.230159793238, "variabl": 2.1687230672, "reset": 4.17950237056, "want": 0.6916366062549999, "unless": 1.69528182715, "combin": 0.529218310751, "educ": 0.696807183384, "ice": 1.75248061485, "general": 0.114952578063, "map": 1.40434493384, "bail": 3.50924900987, "wrong": 1.70078769102, "even": 0.152388564834, "scope": 2.33692983198, "emerg": 0.748173681534, "train": 0.660918312839, "rook": 5.35507570037, "goal": 1.18830712273, "death": 0.485696798112, "error": 1.7985854343, "chart": 2.13460115413, "trial": 1.3966781444299998, "debri": 3.3375095624, "reinforc": 1.86464718498, "white": 0.625566240123, "anim": 1.04365037288, "into": 0.0149128632287, "delinqu": 4.584967478669999, "medic": 1.18644857806, "lifeendang": 7.18765716411, "rapid": 0.965411638564, "requir": 0.424253510675, "where": 0.0649921387457, "figur": 0.7101721121600001, "bishop": 1.9065707344999998, "tell": 1.21236434401, "head": 0.456042582852, "against": 0.254802851078, "help": 0.336207721344, "affect": 0.908041904384, "pot": 3.0564986287700004, "elimin": 1.30201620283, "potenti": 0.9245764122419999, "consider": 0.8325627480600001, "undocu": 4.66861750796, "least": 0.480285584745, "base": 0.13652330228700002, "occur": 0.556973778473, "grand": 1.12000347865, "weather": 1.68537906567, "decid": 0.655322871893, "start": 0.236443369291, "explod": 2.52029495787, "unpredict": 3.47205463986, "black": 0.667404292867, "through": 0.0683586918849, "surpris": 1.47392435861, "much": 0.17749572930100002, "evalu": 1.9388802431299998, "about": 0.0628434774746, "problem": 0.569140724273, "imageri": 2.98545520604, "board": 0.909135739949, "thing": 0.8781935346799999, "wrestl": 3.01841129372, "just": 0.289531434109, "billion": 1.5824680307199999, "bridg": 1.31015483629, "bed": 2.0401626873, "exercis": 1.5552513523, "vantara": 7.18765716411, "competitor": 2.48339607548, "stagger": 3.4460271446199995, "ball": 1.8930968464400002, "across": 0.549198455941, "complex": 0.8502416364309999, "colder": 3.8089326383, "destin": 1.8001086638400001, "tool": 1.60887117963, "great": 0.235805258079, "whenev": 2.45292177377, "articl": 0.702131739574, "guid": 0.912738218589, "countless": 3.3286833797799997, "consumpt": 2.23653599755, "whi": 1.18068843047, "order": 0.22014038079300002, "lose": 1.1265888210600001, "support": 0.237880610037, "accommod": 1.7416384414200001, "mani": 0.0433157581221, "appli": 0.8316941898119999, "the": 0.0, "step": 1.03954505698, "manufactur": 1.21130625482, "flash": 2.5392678590099997, "same": 0.112059649604, "laid": 1.5830813395399999, "exact": 1.2437647732500001, "there": 0.0400978929255, "move": 0.255615859253, "possibl": 0.348805474891, "best": 0.459227932947, "exampl": 0.40868267499899996, "right": 0.34035985417, "illustr": 1.2978562707799999, "blown": 3.2332134428, "slight": 1.17966331506, "take": 0.130691962197, "follow": 0.045356911094199995, "now": 0.149092945021, "hitachi": 5.24174701506, "strategi": 1.49112311818, "tri": 0.61759152916, "discov": 0.924894023806, "twilight": 3.6886275332199996, "interact": 1.4858210267899998, "full": 0.511203624148, "than": 0.0322608622182, "regress": 3.9359915164199997, "power": 0.292396282715, "edg": 1.4944863500499999, "also": 0.0146571578, "around": 0.19387710578200001, "pothol": 5.8883741799800005, "robberi": 3.28064670051, "hole": 2.0969791623500003, "area": 0.327954821122, "gratuit": 5.31585498721, "quantum": 3.36446537239, "smarter": 5.13996432075, "zero": 2.1692741832299998, "challeng": 0.9392919688950001, "snow": 2.15667472869, "captur": 1.0578810012100002, "talk": 1.10867789449, "street": 0.8616567778030001, "themselv": 0.7225497843690001, "howev": 0.0903151173475, "intellig": 1.43349848213, "pedestrian": 3.22051485947, "earthquak": 2.51404981657, "piec": 1.17598157639, "nondeterminist": 7.18765716411, "win": 1.01265652029, "backward": 2.68138692678, "histori": 0.187550624069, "maxim": 2.5594217052, "which": 0.00517841384543, "like": 0.139053576545, "such": 0.059695977806, "tunnel": 2.4269087463099996, "raw": 2.36536149914, "sideway": 4.33984502064, "one": 0.0062553516455, "show": 0.236682766013, "known": 0.0824180805992, "fast": 1.5836950247400001, "ultim": 0.9498209395739999, "see": 0.240921585492, "some": 0.0395735090645, "becaus": 0.139343158825, "auto": 2.7284766056700005, "explicit": 1.7612397949400003, "seduc": 3.8980122683599996, "sun": 1.47916358195, "get": 0.579769005782, "random": 1.9727214065099998, "brother": 0.948193864695, "diagon": 3.63708238138, "collect": 0.49536666052, "autonom": 2.4057364663799996, "process": 0.527829199025, "fuel": 1.72100448275, "that": 0.00397614837964, "recent": 0.434413741288, "understand": 1.0880858756799998, "repeat": 1.0567930591299999, "gather": 1.3313920667299999, "road": 0.915566630279, "super": 1.9988756846400002, "hotter": 4.47406678264, "numreinforcementlearninginternetthingshtml": 7.18765716411, "part": 0.04239531098280001, "hood": 2.9523436587700003, "perform": 0.42618085058, "differ": 0.212321121312, "reward": 2.17424794314, "most": 0.020747896295599998, "between": 0.033953681165299995, "game": 0.9477062580210001, "drive": 1.07674430203, "fail": 0.656536611573, "all": 0.011402632097799998, "version": 0.697313064259, "action": 0.598043165069, "program": 0.7037855787649999, "layout": 2.71032034964, "solv": 1.9836504770400003, "case": 0.395406268889, "normal": 0.959639378783, "unbeliev": 4.17130560336, "call": 0.0654627744488, "more": 0.017024931599999998, "and": 6.29901420636e-05, "stall": 2.7018337357599997, "these": 0.0715336194008, "amount": 0.819898886199, "artifici": 2.11822899018, "made": 0.0680215260973, "faster": 2.03003967967, "night": 0.8183271204970001, "type": 0.707101485387, "point": 0.23103235903299998, "state": 0.0466100027668, "trialanderror": 7.18765716411, "can": 0.162341096394, "comput": 1.36806891594, "make": 0.07349765782289999, "truck": 2.3330261185, "way": 0.19809150993500002, "onli": 0.025324268329099998, "each": 0.173741689304, "threat": 1.2893592624899999, "key": 0.82419811896, "this": 0.0037864490525, "necessari": 1.0445450673999999, "find": 0.547781330288, "rise": 0.707740422218, "dead": 1.0854714951100002, "two": 0.0136988443582, "advanc": 0.6930212121780001, "common": 0.338325805271, "imposs": 1.60165772512, "data": 1.2168205848, "flood": 1.9380049695500001, "oper": 0.441342964347, "address": 1.05137103247, "tornado": 3.38656571939, "rather": 0.442714975539, "traffic": 1.7834794068700002, "sometim": 0.538025155343, "heist": 5.22991255741, "must": 0.653383947388, "might": 0.7683410765340001, "time": 0.0112115188626, "enough": 0.802884439169, "quantiti": 1.9786264883900002, "direct": 0.200705689496, "import": 0.292818277066, "everi": 0.391485427421, "engin": 0.904767558276, "input": 2.50167533539, "extent": 1.40974687623, "generat": 0.719182341736, "while": 0.04324998379380001, "checker": 4.49078026361, "dramat": 1.3825221952000002, "hit": 1.1367451583600001, "within": 0.21263272059799998, "learn": 0.842752064745, "when": 0.0205549888584}, "freq": {"real": 2, "realist": 1, "fall": 1, "onc": 1, "fit": 2, "play": 8, "signal": 1, "immedi": 1, "delay": 1, "space": 3, "grow": 1, "number": 8, "use": 5, "etc": 2, "specif": 1, "function": 1, "retreat": 2, "dog": 1, "unexpect": 1, "whether": 2, "terribl": 1, "speed": 1, "creat": 2, "approach": 1, "hint": 1, "vehicl": 9, "retain": 1, "suffic": 1, "equal": 1, "shortterm": 1, "ahead": 1, "breadth": 1, "polic": 1, "how": 9, "land": 1, "reaction": 1, "bunch": 1, "obstacl": 2, "children": 1, "had": 1, "increas": 3, "surviv": 2, "end": 1, "deep": 1, "will": 2, "bumpi": 1, "scenario": 1, "consid": 3, "determinist": 2, "pop": 1, "terrorist": 1, "new": 1, "near": 2, "but": 6, "schmarzo": 1, "definit": 1, "need": 5, "our": 1, "precipit": 1, "off": 1, "expect": 1, "coin": 1, "applic": 2, "mario": 15, "richer": 1, "has": 4, "have": 4, "realworld": 2, "moor": 2, "experi": 1, "subsequ": 1, "out": 2, "model": 5, "good": 2, "child": 2, "rescu": 2, "hoodlum": 1, "huge": 1, "categori": 1, "optim": 4, "forward": 3, "situat": 3, "attack": 1, "tire": 1, "not": 4, "storag": 1, "growth": 1, "minim": 1, "condit": 3, "restart": 1, "quick": 1, "easi": 1, "handl": 2, "though": 1, "then": 1, "jet": 1, "jump": 1, "effect": 1, "allow": 1, "world": 6, "minimum": 1, "outcom": 1, "blog": 3, "construct": 1, "internet": 2, "wind": 2, "twice": 1, "progress": 1, "simpl": 1, "day": 2, "itself": 1, "algorithm": 1, "longterm": 1, "develop": 2, "intersect": 1, "pattern": 1, "chase": 4, "explor": 2, "brag": 1, "lot": 2, "box": 2, "sourc": 1, "control": 2, "both": 2, "may": 2, "punish": 2, "summari": 1, "smart": 6, "theft": 6, "brute": 3, "devic": 4, "set": 2, "caus": 1, "ani": 1, "king": 1, "virtual": 3, "from": 6, "slick": 1, "account": 1, "answer": 2, "behavior": 1, "dive": 1, "num": 18, "technolog": 2, "william": 1, "environ": 9, "curv": 1, "safe": 3, "balanc": 2, "for": 8, "car": 12, "predict": 1, "chess": 7, "friend": 1, "closer": 1, "with": 8, "teach": 2, "forc": 3, "steer": 1, "think": 3, "are": 7, "solut": 2, "better": 1, "compani": 1, "turbin": 1, "current": 1, "work": 1, "sens": 1, "look": 1, "airplan": 1, "video": 5, "futur": 2, "law": 2, "longerterm": 1, "veri": 2, "variabl": 3, "reset": 1, "want": 2, "unless": 1, "combin": 4, "educ": 1, "ice": 2, "general": 1, "map": 1, "bail": 1, "wrong": 1, "even": 1, "scope": 1, "emerg": 1, "train": 2, "rook": 1, "goal": 1, "death": 1, "error": 1, "chart": 1, "trial": 1, "debri": 1, "reinforc": 15, "white": 1, "anim": 1, "into": 4, "delinqu": 1, "medic": 1, "lifeendang": 1, "rapid": 1, "requir": 2, "where": 4, "figur": 5, "bishop": 1, "tell": 1, "head": 1, "against": 3, "help": 2, "affect": 2, "pot": 1, "elimin": 1, "potenti": 1, "consider": 1, "undocu": 1, "least": 1, "base": 1, "occur": 1, "grand": 6, "weather": 2, "decid": 1, "start": 1, "explod": 1, "unpredict": 1, "black": 2, "through": 2, "surpris": 1, "much": 4, "evalu": 1, "about": 2, "problem": 6, "imageri": 1, "board": 2, "thing": 2, "wrestl": 1, "just": 3, "billion": 3, "bridg": 1, "bed": 1, "exercis": 1, "vantara": 1, "competitor": 1, "stagger": 1, "ball": 2, "across": 1, "complex": 4, "colder": 2, "destin": 2, "tool": 1, "great": 1, "whenev": 1, "articl": 1, "guid": 1, "countless": 1, "consumpt": 1, "whi": 1, "order": 3, "lose": 1, "support": 2, "accommod": 1, "mani": 1, "appli": 1, "the": 72, "step": 2, "manufactur": 1, "flash": 1, "same": 2, "laid": 1, "exact": 1, "there": 2, "move": 14, "possibl": 8, "best": 1, "exampl": 3, "right": 4, "illustr": 1, "blown": 1, "slight": 1, "take": 2, "follow": 2, "now": 1, "hitachi": 1, "strategi": 2, "tri": 2, "discov": 1, "twilight": 1, "interact": 1, "full": 1, "than": 4, "regress": 1, "power": 4, "edg": 5, "also": 2, "around": 1, "pothol": 1, "robberi": 1, "hole": 1, "area": 1, "gratuit": 1, "quantum": 2, "smarter": 1, "zero": 4, "challeng": 6, "snow": 1, "captur": 1, "talk": 1, "street": 2, "themselv": 1, "howev": 1, "intellig": 8, "pedestrian": 1, "earthquak": 1, "piec": 3, "nondeterminist": 1, "win": 1, "backward": 1, "histori": 1, "maxim": 5, "which": 2, "like": 3, "such": 3, "tunnel": 1, "raw": 1, "sideway": 1, "one": 3, "show": 2, "known": 4, "fast": 1, "ultim": 1, "see": 3, "some": 2, "becaus": 1, "auto": 6, "explicit": 1, "seduc": 1, "sun": 2, "get": 5, "random": 5, "brother": 1, "diagon": 4, "collect": 1, "autonom": 7, "process": 3, "fuel": 1, "that": 21, "recent": 1, "understand": 1, "repeat": 1, "gather": 2, "road": 1, "super": 5, "hotter": 2, "numreinforcementlearninginternetthingshtml": 1, "part": 1, "hood": 1, "perform": 1, "differ": 5, "reward": 11, "most": 1, "between": 2, "game": 10, "drive": 6, "fail": 1, "all": 2, "version": 1, "action": 5, "program": 2, "layout": 1, "solv": 3, "case": 1, "normal": 1, "unbeliev": 1, "call": 1, "more": 5, "and": 30, "stall": 1, "these": 2, "amount": 2, "artifici": 8, "made": 1, "faster": 1, "night": 1, "type": 3, "point": 3, "state": 4, "trialanderror": 1, "can": 12, "comput": 5, "make": 1, "truck": 1, "way": 2, "onli": 5, "each": 1, "threat": 1, "key": 2, "this": 2, "necessari": 1, "find": 2, "rise": 1, "dead": 1, "two": 2, "advanc": 3, "common": 1, "imposs": 3, "data": 10, "flood": 1, "oper": 3, "address": 3, "tornado": 1, "rather": 1, "traffic": 2, "sometim": 1, "heist": 1, "must": 2, "might": 4, "time": 7, "enough": 6, "quantiti": 1, "direct": 1, "import": 2, "everi": 1, "engin": 1, "input": 1, "extent": 1, "generat": 4, "while": 3, "checker": 6, "dramat": 1, "hit": 1, "within": 1, "learn": 26, "when": 3}, "idf": {"real": 2.28103448276, "realist": 12.9494290375, "fall": 1.6945244956799999, "onc": 1.4974533106999999, "fit": 3.37070063694, "play": 1.46390041494, "signal": 5.12459651388, "immedi": 2.02862254025, "delay": 4.23247134098, "space": 2.39818731118, "grow": 2.27287043665, "number": 1.10142916609, "use": 1.0296387573799999, "etc": 4.2066772655, "specif": 1.8719490626099997, "function": 2.495441685, "retreat": 7.0970049173000005, "dog": 6.26272189349, "unexpect": 9.88542963885, "whether": 2.20683903253, "terribl": 14.5517873511, "speed": 3.8703071672400005, "creat": 1.2492917847, "approach": 2.07556543339, "hint": 15.2068965517, "vehicl": 4.6928761454300005, "retain": 2.74956702459, "suffic": 64.5365853659, "equal": 2.542193755, "shortterm": 1323.0, "ahead": 5.625797306869999, "breadth": 49.9245283019, "polic": 3.15, "how": 1.60250328051, "land": 1.7209756097599997, "reaction": 4.67904509284, "bunch": 40.5, "obstacl": 13.963060685999999, "children": 1.91484742492, "had": 1.0475750577399998, "increas": 1.32024948025, "surviv": 2.2576791808900003, "end": 1.10680423871, "deep": 3.6279707495399998, "will": 1.22481098596, "bumpi": 305.307692308, "scenario": 15.3986420951, "consid": 1.2397313759200002, "determinist": 100.481012658, "pop": 7.33302540416, "terrorist": 12.7008, "new": 1.0178880554, "near": 1.28769567686, "but": 1.01632417899, "schmarzo": 1323.0, "definit": 3.24, "need": 1.4372623574099999, "our": 2.35758835759, "precipit": 10.08, "off": 1.5121440137200002, "expect": 2.20011086475, "coin": 6.00681044268, "applic": 3.42672134686, "mario": 17.64, "richer": 47.25, "has": 1.0436497502, "have": 1.0148948411399998, "realworld": 1323.0, "moor": 6.48794442174, "experi": 1.87062566278, "subsequ": 1.7534791252500002, "out": 1.06016694491, "model": 2.0905978404, "good": 1.51981619759, "child": 3.20533010297, "rescu": 6.3656776263, "hoodlum": 635.04, "huge": 4.38927287808, "categori": 3.98194130926, "optim": 11.5377906977, "forward": 3.66566612792, "situat": 2.06611140031, "attack": 1.97094972067, "tire": 12.5106382979, "not": 1.01567398119, "storag": 8.623574144489998, "growth": 3.15062512403, "minim": 6.10850327049, "condit": 1.92483026188, "restart": 32.2682926829, "quick": 2.205, "easi": 5.2937645882, "handl": 3.9229058561900003, "though": 1.36076112111, "then": 1.08657860516, "jet": 9.28964306612, "jump": 8.07117437722, "effect": 1.3963060686000002, "allow": 1.2716059271100002, "world": 1.11340206186, "minimum": 6.02962400304, "outcom": 7.48867924528, "blog": 14.1876675603, "construct": 1.9320920043799998, "internet": 4.98461538462, "wind": 4.88191881919, "twice": 3.7638691322900004, "progress": 2.44697903822, "simpl": 3.3981164383599998, "day": 1.18371607516, "itself": 1.74557449148, "algorithm": 27.9507042254, "longterm": 512.129032258, "develop": 1.1955719557200002, "intersect": 12.660287081300002, "pattern": 3.79173632673, "chase": 8.989807474520001, "explor": 3.39593582888, "brag": 130.131147541, "lot": 4.40877534018, "box": 4.12685209254, "sourc": 1.69760479042, "control": 1.46959178006, "both": 1.05215720061, "may": 1.05201775893, "punish": 6.1415860735, "summari": 7.80147420147, "smart": 16.746835443, "theft": 19.8202247191, "brute": 86.28260869569999, "devic": 5.00820189274, "set": 1.18707940781, "caus": 1.38521943984, "ani": 1.13383802314, "king": 2.0281042411900003, "virtual": 4.11295336788, "from": 1.00056721497, "slick": 65.6033057851, "account": 1.94463498285, "answer": 4.64890190337, "behavior": 5.52978056426, "dive": 16.085106383, "num": 1.00031504001, "technolog": 2.6034765496900003, "william": 1.75483585719, "environ": 3.43561999567, "curv": 11.1098670399, "safe": 5.02723242559, "balanc": 4.45329593268, "for": 1.00031504001, "car": 3.53743315508, "predict": 5.18484650555, "chess": 27.5147313692, "friend": 2.20194174757, "closer": 5.5666199158500005, "with": 1.0011982089899998, "teach": 3.98594024605, "forc": 1.32399299475, "steer": 18.0, "think": 2.90715986083, "are": 1.02990593578, "solut": 4.7278141751, "better": 2.0065722952500002, "compani": 1.5523613963, "turbin": 35.0463576159, "current": 1.5325803649, "work": 1.11520089913, "sens": 2.8365195640499996, "look": 1.9086318826599997, "airplan": 17.6204217536, "video": 3.29719626168, "futur": 1.8577112099200002, "law": 1.7973508434299998, "longerterm": 1323.0, "veri": 1.25880114177, "variabl": 8.747107438019999, "reset": 65.3333333333, "want": 1.99698113208, "unless": 5.44818119423, "combin": 1.69760479042, "educ": 2.00733341763, "ice": 5.768895348840001, "general": 1.1218202374200001, "map": 4.0728578758300005, "bail": 33.4231578947, "wrong": 5.478260869570001, "even": 1.16461267606, "scope": 10.3494132986, "emerg": 2.1131372288, "train": 1.9365698950999999, "rook": 211.68, "goal": 3.28152128979, "death": 1.6253071253100002, "error": 6.04109589041, "chart": 8.45367412141, "trial": 4.04175152749, "debri": 28.1489361702, "reinforc": 6.453658536590001, "white": 1.86930413282, "anim": 2.8395635843299996, "into": 1.01502461479, "delinqu": 98.0, "medic": 3.27542809986, "lifeendang": 1323.0, "rapid": 2.62586834271, "requir": 1.52844902282, "where": 1.06715063521, "figur": 2.0343413634, "bishop": 6.72997032641, "tell": 3.36142282448, "head": 1.57781753131, "against": 1.2902072328299998, "help": 1.39962972759, "affect": 2.4794627518400003, "pot": 21.2530120482, "elimin": 3.67670217693, "potenti": 2.52080025405, "consider": 2.29920347574, "undocu": 106.55033557, "least": 1.6165359943000002, "base": 1.14628158845, "occur": 1.7453825857499998, "grand": 3.06486486486, "weather": 5.3944954128400004, "decid": 1.9257641921400002, "start": 1.26673581744, "explod": 12.432263116700002, "unpredict": 32.2028397566, "black": 1.94917127072, "through": 1.07074930869, "surpris": 4.36633663366, "much": 1.1942229577299999, "evalu": 6.9509632224199995, "about": 1.06486015159, "problem": 1.76674827509, "imageri": 19.7955112219, "board": 2.48217636023, "thing": 2.4065484311099996, "wrestl": 20.458762886600002, "just": 1.33580143037, "billion": 4.8669527897, "bridg": 3.7067476068199996, "bed": 7.6918604651199995, "exercis": 4.73627684964, "vantara": 1323.0, "competitor": 11.9818867925, "stagger": 31.3754940711, "ball": 6.63989962359, "across": 1.7318642958400001, "complex": 2.34021226415, "colder": 45.1022727273, "destin": 6.0503048780499995, "tool": 4.99716713881, "great": 1.26592775696, "whenev": 11.622254758399999, "articl": 2.01805008262, "guid": 2.49113447356, "countless": 27.9015817223, "consumpt": 9.3608490566, "whi": 3.2566153846200003, "order": 1.24625166811, "lose": 3.0851146521599997, "support": 1.2685577307200002, "accommod": 5.70668583753, "mani": 1.04426757877, "appli": 2.2972073506, "the": 1.0, "step": 2.8279301745599996, "manufactur": 3.3578680202999998, "flash": 12.6703910615, "same": 1.11857958148, "laid": 4.86993865031, "exact": 3.46864758575, "there": 1.04091266719, "move": 1.29125660838, "possibl": 1.4173734488, "best": 1.5828514456600002, "exampl": 1.50483412322, "right": 1.4054532577899999, "illustr": 3.6614391143900002, "blown": 25.3610223642, "slight": 3.25327868852, "take": 1.13961668222, "follow": 1.04640126549, "now": 1.160780873, "hitachi": 189.0, "strategi": 4.44208170118, "tri": 1.8544562551099997, "discov": 2.52160101652, "twilight": 39.9899244332, "interact": 4.4185917061, "full": 1.66729678639, "than": 1.03278688525, "regress": 51.2129032258, "power": 1.3396337861799998, "edg": 4.45704660303, "also": 1.01476510067, "around": 1.21394708671, "pothol": 360.818181818, "robberi": 26.592964824099997, "hole": 8.14153846154, "area": 1.3881262568900001, "gratuit": 203.53846153799998, "quantum": 28.9180327869, "smarter": 170.709677419, "zero": 8.75192943771, "challeng": 2.55816951337, "snow": 8.64235166032, "captur": 2.88026124819, "talk": 3.0303493033, "street": 2.36707917102, "themselv": 2.05967825636, "howev": 1.0945191313299998, "intellig": 4.19334389857, "pedestrian": 25.0410094637, "earthquak": 12.3548638132, "piec": 3.24132298898, "nondeterminist": 1323.0, "win": 2.75290445639, "backward": 14.605335786600001, "histori": 1.20629131525, "maxim": 12.928338762200001, "which": 1.005191845, "like": 1.14918566775, "such": 1.06151377374, "tunnel": 11.323823109800001, "raw": 10.6478873239, "sideway": 76.6956521739, "one": 1.00627495722, "show": 1.26703910615, "known": 1.0859097127200001, "fast": 4.8729281768, "ultim": 2.58524670249, "see": 1.27242125511, "some": 1.04036697248, "becaus": 1.1495184997499999, "auto": 15.3095467695, "explicit": 5.819648093840001, "seduc": 49.3043478261, "sun": 4.38927287808, "get": 1.78562591385, "random": 7.1902173913, "brother": 2.58104373273, "diagon": 37.980861244, "collect": 1.64109985528, "autonom": 11.086592178800002, "process": 1.69524826482, "fuel": 5.59014084507, "that": 1.00398406375, "recent": 1.54405757635, "understand": 2.96858638743, "repeat": 2.8771293947099994, "gather": 3.78631051753, "road": 2.49819040126, "super": 7.380753138080001, "hotter": 87.7127071823, "numreinforcementlearninginternetthingshtml": 1323.0, "part": 1.04330682789, "hood": 19.1507840772, "perform": 1.5313977042500002, "differ": 1.23654490225, "reward": 8.79556786704, "most": 1.02096463023, "between": 1.03453668708, "game": 2.57978550536, "drive": 2.93510815308, "fail": 1.9281029876099998, "all": 1.01146788991, "version": 2.0083491461099996, "action": 1.81855670103, "program": 2.02139037433, "layout": 15.034090909100001, "solv": 7.26923076923, "case": 1.48498737256, "normal": 2.61075481006, "unbeliev": 64.8, "call": 1.0676529926, "more": 1.0171706817, "and": 1.00006299213, "stall": 14.907042253499998, "these": 1.07415426252, "amount": 2.27027027027, "artifici": 8.31639601886, "made": 1.07038834951, "faster": 7.61438848921, "night": 2.26670474015, "type": 2.0281042411900003, "point": 1.25990000794, "state": 1.0477133240899998, "trialanderror": 1323.0, "can": 1.17626139142, "comput": 3.9277585353800006, "make": 1.0762660158600001, "truck": 10.3090909091, "way": 1.2190739461, "onli": 1.0256476516600002, "each": 1.18974820144, "threat": 3.63045963869, "key": 2.28005170185, "this": 1.00379362671, "necessari": 2.8421052631599997, "find": 1.7294117647099998, "rise": 2.02940048575, "dead": 2.9608355091400003, "two": 1.01379310345, "advanc": 1.9997480791, "common": 1.4025974025999999, "imposs": 4.96125, "data": 3.37643555934, "flood": 6.94488188976, "oper": 1.55479384977, "address": 2.86157173756, "tornado": 29.5642458101, "rather": 1.55692850838, "traffic": 5.95052473763, "sometim": 1.7126213592200001, "heist": 186.776470588, "must": 1.9220338983099996, "might": 2.1561863370900003, "time": 1.01127460348, "enough": 2.2319696330700003, "quantiti": 7.23280182232, "direct": 1.22226499346, "import": 1.3401992233700002, "everi": 1.47917637194, "engin": 2.47135740971, "input": 12.2029208301, "extent": 4.09491875161, "generat": 2.05275407292, "while": 1.0441988950299999, "checker": 89.19101123600001, "dramat": 3.9849397590400004, "hit": 3.1166077738499998, "within": 1.2369302688, "learn": 2.32275054865, "when": 1.02076769755}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Transforming from Autonomous to Smart: Reinforcement Learning Basics</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/transforming-autonomous-smart-reinforcement-learning-basics.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Transforming from Autonomous to Smart: Reinforcement Learning Basics Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/data-science-primer-basic-concepts-for-beginners.html\" rel=\"prev\" title=\"Data Science Primer: Basic Concepts for Beginners\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\" rel=\"next\" title=\"Making Predictive Models Robust: Holdout vs Cross-Validation\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/08/transforming-autonomous-smart-reinforcement-learning-basics.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=70074\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/08/transforming-autonomous-smart-reinforcement-learning-basics.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-70074 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 11-Aug, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/index.html\">Aug</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/tutorials.html\">Tutorials, Overviews</a> \u00bb Transforming from Autonomous to Smart: Reinforcement Learning Basics (\u00a0<a href=\"/2017/n31.html\">17:n31</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Transforming from Autonomous to Smart: Reinforcement Learning Basics</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/08/data-science-primer-basic-concepts-for-beginners.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 85</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/iot\" rel=\"tag\">IoT</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a>, <a href=\"https://www.kdnuggets.com/tag/reinforcement-learning\" rel=\"tag\">Reinforcement Learning</a></div>\n<br/>\n<p class=\"excerpt\">\n     This blog introduces the basics of reinforcement learning. We are going to see how reinforcement learning might help us to address these challenges; to work smarter at the edge when brute force technology advances will not suffice.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/william-schmarzo\" rel=\"author\" title=\"Posts by William Schmarzo\">William Schmarzo</a>, Hitachi Vantara.</b></div>\n<p>In the blog \u201c<a href=\"https://infocus.emc.com/william_schmarzo/autonomous-smart-artificial-intelligence/\" target=\"_blank\">From Autonomous to Smart: Importance of Artificial Intelligence</a>,\u201d we laid out the artificial intelligence (AI) challenges in creating \u201csmart\u201d edge devices:</p>\n<ul>\n<li>Artificial Intelligence Challenge #1: How do the Artificial Intelligence algorithms handle the unexpected, such as flash flooding, terrorist attacks, earthquakes, tornadoes, police car chases, emergency vehicles, blown tires, a child chasing a ball into the street,\u00a0etc.?\n<li>Artificial Intelligence Challenge #2: The more complex the problem state, the more data storage (to retain known state history) and CPU processing power (to find the optimal or best solution) is required in the edge devices in order to create \u201csmart.\u201d\n</li></li></ul>\n<p>We also talked about how Moore\u2019s Law isn\u2019t going to bail us out of these challenges; that the growth of Internet of Things (IOT) data and the complexity of the problems that we are trying to address at the edge (think \u201csmart\u201d cars) is growing much faster than Moore\u2019s Law can accommodate.</p>\n<p>So we are going to use this blog to deep dive into the category of artificial intelligence called <strong>reinforcement learning.</strong>\u00a0We are going to see how reinforcement learning might help us to address these challenges; to <em>work smarter</em> at the edge when brute force technology advances will not suffice.</p>\n<p>\u00a0</p>\n<h3>Why Not Brute Force</h3>\n<p>\u00a0<br>\nWith the rapid increases in computing power, it\u2019s easy to get seduced into thinking that raw computing power can solve problems like smart edge devices (e.g., cars, trains, airplanes, wind turbines, jet engines, medical devices). But to understand the scope of the challenge, consider the following:</br></p>\n<ul>\n<li>Checkers has 500 billion billion (that\u2019s right, billion twice) possible board moves. That\u2019s 500,000,000,000,000,000,000 possible moves (that\u2019s 20 zeros).\n<li>The number of possible moves in a game of chess is a minimum of 10<sup>120</sup> moves (that\u2019s 120 zeros).\n</li></li></ul>\n<p>Look at the dramatic increase in the number of possible moves between checkers and chess even though the board layout is <strong><em>exactly the same</em></strong>. The only difference between checkers and chess is the types of moves that pieces can make. A checker has only two moves: forward diagonally and jump competitor\u2019s pieces diagonally (once a checker is \u201ckinged\u201d, then it can move diagonally both forward and backwards). In chess, the complexity of the chess piece only increases slightly (rooks can move forward and sideways a variable number of spaces, bishops can move diagonally a variable number of spaces, etc.), but the complexity of the potential solutions exploded (from 20 zeros to 120 zeros). And both checkers and chess operate in a deterministic environment, where all possible moves are known ahead of time and there are no surprises (unless your dog decides that he wants to play at the same time).</p>\n<p>Now think about the number and breadth of \u201cmoves\u201d or variables that need to be considered when driving a car in a nondeterministic (random) environment:\u00a0 weather (precipitation, snow, ice, black ice, wind), time of day (day time, twilight, night time, sun rise, sun set), road conditions (pot holes, bumpy, slick), traffic conditions (number of vehicles, types of vehicles, different speeds, different destinations). One can quickly see that the number of possible moves is staggering. We need a better answer than brute force.</p>\n<p>\u00a0</p>\n<h3>Reinforcement Learning to the Rescue</h3>\n<p>\u00a0<br>\n<strong>Reinforcement Learning</strong> is for situations where you don\u2019t have data sets with explicit known outcomes, but you do have a way to telling whether you are getting closer to your goal (<strong>reward function</strong>). Reinforcement learning learns through trial-and-error how to map situations to actions so as to maximize rewards. Actions may affect immediate rewards but actions may also affect subsequent or longer-term rewards, so the full extent of rewards must be considered when evaluating the reinforcement learning effectiveness (i.e., balancing short-term rewards like optimizing fuel consumption while driving a car balanced against the long-term rewards of getting to your destination on time and safely).</br></p>\n<p>Reinforcement learning is used to address two general problems:</p>\n<ul>\n<li>Prediction: How much reward can be expected for every combination of possible future states (e.g., how much can we collect from delinquent accounts based on the following steps?)\n<li>Control: By moving through all possible combinations of the environment (interacting with the environment or state space), find a combination of actions that maximizes reward and allows for optimal control (e.g., steering an autonomous vehicle, winning a game of chess).\n</li></li></ul>\n<p>The children\u2019s game of \u201cHotter or Colder\u201d is a good illustration of reinforcement learning; rather than getting a specific \u201cright or wrong\u201d answer with each data action, you\u2019ll get a delayed reaction and only a hint of whether you\u2019re heading in the right direction (hotter or colder).</p>\n<p>\u00a0</p>\n<h3>Reinforcement Learning and Video Games</h3>\n<p>\u00a0<br>\nReinforcement learning needs lots and lots of data from which to learn and very powerful compute to support its \u201ctrial and error\u201d learning approach. Because it can take a considerable amount of time to gather enough data across enough scenarios in the real world, many of the advances in reinforcement learning are occurring from playing against video games.</br></p>\n<p>One such example is the MarI/O program (\u2018<a href=\"http://www.techtimes.com/articles/60573/20150615/mari-o-ai-program-learns-play-super-mario-world.htm\" target=\"_blank\">MarI/O AI Program Learns To Play Super Mario World\u2019</a>). MarI/O is an artificial intelligence application that has learned how to play the video game \u201cSuper Mario World\u201d (see Figure 1).</p>\n<p><center><img alt=\"Figure 1: MarI/O Playing \u201cSuper Mario World\u201d Video Game\" src=\"https://infocus.emc.com/wp-content/uploads/2017/07/mario.png\" width=\"70%\"/><br>\n<font size=\"-1\">Figure 1: MarI/O Playing \u201cSuper Mario World\u201d Video Game</font></br></center></p>\n<p>Some key points to learn from MarI/O:</p>\n<ul>\n<li>MarI/O uses random steps to start its exploration process and to re-start whenever it stalls.\n<li>MarI/O takes inputs by sensing white boxes (safe landing areas) and black boxes (obstacles).\n<li>Rewards (Fitness points in the case of Mario Brothers) and punishment (death) guide the learning process (try to maximize rewards while minimizing or eliminating punishments)\n<li>Sometimes losing (failing) is the only way to learn.\n</li></li></li></li></ul>\n<p>Figure 2 shows the progress that MarI/O made in learning the environment in order to maximize its fitness points and survive.</p>\n<p><center><img alt=\"Figure 2:\u00a0MarI/O Learning Curve\" src=\"https://infocus.emc.com/wp-content/uploads/2017/07/fitness.png\" width=\"70%\"/><br/>\n<font size=\"-1\">Figure 2:\u00a0MarI/O Learning Curve</font></center></p>\n<p>But \u201cMario Super World\u201d is a deterministic or known environment where the gaming patterns repeat themselves. For example, the chart in Figure 2 doesn\u2019t show any regressions in performance, where the AI model hit a dead end and had to retreat and re-set itself. Retreating is a common behavior that the more advanced AI models must support.</p>\n<p>And the game playing strategy in this model is very simple \u2013 just survive. There is no strategy to maximize the number of coins captured, which is an equally important part of playing Super Mario World (or at least if you want bragging rights with your friends).</p>\n<p>So while the exercise is definitely educational, it\u2019s not terribly application for our smart car example.</p>\n<p>\u00a0</p>\n<h3>Grand Theft Auto to the Rescue!</h3>\n<p>\u00a0<br/>\nApplying reinforcement learning to teach a car to drive requires an unbelievably huge quantity of data. Having a bunch of autonomous car tooling around the \u2018hood just can\u2019t generate enough data fast enough to optimize the models necessary to safely drive a vehicle. However, autonomous car companies have discovered a much richer training environment \u2013 Grand Theft Auto!</p>\n<p><img alt=\"car\" class=\"aligncenter\" src=\"https://infocus.emc.com/wp-content/uploads/2017/07/car.jpg\" width=\"99%\"/></p>\n<p>The virtual environment within the video game Grand Theft Auto is so realistic that it is being used to generate data that\u2019s nearly as good as that generated by using real-world imagery. The most current version of Grand Theft Auto has 262 types of vehicles, more than 1,000 different unpredictable pedestrians and animals, 14 weather conditions and countless bridges, traffic signals, tunnels and intersections. It\u2019s nearly impossible for an autonomous car manufacturer to operate enough vehicles in enough different situations to generate the amount of data that can be virtually gathered by playing against Grand Theft Auto.</p>\n<p>\u00a0</p>\n<h3>Reinforcement Learning Summary</h3>\n<p>\u00a0<br/>\nUltimately, reinforcement learning model development is going to need to wrestle with real (not virtual) random obstacles that pop up in the normal driving of a vehicle. Grand Theft Auto might be great for teaching vehicles how to operate in an environment with hoodlums, robberies, heists and gratuitous car chases, but more real-world experience is going to be needed in order for autonomous cars to learn to handle the random, life-endangering threats, such as a child chasing a ball into the street, a new pothole caused by some (undocumented) construction or random debris falling off of truck beds.</p>\n<p>One recent technology development that might be the key to solving \u201cimpossible\u201d problems like autonomous driving is quantum computing. A future blog will explore how combining artificial intelligence with quantum computing might just help us solve the \u201cimpossible\u201d problems.</p>\n<p>\u00a0<br/>\n<b>Article Sources:</b></p>\n<ul>\n<li>Reinforcement Learning and the Internet of Things<br/>\n<a href=\"/2016/08/reinforcement-learning-internet-things.html\" target=\"_blank\">/2016/08/reinforcement-learning-internet-things.html</a></li></ul></div></div></div></div></div></body></html>\n<li>Ways in Which Machines Learn<br/>\n<a href=\"https://hackernoon.com/ways-in-which-machines-learn-b1824464dd5f\" target=\"_blank\">https://hackernoon.com/ways-in-which-machines-learn-b1824464dd5f</a></li>\n<li>Reinforcement Learning and AI<br/>\n<a href=\"http://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-and-ai\" target=\"_blank\">http://www.datasciencecentral.com/profiles/blogs/reinforcement-learning-and-ai</a></li>\n<li>AI Is Learning To Drive In \u2018Grand Theft Auto.\u2019 It\u2019s Going \u2026 Great<br/>\n<a href=\"http://www.newsy.com/stories/self-driving-ai-powers-grand-theft-auto-twitch-stream/\" target=\"_blank\">http://www.newsy.com/stories/self-driving-ai-powers-grand-theft-auto-twitch-stream/</a></li>\n<li>Deep Learning Machine Teaches Itself Chess in 72 Hours<br/>\n<a href=\"https://www.technologyreview.com/s/541276/deep-learning-machine-teaches-itself-chess-in-72-hours-plays-at-international-master/\" target=\"_blank\">https://www.technologyreview.com/s/541276/deep-learning-machine-teaches-itself-chess-in-72-hours-plays-at-international-master/</a>\n</li>\n<p>\u00a0<br/>\n<a href=\"https://infocus.emc.com/william_schmarzo/transforming-from-autonomous-to-smart-reinforcement-learning-basics/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/03/next-challenges-reinforcement-learning.html\">The Next Challenges for Reinforcement Learning</a>\n<li><a href=\"/2017/01/maluuba-creating-curious-machines-information-seeking-agents.html\">Creating Curious Machines: Building Information-seeking Agents</a>\n<li><a href=\"/2017/07/iot-internet-of-things-intro-tutorial-series.html\">The Internet of Things: An Introductory Tutorial Series</a>\n</li></li></li></ul>\n\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/08/data-science-primer-basic-concepts-for-beginners.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end-->\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/index.html\">Aug</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/08/tutorials.html\">Tutorials, Overviews</a> \u00bb Transforming from Autonomous to Smart: Reinforcement Learning Basics (\u00a0<a href=\"/2017/n31.html\">17:n31</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end-->\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556374080\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper-->\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.704 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 10:08:00 -->\n<!-- Compression = gzip -->", "content_tokenized": ["william", "schmarzo", "hitachi", "vantara", "the", "blog", "from", "autonom", "smart", "import", "artifici", "intellig", "laid", "out", "the", "artifici", "intellig", "challeng", "creat", "smart", "edg", "devic", "artifici", "intellig", "challeng", "num", "how", "the", "artifici", "intellig", "algorithm", "handl", "the", "unexpect", "such", "flash", "flood", "terrorist", "attack", "earthquak", "tornado", "polic", "car", "chase", "emerg", "vehicl", "blown", "tire", "child", "chase", "ball", "into", "the", "street", "etc", "artifici", "intellig", "challeng", "num", "the", "more", "complex", "the", "problem", "state", "the", "more", "data", "storag", "retain", "known", "state", "histori", "and", "process", "power", "find", "the", "optim", "best", "solut", "requir", "the", "edg", "devic", "order", "creat", "smart", "also", "talk", "about", "how", "moor", "law", "bail", "out", "these", "challeng", "that", "the", "growth", "internet", "thing", "data", "and", "the", "complex", "the", "problem", "that", "are", "tri", "address", "the", "edg", "think", "smart", "car", "grow", "much", "faster", "than", "moor", "law", "can", "accommod", "are", "use", "this", "blog", "deep", "dive", "into", "the", "categori", "artifici", "intellig", "call", "reinforc", "learn", "are", "see", "how", "reinforc", "learn", "might", "help", "address", "these", "challeng", "work", "smarter", "the", "edg", "when", "brute", "forc", "technolog", "advanc", "will", "not", "suffic", "whi", "not", "brute", "forc", "with", "the", "rapid", "increas", "comput", "power", "easi", "get", "seduc", "into", "think", "that", "raw", "comput", "power", "can", "solv", "problem", "like", "smart", "edg", "devic", "car", "train", "airplan", "wind", "turbin", "jet", "engin", "medic", "devic", "but", "understand", "the", "scope", "the", "challeng", "consid", "the", "follow", "checker", "has", "num", "billion", "billion", "that", "right", "billion", "twice", "possibl", "board", "move", "that", "num", "possibl", "move", "that", "num", "zero", "the", "number", "possibl", "move", "game", "chess", "minimum", "num", "num", "move", "that", "num", "zero", "look", "the", "dramat", "increas", "the", "number", "possibl", "move", "between", "checker", "and", "chess", "even", "though", "the", "board", "layout", "exact", "the", "same", "the", "onli", "differ", "between", "checker", "and", "chess", "the", "type", "move", "that", "piec", "can", "make", "checker", "has", "onli", "two", "move", "forward", "diagon", "and", "jump", "competitor", "piec", "diagon", "onc", "checker", "king", "then", "can", "move", "diagon", "both", "forward", "and", "backward", "chess", "the", "complex", "the", "chess", "piec", "onli", "increas", "slight", "rook", "can", "move", "forward", "and", "sideway", "variabl", "number", "space", "bishop", "can", "move", "diagon", "variabl", "number", "space", "etc", "but", "the", "complex", "the", "potenti", "solut", "explod", "from", "num", "zero", "num", "zero", "and", "both", "checker", "and", "chess", "oper", "determinist", "environ", "where", "all", "possibl", "move", "are", "known", "ahead", "time", "and", "there", "are", "surpris", "unless", "dog", "decid", "that", "want", "play", "the", "same", "time", "now", "think", "about", "the", "number", "and", "breadth", "move", "variabl", "that", "need", "consid", "when", "drive", "car", "nondeterminist", "random", "environ", "weather", "precipit", "snow", "ice", "black", "ice", "wind", "time", "day", "day", "time", "twilight", "night", "time", "sun", "rise", "sun", "set", "road", "condit", "pot", "hole", "bumpi", "slick", "traffic", "condit", "number", "vehicl", "type", "vehicl", "differ", "speed", "differ", "destin", "one", "can", "quick", "see", "that", "the", "number", "possibl", "move", "stagger", "need", "better", "answer", "than", "brute", "forc", "reinforc", "learn", "the", "rescu", "reinforc", "learn", "for", "situat", "where", "have", "data", "set", "with", "explicit", "known", "outcom", "but", "have", "way", "tell", "whether", "are", "get", "closer", "goal", "reward", "function", "reinforc", "learn", "learn", "through", "trialanderror", "how", "map", "situat", "action", "maxim", "reward", "action", "may", "affect", "immedi", "reward", "but", "action", "may", "also", "affect", "subsequ", "longerterm", "reward", "the", "full", "extent", "reward", "must", "consid", "when", "evalu", "the", "reinforc", "learn", "effect", "balanc", "shortterm", "reward", "like", "optim", "fuel", "consumpt", "while", "drive", "car", "balanc", "against", "the", "longterm", "reward", "get", "destin", "time", "and", "safe", "reinforc", "learn", "use", "address", "two", "general", "problem", "predict", "how", "much", "reward", "can", "expect", "for", "everi", "combin", "possibl", "futur", "state", "how", "much", "can", "collect", "from", "delinqu", "account", "base", "the", "follow", "step", "control", "move", "through", "all", "possibl", "combin", "the", "environ", "interact", "with", "the", "environ", "state", "space", "find", "combin", "action", "that", "maxim", "reward", "and", "allow", "for", "optim", "control", "steer", "autonom", "vehicl", "win", "game", "chess", "the", "children", "game", "hotter", "colder", "good", "illustr", "reinforc", "learn", "rather", "than", "get", "specif", "right", "wrong", "answer", "with", "each", "data", "action", "get", "delay", "reaction", "and", "onli", "hint", "whether", "head", "the", "right", "direct", "hotter", "colder", "reinforc", "learn", "and", "video", "game", "reinforc", "learn", "need", "lot", "and", "lot", "data", "from", "which", "learn", "and", "veri", "power", "comput", "support", "trial", "and", "error", "learn", "approach", "becaus", "can", "take", "consider", "amount", "time", "gather", "enough", "data", "across", "enough", "scenario", "the", "real", "world", "mani", "the", "advanc", "reinforc", "learn", "are", "occur", "from", "play", "against", "video", "game", "one", "such", "exampl", "the", "mario", "program", "mario", "program", "learn", "play", "super", "mario", "world", "mario", "artifici", "intellig", "applic", "that", "has", "learn", "how", "play", "the", "video", "game", "super", "mario", "world", "see", "figur", "num", "figur", "num", "mario", "play", "super", "mario", "world", "video", "game", "some", "key", "point", "learn", "from", "mario", "mario", "use", "random", "step", "start", "explor", "process", "and", "restart", "whenev", "stall", "mario", "take", "input", "sens", "white", "box", "safe", "land", "area", "and", "black", "box", "obstacl", "reward", "fit", "point", "the", "case", "mario", "brother", "and", "punish", "death", "guid", "the", "learn", "process", "tri", "maxim", "reward", "while", "minim", "elimin", "punish", "sometim", "lose", "fail", "the", "onli", "way", "learn", "figur", "num", "show", "the", "progress", "that", "mario", "made", "learn", "the", "environ", "order", "maxim", "fit", "point", "and", "surviv", "figur", "num", "mario", "learn", "curv", "but", "mario", "super", "world", "determinist", "known", "environ", "where", "the", "game", "pattern", "repeat", "themselv", "for", "exampl", "the", "chart", "figur", "num", "show", "ani", "regress", "perform", "where", "the", "model", "hit", "dead", "end", "and", "had", "retreat", "and", "reset", "itself", "retreat", "common", "behavior", "that", "the", "more", "advanc", "model", "must", "support", "and", "the", "game", "play", "strategi", "this", "model", "veri", "simpl", "just", "surviv", "there", "strategi", "maxim", "the", "number", "coin", "captur", "which", "equal", "import", "part", "play", "super", "mario", "world", "least", "want", "brag", "right", "with", "friend", "while", "the", "exercis", "definit", "educ", "not", "terribl", "applic", "for", "our", "smart", "car", "exampl", "grand", "theft", "auto", "the", "rescu", "appli", "reinforc", "learn", "teach", "car", "drive", "requir", "unbeliev", "huge", "quantiti", "data", "have", "bunch", "autonom", "car", "tool", "around", "the", "hood", "just", "can", "generat", "enough", "data", "fast", "enough", "optim", "the", "model", "necessari", "safe", "drive", "vehicl", "howev", "autonom", "car", "compani", "have", "discov", "much", "richer", "train", "environ", "grand", "theft", "auto", "the", "virtual", "environ", "within", "the", "video", "game", "grand", "theft", "auto", "realist", "that", "use", "generat", "data", "that", "near", "good", "that", "generat", "use", "realworld", "imageri", "the", "most", "current", "version", "grand", "theft", "auto", "has", "num", "type", "vehicl", "more", "than", "num", "differ", "unpredict", "pedestrian", "and", "anim", "num", "weather", "condit", "and", "countless", "bridg", "traffic", "signal", "tunnel", "and", "intersect", "near", "imposs", "for", "autonom", "car", "manufactur", "oper", "enough", "vehicl", "enough", "differ", "situat", "generat", "the", "amount", "data", "that", "can", "virtual", "gather", "play", "against", "grand", "theft", "auto", "reinforc", "learn", "summari", "ultim", "reinforc", "learn", "model", "develop", "need", "wrestl", "with", "real", "not", "virtual", "random", "obstacl", "that", "pop", "the", "normal", "drive", "vehicl", "grand", "theft", "auto", "might", "great", "for", "teach", "vehicl", "how", "oper", "environ", "with", "hoodlum", "robberi", "heist", "and", "gratuit", "car", "chase", "but", "more", "realworld", "experi", "need", "order", "for", "autonom", "car", "learn", "handl", "the", "random", "lifeendang", "threat", "such", "child", "chase", "ball", "into", "the", "street", "new", "pothol", "caus", "some", "undocu", "construct", "random", "debri", "fall", "off", "truck", "bed", "one", "recent", "technolog", "develop", "that", "might", "the", "key", "solv", "imposs", "problem", "like", "autonom", "drive", "quantum", "comput", "futur", "blog", "will", "explor", "how", "combin", "artifici", "intellig", "with", "quantum", "comput", "might", "just", "help", "solv", "the", "imposs", "problem", "articl", "sourc", "reinforc", "learn", "and", "the", "internet", "thing", "numreinforcementlearninginternetthingshtml"], "timestamp_scraper": 1556374080.606808, "title": "Transforming from Autonomous to Smart: Reinforcement Learning Basics", "read_time": 424.5, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/william-schmarzo\" rel=\"author\" title=\"Posts by William Schmarzo\">William Schmarzo</a>, Hitachi Vantara.</b></div>\n<p>In the blog \u201c<a href=\"https://infocus.emc.com/william_schmarzo/autonomous-smart-artificial-intelligence/\" target=\"_blank\">From Autonomous to Smart: Importance of Artificial Intelligence</a>,\u201d we laid out the artificial intelligence (AI) challenges in creating \u201csmart\u201d edge devices:</p>\n<ul>\n<li>Artificial Intelligence Challenge #1: How do the Artificial Intelligence algorithms handle the unexpected, such as flash flooding, terrorist attacks, earthquakes, tornadoes, police car chases, emergency vehicles, blown tires, a child chasing a ball into the street,\u00a0etc.?\n<li>Artificial Intelligence Challenge #2: The more complex the problem state, the more data storage (to retain known state history) and CPU processing power (to find the optimal or best solution) is required in the edge devices in order to create \u201csmart.\u201d\n</li></li></ul>\n<p>We also talked about how Moore\u2019s Law isn\u2019t going to bail us out of these challenges; that the growth of Internet of Things (IOT) data and the complexity of the problems that we are trying to address at the edge (think \u201csmart\u201d cars) is growing much faster than Moore\u2019s Law can accommodate.</p>\n<p>So we are going to use this blog to deep dive into the category of artificial intelligence called <strong>reinforcement learning.</strong>\u00a0We are going to see how reinforcement learning might help us to address these challenges; to <em>work smarter</em> at the edge when brute force technology advances will not suffice.</p>\n<p>\u00a0</p>\n<h3>Why Not Brute Force</h3>\n<p>\u00a0<br>\nWith the rapid increases in computing power, it\u2019s easy to get seduced into thinking that raw computing power can solve problems like smart edge devices (e.g., cars, trains, airplanes, wind turbines, jet engines, medical devices). But to understand the scope of the challenge, consider the following:</br></p>\n<ul>\n<li>Checkers has 500 billion billion (that\u2019s right, billion twice) possible board moves. That\u2019s 500,000,000,000,000,000,000 possible moves (that\u2019s 20 zeros).\n<li>The number of possible moves in a game of chess is a minimum of 10<sup>120</sup> moves (that\u2019s 120 zeros).\n</li></li></ul>\n<p>Look at the dramatic increase in the number of possible moves between checkers and chess even though the board layout is <strong><em>exactly the same</em></strong>. The only difference between checkers and chess is the types of moves that pieces can make. A checker has only two moves: forward diagonally and jump competitor\u2019s pieces diagonally (once a checker is \u201ckinged\u201d, then it can move diagonally both forward and backwards). In chess, the complexity of the chess piece only increases slightly (rooks can move forward and sideways a variable number of spaces, bishops can move diagonally a variable number of spaces, etc.), but the complexity of the potential solutions exploded (from 20 zeros to 120 zeros). And both checkers and chess operate in a deterministic environment, where all possible moves are known ahead of time and there are no surprises (unless your dog decides that he wants to play at the same time).</p>\n<p>Now think about the number and breadth of \u201cmoves\u201d or variables that need to be considered when driving a car in a nondeterministic (random) environment:\u00a0 weather (precipitation, snow, ice, black ice, wind), time of day (day time, twilight, night time, sun rise, sun set), road conditions (pot holes, bumpy, slick), traffic conditions (number of vehicles, types of vehicles, different speeds, different destinations). One can quickly see that the number of possible moves is staggering. We need a better answer than brute force.</p>\n<p>\u00a0</p>\n<h3>Reinforcement Learning to the Rescue</h3>\n<p>\u00a0<br>\n<strong>Reinforcement Learning</strong> is for situations where you don\u2019t have data sets with explicit known outcomes, but you do have a way to telling whether you are getting closer to your goal (<strong>reward function</strong>). Reinforcement learning learns through trial-and-error how to map situations to actions so as to maximize rewards. Actions may affect immediate rewards but actions may also affect subsequent or longer-term rewards, so the full extent of rewards must be considered when evaluating the reinforcement learning effectiveness (i.e., balancing short-term rewards like optimizing fuel consumption while driving a car balanced against the long-term rewards of getting to your destination on time and safely).</br></p>\n<p>Reinforcement learning is used to address two general problems:</p>\n<ul>\n<li>Prediction: How much reward can be expected for every combination of possible future states (e.g., how much can we collect from delinquent accounts based on the following steps?)\n<li>Control: By moving through all possible combinations of the environment (interacting with the environment or state space), find a combination of actions that maximizes reward and allows for optimal control (e.g., steering an autonomous vehicle, winning a game of chess).\n</li></li></ul>\n<p>The children\u2019s game of \u201cHotter or Colder\u201d is a good illustration of reinforcement learning; rather than getting a specific \u201cright or wrong\u201d answer with each data action, you\u2019ll get a delayed reaction and only a hint of whether you\u2019re heading in the right direction (hotter or colder).</p>\n<p>\u00a0</p>\n<h3>Reinforcement Learning and Video Games</h3>\n<p>\u00a0<br>\nReinforcement learning needs lots and lots of data from which to learn and very powerful compute to support its \u201ctrial and error\u201d learning approach. Because it can take a considerable amount of time to gather enough data across enough scenarios in the real world, many of the advances in reinforcement learning are occurring from playing against video games.</br></p>\n<p>One such example is the MarI/O program (\u2018<a href=\"http://www.techtimes.com/articles/60573/20150615/mari-o-ai-program-learns-play-super-mario-world.htm\" target=\"_blank\">MarI/O AI Program Learns To Play Super Mario World\u2019</a>). MarI/O is an artificial intelligence application that has learned how to play the video game \u201cSuper Mario World\u201d (see Figure 1).</p>\n<p><center><img alt=\"Figure 1: MarI/O Playing \u201cSuper Mario World\u201d Video Game\" src=\"https://infocus.emc.com/wp-content/uploads/2017/07/mario.png\" width=\"70%\"/><br>\n<font size=\"-1\">Figure 1: MarI/O Playing \u201cSuper Mario World\u201d Video Game</font></br></center></p>\n<p>Some key points to learn from MarI/O:</p>\n<ul>\n<li>MarI/O uses random steps to start its exploration process and to re-start whenever it stalls.\n<li>MarI/O takes inputs by sensing white boxes (safe landing areas) and black boxes (obstacles).\n<li>Rewards (Fitness points in the case of Mario Brothers) and punishment (death) guide the learning process (try to maximize rewards while minimizing or eliminating punishments)\n<li>Sometimes losing (failing) is the only way to learn.\n</li></li></li></li></ul>\n<p>Figure 2 shows the progress that MarI/O made in learning the environment in order to maximize its fitness points and survive.</p>\n<p><center><img alt=\"Figure 2:\u00a0MarI/O Learning Curve\" src=\"https://infocus.emc.com/wp-content/uploads/2017/07/fitness.png\" width=\"70%\"/><br/>\n<font size=\"-1\">Figure 2:\u00a0MarI/O Learning Curve</font></center></p>\n<p>But \u201cMario Super World\u201d is a deterministic or known environment where the gaming patterns repeat themselves. For example, the chart in Figure 2 doesn\u2019t show any regressions in performance, where the AI model hit a dead end and had to retreat and re-set itself. Retreating is a common behavior that the more advanced AI models must support.</p>\n<p>And the game playing strategy in this model is very simple \u2013 just survive. There is no strategy to maximize the number of coins captured, which is an equally important part of playing Super Mario World (or at least if you want bragging rights with your friends).</p>\n<p>So while the exercise is definitely educational, it\u2019s not terribly application for our smart car example.</p>\n<p>\u00a0</p>\n<h3>Grand Theft Auto to the Rescue!</h3>\n<p>\u00a0<br/>\nApplying reinforcement learning to teach a car to drive requires an unbelievably huge quantity of data. Having a bunch of autonomous car tooling around the \u2018hood just can\u2019t generate enough data fast enough to optimize the models necessary to safely drive a vehicle. However, autonomous car companies have discovered a much richer training environment \u2013 Grand Theft Auto!</p>\n<p><img alt=\"car\" class=\"aligncenter\" src=\"https://infocus.emc.com/wp-content/uploads/2017/07/car.jpg\" width=\"99%\"/></p>\n<p>The virtual environment within the video game Grand Theft Auto is so realistic that it is being used to generate data that\u2019s nearly as good as that generated by using real-world imagery. The most current version of Grand Theft Auto has 262 types of vehicles, more than 1,000 different unpredictable pedestrians and animals, 14 weather conditions and countless bridges, traffic signals, tunnels and intersections. It\u2019s nearly impossible for an autonomous car manufacturer to operate enough vehicles in enough different situations to generate the amount of data that can be virtually gathered by playing against Grand Theft Auto.</p>\n<p>\u00a0</p>\n<h3>Reinforcement Learning Summary</h3>\n<p>\u00a0<br/>\nUltimately, reinforcement learning model development is going to need to wrestle with real (not virtual) random obstacles that pop up in the normal driving of a vehicle. Grand Theft Auto might be great for teaching vehicles how to operate in an environment with hoodlums, robberies, heists and gratuitous car chases, but more real-world experience is going to be needed in order for autonomous cars to learn to handle the random, life-endangering threats, such as a child chasing a ball into the street, a new pothole caused by some (undocumented) construction or random debris falling off of truck beds.</p>\n<p>One recent technology development that might be the key to solving \u201cimpossible\u201d problems like autonomous driving is quantum computing. A future blog will explore how combining artificial intelligence with quantum computing might just help us solve the \u201cimpossible\u201d problems.</p>\n<p>\u00a0<br/>\n<b>Article Sources:</b></p>\n<ul>\n<li>Reinforcement Learning and the Internet of Things<br/>\n<a href=\"/2016/08/reinforcement-learning-internet-things.html\" target=\"_blank\">/2016/08/reinforcement-learning-internet-things.html</a></li></ul></div> ", "website": "kdnuggets"}