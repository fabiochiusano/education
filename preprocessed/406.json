{"title": "Pedestrian Detection in Aerial Images Using RetinaNet", "tfidf": {"tfidf": {"occlud": 529.2, "decreas": 4.5230769230800005, "but": 1.01632417899, "test": 2.65707112971, "famous": 2.28201811125, "generat": 2.05275407292, "veri": 1.25880114177, "see": 1.27242125511, "from": 2.00113442994, "for": 1.00031504001, "shade": 16.979679144400002, "consult": 5.21721984883, "model": 2.0905978404, "interest": 1.60331246213, "which": 1.005191845, "detect": 21.65155131264, "this": 2.00758725342, "object": 11.744340878850002, "have": 2.0297896822799997, "set": 1.18707940781, "introduct": 2.7808723068799996, "below": 2.25607503197, "stanford": 12.6, "can": 1.17626139142, "sinc": 1.08368600683, "sampl": 7.23280182232, "priyanka": 1323.0, "harder": 17.1262135922, "amount": 2.27027027027, "wide": 1.5598349381, "challeng": 7.674508540110001, "link": 2.15151104486, "carsplan": 1323.0, "few": 2.63458347162, "kochhar": 1323.0, "will": 1.22481098596, "biker": 132.3, "want": 1.99698113208, "blog": 28.3753351206, "valuabl": 7.46754468485, "imag": 10.80551301684, "surg": 17.294117647100002, "with": 1.0011982089899998, "onli": 2.0512953033200003, "data": 10.12930667802, "cost": 2.31935719503, "detector": 45.6206896552, "there": 2.08182533438, "sever": 1.07241286139, "read": 2.3149606299200003, "deep": 3.6279707495399998, "retina": 138.052173913, "use": 1.0296387573799999, "even": 1.16461267606, "inform": 1.5753125620200001, "problem": 3.53349655018, "aerial": 81.83505154619999, "pixel": 86.28260869569999, "learn": 2.32275054865, "stage": 2.0831911822599998, "that": 1.00398406375, "most": 2.04192926046, "extract": 7.703056768560001, "pedestrian": 50.0820189274, "comment": 3.05954904606, "and": 4.00025196852, "the": 3.0, "net": 6.96315789474, "out": 1.06016694491, "singl": 1.60948905109, "are": 4.11962374312, "drone": 105.84, "especi": 1.66712170534, "some": 1.04036697248}, "idf": {"occlud": 529.2, "decreas": 4.5230769230800005, "but": 1.01632417899, "test": 2.65707112971, "famous": 2.28201811125, "generat": 2.05275407292, "veri": 1.25880114177, "see": 1.27242125511, "from": 1.00056721497, "for": 1.00031504001, "shade": 16.979679144400002, "consult": 5.21721984883, "model": 2.0905978404, "interest": 1.60331246213, "which": 1.005191845, "detect": 5.41288782816, "this": 1.00379362671, "object": 2.3488681757700003, "have": 1.0148948411399998, "set": 1.18707940781, "introduct": 2.7808723068799996, "below": 2.25607503197, "stanford": 12.6, "can": 1.17626139142, "sinc": 1.08368600683, "sampl": 7.23280182232, "priyanka": 1323.0, "harder": 17.1262135922, "amount": 2.27027027027, "wide": 1.5598349381, "challeng": 2.55816951337, "link": 2.15151104486, "carsplan": 1323.0, "few": 1.31729173581, "kochhar": 1323.0, "will": 1.22481098596, "biker": 132.3, "want": 1.99698113208, "blog": 14.1876675603, "valuabl": 7.46754468485, "imag": 2.70137825421, "surg": 17.294117647100002, "with": 1.0011982089899998, "onli": 1.0256476516600002, "data": 3.37643555934, "cost": 2.31935719503, "detector": 45.6206896552, "there": 1.04091266719, "sever": 1.07241286139, "read": 2.3149606299200003, "deep": 3.6279707495399998, "retina": 138.052173913, "use": 1.0296387573799999, "even": 1.16461267606, "inform": 1.5753125620200001, "problem": 1.76674827509, "aerial": 13.6391752577, "pixel": 86.28260869569999, "learn": 2.32275054865, "stage": 2.0831911822599998, "that": 1.00398406375, "most": 1.02096463023, "extract": 7.703056768560001, "pedestrian": 25.0410094637, "comment": 3.05954904606, "and": 1.00006299213, "the": 1.0, "net": 6.96315789474, "out": 1.06016694491, "singl": 1.60948905109, "are": 1.02990593578, "drone": 52.92, "especi": 1.66712170534, "some": 1.04036697248}, "logidf": {"occlud": 6.27136643224, "decreas": 1.50919249744, "but": 0.0161923720719, "test": 0.977224437103, "famous": 0.825060187979, "generat": 0.719182341736, "veri": 0.230159793238, "see": 0.240921585492, "from": 0.000567054168866, "for": 0.00031499039539700004, "shade": 2.8320172846099996, "consult": 1.6519646640099999, "model": 0.7374500731110001, "interest": 0.47207177798199995, "which": 0.00517841384543, "detect": 1.68878274493, "this": 0.0037864490525, "object": 0.853933584803, "have": 0.0147850023412, "set": 0.171496011289, "introduct": 1.02276465794, "below": 0.813626591936, "stanford": 2.53369681396, "can": 0.162341096394, "sinc": 0.0803681994577, "sampl": 1.9786264883900002, "priyanka": 7.18765716411, "harder": 2.84061024834, "amount": 0.819898886199, "wide": 0.44458000675399995, "challeng": 0.9392919688950001, "link": 0.7661704068449999, "carsplan": 7.18765716411, "few": 0.275577913653, "kochhar": 7.18765716411, "will": 0.202786534915, "biker": 4.88507207112, "want": 0.6916366062549999, "blog": 2.65237310559, "valuabl": 2.010566255, "imag": 0.99376210729, "surg": 2.85036642328, "with": 0.00119749171339, "onli": 0.025324268329099998, "data": 1.2168205848, "cost": 0.84129007618, "detector": 3.8203613341300007, "there": 0.0400978929255, "sever": 0.06991112039689999, "read": 0.83939268088, "deep": 1.2886734698, "retina": 4.927631685540001, "use": 0.0292080197316, "even": 0.152388564834, "inform": 0.454453704662, "problem": 0.569140724273, "aerial": 2.61294618561, "pixel": 4.45762805629, "learn": 0.842752064745, "stage": 0.733900940237, "that": 0.00397614837964, "most": 0.020747896295599998, "extract": 2.04161723301, "pedestrian": 3.22051485947, "comment": 1.11826753454, "and": 6.29901420636e-05, "the": 0.0, "net": 1.9406330919499999, "out": 0.0584263909193, "singl": 0.475916769059, "are": 0.0294674735827, "drone": 3.96878133925, "especi": 0.511098609709, "some": 0.0395735090645}, "freq": {"occlud": 1, "decreas": 1, "but": 1, "test": 1, "famous": 1, "generat": 1, "veri": 1, "see": 1, "from": 2, "for": 1, "shade": 1, "consult": 1, "model": 1, "interest": 1, "which": 1, "detect": 4, "this": 2, "object": 5, "have": 2, "set": 1, "introduct": 1, "below": 1, "stanford": 1, "can": 1, "sinc": 1, "sampl": 1, "priyanka": 1, "harder": 1, "amount": 1, "wide": 1, "challeng": 3, "link": 1, "carsplan": 1, "few": 2, "kochhar": 1, "will": 1, "biker": 1, "want": 1, "blog": 2, "valuabl": 1, "imag": 4, "surg": 1, "with": 1, "onli": 2, "data": 3, "cost": 1, "detector": 1, "there": 2, "sever": 1, "read": 1, "deep": 1, "retina": 1, "use": 1, "even": 1, "inform": 1, "problem": 2, "aerial": 6, "pixel": 1, "learn": 1, "stage": 1, "that": 1, "most": 2, "extract": 1, "pedestrian": 2, "comment": 1, "and": 4, "the": 3, "net": 1, "out": 1, "singl": 1, "are": 4, "drone": 2, "especi": 1, "some": 1}, "logtfidf": {"occlud": 6.27136643224, "decreas": 1.50919249744, "but": 0.0161923720719, "test": 0.977224437103, "famous": 0.825060187979, "generat": 0.719182341736, "veri": 0.230159793238, "see": 0.240921585492, "from": 0.001134108337732, "for": 0.00031499039539700004, "shade": 2.8320172846099996, "consult": 1.6519646640099999, "model": 0.7374500731110001, "interest": 0.47207177798199995, "which": 0.00517841384543, "detect": 6.75513097972, "this": 0.007572898105, "object": 4.269667924015, "have": 0.0295700046824, "set": 0.171496011289, "introduct": 1.02276465794, "below": 0.813626591936, "stanford": 2.53369681396, "can": 0.162341096394, "sinc": 0.0803681994577, "sampl": 1.9786264883900002, "priyanka": 7.18765716411, "harder": 2.84061024834, "amount": 0.819898886199, "wide": 0.44458000675399995, "challeng": 2.8178759066850003, "link": 0.7661704068449999, "carsplan": 7.18765716411, "few": 0.551155827306, "kochhar": 7.18765716411, "will": 0.202786534915, "biker": 4.88507207112, "want": 0.6916366062549999, "blog": 5.30474621118, "valuabl": 2.010566255, "imag": 3.97504842916, "surg": 2.85036642328, "with": 0.00119749171339, "onli": 0.050648536658199995, "data": 3.6504617544, "cost": 0.84129007618, "detector": 3.8203613341300007, "there": 0.080195785851, "sever": 0.06991112039689999, "read": 0.83939268088, "deep": 1.2886734698, "retina": 4.927631685540001, "use": 0.0292080197316, "even": 0.152388564834, "inform": 0.454453704662, "problem": 1.138281448546, "aerial": 15.67767711366, "pixel": 4.45762805629, "learn": 0.842752064745, "stage": 0.733900940237, "that": 0.00397614837964, "most": 0.041495792591199995, "extract": 2.04161723301, "pedestrian": 6.44102971894, "comment": 1.11826753454, "and": 0.0002519605682544, "the": 0.0, "net": 1.9406330919499999, "out": 0.0584263909193, "singl": 0.475916769059, "are": 0.1178698943308, "drone": 7.9375626785, "especi": 0.511098609709, "some": 0.0395735090645}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Pedestrian Detection in Aerial Images Using RetinaNet</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Pedestrian Detection in Aerial Images Using RetinaNet Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/data-science-decision-makers.html\" rel=\"prev\" title=\"Data Science for Decision Makers: A Discussion with Dr Stelios Kampakis\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/four-levels-analytics-maturity.html\" rel=\"next\" title=\"The Four Levels of Analytics Maturity\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=92220\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-92220 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 26-Mar, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/tutorials.html\">Tutorials, Overviews</a> \u00bb Pedestrian Detection in Aerial Images Using RetinaNet (\u00a0<a href=\"/2019/n12.html\">19:n12</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Pedestrian Detection in Aerial Images Using RetinaNet</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/data-science-decision-makers.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/four-levels-analytics-maturity.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/ai\" rel=\"tag\">AI</a>, <a href=\"https://www.kdnuggets.com/tag/computer-vision\" rel=\"tag\">Computer Vision</a>, <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/keras\" rel=\"tag\">Keras</a>, <a href=\"https://www.kdnuggets.com/tag/object-detection\" rel=\"tag\">Object Detection</a>, <a href=\"https://www.kdnuggets.com/tag/retina-net\" rel=\"tag\">Retina Net</a></div>\n<br/>\n<p class=\"excerpt\">\n     Object Detection in Aerial Images is a challenging and interesting problem. By using Keras to train a RetinaNet model for object detection in aerial images, we can use it to extract valuable information.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://github.com/priya-dwivedi\" rel=\"noopener noreferrer\" target=\"_blank\">Priyanka Kochhar</a>, Deep Learning Consultant</b></p>\n<h3>Introduction</h3>\n<p>\u00a0<br>\nObject Detection in Aerial Images is a challenging and interesting problem. With the cost of drones decreasing, there is a surge in amount of aerial data being generated. It will be very useful to have models that can extract valuable information from aerial data. <a href=\"https://arxiv.org/abs/1708.02002\" rel=\"noopener noreferrer\" target=\"_blank\">Retina Net </a>is the most famous single stage detector and in this blog, I want to test it out on an aerial images of pedestrians and bikers from the <a href=\"http://cvgl.stanford.edu/projects/uav_data/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford Drone Data set</a>. See a sample image below. This is a challenging problem since most objects are only a few pixels wide, some objects are occluded and objects in shade are even harder to detect. I have read several blogs of object detection on aerial images or cars/planes but there are only a few links for pedestrian detection aerially which is especially challenging.</br></p>\n<div style=\"text-align:center\"><img alt=\"figure-name\" src=\"/wp-content/uploads/aerial-images-pedestrians.jpeg\" width=\"99%\"><font size=\"-1\"></font></img></div></div></div></div></div></div></body></html>\n<div class=\"caption\">Aerial Images from Stanford drone dataset\u200a\u2014\u200aPedestrians in pink and Bikers in red</div>\n<p></p>\n\n<p>\u00a0</p>\n<h3>Retina Net</h3>\n<p>\u00a0<br>\n<a href=\"https://arxiv.org/abs/1708.02002\" rel=\"noopener noreferrer\" target=\"_blank\">RetinaNet</a> is a single stage detector that uses Feature Pyramid Network (FPN) and Focal loss for training. <a href=\"https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c\" rel=\"noopener noreferrer\" target=\"_blank\">Feature pyramid network</a> is a structure for multiscale object detection introduced in this <a href=\"https://arxiv.org/abs/1612.03144\" rel=\"noopener noreferrer\" target=\"_blank\">paper</a>. It combines low-resolution, semantically strong features with high-resolution, semantically weak features via a top-down pathway and lateral connections. The net result is that it produces feature maps of different scale on multiple levels in the network which helps with both classifier and regressor networks.</br></p>\n<p>The Focal Loss is designed to address the single-stage object detection problems with the imbalance where there is a very large number of possible background classes and just a few foreground classes. This causes training to be inefficient as most locations are easy negatives that contribute no useful signal and the massive amount of these negative examples overwhelm the training and reduces model performance. Focal loss is based on cross entropy loss as shown below and by adjusting the gamma parameter, we can reduce the loss contribution from well classified examples.</p>\n<div style=\"text-align:center\"><img alt=\"Focal Loss Explanation\" src=\"/wp-content/uploads/focal-loss.png\" width=\"99%\"/><font size=\"-1\"></font></div>\n<div>Focal Loss Explanation</div>\n<p></p>\n\n<p>In this blog, I want to talk about how to train a RetinaNet model on Keras. I haven\u2019t done enough justice to the theory behind RetinaNet. I used this <a href=\"https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d\" rel=\"noopener noreferrer\" target=\"_blank\">link</a> to understand the model and would highly recommend it. My first trained model worked quite well in detecting objects aerially as shown in the video below. I have also open sourced the code on my <a href=\"https://github.com/priya-dwivedi/keras_retinanet_cs230\" rel=\"noopener noreferrer\" target=\"_blank\">Github link</a>.</p>\n<div style=\"text-align:center\"><img alt=\"Retina Net on Aerial Images of pedestrians and bikers\" src=\"https://i.ibb.co/zHb8nSK/retina-net-aerial-images-pedestrians.gif\" width=\"99%\"/><font size=\"-1\"></font></div>\n<div class=\"caption\">Retina Net on Aerial Images of pedestrians and bikers</div>\n<p></p>\n\n<p>\u00a0</p>\n<h3>Stanford Drone DataSet</h3>\n<p>\u00a0<br>\n<a href=\"http://cvgl.stanford.edu/projects/uav_data/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford Drone Data</a> is a massive data set of aerial images collected by drone over the Stanford campus. The data set is ideal for object detection and tracking problems. It contains about 60 aerial videos. For each video we have bounding box coordinates for the 6 classes\u200a\u2014\u200a\u201cPedestrian\u201d, \u201cBiker\u201d, \u201cSkateboarder\u201d, \u201cCart\u201d, \u201cCar\u201d and \u201c Bus\u201d. The data set is very rich in pedestrians and bikers with these 2 classes covering about 85%-95% of the annotations.</br></p>\n<p>\u00a0</p>\n<h3>Training a RetinaNet in Keras on Stanford Drone Data Set</h3>\n<p>\u00a0<br>\nTo train the Retina Net, I used <a href=\"https://github.com/fizyr/keras-retinanet\" rel=\"noopener noreferrer\" target=\"_blank\">this implementation</a> in Keras. It is very well documented and works without bugs. Thanks a lot to Fizyr for open sourcing their implementation!<br/>\nThe main steps I followed were:</br></p>\n<ul>\n<li>Selecting a sample of images from the massive stanford drone data set for building the model. I took about 2200 training images with 30,000+ annoations and kept around 1000 images for validation. I have put my image data set on google drive <a href=\"https://drive.google.com/drive/u/0/folders/1bLt6KK_9zKogJdvW-lKh9BnBKgFfvPp9\" rel=\"noopener noreferrer\" target=\"_blank\">here</a> for anyone interested in skipping this step.</li>\n<li>Generating annotations in the format required for Retina Net. Retina Net requires all annotations to be in the format.</li>\n</ul>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\npath/to/image.jpg,x1,y1,x2,y2,class_name\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>I converted Stanford annotations in this format and my train and validation annotations are uploaded to my <a href=\"https://github.com/priya-dwivedi/keras_retinanet_cs230\" rel=\"noopener noreferrer\" target=\"_blank\">Github</a>.</p>\n<ul>\n<li>Adjusting the anchor sizes: The Retina Net has default anchor sizes of 32, 64, 128, 256, 512. These anchor sizes work well for most objects however since we are working on aerial images, some objects may be smaller than 32. This repo provides a handy tool for checking if existing anchors suffice. In the image below annotations in green are covered by existing in anchors and those in red are ignored. As can been seen a good portion of annotations are too small for even the smallest anchor size.</li>\n</ul>\n<div style=\"text-align:center\"><img alt=\"Retina Net with default anchors\" src=\"https://i.ibb.co/phXcNwt/retina-net-default-anchors.png\" width=\"99%\"/><font size=\"-1\"></font></div>\n<div class=\"caption\">Retina Net with default anchors</div>\n<p></p>\n\n<p>So I adjusted the anchors to drop the biggest one of 512 and instead add a small anchor of size 16. This results in a noticeable improvement as shown below:</p>\n<div style=\"text-align:center\"><img alt=\"After adding a small anchor\" src=\"https://i.ibb.co/h2J9fgT/retina-net-add-small-anchor.png\" width=\"99%\"/><font size=\"-1\"></font></div>\n<div class=\"caption\">After adding a small anchor</div>\n<p></p>\n\n<ul>\n<li>With all this we are ready to start training. I kept most other default parameters including the Resnet50 backbone and started training by:</li>\n</ul>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nkeras_retinanet/bin/train.py --weights\r\nsnapshots/resnet50_coco_best_v2.1.0.h5  --config config.ini\r\ncsv train_annotations.csv labels.csv --val-annotations\r\nval_annotations.csv\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Here weights are the COCO weights that can be used to jump start training. The annotations for training and validation are the input data and config.ini has the updated anchor sizes. All the files are on my <a href=\"https://github.com/priya-dwivedi/keras_retinanet_cs230\" rel=\"noopener noreferrer\" target=\"_blank\">Github repo </a>too.</p>\n<p>That\u2019s it! The model is slow to train and I trained it overnight. I tested the accuracy of the trained model by checking for <strong>mean average precision (MAP) </strong>on the test set. As can be seen below the first trained model had a very good MAP of 0.63. The performance is especially good on car and bus classes which are easy to see aerially. The MAP on Biker class is low as this is often confused by pedestrian. I am currently working on further improving accuracy of the Biker class.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nBiker: 0.4862\r\nCar:0.9363\r\nBus: 0.7892\r\nPedestrian: 0.7059\r\nWeighted: 0.6376\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3>Conclusion</h3>\n<p>\u00a0<br/>\nRetina Net is a powerful model that uses Feature Pyramid Networks. It is able to detect objects aerially on a very challenging data set where object sizes are quite small. I was able to train a Retina Net with half a day of work. The first version of the trained model has pretty good performance. I am still exploring how to further adapt Retina Net architecture to have a higher accuracy in aerial detection. That will be covered in my next blog.</p>\n<p>I hope you liked the blog and try training the model yourself too.</p>\n<p>I have my own deep learning consultancy and love to work on interesting problems. I have helped many startups deploy innovative AI based solutions. Check us out at\u200a\u2014\u200a<a href=\"http://deeplearninganalytics.org/\" rel=\"noopener noreferrer\" target=\"_blank\">http://deeplearninganalytics.org/</a>.</p>\n<p>You can also see my other writings at: <a href=\"http://deeplearninganalytics.org/blog\" rel=\"noopener noreferrer\" target=\"_blank\">http://deeplearninganalytics.org/blog</a></p>\n<p>If you have a project that we can collaborate on, then please contact me through my website or at priya.toronto3@gmail.com</p>\n<p>\u00a0</p>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d\" rel=\"noopener noreferrer\" target=\"_blank\">Retina Net</a></li>\n<li><a href=\"http://cvgl.stanford.edu/projects/uav_data/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford Drone Data Set</a></li>\n<li><a href=\"https://github.com/fizyr/keras-retinanet\" rel=\"noopener noreferrer\" target=\"_blank\">Retina Net Keras Implementation</a></li>\n</ul>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://github.com/priya-dwivedi\" rel=\"noopener noreferrer\" target=\"_blank\">Priyanka Kochhar</a></b> has been a data scientist for 10+ years. She now has her own deep learning consultancy and loves to work on interesting problems. She has helped several startups deploy innovative AI based solutions. If you have a project that she can collaborate on then please contact her at <a href=\"mailto:priya.toronto3@gmail.com\">priya.toronto3@gmail.com</a></p>\n<p><a href=\"https://towardsdatascience.com/pedestrian-detection-in-aerial-images-using-retinanet-9053e8a72c6\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2019/03/people-tracking-using-deep-learning.html\">People Tracking using Deep Learning </a>\n<li><a href=\"/2018/10/introduction-deep-learning-keras.html\">Introduction to Deep Learning with Keras</a>\n<li><a href=\"/2018/08/auto-keras-create-deep-learning-model-4-lines-code.html\">The Keras 4 Step Workflow</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/data-science-decision-makers.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/four-levels-analytics-maturity.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-1-another-10');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-2-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/03/data-science-job-applications.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-3-tell-you');\"><b>What no one will tell you about data science job applications</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/02/asking-great-questions-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-5-great-questions');\"><b>Asking Great Questions as a Data Scientist</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/03/women-ai-big-data-science-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-7-19-inspiring-women');\"><b>19 Inspiring Women in AI, Big Data, Data Science, Machine Learning</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-1-ann-genetic');\"><b>Artificial Neural Networks Optimization using Genetic Algorithm with Python</b></a>\n<li> <a href=\"/2019/02/artificial-neural-network-implementation-using-numpy-and-image-classification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-2-ann-numpy-images');\"><b>Artificial Neural Network Implementation using NumPy and Image Classification</b></a>\n<li> <a href=\"/2019/02/setup-python-environment-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-3-py-ml-setup');\"><b>How to Setup a Python Environment for Machine Learning</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-5-azure-cert');\"><b>8 Reasons Why You Should Get a Microsoft Azure Certification</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/02/running-r-and-python-in-jupyter.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-7-r-python-jupyter');\"><b>Running R and Python in Jupyter</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end-->\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/03/datathon-data-science-hackathon-april.html\">Datathon 2019: The International Data Science Hackathon...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/random-forest-python.html\">Explaining Random Forest (with Python Implementation)</a><li> <a href=\"https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html\">A Beginner\u2019s Guide to Linear Regression in Python wit...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html\">Interpolation in Autoencoders via an Adversarial Regula...</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/03-29-cisco-machine-learning-engineer-support-bot-b.html\">Cisco: Machine Learning Engineer/Support Bot Designer [...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/delaware-gain-skills-need-data-driven-career.html\">Gain the Skills You Need to Level-Up in Your Data-Drive...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n<div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/tutorials.html\">Tutorials, Overviews</a> \u00bb Pedestrian Detection in Aerial Images Using RetinaNet (\u00a0<a href=\"/2019/n12.html\">19:n12</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end-->\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1554079176\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"bottom-left\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"bottom-left\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper-->\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 1.385 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-03-31 20:39:36 -->\n<!-- Compression = gzip -->", "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://github.com/priya-dwivedi\" rel=\"noopener noreferrer\" target=\"_blank\">Priyanka Kochhar</a>, Deep Learning Consultant</b></p>\n<h3>Introduction</h3>\n<p>\u00a0<br>\nObject Detection in Aerial Images is a challenging and interesting problem. With the cost of drones decreasing, there is a surge in amount of aerial data being generated. It will be very useful to have models that can extract valuable information from aerial data. <a href=\"https://arxiv.org/abs/1708.02002\" rel=\"noopener noreferrer\" target=\"_blank\">Retina Net </a>is the most famous single stage detector and in this blog, I want to test it out on an aerial images of pedestrians and bikers from the <a href=\"http://cvgl.stanford.edu/projects/uav_data/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford Drone Data set</a>. See a sample image below. This is a challenging problem since most objects are only a few pixels wide, some objects are occluded and objects in shade are even harder to detect. I have read several blogs of object detection on aerial images or cars/planes but there are only a few links for pedestrian detection aerially which is especially challenging.</br></p>\n<div style=\"text-align:center\"><img alt=\"figure-name\" src=\"/wp-content/uploads/aerial-images-pedestrians.jpeg\" width=\"99%\"><font size=\"-1\"></font></img></div></div>", "content": "comments By Priyanka Kochhar, Deep Learning Consultant Introduction \u00a0 Object Detection in Aerial Images is a challenging and interesting problem. With the cost of drones decreasing, there is a surge in amount of aerial data being generated. It will be very useful to have models that can extract valuable information from aerial data. Retina Net is the most famous single stage detector and in this blog, I want to test it out on an aerial images of pedestrians and bikers from the Stanford Drone Data set. See a sample image below. This is a challenging problem since most objects are only a few pixels wide, some objects are occluded and objects in shade are even harder to detect. I have read several blogs of object detection on aerial images or cars/planes but there are only a few links for pedestrian detection aerially which is especially challenging.", "read_time": 43.8, "title_html": "<h1 id=\"title\">Pedestrian Detection in Aerial Images Using RetinaNet</h1>", "url": "https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html"}