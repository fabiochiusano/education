{"content": "By Rachel Thomas, Co-founder at fast.ai . An all-too-common scenario: a seemingly impressive machine learning model is a complete failure when implemented in production. The fallout includes leaders who are now skeptical of machine learning and reluctant to try it again. How can this happen? One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a\u00a0 train_test_split method , this method takes a random subset of the data, which is a poor choice for many real-world problems. The definitions of\u00a0 training ,\u00a0 validation , and\u00a0 test \u00a0sets can be fairly nuanced, and the terms are sometimes inconsistently used. In the deep learning community, \u201ctest-time inference\u201d is often used to refer to evaluating on data in production, which is not the technical definition of a test set. As mentioned above, sklearn has a\u00a0 train_test_split \u00a0method, but no train_validation_test_split . Kaggle only provides training and test sets, yet to do well, you will need to split their training set into your own validation and training sets. Also, it turns out that Kaggle\u2019s test set is actually sub-divided into two sets. It\u2019s no suprise that many beginners may be confused! I will address these subtleties below. \u00a0 First, what is a \u201cvalidation set\u201d? \u00a0 When creating a machine learning model, the ultimate goal is for it to be accurate on new data, not just the data you are using to build it. Consider the below example of 3 different models for a set of data: Source:\u00a0 Quora The error for the pictured data points is lowest for the model on the far right (the blue curve passes through the red points almost perfectly), yet it\u2019s not the best choice. Why is that? If you were to gather some new data points, they most likely would not be on that curve in the graph on the right, but would be closer to the curve in the middle graph. The underlying idea is that: the training set is used to train a given model the validation set is used to choose between models (for instance, does a random forest or a neural net work better for your problem? do you want a random forest with 40 trees or 50 trees?) the test set tells you how you\u2019ve done. If you\u2019ve tried out a lot of different models, you may get one that does well on your validation set just by chance, and having a test set helps make sure that is not the case. A key property of the validation and test sets is that they must be representative of the\u00a0 new data you will see in the future . This may sound like an impossible order! By definition, you haven\u2019t seen this data yet. But there are still a few things you know about it. \u00a0 When is a random subset not good enough? \u00a0 It\u2019s instructive to look at a few examples. Although many of these examples come from Kaggle competitions, they are representative of problems you would see in the workplace. Time series If your data is a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates your are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future). If your data includes the date and you are building a model to use in the future, you will want to choose a continuous section with the latest dates as your validation set (for instance, the last two weeks or last month of the available data). Suppose you want to split the time series data below into training and validation sets: Time series data A random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you\u2019ll need in production): A poor choice for your training set Use the earlier data as your training set (and the later data for the validation set): A better choice for your training set Kaggle currently has a competition to\u00a0 predict the sales in a chain of Ecuadorian grocery stores . Kaggle\u2019s \u201ctraining data\u201d runs from Jan 1 2013 to Aug 15 2017 and the test data spans Aug 16 2017 to Aug 31 2017. A good approach would be to use Aug 1 to Aug 15 2017 as your validation set, and all the earlier data as your training set. New people, new boats, new... You also need to think about what ways the data you will be making predictions for in production may be\u00a0 qualitatively different \u00a0from the data you have to train your model with. In the Kaggle\u00a0 distracted driver competition , the independent data are pictures of drivers at the wheel of a car, and the dependent variable is a category such as texting, eating, or safely looking ahead. If you were the insurance company building a model from this data, note that you would be most interested in how the model performs on drivers you haven\u2019t seen before (since you would likely have training data only for a small group of people). This is true of the Kaggle competition as well: the test data consists of people that weren\u2019t used in the training set. Two images of the same person talking on the phone while driving. If you put one of the above images in your training set and one in the validation set, your model will seem to be performing better than it would on new people. Another perspective is that if you used all the people in training your model, your model may be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc). A similar dynamic was at work in the\u00a0 Kaggle fisheries competition \u00a0to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations. The test set consisted of boats that didn\u2019t appear in the training data. This means that you\u2019d want your validation set to include boats that are not in the training set. Sometimes it may not be clear how your test data will differ. For instance, for a problem using satellite imagery, you\u2019d need to gather more information on whether the training set just contained certain geographic locations, or if it came from geographically scattered data. \u00a0 The dangers of cross-validation \u00a0 The reason that sklearn doesn\u2019t have a\u00a0 train_validation_test \u00a0split is that it is assumed you will often be using\u00a0 cross-validation , in which different subsets of the training set serve as the validation set. For example, for a 3-fold cross validation, the data is divided into 3 sets: A, B, and C. A model is first trained on A and B combined as the training set, and evaluated on the validation set C. Next, a model is trained on A and C combined as the training set, and evaluated on validation set B. And so on, with the model performance from the 3 folds being averaged in the end. However, the problem with cross-validation is that it is rarely applicable to real world problems, for all the reasons described in the above sections. Cross-validation only works in the same cases where you can randomly shuffle your data to choose a validation set. \u00a0 Kaggle\u2019s \u201ctraining set\u201d = your training + validation sets \u00a0 One great thing about Kaggle competitions is that they force you to think about validation sets more rigorously (in order to do well). For those who are new to Kaggle, it is a platform that hosts machine learning competitions. Kaggle typically breaks the data into two sets you can download: a\u00a0 training set , which includes the\u00a0 independent variables , as well as the\u00a0 dependent variable \u00a0(what you are trying to predict). For the example of an Ecuadorian grocery store trying to predict sales, the independent variables include the store id, item id, and date; the dependent variable is the number sold. For the example of trying to determine whether a driver is engaging in dangerous behaviors behind the wheel, the independent variable could be a picture of the driver, and the dependent variable is a category (such as texting, eating, or safely looking forward). a\u00a0 test set , which just has the independent variables. You will make predictions for the test set, which you can submit to Kaggle and get back a score of how well you did. This is the basic idea needed to get started with machine learning, but to do well, there is a bit more complexity to understand. You will want to create your own training and validation sets (by splitting the Kaggle \u201ctraining\u201d data). You will just use your smaller training set (a subset of Kaggle\u2019s training data) for building your model, and you can evaluate it on your validation set (also a subset of Kaggle\u2019s training data) before you submit to Kaggle. The most important reason for this is that Kaggle has split the test data into two sets: for the public and private leaderboards. The score you see on the public leaderboard is just for a subset of your predictions (and you don\u2019t know which subset!). How your predictions fare on the private leaderboard won\u2019t be revealed until the end of the competition. The reason this is important is that you could end up overfitting to the public leaderboard and you wouldn\u2019t realize it until the very end when you did poorly on the private leaderboard. Using a good validation set can prevent this. You can check if your validation set is any good by seeing if your model has similar scores on it to compared with on the Kaggle test set. Another reason it\u2019s important to create your own validation set is that Kaggle limits you to two submissions per day, and you will likely want to experiment more than that. Thirdly, it can be instructive to see exactly what you\u2019re getting wrong on the validation set, and Kaggle doesn\u2019t tell you the right answers for the test set or even which data points you\u2019re getting wrong, just your overall score. Understanding these distinctions is not just useful for Kaggle. In any predictive machine learning project, you want your model to be able to perform well on new data. \u00a0 Bio: Rachel Thomas is co-founder at fast.ai and a professor of the MS in Analytics program at the University of San Francisco. She is also an Ask-a-Data-Scientist Advice Columnist, a Duke Math PhD, ex-Quant, and ex-Uber Software Dev. Original . Reposted with permission. Related: Visualizing Cross-validation Code Understanding the Bias-Variance Tradeoff: An Overview Data Sources for Cool Data Science Projects", "title_html": "<h1 id=\"title\">How (and Why) to Create a Good Validation Set</h1> ", "url": "https://www.kdnuggets.com/2017/11/create-good-validation-set.html", "tfidf": {"tfidf": {"after": 1.02070207021, "real": 2.28103448276, "duke": 6.30750893921, "failur": 3.28559602649, "sold": 2.7935949322500004, "too": 3.6317053643, "relat": 1.23750876919, "ahead": 5.625797306869999, "skeptic": 16.1834862385, "red": 2.22228443449, "fastai": 2646.0, "satellit": 7.9899345747399995, "would": 7.580110497259999, "number": 1.10142916609, "etc": 4.2066772655, "specif": 1.8719490626099997, "supris": 1323.0, "thoma": 4.79347826086, "driver": 33.99571734475, "well": 8.5245989664, "product": 8.113246116100001, "done": 2.3302509907499998, "askadatascientist": 1323.0, "complet": 1.24021560816, "approach": 2.07556543339, "technic": 3.1400316455699997, "know": 5.1865403463, "their": 1.01547908405, "dev": 148.373831776, "won": 2.31732593782, "particular": 1.3814827706200001, "testtim": 1323.0, "creat": 3.7478753541, "how": 9.61501968306, "test": 42.51313807536, "instruct": 8.338235294119999, "repost": 933.882352941, "fair": 3.20533010297, "inconsist": 14.3934723481, "end": 4.42721695484, "given": 1.35426085473, "fish": 15.844311377250001, "interest": 1.60331246213, "deep": 3.6279707495399998, "depend": 11.205533596850001, "beginn": 53.4545454545, "true": 2.55569864778, "scenario": 15.3986420951, "consid": 1.2397313759200002, "confus": 4.1451697127900005, "new": 9.1609924986, "below": 6.76822509591, "perform": 6.125590817000001, "but": 4.06529671596, "definit": 9.72, "need": 7.186311787049999, "overal": 3.0442953020099996, "point": 5.03960003176, "applic": 3.42672134686, "prevent": 2.16117615029, "has": 5.218248751, "enough": 2.2319696330700003, "impress": 3.90457452041, "realworld": 1323.0, "pass": 1.61818367139, "use": 18.533497632839996, "experi": 1.87062566278, "sound": 3.11294117647, "out": 2.12033388982, "model": 43.9025546484, "submiss": 18.5250875146, "good": 6.07926479036, "sure": 7.453521126760001, "under": 1.0781663837, "forc": 1.32399299475, "categori": 7.96388261852, "forward": 3.66566612792, "program": 2.02139037433, "not": 12.18808777428, "far": 1.71022298826, "are": 12.35887122936, "wrong": 10.956521739140001, "privat": 6.071902090770001, "happen": 2.96359902931, "easi": 10.5875291764, "danger": 6.84015510556, "fold": 12.3452566096, "they": 4.12069301148, "anoth": 2.27287043664, "sale": 6.8549222798, "blue": 3.07019918778, "turn": 1.3838912133899999, "last": 2.4234468020200004, "choos": 20.894972361150003, "world": 1.11340206186, "scienc": 2.31969608416, "chosen": 3.59266802444, "geograph": 9.461263408819999, "section": 4.2568708942199995, "behavior": 5.52978056426, "culprit": 91.76878612719999, "item": 5.07869481766, "appear": 1.3214582986499999, "phone": 9.118897185529999, "provid": 1.21552714187, "offer": 1.53896859248, "insur": 9.36637168142, "softwar": 10.2624434389, "develop": 1.1955719557200002, "such": 2.12302754748, "fallout": 53.6351351351, "those": 2.39096385542, "talk": 3.0303493033, "with": 8.009585671919998, "trainvalidationtest": 1323.0, "math": 22.0806675939, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 3.39520958084, "small": 1.3594793629, "both": 2.10431440122, "locat": 1.59766529134, "result": 2.29223216864, "subset": 245.92771084319997, "platform": 6.2332155476999995, "set": 68.85060565298, "futur": 5.573133629760001, "ani": 2.26767604628, "two": 6.0827586207, "divid": 2.3169877408099997, "from": 6.00340328982, "answer": 4.64890190337, "limit": 1.5186531471200002, "whether": 4.41367806506, "num": 16.00504064016, "instanc": 9.771850636020002, "biasvari": 1323.0, "idea": 4.1861568886, "advic": 7.08117752007, "tree": 8.255850234, "curv": 33.3296011197, "safe": 10.05446485118, "for": 31.00976624031, "caught": 6.06648834543, "predict": 46.66361854995, "quora": 1323.0, "closer": 5.5666199158500005, "seen": 3.2215909091, "split": 17.354613030150002, "competit": 24.5568445476, "assum": 2.9575260804799997, "determin": 2.1658935879900003, "poor": 12.10983981695, "better": 6.01971688575, "compani": 1.5523613963, "current": 1.5325803649, "month": 1.5079787234, "look": 7.634527530639999, "histor": 1.6755672823199999, "combin": 3.39520958084, "chanc": 4.2449197861000005, "think": 5.81431972166, "work": 3.34560269739, "public": 3.67273288095, "forest": 9.79093432008, "later": 1.08650424309, "net": 6.96315789474, "again": 1.50883862384, "compar": 1.8662278123900002, "group": 1.20996875238, "doe": 3.4116256581, "even": 2.32922535212, "infer": 21.1398135819, "valid": 185.14285714288002, "ecuadorian": 240.54545454599997, "exquant": 1323.0, "alltoocommon": 1323.0, "great": 1.26592775696, "shuffl": 62.5039370079, "subtleti": 91.2413793103, "step": 2.8279301745599996, "error": 6.04109589041, "continu": 1.13928955867, "eat": 22.51914893616, "note": 1.42449528937, "workplac": 30.5895953757, "thing": 4.813096862219999, "qualit": 42.223404255300004, "machin": 24.146007604559998, "into": 6.09014768874, "came": 1.46013059873, "crossvalid": 6615.0, "traintestsplit": 2646.0, "earlier": 3.73552941176, "suppos": 4.23021582734, "latest": 7.078020508250001, "overfit": 2646.0, "help": 1.39962972759, "clear": 1.85423966363, "san": 3.30131004367, "nuanc": 48.2553191489, "own": 3.5353325415600003, "natur": 1.5392670157100001, "can": 12.93887530562, "who": 2.12558575446, "pictur": 10.486129458390002, "univers": 1.24889867841, "permiss": 6.280063291139999, "veri": 1.25880114177, "were": 2.04917715392, "averag": 2.60390355913, "through": 1.07074930869, "engag": 2.6926729986400004, "evalu": 27.803852889679998, "contain": 1.59814777532, "about": 4.25944060636, "problem": 10.60048965054, "imageri": 19.7955112219, "communiti": 1.96121062384, "neural": 59.4606741573, "distinct": 2.2836593786000003, "just": 12.022212873330002, "perspect": 5.03520456708, "understand": 8.90575916229, "cofound": 529.2, "speci": 6.648241206030001, "she": 2.16, "jan": 8.31639601886, "check": 6.50655737705, "aug": 176.4, "dynam": 6.52527743527, "where": 2.13430127042, "train": 63.906806538299996, "complex": 2.34021226415, "few": 2.63458347162, "run": 1.55692850838, "seri": 5.86046511628, "whi": 3.2566153846200003, "professor": 4.31061634537, "fill": 3.33809924306, "exub": 1323.0, "scatter": 9.38852749852, "until": 2.29704116328, "subdivid": 22.744985673400002, "abl": 1.8208510150200001, "columnist": 25.647819063000004, "mani": 3.13280273631, "realiz": 4.89244992296, "the": 123.0, "goal": 3.28152128979, "date": 6.52326656396, "disconnect": 42.223404255300004, "seem": 4.58247943426, "consist": 2.9802890932999997, "order": 3.7387550043299997, "sklearn": 3969.0, "exact": 3.46864758575, "there": 2.08182533438, "inform": 1.5753125620200001, "way": 1.2190739461, "best": 1.5828514456600002, "repres": 4.40918348454, "right": 4.21635977337, "take": 1.13961668222, "visual": 5.22752716497, "now": 1.160780873, "tri": 11.126737530659998, "code": 3.8807137619199996, "per": 1.9597580545599997, "than": 2.0655737705, "basic": 2.7301805675, "haven": 25.381294964000002, "indic": 2.0826446281, "break": 2.42863698944, "also": 4.05906040268, "typic": 2.2541530597799997, "person": 1.40520446097, "mean": 1.44906900329, "reveal": 2.63196286472, "will": 15.92254281748, "exampl": 9.02900473932, "overview": 12.6805111821, "may": 6.31210655358, "lowest": 6.549504950499999, "peopl": 7.279229711160001, "boat": 25.867209775960003, "want": 13.97886792456, "build": 8.170869789000001, "behind": 2.0845588235299997, "ultim": 2.58524670249, "howev": 1.0945191313299998, "although": 2.2993699761, "actual": 1.87482286254, "week": 1.80532181033, "span": 6.17262830482, "which": 8.04153476, "like": 5.745928338750001, "term": 1.39520168732, "variabl": 69.97685950415999, "refer": 1.30024570025, "one": 5.031374786100001, "graph": 75.4204275534, "see": 6.36210627555, "imag": 5.40275650842, "phd": 22.3605633803, "get": 8.92812956925, "still": 1.1866357724799999, "random": 50.3315217391, "numfold": 1323.0, "implement": 3.57648118946, "abov": 5.7114761961900005, "cross": 2.33127753304, "tell": 6.72284564896, "put": 1.65806788512, "independ": 7.947537044450001, "analyt": 17.256521739100002, "that": 23.09163346625, "yet": 6.377611140870001, "includ": 5.095320623899999, "cool": 6.8578833693300005, "next": 1.4950560316400001, "gather": 7.57262103506, "this": 12.04552352052, "choic": 15.659893470100002, "time": 4.04509841392, "back": 1.26070038911, "bit": 8.33385826772, "similar": 2.75028150714, "smaller": 2.59369384088, "project": 3.5069582505000003, "differ": 6.182724511249999, "same": 2.23715916296, "most": 6.12578778138, "between": 2.06907337416, "what": 6.2671719563999995, "certain": 1.8077886586200003, "drive": 2.93510815308, "rachel": 45.7521613832, "all": 4.04587155964, "illeg": 5.61584718783, "leaderboard": 6615.0, "third": 1.4195278969999998, "store": 10.34042553192, "endang": 16.020181634700002, "almost": 1.53584212054, "case": 4.45496211768, "middl": 2.04245465071, "day": 1.18371607516, "tradeoff": 208.89473684200001, "chain": 5.17639387023, "more": 4.0686827268, "and": 36.002267716679995, "groceri": 91.5043227666, "reluct": 7.886736214610001, "these": 3.22246278756, "could": 2.4087391898, "car": 3.53743315508, "befor": 3.30108123093, "submit": 11.541984732820001, "state": 1.0477133240899998, "download": 14.6457564576, "wors": 9.58695652174, "serv": 1.4668760972, "francisco": 5.2937645882, "avail": 1.7288467821, "describ": 1.47027227264, "make": 3.2287980475800007, "kaggl": 29106.0, "onli": 3.0769429549800007, "gap": 7.302667893280001, "rare": 2.7259615384599996, "key": 2.28005170185, "distract": 16.5375, "accur": 5.768895348840001, "fare": 15.3095467695, "start": 1.26673581744, "weren": 1323.0, "imposs": 4.96125, "while": 1.0441988950299999, "data": 145.18672905162, "reduc": 1.98698372966, "address": 2.86157173756, "method": 7.714285714290001, "perfect": 4.48601299802, "sinc": 1.08368600683, "sometim": 3.4252427184400003, "bio": 42.336000000000006, "wheel": 17.91873589164, "come": 1.32831325301, "must": 1.9220338983099996, "origin": 1.13724928367, "fisheri": 36.4965517241, "popul": 2.17807655371, "text": 9.384827586210001, "leader": 2.0994445913799997, "identifi": 2.30187037843, "trainvalidationtestsplit": 1323.0, "import": 5.360796893480001, "first": 2.01523229246, "busi": 2.05541170378, "have": 4.059579364559999, "score": 17.153970826600002, "properti": 2.5949656750599996, "host": 2.7092150170599996, "reason": 8.6170212766, "often": 2.5890410959, "rigor": 17.8783783784, "learn": 18.5820043892, "when": 4.0830707902, "mention": 2.53894130817}, "logtfidf": {"after": 0.020490694648099998, "real": 0.824629060574, "duke": 1.84174081877, "failur": 1.18954807429, "sold": 1.02732927261, "too": 1.1931103094439999, "relat": 0.21310030165399999, "ahead": 1.7273626814900003, "skeptic": 2.7839913543400003, "red": 0.798535691347, "fastai": 14.37531432822, "satellit": 2.0781825713499997, "would": 0.5573233957529, "number": 0.0966085784186, "etc": 1.4366730879700003, "specif": 0.626980167541, "supris": 7.18765716411, "thoma": 1.748218235676, "driver": 9.583983219, "well": 0.5081155065248, "product": 2.4203006826799998, "done": 0.845975983129, "askadatascientist": 7.18765716411, "complet": 0.215285242047, "approach": 0.7302336145810001, "technic": 1.14423287808, "know": 1.905839388796, "their": 0.015360505122700001, "dev": 4.99973497944, "won": 0.8404139079, "particular": 0.323157393804, "testtim": 7.18765716411, "creat": 0.667730455542, "how": 2.8294017415800004, "test": 15.635590993648, "instruct": 2.85540883598, "repost": 6.83935046985, "fair": 1.16481508131, "inconsist": 2.6667747946500002, "end": 0.405907194472, "given": 0.303255810831, "fish": 4.99259473077, "interest": 0.47207177798199995, "deep": 1.2886734698, "depend": 4.034849075, "beginn": 3.9788316751, "true": 0.938325629634, "scenario": 2.73427932989, "consid": 0.214894723824, "confus": 1.4219437317299999, "new": 0.1595695216599, "below": 2.440879775808, "perform": 1.70472340232, "but": 0.0647694882876, "definit": 3.5267199894, "need": 1.81370081721, "overal": 1.1132694464700001, "point": 0.9241294361319999, "applic": 1.23160392849, "prevent": 0.7706525875229999, "has": 0.213619724274, "enough": 0.802884439169, "impress": 1.3621488197100002, "realworld": 7.18765716411, "pass": 0.48130432974, "use": 0.5257443551688, "experi": 0.626272953933, "sound": 1.13556799519, "out": 0.1168527818386, "model": 15.486451535331001, "submiss": 2.9191258953099997, "good": 1.674357619628, "sure": 2.0086865552, "under": 0.07526180538319999, "forc": 0.280652166524, "categori": 2.76353893304, "forward": 1.29901007269, "program": 0.7037855787649999, "not": 0.18662895609, "far": 0.536623764503, "are": 0.35360968299240003, "wrong": 3.40157538204, "privat": 2.1151788797610003, "happen": 1.08640441802, "easi": 3.3330592702999997, "danger": 2.45932645414, "fold": 2.5132719091099998, "they": 0.1189079790704, "anoth": 0.255792723304, "sale": 2.4636395893, "blue": 1.1217424415100001, "turn": 0.324899251064, "last": 0.38408728922200003, "choos": 7.1503533036, "world": 0.107420248621, "scienc": 0.841436178891, "chosen": 1.27889510877, "geograph": 3.10811749264, "section": 1.510774355896, "behavior": 1.71014813378, "culprit": 4.5192722194099995, "item": 1.62505430292, "appear": 0.278735898493, "phone": 2.2103488741299997, "provid": 0.19517784432500002, "offer": 0.431112446902, "insur": 2.2371257940900002, "softwar": 2.32849096333, "develop": 0.178624694913, "such": 0.119391955612, "fallout": 3.98220435958, "those": 0.35709878174599996, "talk": 1.10867789449, "with": 0.00957993370712, "trainvalidationtest": 7.18765716411, "math": 3.09470245618, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 1.058436621502, "small": 0.307101805059, "both": 0.10168506677860001, "locat": 0.46854337067199997, "result": 0.272757816762, "subset": 29.770317513449996, "platform": 1.8298923389200001, "set": 9.946768654762, "futur": 1.858035593097, "ani": 0.251216716732, "two": 0.08219306614920001, "divid": 0.8402679544589999, "from": 0.0034023250131959997, "answer": 1.5366310419, "limit": 0.41782385463, "whether": 1.583122379294, "num": 0.005039846326352001, "instanc": 3.5426807391599997, "biasvari": 7.18765716411, "idea": 1.47727184424, "advic": 1.9574402102700001, "tree": 2.8355497755, "curv": 7.223500907909999, "safe": 3.22973923818, "for": 0.009764702257307002, "caught": 1.80277991137, "predict": 14.811662139209998, "quora": 7.18765716411, "closer": 1.7167880323700002, "seen": 0.95345625626, "split": 6.2221021966, "competit": 8.97239259208, "assum": 1.08435313525, "determin": 0.772833019022, "poor": 4.422902088525, "better": 2.0892838218, "compani": 0.439777253097, "current": 0.42695282784500005, "month": 0.410770160338, "look": 2.5855467744, "histor": 0.516151783952, "combin": 1.058436621502, "chanc": 1.44572292349, "think": 2.1343532235, "work": 0.327103701819, "public": 0.6069712514610001, "forest": 3.1766194152, "later": 0.0829654259878, "net": 1.9406330919499999, "again": 0.411340231612, "compar": 0.6239191809269999, "group": 0.190594534797, "doe": 1.0680834594339998, "even": 0.304777129668, "infer": 3.0511581621399997, "valid": 52.88985009504, "ecuadorian": 9.579523782639999, "exquant": 7.18765716411, "alltoocommon": 7.18765716411, "great": 0.235805258079, "shuffl": 4.135229546880001, "subtleti": 4.513508514690001, "step": 1.03954505698, "error": 1.7985854343, "continu": 0.13040487398700001, "eat": 6.04726116726, "note": 0.353817568083, "workplac": 3.42065993074, "thing": 1.7563870693599999, "qualit": 3.74297467051, "machin": 8.35415748372, "into": 0.0894771793722, "came": 0.378525882905, "crossvalid": 35.93828582055, "traintestsplit": 14.37531432822, "earlier": 1.24948474285, "suppos": 1.44225301477, "latest": 1.95699427938, "overfit": 14.37531432822, "help": 0.336207721344, "clear": 0.617474727198, "san": 1.1943193726299999, "nuanc": 3.87650606314, "own": 0.492585232263, "natur": 0.431306339292, "can": 1.7857520603339998, "who": 0.1218004659718, "pictur": 3.75432327372, "univers": 0.222262105686, "permiss": 1.8373800586400002, "veri": 0.230159793238, "were": 0.048582287362199994, "averag": 0.957011687995, "through": 0.0683586918849, "engag": 0.990534380034, "evalu": 7.755520972519999, "contain": 0.468845318236, "about": 0.2513739098984, "problem": 3.414844345638, "imageri": 2.98545520604, "communiti": 0.673561947791, "neural": 4.0853151555, "distinct": 0.825779146958, "just": 2.605782906981, "perspect": 1.61645415436, "understand": 3.264257627039999, "cofound": 11.15643850336, "speci": 1.8943523393900001, "she": 0.7701082216959999, "jan": 2.11822899018, "check": 1.87281049562, "aug": 17.816581155700003, "dynam": 1.8756834711200001, "where": 0.1299842774914, "train": 21.810304323687003, "complex": 0.8502416364309999, "few": 0.551155827306, "run": 0.442714975539, "seri": 1.5277384427919998, "whi": 1.18068843047, "professor": 1.46108089746, "fill": 1.20540155609, "exub": 7.18765716411, "scatter": 2.239488465, "until": 0.276949326878, "subdivid": 3.12434471114, "abl": 0.599303982475, "columnist": 3.2444585412199998, "mani": 0.1299472743663, "realiz": 1.5876931847600002, "the": 0.0, "goal": 1.18830712273, "date": 1.956323584388, "disconnect": 3.74297467051, "seem": 1.658186064552, "consist": 0.797746252852, "order": 0.6604211423790001, "sklearn": 21.56297149233, "exact": 1.2437647732500001, "there": 0.080195785851, "inform": 0.454453704662, "way": 0.19809150993500002, "best": 0.459227932947, "repres": 1.15523169825, "right": 1.02107956251, "take": 0.130691962197, "visual": 1.6539383488600001, "now": 0.149092945021, "tri": 3.7055491749600002, "code": 1.35601909597, "per": 0.672821024072, "than": 0.0645217244364, "basic": 1.00436774895, "haven": 5.08173060688, "indic": 0.7336385419149999, "break": 0.88733019029, "also": 0.0586286312, "typic": 0.812774319158, "person": 0.34018281601800004, "mean": 0.37092128352, "reveal": 0.9677299042149999, "will": 2.6362249538950002, "exampl": 2.4520960499939997, "overview": 2.54006626224, "may": 0.3042599717064, "lowest": 1.8793894667099997, "peopl": 1.159593470838, "boat": 7.46672709468, "want": 4.841456243784999, "build": 2.455687260455, "behind": 0.7345572374320001, "ultim": 0.9498209395739999, "howev": 0.0903151173475, "although": 0.278975962836, "actual": 0.628514181648, "week": 0.5907388641619999, "span": 1.82012472855, "which": 0.04142731076344, "like": 0.6952678827250001, "term": 0.33303898354600003, "variabl": 17.3497845376, "refer": 0.262553246798, "one": 0.0312767582275, "graph": 7.259861960439999, "see": 1.20460792746, "imag": 1.98752421458, "phd": 3.10729884387, "get": 2.89884502891, "still": 0.17112222142900002, "random": 13.809049845569998, "numfold": 7.18765716411, "implement": 1.27437940907, "abov": 1.9315956894480002, "cross": 0.846416414759, "tell": 2.42472868802, "put": 0.505652999854, "independ": 2.3171208125150002, "analyt": 2.8481901438599997, "that": 0.09145141273171999, "yet": 2.262543927723, "includ": 0.09442340695250001, "cool": 1.9253988473800001, "next": 0.402163685499, "gather": 2.6627841334599998, "this": 0.04543738863, "choic": 5.70832487715, "time": 0.0448460754504, "back": 0.23166743089699998, "bit": 2.12032652634, "similar": 0.637112184228, "smaller": 0.9530830530519999, "project": 1.123203771814, "differ": 1.0616056065600001, "same": 0.224119299208, "most": 0.12448737777359999, "between": 0.06790736233059999, "what": 1.129436484135, "certain": 0.592104362781, "drive": 1.07674430203, "rachel": 6.2601837067999995, "all": 0.04561052839119999, "illeg": 1.72559245621, "leaderboard": 35.93828582055, "third": 0.35032434942900004, "store": 3.7123462005600008, "endang": 2.7738492795700003, "almost": 0.42907884333400004, "case": 1.186218806667, "middl": 0.7141523446729999, "day": 0.16865870631700003, "tradeoff": 5.34183047362, "chain": 1.64410864979, "more": 0.06809972639999999, "and": 0.0022676451142896, "groceri": 7.6464780679199995, "reluct": 2.06518238826, "these": 0.2146008582024, "could": 0.37191254458000006, "car": 1.2634013667, "befor": 0.2869133156385, "submit": 3.5056881059599996, "state": 0.0466100027668, "download": 2.6841506319, "wors": 2.26040347896, "serv": 0.383135035608, "francisco": 1.6665296351499999, "avail": 0.547454586289, "describ": 0.385447603125, "make": 0.22049297346869998, "kaggl": 158.12845761042, "onli": 0.0759728049873, "gap": 1.98823974622, "rare": 1.00282122403, "key": 0.82419811896, "distract": 2.80563052944, "accur": 1.75248061485, "fare": 2.7284766056700005, "start": 0.236443369291, "weren": 7.18765716411, "imposs": 1.60165772512, "while": 0.04324998379380001, "data": 52.323285146399996, "reduc": 0.686617775143, "address": 1.05137103247, "method": 2.833384826523, "perfect": 1.50096433356, "sinc": 0.0803681994577, "sometim": 1.076050310686, "bio": 3.7456377879300002, "wheel": 4.3853993654800005, "come": 0.28390990653000003, "must": 0.653383947388, "origin": 0.128612437587, "fisheri": 3.5972177828099996, "popul": 0.778442172521, "text": 3.42144602997, "leader": 0.741672829452, "identifi": 0.833722000472, "trainvalidationtestsplit": 7.18765716411, "import": 1.171273108264, "first": 0.015174579624319999, "busi": 0.720476170355, "have": 0.0591400093648, "score": 5.823741283080001, "properti": 0.953573289192, "host": 0.996658931332, "reason": 2.72150776481, "often": 0.516280786702, "rigor": 2.88359207091, "learn": 6.74201651796, "when": 0.0822199554336, "mention": 0.931747186336}, "logidf": {"after": 0.020490694648099998, "real": 0.824629060574, "duke": 1.84174081877, "failur": 1.18954807429, "sold": 1.02732927261, "too": 0.5965551547219999, "relat": 0.21310030165399999, "ahead": 1.7273626814900003, "skeptic": 2.7839913543400003, "red": 0.798535691347, "fastai": 7.18765716411, "satellit": 2.0781825713499997, "would": 0.0796176279647, "number": 0.0966085784186, "etc": 1.4366730879700003, "specif": 0.626980167541, "supris": 7.18765716411, "thoma": 0.874109117838, "driver": 1.9167966438, "well": 0.0635144383156, "product": 0.484060136536, "done": 0.845975983129, "askadatascientist": 7.18765716411, "complet": 0.215285242047, "approach": 0.7302336145810001, "technic": 1.14423287808, "know": 0.952919694398, "their": 0.015360505122700001, "dev": 4.99973497944, "won": 0.8404139079, "particular": 0.323157393804, "testtim": 7.18765716411, "creat": 0.222576818514, "how": 0.47156695693000006, "test": 0.977224437103, "instruct": 1.42770441799, "repost": 6.83935046985, "fair": 1.16481508131, "inconsist": 2.6667747946500002, "end": 0.101476798618, "given": 0.303255810831, "fish": 1.66419824359, "interest": 0.47207177798199995, "deep": 1.2886734698, "depend": 0.806969815, "beginn": 3.9788316751, "true": 0.938325629634, "scenario": 2.73427932989, "consid": 0.214894723824, "confus": 1.4219437317299999, "new": 0.0177299468511, "below": 0.813626591936, "perform": 0.42618085058, "but": 0.0161923720719, "definit": 1.1755733298, "need": 0.362740163442, "overal": 1.1132694464700001, "point": 0.23103235903299998, "applic": 1.23160392849, "prevent": 0.7706525875229999, "has": 0.0427239448548, "enough": 0.802884439169, "impress": 1.3621488197100002, "realworld": 7.18765716411, "pass": 0.48130432974, "use": 0.0292080197316, "experi": 0.626272953933, "sound": 1.13556799519, "out": 0.0584263909193, "model": 0.7374500731110001, "submiss": 2.9191258953099997, "good": 0.418589404907, "sure": 2.0086865552, "under": 0.07526180538319999, "forc": 0.280652166524, "categori": 1.38176946652, "forward": 1.29901007269, "program": 0.7037855787649999, "not": 0.0155524130075, "far": 0.536623764503, "are": 0.0294674735827, "wrong": 1.70078769102, "privat": 0.705059626587, "happen": 1.08640441802, "easi": 1.6665296351499999, "danger": 1.22966322707, "fold": 2.5132719091099998, "they": 0.0297269947676, "anoth": 0.127896361652, "sale": 1.23181979465, "blue": 1.1217424415100001, "turn": 0.324899251064, "last": 0.19204364461100001, "choos": 1.43007066072, "world": 0.107420248621, "scienc": 0.841436178891, "chosen": 1.27889510877, "geograph": 1.55405874632, "section": 0.755387177948, "behavior": 1.71014813378, "culprit": 4.5192722194099995, "item": 1.62505430292, "appear": 0.278735898493, "phone": 2.2103488741299997, "provid": 0.19517784432500002, "offer": 0.431112446902, "insur": 2.2371257940900002, "softwar": 2.32849096333, "develop": 0.178624694913, "such": 0.059695977806, "fallout": 3.98220435958, "those": 0.17854939087299998, "talk": 1.10867789449, "with": 0.00119749171339, "trainvalidationtest": 7.18765716411, "math": 3.09470245618, "lot": 1.4835969502500002, "some": 0.0395735090645, "sourc": 0.529218310751, "small": 0.307101805059, "both": 0.050842533389300004, "locat": 0.46854337067199997, "result": 0.136378908381, "subset": 3.3078130570499997, "platform": 1.8298923389200001, "set": 0.171496011289, "futur": 0.619345197699, "ani": 0.125608358366, "two": 0.0136988443582, "divid": 0.8402679544589999, "from": 0.000567054168866, "answer": 1.5366310419, "limit": 0.41782385463, "whether": 0.791561189647, "num": 0.00031499039539700004, "instanc": 1.18089357972, "biasvari": 7.18765716411, "idea": 0.73863592212, "advic": 1.9574402102700001, "tree": 1.41777488775, "curv": 2.40783363597, "safe": 1.61486961909, "for": 0.00031499039539700004, "caught": 1.80277991137, "predict": 1.6457402376899999, "quora": 7.18765716411, "closer": 1.7167880323700002, "seen": 0.47672812813, "split": 1.24442043932, "competit": 1.12154907401, "assum": 1.08435313525, "determin": 0.772833019022, "poor": 0.8845804177050001, "better": 0.6964279406, "compani": 0.439777253097, "current": 0.42695282784500005, "month": 0.410770160338, "look": 0.6463866936, "histor": 0.516151783952, "combin": 0.529218310751, "chanc": 1.44572292349, "think": 1.06717661175, "work": 0.109034567273, "public": 0.20232375048700002, "forest": 1.5883097076, "later": 0.0829654259878, "net": 1.9406330919499999, "again": 0.411340231612, "compar": 0.6239191809269999, "group": 0.190594534797, "doe": 0.5340417297169999, "even": 0.152388564834, "infer": 3.0511581621399997, "valid": 1.8889232176800002, "ecuadorian": 4.7897618913199995, "exquant": 7.18765716411, "alltoocommon": 7.18765716411, "great": 0.235805258079, "shuffl": 4.135229546880001, "subtleti": 4.513508514690001, "step": 1.03954505698, "error": 1.7985854343, "continu": 0.13040487398700001, "eat": 2.01575372242, "note": 0.353817568083, "workplac": 3.42065993074, "thing": 0.8781935346799999, "qualit": 3.74297467051, "machin": 1.39235958062, "into": 0.0149128632287, "came": 0.378525882905, "crossvalid": 7.18765716411, "traintestsplit": 7.18765716411, "earlier": 0.624742371425, "suppos": 1.44225301477, "latest": 1.95699427938, "overfit": 7.18765716411, "help": 0.336207721344, "clear": 0.617474727198, "san": 1.1943193726299999, "nuanc": 3.87650606314, "own": 0.164195077421, "natur": 0.431306339292, "can": 0.162341096394, "who": 0.0609002329859, "pictur": 1.25144109124, "univers": 0.222262105686, "permiss": 1.8373800586400002, "veri": 0.230159793238, "were": 0.024291143681099997, "averag": 0.957011687995, "through": 0.0683586918849, "engag": 0.990534380034, "evalu": 1.9388802431299998, "contain": 0.468845318236, "about": 0.0628434774746, "problem": 0.569140724273, "imageri": 2.98545520604, "communiti": 0.673561947791, "neural": 4.0853151555, "distinct": 0.825779146958, "just": 0.289531434109, "perspect": 1.61645415436, "understand": 1.0880858756799998, "cofound": 5.57821925168, "speci": 1.8943523393900001, "she": 0.7701082216959999, "jan": 2.11822899018, "check": 1.87281049562, "aug": 3.5633162311400004, "dynam": 1.8756834711200001, "where": 0.0649921387457, "train": 0.660918312839, "complex": 0.8502416364309999, "few": 0.275577913653, "run": 0.442714975539, "seri": 0.38193461069799994, "whi": 1.18068843047, "professor": 1.46108089746, "fill": 1.20540155609, "exub": 7.18765716411, "scatter": 2.239488465, "until": 0.138474663439, "subdivid": 3.12434471114, "abl": 0.599303982475, "columnist": 3.2444585412199998, "mani": 0.0433157581221, "realiz": 1.5876931847600002, "the": 0.0, "goal": 1.18830712273, "date": 0.489080896097, "disconnect": 3.74297467051, "seem": 0.829093032276, "consist": 0.398873126426, "order": 0.22014038079300002, "sklearn": 7.18765716411, "exact": 1.2437647732500001, "there": 0.0400978929255, "inform": 0.454453704662, "way": 0.19809150993500002, "best": 0.459227932947, "repres": 0.38507723275, "right": 0.34035985417, "take": 0.130691962197, "visual": 1.6539383488600001, "now": 0.149092945021, "tri": 0.61759152916, "code": 1.35601909597, "per": 0.672821024072, "than": 0.0322608622182, "basic": 1.00436774895, "haven": 2.54086530344, "indic": 0.7336385419149999, "break": 0.88733019029, "also": 0.0146571578, "typic": 0.812774319158, "person": 0.34018281601800004, "mean": 0.37092128352, "reveal": 0.9677299042149999, "will": 0.202786534915, "exampl": 0.40868267499899996, "overview": 2.54006626224, "may": 0.050709995284400004, "lowest": 1.8793894667099997, "peopl": 0.193265578473, "boat": 1.86668177367, "want": 0.6916366062549999, "build": 0.491137452091, "behind": 0.7345572374320001, "ultim": 0.9498209395739999, "howev": 0.0903151173475, "although": 0.139487981418, "actual": 0.628514181648, "week": 0.5907388641619999, "span": 1.82012472855, "which": 0.00517841384543, "like": 0.139053576545, "term": 0.33303898354600003, "variabl": 2.1687230672, "refer": 0.262553246798, "one": 0.0062553516455, "graph": 3.6299309802199997, "see": 0.240921585492, "imag": 0.99376210729, "phd": 3.10729884387, "get": 0.579769005782, "still": 0.17112222142900002, "random": 1.9727214065099998, "numfold": 7.18765716411, "implement": 1.27437940907, "abov": 0.643865229816, "cross": 0.846416414759, "tell": 1.21236434401, "put": 0.505652999854, "independ": 0.463424162503, "analyt": 2.8481901438599997, "that": 0.00397614837964, "yet": 0.754181309241, "includ": 0.0188846813905, "cool": 1.9253988473800001, "next": 0.402163685499, "gather": 1.3313920667299999, "this": 0.0037864490525, "choic": 1.14166497543, "time": 0.0112115188626, "back": 0.23166743089699998, "bit": 2.12032652634, "similar": 0.318556092114, "smaller": 0.9530830530519999, "project": 0.561601885907, "differ": 0.212321121312, "same": 0.112059649604, "most": 0.020747896295599998, "between": 0.033953681165299995, "what": 0.225887296827, "certain": 0.592104362781, "drive": 1.07674430203, "rachel": 3.1300918533999997, "all": 0.011402632097799998, "illeg": 1.72559245621, "leaderboard": 7.18765716411, "third": 0.35032434942900004, "store": 1.2374487335200002, "endang": 2.7738492795700003, "almost": 0.42907884333400004, "case": 0.395406268889, "middl": 0.7141523446729999, "day": 0.16865870631700003, "tradeoff": 5.34183047362, "chain": 1.64410864979, "more": 0.017024931599999998, "and": 6.29901420636e-05, "groceri": 3.8232390339599998, "reluct": 2.06518238826, "these": 0.0715336194008, "could": 0.18595627229000003, "car": 1.2634013667, "befor": 0.0956377718795, "submit": 1.7528440529799998, "state": 0.0466100027668, "download": 2.6841506319, "wors": 2.26040347896, "serv": 0.383135035608, "francisco": 1.6665296351499999, "avail": 0.547454586289, "describ": 0.385447603125, "make": 0.07349765782289999, "kaggl": 7.18765716411, "onli": 0.025324268329099998, "gap": 1.98823974622, "rare": 1.00282122403, "key": 0.82419811896, "distract": 2.80563052944, "accur": 1.75248061485, "fare": 2.7284766056700005, "start": 0.236443369291, "weren": 7.18765716411, "imposs": 1.60165772512, "while": 0.04324998379380001, "data": 1.2168205848, "reduc": 0.686617775143, "address": 1.05137103247, "method": 0.944461608841, "perfect": 1.50096433356, "sinc": 0.0803681994577, "sometim": 0.538025155343, "bio": 3.7456377879300002, "wheel": 2.1926996827400003, "come": 0.28390990653000003, "must": 0.653383947388, "origin": 0.128612437587, "fisheri": 3.5972177828099996, "popul": 0.778442172521, "text": 1.14048200999, "leader": 0.741672829452, "identifi": 0.833722000472, "trainvalidationtestsplit": 7.18765716411, "import": 0.292818277066, "first": 0.0075872898121599995, "busi": 0.720476170355, "have": 0.0147850023412, "score": 1.4559353207700003, "properti": 0.953573289192, "host": 0.996658931332, "reason": 0.544301552962, "often": 0.258140393351, "rigor": 2.88359207091, "learn": 0.842752064745, "when": 0.0205549888584, "mention": 0.931747186336}, "freq": {"after": 1, "real": 1, "duke": 1, "failur": 1, "sold": 1, "too": 2, "relat": 1, "ahead": 1, "skeptic": 1, "red": 1, "fastai": 2, "satellit": 1, "would": 7, "number": 1, "etc": 1, "specif": 1, "supris": 1, "thoma": 2, "driver": 5, "well": 8, "product": 5, "done": 1, "askadatascientist": 1, "complet": 1, "approach": 1, "technic": 1, "know": 2, "their": 1, "dev": 1, "won": 1, "particular": 1, "testtim": 1, "creat": 3, "how": 6, "test": 16, "instruct": 2, "repost": 1, "fair": 1, "inconsist": 1, "end": 4, "given": 1, "fish": 3, "interest": 1, "deep": 1, "depend": 5, "beginn": 1, "true": 1, "scenario": 1, "consid": 1, "confus": 1, "new": 9, "below": 3, "perform": 4, "but": 4, "definit": 3, "need": 5, "overal": 1, "point": 4, "applic": 1, "prevent": 1, "has": 5, "enough": 1, "impress": 1, "realworld": 1, "pass": 1, "use": 18, "experi": 1, "sound": 1, "out": 2, "model": 21, "submiss": 1, "good": 4, "sure": 1, "under": 1, "forc": 1, "categori": 2, "forward": 1, "program": 1, "not": 12, "far": 1, "are": 12, "wrong": 2, "privat": 3, "happen": 1, "easi": 2, "danger": 2, "fold": 1, "they": 4, "anoth": 2, "sale": 2, "blue": 1, "turn": 1, "last": 2, "choos": 5, "world": 1, "scienc": 1, "chosen": 1, "geograph": 2, "section": 2, "behavior": 1, "culprit": 1, "item": 1, "appear": 1, "phone": 1, "provid": 1, "offer": 1, "insur": 1, "softwar": 1, "develop": 1, "such": 2, "fallout": 1, "those": 2, "talk": 1, "with": 8, "trainvalidationtest": 1, "math": 1, "lot": 1, "some": 1, "sourc": 2, "small": 1, "both": 2, "locat": 1, "result": 2, "subset": 9, "platform": 1, "set": 58, "futur": 3, "ani": 2, "two": 6, "divid": 1, "from": 6, "answer": 1, "limit": 1, "whether": 2, "num": 16, "instanc": 3, "biasvari": 1, "idea": 2, "advic": 1, "tree": 2, "curv": 3, "safe": 2, "for": 31, "caught": 1, "predict": 9, "quora": 1, "closer": 1, "seen": 2, "split": 5, "competit": 8, "assum": 1, "determin": 1, "poor": 5, "better": 3, "compani": 1, "current": 1, "month": 1, "look": 4, "histor": 1, "combin": 2, "chanc": 1, "think": 2, "work": 3, "public": 3, "forest": 2, "later": 1, "net": 1, "again": 1, "compar": 1, "group": 1, "doe": 2, "even": 2, "infer": 1, "valid": 28, "ecuadorian": 2, "exquant": 1, "alltoocommon": 1, "great": 1, "shuffl": 1, "subtleti": 1, "step": 1, "error": 1, "continu": 1, "eat": 3, "note": 1, "workplac": 1, "thing": 2, "qualit": 1, "machin": 6, "into": 6, "came": 1, "crossvalid": 5, "traintestsplit": 2, "earlier": 2, "suppos": 1, "latest": 1, "overfit": 2, "help": 1, "clear": 1, "san": 1, "nuanc": 1, "own": 3, "natur": 1, "can": 11, "who": 2, "pictur": 3, "univers": 1, "permiss": 1, "veri": 1, "were": 2, "averag": 1, "through": 1, "engag": 1, "evalu": 4, "contain": 1, "about": 4, "problem": 6, "imageri": 1, "communiti": 1, "neural": 1, "distinct": 1, "just": 9, "perspect": 1, "understand": 3, "cofound": 2, "speci": 1, "she": 1, "jan": 1, "check": 1, "aug": 5, "dynam": 1, "where": 2, "train": 33, "complex": 1, "few": 2, "run": 1, "seri": 4, "whi": 1, "professor": 1, "fill": 1, "exub": 1, "scatter": 1, "until": 2, "subdivid": 1, "abl": 1, "columnist": 1, "mani": 3, "realiz": 1, "the": 123, "goal": 1, "date": 4, "disconnect": 1, "seem": 2, "consist": 2, "order": 3, "sklearn": 3, "exact": 1, "there": 2, "inform": 1, "way": 1, "best": 1, "repres": 3, "right": 3, "take": 1, "visual": 1, "now": 1, "tri": 6, "code": 1, "per": 1, "than": 2, "basic": 1, "haven": 2, "indic": 1, "break": 1, "also": 4, "typic": 1, "person": 1, "mean": 1, "reveal": 1, "will": 13, "exampl": 6, "overview": 1, "may": 6, "lowest": 1, "peopl": 6, "boat": 4, "want": 7, "build": 5, "behind": 1, "ultim": 1, "howev": 1, "although": 2, "actual": 1, "week": 1, "span": 1, "which": 8, "like": 5, "term": 1, "variabl": 8, "refer": 1, "one": 5, "graph": 2, "see": 5, "imag": 2, "phd": 1, "get": 5, "still": 1, "random": 7, "numfold": 1, "implement": 1, "abov": 3, "cross": 1, "tell": 2, "put": 1, "independ": 5, "analyt": 1, "that": 23, "yet": 3, "includ": 5, "cool": 1, "next": 1, "gather": 2, "this": 12, "choic": 5, "time": 4, "back": 1, "bit": 1, "similar": 2, "smaller": 1, "project": 2, "differ": 5, "same": 2, "most": 6, "between": 2, "what": 5, "certain": 1, "drive": 1, "rachel": 2, "all": 4, "illeg": 1, "leaderboard": 5, "third": 1, "store": 3, "endang": 1, "almost": 1, "case": 3, "middl": 1, "day": 1, "tradeoff": 1, "chain": 1, "more": 4, "and": 36, "groceri": 2, "reluct": 1, "these": 3, "could": 2, "car": 1, "befor": 3, "submit": 2, "state": 1, "download": 1, "wors": 1, "serv": 1, "francisco": 1, "avail": 1, "describ": 1, "make": 3, "kaggl": 22, "onli": 3, "gap": 1, "rare": 1, "key": 1, "distract": 1, "accur": 1, "fare": 1, "start": 1, "weren": 1, "imposs": 1, "while": 1, "data": 43, "reduc": 1, "address": 1, "method": 3, "perfect": 1, "sinc": 1, "sometim": 2, "bio": 1, "wheel": 2, "come": 1, "must": 1, "origin": 1, "fisheri": 1, "popul": 1, "text": 3, "leader": 1, "identifi": 1, "trainvalidationtestsplit": 1, "import": 4, "first": 2, "busi": 1, "have": 4, "score": 4, "properti": 1, "host": 1, "reason": 5, "often": 2, "rigor": 1, "learn": 8, "when": 4, "mention": 1}, "idf": {"after": 1.02070207021, "real": 2.28103448276, "duke": 6.30750893921, "failur": 3.28559602649, "sold": 2.7935949322500004, "too": 1.81585268215, "relat": 1.23750876919, "ahead": 5.625797306869999, "skeptic": 16.1834862385, "red": 2.22228443449, "fastai": 1323.0, "satellit": 7.9899345747399995, "would": 1.0828729281799998, "number": 1.10142916609, "etc": 4.2066772655, "specif": 1.8719490626099997, "supris": 1323.0, "thoma": 2.39673913043, "driver": 6.79914346895, "well": 1.0655748708, "product": 1.62264922322, "done": 2.3302509907499998, "askadatascientist": 1323.0, "complet": 1.24021560816, "approach": 2.07556543339, "technic": 3.1400316455699997, "know": 2.59327017315, "their": 1.01547908405, "dev": 148.373831776, "won": 2.31732593782, "particular": 1.3814827706200001, "testtim": 1323.0, "creat": 1.2492917847, "how": 1.60250328051, "test": 2.65707112971, "instruct": 4.169117647059999, "repost": 933.882352941, "fair": 3.20533010297, "inconsist": 14.3934723481, "end": 1.10680423871, "given": 1.35426085473, "fish": 5.28143712575, "interest": 1.60331246213, "deep": 3.6279707495399998, "depend": 2.2411067193700003, "beginn": 53.4545454545, "true": 2.55569864778, "scenario": 15.3986420951, "consid": 1.2397313759200002, "confus": 4.1451697127900005, "new": 1.0178880554, "below": 2.25607503197, "perform": 1.5313977042500002, "but": 1.01632417899, "definit": 3.24, "need": 1.4372623574099999, "overal": 3.0442953020099996, "point": 1.25990000794, "applic": 3.42672134686, "prevent": 2.16117615029, "has": 1.0436497502, "enough": 2.2319696330700003, "impress": 3.90457452041, "realworld": 1323.0, "pass": 1.61818367139, "use": 1.0296387573799999, "experi": 1.87062566278, "sound": 3.11294117647, "out": 1.06016694491, "model": 2.0905978404, "submiss": 18.5250875146, "good": 1.51981619759, "sure": 7.453521126760001, "under": 1.0781663837, "forc": 1.32399299475, "categori": 3.98194130926, "forward": 3.66566612792, "program": 2.02139037433, "not": 1.01567398119, "far": 1.71022298826, "are": 1.02990593578, "wrong": 5.478260869570001, "privat": 2.02396736359, "happen": 2.96359902931, "easi": 5.2937645882, "danger": 3.42007755278, "fold": 12.3452566096, "they": 1.03017325287, "anoth": 1.13643521832, "sale": 3.4274611399, "blue": 3.07019918778, "turn": 1.3838912133899999, "last": 1.2117234010100002, "choos": 4.17899447223, "world": 1.11340206186, "scienc": 2.31969608416, "chosen": 3.59266802444, "geograph": 4.7306317044099995, "section": 2.1284354471099998, "behavior": 5.52978056426, "culprit": 91.76878612719999, "item": 5.07869481766, "appear": 1.3214582986499999, "phone": 9.118897185529999, "provid": 1.21552714187, "offer": 1.53896859248, "insur": 9.36637168142, "softwar": 10.2624434389, "develop": 1.1955719557200002, "such": 1.06151377374, "fallout": 53.6351351351, "those": 1.19548192771, "talk": 3.0303493033, "with": 1.0011982089899998, "trainvalidationtest": 1323.0, "math": 22.0806675939, "lot": 4.40877534018, "some": 1.04036697248, "sourc": 1.69760479042, "small": 1.3594793629, "both": 1.05215720061, "locat": 1.59766529134, "result": 1.14611608432, "subset": 27.3253012048, "platform": 6.2332155476999995, "set": 1.18707940781, "futur": 1.8577112099200002, "ani": 1.13383802314, "two": 1.01379310345, "divid": 2.3169877408099997, "from": 1.00056721497, "answer": 4.64890190337, "limit": 1.5186531471200002, "whether": 2.20683903253, "num": 1.00031504001, "instanc": 3.2572835453400004, "biasvari": 1323.0, "idea": 2.0930784443, "advic": 7.08117752007, "tree": 4.127925117, "curv": 11.1098670399, "safe": 5.02723242559, "for": 1.00031504001, "caught": 6.06648834543, "predict": 5.18484650555, "quora": 1323.0, "closer": 5.5666199158500005, "seen": 1.61079545455, "split": 3.4709226060300002, "competit": 3.06960556845, "assum": 2.9575260804799997, "determin": 2.1658935879900003, "poor": 2.42196796339, "better": 2.0065722952500002, "compani": 1.5523613963, "current": 1.5325803649, "month": 1.5079787234, "look": 1.9086318826599997, "histor": 1.6755672823199999, "combin": 1.69760479042, "chanc": 4.2449197861000005, "think": 2.90715986083, "work": 1.11520089913, "public": 1.22424429365, "forest": 4.89546716004, "later": 1.08650424309, "net": 6.96315789474, "again": 1.50883862384, "compar": 1.8662278123900002, "group": 1.20996875238, "doe": 1.70581282905, "even": 1.16461267606, "infer": 21.1398135819, "valid": 6.61224489796, "ecuadorian": 120.27272727299999, "exquant": 1323.0, "alltoocommon": 1323.0, "great": 1.26592775696, "shuffl": 62.5039370079, "subtleti": 91.2413793103, "step": 2.8279301745599996, "error": 6.04109589041, "continu": 1.13928955867, "eat": 7.50638297872, "note": 1.42449528937, "workplac": 30.5895953757, "thing": 2.4065484311099996, "qualit": 42.223404255300004, "machin": 4.02433460076, "into": 1.01502461479, "came": 1.46013059873, "crossvalid": 1323.0, "traintestsplit": 1323.0, "earlier": 1.86776470588, "suppos": 4.23021582734, "latest": 7.078020508250001, "overfit": 1323.0, "help": 1.39962972759, "clear": 1.85423966363, "san": 3.30131004367, "nuanc": 48.2553191489, "own": 1.17844418052, "natur": 1.5392670157100001, "can": 1.17626139142, "who": 1.06279287723, "pictur": 3.4953764861300005, "univers": 1.24889867841, "permiss": 6.280063291139999, "veri": 1.25880114177, "were": 1.02458857696, "averag": 2.60390355913, "through": 1.07074930869, "engag": 2.6926729986400004, "evalu": 6.9509632224199995, "contain": 1.59814777532, "about": 1.06486015159, "problem": 1.76674827509, "imageri": 19.7955112219, "communiti": 1.96121062384, "neural": 59.4606741573, "distinct": 2.2836593786000003, "just": 1.33580143037, "perspect": 5.03520456708, "understand": 2.96858638743, "cofound": 264.6, "speci": 6.648241206030001, "she": 2.16, "jan": 8.31639601886, "check": 6.50655737705, "aug": 35.28, "dynam": 6.52527743527, "where": 1.06715063521, "train": 1.9365698950999999, "complex": 2.34021226415, "few": 1.31729173581, "run": 1.55692850838, "seri": 1.46511627907, "whi": 3.2566153846200003, "professor": 4.31061634537, "fill": 3.33809924306, "exub": 1323.0, "scatter": 9.38852749852, "until": 1.14852058164, "subdivid": 22.744985673400002, "abl": 1.8208510150200001, "columnist": 25.647819063000004, "mani": 1.04426757877, "realiz": 4.89244992296, "the": 1.0, "goal": 3.28152128979, "date": 1.63081664099, "disconnect": 42.223404255300004, "seem": 2.29123971713, "consist": 1.4901445466499998, "order": 1.24625166811, "sklearn": 1323.0, "exact": 3.46864758575, "there": 1.04091266719, "inform": 1.5753125620200001, "way": 1.2190739461, "best": 1.5828514456600002, "repres": 1.46972782818, "right": 1.4054532577899999, "take": 1.13961668222, "visual": 5.22752716497, "now": 1.160780873, "tri": 1.8544562551099997, "code": 3.8807137619199996, "per": 1.9597580545599997, "than": 1.03278688525, "basic": 2.7301805675, "haven": 12.690647482000001, "indic": 2.0826446281, "break": 2.42863698944, "also": 1.01476510067, "typic": 2.2541530597799997, "person": 1.40520446097, "mean": 1.44906900329, "reveal": 2.63196286472, "will": 1.22481098596, "exampl": 1.50483412322, "overview": 12.6805111821, "may": 1.05201775893, "lowest": 6.549504950499999, "peopl": 1.21320495186, "boat": 6.466802443990001, "want": 1.99698113208, "build": 1.6341739578, "behind": 2.0845588235299997, "ultim": 2.58524670249, "howev": 1.0945191313299998, "although": 1.14968498805, "actual": 1.87482286254, "week": 1.80532181033, "span": 6.17262830482, "which": 1.005191845, "like": 1.14918566775, "term": 1.39520168732, "variabl": 8.747107438019999, "refer": 1.30024570025, "one": 1.00627495722, "graph": 37.7102137767, "see": 1.27242125511, "imag": 2.70137825421, "phd": 22.3605633803, "get": 1.78562591385, "still": 1.1866357724799999, "random": 7.1902173913, "numfold": 1323.0, "implement": 3.57648118946, "abov": 1.90382539873, "cross": 2.33127753304, "tell": 3.36142282448, "put": 1.65806788512, "independ": 1.58950740889, "analyt": 17.256521739100002, "that": 1.00398406375, "yet": 2.1258703802900003, "includ": 1.0190641247799999, "cool": 6.8578833693300005, "next": 1.4950560316400001, "gather": 3.78631051753, "this": 1.00379362671, "choic": 3.1319786940200003, "time": 1.01127460348, "back": 1.26070038911, "bit": 8.33385826772, "similar": 1.37514075357, "smaller": 2.59369384088, "project": 1.7534791252500002, "differ": 1.23654490225, "same": 1.11857958148, "most": 1.02096463023, "between": 1.03453668708, "what": 1.25343439128, "certain": 1.8077886586200003, "drive": 2.93510815308, "rachel": 22.8760806916, "all": 1.01146788991, "illeg": 5.61584718783, "leaderboard": 1323.0, "third": 1.4195278969999998, "store": 3.44680851064, "endang": 16.020181634700002, "almost": 1.53584212054, "case": 1.48498737256, "middl": 2.04245465071, "day": 1.18371607516, "tradeoff": 208.89473684200001, "chain": 5.17639387023, "more": 1.0171706817, "and": 1.00006299213, "groceri": 45.7521613833, "reluct": 7.886736214610001, "these": 1.07415426252, "could": 1.2043695949, "car": 3.53743315508, "befor": 1.10036041031, "submit": 5.770992366410001, "state": 1.0477133240899998, "download": 14.6457564576, "wors": 9.58695652174, "serv": 1.4668760972, "francisco": 5.2937645882, "avail": 1.7288467821, "describ": 1.47027227264, "make": 1.0762660158600001, "kaggl": 1323.0, "onli": 1.0256476516600002, "gap": 7.302667893280001, "rare": 2.7259615384599996, "key": 2.28005170185, "distract": 16.5375, "accur": 5.768895348840001, "fare": 15.3095467695, "start": 1.26673581744, "weren": 1323.0, "imposs": 4.96125, "while": 1.0441988950299999, "data": 3.37643555934, "reduc": 1.98698372966, "address": 2.86157173756, "method": 2.5714285714300003, "perfect": 4.48601299802, "sinc": 1.08368600683, "sometim": 1.7126213592200001, "bio": 42.336000000000006, "wheel": 8.95936794582, "come": 1.32831325301, "must": 1.9220338983099996, "origin": 1.13724928367, "fisheri": 36.4965517241, "popul": 2.17807655371, "text": 3.12827586207, "leader": 2.0994445913799997, "identifi": 2.30187037843, "trainvalidationtestsplit": 1323.0, "import": 1.3401992233700002, "first": 1.00761614623, "busi": 2.05541170378, "have": 1.0148948411399998, "score": 4.2884927066500005, "properti": 2.5949656750599996, "host": 2.7092150170599996, "reason": 1.72340425532, "often": 1.29452054795, "rigor": 17.8783783784, "learn": 2.32275054865, "when": 1.02076769755, "mention": 2.53894130817}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  How (and Why) to Create a Good Validation Set</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/create-good-validation-set.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb How (and Why) to Create a Good Validation Set Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/scientists-too-much-research.html\" rel=\"prev\" title=\"Are Scientists Doing Too Much Research?\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/ng-deep-learning-specialization-21-lessons.html\" rel=\"next\" title=\"Deep Learning Specialization by Andrew Ng\u200a \u2013 \u200a21 Lessons Learned\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2017/11/create-good-validation-set.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=74981\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2017/11/create-good-validation-set.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-74981 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 24-Nov, 2017  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/tutorials.html\">Tutorials, Overviews</a> \u00bb How (and Why) to Create a Good Validation Set (\u00a0<a href=\"/2017/n45.html\">17:n45</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">How (and Why) to Create a Good Validation Set</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/11/scientists-too-much-research.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/11/ng-deep-learning-specialization-21-lessons.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/cross-validation\" rel=\"tag\">Cross-validation</a>, <a href=\"https://www.kdnuggets.com/tag/datasets\" rel=\"tag\">Datasets</a>, <a href=\"https://www.kdnuggets.com/tag/training-data\" rel=\"tag\">Training Data</a>, <a href=\"https://www.kdnuggets.com/tag/validation\" rel=\"tag\">Validation</a></div>\n<br/>\n<p class=\"excerpt\">\n     The definitions of training, validation, and test sets can be fairly nuanced, and the terms are sometimes inconsistently used. In the deep learning community, \u201ctest-time inference\u201d is often used to refer to evaluating on data in production, which is not the technical definition of a test set.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<p><b>By Rachel Thomas, Co-founder at <a href=\"http://www.fast.ai/\" rel=\"noopener\" target=\"_blank\">fast.ai</a>.</b></p>\n<p>An all-too-common scenario: a seemingly impressive machine learning model is a complete failure when implemented in production. The fallout includes leaders who are now skeptical of machine learning and reluctant to try it again. How can this happen?</p>\n<p>One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a\u00a0<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" target=\"_blank\"><code>train_test_split</code> method</a>, this method takes a random subset of the data, which is a poor choice for many real-world problems.</p>\n<p>The definitions of\u00a0<em>training</em>,\u00a0<em>validation</em>, and\u00a0<em>test</em>\u00a0sets can be fairly nuanced, and the terms are sometimes inconsistently used. In the deep learning community, \u201ctest-time inference\u201d is often used to refer to evaluating on data in production, which is not the technical definition of a test set. As mentioned above, sklearn has a\u00a0<code>train_test_split</code>\u00a0method, but no <code>train_validation_test_split</code>. Kaggle only provides training and test sets, yet to do well, you will need to split their training set into your own validation and training sets. Also, it turns out that Kaggle\u2019s test set is actually sub-divided into two sets. It\u2019s no suprise that many beginners may be confused! I will address these subtleties below.</p>\n<p>\u00a0</p>\n<h3>First, what is a \u201cvalidation set\u201d?</h3>\n<p>\u00a0<br>\nWhen creating a machine learning model, the ultimate goal is for it to be accurate on new data, not just the data you are using to build it. Consider the below example of 3 different models for a set of data:</br></p>\n<p><center><img alt=\"under-fitting and over-fitting\" src=\"https://image.ibb.co/bDA9TR/overfitting2.png\" width=\"85%\"/><br>\n<font size=\"-1\">Source:\u00a0<a href=\"https://www.quora.com/What-is-the-best-way-to-explain-the-bias-variance-trade-off-in-layman%E2%80%99s-terms\" target=\"_blank\">Quora</a></font></br></center></p>\n<p>The error for the pictured data points is lowest for the model on the far right (the blue curve passes through the red points almost perfectly), yet it\u2019s not the best choice. Why is that? If you were to gather some new data points, they most likely would not be on that curve in the graph on the right, but would be closer to the curve in the middle graph.</p>\n<p>The underlying idea is that:</p>\n<ul>\n<li>the training set is used to train a given model\n<li>the validation set is used to choose between models (for instance, does a random forest or a neural net work better for your problem? do you want a random forest with 40 trees or 50 trees?)\n<li>the test set tells you how you\u2019ve done. If you\u2019ve tried out a lot of different models, you may get one that does well on your validation set just by chance, and having a test set helps make sure that is not the case.\n</li></li></li></ul>\n<p>A key property of the validation and test sets is that they must be representative of the\u00a0<strong>new data you will see in the future</strong>. This may sound like an impossible order! By definition, you haven\u2019t seen this data yet. But there are still a few things you know about it.</p>\n<p>\u00a0</p>\n<h3>When is a random subset not good enough?</h3>\n<p>\u00a0<br>\nIt\u2019s instructive to look at a few examples. Although many of these examples come from Kaggle competitions, they are representative of problems you would see in the workplace.</br></p>\n<p><b>Time series</b></p>\n<p>If your data is a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates your are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future). If your data includes the date and you are building a model to use in the future, you will want to choose a continuous section with the latest dates as your validation set (for instance, the last two weeks or last month of the available data).</p>\n<p>Suppose you want to split the time series data below into training and validation sets:</p>\n<p><center><img alt=\"Time series data\" src=\"https://image.ibb.co/gbHChm/timeseries1.png\" width=\"75%\"/><br>\n<font size=\"-1\">Time series data</font></br></center></p>\n<p>A random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you\u2019ll need in production):</p>\n<p><center><img alt=\"a poor choice for your training set\" src=\"https://image.ibb.co/jMpQ2m/timeseries2.png\" width=\"75%\"/><br/>\n<font size=\"-1\">A poor choice for your training set</font></center></p>\n<p>Use the earlier data as your training set (and the later data for the validation set):</p>\n<p><center><img alt=\"a better choice for your training set\" src=\"https://image.ibb.co/jUOJNm/timeseries3.png\" width=\"75%\"/><br/>\n<font size=\"-1\">A better choice for your training set</font></center></p>\n<p>Kaggle currently has a competition to\u00a0<a href=\"https://www.kaggle.com/c/favorita-grocery-sales-forecasting\" target=\"_blank\">predict the sales in a chain of Ecuadorian grocery stores</a>. Kaggle\u2019s \u201ctraining data\u201d runs from Jan 1 2013 to Aug 15 2017 and the test data spans Aug 16 2017 to Aug 31 2017. A good approach would be to use Aug 1 to Aug 15 2017 as your validation set, and all the earlier data as your training set.</p>\n<p><b>New people, new boats, new...</b></p>\n<p>You also need to think about what ways the data you will be making predictions for in production may be\u00a0<em>qualitatively different</em>\u00a0from the data you have to train your model with.</p>\n<p>In the Kaggle\u00a0<a href=\"https://www.kaggle.com/c/state-farm-distracted-driver-detection\" target=\"_blank\">distracted driver competition</a>, the independent data are pictures of drivers at the wheel of a car, and the dependent variable is a category such as texting, eating, or safely looking ahead. If you were the insurance company building a model from this data, note that you would be most interested in how the model performs on drivers you haven\u2019t seen before (since you would likely have training data only for a small group of people). This is true of the Kaggle competition as well: the test data consists of people that weren\u2019t used in the training set.</p>\n<p><center><img alt=\"\" src=\"https://image.ibb.co/cNqXhm/driver_phone.png\" width=\"50%\"/><br/>\n<img alt=\"Two images of the same person talking on the phone while driving.\" src=\"https://image.ibb.co/cM4Ev6/driver_phone2.png\" width=\"50%\"/><br/>\n<font size=\"-1\">Two images of the same person talking on the phone while driving.</font></center></p>\n<p>If you put one of the above images in your training set and one in the validation set, your model will seem to be performing better than it would on new people. Another perspective is that if you used all the people in training your model, your model may be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc).</p>\n<p>A similar dynamic was at work in the\u00a0<a href=\"https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring\" target=\"_blank\">Kaggle fisheries competition</a>\u00a0to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations. The test set consisted of boats that didn\u2019t appear in the training data. This means that you\u2019d want your validation set to include boats that are not in the training set.</p>\n<p>Sometimes it may not be clear how your test data will differ. For instance, for a problem using satellite imagery, you\u2019d need to gather more information on whether the training set just contained certain geographic locations, or if it came from geographically scattered data.</p>\n<p>\u00a0</p>\n<h3>The dangers of cross-validation</h3>\n<p>\u00a0<br/>\nThe reason that sklearn doesn\u2019t have a\u00a0<code>train_validation_test</code>\u00a0split is that it is assumed you will often be using\u00a0<strong>cross-validation</strong>, in which different subsets of the training set serve as the validation set. For example, for a 3-fold cross validation, the data is divided into 3 sets: A, B, and C. A model is first trained on A and B combined as the training set, and evaluated on the validation set C. Next, a model is trained on A and C combined as the training set, and evaluated on validation set B. And so on, with the model performance from the 3 folds being averaged in the end.</p>\n<p>However, the problem with cross-validation is that it is rarely applicable to real world problems, for all the reasons described in the above sections. Cross-validation only works in the same cases where you can randomly shuffle your data to choose a validation set.</p>\n<p>\u00a0</p>\n<h3>Kaggle\u2019s \u201ctraining set\u201d = your training + validation sets</h3>\n<p>\u00a0<br/>\nOne great thing about Kaggle competitions is that they force you to think about validation sets more rigorously (in order to do well). For those who are new to Kaggle, it is a platform that hosts machine learning competitions. Kaggle typically breaks the data into two sets you can download:</p>\n<ol>\n<li>a\u00a0<strong>training set</strong>, which includes the\u00a0<em>independent variables</em>, as well as the\u00a0<em>dependent variable</em>\u00a0(what you are trying to predict). For the example of an Ecuadorian grocery store trying to predict sales, the independent variables include the store id, item id, and date; the dependent variable is the number sold. For the example of trying to determine whether a driver is engaging in dangerous behaviors behind the wheel, the independent variable could be a picture of the driver, and the dependent variable is a category (such as texting, eating, or safely looking forward).\n<li>a\u00a0<strong>test set</strong>, which just has the independent variables. You will make predictions for the test set, which you can submit to Kaggle and get back a score of how well you did.\n</li></li></ol>\n<p>This is the basic idea needed to get started with machine learning, but to do well, there is a bit more complexity to understand. You will want to create your own training and validation sets (by splitting the Kaggle \u201ctraining\u201d data). You will just use your smaller training set (a subset of Kaggle\u2019s training data) for building your model, and you can evaluate it on your validation set (also a subset of Kaggle\u2019s training data) before you submit to Kaggle.</p>\n<p>The most important reason for this is that Kaggle has split the test data into two sets: for the public and private leaderboards. The score you see on the public leaderboard is just for a subset of your predictions (and you don\u2019t know which subset!). How your predictions fare on the private leaderboard won\u2019t be revealed until the end of the competition. The reason this is important is that you could end up overfitting to the public leaderboard and you wouldn\u2019t realize it until the very end when you did poorly on the private leaderboard. Using a good validation set can prevent this. You can check if your validation set is any good by seeing if your model has similar scores on it to compared with on the Kaggle test set.</p>\n<p>Another reason it\u2019s important to create your own validation set is that Kaggle limits you to two submissions per day, and you will likely want to experiment more than that. Thirdly, it can be instructive to see exactly what you\u2019re getting wrong on the validation set, and Kaggle doesn\u2019t tell you the right answers for the test set or even which data points you\u2019re getting wrong, just your overall score.</p>\n<p>Understanding these distinctions is not just useful for Kaggle. In any predictive machine learning project, you want your model to be able to perform well on new data.</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://twitter.com/math_rachel\" target=\"_blank\">Rachel Thomas</a></b> is co-founder at <a href=\"http://www.fast.ai\" rel=\"noopener\" target=\"_blank\"><strong>fast.ai</strong></a> and a professor of the MS in Analytics program at the University of San Francisco. She is also an Ask-a-Data-Scientist Advice Columnist, a Duke Math PhD, ex-Quant, and ex-Uber Software Dev.</p>\n<p><a href=\"http://www.fast.ai/2017/11/13/validation-sets/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/09/visualizing-cross-validation-code.html\">Visualizing Cross-validation Code</a>\n<li><a href=\"/2016/08/bias-variance-tradeoff-overview.html\">Understanding the Bias-Variance Tradeoff: An Overview</a>\n<li><a href=\"/2016/12/thedataincubator-data-sources-data-science.html\">Data Sources for Cool Data Science Projects</a>\n</li></li></li></ul>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2017/11/scientists-too-much-research.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2017/11/ng-deep-learning-specialization-21-lessons.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a><li> <a href=\"https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html\">Graduating in GANs: Going From Understanding Generative Advers...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-join-new-generation-ai-technologists.html\">Join the new generation of AI technologists</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr17-apr23.html\">Top tweets, Apr 17\u201323: The History of Artificial #NeuralN...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/activestate-top-10-python-use-cases.html\">Top 10 Python Use Cases</a><li> <a href=\"https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html\">Generative Adversarial Networks \u2013 Key Milestones and Sta...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/attention-craving-rnn-building-transformer-networks.html\">Attention Craving RNNS: Building Up To Transformer Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-24-fors-marsh-group-lead-data-scientist.html\">Fors Marsh Group: Lead Data Scientist [Arlington, VA]</a><li> <a href=\"https://www.kdnuggets.com/2019/n16.html\">KDnuggets 19:n16, Apr 24: Data Visualization in Python with...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-mega-paw-las-vegas-lower-rates-end-friday.html\">Lower Rates End Friday for Mega-PAW Vegas \u2013 the Largest Pred...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0415-0421.html\">Top Stories, Apr 15-21: Data Visualization in Python: Matplotl...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/wharton-customer-analytics-initiative-conference.html\">Wharton Customer Analytics Initiative Annual Conference in Phi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/machine-learning-graph-analytics.html\">Machine Learning and Deep Link Graph Analytics: A Powerful Com...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-online.html\">2019 Best Masters in Data Science and Analytics \u2013 Online</a><li> <a href=\"https://www.kdnuggets.com/2019/04/worth-studying-data-science-masters.html\">Was it Worth Studying a Data Science Masters?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/approach-pre-trained-deep-learning-models-caution.html\">Approach pre-trained deep learning models with caution</a><li> <a href=\"https://www.kdnuggets.com/2019/04/coursera-earn-deep-learning-certificate.html\">Earn a Deep Learning Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/04/octoparse-scrape-data-website.html\">Easy Way to Scrape Data from Website By Yourself</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-environment.html\">AI Supporting The Earth</a><li> <a href=\"https://www.kdnuggets.com/2019/04/mueller-report-word-cloud-brief-tutorial-r.html\">The Mueller Report Word Cloud: A brief tutorial in R</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2017/index.html\">2017</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2017/11/tutorials.html\">Tutorials, Overviews</a> \u00bb How (and Why) to Create a Good Validation Set (\u00a0<a href=\"/2017/n45.html\">17:n45</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556338881\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.774 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 00:21:21 -->\n<!-- Compression = gzip -->", "content_tokenized": ["rachel", "thoma", "cofound", "fastai", "alltoocommon", "scenario", "seem", "impress", "machin", "learn", "model", "complet", "failur", "when", "implement", "product", "the", "fallout", "includ", "leader", "who", "are", "now", "skeptic", "machin", "learn", "and", "reluct", "tri", "again", "how", "can", "this", "happen", "one", "the", "most", "like", "culprit", "for", "this", "disconnect", "between", "result", "develop", "result", "product", "poor", "chosen", "valid", "set", "even", "wors", "valid", "set", "all", "depend", "the", "natur", "data", "choos", "valid", "set", "can", "the", "most", "import", "step", "although", "sklearn", "offer", "traintestsplit", "method", "this", "method", "take", "random", "subset", "the", "data", "which", "poor", "choic", "for", "mani", "realworld", "problem", "the", "definit", "train", "valid", "and", "test", "set", "can", "fair", "nuanc", "and", "the", "term", "are", "sometim", "inconsist", "use", "the", "deep", "learn", "communiti", "testtim", "infer", "often", "use", "refer", "evalu", "data", "product", "which", "not", "the", "technic", "definit", "test", "set", "mention", "abov", "sklearn", "has", "traintestsplit", "method", "but", "trainvalidationtestsplit", "kaggl", "onli", "provid", "train", "and", "test", "set", "yet", "well", "will", "need", "split", "their", "train", "set", "into", "own", "valid", "and", "train", "set", "also", "turn", "out", "that", "kaggl", "test", "set", "actual", "subdivid", "into", "two", "set", "supris", "that", "mani", "beginn", "may", "confus", "will", "address", "these", "subtleti", "below", "first", "what", "valid", "set", "when", "creat", "machin", "learn", "model", "the", "ultim", "goal", "for", "accur", "new", "data", "not", "just", "the", "data", "are", "use", "build", "consid", "the", "below", "exampl", "num", "differ", "model", "for", "set", "data", "sourc", "quora", "the", "error", "for", "the", "pictur", "data", "point", "lowest", "for", "the", "model", "the", "far", "right", "the", "blue", "curv", "pass", "through", "the", "red", "point", "almost", "perfect", "yet", "not", "the", "best", "choic", "whi", "that", "were", "gather", "some", "new", "data", "point", "they", "most", "like", "would", "not", "that", "curv", "the", "graph", "the", "right", "but", "would", "closer", "the", "curv", "the", "middl", "graph", "the", "under", "idea", "that", "the", "train", "set", "use", "train", "given", "model", "the", "valid", "set", "use", "choos", "between", "model", "for", "instanc", "doe", "random", "forest", "neural", "net", "work", "better", "for", "problem", "want", "random", "forest", "with", "num", "tree", "num", "tree", "the", "test", "set", "tell", "how", "done", "tri", "out", "lot", "differ", "model", "may", "get", "one", "that", "doe", "well", "valid", "set", "just", "chanc", "and", "have", "test", "set", "help", "make", "sure", "that", "not", "the", "case", "key", "properti", "the", "valid", "and", "test", "set", "that", "they", "must", "repres", "the", "new", "data", "will", "see", "the", "futur", "this", "may", "sound", "like", "imposs", "order", "definit", "haven", "seen", "this", "data", "yet", "but", "there", "are", "still", "few", "thing", "know", "about", "when", "random", "subset", "not", "good", "enough", "instruct", "look", "few", "exampl", "although", "mani", "these", "exampl", "come", "from", "kaggl", "competit", "they", "are", "repres", "problem", "would", "see", "the", "workplac", "time", "seri", "data", "time", "seri", "choos", "random", "subset", "the", "data", "will", "both", "too", "easi", "can", "look", "the", "data", "both", "befor", "and", "after", "the", "date", "are", "tri", "predict", "and", "not", "repres", "most", "busi", "use", "case", "where", "are", "use", "histor", "data", "build", "model", "for", "use", "the", "futur", "data", "includ", "the", "date", "and", "are", "build", "model", "use", "the", "futur", "will", "want", "choos", "continu", "section", "with", "the", "latest", "date", "valid", "set", "for", "instanc", "the", "last", "two", "week", "last", "month", "the", "avail", "data", "suppos", "want", "split", "the", "time", "seri", "data", "below", "into", "train", "and", "valid", "set", "time", "seri", "data", "random", "subset", "poor", "choic", "too", "easi", "fill", "the", "gap", "and", "not", "indic", "what", "need", "product", "poor", "choic", "for", "train", "set", "use", "the", "earlier", "data", "train", "set", "and", "the", "later", "data", "for", "the", "valid", "set", "better", "choic", "for", "train", "set", "kaggl", "current", "has", "competit", "predict", "the", "sale", "chain", "ecuadorian", "groceri", "store", "kaggl", "train", "data", "run", "from", "jan", "num", "num", "aug", "num", "num", "and", "the", "test", "data", "span", "aug", "num", "num", "aug", "num", "num", "good", "approach", "would", "use", "aug", "num", "aug", "num", "num", "valid", "set", "and", "all", "the", "earlier", "data", "train", "set", "new", "peopl", "new", "boat", "new", "also", "need", "think", "about", "what", "way", "the", "data", "will", "make", "predict", "for", "product", "may", "qualit", "differ", "from", "the", "data", "have", "train", "model", "with", "the", "kaggl", "distract", "driver", "competit", "the", "independ", "data", "are", "pictur", "driver", "the", "wheel", "car", "and", "the", "depend", "variabl", "categori", "such", "text", "eat", "safe", "look", "ahead", "were", "the", "insur", "compani", "build", "model", "from", "this", "data", "note", "that", "would", "most", "interest", "how", "the", "model", "perform", "driver", "haven", "seen", "befor", "sinc", "would", "like", "have", "train", "data", "onli", "for", "small", "group", "peopl", "this", "true", "the", "kaggl", "competit", "well", "the", "test", "data", "consist", "peopl", "that", "weren", "use", "the", "train", "set", "two", "imag", "the", "same", "person", "talk", "the", "phone", "while", "drive", "put", "one", "the", "abov", "imag", "train", "set", "and", "one", "the", "valid", "set", "model", "will", "seem", "perform", "better", "than", "would", "new", "peopl", "anoth", "perspect", "that", "use", "all", "the", "peopl", "train", "model", "model", "may", "overfit", "particular", "those", "specif", "peopl", "and", "not", "just", "learn", "the", "state", "text", "eat", "etc", "similar", "dynam", "work", "the", "kaggl", "fisheri", "competit", "identifi", "the", "speci", "fish", "caught", "fish", "boat", "order", "reduc", "illeg", "fish", "endang", "popul", "the", "test", "set", "consist", "boat", "that", "appear", "the", "train", "data", "this", "mean", "that", "want", "valid", "set", "includ", "boat", "that", "are", "not", "the", "train", "set", "sometim", "may", "not", "clear", "how", "test", "data", "will", "differ", "for", "instanc", "for", "problem", "use", "satellit", "imageri", "need", "gather", "more", "inform", "whether", "the", "train", "set", "just", "contain", "certain", "geograph", "locat", "came", "from", "geograph", "scatter", "data", "the", "danger", "crossvalid", "the", "reason", "that", "sklearn", "have", "trainvalidationtest", "split", "that", "assum", "will", "often", "use", "crossvalid", "which", "differ", "subset", "the", "train", "set", "serv", "the", "valid", "set", "for", "exampl", "for", "numfold", "cross", "valid", "the", "data", "divid", "into", "num", "set", "and", "model", "first", "train", "and", "combin", "the", "train", "set", "and", "evalu", "the", "valid", "set", "next", "model", "train", "and", "combin", "the", "train", "set", "and", "evalu", "valid", "set", "and", "with", "the", "model", "perform", "from", "the", "num", "fold", "averag", "the", "end", "howev", "the", "problem", "with", "crossvalid", "that", "rare", "applic", "real", "world", "problem", "for", "all", "the", "reason", "describ", "the", "abov", "section", "crossvalid", "onli", "work", "the", "same", "case", "where", "can", "random", "shuffl", "data", "choos", "valid", "set", "kaggl", "train", "set", "train", "valid", "set", "one", "great", "thing", "about", "kaggl", "competit", "that", "they", "forc", "think", "about", "valid", "set", "more", "rigor", "order", "well", "for", "those", "who", "are", "new", "kaggl", "platform", "that", "host", "machin", "learn", "competit", "kaggl", "typic", "break", "the", "data", "into", "two", "set", "can", "download", "train", "set", "which", "includ", "the", "independ", "variabl", "well", "the", "depend", "variabl", "what", "are", "tri", "predict", "for", "the", "exampl", "ecuadorian", "groceri", "store", "tri", "predict", "sale", "the", "independ", "variabl", "includ", "the", "store", "item", "and", "date", "the", "depend", "variabl", "the", "number", "sold", "for", "the", "exampl", "tri", "determin", "whether", "driver", "engag", "danger", "behavior", "behind", "the", "wheel", "the", "independ", "variabl", "could", "pictur", "the", "driver", "and", "the", "depend", "variabl", "categori", "such", "text", "eat", "safe", "look", "forward", "test", "set", "which", "just", "has", "the", "independ", "variabl", "will", "make", "predict", "for", "the", "test", "set", "which", "can", "submit", "kaggl", "and", "get", "back", "score", "how", "well", "this", "the", "basic", "idea", "need", "get", "start", "with", "machin", "learn", "but", "well", "there", "bit", "more", "complex", "understand", "will", "want", "creat", "own", "train", "and", "valid", "set", "split", "the", "kaggl", "train", "data", "will", "just", "use", "smaller", "train", "set", "subset", "kaggl", "train", "data", "for", "build", "model", "and", "can", "evalu", "valid", "set", "also", "subset", "kaggl", "train", "data", "befor", "submit", "kaggl", "the", "most", "import", "reason", "for", "this", "that", "kaggl", "has", "split", "the", "test", "data", "into", "two", "set", "for", "the", "public", "and", "privat", "leaderboard", "the", "score", "see", "the", "public", "leaderboard", "just", "for", "subset", "predict", "and", "know", "which", "subset", "how", "predict", "fare", "the", "privat", "leaderboard", "won", "reveal", "until", "the", "end", "the", "competit", "the", "reason", "this", "import", "that", "could", "end", "overfit", "the", "public", "leaderboard", "and", "realiz", "until", "the", "veri", "end", "when", "poor", "the", "privat", "leaderboard", "use", "good", "valid", "set", "can", "prevent", "this", "can", "check", "valid", "set", "ani", "good", "see", "model", "has", "similar", "score", "compar", "with", "the", "kaggl", "test", "set", "anoth", "reason", "import", "creat", "own", "valid", "set", "that", "kaggl", "limit", "two", "submiss", "per", "day", "and", "will", "like", "want", "experi", "more", "than", "that", "third", "can", "instruct", "see", "exact", "what", "get", "wrong", "the", "valid", "set", "and", "kaggl", "tell", "the", "right", "answer", "for", "the", "test", "set", "even", "which", "data", "point", "get", "wrong", "just", "overal", "score", "understand", "these", "distinct", "not", "just", "use", "for", "kaggl", "ani", "predict", "machin", "learn", "project", "want", "model", "abl", "perform", "well", "new", "data", "bio", "rachel", "thoma", "cofound", "fastai", "and", "professor", "the", "analyt", "program", "the", "univers", "san", "francisco", "she", "also", "askadatascientist", "advic", "columnist", "duke", "math", "phd", "exquant", "and", "exub", "softwar", "dev", "origin", "repost", "with", "permiss", "relat", "visual", "crossvalid", "code", "understand", "the", "biasvari", "tradeoff", "overview", "data", "sourc", "for", "cool", "data", "scienc", "project"], "timestamp_scraper": 1556379304.156511, "title": "How (and Why) to Create a Good Validation Set", "read_time": 547.1999999999999, "content_html": "<div class=\"post\" id=\"post-\">\n<p><b>By Rachel Thomas, Co-founder at <a href=\"http://www.fast.ai/\" rel=\"noopener\" target=\"_blank\">fast.ai</a>.</b></p>\n<p>An all-too-common scenario: a seemingly impressive machine learning model is a complete failure when implemented in production. The fallout includes leaders who are now skeptical of machine learning and reluctant to try it again. How can this happen?</p>\n<p>One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a\u00a0<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" target=\"_blank\"><code>train_test_split</code> method</a>, this method takes a random subset of the data, which is a poor choice for many real-world problems.</p>\n<p>The definitions of\u00a0<em>training</em>,\u00a0<em>validation</em>, and\u00a0<em>test</em>\u00a0sets can be fairly nuanced, and the terms are sometimes inconsistently used. In the deep learning community, \u201ctest-time inference\u201d is often used to refer to evaluating on data in production, which is not the technical definition of a test set. As mentioned above, sklearn has a\u00a0<code>train_test_split</code>\u00a0method, but no <code>train_validation_test_split</code>. Kaggle only provides training and test sets, yet to do well, you will need to split their training set into your own validation and training sets. Also, it turns out that Kaggle\u2019s test set is actually sub-divided into two sets. It\u2019s no suprise that many beginners may be confused! I will address these subtleties below.</p>\n<p>\u00a0</p>\n<h3>First, what is a \u201cvalidation set\u201d?</h3>\n<p>\u00a0<br>\nWhen creating a machine learning model, the ultimate goal is for it to be accurate on new data, not just the data you are using to build it. Consider the below example of 3 different models for a set of data:</br></p>\n<p><center><img alt=\"under-fitting and over-fitting\" src=\"https://image.ibb.co/bDA9TR/overfitting2.png\" width=\"85%\"/><br>\n<font size=\"-1\">Source:\u00a0<a href=\"https://www.quora.com/What-is-the-best-way-to-explain-the-bias-variance-trade-off-in-layman%E2%80%99s-terms\" target=\"_blank\">Quora</a></font></br></center></p>\n<p>The error for the pictured data points is lowest for the model on the far right (the blue curve passes through the red points almost perfectly), yet it\u2019s not the best choice. Why is that? If you were to gather some new data points, they most likely would not be on that curve in the graph on the right, but would be closer to the curve in the middle graph.</p>\n<p>The underlying idea is that:</p>\n<ul>\n<li>the training set is used to train a given model\n<li>the validation set is used to choose between models (for instance, does a random forest or a neural net work better for your problem? do you want a random forest with 40 trees or 50 trees?)\n<li>the test set tells you how you\u2019ve done. If you\u2019ve tried out a lot of different models, you may get one that does well on your validation set just by chance, and having a test set helps make sure that is not the case.\n</li></li></li></ul>\n<p>A key property of the validation and test sets is that they must be representative of the\u00a0<strong>new data you will see in the future</strong>. This may sound like an impossible order! By definition, you haven\u2019t seen this data yet. But there are still a few things you know about it.</p>\n<p>\u00a0</p>\n<h3>When is a random subset not good enough?</h3>\n<p>\u00a0<br>\nIt\u2019s instructive to look at a few examples. Although many of these examples come from Kaggle competitions, they are representative of problems you would see in the workplace.</br></p>\n<p><b>Time series</b></p>\n<p>If your data is a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates your are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future). If your data includes the date and you are building a model to use in the future, you will want to choose a continuous section with the latest dates as your validation set (for instance, the last two weeks or last month of the available data).</p>\n<p>Suppose you want to split the time series data below into training and validation sets:</p>\n<p><center><img alt=\"Time series data\" src=\"https://image.ibb.co/gbHChm/timeseries1.png\" width=\"75%\"/><br>\n<font size=\"-1\">Time series data</font></br></center></p>\n<p>A random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you\u2019ll need in production):</p>\n<p><center><img alt=\"a poor choice for your training set\" src=\"https://image.ibb.co/jMpQ2m/timeseries2.png\" width=\"75%\"/><br/>\n<font size=\"-1\">A poor choice for your training set</font></center></p>\n<p>Use the earlier data as your training set (and the later data for the validation set):</p>\n<p><center><img alt=\"a better choice for your training set\" src=\"https://image.ibb.co/jUOJNm/timeseries3.png\" width=\"75%\"/><br/>\n<font size=\"-1\">A better choice for your training set</font></center></p>\n<p>Kaggle currently has a competition to\u00a0<a href=\"https://www.kaggle.com/c/favorita-grocery-sales-forecasting\" target=\"_blank\">predict the sales in a chain of Ecuadorian grocery stores</a>. Kaggle\u2019s \u201ctraining data\u201d runs from Jan 1 2013 to Aug 15 2017 and the test data spans Aug 16 2017 to Aug 31 2017. A good approach would be to use Aug 1 to Aug 15 2017 as your validation set, and all the earlier data as your training set.</p>\n<p><b>New people, new boats, new...</b></p>\n<p>You also need to think about what ways the data you will be making predictions for in production may be\u00a0<em>qualitatively different</em>\u00a0from the data you have to train your model with.</p>\n<p>In the Kaggle\u00a0<a href=\"https://www.kaggle.com/c/state-farm-distracted-driver-detection\" target=\"_blank\">distracted driver competition</a>, the independent data are pictures of drivers at the wheel of a car, and the dependent variable is a category such as texting, eating, or safely looking ahead. If you were the insurance company building a model from this data, note that you would be most interested in how the model performs on drivers you haven\u2019t seen before (since you would likely have training data only for a small group of people). This is true of the Kaggle competition as well: the test data consists of people that weren\u2019t used in the training set.</p>\n<p><center><img alt=\"\" src=\"https://image.ibb.co/cNqXhm/driver_phone.png\" width=\"50%\"/><br/>\n<img alt=\"Two images of the same person talking on the phone while driving.\" src=\"https://image.ibb.co/cM4Ev6/driver_phone2.png\" width=\"50%\"/><br/>\n<font size=\"-1\">Two images of the same person talking on the phone while driving.</font></center></p>\n<p>If you put one of the above images in your training set and one in the validation set, your model will seem to be performing better than it would on new people. Another perspective is that if you used all the people in training your model, your model may be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc).</p>\n<p>A similar dynamic was at work in the\u00a0<a href=\"https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring\" target=\"_blank\">Kaggle fisheries competition</a>\u00a0to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations. The test set consisted of boats that didn\u2019t appear in the training data. This means that you\u2019d want your validation set to include boats that are not in the training set.</p>\n<p>Sometimes it may not be clear how your test data will differ. For instance, for a problem using satellite imagery, you\u2019d need to gather more information on whether the training set just contained certain geographic locations, or if it came from geographically scattered data.</p>\n<p>\u00a0</p>\n<h3>The dangers of cross-validation</h3>\n<p>\u00a0<br/>\nThe reason that sklearn doesn\u2019t have a\u00a0<code>train_validation_test</code>\u00a0split is that it is assumed you will often be using\u00a0<strong>cross-validation</strong>, in which different subsets of the training set serve as the validation set. For example, for a 3-fold cross validation, the data is divided into 3 sets: A, B, and C. A model is first trained on A and B combined as the training set, and evaluated on the validation set C. Next, a model is trained on A and C combined as the training set, and evaluated on validation set B. And so on, with the model performance from the 3 folds being averaged in the end.</p>\n<p>However, the problem with cross-validation is that it is rarely applicable to real world problems, for all the reasons described in the above sections. Cross-validation only works in the same cases where you can randomly shuffle your data to choose a validation set.</p>\n<p>\u00a0</p>\n<h3>Kaggle\u2019s \u201ctraining set\u201d = your training + validation sets</h3>\n<p>\u00a0<br/>\nOne great thing about Kaggle competitions is that they force you to think about validation sets more rigorously (in order to do well). For those who are new to Kaggle, it is a platform that hosts machine learning competitions. Kaggle typically breaks the data into two sets you can download:</p>\n<ol>\n<li>a\u00a0<strong>training set</strong>, which includes the\u00a0<em>independent variables</em>, as well as the\u00a0<em>dependent variable</em>\u00a0(what you are trying to predict). For the example of an Ecuadorian grocery store trying to predict sales, the independent variables include the store id, item id, and date; the dependent variable is the number sold. For the example of trying to determine whether a driver is engaging in dangerous behaviors behind the wheel, the independent variable could be a picture of the driver, and the dependent variable is a category (such as texting, eating, or safely looking forward).\n<li>a\u00a0<strong>test set</strong>, which just has the independent variables. You will make predictions for the test set, which you can submit to Kaggle and get back a score of how well you did.\n</li></li></ol>\n<p>This is the basic idea needed to get started with machine learning, but to do well, there is a bit more complexity to understand. You will want to create your own training and validation sets (by splitting the Kaggle \u201ctraining\u201d data). You will just use your smaller training set (a subset of Kaggle\u2019s training data) for building your model, and you can evaluate it on your validation set (also a subset of Kaggle\u2019s training data) before you submit to Kaggle.</p>\n<p>The most important reason for this is that Kaggle has split the test data into two sets: for the public and private leaderboards. The score you see on the public leaderboard is just for a subset of your predictions (and you don\u2019t know which subset!). How your predictions fare on the private leaderboard won\u2019t be revealed until the end of the competition. The reason this is important is that you could end up overfitting to the public leaderboard and you wouldn\u2019t realize it until the very end when you did poorly on the private leaderboard. Using a good validation set can prevent this. You can check if your validation set is any good by seeing if your model has similar scores on it to compared with on the Kaggle test set.</p>\n<p>Another reason it\u2019s important to create your own validation set is that Kaggle limits you to two submissions per day, and you will likely want to experiment more than that. Thirdly, it can be instructive to see exactly what you\u2019re getting wrong on the validation set, and Kaggle doesn\u2019t tell you the right answers for the test set or even which data points you\u2019re getting wrong, just your overall score.</p>\n<p>Understanding these distinctions is not just useful for Kaggle. In any predictive machine learning project, you want your model to be able to perform well on new data.</p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://twitter.com/math_rachel\" target=\"_blank\">Rachel Thomas</a></b> is co-founder at <a href=\"http://www.fast.ai\" rel=\"noopener\" target=\"_blank\"><strong>fast.ai</strong></a> and a professor of the MS in Analytics program at the University of San Francisco. She is also an Ask-a-Data-Scientist Advice Columnist, a Duke Math PhD, ex-Quant, and ex-Uber Software Dev.</p>\n<p><a href=\"http://www.fast.ai/2017/11/13/validation-sets/\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2017/09/visualizing-cross-validation-code.html\">Visualizing Cross-validation Code</a>\n<li><a href=\"/2016/08/bias-variance-tradeoff-overview.html\">Understanding the Bias-Variance Tradeoff: An Overview</a>\n<li><a href=\"/2016/12/thedataincubator-data-sources-data-science.html\">Data Sources for Cool Data Science Projects</a>\n</li></li></li></ul>\n</div> ", "website": "kdnuggets"}