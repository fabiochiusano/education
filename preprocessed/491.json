{"content": "By Matthew Mayo , KDnuggets. comments Generating text is one of those projects that seems like a lot of fun to machine learning and NLP beginners, but one which is also pretty daunting. Or, at least it was for me. Thankfully, there are all sorts of great materials online for learning how RNNs can be used for generating text, ranging from the theoretical to the technically in-depth to those decidedly focused on the practical. There are also some very good posts which cover it all and are now considered canon in this space. All of these materials share one thing in particular: at some point along the way, you have to build and tune an RNN to do the work. While this is a obviously a worthwhile undertaking, especially for the sake of learning, what if you are OK with a much higher level of abstraction, whatever your reason may be? What if you are a data scientist that requires a building block in the form of an RNN text generator to plug into your project? Or, what if, as a newcomer, you simply want to get your hands a bit -- but not too -- dirty, as a means of testing the water or as motivation to dig down further? In that vein, let's take a look at textgenrnn , a project which allows you to \"easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.\" textgenrnn is authored by Max Woolf, an Associate Data Scientist at BuzzFeed, and former Apple Software QA Engineer. textgenrnn is a built on top of Keras and TensorFlow, and can be used to generate both character and word level text (character level is the default). The network architecture uses attention-weighting and skip-embedding for accelerated training and improved quality, and allows for the tuning of a number of hyperparameters, such as RNN size, RNN layers, and the inclusion of bidirectional RNNs. You can read more about textgenrnn and its features and architecture at its Github repo or in this introductory blog post . Since the \"Hello, World!\" for text generation (at least, in my mind) seems to be generating Trump tweets, let's go with that. textgenrnn's default pretrained model can be trained on new texts easily -- though you can also use textgenrnn to train a new model (just add new_model=True to any of its train functions) -- and since we want to see how quickly we can get generating tweets, let's go that route. \u00a0 Acquiring the Data \u00a0 I grabbed a selection of Donald Trump's tweets -- Jan 1, 2014 - Jun 11, 2018 (yesterday, at time of writing), which clearly includes tweets from both before and after his inauguration as President of the United States -- from Trump Twitter Archive , a site which makes querying and downloading tweets from the President painless. I chose only to grab the text from the tweets in that date range, since I don't care about any of the metadata, and saved it to a text file I appropriately called trump-tweets.txt . \u00a0 Training the Model \u00a0 Let's see how uncomplicated it is to generate text with textgenrnn. The following 4 lines are all we need to import the library, create a text generation object, train the model on the trump-tweets.txt file for 10 epochs, and then generate some sample tweets. HTML generated using hilite.me from textgenrnn import textgenrnn\r textgen = \r textgen . \r textgen . \r After about 30 minutes, here's what's generated (on the 10th epoch): \r My @FoxNews will be self finally complaining about me that so he is a great day and companies and is starting to report the president in safety and more than any mention of the bail of the underaches to the construction and freedom and efforts the politicians and expensive meetings should have bee\r \r The world will be interviewed on @foxandfriends at 7:30pm. Enjoy!\r \r .@JebBush and Fake News Media is a major place in the White House in the service and sense where the people of the debate and his show of many people who is a great press considering the GREAT job on the way to the U.S. A the best and people in the biggest! Thank you!\r \r New Hampshire Trump Int'l Hotel Leadership Barrier Lou Clinton is a forever person politically record supporters have really beginning in the media on the heart of the bad and women who have been succeeded and before you can also work the people are there a time strong and send out the world with \r \r Join me in Maryland at 7:00 A.M. and happened to the WALL and be true the longer of the same sign into the Fake News Media will be a great honor to serve that the Republican Party will be a great legal rate the media with the Best Republican Party and the American people that will be the bill by a Leaving politics aside, and given that we are only using ~12K tweets for training in a mere 10 epochs, these generated tweets are not... terrible. Want to play with temperature (the textgenrnn default is 0.5) to get some more creative tweets? Let's try it out: HTML generated using hilite.me textgen . \r \r \u201cVia-can see this Democrats were the opening at GREAT ENSUS CALL!\r \r .@GovSeptorald Taster is got to that the subcent Vote waiting them. @Calkers\r \r Major President Obama will listen for the disaster!\r \r Grateful and South Carolina so his real ability and much better-- or big crisis on many signing!\r \r It is absolutely dumbers for well tonight. Love us in the great inherition of fast. With bill of badly to forget the greatest puppet at my wedds. No Turnberry is \"bigger.\u201d - Al\r Well, that's less convincing. How about something more conservative, which the model is more confident of: HTML generated using hilite.me textgen . \r \r The Fake News Media is a great people of the president was a great people of the many people who would be a great people of the president was a big crowd of the statement of the media is a great people of the people of the statement of the people of the people of the world with the statement of th\r \r Thank you @TrumpTowerNY #Trump2016 /25551R58350\r \r Thank you for your support! #Trump2016 /7eN53P55c\r \r The people of the U.S. has been a great people of the presidential country is a great time and the best thing that the people of the statement of the media is the people of the state of the best thing that the people of the statement of the statement of the problem in the problem and success and t\r \r Thank you @TheBrodyFile tonight at 8:00 A.M. Enjoy! Well now, some of these are seemingly more legible. Of course, this isn't perfect. There are all sorts of other things we could have tried, and the good news is that, if you don't want to implement your own solution, textgenrnn can be used to perform many of these things (again, see the Github repo ): Train our own model from scratch Train with more sample data for a greater number of iterations Tune other hyperparameters Preprocess the data a bit (at the very least to eliminate the fake URLs) Kind of fun. I'm interested in seeing how a default textgenrnn model performs out-of-the-box against a custom, well-tuned model. Maybe something for next time. \u00a0 Related : 5 Machine Learning Projects You Should Not Overlook, June 2018 Getting Started with spaCy for Natural Language Processing Find Out What Celebrities Tweet About the Most", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"Silver Blog\" src=\"/images/tkb-1806-s.png\" width=\"94\"/>Generating Text with RNNs in 4 Lines of Code</h1> ", "url": "https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html", "tfidf": {"tfidf": {"after": 2.04140414042, "hand": 1.6152202665600002, "real": 2.28103448276, "matthew": 6.908616187989999, "hyperparamet": 3175.2, "donald": 7.0970049173000005, "then": 1.08657860516, "too": 1.81585268215, "relat": 1.23750876919, "play": 1.46390041494, "form": 1.12755681818, "repo": 738.418604652, "kind": 2.5806241872599998, "space": 2.39818731118, "numth": 1.1751295336799998, "dirti": 18.2482758621, "june": 1.43414634146, "number": 2.20285833218, "taster": 882.0, "dataset": 193.609756098, "function": 2.495441685, "int": 85.3548387097, "undertak": 10.8, "well": 3.1967246123999997, "join": 1.7922781666299998, "tri": 3.7089125102199993, "terribl": 14.5517873511, "convinc": 4.4051054384, "water": 2.13157894737, "technic": 3.1400316455699997, "url": 41.669291338600004, "higher": 2.1218925421, "motiv": 5.01611374408, "legal": 2.6000655093400002, "chose": 4.42105263158, "tonight": 48.0363086232, "particular": 1.3814827706200001, "creat": 1.2492917847, "enjoy": 6.653813914500001, "woolf": 89.19101123600001, "how": 8.01251640255, "test": 2.65707112971, "news": 8.32730133752, "good": 3.03963239518, "especi": 1.66712170534, "would": 1.0828729281799998, "mayb": 21.0557029178, "given": 1.35426085473, "word": 1.7965372864099998, "interest": 1.60331246213, "beginn": 53.4545454545, "conserv": 3.3199498117900004, "consid": 2.4794627518400003, "site": 1.9721739130400002, "lou": 21.4251012146, "textgener": 1587.6, "safeti": 4.4235162998, "improv": 2.04376930999, "textgen": 7938.0, "next": 1.4950560316400001, "perform": 3.0627954085000004, "but": 2.03264835798, "inherit": 6.4932515337400005, "were": 1.02458857696, "need": 1.4372623574099999, "our": 2.35758835759, "longer": 2.02319357716, "final": 1.34008609775, "tune": 31.2519685038, "point": 1.25990000794, "record": 1.42334588488, "jan": 8.31639601886, "level": 4.96331804919, "dig": 18.5034965035, "success": 1.32002993265, "fun": 25.7727272728, "spaci": 1587.6, "tensorflow": 1587.6, "listen": 6.97846153846, "use": 9.266748816419998, "default": 84.5592543276, "painless": 252.0, "out": 3.18050083473, "model": 16.7247827232, "jebbush": 1587.6, "trumpnum": 3175.2, "much": 2.3884459154599997, "cours": 2.15092805853, "absolut": 5.3472549680000006, "daunt": 102.425806452, "not": 3.04702194357, "someth": 6.56304257958, "countri": 1.4138391664399999, "less": 1.46904783936, "solut": 4.7278141751, "happen": 2.96359902931, "quick": 2.205, "true": 2.55569864778, "appropri": 4.31413043478, "though": 1.36076112111, "problem": 3.53349655018, "compani": 1.5523613963, "allow": 2.5432118542200004, "world": 4.45360824744, "kdnugget": 1587.6, "github": 3175.2, "construct": 1.9320920043799998, "hilitem": 4762.799999999999, "featur": 1.52712581762, "carolina": 7.54921540656, "practic": 1.70434782609, "author": 1.4229631621399998, "block": 3.20274359492, "twitter": 33.213389121300004, "overlook": 11.4051724138, "softwar": 10.2624434389, "got": 3.61969904241, "such": 1.06151377374, "succeed": 3.3550295857999997, "meet": 1.6658971668399998, "network": 5.18738768176, "politician": 4.7235941684, "lot": 4.40877534018, "some": 5.2018348624, "should": 3.3286508019800003, "add": 4.61243463103, "call": 1.0676529926, "confid": 6.327620565959999, "press": 1.41245551601, "bee": 25.0805687204, "rate": 2.14048806795, "languag": 2.29488291414, "media": 18.15585688616, "wait": 4.55421686747, "ani": 5.6691901157, "and": 42.002645669459994, "from": 7.00397050479, "temperatur": 5.45567010309, "work": 2.23040179826, "num": 13.00409552013, "inaugur": 6.38616251006, "turnberri": 1134.0, "mere": 4.20222339862, "freedom": 3.4854006586199997, "yesterday": 33.213389121300004, "acquir": 3.10563380282, "for": 15.004725600150001, "american": 1.31641791045, "with": 11.013180298889997, "requir": 1.52844902282, "new": 3.0536641662, "these": 4.29661705008, "are": 11.32896529358, "south": 1.5457112257799999, "max": 7.474576271189999, "better": 2.0065722952500002, "calker": 1587.6, "effort": 1.89247824532, "sens": 2.8365195640499996, "preprocess": 1221.23076923, "look": 1.9086318826599997, "statement": 20.53373571888, "trumptowerni": 1587.6, "veri": 2.51760228354, "fake": 73.16129032239999, "welltun": 1587.6, "whatev": 7.6473988439300005, "thebrodyfil": 1587.6, "bidirect": 288.654545455, "complain": 8.299006795610001, "focus": 2.01012914662, "iter": 37.4433962264, "foxnew": 1587.6, "disast": 6.58481957694, "bail": 33.4231578947, "top": 1.8387769284200002, "vote": 3.0011342155, "place": 1.1004366812200002, "great": 15.19113308352, "legibl": 223.605633803, "scratch": 25.8146341463, "his": 3.2831047080600007, "big": 5.480151881259999, "comment": 3.05954904606, "honor": 3.5272161741800003, "heart": 3.00340522134, "thing": 12.032742155549998, "presid": 11.905511811, "scientist": 9.38852749852, "machin": 8.04866920152, "into": 2.03004922958, "appl": 13.6980155306, "sinc": 3.2510580204900004, "servic": 1.51300867245, "presidenti": 6.325099601590001, "where": 1.06715063521, "canon": 10.8220858896, "rout": 3.1619199362700003, "what": 6.2671719563999995, "let": 17.43083003955, "save": 2.8178913737999998, "against": 1.2902072328299998, "clear": 1.85423966363, "find": 1.7294117647099998, "trump": 248.0625, "line": 2.8365195640599996, "cover": 1.69380134429, "own": 3.5353325415600003, "sake": 19.9447236181, "natur": 1.5392670157100001, "who": 3.18837863169, "decid": 1.9257641921400002, "women": 2.31732593782, "bigger": 13.23, "post": 4.47652615254, "here": 2.42307692308, "obama": 14.5251601098, "report": 1.3634489866, "viacan": 1587.6, "blog": 14.1876675603, "onlin": 2.6051854282900004, "layer": 8.14153846154, "queri": 56.2978723404, "greater": 2.14801785956, "care": 2.49426551453, "about": 6.38916090954, "biggest": 5.2972972973, "epoch": 115.043478261, "job": 3.2539454806299997, "neural": 59.4606741573, "mind": 3.5918552036199998, "have": 5.0744742057, "just": 1.33580143037, "tweet": 1021.2631578951999, "unit": 1.15394679459, "simpli": 2.5192002538900002, "crowd": 5.4, "expens": 3.5453327378300004, "dumber": 721.636363636, "train": 19.365698951, "newcom": 27.5147313692, "complex": 2.34021226415, "start": 2.53347163488, "barrier": 8.66593886463, "love": 2.97303370787, "them": 1.09876115994, "democrat": 4.1214953271, "bad": 6.788967286719999, "wedd": 1587.6, "support": 2.5371154614400004, "inclus": 8.756756756760002, "learn": 9.2910021946, "mani": 4.17707031508, "the": 94.0, "theoret": 7.83613030602, "generat": 30.7913110938, "build": 3.2683479156, "creativ": 6.52259654889, "seem": 6.87371915139, "pretrain": 1587.6, "select": 2.02345144022, "trumptweetstxt": 3175.2, "same": 1.11857958148, "rnns": 3175.2, "there": 4.16365066876, "govseptorald": 1587.6, "least": 4.8496079829, "maryland": 12.335664335699999, "best": 6.331405782640001, "jun": 31.943661971799997, "interview": 3.3981164383599998, "introductori": 30.297709923699998, "hous": 1.4624170965399999, "take": 1.13961668222, "follow": 1.04640126549, "now": 2.321561746, "further": 1.3618116315, "code": 3.8807137619199996, "hello": 44.4705882353, "than": 1.03278688525, "self": 11.972850678699999, "realli": 4.7476076555, "abil": 2.70875277256, "also": 4.05906040268, "person": 1.40520446097, "mean": 1.44906900329, "acceler": 8.15408320493, "materi": 4.26029786664, "white": 1.86930413282, "major": 2.29704116328, "associ": 1.3263157894700002, "may": 1.05201775893, "mayo": 49.7680250784, "clinton": 13.488530161400002, "peopl": 21.83768913348, "open": 1.24556723678, "polit": 3.53703909992, "those": 2.39096385542, "want": 7.98792452832, "vein": 24.3870967742, "grate": 27.7068062827, "outofthebox": 1587.6, "share": 1.8566249561500001, "elimin": 3.67670217693, "archiv": 3.3451327433599998, "minut": 3.11233091551, "plug": 30.297709923699998, "debat": 3.2294548413300004, "which": 6.03115107, "buzzfe": 1134.0, "other": 2.01984732824, "one": 3.01882487166, "show": 1.26703910615, "fast": 4.8729281768, "custom": 3.6346153846199996, "begin": 1.3305397251100002, "see": 6.36210627555, "get": 7.1425036554, "like": 1.14918566775, "implement": 3.57648118946, "file": 7.542042755339999, "process": 1.69524826482, "both": 2.10431440122, "that": 15.059760956249999, "includ": 1.0190641247799999, "sign": 3.5213485638199997, "celebr": 2.48256450352, "leadership": 4.03661327231, "kera": 835.5789473680001, "textgenrnn": 19051.199999999997, "this": 5.0189681335500005, "pretti": 15.75, "sampl": 14.46560364464, "rang": 3.5696458684599994, "time": 4.04509841392, "engin": 2.47135740971, "grab": 44.7211267606, "bit": 16.66771653544, "bill": 5.585224274400001, "project": 7.013916501000001, "will": 7.34886591576, "been": 2.0478555304799997, "puppet": 19.5517241379, "forget": 16.9978586724, "most": 1.02096463023, "forev": 12.0363912055, "attentionweight": 1587.6, "uncompl": 273.724137931, "obvious": 6.44841592201, "along": 1.2973768080399999, "all": 5.05733944955, "charact": 5.03440621532, "reason": 1.72340425532, "strong": 1.6439888163999998, "former": 1.36111111111, "metadata": 211.68, "day": 1.18371607516, "sort": 10.376470588239998, "foxandfriend": 1587.6, "architectur": 10.25581395348, "built": 1.99447236181, "thank": 30.0340522134, "object": 2.3488681757700003, "more": 7.1201947719, "hotel": 5.05927342256, "again": 1.50883862384, "while": 1.0441988950299999, "indepth": 1587.6, "numennumpnumc": 1587.6, "greatest": 3.00738776283, "could": 1.2043695949, "befor": 2.20072082062, "librari": 2.68266306185, "parti": 4.12738853504, "state": 2.0954266481799997, "download": 14.6457564576, "serv": 1.4668760972, "can": 9.41009113136, "make": 1.0762660158600001, "asid": 6.69873417722, "way": 2.4381478922, "write": 2.0575427682700003, "onli": 2.0512953033200003, "size": 4.9877474081, "few": 1.31729173581, "hampshir": 18.3114186851, "read": 2.3149606299200003, "underach": 1587.6, "data": 16.8821777967, "qualiti": 2.9329392204, "perfect": 4.48601299802, "crisi": 4.24832753546, "abstract": 9.966101694919999, "numpm": 75.961722488, "text": 34.41103448277, "send": 3.75053153792, "import": 2.6803984467400004, "has": 1.0436497502, "skipembed": 1587.6, "leav": 1.6615384615399997, "date": 1.63081664099, "subcent": 1587.6, "republican": 12.7313552526, "easili": 7.387622149839999, "down": 1.35889754344, "newmodeltru": 1587.6, "mention": 2.53894130817, "worthwhil": 86.28260869569999}, "logtfidf": {"after": 0.040981389296199995, "hand": 0.479471335336, "real": 0.824629060574, "matthew": 1.9327693554900003, "hyperparamet": 14.739957441820001, "donald": 1.95967285241, "then": 0.08303386523089999, "too": 0.5965551547219999, "relat": 0.21310030165399999, "play": 0.38110439064199997, "form": 0.120053184191, "repo": 11.82272739642, "kind": 0.948031302717, "space": 0.874713164972, "numth": 0.161378382949, "dirti": 2.90407060225, "june": 0.3605697882, "number": 0.1932171568372, "taster": 6.7821920560099995, "dataset": 5.26584456664, "function": 0.914465741594, "int": 4.44681714019, "undertak": 2.37954613413, "well": 0.1905433149468, "join": 0.58348752942, "tri": 1.23518305832, "terribl": 2.67771382807, "convinc": 1.4827641951700001, "water": 0.756862994946, "technic": 1.14423287808, "url": 3.72976443878, "higher": 0.752308398995, "motiv": 1.61265547932, "legal": 0.955536640608, "chose": 1.48637781968, "tonight": 6.357619948099999, "particular": 0.323157393804, "creat": 0.222576818514, "enjoy": 2.4040860613799997, "woolf": 4.49078026361, "how": 2.3578347846500005, "test": 0.977224437103, "news": 2.93298029394, "good": 0.837178809814, "especi": 0.511098609709, "would": 0.0796176279647, "mayb": 3.0471714458899997, "given": 0.303255810831, "word": 0.585861082385, "interest": 0.47207177798199995, "beginn": 3.9788316751, "conserv": 1.19994966588, "consid": 0.429789447648, "site": 0.6791364434899999, "lou": 3.06456318861, "textgener": 7.369978720910001, "safeti": 1.48693492276, "improv": 0.7147958039319999, "textgen": 36.849893604550005, "next": 0.402163685499, "perform": 0.85236170116, "but": 0.0323847441438, "inherit": 1.87076341199, "were": 0.024291143681099997, "need": 0.362740163442, "our": 0.8576392141820001, "longer": 0.7046772417749999, "final": 0.292733863948, "tune": 7.03041023298, "point": 0.23103235903299998, "record": 0.353010356953, "jan": 2.11822899018, "level": 1.510386569829, "dig": 2.91795971441, "success": 0.27765441259199997, "fun": 5.112339339619999, "spaci": 7.369978720910001, "tensorflow": 7.369978720910001, "listen": 1.94282848252, "use": 0.2628721775844, "default": 12.204632648559999, "painless": 5.52942908751, "out": 0.1752791727579, "model": 5.899600584888001, "jebbush": 7.369978720910001, "trumpnum": 14.739957441820001, "much": 0.35499145860200004, "cours": 0.765899404133, "absolut": 1.67658333914, "daunt": 4.62913869698, "not": 0.0466572390225, "someth": 2.37661424546, "countri": 0.34630881733, "less": 0.3846144626, "solut": 1.55346297627, "happen": 1.08640441802, "quick": 0.790727508899, "true": 0.938325629634, "appropri": 1.4618957827399999, "though": 0.308044191079, "problem": 1.138281448546, "compani": 0.439777253097, "allow": 0.48056122237800003, "world": 0.429680994484, "kdnugget": 7.369978720910001, "github": 14.739957441820001, "construct": 0.658603355972, "hilitem": 22.10993616273, "featur": 0.423387418142, "carolina": 2.0214436382, "practic": 0.533182530867, "author": 0.35274143130999996, "block": 1.16400781588, "twitter": 3.50295308141, "overlook": 2.43406697301, "softwar": 2.32849096333, "got": 1.2863908849299999, "such": 0.059695977806, "succeed": 1.2104605888, "meet": 0.510363817255, "network": 1.9061661061039998, "politician": 1.55256998618, "lot": 1.4835969502500002, "some": 0.1978675453225, "should": 1.018839753516, "add": 1.52875583713, "call": 0.0654627744488, "confid": 1.8449242675400002, "press": 0.345329690455, "bee": 3.22209339176, "rate": 0.761033872166, "languag": 0.8306818244059999, "media": 6.671581371364, "wait": 1.51605358782, "ani": 0.6280417918300001, "and": 0.0026455859666712, "from": 0.0039693791820619995, "temperatur": 1.6966554537399998, "work": 0.218069134546, "num": 0.004094875140161, "inaugur": 1.85413354183, "turnberri": 7.033506484289999, "mere": 1.43561376584, "freedom": 1.2485830042100001, "yesterday": 3.50295308141, "acquir": 1.1332178178499999, "for": 0.004724855930955001, "american": 0.274914343622, "with": 0.01317240884729, "requir": 0.424253510675, "new": 0.0531898405533, "these": 0.2861344776032, "are": 0.3241422094097, "south": 0.43548414473700003, "max": 2.01150743154, "better": 0.6964279406, "calker": 7.369978720910001, "effort": 0.637887211057, "sens": 1.04257779501, "preprocess": 7.1076144564399995, "look": 0.6463866936, "statement": 7.381858254900001, "trumptowerni": 7.369978720910001, "veri": 0.460319586476, "fake": 11.625488396960002, "welltun": 7.369978720910001, "whatev": 2.0343655696200003, "thebrodyfil": 7.369978720910001, "bidirect": 5.66523062867, "complain": 2.1161358444599996, "focus": 0.6981989720559999, "iter": 3.62283035867, "foxnew": 7.369978720910001, "disast": 1.8847669357199999, "bail": 3.50924900987, "top": 0.609100637788, "vote": 1.09899028905, "place": 0.0957070839572, "great": 2.829663096948, "legibl": 5.40988393686, "scratch": 3.2509415461, "his": 0.2705317300923, "big": 2.01597127114, "comment": 1.11826753454, "honor": 1.26050894061, "heart": 1.09974671874, "thing": 4.3909676734, "presid": 4.111452006317999, "scientist": 3.09268256888, "machin": 2.78471916124, "into": 0.0298257264574, "appl": 2.61725097056, "sinc": 0.2411045983731, "servic": 0.41410016674500005, "presidenti": 1.84452578178, "where": 0.0649921387457, "canon": 2.38158903576, "rout": 1.15117941787, "what": 1.129436484135, "let": 6.2440128364, "save": 1.03598886547, "against": 0.254802851078, "clear": 0.617474727198, "find": 0.547781330288, "trump": 16.50954547768, "line": 0.698861228904, "cover": 0.526975319156, "own": 0.492585232263, "sake": 2.9929646280599997, "natur": 0.431306339292, "who": 0.1827006989577, "decid": 0.655322871893, "women": 0.8404139079, "bigger": 2.58248697813, "post": 1.6114003054019999, "here": 0.8850381883700001, "obama": 2.67588232573, "report": 0.31001750903700004, "viacan": 7.369978720910001, "blog": 2.65237310559, "onlin": 0.957503854357, "layer": 2.0969791623500003, "queri": 4.03065674296, "greater": 0.764545491118, "care": 0.9139943029109999, "about": 0.37706086484760004, "biggest": 1.6671967465900002, "epoch": 10.940093520240001, "job": 1.1798682540899998, "neural": 4.0853151555, "mind": 1.2786688388299998, "have": 0.07392501170600001, "just": 0.289531434109, "tweet": 49.839902831399996, "unit": 0.143188061817, "simpli": 0.923941491586, "crowd": 1.68639895357, "expens": 1.26563201674, "dumber": 6.58152136054, "train": 6.609183128390001, "newcom": 3.31472154739, "complex": 0.8502416364309999, "start": 0.472886738582, "barrier": 2.1594002686700002, "love": 1.08958288195, "them": 0.0941833269093, "democrat": 1.41621604098, "bad": 2.4443033123599998, "wedd": 7.369978720910001, "support": 0.475761220074, "inclus": 2.16982560315, "learn": 3.37100825898, "mani": 0.1732630324884, "the": 0.0, "theoret": 2.05874512909, "generat": 10.787735126040001, "build": 0.982274904182, "creativ": 1.87527254036, "seem": 2.487279096828, "pretrain": 7.369978720910001, "select": 0.704804687133, "trumptweetstxt": 14.739957441820001, "same": 0.112059649604, "rnns": 14.739957441820001, "there": 0.160391571702, "govseptorald": 7.369978720910001, "least": 1.440856754235, "maryland": 2.5124946063099998, "best": 1.836911731788, "jun": 3.4639737878099996, "interview": 1.2232212893899999, "introductori": 3.41107212958, "hous": 0.38009061238799996, "take": 0.130691962197, "follow": 0.045356911094199995, "now": 0.298185890042, "further": 0.308815895297, "code": 1.35601909597, "hello": 3.7948280321199994, "than": 0.0322608622182, "self": 2.48264164316, "realli": 1.5576408397, "abil": 0.996488297427, "also": 0.0586286312, "person": 0.34018281601800004, "mean": 0.37092128352, "acceler": 2.0985188085299997, "materi": 1.5123837980419998, "white": 0.625566240123, "major": 0.276949326878, "associ": 0.28240501535100004, "may": 0.050709995284400004, "mayo": 3.90737271112, "clinton": 2.60183970664, "peopl": 3.478780412514, "open": 0.219591038029, "polit": 1.140285568292, "those": 0.35709878174599996, "want": 2.7665464250199996, "vein": 3.1940541716900004, "grate": 3.3216780971900004, "outofthebox": 7.369978720910001, "share": 0.618760299747, "elimin": 1.30201620283, "archiv": 1.20750637691, "minut": 1.1353719359799999, "plug": 3.41107212958, "debat": 1.1723133432200001, "which": 0.03107048307258, "buzzfe": 7.033506484289999, "other": 0.01974949583952, "one": 0.0187660549365, "show": 0.236682766013, "fast": 1.5836950247400001, "custom": 1.2905032964799998, "begin": 0.285584668268, "see": 1.20460792746, "get": 2.319076023128, "like": 0.139053576545, "implement": 1.27437940907, "file": 2.65469177446, "process": 0.527829199025, "both": 0.10168506677860001, "that": 0.059642225694599996, "includ": 0.0188846813905, "sign": 1.131393700806, "celebr": 0.9092920998899999, "leadership": 1.3954060414700002, "kera": 6.72812483474, "textgenrnn": 88.43974465092, "this": 0.0189322452625, "pretti": 2.75684036527, "sampl": 3.9572529767800004, "rang": 1.158638427606, "time": 0.0448460754504, "engin": 0.904767558276, "grab": 6.21459768774, "bit": 4.24065305268, "bill": 2.0539548154400005, "project": 2.246407543628, "will": 1.2167192094900001, "been": 0.04729196473680001, "puppet": 2.97306347374, "forget": 2.8330873756700004, "most": 0.020747896295599998, "forev": 2.48793466119, "attentionweight": 7.369978720910001, "uncompl": 5.61212080336, "obvious": 1.86383450716, "along": 0.260344385917, "all": 0.057013160488999994, "charact": 1.846296814478, "reason": 0.544301552962, "strong": 0.49712549393600003, "former": 0.308301359655, "metadata": 5.35507570037, "day": 0.16865870631700003, "sort": 3.29278723792, "foxandfriend": 7.369978720910001, "architectur": 3.26939515838, "built": 0.690379535065, "thank": 8.964469496500001, "object": 0.853933584803, "more": 0.11917452119999998, "hotel": 1.62122288061, "again": 0.411340231612, "while": 0.04324998379380001, "indepth": 7.369978720910001, "numennumpnumc": 7.369978720910001, "greatest": 1.10107184908, "could": 0.18595627229000003, "befor": 0.191275543759, "librari": 0.986809980943, "parti": 1.448995420888, "state": 0.0932200055336, "download": 2.6841506319, "serv": 0.383135035608, "can": 1.298728771152, "make": 0.07349765782289999, "asid": 1.90191857977, "way": 0.39618301987000004, "write": 0.721512439877, "onli": 0.050648536658199995, "size": 1.8276744121219999, "few": 0.275577913653, "hampshir": 2.90752483712, "read": 0.83939268088, "underach": 7.369978720910001, "data": 6.084102924, "qualiti": 1.07600506711, "perfect": 1.50096433356, "crisi": 1.4465253844200001, "abstract": 2.29918950399, "numpm": 4.33022956194, "text": 12.545302109889999, "send": 1.32189757338, "import": 0.585636554132, "has": 0.0427239448548, "skipembed": 7.369978720910001, "leav": 0.507743957229, "date": 0.489080896097, "subcent": 7.369978720910001, "republican": 3.7018413753199995, "easili": 2.6133174734, "down": 0.306673741186, "newmodeltru": 7.369978720910001, "mention": 0.931747186336, "worthwhil": 4.45762805629}, "logidf": {"after": 0.020490694648099998, "hand": 0.479471335336, "real": 0.824629060574, "matthew": 1.9327693554900003, "hyperparamet": 7.369978720910001, "donald": 1.95967285241, "then": 0.08303386523089999, "too": 0.5965551547219999, "relat": 0.21310030165399999, "play": 0.38110439064199997, "form": 0.120053184191, "repo": 5.91136369821, "kind": 0.948031302717, "space": 0.874713164972, "numth": 0.161378382949, "dirti": 2.90407060225, "june": 0.3605697882, "number": 0.0966085784186, "taster": 6.7821920560099995, "dataset": 5.26584456664, "function": 0.914465741594, "int": 4.44681714019, "undertak": 2.37954613413, "well": 0.0635144383156, "join": 0.58348752942, "tri": 0.61759152916, "terribl": 2.67771382807, "convinc": 1.4827641951700001, "water": 0.756862994946, "technic": 1.14423287808, "url": 3.72976443878, "higher": 0.752308398995, "motiv": 1.61265547932, "legal": 0.955536640608, "chose": 1.48637781968, "tonight": 3.1788099740499995, "particular": 0.323157393804, "creat": 0.222576818514, "enjoy": 1.2020430306899998, "woolf": 4.49078026361, "how": 0.47156695693000006, "test": 0.977224437103, "news": 0.733245073485, "good": 0.418589404907, "especi": 0.511098609709, "would": 0.0796176279647, "mayb": 3.0471714458899997, "given": 0.303255810831, "word": 0.585861082385, "interest": 0.47207177798199995, "beginn": 3.9788316751, "conserv": 1.19994966588, "consid": 0.214894723824, "site": 0.6791364434899999, "lou": 3.06456318861, "textgener": 7.369978720910001, "safeti": 1.48693492276, "improv": 0.7147958039319999, "textgen": 7.369978720910001, "next": 0.402163685499, "perform": 0.42618085058, "but": 0.0161923720719, "inherit": 1.87076341199, "were": 0.024291143681099997, "need": 0.362740163442, "our": 0.8576392141820001, "longer": 0.7046772417749999, "final": 0.292733863948, "tune": 2.3434700776599997, "point": 0.23103235903299998, "record": 0.353010356953, "jan": 2.11822899018, "level": 0.503462189943, "dig": 2.91795971441, "success": 0.27765441259199997, "fun": 2.5561696698099996, "spaci": 7.369978720910001, "tensorflow": 7.369978720910001, "listen": 1.94282848252, "use": 0.0292080197316, "default": 3.0511581621399997, "painless": 5.52942908751, "out": 0.0584263909193, "model": 0.7374500731110001, "jebbush": 7.369978720910001, "trumpnum": 7.369978720910001, "much": 0.17749572930100002, "cours": 0.765899404133, "absolut": 1.67658333914, "daunt": 4.62913869698, "not": 0.0155524130075, "someth": 1.18830712273, "countri": 0.34630881733, "less": 0.3846144626, "solut": 1.55346297627, "happen": 1.08640441802, "quick": 0.790727508899, "true": 0.938325629634, "appropri": 1.4618957827399999, "though": 0.308044191079, "problem": 0.569140724273, "compani": 0.439777253097, "allow": 0.24028061118900002, "world": 0.107420248621, "kdnugget": 7.369978720910001, "github": 7.369978720910001, "construct": 0.658603355972, "hilitem": 7.369978720910001, "featur": 0.423387418142, "carolina": 2.0214436382, "practic": 0.533182530867, "author": 0.35274143130999996, "block": 1.16400781588, "twitter": 3.50295308141, "overlook": 2.43406697301, "softwar": 2.32849096333, "got": 1.2863908849299999, "such": 0.059695977806, "succeed": 1.2104605888, "meet": 0.510363817255, "network": 0.9530830530519999, "politician": 1.55256998618, "lot": 1.4835969502500002, "some": 0.0395735090645, "should": 0.509419876758, "add": 1.52875583713, "call": 0.0654627744488, "confid": 1.8449242675400002, "press": 0.345329690455, "bee": 3.22209339176, "rate": 0.761033872166, "languag": 0.8306818244059999, "media": 0.9530830530519999, "wait": 1.51605358782, "ani": 0.125608358366, "and": 6.29901420636e-05, "from": 0.000567054168866, "temperatur": 1.6966554537399998, "work": 0.109034567273, "num": 0.00031499039539700004, "inaugur": 1.85413354183, "turnberri": 7.033506484289999, "mere": 1.43561376584, "freedom": 1.2485830042100001, "yesterday": 3.50295308141, "acquir": 1.1332178178499999, "for": 0.00031499039539700004, "american": 0.274914343622, "with": 0.00119749171339, "requir": 0.424253510675, "new": 0.0177299468511, "these": 0.0715336194008, "are": 0.0294674735827, "south": 0.43548414473700003, "max": 2.01150743154, "better": 0.6964279406, "calker": 7.369978720910001, "effort": 0.637887211057, "sens": 1.04257779501, "preprocess": 7.1076144564399995, "look": 0.6463866936, "statement": 1.2303097091500002, "trumptowerni": 7.369978720910001, "veri": 0.230159793238, "fake": 2.9063720992400004, "welltun": 7.369978720910001, "whatev": 2.0343655696200003, "thebrodyfil": 7.369978720910001, "bidirect": 5.66523062867, "complain": 2.1161358444599996, "focus": 0.6981989720559999, "iter": 3.62283035867, "foxnew": 7.369978720910001, "disast": 1.8847669357199999, "bail": 3.50924900987, "top": 0.609100637788, "vote": 1.09899028905, "place": 0.0957070839572, "great": 0.235805258079, "legibl": 5.40988393686, "scratch": 3.2509415461, "his": 0.0901772433641, "big": 1.00798563557, "comment": 1.11826753454, "honor": 1.26050894061, "heart": 1.09974671874, "thing": 0.8781935346799999, "presid": 0.6852420010529999, "scientist": 1.54634128444, "machin": 1.39235958062, "into": 0.0149128632287, "appl": 2.61725097056, "sinc": 0.0803681994577, "servic": 0.41410016674500005, "presidenti": 1.84452578178, "where": 0.0649921387457, "canon": 2.38158903576, "rout": 1.15117941787, "what": 0.225887296827, "let": 1.2488025672799998, "save": 1.03598886547, "against": 0.254802851078, "clear": 0.617474727198, "find": 0.547781330288, "trump": 4.12738636942, "line": 0.349430614452, "cover": 0.526975319156, "own": 0.164195077421, "sake": 2.9929646280599997, "natur": 0.431306339292, "who": 0.0609002329859, "decid": 0.655322871893, "women": 0.8404139079, "bigger": 2.58248697813, "post": 0.8057001527009999, "here": 0.8850381883700001, "obama": 2.67588232573, "report": 0.31001750903700004, "viacan": 7.369978720910001, "blog": 2.65237310559, "onlin": 0.957503854357, "layer": 2.0969791623500003, "queri": 4.03065674296, "greater": 0.764545491118, "care": 0.9139943029109999, "about": 0.0628434774746, "biggest": 1.6671967465900002, "epoch": 3.6466978400800003, "job": 1.1798682540899998, "neural": 4.0853151555, "mind": 1.2786688388299998, "have": 0.0147850023412, "just": 0.289531434109, "tweet": 4.5309002574, "unit": 0.143188061817, "simpli": 0.923941491586, "crowd": 1.68639895357, "expens": 1.26563201674, "dumber": 6.58152136054, "train": 0.660918312839, "newcom": 3.31472154739, "complex": 0.8502416364309999, "start": 0.236443369291, "barrier": 2.1594002686700002, "love": 1.08958288195, "them": 0.0941833269093, "democrat": 1.41621604098, "bad": 1.2221516561799999, "wedd": 7.369978720910001, "support": 0.237880610037, "inclus": 2.16982560315, "learn": 0.842752064745, "mani": 0.0433157581221, "the": 0.0, "theoret": 2.05874512909, "generat": 0.719182341736, "build": 0.491137452091, "creativ": 1.87527254036, "seem": 0.829093032276, "pretrain": 7.369978720910001, "select": 0.704804687133, "trumptweetstxt": 7.369978720910001, "same": 0.112059649604, "rnns": 7.369978720910001, "there": 0.0400978929255, "govseptorald": 7.369978720910001, "least": 0.480285584745, "maryland": 2.5124946063099998, "best": 0.459227932947, "jun": 3.4639737878099996, "interview": 1.2232212893899999, "introductori": 3.41107212958, "hous": 0.38009061238799996, "take": 0.130691962197, "follow": 0.045356911094199995, "now": 0.149092945021, "further": 0.308815895297, "code": 1.35601909597, "hello": 3.7948280321199994, "than": 0.0322608622182, "self": 2.48264164316, "realli": 1.5576408397, "abil": 0.996488297427, "also": 0.0146571578, "person": 0.34018281601800004, "mean": 0.37092128352, "acceler": 2.0985188085299997, "materi": 0.7561918990209999, "white": 0.625566240123, "major": 0.138474663439, "associ": 0.28240501535100004, "may": 0.050709995284400004, "mayo": 3.90737271112, "clinton": 2.60183970664, "peopl": 0.193265578473, "open": 0.219591038029, "polit": 0.570142784146, "those": 0.17854939087299998, "want": 0.6916366062549999, "vein": 3.1940541716900004, "grate": 3.3216780971900004, "outofthebox": 7.369978720910001, "share": 0.618760299747, "elimin": 1.30201620283, "archiv": 1.20750637691, "minut": 1.1353719359799999, "plug": 3.41107212958, "debat": 1.1723133432200001, "which": 0.00517841384543, "buzzfe": 7.033506484289999, "other": 0.00987474791976, "one": 0.0062553516455, "show": 0.236682766013, "fast": 1.5836950247400001, "custom": 1.2905032964799998, "begin": 0.285584668268, "see": 0.240921585492, "get": 0.579769005782, "like": 0.139053576545, "implement": 1.27437940907, "file": 1.32734588723, "process": 0.527829199025, "both": 0.050842533389300004, "that": 0.00397614837964, "includ": 0.0188846813905, "sign": 0.565696850403, "celebr": 0.9092920998899999, "leadership": 1.3954060414700002, "kera": 6.72812483474, "textgenrnn": 7.369978720910001, "this": 0.0037864490525, "pretti": 2.75684036527, "sampl": 1.9786264883900002, "rang": 0.579319213803, "time": 0.0112115188626, "engin": 0.904767558276, "grab": 3.10729884387, "bit": 2.12032652634, "bill": 1.0269774077200002, "project": 0.561601885907, "will": 0.202786534915, "been": 0.023645982368400004, "puppet": 2.97306347374, "forget": 2.8330873756700004, "most": 0.020747896295599998, "forev": 2.48793466119, "attentionweight": 7.369978720910001, "uncompl": 5.61212080336, "obvious": 1.86383450716, "along": 0.260344385917, "all": 0.011402632097799998, "charact": 0.923148407239, "reason": 0.544301552962, "strong": 0.49712549393600003, "former": 0.308301359655, "metadata": 5.35507570037, "day": 0.16865870631700003, "sort": 1.64639361896, "foxandfriend": 7.369978720910001, "architectur": 1.63469757919, "built": 0.690379535065, "thank": 1.7928938993, "object": 0.853933584803, "more": 0.017024931599999998, "hotel": 1.62122288061, "again": 0.411340231612, "while": 0.04324998379380001, "indepth": 7.369978720910001, "numennumpnumc": 7.369978720910001, "greatest": 1.10107184908, "could": 0.18595627229000003, "befor": 0.0956377718795, "librari": 0.986809980943, "parti": 0.724497710444, "state": 0.0466100027668, "download": 2.6841506319, "serv": 0.383135035608, "can": 0.162341096394, "make": 0.07349765782289999, "asid": 1.90191857977, "way": 0.19809150993500002, "write": 0.721512439877, "onli": 0.025324268329099998, "size": 0.9138372060609999, "few": 0.275577913653, "hampshir": 2.90752483712, "read": 0.83939268088, "underach": 7.369978720910001, "data": 1.2168205848, "qualiti": 1.07600506711, "perfect": 1.50096433356, "crisi": 1.4465253844200001, "abstract": 2.29918950399, "numpm": 4.33022956194, "text": 1.14048200999, "send": 1.32189757338, "import": 0.292818277066, "has": 0.0427239448548, "skipembed": 7.369978720910001, "leav": 0.507743957229, "date": 0.489080896097, "subcent": 7.369978720910001, "republican": 1.8509206876599997, "easili": 1.3066587367, "down": 0.306673741186, "newmodeltru": 7.369978720910001, "mention": 0.931747186336, "worthwhil": 4.45762805629}, "freq": {"after": 2, "hand": 1, "real": 1, "matthew": 1, "hyperparamet": 2, "donald": 1, "then": 1, "too": 1, "relat": 1, "play": 1, "form": 1, "repo": 2, "kind": 1, "space": 1, "numth": 1, "dirti": 1, "june": 1, "number": 2, "taster": 1, "dataset": 1, "function": 1, "int": 1, "undertak": 1, "well": 3, "join": 1, "tri": 2, "terribl": 1, "convinc": 1, "water": 1, "technic": 1, "url": 1, "higher": 1, "motiv": 1, "legal": 1, "chose": 1, "tonight": 2, "particular": 1, "creat": 1, "enjoy": 2, "woolf": 1, "how": 5, "test": 1, "news": 4, "good": 2, "especi": 1, "would": 1, "mayb": 1, "given": 1, "word": 1, "interest": 1, "beginn": 1, "conserv": 1, "consid": 2, "site": 1, "lou": 1, "textgener": 1, "safeti": 1, "improv": 1, "textgen": 5, "next": 1, "perform": 2, "but": 2, "inherit": 1, "were": 1, "need": 1, "our": 1, "longer": 1, "final": 1, "tune": 3, "point": 1, "record": 1, "jan": 1, "level": 3, "dig": 1, "success": 1, "fun": 2, "spaci": 1, "tensorflow": 1, "listen": 1, "use": 9, "default": 4, "painless": 1, "out": 3, "model": 8, "jebbush": 1, "trumpnum": 2, "much": 2, "cours": 1, "absolut": 1, "daunt": 1, "not": 3, "someth": 2, "countri": 1, "less": 1, "solut": 1, "happen": 1, "quick": 1, "true": 1, "appropri": 1, "though": 1, "problem": 2, "compani": 1, "allow": 2, "world": 4, "kdnugget": 1, "github": 2, "construct": 1, "hilitem": 3, "featur": 1, "carolina": 1, "practic": 1, "author": 1, "block": 1, "twitter": 1, "overlook": 1, "softwar": 1, "got": 1, "such": 1, "succeed": 1, "meet": 1, "network": 2, "politician": 1, "lot": 1, "some": 5, "should": 2, "add": 1, "call": 1, "confid": 1, "press": 1, "bee": 1, "rate": 1, "languag": 1, "media": 7, "wait": 1, "ani": 5, "and": 42, "from": 7, "temperatur": 1, "work": 2, "num": 13, "inaugur": 1, "turnberri": 1, "mere": 1, "freedom": 1, "yesterday": 1, "acquir": 1, "for": 15, "american": 1, "with": 11, "requir": 1, "new": 3, "these": 4, "are": 11, "south": 1, "max": 1, "better": 1, "calker": 1, "effort": 1, "sens": 1, "preprocess": 1, "look": 1, "statement": 6, "trumptowerni": 1, "veri": 2, "fake": 4, "welltun": 1, "whatev": 1, "thebrodyfil": 1, "bidirect": 1, "complain": 1, "focus": 1, "iter": 1, "foxnew": 1, "disast": 1, "bail": 1, "top": 1, "vote": 1, "place": 1, "great": 12, "legibl": 1, "scratch": 1, "his": 3, "big": 2, "comment": 1, "honor": 1, "heart": 1, "thing": 5, "presid": 6, "scientist": 2, "machin": 2, "into": 2, "appl": 1, "sinc": 3, "servic": 1, "presidenti": 1, "where": 1, "canon": 1, "rout": 1, "what": 5, "let": 5, "save": 1, "against": 1, "clear": 1, "find": 1, "trump": 4, "line": 2, "cover": 1, "own": 3, "sake": 1, "natur": 1, "who": 3, "decid": 1, "women": 1, "bigger": 1, "post": 2, "here": 1, "obama": 1, "report": 1, "viacan": 1, "blog": 1, "onlin": 1, "layer": 1, "queri": 1, "greater": 1, "care": 1, "about": 6, "biggest": 1, "epoch": 3, "job": 1, "neural": 1, "mind": 1, "have": 5, "just": 1, "tweet": 11, "unit": 1, "simpli": 1, "crowd": 1, "expens": 1, "dumber": 1, "train": 10, "newcom": 1, "complex": 1, "start": 2, "barrier": 1, "love": 1, "them": 1, "democrat": 1, "bad": 2, "wedd": 1, "support": 2, "inclus": 1, "learn": 4, "mani": 4, "the": 94, "theoret": 1, "generat": 15, "build": 2, "creativ": 1, "seem": 3, "pretrain": 1, "select": 1, "trumptweetstxt": 2, "same": 1, "rnns": 2, "there": 4, "govseptorald": 1, "least": 3, "maryland": 1, "best": 4, "jun": 1, "interview": 1, "introductori": 1, "hous": 1, "take": 1, "follow": 1, "now": 2, "further": 1, "code": 1, "hello": 1, "than": 1, "self": 1, "realli": 1, "abil": 1, "also": 4, "person": 1, "mean": 1, "acceler": 1, "materi": 2, "white": 1, "major": 2, "associ": 1, "may": 1, "mayo": 1, "clinton": 1, "peopl": 18, "open": 1, "polit": 2, "those": 2, "want": 4, "vein": 1, "grate": 1, "outofthebox": 1, "share": 1, "elimin": 1, "archiv": 1, "minut": 1, "plug": 1, "debat": 1, "which": 6, "buzzfe": 1, "other": 2, "one": 3, "show": 1, "fast": 1, "custom": 1, "begin": 1, "see": 5, "get": 4, "like": 1, "implement": 1, "file": 2, "process": 1, "both": 2, "that": 15, "includ": 1, "sign": 2, "celebr": 1, "leadership": 1, "kera": 1, "textgenrnn": 12, "this": 5, "pretti": 1, "sampl": 2, "rang": 2, "time": 4, "engin": 1, "grab": 2, "bit": 2, "bill": 2, "project": 4, "will": 6, "been": 2, "puppet": 1, "forget": 1, "most": 1, "forev": 1, "attentionweight": 1, "uncompl": 1, "obvious": 1, "along": 1, "all": 5, "charact": 2, "reason": 1, "strong": 1, "former": 1, "metadata": 1, "day": 1, "sort": 2, "foxandfriend": 1, "architectur": 2, "built": 1, "thank": 5, "object": 1, "more": 7, "hotel": 1, "again": 1, "while": 1, "indepth": 1, "numennumpnumc": 1, "greatest": 1, "could": 1, "befor": 2, "librari": 1, "parti": 2, "state": 2, "download": 1, "serv": 1, "can": 8, "make": 1, "asid": 1, "way": 2, "write": 1, "onli": 2, "size": 2, "few": 1, "hampshir": 1, "read": 1, "underach": 1, "data": 5, "qualiti": 1, "perfect": 1, "crisi": 1, "abstract": 1, "numpm": 1, "text": 11, "send": 1, "import": 2, "has": 1, "skipembed": 1, "leav": 1, "date": 1, "subcent": 1, "republican": 2, "easili": 2, "down": 1, "newmodeltru": 1, "mention": 1, "worthwhil": 1}, "idf": {"after": 1.02070207021, "hand": 1.6152202665600002, "real": 2.28103448276, "matthew": 6.908616187989999, "hyperparamet": 1587.6, "donald": 7.0970049173000005, "then": 1.08657860516, "too": 1.81585268215, "relat": 1.23750876919, "play": 1.46390041494, "form": 1.12755681818, "repo": 369.209302326, "kind": 2.5806241872599998, "space": 2.39818731118, "numth": 1.1751295336799998, "dirti": 18.2482758621, "june": 1.43414634146, "number": 1.10142916609, "taster": 882.0, "dataset": 193.609756098, "function": 2.495441685, "int": 85.3548387097, "undertak": 10.8, "well": 1.0655748708, "join": 1.7922781666299998, "tri": 1.8544562551099997, "terribl": 14.5517873511, "convinc": 4.4051054384, "water": 2.13157894737, "technic": 3.1400316455699997, "url": 41.669291338600004, "higher": 2.1218925421, "motiv": 5.01611374408, "legal": 2.6000655093400002, "chose": 4.42105263158, "tonight": 24.0181543116, "particular": 1.3814827706200001, "creat": 1.2492917847, "enjoy": 3.3269069572500003, "woolf": 89.19101123600001, "how": 1.60250328051, "test": 2.65707112971, "news": 2.08182533438, "good": 1.51981619759, "especi": 1.66712170534, "would": 1.0828729281799998, "mayb": 21.0557029178, "given": 1.35426085473, "word": 1.7965372864099998, "interest": 1.60331246213, "beginn": 53.4545454545, "conserv": 3.3199498117900004, "consid": 1.2397313759200002, "site": 1.9721739130400002, "lou": 21.4251012146, "textgener": 1587.6, "safeti": 4.4235162998, "improv": 2.04376930999, "textgen": 1587.6, "next": 1.4950560316400001, "perform": 1.5313977042500002, "but": 1.01632417899, "inherit": 6.4932515337400005, "were": 1.02458857696, "need": 1.4372623574099999, "our": 2.35758835759, "longer": 2.02319357716, "final": 1.34008609775, "tune": 10.4173228346, "point": 1.25990000794, "record": 1.42334588488, "jan": 8.31639601886, "level": 1.6544393497299998, "dig": 18.5034965035, "success": 1.32002993265, "fun": 12.8863636364, "spaci": 1587.6, "tensorflow": 1587.6, "listen": 6.97846153846, "use": 1.0296387573799999, "default": 21.1398135819, "painless": 252.0, "out": 1.06016694491, "model": 2.0905978404, "jebbush": 1587.6, "trumpnum": 1587.6, "much": 1.1942229577299999, "cours": 2.15092805853, "absolut": 5.3472549680000006, "daunt": 102.425806452, "not": 1.01567398119, "someth": 3.28152128979, "countri": 1.4138391664399999, "less": 1.46904783936, "solut": 4.7278141751, "happen": 2.96359902931, "quick": 2.205, "true": 2.55569864778, "appropri": 4.31413043478, "though": 1.36076112111, "problem": 1.76674827509, "compani": 1.5523613963, "allow": 1.2716059271100002, "world": 1.11340206186, "kdnugget": 1587.6, "github": 1587.6, "construct": 1.9320920043799998, "hilitem": 1587.6, "featur": 1.52712581762, "carolina": 7.54921540656, "practic": 1.70434782609, "author": 1.4229631621399998, "block": 3.20274359492, "twitter": 33.213389121300004, "overlook": 11.4051724138, "softwar": 10.2624434389, "got": 3.61969904241, "such": 1.06151377374, "succeed": 3.3550295857999997, "meet": 1.6658971668399998, "network": 2.59369384088, "politician": 4.7235941684, "lot": 4.40877534018, "some": 1.04036697248, "should": 1.6643254009900001, "add": 4.61243463103, "call": 1.0676529926, "confid": 6.327620565959999, "press": 1.41245551601, "bee": 25.0805687204, "rate": 2.14048806795, "languag": 2.29488291414, "media": 2.59369384088, "wait": 4.55421686747, "ani": 1.13383802314, "and": 1.00006299213, "from": 1.00056721497, "temperatur": 5.45567010309, "work": 1.11520089913, "num": 1.00031504001, "inaugur": 6.38616251006, "turnberri": 1134.0, "mere": 4.20222339862, "freedom": 3.4854006586199997, "yesterday": 33.213389121300004, "acquir": 3.10563380282, "for": 1.00031504001, "american": 1.31641791045, "with": 1.0011982089899998, "requir": 1.52844902282, "new": 1.0178880554, "these": 1.07415426252, "are": 1.02990593578, "south": 1.5457112257799999, "max": 7.474576271189999, "better": 2.0065722952500002, "calker": 1587.6, "effort": 1.89247824532, "sens": 2.8365195640499996, "preprocess": 1221.23076923, "look": 1.9086318826599997, "statement": 3.42228928648, "trumptowerni": 1587.6, "veri": 1.25880114177, "fake": 18.290322580599998, "welltun": 1587.6, "whatev": 7.6473988439300005, "thebrodyfil": 1587.6, "bidirect": 288.654545455, "complain": 8.299006795610001, "focus": 2.01012914662, "iter": 37.4433962264, "foxnew": 1587.6, "disast": 6.58481957694, "bail": 33.4231578947, "top": 1.8387769284200002, "vote": 3.0011342155, "place": 1.1004366812200002, "great": 1.26592775696, "legibl": 223.605633803, "scratch": 25.8146341463, "his": 1.0943682360200002, "big": 2.7400759406299997, "comment": 3.05954904606, "honor": 3.5272161741800003, "heart": 3.00340522134, "thing": 2.4065484311099996, "presid": 1.9842519685, "scientist": 4.69426374926, "machin": 4.02433460076, "into": 1.01502461479, "appl": 13.6980155306, "sinc": 1.08368600683, "servic": 1.51300867245, "presidenti": 6.325099601590001, "where": 1.06715063521, "canon": 10.8220858896, "rout": 3.1619199362700003, "what": 1.25343439128, "let": 3.48616600791, "save": 2.8178913737999998, "against": 1.2902072328299998, "clear": 1.85423966363, "find": 1.7294117647099998, "trump": 62.015625, "line": 1.4182597820299998, "cover": 1.69380134429, "own": 1.17844418052, "sake": 19.9447236181, "natur": 1.5392670157100001, "who": 1.06279287723, "decid": 1.9257641921400002, "women": 2.31732593782, "bigger": 13.23, "post": 2.23826307627, "here": 2.42307692308, "obama": 14.5251601098, "report": 1.3634489866, "viacan": 1587.6, "blog": 14.1876675603, "onlin": 2.6051854282900004, "layer": 8.14153846154, "queri": 56.2978723404, "greater": 2.14801785956, "care": 2.49426551453, "about": 1.06486015159, "biggest": 5.2972972973, "epoch": 38.347826087, "job": 3.2539454806299997, "neural": 59.4606741573, "mind": 3.5918552036199998, "have": 1.0148948411399998, "just": 1.33580143037, "tweet": 92.8421052632, "unit": 1.15394679459, "simpli": 2.5192002538900002, "crowd": 5.4, "expens": 3.5453327378300004, "dumber": 721.636363636, "train": 1.9365698950999999, "newcom": 27.5147313692, "complex": 2.34021226415, "start": 1.26673581744, "barrier": 8.66593886463, "love": 2.97303370787, "them": 1.09876115994, "democrat": 4.1214953271, "bad": 3.3944836433599996, "wedd": 1587.6, "support": 1.2685577307200002, "inclus": 8.756756756760002, "learn": 2.32275054865, "mani": 1.04426757877, "the": 1.0, "theoret": 7.83613030602, "generat": 2.05275407292, "build": 1.6341739578, "creativ": 6.52259654889, "seem": 2.29123971713, "pretrain": 1587.6, "select": 2.02345144022, "trumptweetstxt": 1587.6, "same": 1.11857958148, "rnns": 1587.6, "there": 1.04091266719, "govseptorald": 1587.6, "least": 1.6165359943000002, "maryland": 12.335664335699999, "best": 1.5828514456600002, "jun": 31.943661971799997, "interview": 3.3981164383599998, "introductori": 30.297709923699998, "hous": 1.4624170965399999, "take": 1.13961668222, "follow": 1.04640126549, "now": 1.160780873, "further": 1.3618116315, "code": 3.8807137619199996, "hello": 44.4705882353, "than": 1.03278688525, "self": 11.972850678699999, "realli": 4.7476076555, "abil": 2.70875277256, "also": 1.01476510067, "person": 1.40520446097, "mean": 1.44906900329, "acceler": 8.15408320493, "materi": 2.13014893332, "white": 1.86930413282, "major": 1.14852058164, "associ": 1.3263157894700002, "may": 1.05201775893, "mayo": 49.7680250784, "clinton": 13.488530161400002, "peopl": 1.21320495186, "open": 1.24556723678, "polit": 1.76851954996, "those": 1.19548192771, "want": 1.99698113208, "vein": 24.3870967742, "grate": 27.7068062827, "outofthebox": 1587.6, "share": 1.8566249561500001, "elimin": 3.67670217693, "archiv": 3.3451327433599998, "minut": 3.11233091551, "plug": 30.297709923699998, "debat": 3.2294548413300004, "which": 1.005191845, "buzzfe": 1134.0, "other": 1.00992366412, "one": 1.00627495722, "show": 1.26703910615, "fast": 4.8729281768, "custom": 3.6346153846199996, "begin": 1.3305397251100002, "see": 1.27242125511, "get": 1.78562591385, "like": 1.14918566775, "implement": 3.57648118946, "file": 3.7710213776699995, "process": 1.69524826482, "both": 1.05215720061, "that": 1.00398406375, "includ": 1.0190641247799999, "sign": 1.7606742819099999, "celebr": 2.48256450352, "leadership": 4.03661327231, "kera": 835.5789473680001, "textgenrnn": 1587.6, "this": 1.00379362671, "pretti": 15.75, "sampl": 7.23280182232, "rang": 1.7848229342299997, "time": 1.01127460348, "engin": 2.47135740971, "grab": 22.3605633803, "bit": 8.33385826772, "bill": 2.7926121372000003, "project": 1.7534791252500002, "will": 1.22481098596, "been": 1.0239277652399998, "puppet": 19.5517241379, "forget": 16.9978586724, "most": 1.02096463023, "forev": 12.0363912055, "attentionweight": 1587.6, "uncompl": 273.724137931, "obvious": 6.44841592201, "along": 1.2973768080399999, "all": 1.01146788991, "charact": 2.51720310766, "reason": 1.72340425532, "strong": 1.6439888163999998, "former": 1.36111111111, "metadata": 211.68, "day": 1.18371607516, "sort": 5.188235294119999, "foxandfriend": 1587.6, "architectur": 5.12790697674, "built": 1.99447236181, "thank": 6.00681044268, "object": 2.3488681757700003, "more": 1.0171706817, "hotel": 5.05927342256, "again": 1.50883862384, "while": 1.0441988950299999, "indepth": 1587.6, "numennumpnumc": 1587.6, "greatest": 3.00738776283, "could": 1.2043695949, "befor": 1.10036041031, "librari": 2.68266306185, "parti": 2.06369426752, "state": 1.0477133240899998, "download": 14.6457564576, "serv": 1.4668760972, "can": 1.17626139142, "make": 1.0762660158600001, "asid": 6.69873417722, "way": 1.2190739461, "write": 2.0575427682700003, "onli": 1.0256476516600002, "size": 2.49387370405, "few": 1.31729173581, "hampshir": 18.3114186851, "read": 2.3149606299200003, "underach": 1587.6, "data": 3.37643555934, "qualiti": 2.9329392204, "perfect": 4.48601299802, "crisi": 4.24832753546, "abstract": 9.966101694919999, "numpm": 75.961722488, "text": 3.12827586207, "send": 3.75053153792, "import": 1.3401992233700002, "has": 1.0436497502, "skipembed": 1587.6, "leav": 1.6615384615399997, "date": 1.63081664099, "subcent": 1587.6, "republican": 6.3656776263, "easili": 3.6938110749199997, "down": 1.35889754344, "newmodeltru": 1587.6, "mention": 2.53894130817, "worthwhil": 86.28260869569999}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Generating Text with RNNs in 4 Lines of Code</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Generating Text with RNNs in 4 Lines of Code Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/advice-applying-data-science-jobs.html\" rel=\"prev\" title=\"Advice For Applying To Data Science Jobs\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html\" rel=\"next\" title=\"Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=82033\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-82033 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 14-Jun, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/tutorials.html\">Tutorials, Overviews</a> \u00bb Generating Text with RNNs in 4 Lines of Code (\u00a0<a href=\"/2018/n24.html\">18:n24</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"Silver Blog\" src=\"/images/tkb-1806-s.png\" width=\"94\"/>Generating Text with RNNs in 4 Lines of Code</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/06/advice-applying-data-science-jobs.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/donald-trump\" rel=\"tag\">Donald Trump</a>, <a href=\"https://www.kdnuggets.com/tag/lstm\" rel=\"tag\">LSTM</a>, <a href=\"https://www.kdnuggets.com/tag/nlp\" rel=\"tag\">NLP</a>, <a href=\"https://www.kdnuggets.com/tag/python\" rel=\"tag\">Python</a>, <a href=\"https://www.kdnuggets.com/tag/recurrent-neural-networks\" rel=\"tag\">Recurrent Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/twitter\" rel=\"tag\">Twitter</a></div>\n<br/>\n<p class=\"excerpt\">\n     Want to generate text with little trouble, and without building and tuning a neural network yourself? Let's check out a project which allows you to \"easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.\"\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/matt-mayo\" rel=\"author\" title=\"Posts by Matthew Mayo\">Matthew Mayo</a>, KDnuggets.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p>Generating text is one of those projects that seems like a lot of fun to machine learning and NLP beginners, but one which is also pretty daunting. Or, at least it was for me.</p>\n<p>Thankfully, there are all sorts of great materials online for learning how RNNs can be used for generating text, ranging from the theoretical to the technically in-depth to those decidedly focused on the practical. There are also some very good posts which <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\" rel=\"noopener noreferrer\" target=\"_blank\">cover it all</a> and are now considered canon in this space. All of these materials share one thing in particular: at some point along the way, you have to build and tune an RNN to do the work.</p>\n<p>While this is a obviously a worthwhile undertaking, especially for the sake of learning, what if you are OK with a much higher level of abstraction, whatever your reason may be? What if you are a data scientist that requires a building block in the form of an RNN text generator to plug into your project? Or, what if, as a newcomer, you simply want to get your hands a bit -- but not too -- dirty, as a means of testing the water or as motivation to dig down further?</p>\n<p>In that vein, let's take a look at <a href=\"https://github.com/minimaxir/textgenrnn\" rel=\"noopener\" target=\"_blank\">textgenrnn</a>, a project which allows you to \"easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.\" textgenrnn is authored by Max Woolf, an Associate Data Scientist at BuzzFeed, and former Apple Software QA Engineer.</p>\n<p>textgenrnn is a built on top of Keras and TensorFlow, and can be used to generate both character and word level text (character level is the default). The network architecture uses attention-weighting and skip-embedding for accelerated training and improved quality, and allows for the tuning of a number of hyperparameters, such as RNN size, RNN layers, and the inclusion of bidirectional RNNs. You can read more about textgenrnn and its features and architecture at its <a href=\"https://github.com/minimaxir/textgenrnn\" rel=\"noopener\" target=\"_blank\">Github repo</a> or in this <a href=\"http://minimaxir.com/2018/05/text-neural-networks/\" rel=\"noopener\" target=\"_blank\">introductory blog post</a>.</p>\n<p><img alt=\"Image\" class=\"aligncenter\" src=\"/wp-content/uploads/trump-tweets-hdr-02.jpg\" width=\"85%\"/></p>\n<p>Since the \"Hello, World!\" for text generation (at least, in my mind) seems to be generating Trump tweets, let's go with that. textgenrnn's default pretrained model can be trained on new texts easily -- though you can also use textgenrnn to train a new model (just add new_model=True to any of its train functions) -- and since we want to see how quickly we can get generating tweets, let's go that route.</p>\n<p>\u00a0</p>\n<h3>Acquiring the Data</h3>\n<p>\u00a0<br>\nI grabbed a selection of Donald Trump's tweets -- Jan 1, 2014 - Jun 11, 2018 (yesterday, at time of writing), which clearly includes tweets from both before and after his inauguration as President of the United States -- from <a href=\"http://www.trumptwitterarchive.com/archive\" rel=\"noopener\" target=\"_blank\">Trump Twitter Archive</a>, a site which makes querying and downloading tweets from the President painless. I chose only to grab the text from the tweets in that date range, since I don't care about any of the metadata, and saved it to a text file I appropriately called <code>trump-tweets.txt</code>.</br></p>\n<p><a href=\"https://image.ibb.co/mdzied/trump_tweets_archive.jpg\" rel=\"noopener noreferrer\" target=\"_blank\"><img alt=\"Image\" class=\"aligncenter\" src=\"https://image.ibb.co/mdzied/trump_tweets_archive.jpg\" width=\"99%\"/></a></p>\n<p>\u00a0</p>\n<h3>Training the Model</h3>\n<p>\u00a0<br>\nLet's see how uncomplicated it is to generate text with textgenrnn. The following 4 lines are all we need to import the library, create a text generation object, train the model on the <code>trump-tweets.txt</code> file for 10 epochs, and then generate some sample tweets.</br></p>\n<p><!-- HTML generated using hilite.me --></p>\n<div style=\"background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .2em;padding:.8em .6em;\">\n<pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #006699; font-weight: bold\">from</span> <span style=\"color: #00CCFF; font-weight: bold\">textgenrnn</span> <span style=\"color: #006699; font-weight: bold\">import</span> textgenrnn\r\ntextgen <span style=\"color: #555555\">=</span> textgenrnn()\r\ntextgen<span style=\"color: #555555\">.</span>train_from_file(<span style=\"color: #CC3300\">'trump-tweets.txt'</span>, num_epochs<span style=\"color: #555555\">=</span><span style=\"color: #FF6600\">10</span>)\r\ntextgen<span style=\"color: #555555\">.</span>generate(<span style=\"color: #FF6600\">5</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>After about 30 minutes, here's what's generated (on the 10th epoch):</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nMy @FoxNews will be self finally complaining about me that so he is a great day and companies and is starting to report the president in safety and more than any mention of the bail of the underaches to the construction and freedom and efforts the politicians and expensive meetings should have bee\r\n\r\nThe world will be interviewed on @foxandfriends at 7:30pm. Enjoy!\r\n\r\n.@JebBush and Fake News Media is a major place in the White House in the service and sense where the people of the debate and his show of many people who is a great press considering the GREAT job on the way to the U.S. A the best and people in the biggest! Thank you!\r\n\r\nNew Hampshire Trump Int'l Hotel Leadership Barrier Lou Clinton is a forever person politically record supporters have really beginning in the media on the heart of the bad and women who have been succeeded and before you can also work the people are there a time strong and send out the world with \r\n\r\nJoin me in Maryland at 7:00 A.M. and happened to the WALL and be true the longer of the same sign into the Fake News Media will be a great honor to serve that the Republican Party will be a great legal rate the media with the Best Republican Party and the American people that will be the bill by a</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Leaving politics aside, and given that we are only using ~12K tweets for training in a mere 10 epochs, these generated tweets are not... terrible. Want to play with <a href=\"https://www.quora.com/What-is-Temperature-in-LSTM\" rel=\"noopener\" target=\"_blank\">temperature</a> (the textgenrnn default is 0.5) to get some more creative tweets? Let's try it out:</p>\n<p><!-- HTML generated using hilite.me --></p>\n<div style=\"background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .2em;padding:.8em .6em;\">\n<pre style=\"margin: 0; line-height: 125%\">textgen<span style=\"color: #555555\">.</span>generate(<span style=\"color: #FF6600\">5</span>, temperature<span style=\"color: #555555\">=</span><span style=\"color: #FF6600\">0.9</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\n\u201cVia-can see this Democrats were the opening at GREAT ENSUS CALL!\r\n\r\n.@GovSeptorald Taster is got to that the subcent Vote waiting them. @Calkers\r\n\r\nMajor President Obama will listen for the disaster!\r\n\r\nGrateful and South Carolina so his real ability and much better-- or big crisis on many signing!\r\n\r\nIt is absolutely dumbers for well tonight. Love us in the great inherition of fast. With bill of badly to forget the greatest puppet at my wedds. No Turnberry is \"bigger.\u201d - Al\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Well, that's less convincing. How about something more conservative, which the model is more confident of:</p>\n<p><!-- HTML generated using hilite.me --></p>\n<div style=\"background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .2em;padding:.8em .6em;\">\n<pre style=\"margin: 0; line-height: 125%\">textgen<span style=\"color: #555555\">.</span>generate(<span style=\"color: #FF6600\">5</span>, temperature<span style=\"color: #555555\">=</span><span style=\"color: #FF6600\">0.1</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nThe Fake News Media is a great people of the president was a great people of the many people who would be a great people of the president was a big crowd of the statement of the media is a great people of the people of the statement of the people of the people of the world with the statement of th\r\n\r\nThank you @TrumpTowerNY #Trump2016 https://t.co/25551R58350\r\n\r\nThank you for your support! #Trump2016 https://t.co/7eN53P55c\r\n\r\nThe people of the U.S. has been a great people of the presidential country is a great time and the best thing that the people of the statement of the media is the people of the state of the best thing that the people of the statement of the statement of the problem in the problem and success and t\r\n\r\nThank you @TheBrodyFile tonight at 8:00 A.M. Enjoy!</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Well now, some of these are seemingly more legible. </p>\n<p>Of course, this isn't perfect. There are all sorts of other things we could have tried, and the good news is that, if you don't want to implement your own solution, textgenrnn can be used to perform many of these things (again, see the <a href=\"https://github.com/minimaxir/textgenrnn\" rel=\"noopener\" target=\"_blank\">Github repo</a>):</p>\n<ul>\n<li>Train our own model from scratch\n<li>Train with more sample data for a greater number of iterations\n<li>Tune other hyperparameters\n<li>Preprocess the data a bit (at the very least to eliminate the fake URLs)\n</li></li></li></li></ul>\n<p>Kind of fun. I'm interested in seeing how a default textgenrnn model performs out-of-the-box against a custom, well-tuned model. Maybe something for next time.</p>\n<p>\u00a0<br/>\n<b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/06/5-machine-learning-projects-overlook-jun-2018.html\">5 Machine Learning Projects You Should Not Overlook, June 2018</a>\n<li><a href=\"/2018/05/getting-started-spacy-natural-language-processing.html\">Getting Started with spaCy for Natural Language Processing</a>\n<li><a href=\"/2017/10/what-celebrities-tweet-about-most.html\">Find Out What Celebrities Tweet About the Most</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/06/advice-applying-data-science-jobs.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/tutorials.html\">Tutorials, Overviews</a> \u00bb Generating Text with RNNs in 4 Lines of Code (\u00a0<a href=\"/2018/n24.html\">18:n24</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556350051\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.632 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-27 03:27:31 -->\n<!-- Compression = gzip -->", "content_tokenized": ["matthew", "mayo", "kdnugget", "comment", "generat", "text", "one", "those", "project", "that", "seem", "like", "lot", "fun", "machin", "learn", "and", "beginn", "but", "one", "which", "also", "pretti", "daunt", "least", "for", "thank", "there", "are", "all", "sort", "great", "materi", "onlin", "for", "learn", "how", "rnns", "can", "use", "for", "generat", "text", "rang", "from", "the", "theoret", "the", "technic", "indepth", "those", "decid", "focus", "the", "practic", "there", "are", "also", "some", "veri", "good", "post", "which", "cover", "all", "and", "are", "now", "consid", "canon", "this", "space", "all", "these", "materi", "share", "one", "thing", "particular", "some", "point", "along", "the", "way", "have", "build", "and", "tune", "the", "work", "while", "this", "obvious", "worthwhil", "undertak", "especi", "for", "the", "sake", "learn", "what", "are", "with", "much", "higher", "level", "abstract", "whatev", "reason", "may", "what", "are", "data", "scientist", "that", "requir", "build", "block", "the", "form", "text", "generat", "plug", "into", "project", "what", "newcom", "simpli", "want", "get", "hand", "bit", "but", "not", "too", "dirti", "mean", "test", "the", "water", "motiv", "dig", "down", "further", "that", "vein", "let", "take", "look", "textgenrnn", "project", "which", "allow", "easili", "train", "own", "textgener", "neural", "network", "ani", "size", "and", "complex", "ani", "text", "dataset", "with", "few", "line", "code", "textgenrnn", "author", "max", "woolf", "associ", "data", "scientist", "buzzfe", "and", "former", "appl", "softwar", "engin", "textgenrnn", "built", "top", "kera", "and", "tensorflow", "and", "can", "use", "generat", "both", "charact", "and", "word", "level", "text", "charact", "level", "the", "default", "the", "network", "architectur", "use", "attentionweight", "and", "skipembed", "for", "acceler", "train", "and", "improv", "qualiti", "and", "allow", "for", "the", "tune", "number", "hyperparamet", "such", "size", "layer", "and", "the", "inclus", "bidirect", "rnns", "can", "read", "more", "about", "textgenrnn", "and", "featur", "and", "architectur", "github", "repo", "this", "introductori", "blog", "post", "sinc", "the", "hello", "world", "for", "text", "generat", "least", "mind", "seem", "generat", "trump", "tweet", "let", "with", "that", "textgenrnn", "default", "pretrain", "model", "can", "train", "new", "text", "easili", "though", "can", "also", "use", "textgenrnn", "train", "new", "model", "just", "add", "newmodeltru", "ani", "train", "function", "and", "sinc", "want", "see", "how", "quick", "can", "get", "generat", "tweet", "let", "that", "rout", "acquir", "the", "data", "grab", "select", "donald", "trump", "tweet", "jan", "num", "num", "jun", "num", "num", "yesterday", "time", "write", "which", "clear", "includ", "tweet", "from", "both", "befor", "and", "after", "his", "inaugur", "presid", "the", "unit", "state", "from", "trump", "twitter", "archiv", "site", "which", "make", "queri", "and", "download", "tweet", "from", "the", "presid", "painless", "chose", "onli", "grab", "the", "text", "from", "the", "tweet", "that", "date", "rang", "sinc", "care", "about", "ani", "the", "metadata", "and", "save", "text", "file", "appropri", "call", "trumptweetstxt", "train", "the", "model", "let", "see", "how", "uncompl", "generat", "text", "with", "textgenrnn", "the", "follow", "num", "line", "are", "all", "need", "import", "the", "librari", "creat", "text", "generat", "object", "train", "the", "model", "the", "trumptweetstxt", "file", "for", "num", "epoch", "and", "then", "generat", "some", "sampl", "tweet", "generat", "use", "hilitem", "from", "textgenrnn", "import", "textgenrnn", "textgen", "textgen", "textgen", "after", "about", "num", "minut", "here", "what", "generat", "the", "numth", "epoch", "foxnew", "will", "self", "final", "complain", "about", "that", "great", "day", "and", "compani", "and", "start", "report", "the", "presid", "safeti", "and", "more", "than", "ani", "mention", "the", "bail", "the", "underach", "the", "construct", "and", "freedom", "and", "effort", "the", "politician", "and", "expens", "meet", "should", "have", "bee", "the", "world", "will", "interview", "foxandfriend", "numpm", "enjoy", "jebbush", "and", "fake", "news", "media", "major", "place", "the", "white", "hous", "the", "servic", "and", "sens", "where", "the", "peopl", "the", "debat", "and", "his", "show", "mani", "peopl", "who", "great", "press", "consid", "the", "job", "the", "way", "the", "the", "best", "and", "peopl", "the", "biggest", "thank", "new", "hampshir", "trump", "int", "hotel", "leadership", "barrier", "lou", "clinton", "forev", "person", "polit", "record", "support", "have", "realli", "begin", "the", "media", "the", "heart", "the", "bad", "and", "women", "who", "have", "been", "succeed", "and", "befor", "can", "also", "work", "the", "peopl", "are", "there", "time", "strong", "and", "send", "out", "the", "world", "with", "join", "maryland", "num", "and", "happen", "the", "and", "true", "the", "longer", "the", "same", "sign", "into", "the", "fake", "news", "media", "will", "great", "honor", "serv", "that", "the", "republican", "parti", "will", "great", "legal", "rate", "the", "media", "with", "the", "best", "republican", "parti", "and", "the", "american", "peopl", "that", "will", "the", "bill", "leav", "polit", "asid", "and", "given", "that", "are", "onli", "use", "tweet", "for", "train", "mere", "num", "epoch", "these", "generat", "tweet", "are", "not", "terribl", "want", "play", "with", "temperatur", "the", "textgenrnn", "default", "num", "get", "some", "more", "creativ", "tweet", "let", "tri", "out", "generat", "use", "hilitem", "textgen", "viacan", "see", "this", "democrat", "were", "the", "open", "govseptorald", "taster", "got", "that", "the", "subcent", "vote", "wait", "them", "calker", "major", "presid", "obama", "will", "listen", "for", "the", "disast", "grate", "and", "south", "carolina", "his", "real", "abil", "and", "much", "better", "big", "crisi", "mani", "sign", "absolut", "dumber", "for", "well", "tonight", "love", "the", "great", "inherit", "fast", "with", "bill", "bad", "forget", "the", "greatest", "puppet", "wedd", "turnberri", "bigger", "well", "that", "less", "convinc", "how", "about", "someth", "more", "conserv", "which", "the", "model", "more", "confid", "generat", "use", "hilitem", "textgen", "the", "fake", "news", "media", "great", "peopl", "the", "presid", "great", "peopl", "the", "mani", "peopl", "who", "would", "great", "peopl", "the", "presid", "big", "crowd", "the", "statement", "the", "media", "great", "peopl", "the", "peopl", "the", "statement", "the", "peopl", "the", "peopl", "the", "world", "with", "the", "statement", "thank", "trumptowerni", "trumpnum", "thank", "for", "support", "trumpnum", "numennumpnumc", "the", "peopl", "the", "has", "been", "great", "peopl", "the", "presidenti", "countri", "great", "time", "and", "the", "best", "thing", "that", "the", "peopl", "the", "statement", "the", "media", "the", "peopl", "the", "state", "the", "best", "thing", "that", "the", "peopl", "the", "statement", "the", "statement", "the", "problem", "the", "problem", "and", "success", "and", "thank", "thebrodyfil", "tonight", "num", "enjoy", "well", "now", "some", "these", "are", "seem", "more", "legibl", "cours", "this", "perfect", "there", "are", "all", "sort", "other", "thing", "could", "have", "tri", "and", "the", "good", "news", "that", "want", "implement", "own", "solut", "textgenrnn", "can", "use", "perform", "mani", "these", "thing", "again", "see", "the", "github", "repo", "train", "our", "own", "model", "from", "scratch", "train", "with", "more", "sampl", "data", "for", "greater", "number", "iter", "tune", "other", "hyperparamet", "preprocess", "the", "data", "bit", "the", "veri", "least", "elimin", "the", "fake", "url", "kind", "fun", "interest", "see", "how", "default", "textgenrnn", "model", "perform", "outofthebox", "against", "custom", "welltun", "model", "mayb", "someth", "for", "next", "time", "relat", "num", "machin", "learn", "project", "should", "not", "overlook", "june", "num", "get", "start", "with", "spaci", "for", "natur", "languag", "process", "find", "out", "what", "celebr", "tweet", "about", "the", "most"], "timestamp_scraper": 1556367940.185702, "title": "Generating Text with RNNs in 4 Lines of Code", "read_time": 385.5, "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/matt-mayo\" rel=\"author\" title=\"Posts by Matthew Mayo\">Matthew Mayo</a>, KDnuggets.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p>Generating text is one of those projects that seems like a lot of fun to machine learning and NLP beginners, but one which is also pretty daunting. Or, at least it was for me.</p>\n<p>Thankfully, there are all sorts of great materials online for learning how RNNs can be used for generating text, ranging from the theoretical to the technically in-depth to those decidedly focused on the practical. There are also some very good posts which <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\" rel=\"noopener noreferrer\" target=\"_blank\">cover it all</a> and are now considered canon in this space. All of these materials share one thing in particular: at some point along the way, you have to build and tune an RNN to do the work.</p>\n<p>While this is a obviously a worthwhile undertaking, especially for the sake of learning, what if you are OK with a much higher level of abstraction, whatever your reason may be? What if you are a data scientist that requires a building block in the form of an RNN text generator to plug into your project? Or, what if, as a newcomer, you simply want to get your hands a bit -- but not too -- dirty, as a means of testing the water or as motivation to dig down further?</p>\n<p>In that vein, let's take a look at <a href=\"https://github.com/minimaxir/textgenrnn\" rel=\"noopener\" target=\"_blank\">textgenrnn</a>, a project which allows you to \"easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.\" textgenrnn is authored by Max Woolf, an Associate Data Scientist at BuzzFeed, and former Apple Software QA Engineer.</p>\n<p>textgenrnn is a built on top of Keras and TensorFlow, and can be used to generate both character and word level text (character level is the default). The network architecture uses attention-weighting and skip-embedding for accelerated training and improved quality, and allows for the tuning of a number of hyperparameters, such as RNN size, RNN layers, and the inclusion of bidirectional RNNs. You can read more about textgenrnn and its features and architecture at its <a href=\"https://github.com/minimaxir/textgenrnn\" rel=\"noopener\" target=\"_blank\">Github repo</a> or in this <a href=\"http://minimaxir.com/2018/05/text-neural-networks/\" rel=\"noopener\" target=\"_blank\">introductory blog post</a>.</p>\n<p><img alt=\"Image\" class=\"aligncenter\" src=\"/wp-content/uploads/trump-tweets-hdr-02.jpg\" width=\"85%\"/></p>\n<p>Since the \"Hello, World!\" for text generation (at least, in my mind) seems to be generating Trump tweets, let's go with that. textgenrnn's default pretrained model can be trained on new texts easily -- though you can also use textgenrnn to train a new model (just add new_model=True to any of its train functions) -- and since we want to see how quickly we can get generating tweets, let's go that route.</p>\n<p>\u00a0</p>\n<h3>Acquiring the Data</h3>\n<p>\u00a0<br>\nI grabbed a selection of Donald Trump's tweets -- Jan 1, 2014 - Jun 11, 2018 (yesterday, at time of writing), which clearly includes tweets from both before and after his inauguration as President of the United States -- from <a href=\"http://www.trumptwitterarchive.com/archive\" rel=\"noopener\" target=\"_blank\">Trump Twitter Archive</a>, a site which makes querying and downloading tweets from the President painless. I chose only to grab the text from the tweets in that date range, since I don't care about any of the metadata, and saved it to a text file I appropriately called <code>trump-tweets.txt</code>.</br></p>\n<p><a href=\"https://image.ibb.co/mdzied/trump_tweets_archive.jpg\" rel=\"noopener noreferrer\" target=\"_blank\"><img alt=\"Image\" class=\"aligncenter\" src=\"https://image.ibb.co/mdzied/trump_tweets_archive.jpg\" width=\"99%\"/></a></p>\n<p>\u00a0</p>\n<h3>Training the Model</h3>\n<p>\u00a0<br>\nLet's see how uncomplicated it is to generate text with textgenrnn. The following 4 lines are all we need to import the library, create a text generation object, train the model on the <code>trump-tweets.txt</code> file for 10 epochs, and then generate some sample tweets.</br></p>\n<p><!-- HTML generated using hilite.me --></p>\n<div style=\"background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .2em;padding:.8em .6em;\">\n<pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #006699; font-weight: bold\">from</span> <span style=\"color: #00CCFF; font-weight: bold\">textgenrnn</span> <span style=\"color: #006699; font-weight: bold\">import</span> textgenrnn\r\ntextgen <span style=\"color: #555555\">=</span> textgenrnn()\r\ntextgen<span style=\"color: #555555\">.</span>train_from_file(<span style=\"color: #CC3300\">'trump-tweets.txt'</span>, num_epochs<span style=\"color: #555555\">=</span><span style=\"color: #FF6600\">10</span>)\r\ntextgen<span style=\"color: #555555\">.</span>generate(<span style=\"color: #FF6600\">5</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>After about 30 minutes, here's what's generated (on the 10th epoch):</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nMy @FoxNews will be self finally complaining about me that so he is a great day and companies and is starting to report the president in safety and more than any mention of the bail of the underaches to the construction and freedom and efforts the politicians and expensive meetings should have bee\r\n\r\nThe world will be interviewed on @foxandfriends at 7:30pm. Enjoy!\r\n\r\n.@JebBush and Fake News Media is a major place in the White House in the service and sense where the people of the debate and his show of many people who is a great press considering the GREAT job on the way to the U.S. A the best and people in the biggest! Thank you!\r\n\r\nNew Hampshire Trump Int'l Hotel Leadership Barrier Lou Clinton is a forever person politically record supporters have really beginning in the media on the heart of the bad and women who have been succeeded and before you can also work the people are there a time strong and send out the world with \r\n\r\nJoin me in Maryland at 7:00 A.M. and happened to the WALL and be true the longer of the same sign into the Fake News Media will be a great honor to serve that the Republican Party will be a great legal rate the media with the Best Republican Party and the American people that will be the bill by a</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Leaving politics aside, and given that we are only using ~12K tweets for training in a mere 10 epochs, these generated tweets are not... terrible. Want to play with <a href=\"https://www.quora.com/What-is-Temperature-in-LSTM\" rel=\"noopener\" target=\"_blank\">temperature</a> (the textgenrnn default is 0.5) to get some more creative tweets? Let's try it out:</p>\n<p><!-- HTML generated using hilite.me --></p>\n<div style=\"background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .2em;padding:.8em .6em;\">\n<pre style=\"margin: 0; line-height: 125%\">textgen<span style=\"color: #555555\">.</span>generate(<span style=\"color: #FF6600\">5</span>, temperature<span style=\"color: #555555\">=</span><span style=\"color: #FF6600\">0.9</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\n\u201cVia-can see this Democrats were the opening at GREAT ENSUS CALL!\r\n\r\n.@GovSeptorald Taster is got to that the subcent Vote waiting them. @Calkers\r\n\r\nMajor President Obama will listen for the disaster!\r\n\r\nGrateful and South Carolina so his real ability and much better-- or big crisis on many signing!\r\n\r\nIt is absolutely dumbers for well tonight. Love us in the great inherition of fast. With bill of badly to forget the greatest puppet at my wedds. No Turnberry is \"bigger.\u201d - Al\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Well, that's less convincing. How about something more conservative, which the model is more confident of:</p>\n<p><!-- HTML generated using hilite.me --></p>\n<div style=\"background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .2em;padding:.8em .6em;\">\n<pre style=\"margin: 0; line-height: 125%\">textgen<span style=\"color: #555555\">.</span>generate(<span style=\"color: #FF6600\">5</span>, temperature<span style=\"color: #555555\">=</span><span style=\"color: #FF6600\">0.1</span>)\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>\r\nThe Fake News Media is a great people of the president was a great people of the many people who would be a great people of the president was a big crowd of the statement of the media is a great people of the people of the statement of the people of the people of the world with the statement of th\r\n\r\nThank you @TrumpTowerNY #Trump2016 https://t.co/25551R58350\r\n\r\nThank you for your support! #Trump2016 https://t.co/7eN53P55c\r\n\r\nThe people of the U.S. has been a great people of the presidential country is a great time and the best thing that the people of the statement of the media is the people of the state of the best thing that the people of the statement of the statement of the problem in the problem and success and t\r\n\r\nThank you @TheBrodyFile tonight at 8:00 A.M. Enjoy!</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Well now, some of these are seemingly more legible. </p>\n<p>Of course, this isn't perfect. There are all sorts of other things we could have tried, and the good news is that, if you don't want to implement your own solution, textgenrnn can be used to perform many of these things (again, see the <a href=\"https://github.com/minimaxir/textgenrnn\" rel=\"noopener\" target=\"_blank\">Github repo</a>):</p>\n<ul>\n<li>Train our own model from scratch\n<li>Train with more sample data for a greater number of iterations\n<li>Tune other hyperparameters\n<li>Preprocess the data a bit (at the very least to eliminate the fake URLs)\n</li></li></li></li></ul>\n<p>Kind of fun. I'm interested in seeing how a default textgenrnn model performs out-of-the-box against a custom, well-tuned model. Maybe something for next time.</p>\n<p>\u00a0<br/>\n<b>Related</b>:</p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/06/5-machine-learning-projects-overlook-jun-2018.html\">5 Machine Learning Projects You Should Not Overlook, June 2018</a>\n<li><a href=\"/2018/05/getting-started-spacy-natural-language-processing.html\">Getting Started with spaCy for Natural Language Processing</a>\n<li><a href=\"/2017/10/what-celebrities-tweet-about-most.html\">Find Out What Celebrities Tweet About the Most</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}