{"content": "comments By William Falcon , PhD Candidate, AI, Neuroscience (NYU) If you\u2019ve used PyTorch you have likely experienced euphoria, increased energy and may have even felt like walking in the sun for a bit. Your life feels complete again. That is, until you tried to have variable-sized mini-batches using RNNs. All hope is not lost . After reading this, you\u2019ll be back to fantasies of you + PyTorch eloping into the sunset while your Recurrent Networks achieve new accuracies you\u2019ve only read about on Arxiv. Ninja skills we\u2019ll develop: How to implement an LSTM in PyTorch with variable-sized sequences in each mini-batch. What\u00a0 pack_padded_sequence \u00a0and\u00a0 pad_packed_sequence \u00a0do in PyTorch. Masking padded tokens for\u00a0 back-propagation through time . \u00a0 TL;DR version : Pad sentences, make all the same length,\u00a0 pack_padded_sequence , run through LSTM, use\u00a0 pad_packed_sequence , flatten all outputs and label, mask out padded outputs, calculate cross-entropy. \u00a0 Why is this so hard and why do I\u00a0care? \u00a0 Speed and Performance. Feeding variable length elements at ONCE into an LSTM has been a huge technical challenge which frameworks like PyTorch have largely solved (Tensorflow also has a nice abstraction but it\u2019s very very very involved). Furthermore, the documentation is unclear and examples are too old. Properly doing this will speed up training AND increase the accuracy of gradient descent by having a better estimator for the gradients from multiple examples instead of just ONE. Although RNNs are hard to parallelize because each step depends on the previous step, we can get a huge boost by using mini-batches. \u00a0 Sequence Tagging \u00a0 While I can\u2019t help you with your Justin Bieber obsession (I won\u2019t tell), I can help you do part of speech tagging on your favorite JB song,\u00a0 Sorry . Here\u2019s an example of the model with the song sentence: \u201cis it too late now to say sorry?\u201d (removed \u2018 to\u2019 \u00a0and \u2018 ?\u2019 \u00a0). LSTM/GRU model we\u2019re\u00a0building \u00a0 Data Formatting \u00a0 While you can do a ton of formatting, we won\u2019t... For simplicity, let\u2019s make this contrived batch of data with different sized sequences. sent_1_x = ['is', 'it', 'too', 'late', 'now', 'say', 'sorry']\r sent_1_y = ['VB', 'PRP', 'RB', 'RB', 'RB', 'VB', 'JJ']\r \r sent_2_x = ['ooh', 'ooh']\r sent_2_y = ['NNP', 'NNP']\r \r sent_3_x = ['sorry', 'yeah']\r sent_3_y = ['JJ', 'NNP']\r \r X = [sent_1_x, sent_2_x, sent_3_x]\r Y = [sent_1_y, sent_2_y, sent_3_y] When we feed each sentence to the embedding layer, each word will map to an index, so we need to convert them to list of integers. Here we map these sentences to their corresponding vocabulary index # map sentences to vocab\r vocab = {' ': 0, 'is': 1, 'it': 2, 'too': 3, 'late': 4, 'now': 5, 'say': 6, 'sorry': 7, 'ooh': 8, 'yeah': 9} \r \r # fancy nested list comprehension\r X = [[vocab[word] for word in sentence] for sentence in X]\r \r # X now looks like: \r # [[1, 2, 3, 4, 5, 6, 7], [8, 8], [7, 9]] Same for the classification labels (in our case POS tags). These won\u2019t be embedded. tags = {' ': 0, 'VB': 1, 'PRP': 2, 'RB': 3, 'JJ': 4, 'NNP': 5}\r \r # fancy nested list comprehension\r Y = [[tags[tag] for tag in sentence] for sentence in Y]\r \r # Y now looks like:\r # [[1, 2, 3, 3, 3, 1, 4], [5, 5], [4, 5]] \u00a0 Trick 1: Make all sequences in the mini-batch have the same length by\u00a0padding. \u00a0 What is in a box and has all different lengths? Not our mini-batch! For PyTorch to do its thing, we need to save the lengths of each sequence before we pad. We\u2019ll use this information to mask out the loss function. import numpy as np\r \r X = [[0, 1, 2, 3, 4, 5, 6], \r [7, 7], \r [6, 8]]\r \r # get the length of each sentence\r X_lengths = [ for sentence in X]\r \r # create an empty matrix with padding tokens\r pad_token = vocab[' ']\r longest_sent = \r batch_size = \r padded_X = ) * pad_token\r \r # copy over the actual sequences\r for i, x_len in :\r sequence = X[i]\r padded_X[i, 0:x_len] = sequence[:x_len]\r \r # padded_X looks like:\r  We do the same for the tags: import numpy as np\r \r Y = [[1, 2, 3, 3, 3, 1, 4], \r [5, 5], \r [4, 5]]\r \r # get the length of each sentence\r Y_lengths = [ for sentence in Y]\r \r # create an empty matrix with padding tokens\r pad_token = tags[' ']\r longest_sent = \r batch_size = \r padded_Y = ) * pad_token\r \r # copy over the actual sequences\r for i, y_len in :\r sequence = Y[i]\r padded_Y[i, 0:y_len] = sequence[:y_len]\r \r # padded_Y looks like:\r  Data processing summary: We turned words into sequences of indexes and padded each sequence with a zero so the batch could all be the same size. Our data now look like: # X \r \r \r # Y \r  \u00a0 The model \u00a0 We\u2019ll make a very simple LSTM network using PyTorch. The layers will be: Embedding LSTM Linear Softmax \u00a0 Trick 2: How to use PyTorch pack_padded_sequence and pad_packed_sequence \u00a0 To recap, we are now feeding a batch where each element HAS BEEN PADDED already. In the forward pass we\u2019ll: Embed the sequences Use pack_padded_sequence to make sure the LSTM won\u2019t see the padded items Run the packed_batch into the LSTM Undo the packing by using pad_packed_sequence Transform the lstm output so we can feed to linear layer Run through log_softmax Convert shape back so we finish with (batch_size, seq_len, nb_tags) \u00a0 Trick 3: Mask out network outputs we don\u2019t want to consider in our loss\u00a0function \u00a0 Mask out those padded activations Finally, we\u2019re ready to calculate the loss function. The main point here is that we don\u2019t want to take into account the network output for padded elements. Intuition alert:\u00a0 Best way to think about doing this is to FLATTEN ALL network outputs AND labels. Then calculate the loss on that ONE sequence. Waaaaaaaa\u2026 It\u2019s that easy. Now you can train your model MUCH faster with mini-batches and get back to obsessing over JB (still won\u2019t tell, don\u2019t worry). I know how you\u2019re feeling now\u2026 This is of course a very barebones LSTM. Things you can do to fancy up your model (not comprehensive): Initialize with Glove embeddings. Use GRU cell. Use Bidirectional mechanism (don\u2019t forget to modify init_hidden). Use character level features by creating an encoding vector with a Convolutional network and appending to the word vector. Add dropout. Increase number of layers \u2026 soooo much more And of course, a very thorough hyper-parameter search using the best hyperparemeter optimization library for Python:\u00a0 test-tube \u00a0 (disclaimer: I wrote test-tube). \u00a0 In Summary: \u00a0 This is how you get your sanity back in PyTorch with variable length batched inputs to an LSTM Sort inputs by largest sequence first Make all the same length by padding to largest sequence in the batch Use pack_padded_sequence to make sure LSTM doesn\u2019t see padded items (Facebook team, you really should rename this API). Undo step 3 with pad_packed_sequence. Flatten outputs and labels into ONE LONG VECTOR. Mask out outputs you don\u2019t want Calculate cross-entropy on that. \u00a0 Full Code: \u00a0 \u00a0 Bio: William Falcon is a PhD Candidate, AI, Neuroscience (NYU), and Co-Founder @Nextgenvest. He is a former Product Manager and iOS Eng. Prior at Goldman Sachs, Bonobos, Columbia. Original . Reposted with permission. Related: PyTorch Tensor Basics Getting Started with PyTorch Part 1: Understanding How Automatic Differentiation Works A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs)", "title_html": "<h1 id=\"title\">Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health</h1> ", "url": "https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html", "tfidf": {"tfidf": {"after": 1.02070207021, "relat": 1.23750876919, "boost": 9.16099249856, "song": 6.866782006919999, "vocab": 3735.529411764, "still": 1.1866357724799999, "permiss": 6.280063291139999, "too": 7.2634107286, "pytorch": 10272.705882351, "here": 7.26923076924, "label": 17.90862944164, "save": 2.8178913737999998, "new": 1.0178880554, "contriv": 64.8, "with": 15.017973134849997, "integ": 46.017391304300006, "layer": 32.56615384616, "encod": 29.0237659963, "parallel": 4.57917507932, "care": 2.49426551453, "about": 2.12972030318, "function": 7.486325055, "run": 4.6707855251399995, "renam": 3.98994722292, "which": 1.005191845, "wrote": 2.10473286491, "felt": 3.28559602649, "descent": 8.494382022469999, "thing": 4.813096862219999, "sentenc": 75.98969072162001, "python": 56.2978723404, "just": 1.33580143037, "product": 1.62264922322, "work": 1.11520089913, "cofound": 264.6, "solv": 7.26923076923, "complet": 1.24021560816, "repost": 933.882352941, "skill": 3.6989748369099997, "nbtag": 933.882352941, "longests": 1867.764705882, "know": 2.59327017315, "them": 1.09876115994, "should": 1.6643254009900001, "goldman": 43.2588555858, "out": 5.30083472455, "automat": 6.787516032490001, "feed": 31.11415972564, "where": 1.06715063521, "pack": 7.85163204748, "cours": 4.30185611706, "sach": 63.504, "instead": 1.59461631177, "creat": 3.7478753541, "their": 1.01547908405, "start": 1.26673581744, "multipl": 2.74813917258, "mechan": 3.41492794149, "vector": 51.79771615, "intuit": 27.7068062827, "how": 8.01251640255, "columbia": 5.41473396999, "ooh": 1190.6999999999998, "guid": 2.49113447356, "format": 5.0625, "seri": 1.46511627907, "lost": 1.74634253657, "thorough": 10.956521739100001, "energi": 3.66566612792, "ylen": 2801.647058823, "falcon": 46.762886598, "can": 8.23382973994, "sure": 14.907042253520002, "whi": 6.513230769240001, "word": 8.982686432049999, "batchsiz": 2801.647058823, "will": 3.67443295788, "over": 3.07575072651, "barebon": 933.882352941, "consid": 1.2397313759200002, "increas": 3.9607484407499998, "build": 1.6341739578, "veri": 7.55280685062, "padpackedsequ": 4669.411764705, "padtoken": 3735.529411764, "simplic": 25.4423076923, "seqlen": 933.882352941, "number": 1.10142916609, "linear": 27.7552447552, "initi": 1.35, "readi": 5.15789473684, "simpl": 3.3981164383599998, "perform": 1.5313977042500002, "but": 1.01632417899, "rnns": 1867.764705882, "largest": 4.1023255814, "our": 9.43035343036, "classif": 8.067073170730001, "output": 61.415860735040006, "final": 1.34008609775, "inform": 1.5753125620200001, "bieber": 311.294117647, "matrix": 45.2307692308, "num": 67.02110768067, "modifi": 4.45329593268, "walk": 3.56363636364, "say": 5.2633440159, "level": 1.6544393497299998, "exampl": 4.51450236966, "huge": 8.77854575616, "has": 3.1309492505999996, "have": 6.089369046839999, "tensorflow": 933.882352941, "take": 1.13961668222, "pass": 1.61818367139, "alert": 13.6041131105, "previous": 1.42846859816, "now": 9.286246984, "sentnumx": 5603.294117646, "saniti": 103.764705882, "tri": 1.8544562551099997, "sorri": 196.9727047145, "code": 3.8807137619199996, "hard": 5.46506024096, "model": 10.452989202000001, "full": 1.66729678639, "comprehens": 16.0634064081, "packedbatch": 933.882352941, "basic": 2.7301805675, "time": 2.02254920696, "realli": 4.7476076555, "much": 1.1942229577299999, "glove": 31.3754940711, "feel": 6.271380604380001, "hyperparamet": 933.882352941, "also": 1.01476510067, "optim": 11.5377906977, "forward": 3.66566612792, "train": 3.8731397901999998, "loss": 9.70119156736, "softmax": 933.882352941, "not": 3.04702194357, "involv": 1.4498630137000001, "accuraci": 25.5241157556, "fanci": 91.7687861271, "batch": 178.38202247200002, "length": 33.22111136949, "are": 3.08971780734, "may": 1.05201775893, "candid": 9.02558271746, "experienc": 3.5564516129, "tag": 177.7164179103, "hyperparemet": 933.882352941, "easi": 5.2937645882, "challeng": 2.55816951337, "want": 5.99094339624, "better": 2.0065722952500002, "convert": 6.5481542586199994, "then": 1.08657860516, "index": 20.9907448215, "into": 6.09014768874, "item": 10.15738963532, "sun": 4.38927287808, "recurr": 71.1928251122, "testtub": 1867.764705882, "let": 3.48616600791, "although": 1.14968498805, "variabl": 17.494214876039997, "actual": 3.74964572508, "token": 101.12101910819999, "disclaim": 98.6086956522, "obsess": 35.201773836, "could": 1.2043695949, "nextgenvest": 933.882352941, "neurosci": 133.4117647058, "version": 2.0083491461099996, "featur": 1.52712581762, "euphoria": 124.03125, "activ": 1.46403541129, "neural": 59.4606741573, "estim": 2.34991119005, "alreadi": 1.9551724137900002, "flatten": 84.67200000000001, "until": 1.14852058164, "calcul": 24.51891891892, "see": 2.54484251022, "packpaddedsequ": 4669.411764705, "waaaaaaaa\u2026": 933.882352941, "hope": 2.50884955752, "develop": 1.1955719557200002, "manag": 1.6448404475799998, "becaus": 1.1495184997499999, "facebook": 28.5539568345, "justin": 17.5038588754, "those": 1.19548192771, "bonobo": 396.9, "get": 10.7137554831, "network": 18.15585688616, "like": 9.193485342, "implement": 3.57648118946, "nest": 42.5060240964, "box": 4.12685209254, "phd": 44.7211267606, "paddedx": 2801.647058823, "add": 4.61243463103, "part": 2.08661365578, "append": 55.125, "transform": 3.42007755278, "backpropag": 933.882352941, "element": 7.08012486993, "summari": 15.60294840294, "minibatch": 5603.294117646, "cell": 7.1033557047, "now\u2026": 933.882352941, "team": 2.2748244734200003, "need": 2.8745247148199997, "logsoftmax": 933.882352941, "the": 41.0, "numpi": 1867.764705882, "this": 9.03414264039, "emb": 186.776470588, "trick": 44.1818181819, "furthermor": 5.50294627383, "from": 1.00056721497, "process": 1.69524826482, "back": 5.04280155644, "account": 1.94463498285, "bit": 8.33385826772, "document": 2.5409731114, "differ": 2.4730898045, "embed": 67.34252386, "been": 1.0239277652399998, "eng": 85.3548387097, "turn": 1.3838912133899999, "sentnumi": 5603.294117646, "forget": 16.9978586724, "correspond": 3.32481675393, "william": 3.50967171438, "inithidden": 933.882352941, "for": 18.00567072018, "depend": 2.2411067193700003, "predict": 5.18484650555, "gradient": 83.778364116, "all": 7.080275229370001, "charact": 2.51720310766, "paddedi": 2801.647058823, "xlen": 2801.647058823, "ton": 10.5278514589, "zero": 8.75192943771, "think": 2.90715986083, "late": 3.95220313668, "former": 1.36111111111, "empti": 16.134146341460003, "case": 1.48498737256, "vocabulari": 23.2785923754, "xlength": 933.882352941, "that": 5.01992031875, "sort": 5.188235294119999, "look": 9.543159413299998, "technic": 3.1400316455699997, "variables": 1867.764705882, "dropout": 167.115789474, "more": 1.0171706817, "and": 16.00100787408, "list": 4.08964451313, "favorit": 8.116564417180001, "finish": 3.22879804759, "achiev": 1.87216981132, "these": 2.14830852504, "life": 1.37051104972, "sunset": 24.091047041, "pad": 320.47826086900005, "recap": 182.482758621, "while": 3.1325966850899993, "faster": 7.61438848921, "befor": 1.10036041031, "librari": 2.68266306185, "again": 1.50883862384, "yeah": 160.3636363636, "remov": 2.0058117498400003, "map": 12.218573627490002, "won": 11.5866296891, "even": 1.16461267606, "old": 1.52844902282, "bidirect": 288.654545455, "make": 7.533862111020001, "way": 1.2190739461, "proper": 3.3388012618299996, "onli": 1.0256476516600002, "each": 10.70773381296, "size": 4.9877474081, "ninja": 98.0, "larg": 1.18574949585, "tensor": 152.653846154, "search": 3.2539454806299997, "speech": 3.8227787141800005, "step": 8.48379052368, "read": 4.629921259840001, "framework": 8.200413223139998, "soooo": 933.882352941, "worri": 10.302401038300001, "same": 6.71147748888, "comment": 3.05954904606, "data": 13.50574223736, "unclear": 9.55809753161, "shape": 3.20338983051, "sequenc": 103.20917782018999, "undo": 132.85355648540002, "best": 3.1657028913200005, "convolut": 101.121019108, "bio": 42.336000000000006, "ylength": 933.882352941, "prior": 2.17807655371, "abstract": 9.966101694919999, "origin": 1.13724928367, "mask": 70.66468842719999, "through": 3.21224792607, "lstms": 933.882352941, "understand": 2.96858638743, "differenti": 7.759530791789999, "import": 2.6803984467400004, "first": 1.00761614623, "what": 2.50686878256, "copi": 7.675126903560001, "input": 24.4058416602, "tell": 6.72284564896, "nice": 17.7583892617, "use": 15.444581360699999, "elop": 128.032258065, "fantasi": 12.0090771558, "crossentropi": 1867.764705882, "help": 2.79925945518, "main": 1.25303867403, "when": 1.02076769755, "lstm": 933.882352941, "point": 1.25990000794, "speed": 7.740614334480001, "arxiv": 441.0}, "logtfidf": {"after": 0.020490694648099998, "relat": 0.21310030165399999, "boost": 2.2149545241900004, "song": 2.4670968071, "vocab": 27.3574018794, "still": 0.17112222142900002, "permiss": 1.8373800586400002, "too": 2.3862206188879997, "pytorch": 75.23285516835, "here": 2.6551145651100003, "label": 5.99595330908, "save": 1.03598886547, "new": 0.0177299468511, "contriv": 4.17130560336, "with": 0.01796237570085, "integ": 3.8290193968699997, "layer": 8.387916649400001, "encod": 3.36811501148, "parallel": 1.52151886822, "care": 0.9139943029109999, "about": 0.1256869549492, "function": 2.743397224782, "run": 1.328144926617, "renam": 1.3837780034799998, "which": 0.00517841384543, "wrote": 0.744188554049, "felt": 1.18954807429, "descent": 2.13940500645, "thing": 1.7563870693599999, "sentenc": 22.95342822786, "python": 4.03065674296, "just": 0.289531434109, "product": 0.484060136536, "work": 0.109034567273, "cofound": 5.57821925168, "solv": 1.9836504770400003, "complet": 0.215285242047, "repost": 6.83935046985, "skill": 1.30805571015, "nbtag": 6.83935046985, "longests": 13.6787009397, "know": 0.952919694398, "them": 0.0941833269093, "should": 0.509419876758, "goldman": 3.76720196585, "out": 0.2921319545965, "automat": 1.9150850473199998, "feed": 8.20547460436, "where": 0.0649921387457, "pack": 2.06072141432, "cours": 1.531798808266, "sach": 4.15110289604, "instead": 0.46663315041500003, "creat": 0.667730455542, "their": 0.015360505122700001, "start": 0.236443369291, "multipl": 1.01092401812, "mechan": 1.22815639221, "vector": 6.50839775594, "intuit": 3.3216780971900004, "how": 2.3578347846500005, "columbia": 1.6891237509, "ooh": 17.95105307937, "guid": 0.912738218589, "format": 1.8574265037459998, "seri": 0.38193461069799994, "lost": 0.557523621781, "thorough": 2.39393487158, "energi": 1.29901007269, "ylen": 20.51805140955, "falcon": 6.30388537268, "can": 1.136387674758, "sure": 4.0173731104, "whi": 2.36137686094, "word": 2.929305411925, "batchsiz": 20.51805140955, "will": 0.6083596047450001, "over": 0.0748101644871, "barebon": 6.83935046985, "consid": 0.214894723824, "increas": 0.833462156787, "build": 0.491137452091, "veri": 1.3809587594280002, "padpackedsequ": 34.196752349250005, "padtoken": 27.3574018794, "simplic": 3.2364134455299998, "seqlen": 6.83935046985, "number": 0.0966085784186, "linear": 5.26055528392, "initi": 0.30010459245, "readi": 1.6405284994999998, "simpl": 1.2232212893899999, "perform": 0.42618085058, "but": 0.0161923720719, "rnns": 13.6787009397, "largest": 1.4368136946380001, "our": 3.4305568567280003, "classif": 2.08779073629, "output": 16.30581262616, "final": 0.292733863948, "inform": 0.454453704662, "bieber": 5.74073818118, "matrix": 6.2372608197599995, "num": 0.021104356491599002, "modifi": 1.4936444810499998, "walk": 1.270781474, "say": 1.6864628416560001, "level": 0.503462189943, "exampl": 1.2260480249969998, "huge": 2.9583271639, "has": 0.1281718345644, "have": 0.0887100140472, "tensorflow": 6.83935046985, "take": 0.130691962197, "pass": 0.48130432974, "alert": 2.61037218162, "previous": 0.356602960063, "now": 1.192743560168, "sentnumx": 41.0361028191, "saniti": 4.64212589251, "tri": 0.61759152916, "sorri": 18.3681362598, "code": 1.35601909597, "hard": 2.01045592812, "model": 3.687250365555, "full": 0.511203624148, "comprehens": 5.033794507410001, "packedbatch": 6.83935046985, "basic": 1.00436774895, "time": 0.0224230377252, "realli": 1.5576408397, "much": 0.17749572930100002, "glove": 3.4460271446199995, "feel": 2.2856986838599997, "hyperparamet": 6.83935046985, "also": 0.0146571578, "optim": 2.4456277954099996, "forward": 1.29901007269, "train": 1.321836625678, "loss": 3.543817435368, "softmax": 6.83935046985, "not": 0.0466572390225, "involv": 0.371469078658, "accuraci": 5.0929530812, "fanci": 10.26197979222, "batch": 17.8724476587, "length": 11.753648830080001, "are": 0.08840242074810001, "may": 0.050709995284400004, "candid": 3.01383177722, "experienc": 1.26876330984, "tag": 26.846680902480003, "hyperparemet": 6.83935046985, "easi": 1.6665296351499999, "challeng": 0.9392919688950001, "want": 2.0749098187649997, "better": 0.6964279406, "convert": 2.3720720736, "then": 0.08303386523089999, "index": 5.83640798736, "into": 0.0894771793722, "item": 3.25010860584, "sun": 1.47916358195, "recurr": 7.1444897237600005, "testtub": 13.6787009397, "let": 1.2488025672799998, "although": 0.139487981418, "variabl": 4.3374461344, "actual": 1.257028363296, "token": 10.553117159670002, "disclaim": 4.591159448919999, "obsess": 5.73589858768, "could": 0.18595627229000003, "nextgenvest": 6.83935046985, "neurosci": 8.40058628046, "version": 0.697313064259, "featur": 0.423387418142, "euphoria": 4.82053354998, "activ": 0.381196603284, "neural": 4.0853151555, "estim": 0.854377535975, "alreadi": 0.670478380747, "flatten": 7.4912755758600005, "until": 0.138474663439, "calcul": 7.252602636839999, "see": 0.481843170984, "packpaddedsequ": 34.196752349250005, "waaaaaaaa\u2026": 6.83935046985, "hope": 0.919824304455, "develop": 0.178624694913, "manag": 0.497643387158, "becaus": 0.139343158825, "facebook": 3.3517955196499996, "justin": 2.8624213637900002, "those": 0.17854939087299998, "bonobo": 5.98368435979, "get": 3.478614034692, "network": 6.671581371364, "like": 1.11242861236, "implement": 1.27437940907, "nest": 6.112997257540001, "box": 1.41751491115, "phd": 6.21459768774, "paddedx": 20.51805140955, "add": 1.52875583713, "part": 0.08479062196560001, "append": 4.0096033337699994, "transform": 1.22966322707, "backpropag": 6.83935046985, "element": 2.5760377676309996, "summari": 4.108625432059999, "minibatch": 41.0361028191, "cell": 1.9605673068599998, "now\u2026": 6.83935046985, "team": 0.821902894886, "need": 0.725480326884, "logsoftmax": 6.83935046985, "the": 0.0, "numpi": 13.6787009397, "this": 0.0340780414725, "emb": 5.22991255741, "trick": 8.069103187289999, "furthermor": 1.70528363496, "from": 0.000567054168866, "process": 0.527829199025, "back": 0.9266697235879999, "account": 0.665074289973, "bit": 2.12032652634, "document": 0.932547122383, "differ": 0.424642242624, "embed": 11.29399012508, "been": 0.023645982368400004, "eng": 4.44681714019, "turn": 0.324899251064, "sentnumi": 41.0361028191, "forget": 2.8330873756700004, "correspond": 1.20141456099, "william": 1.124750647754, "inithidden": 6.83935046985, "for": 0.005669827117146001, "depend": 0.806969815, "predict": 1.6457402376899999, "gradient": 7.47005521764, "all": 0.07981842468459999, "charact": 0.923148407239, "paddedi": 20.51805140955, "xlen": 20.51805140955, "ton": 2.35402426534, "zero": 2.1692741832299998, "think": 1.06717661175, "late": 0.826982672628, "former": 0.308301359655, "empti": 4.17558147258, "case": 0.395406268889, "vocabulari": 3.14753415606, "xlength": 6.83935046985, "that": 0.019880741898199997, "sort": 1.64639361896, "look": 3.2319334680000003, "technic": 1.14423287808, "variables": 13.6787009397, "dropout": 5.1186869223, "more": 0.017024931599999998, "and": 0.0010078422730176, "list": 0.9295372845180001, "favorit": 2.09390696331, "finish": 1.17210994649, "achiev": 0.6270980851169999, "these": 0.1430672388016, "life": 0.315183699277, "sunset": 3.1818402794, "pad": 41.663246141399995, "recap": 5.206655695249999, "while": 0.12974995138140002, "faster": 2.03003967967, "befor": 0.0956377718795, "librari": 0.986809980943, "again": 0.411340231612, "yeah": 8.76859356642, "remov": 0.6960488415880001, "map": 4.21303480152, "won": 4.2020695395, "even": 0.152388564834, "old": 0.424253510675, "bidirect": 5.66523062867, "make": 0.5144836047603, "way": 0.19809150993500002, "proper": 1.2056118389200001, "onli": 0.025324268329099998, "each": 1.563675203736, "size": 1.8276744121219999, "ninja": 4.584967478669999, "larg": 0.17037506060600002, "tensor": 5.02817291476, "search": 1.1798682540899998, "speech": 1.3409775702700002, "step": 3.11863517094, "read": 1.67878536176, "framework": 2.10418454607, "soooo": 6.83935046985, "worri": 2.3323769785799997, "same": 0.672357897624, "comment": 1.11826753454, "data": 4.8672823392, "unclear": 2.2573887042900003, "shape": 1.16420957115, "sequenc": 30.6602554358, "undo": 8.39220052394, "best": 0.918455865894, "convolut": 4.61631800855, "bio": 3.7456377879300002, "ylength": 6.83935046985, "prior": 0.778442172521, "abstract": 2.29918950399, "origin": 0.128612437587, "mask": 14.79711913458, "through": 0.20507607565469999, "lstms": 6.83935046985, "understand": 1.0880858756799998, "differenti": 2.0489218673900003, "import": 0.585636554132, "first": 0.0075872898121599995, "what": 0.451774593654, "copi": 2.68967529488, "input": 5.00335067078, "tell": 2.42472868802, "nice": 2.8768580387299996, "use": 0.43812029597400004, "elop": 4.8522822483, "fantasi": 2.48566279349, "crossentropi": 13.6787009397, "help": 0.672415442688, "main": 0.225571540588, "when": 0.0205549888584, "lstm": 6.83935046985, "point": 0.23103235903299998, "speed": 2.7066677505400003, "arxiv": 6.08904487545}, "logidf": {"after": 0.020490694648099998, "relat": 0.21310030165399999, "boost": 2.2149545241900004, "song": 1.23354840355, "vocab": 6.83935046985, "still": 0.17112222142900002, "permiss": 1.8373800586400002, "too": 0.5965551547219999, "pytorch": 6.83935046985, "here": 0.8850381883700001, "label": 1.49898832727, "save": 1.03598886547, "new": 0.0177299468511, "contriv": 4.17130560336, "with": 0.00119749171339, "integ": 3.8290193968699997, "layer": 2.0969791623500003, "encod": 3.36811501148, "parallel": 1.52151886822, "care": 0.9139943029109999, "about": 0.0628434774746, "function": 0.914465741594, "run": 0.442714975539, "renam": 1.3837780034799998, "which": 0.00517841384543, "wrote": 0.744188554049, "felt": 1.18954807429, "descent": 2.13940500645, "thing": 0.8781935346799999, "sentenc": 1.7656483252200001, "python": 4.03065674296, "just": 0.289531434109, "product": 0.484060136536, "work": 0.109034567273, "cofound": 5.57821925168, "solv": 1.9836504770400003, "complet": 0.215285242047, "repost": 6.83935046985, "skill": 1.30805571015, "nbtag": 6.83935046985, "longests": 6.83935046985, "know": 0.952919694398, "them": 0.0941833269093, "should": 0.509419876758, "goldman": 3.76720196585, "out": 0.0584263909193, "automat": 1.9150850473199998, "feed": 2.05136865109, "where": 0.0649921387457, "pack": 2.06072141432, "cours": 0.765899404133, "sach": 4.15110289604, "instead": 0.46663315041500003, "creat": 0.222576818514, "their": 0.015360505122700001, "start": 0.236443369291, "multipl": 1.01092401812, "mechan": 1.22815639221, "vector": 3.25419887797, "intuit": 3.3216780971900004, "how": 0.47156695693000006, "columbia": 1.6891237509, "ooh": 5.98368435979, "guid": 0.912738218589, "format": 0.9287132518729999, "seri": 0.38193461069799994, "lost": 0.557523621781, "thorough": 2.39393487158, "energi": 1.29901007269, "ylen": 6.83935046985, "falcon": 3.15194268634, "can": 0.162341096394, "sure": 2.0086865552, "whi": 1.18068843047, "word": 0.585861082385, "batchsiz": 6.83935046985, "will": 0.202786534915, "over": 0.0249367214957, "barebon": 6.83935046985, "consid": 0.214894723824, "increas": 0.277820718929, "build": 0.491137452091, "veri": 0.230159793238, "padpackedsequ": 6.83935046985, "padtoken": 6.83935046985, "simplic": 3.2364134455299998, "seqlen": 6.83935046985, "number": 0.0966085784186, "linear": 2.63027764196, "initi": 0.30010459245, "readi": 1.6405284994999998, "simpl": 1.2232212893899999, "perform": 0.42618085058, "but": 0.0161923720719, "rnns": 6.83935046985, "largest": 0.7184068473190001, "our": 0.8576392141820001, "classif": 2.08779073629, "output": 2.03822657827, "final": 0.292733863948, "inform": 0.454453704662, "bieber": 5.74073818118, "matrix": 3.1186304098799997, "num": 0.00031499039539700004, "modifi": 1.4936444810499998, "walk": 1.270781474, "say": 0.562154280552, "level": 0.503462189943, "exampl": 0.40868267499899996, "huge": 1.47916358195, "has": 0.0427239448548, "have": 0.0147850023412, "tensorflow": 6.83935046985, "take": 0.130691962197, "pass": 0.48130432974, "alert": 2.61037218162, "previous": 0.356602960063, "now": 0.149092945021, "sentnumx": 6.83935046985, "saniti": 4.64212589251, "tri": 0.61759152916, "sorri": 3.6736272519599997, "code": 1.35601909597, "hard": 1.00522796406, "model": 0.7374500731110001, "full": 0.511203624148, "comprehens": 1.6779315024700001, "packedbatch": 6.83935046985, "basic": 1.00436774895, "time": 0.0112115188626, "realli": 1.5576408397, "much": 0.17749572930100002, "glove": 3.4460271446199995, "feel": 1.1428493419299999, "hyperparamet": 6.83935046985, "also": 0.0146571578, "optim": 2.4456277954099996, "forward": 1.29901007269, "train": 0.660918312839, "loss": 0.885954358842, "softmax": 6.83935046985, "not": 0.0155524130075, "involv": 0.371469078658, "accuraci": 2.5464765406, "fanci": 3.42065993074, "batch": 3.5744895317400003, "length": 1.3059609811200001, "are": 0.0294674735827, "may": 0.050709995284400004, "candid": 1.50691588861, "experienc": 1.26876330984, "tag": 2.98296454472, "hyperparemet": 6.83935046985, "easi": 1.6665296351499999, "challeng": 0.9392919688950001, "want": 0.6916366062549999, "better": 0.6964279406, "convert": 1.1860360368, "then": 0.08303386523089999, "index": 1.94546932912, "into": 0.0149128632287, "item": 1.62505430292, "sun": 1.47916358195, "recurr": 3.5722448618800002, "testtub": 6.83935046985, "let": 1.2488025672799998, "although": 0.139487981418, "variabl": 2.1687230672, "actual": 0.628514181648, "token": 3.5177057198900004, "disclaim": 4.591159448919999, "obsess": 2.86794929384, "could": 0.18595627229000003, "nextgenvest": 6.83935046985, "neurosci": 4.20029314023, "version": 0.697313064259, "featur": 0.423387418142, "euphoria": 4.82053354998, "activ": 0.381196603284, "neural": 4.0853151555, "estim": 0.854377535975, "alreadi": 0.670478380747, "flatten": 3.7456377879300002, "until": 0.138474663439, "calcul": 1.8131506592099997, "see": 0.240921585492, "packpaddedsequ": 6.83935046985, "waaaaaaaa\u2026": 6.83935046985, "hope": 0.919824304455, "develop": 0.178624694913, "manag": 0.497643387158, "becaus": 0.139343158825, "facebook": 3.3517955196499996, "justin": 2.8624213637900002, "those": 0.17854939087299998, "bonobo": 5.98368435979, "get": 0.579769005782, "network": 0.9530830530519999, "like": 0.139053576545, "implement": 1.27437940907, "nest": 3.0564986287700004, "box": 1.41751491115, "phd": 3.10729884387, "paddedx": 6.83935046985, "add": 1.52875583713, "part": 0.04239531098280001, "append": 4.0096033337699994, "transform": 1.22966322707, "backpropag": 6.83935046985, "element": 0.8586792558769999, "summari": 2.0543127160299997, "minibatch": 6.83935046985, "cell": 1.9605673068599998, "now\u2026": 6.83935046985, "team": 0.821902894886, "need": 0.362740163442, "logsoftmax": 6.83935046985, "the": 0.0, "numpi": 6.83935046985, "this": 0.0037864490525, "emb": 5.22991255741, "trick": 2.6897010624299997, "furthermor": 1.70528363496, "from": 0.000567054168866, "process": 0.527829199025, "back": 0.23166743089699998, "account": 0.665074289973, "bit": 2.12032652634, "document": 0.932547122383, "differ": 0.212321121312, "embed": 2.82349753127, "been": 0.023645982368400004, "eng": 4.44681714019, "turn": 0.324899251064, "sentnumi": 6.83935046985, "forget": 2.8330873756700004, "correspond": 1.20141456099, "william": 0.562375323877, "inithidden": 6.83935046985, "for": 0.00031499039539700004, "depend": 0.806969815, "predict": 1.6457402376899999, "gradient": 3.73502760882, "all": 0.011402632097799998, "charact": 0.923148407239, "paddedi": 6.83935046985, "xlen": 6.83935046985, "ton": 2.35402426534, "zero": 2.1692741832299998, "think": 1.06717661175, "late": 0.275660890876, "former": 0.308301359655, "empti": 2.08779073629, "case": 0.395406268889, "vocabulari": 3.14753415606, "xlength": 6.83935046985, "that": 0.00397614837964, "sort": 1.64639361896, "look": 0.6463866936, "technic": 1.14423287808, "variables": 6.83935046985, "dropout": 5.1186869223, "more": 0.017024931599999998, "and": 6.29901420636e-05, "list": 0.309845761506, "favorit": 2.09390696331, "finish": 1.17210994649, "achiev": 0.6270980851169999, "these": 0.0715336194008, "life": 0.315183699277, "sunset": 3.1818402794, "pad": 3.2048650877999996, "recap": 5.206655695249999, "while": 0.04324998379380001, "faster": 2.03003967967, "befor": 0.0956377718795, "librari": 0.986809980943, "again": 0.411340231612, "yeah": 4.38429678321, "remov": 0.6960488415880001, "map": 1.40434493384, "won": 0.8404139079, "even": 0.152388564834, "old": 0.424253510675, "bidirect": 5.66523062867, "make": 0.07349765782289999, "way": 0.19809150993500002, "proper": 1.2056118389200001, "onli": 0.025324268329099998, "each": 0.173741689304, "size": 0.9138372060609999, "ninja": 4.584967478669999, "larg": 0.17037506060600002, "tensor": 5.02817291476, "search": 1.1798682540899998, "speech": 1.3409775702700002, "step": 1.03954505698, "read": 0.83939268088, "framework": 2.10418454607, "soooo": 6.83935046985, "worri": 2.3323769785799997, "same": 0.112059649604, "comment": 1.11826753454, "data": 1.2168205848, "unclear": 2.2573887042900003, "shape": 1.16420957115, "sequenc": 1.8035444374, "undo": 4.19610026197, "best": 0.459227932947, "convolut": 4.61631800855, "bio": 3.7456377879300002, "ylength": 6.83935046985, "prior": 0.778442172521, "abstract": 2.29918950399, "origin": 0.128612437587, "mask": 2.46618652243, "through": 0.0683586918849, "lstms": 6.83935046985, "understand": 1.0880858756799998, "differenti": 2.0489218673900003, "import": 0.292818277066, "first": 0.0075872898121599995, "what": 0.225887296827, "copi": 1.34483764744, "input": 2.50167533539, "tell": 1.21236434401, "nice": 2.8768580387299996, "use": 0.0292080197316, "elop": 4.8522822483, "fantasi": 2.48566279349, "crossentropi": 6.83935046985, "help": 0.336207721344, "main": 0.225571540588, "when": 0.0205549888584, "lstm": 6.83935046985, "point": 0.23103235903299998, "speed": 1.3533338752700002, "arxiv": 6.08904487545}, "freq": {"after": 1, "relat": 1, "boost": 1, "song": 2, "vocab": 4, "still": 1, "permiss": 1, "too": 4, "pytorch": 11, "here": 3, "label": 4, "save": 1, "new": 1, "contriv": 1, "with": 15, "integ": 1, "layer": 4, "encod": 1, "parallel": 1, "care": 1, "about": 2, "function": 3, "run": 3, "renam": 1, "which": 1, "wrote": 1, "felt": 1, "descent": 1, "thing": 2, "sentenc": 13, "python": 1, "just": 1, "product": 1, "work": 1, "cofound": 1, "solv": 1, "complet": 1, "repost": 1, "skill": 1, "nbtag": 1, "longests": 2, "know": 1, "them": 1, "should": 1, "goldman": 1, "out": 5, "automat": 1, "feed": 4, "where": 1, "pack": 1, "cours": 2, "sach": 1, "instead": 1, "creat": 3, "their": 1, "start": 1, "multipl": 1, "mechan": 1, "vector": 2, "intuit": 1, "how": 5, "columbia": 1, "ooh": 3, "guid": 1, "format": 2, "seri": 1, "lost": 1, "thorough": 1, "energi": 1, "ylen": 3, "falcon": 2, "can": 7, "sure": 2, "whi": 2, "word": 5, "batchsiz": 3, "will": 3, "over": 3, "barebon": 1, "consid": 1, "increas": 3, "build": 1, "veri": 6, "padpackedsequ": 5, "padtoken": 4, "simplic": 1, "seqlen": 1, "number": 1, "linear": 2, "initi": 1, "readi": 1, "simpl": 1, "perform": 1, "but": 1, "rnns": 2, "largest": 2, "our": 4, "classif": 1, "output": 8, "final": 1, "inform": 1, "bieber": 1, "matrix": 2, "num": 67, "modifi": 1, "walk": 1, "say": 3, "level": 1, "exampl": 3, "huge": 2, "has": 3, "have": 6, "tensorflow": 1, "take": 1, "pass": 1, "alert": 1, "previous": 1, "now": 8, "sentnumx": 6, "saniti": 1, "tri": 1, "sorri": 5, "code": 1, "hard": 2, "model": 5, "full": 1, "comprehens": 3, "packedbatch": 1, "basic": 1, "time": 2, "realli": 1, "much": 1, "glove": 1, "feel": 2, "hyperparamet": 1, "also": 1, "optim": 1, "forward": 1, "train": 2, "loss": 4, "softmax": 1, "not": 3, "involv": 1, "accuraci": 2, "fanci": 3, "batch": 5, "length": 9, "are": 3, "may": 1, "candid": 2, "experienc": 1, "tag": 9, "hyperparemet": 1, "easi": 1, "challeng": 1, "want": 3, "better": 1, "convert": 2, "then": 1, "index": 3, "into": 6, "item": 2, "sun": 1, "recurr": 2, "testtub": 2, "let": 1, "although": 1, "variabl": 2, "actual": 2, "token": 3, "disclaim": 1, "obsess": 2, "could": 1, "nextgenvest": 1, "neurosci": 2, "version": 1, "featur": 1, "euphoria": 1, "activ": 1, "neural": 1, "estim": 1, "alreadi": 1, "flatten": 2, "until": 1, "calcul": 4, "see": 2, "packpaddedsequ": 5, "waaaaaaaa\u2026": 1, "hope": 1, "develop": 1, "manag": 1, "becaus": 1, "facebook": 1, "justin": 1, "those": 1, "bonobo": 1, "get": 6, "network": 7, "like": 8, "implement": 1, "nest": 2, "box": 1, "phd": 2, "paddedx": 3, "add": 1, "part": 2, "append": 1, "transform": 1, "backpropag": 1, "element": 3, "summari": 2, "minibatch": 6, "cell": 1, "now\u2026": 1, "team": 1, "need": 2, "logsoftmax": 1, "the": 41, "numpi": 2, "this": 9, "emb": 1, "trick": 3, "furthermor": 1, "from": 1, "process": 1, "back": 4, "account": 1, "bit": 1, "document": 1, "differ": 2, "embed": 4, "been": 1, "eng": 1, "turn": 1, "sentnumi": 6, "forget": 1, "correspond": 1, "william": 2, "inithidden": 1, "for": 18, "depend": 1, "predict": 1, "gradient": 2, "all": 7, "charact": 1, "paddedi": 3, "xlen": 3, "ton": 1, "zero": 1, "think": 1, "late": 3, "former": 1, "empti": 2, "case": 1, "vocabulari": 1, "xlength": 1, "that": 5, "sort": 1, "look": 5, "technic": 1, "variables": 2, "dropout": 1, "more": 1, "and": 16, "list": 3, "favorit": 1, "finish": 1, "achiev": 1, "these": 2, "life": 1, "sunset": 1, "pad": 13, "recap": 1, "while": 3, "faster": 1, "befor": 1, "librari": 1, "again": 1, "yeah": 2, "remov": 1, "map": 3, "won": 5, "even": 1, "old": 1, "bidirect": 1, "make": 7, "way": 1, "proper": 1, "onli": 1, "each": 9, "size": 2, "ninja": 1, "larg": 1, "tensor": 1, "search": 1, "speech": 1, "step": 3, "read": 2, "framework": 1, "soooo": 1, "worri": 1, "same": 6, "comment": 1, "data": 4, "unclear": 1, "shape": 1, "sequenc": 17, "undo": 2, "best": 2, "convolut": 1, "bio": 1, "ylength": 1, "prior": 1, "abstract": 1, "origin": 1, "mask": 6, "through": 3, "lstms": 1, "understand": 1, "differenti": 1, "import": 2, "first": 1, "what": 2, "copi": 2, "input": 2, "tell": 2, "nice": 1, "use": 15, "elop": 1, "fantasi": 1, "crossentropi": 2, "help": 2, "main": 1, "when": 1, "lstm": 1, "point": 1, "speed": 2, "arxiv": 1}, "idf": {"after": 1.02070207021, "relat": 1.23750876919, "boost": 9.16099249856, "song": 3.4333910034599997, "vocab": 933.882352941, "still": 1.1866357724799999, "permiss": 6.280063291139999, "too": 1.81585268215, "pytorch": 933.882352941, "here": 2.42307692308, "label": 4.47715736041, "save": 2.8178913737999998, "new": 1.0178880554, "contriv": 64.8, "with": 1.0011982089899998, "integ": 46.017391304300006, "layer": 8.14153846154, "encod": 29.0237659963, "parallel": 4.57917507932, "care": 2.49426551453, "about": 1.06486015159, "function": 2.495441685, "run": 1.55692850838, "renam": 3.98994722292, "which": 1.005191845, "wrote": 2.10473286491, "felt": 3.28559602649, "descent": 8.494382022469999, "thing": 2.4065484311099996, "sentenc": 5.84536082474, "python": 56.2978723404, "just": 1.33580143037, "product": 1.62264922322, "work": 1.11520089913, "cofound": 264.6, "solv": 7.26923076923, "complet": 1.24021560816, "repost": 933.882352941, "skill": 3.6989748369099997, "nbtag": 933.882352941, "longests": 933.882352941, "know": 2.59327017315, "them": 1.09876115994, "should": 1.6643254009900001, "goldman": 43.2588555858, "out": 1.06016694491, "automat": 6.787516032490001, "feed": 7.77853993141, "where": 1.06715063521, "pack": 7.85163204748, "cours": 2.15092805853, "sach": 63.504, "instead": 1.59461631177, "creat": 1.2492917847, "their": 1.01547908405, "start": 1.26673581744, "multipl": 2.74813917258, "mechan": 3.41492794149, "vector": 25.898858075, "intuit": 27.7068062827, "how": 1.60250328051, "columbia": 5.41473396999, "ooh": 396.9, "guid": 2.49113447356, "format": 2.53125, "seri": 1.46511627907, "lost": 1.74634253657, "thorough": 10.956521739100001, "energi": 3.66566612792, "ylen": 933.882352941, "falcon": 23.381443299, "can": 1.17626139142, "sure": 7.453521126760001, "whi": 3.2566153846200003, "word": 1.7965372864099998, "batchsiz": 933.882352941, "will": 1.22481098596, "over": 1.02525024217, "barebon": 933.882352941, "consid": 1.2397313759200002, "increas": 1.32024948025, "build": 1.6341739578, "veri": 1.25880114177, "padpackedsequ": 933.882352941, "padtoken": 933.882352941, "simplic": 25.4423076923, "seqlen": 933.882352941, "number": 1.10142916609, "linear": 13.8776223776, "initi": 1.35, "readi": 5.15789473684, "simpl": 3.3981164383599998, "perform": 1.5313977042500002, "but": 1.01632417899, "rnns": 933.882352941, "largest": 2.0511627907, "our": 2.35758835759, "classif": 8.067073170730001, "output": 7.676982591880001, "final": 1.34008609775, "inform": 1.5753125620200001, "bieber": 311.294117647, "matrix": 22.6153846154, "num": 1.00031504001, "modifi": 4.45329593268, "walk": 3.56363636364, "say": 1.7544480053, "level": 1.6544393497299998, "exampl": 1.50483412322, "huge": 4.38927287808, "has": 1.0436497502, "have": 1.0148948411399998, "tensorflow": 933.882352941, "take": 1.13961668222, "pass": 1.61818367139, "alert": 13.6041131105, "previous": 1.42846859816, "now": 1.160780873, "sentnumx": 933.882352941, "saniti": 103.764705882, "tri": 1.8544562551099997, "sorri": 39.3945409429, "code": 3.8807137619199996, "hard": 2.73253012048, "model": 2.0905978404, "full": 1.66729678639, "comprehens": 5.3544688027, "packedbatch": 933.882352941, "basic": 2.7301805675, "time": 1.01127460348, "realli": 4.7476076555, "much": 1.1942229577299999, "glove": 31.3754940711, "feel": 3.1356903021900004, "hyperparamet": 933.882352941, "also": 1.01476510067, "optim": 11.5377906977, "forward": 3.66566612792, "train": 1.9365698950999999, "loss": 2.42529789184, "softmax": 933.882352941, "not": 1.01567398119, "involv": 1.4498630137000001, "accuraci": 12.7620578778, "fanci": 30.5895953757, "batch": 35.6764044944, "length": 3.69123459661, "are": 1.02990593578, "may": 1.05201775893, "candid": 4.51279135873, "experienc": 3.5564516129, "tag": 19.7462686567, "hyperparemet": 933.882352941, "easi": 5.2937645882, "challeng": 2.55816951337, "want": 1.99698113208, "better": 2.0065722952500002, "convert": 3.2740771293099997, "then": 1.08657860516, "index": 6.9969149405, "into": 1.01502461479, "item": 5.07869481766, "sun": 4.38927287808, "recurr": 35.5964125561, "testtub": 933.882352941, "let": 3.48616600791, "although": 1.14968498805, "variabl": 8.747107438019999, "actual": 1.87482286254, "token": 33.7070063694, "disclaim": 98.6086956522, "obsess": 17.600886918, "could": 1.2043695949, "nextgenvest": 933.882352941, "neurosci": 66.7058823529, "version": 2.0083491461099996, "featur": 1.52712581762, "euphoria": 124.03125, "activ": 1.46403541129, "neural": 59.4606741573, "estim": 2.34991119005, "alreadi": 1.9551724137900002, "flatten": 42.336000000000006, "until": 1.14852058164, "calcul": 6.12972972973, "see": 1.27242125511, "packpaddedsequ": 933.882352941, "waaaaaaaa\u2026": 933.882352941, "hope": 2.50884955752, "develop": 1.1955719557200002, "manag": 1.6448404475799998, "becaus": 1.1495184997499999, "facebook": 28.5539568345, "justin": 17.5038588754, "those": 1.19548192771, "bonobo": 396.9, "get": 1.78562591385, "network": 2.59369384088, "like": 1.14918566775, "implement": 3.57648118946, "nest": 21.2530120482, "box": 4.12685209254, "phd": 22.3605633803, "paddedx": 933.882352941, "add": 4.61243463103, "part": 1.04330682789, "append": 55.125, "transform": 3.42007755278, "backpropag": 933.882352941, "element": 2.36004162331, "summari": 7.80147420147, "minibatch": 933.882352941, "cell": 7.1033557047, "now\u2026": 933.882352941, "team": 2.2748244734200003, "need": 1.4372623574099999, "logsoftmax": 933.882352941, "the": 1.0, "numpi": 933.882352941, "this": 1.00379362671, "emb": 186.776470588, "trick": 14.7272727273, "furthermor": 5.50294627383, "from": 1.00056721497, "process": 1.69524826482, "back": 1.26070038911, "account": 1.94463498285, "bit": 8.33385826772, "document": 2.5409731114, "differ": 1.23654490225, "embed": 16.835630965, "been": 1.0239277652399998, "eng": 85.3548387097, "turn": 1.3838912133899999, "sentnumi": 933.882352941, "forget": 16.9978586724, "correspond": 3.32481675393, "william": 1.75483585719, "inithidden": 933.882352941, "for": 1.00031504001, "depend": 2.2411067193700003, "predict": 5.18484650555, "gradient": 41.889182058, "all": 1.01146788991, "charact": 2.51720310766, "paddedi": 933.882352941, "xlen": 933.882352941, "ton": 10.5278514589, "zero": 8.75192943771, "think": 2.90715986083, "late": 1.31740104556, "former": 1.36111111111, "empti": 8.067073170730001, "case": 1.48498737256, "vocabulari": 23.2785923754, "xlength": 933.882352941, "that": 1.00398406375, "sort": 5.188235294119999, "look": 1.9086318826599997, "technic": 3.1400316455699997, "variables": 933.882352941, "dropout": 167.115789474, "more": 1.0171706817, "and": 1.00006299213, "list": 1.36321483771, "favorit": 8.116564417180001, "finish": 3.22879804759, "achiev": 1.87216981132, "these": 1.07415426252, "life": 1.37051104972, "sunset": 24.091047041, "pad": 24.652173913000002, "recap": 182.482758621, "while": 1.0441988950299999, "faster": 7.61438848921, "befor": 1.10036041031, "librari": 2.68266306185, "again": 1.50883862384, "yeah": 80.1818181818, "remov": 2.0058117498400003, "map": 4.0728578758300005, "won": 2.31732593782, "even": 1.16461267606, "old": 1.52844902282, "bidirect": 288.654545455, "make": 1.0762660158600001, "way": 1.2190739461, "proper": 3.3388012618299996, "onli": 1.0256476516600002, "each": 1.18974820144, "size": 2.49387370405, "ninja": 98.0, "larg": 1.18574949585, "tensor": 152.653846154, "search": 3.2539454806299997, "speech": 3.8227787141800005, "step": 2.8279301745599996, "read": 2.3149606299200003, "framework": 8.200413223139998, "soooo": 933.882352941, "worri": 10.302401038300001, "same": 1.11857958148, "comment": 3.05954904606, "data": 3.37643555934, "unclear": 9.55809753161, "shape": 3.20338983051, "sequenc": 6.07112810707, "undo": 66.42677824270001, "best": 1.5828514456600002, "convolut": 101.121019108, "bio": 42.336000000000006, "ylength": 933.882352941, "prior": 2.17807655371, "abstract": 9.966101694919999, "origin": 1.13724928367, "mask": 11.777448071199998, "through": 1.07074930869, "lstms": 933.882352941, "understand": 2.96858638743, "differenti": 7.759530791789999, "import": 1.3401992233700002, "first": 1.00761614623, "what": 1.25343439128, "copi": 3.8375634517800004, "input": 12.2029208301, "tell": 3.36142282448, "nice": 17.7583892617, "use": 1.0296387573799999, "elop": 128.032258065, "fantasi": 12.0090771558, "crossentropi": 933.882352941, "help": 1.39962972759, "main": 1.25303867403, "when": 1.02076769755, "lstm": 933.882352941, "point": 1.25990000794, "speed": 3.8703071672400005, "arxiv": 441.0}}, "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html\" rel=\"prev\" title=\"Generating Text with RNNs in 4 Lines of Code\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/data-lake-evolution-data-processing.html\" rel=\"next\" title=\"Data Lake \u2013 the evolution of data processing\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=81823\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-81823 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 14-Jun, 2018  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/tutorials.html\">Tutorials, Overviews</a> \u00bb Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health (\u00a0<a href=\"/2018/n24.html\">18:n24</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/06/data-lake-evolution-data-processing.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/lstm\" rel=\"tag\">LSTM</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/pytorch\" rel=\"tag\">PyTorch</a>, <a href=\"https://www.kdnuggets.com/tag/recurrent-neural-networks\" rel=\"tag\">Recurrent Neural Networks</a></div>\n<br/>\n<p class=\"excerpt\">\n     After reading this, you\u2019ll be back to fantasies of you + PyTorch eloping into the sunset while your Recurrent Networks achieve new accuracies you\u2019ve only read about on Arxiv.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/wfalcon/\" rel=\"noopener noreferrer\" target=\"_blank\">William Falcon</a>, PhD Candidate, AI, Neuroscience (NYU)</b></p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/1*_odqFvts1GBGFgddcmcGvg.gif\" width=\"50%\"/></p>\n<p>If you\u2019ve used PyTorch you have likely experienced euphoria, increased energy and may have even felt like walking in the sun for a bit. Your life feels complete again. That is, until you tried to have variable-sized mini-batches using RNNs.</p>\n<p><strong>All hope is not lost</strong>. After reading this, you\u2019ll be back to fantasies of you + PyTorch eloping into the sunset while your Recurrent Networks achieve new accuracies you\u2019ve only read about on Arxiv.</p>\n<p><strong>Ninja skills we\u2019ll develop:</strong></p>\n<ol>\n<li>How to implement an LSTM in PyTorch with variable-sized sequences in each mini-batch.\n<li>What\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pack_padded_sequence</a>\u00a0and\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pad_packed_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pad_packed_sequence</a>\u00a0do in PyTorch.\n<li>Masking padded tokens for\u00a0<a href=\"https://en.wikipedia.org/wiki/Backpropagation_through_time\" rel=\"noopener noreferrer\" target=\"_blank\">back-propagation through time</a>.\n</li></li></li></ol>\n<p>\u00a0</p>\n<blockquote><p><strong>TL;DR version</strong>: Pad sentences, make all the same length,\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pack_padded_sequence</a>, run through LSTM, use\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pad_packed_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pad_packed_sequence</a>, flatten all outputs and label, mask out padded outputs, calculate cross-entropy.</p></blockquote>\n<p>\u00a0</p>\n<h3>Why is this so hard and why do I\u00a0care?</h3>\n<p>\u00a0<br>\nSpeed and Performance.</br></p>\n<p>Feeding variable length elements at ONCE into an LSTM has been a huge technical challenge which frameworks like PyTorch have largely solved (Tensorflow also has a nice abstraction but it\u2019s very very very involved).</p>\n<p>Furthermore, the documentation is unclear and examples are too old. Properly doing this will speed up training AND increase the accuracy of gradient descent by having a better estimator for the gradients from multiple examples instead of just ONE.</p>\n<p>Although RNNs are hard to parallelize because each step depends on the previous step, we can get a huge boost by using mini-batches.</p>\n<p>\u00a0</p>\n<h3><strong>Sequence Tagging</strong></h3>\n<p>\u00a0<br>\nWhile I can\u2019t help you with your Justin Bieber obsession (I won\u2019t tell), I can help you do part of speech tagging on your favorite JB song,\u00a0<a href=\"https://www.youtube.com/watch?v=fRh_vgS2dFE\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Sorry</em></a>.</br></p>\n<p>Here\u2019s an example of the model with the song sentence: \u201cis it too late now to say sorry?\u201d (removed \u2018<strong>to\u2019</strong>\u00a0and \u2018<strong>?\u2019</strong>\u00a0).</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*wf9iOTO853P5ewjPX079RQ.png\" width=\"99%\"/><br>\n<font size=\"-1\">LSTM/GRU model we\u2019re\u00a0building</font></br></center></p>\n<p>\u00a0</p>\n<h3><strong>Data Formatting</strong></h3>\n<p>\u00a0<br>\nWhile you can do a ton of formatting, we won\u2019t... For simplicity, let\u2019s make this contrived batch of data with different sized sequences.</br></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>sent_1_x = ['is', 'it', 'too', 'late', 'now', 'say', 'sorry']\r\nsent_1_y = ['VB', 'PRP', 'RB', 'RB', 'RB', 'VB', 'JJ']\r\n\r\nsent_2_x = ['ooh', 'ooh']\r\nsent_2_y = ['NNP', 'NNP']\r\n\r\nsent_3_x = ['sorry', 'yeah']\r\nsent_3_y = ['JJ', 'NNP']\r\n\r\nX = [sent_1_x, sent_2_x, sent_3_x]\r\nY = [sent_1_y, sent_2_y, sent_3_y]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>When we feed each sentence to the embedding layer, each word will map to an index, so we need to convert them to list of integers.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*Y29f-F-HVDUSJMGzU3LdRg.png\" width=\"80%\"/><br/>\n<font size=\"-1\">Here we map these sentences to their corresponding vocabulary index</font></center></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># map sentences to vocab\r\nvocab = {'<pad>': 0, 'is': 1, 'it': 2, 'too': 3, 'late': 4, 'now': 5, 'say': 6, 'sorry': 7, 'ooh': 8, 'yeah': 9} \r\n\r\n# fancy nested list comprehension\r\nX =  [[vocab[word] for word in sentence] for sentence in X]\r\n\r\n# X now looks like:  \r\n# [[1, 2, 3, 4, 5, 6, 7], [8, 8], [7, 9]]</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Same for the classification labels (in our case POS tags). These won\u2019t be embedded.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>tags = {'<pad>': 0, 'VB': 1, 'PRP': 2, 'RB': 3, 'JJ': 4, 'NNP': 5}\r\n\r\n# fancy nested list comprehension\r\nY =  [[tags[tag] for tag in sentence] for sentence in Y]\r\n\r\n# Y now looks like:\r\n# [[1, 2, 3, 3, 3, 1, 4], [5, 5], [4, 5]]</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3><strong>Trick 1: Make all sequences in the mini-batch have the same length by\u00a0padding.</strong></h3>\n<p>\u00a0<br/>\nWhat is in a box and has all different lengths? Not our mini-batch!</p>\n<p>For PyTorch to do its thing, we need to save the lengths of each sequence before we pad. We\u2019ll use this information to mask out the loss function.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import numpy as np\r\n\r\nX = [[0, 1, 2, 3, 4, 5, 6], \r\n    [7, 7], \r\n    [6, 8]]\r\n\r\n# get the length of each sentence\r\nX_lengths = [len(sentence) for sentence in X]\r\n\r\n# create an empty matrix with padding tokens\r\npad_token = vocab['<pad>']\r\nlongest_sent = max(X_lengths)\r\nbatch_size = len(X)\r\npadded_X = np.ones((batch_size, longest_sent)) * pad_token\r\n\r\n# copy over the actual sequences\r\nfor i, x_len in enumerate(X_lengths):\r\n  sequence = X[i]\r\n  padded_X[i, 0:x_len] = sequence[:x_len]\r\n\r\n# padded_X looks like:\r\narray([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.],\r\n       [ 8.,  8.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 7.,  9.,  0.,  0.,  0.,  0.,  0.]])</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>We do the same for the tags:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import numpy as np\r\n\r\nY = [[1, 2, 3, 3, 3, 1, 4], \r\n    [5, 5], \r\n    [4, 5]]\r\n\r\n# get the length of each sentence\r\nY_lengths = [len(sentence) for sentence in Y]\r\n\r\n# create an empty matrix with padding tokens\r\npad_token = tags['<pad>']\r\nlongest_sent = max(Y_lengths)\r\nbatch_size = len(Y)\r\npadded_Y = np.ones((batch_size, longest_sent)) * pad_token\r\n\r\n# copy over the actual sequences\r\nfor i, y_len in enumerate(Y_lengths):\r\n  sequence = Y[i]\r\n  padded_Y[i, 0:y_len] = sequence[:y_len]\r\n\r\n# padded_Y looks like:\r\narray([[ 1.,  2.,  3.,  3.,  3.,  1.,  4.],\r\n       [ 5.,  5.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 4.,  5.,  0.,  0.,  0.,  0.,  0.]])</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><strong>Data processing summary:</strong></p>\n<p>We turned words into sequences of indexes and padded each sequence with a zero so the batch could all be the same size. Our data now look like:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># X \r\narray([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.],\r\n       [ 8.,  8.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 7.,  9.,  0.,  0.,  0.,  0.,  0.]])\r\n\r\n# Y \r\narray([[ 1.,  2.,  3.,  3.,  3.,  1.,  4.],\r\n       [ 5.,  5.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 4.,  5.,  0.,  0.,  0.,  0.,  0.]])</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3>The model</h3>\n<p>\u00a0<br/>\nWe\u2019ll make a very simple LSTM network using PyTorch. The layers will be:</p>\n<ol>\n<li>Embedding\n<li>LSTM\n<li>Linear\n<li>Softmax\n</li></li></li></li></ol>\n<p><script src=\"https://gist.github.com/williamFalcon/f75b01b47bf1be8b1e80be173ebdf39c.js\"></script></p>\n<p>\u00a0</p>\n<h3>Trick 2: How to use PyTorch pack_padded_sequence and pad_packed_sequence</h3>\n<p>\u00a0<br/>\nTo recap, we are now feeding a batch where each element HAS BEEN PADDED already. In the forward pass we\u2019ll:</p>\n<ol>\n<li>Embed the sequences\n<li>Use pack_padded_sequence to make sure the LSTM won\u2019t see the padded items\n<li>Run the packed_batch into the LSTM\n<li>Undo the packing by using pad_packed_sequence\n<li>Transform the lstm output so we can feed to linear layer\n<li>Run through log_softmax\n<li>Convert shape back so we finish with (batch_size, seq_len, nb_tags)\n</li></li></li></li></li></li></li></ol>\n<p><script src=\"https://gist.github.com/williamFalcon/b0dc6d25b39e7da0d05e5713ef0a57af.js\"></script></p>\n<p>\u00a0</p>\n<h3>Trick 3: Mask out network outputs we don\u2019t want to consider in our loss\u00a0function</h3>\n<p>\u00a0<br/>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/1*3U8qtLOIee4TV7mtv-nJvA.jpeg\" width=\"75%\"/><br/>\n<font size=\"-1\">Mask out those padded activations</font></center></p>\n<p>Finally, we\u2019re ready to calculate the loss function. The main point here is that we don\u2019t want to take into account the network output for padded elements.</p>\n<p><strong>Intuition alert:\u00a0</strong>Best way to think about doing this is to FLATTEN ALL network outputs AND labels. Then calculate the loss on that ONE sequence.</p>\n<p><script src=\"https://gist.github.com/williamFalcon/42da07d5cea5d00151f9cfde30f092b6.js\"></script></p>\n<p>Waaaaaaaa\u2026 It\u2019s that easy. Now you can train your model MUCH faster with mini-batches and get back to obsessing over JB (still won\u2019t tell, don\u2019t worry).<br/>\nI know how you\u2019re feeling now\u2026</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/1*SmFYrU8wxx9P7PIkzsEusQ.gif\" width=\"50%\"/></p>\n<p>This is of course a very barebones LSTM. Things you can do to fancy up your model (not comprehensive):</p>\n<ol>\n<li>Initialize with Glove embeddings.\n<li>Use GRU cell.\n<li>Use Bidirectional mechanism (don\u2019t forget to modify init_hidden).\n<li>Use character level features by creating an encoding vector with a Convolutional network and appending to the word vector.\n<li>Add dropout.\n<li>Increase number of layers\n<li>\u2026 soooo much more\n<li>And of course, a very thorough hyper-parameter search using the best hyperparemeter optimization library for Python:\u00a0<a href=\"https://github.com/williamFalcon/test_tube\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>test-tube</strong></a><strong>\u00a0</strong>(disclaimer: I wrote test-tube).\n</li></li></li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>In Summary:</h3>\n<p>\u00a0<br/>\nThis is how you get your sanity back in PyTorch with variable length batched inputs to an LSTM</p>\n<ol>\n<li>Sort inputs by largest sequence first\n<li>Make all the same length by padding to largest sequence in the batch\n<li>Use pack_padded_sequence to make sure LSTM doesn\u2019t see padded items (Facebook team, you really should rename this API).\n<li>Undo step 3 with pad_packed_sequence.\n<li>Flatten outputs and labels into ONE LONG VECTOR.\n<li>Mask out outputs you don\u2019t want\n<li>Calculate cross-entropy on that.\n</li></li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Full Code:</h3>\n<p>\u00a0<br/>\n<script src=\"https://gist.github.com/williamFalcon/f27c7b90e34b4ba88ced042d9ef33edd.js\"></script></p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/wfalcon/\" rel=\"noopener noreferrer\" target=\"_blank\">William Falcon</a></b> is a PhD Candidate, AI, Neuroscience (NYU), and Co-Founder @Nextgenvest. He is a former Product Manager and iOS Eng. Prior at Goldman Sachs, Bonobos, Columbia.</p>\n<p><a href=\"https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/05/pytorch-tensor-basics.html\">PyTorch Tensor Basics</a>\n<li><a href=\"/2018/04/getting-started-pytorch-understanding-automatic-differentiation.html\">Getting Started with PyTorch Part 1: Understanding How Automatic Differentiation Works</a>\n<li><a href=\"/2017/10/guide-time-series-prediction-recurrent-neural-networks-lstms.html\">A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs)</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2018/06/generating-text-rnn-4-lines-code.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2018/06/data-lake-evolution-data-processing.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-2-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-3-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-4-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-5-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-6-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/best-data-visualization-techniques.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-mp-7-best-data-viz');\"><b>Best Data Visualization Techniques for small and large data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-1-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-2-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-3-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-4-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/04/data-visualization-python-matplotlib-seaborn.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-5-plt-sea-viz');\"><b>Data Visualization in Python: Matplotlib vs Seaborn</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-6-ts-intro');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-23-ms-7-recognize');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-delivering-trusted-ai-microsoft.html\">Delivering Trusted AI with DataRobot and Microsoft</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-ai-data-production-landscape.html\">AI and the data production landscape</a><li> <a href=\"https://www.kdnuggets.com/2019/04/most-desired-skill-data-science.html\">The most desired skill in data science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/projects-include-data-science-portfolio.html\">Projects to Include in a Data Science Portfolio</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rework-meet-worlds-leading-ai-deep-learning-experts.html\">Meet the World\u2019s Leading AI &amp; Deep Learning ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/problem-data-science-job-postings.html\">The problem with data science job postings</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2018/index.html\">2018</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/index.html\">Jun</a> \u00bb <a href=\"https://www.kdnuggets.com/2018/06/tutorials.html\">Tutorials, Overviews</a> \u00bb Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health (\u00a0<a href=\"/2018/n24.html\">18:n24</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1556325230\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.647 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-26 20:33:50 -->\n<!-- Compression = gzip -->", "content_tokenized": ["comment", "william", "falcon", "phd", "candid", "neurosci", "use", "pytorch", "have", "like", "experienc", "euphoria", "increas", "energi", "and", "may", "have", "even", "felt", "like", "walk", "the", "sun", "for", "bit", "life", "feel", "complet", "again", "that", "until", "tri", "have", "variables", "minibatch", "use", "rnns", "all", "hope", "not", "lost", "after", "read", "this", "back", "fantasi", "pytorch", "elop", "into", "the", "sunset", "while", "recurr", "network", "achiev", "new", "accuraci", "onli", "read", "about", "arxiv", "ninja", "skill", "develop", "how", "implement", "pytorch", "with", "variables", "sequenc", "each", "minibatch", "what", "packpaddedsequ", "and", "padpackedsequ", "pytorch", "mask", "pad", "token", "for", "backpropag", "through", "time", "version", "pad", "sentenc", "make", "all", "the", "same", "length", "packpaddedsequ", "run", "through", "use", "padpackedsequ", "flatten", "all", "output", "and", "label", "mask", "out", "pad", "output", "calcul", "crossentropi", "whi", "this", "hard", "and", "whi", "care", "speed", "and", "perform", "feed", "variabl", "length", "element", "into", "has", "been", "huge", "technic", "challeng", "which", "framework", "like", "pytorch", "have", "larg", "solv", "tensorflow", "also", "has", "nice", "abstract", "but", "veri", "veri", "veri", "involv", "furthermor", "the", "document", "unclear", "and", "exampl", "are", "too", "old", "proper", "this", "will", "speed", "train", "increas", "the", "accuraci", "gradient", "descent", "have", "better", "estim", "for", "the", "gradient", "from", "multipl", "exampl", "instead", "just", "although", "rnns", "are", "hard", "parallel", "becaus", "each", "step", "depend", "the", "previous", "step", "can", "get", "huge", "boost", "use", "minibatch", "sequenc", "tag", "while", "can", "help", "with", "justin", "bieber", "obsess", "won", "tell", "can", "help", "part", "speech", "tag", "favorit", "song", "sorri", "here", "exampl", "the", "model", "with", "the", "song", "sentenc", "too", "late", "now", "say", "sorri", "remov", "and", "model", "build", "data", "format", "while", "can", "ton", "format", "won", "for", "simplic", "let", "make", "this", "contriv", "batch", "data", "with", "differ", "size", "sequenc", "sentnumx", "too", "late", "now", "say", "sorri", "sentnumi", "sentnumx", "ooh", "ooh", "sentnumi", "sentnumx", "sorri", "yeah", "sentnumi", "sentnumx", "sentnumx", "sentnumx", "sentnumi", "sentnumi", "sentnumi", "when", "feed", "each", "sentenc", "the", "embed", "layer", "each", "word", "will", "map", "index", "need", "convert", "them", "list", "integ", "here", "map", "these", "sentenc", "their", "correspond", "vocabulari", "index", "map", "sentenc", "vocab", "vocab", "num", "num", "num", "too", "num", "late", "num", "now", "num", "say", "num", "sorri", "num", "ooh", "num", "yeah", "num", "fanci", "nest", "list", "comprehens", "vocab", "word", "for", "word", "sentenc", "for", "sentenc", "now", "look", "like", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "same", "for", "the", "classif", "label", "our", "case", "tag", "these", "won", "embed", "tag", "num", "num", "num", "num", "num", "num", "fanci", "nest", "list", "comprehens", "tag", "tag", "for", "tag", "sentenc", "for", "sentenc", "now", "look", "like", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "trick", "num", "make", "all", "sequenc", "the", "minibatch", "have", "the", "same", "length", "pad", "what", "box", "and", "has", "all", "differ", "length", "not", "our", "minibatch", "for", "pytorch", "thing", "need", "save", "the", "length", "each", "sequenc", "befor", "pad", "use", "this", "inform", "mask", "out", "the", "loss", "function", "import", "numpi", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "get", "the", "length", "each", "sentenc", "xlength", "for", "sentenc", "creat", "empti", "matrix", "with", "pad", "token", "padtoken", "vocab", "longests", "batchsiz", "paddedx", "padtoken", "copi", "over", "the", "actual", "sequenc", "for", "xlen", "sequenc", "paddedx", "num", "xlen", "sequenc", "xlen", "paddedx", "look", "like", "the", "same", "for", "the", "tag", "import", "numpi", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "num", "get", "the", "length", "each", "sentenc", "ylength", "for", "sentenc", "creat", "empti", "matrix", "with", "pad", "token", "padtoken", "tag", "longests", "batchsiz", "paddedi", "padtoken", "copi", "over", "the", "actual", "sequenc", "for", "ylen", "sequenc", "paddedi", "num", "ylen", "sequenc", "ylen", "paddedi", "look", "like", "data", "process", "summari", "turn", "word", "into", "sequenc", "index", "and", "pad", "each", "sequenc", "with", "zero", "the", "batch", "could", "all", "the", "same", "size", "our", "data", "now", "look", "like", "the", "model", "make", "veri", "simpl", "network", "use", "pytorch", "the", "layer", "will", "embed", "linear", "softmax", "trick", "num", "how", "use", "pytorch", "packpaddedsequ", "and", "padpackedsequ", "recap", "are", "now", "feed", "batch", "where", "each", "element", "alreadi", "the", "forward", "pass", "emb", "the", "sequenc", "use", "packpaddedsequ", "make", "sure", "the", "won", "see", "the", "pad", "item", "run", "the", "packedbatch", "into", "the", "undo", "the", "pack", "use", "padpackedsequ", "transform", "the", "lstm", "output", "can", "feed", "linear", "layer", "run", "through", "logsoftmax", "convert", "shape", "back", "finish", "with", "batchsiz", "seqlen", "nbtag", "trick", "num", "mask", "out", "network", "output", "want", "consid", "our", "loss", "function", "mask", "out", "those", "pad", "activ", "final", "readi", "calcul", "the", "loss", "function", "the", "main", "point", "here", "that", "want", "take", "into", "account", "the", "network", "output", "for", "pad", "element", "intuit", "alert", "best", "way", "think", "about", "this", "network", "output", "label", "then", "calcul", "the", "loss", "that", "sequenc", "waaaaaaaa\u2026", "that", "easi", "now", "can", "train", "model", "faster", "with", "minibatch", "and", "get", "back", "obsess", "over", "still", "won", "tell", "worri", "know", "how", "feel", "now\u2026", "this", "cours", "veri", "barebon", "thing", "can", "fanci", "model", "not", "comprehens", "initi", "with", "glove", "embed", "use", "cell", "use", "bidirect", "mechan", "forget", "modifi", "inithidden", "use", "charact", "level", "featur", "creat", "encod", "vector", "with", "convolut", "network", "and", "append", "the", "word", "vector", "add", "dropout", "increas", "number", "layer", "soooo", "much", "more", "and", "cours", "veri", "thorough", "hyperparamet", "search", "use", "the", "best", "hyperparemet", "optim", "librari", "for", "python", "testtub", "disclaim", "wrote", "testtub", "summari", "this", "how", "get", "saniti", "back", "pytorch", "with", "variabl", "length", "batch", "input", "sort", "input", "largest", "sequenc", "first", "make", "all", "the", "same", "length", "pad", "largest", "sequenc", "the", "batch", "use", "packpaddedsequ", "make", "sure", "see", "pad", "item", "facebook", "team", "realli", "should", "renam", "this", "undo", "step", "num", "with", "padpackedsequ", "flatten", "output", "and", "label", "into", "mask", "out", "output", "want", "calcul", "crossentropi", "that", "full", "code", "bio", "william", "falcon", "phd", "candid", "neurosci", "and", "cofound", "nextgenvest", "former", "product", "manag", "and", "eng", "prior", "goldman", "sach", "bonobo", "columbia", "origin", "repost", "with", "permiss", "relat", "pytorch", "tensor", "basic", "get", "start", "with", "pytorch", "part", "num", "understand", "how", "automat", "differenti", "work", "guid", "for", "time", "seri", "predict", "use", "recurr", "neural", "network", "lstms"], "timestamp_scraper": 1556368249.927609, "title": "Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health", "read_time": 380.09999999999997, "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/wfalcon/\" rel=\"noopener noreferrer\" target=\"_blank\">William Falcon</a>, PhD Candidate, AI, Neuroscience (NYU)</b></p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/1*_odqFvts1GBGFgddcmcGvg.gif\" width=\"50%\"/></p>\n<p>If you\u2019ve used PyTorch you have likely experienced euphoria, increased energy and may have even felt like walking in the sun for a bit. Your life feels complete again. That is, until you tried to have variable-sized mini-batches using RNNs.</p>\n<p><strong>All hope is not lost</strong>. After reading this, you\u2019ll be back to fantasies of you + PyTorch eloping into the sunset while your Recurrent Networks achieve new accuracies you\u2019ve only read about on Arxiv.</p>\n<p><strong>Ninja skills we\u2019ll develop:</strong></p>\n<ol>\n<li>How to implement an LSTM in PyTorch with variable-sized sequences in each mini-batch.\n<li>What\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pack_padded_sequence</a>\u00a0and\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pad_packed_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pad_packed_sequence</a>\u00a0do in PyTorch.\n<li>Masking padded tokens for\u00a0<a href=\"https://en.wikipedia.org/wiki/Backpropagation_through_time\" rel=\"noopener noreferrer\" target=\"_blank\">back-propagation through time</a>.\n</li></li></li></ol>\n<p>\u00a0</p>\n<blockquote><p><strong>TL;DR version</strong>: Pad sentences, make all the same length,\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pack_padded_sequence</a>, run through LSTM, use\u00a0<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pad_packed_sequence\" rel=\"noopener noreferrer\" target=\"_blank\">pad_packed_sequence</a>, flatten all outputs and label, mask out padded outputs, calculate cross-entropy.</p></blockquote>\n<p>\u00a0</p>\n<h3>Why is this so hard and why do I\u00a0care?</h3>\n<p>\u00a0<br>\nSpeed and Performance.</br></p>\n<p>Feeding variable length elements at ONCE into an LSTM has been a huge technical challenge which frameworks like PyTorch have largely solved (Tensorflow also has a nice abstraction but it\u2019s very very very involved).</p>\n<p>Furthermore, the documentation is unclear and examples are too old. Properly doing this will speed up training AND increase the accuracy of gradient descent by having a better estimator for the gradients from multiple examples instead of just ONE.</p>\n<p>Although RNNs are hard to parallelize because each step depends on the previous step, we can get a huge boost by using mini-batches.</p>\n<p>\u00a0</p>\n<h3><strong>Sequence Tagging</strong></h3>\n<p>\u00a0<br>\nWhile I can\u2019t help you with your Justin Bieber obsession (I won\u2019t tell), I can help you do part of speech tagging on your favorite JB song,\u00a0<a href=\"https://www.youtube.com/watch?v=fRh_vgS2dFE\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Sorry</em></a>.</br></p>\n<p>Here\u2019s an example of the model with the song sentence: \u201cis it too late now to say sorry?\u201d (removed \u2018<strong>to\u2019</strong>\u00a0and \u2018<strong>?\u2019</strong>\u00a0).</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/1000/1*wf9iOTO853P5ewjPX079RQ.png\" width=\"99%\"/><br>\n<font size=\"-1\">LSTM/GRU model we\u2019re\u00a0building</font></br></center></p>\n<p>\u00a0</p>\n<h3><strong>Data Formatting</strong></h3>\n<p>\u00a0<br>\nWhile you can do a ton of formatting, we won\u2019t... For simplicity, let\u2019s make this contrived batch of data with different sized sequences.</br></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>sent_1_x = ['is', 'it', 'too', 'late', 'now', 'say', 'sorry']\r\nsent_1_y = ['VB', 'PRP', 'RB', 'RB', 'RB', 'VB', 'JJ']\r\n\r\nsent_2_x = ['ooh', 'ooh']\r\nsent_2_y = ['NNP', 'NNP']\r\n\r\nsent_3_x = ['sorry', 'yeah']\r\nsent_3_y = ['JJ', 'NNP']\r\n\r\nX = [sent_1_x, sent_2_x, sent_3_x]\r\nY = [sent_1_y, sent_2_y, sent_3_y]</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>When we feed each sentence to the embedding layer, each word will map to an index, so we need to convert them to list of integers.</p>\n<p><center><img src=\"https://cdn-images-1.medium.com/max/800/1*Y29f-F-HVDUSJMGzU3LdRg.png\" width=\"80%\"/><br/>\n<font size=\"-1\">Here we map these sentences to their corresponding vocabulary index</font></center></p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># map sentences to vocab\r\nvocab = {'<pad>': 0, 'is': 1, 'it': 2, 'too': 3, 'late': 4, 'now': 5, 'say': 6, 'sorry': 7, 'ooh': 8, 'yeah': 9} \r\n\r\n# fancy nested list comprehension\r\nX =  [[vocab[word] for word in sentence] for sentence in X]\r\n\r\n# X now looks like:  \r\n# [[1, 2, 3, 4, 5, 6, 7], [8, 8], [7, 9]]</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>Same for the classification labels (in our case POS tags). These won\u2019t be embedded.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>tags = {'<pad>': 0, 'VB': 1, 'PRP': 2, 'RB': 3, 'JJ': 4, 'NNP': 5}\r\n\r\n# fancy nested list comprehension\r\nY =  [[tags[tag] for tag in sentence] for sentence in Y]\r\n\r\n# Y now looks like:\r\n# [[1, 2, 3, 3, 3, 1, 4], [5, 5], [4, 5]]</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3><strong>Trick 1: Make all sequences in the mini-batch have the same length by\u00a0padding.</strong></h3>\n<p>\u00a0<br/>\nWhat is in a box and has all different lengths? Not our mini-batch!</p>\n<p>For PyTorch to do its thing, we need to save the lengths of each sequence before we pad. We\u2019ll use this information to mask out the loss function.</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import numpy as np\r\n\r\nX = [[0, 1, 2, 3, 4, 5, 6], \r\n    [7, 7], \r\n    [6, 8]]\r\n\r\n# get the length of each sentence\r\nX_lengths = [len(sentence) for sentence in X]\r\n\r\n# create an empty matrix with padding tokens\r\npad_token = vocab['<pad>']\r\nlongest_sent = max(X_lengths)\r\nbatch_size = len(X)\r\npadded_X = np.ones((batch_size, longest_sent)) * pad_token\r\n\r\n# copy over the actual sequences\r\nfor i, x_len in enumerate(X_lengths):\r\n  sequence = X[i]\r\n  padded_X[i, 0:x_len] = sequence[:x_len]\r\n\r\n# padded_X looks like:\r\narray([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.],\r\n       [ 8.,  8.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 7.,  9.,  0.,  0.,  0.,  0.,  0.]])</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>We do the same for the tags:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre>import numpy as np\r\n\r\nY = [[1, 2, 3, 3, 3, 1, 4], \r\n    [5, 5], \r\n    [4, 5]]\r\n\r\n# get the length of each sentence\r\nY_lengths = [len(sentence) for sentence in Y]\r\n\r\n# create an empty matrix with padding tokens\r\npad_token = tags['<pad>']\r\nlongest_sent = max(Y_lengths)\r\nbatch_size = len(Y)\r\npadded_Y = np.ones((batch_size, longest_sent)) * pad_token\r\n\r\n# copy over the actual sequences\r\nfor i, y_len in enumerate(Y_lengths):\r\n  sequence = Y[i]\r\n  padded_Y[i, 0:y_len] = sequence[:y_len]\r\n\r\n# padded_Y looks like:\r\narray([[ 1.,  2.,  3.,  3.,  3.,  1.,  4.],\r\n       [ 5.,  5.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 4.,  5.,  0.,  0.,  0.,  0.,  0.]])</pad></pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p><strong>Data processing summary:</strong></p>\n<p>We turned words into sequences of indexes and padded each sequence with a zero so the batch could all be the same size. Our data now look like:</p>\n<div style=\"width:98%;border:1px solid #ccc; overflow:auto; padding-left:10px; padding-bottom:10px; padding-top:10px\">\n<pre># X \r\narray([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.],\r\n       [ 8.,  8.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 7.,  9.,  0.,  0.,  0.,  0.,  0.]])\r\n\r\n# Y \r\narray([[ 1.,  2.,  3.,  3.,  3.,  1.,  4.],\r\n       [ 5.,  5.,  0.,  0.,  0.,  0.,  0.],\r\n       [ 4.,  5.,  0.,  0.,  0.,  0.,  0.]])</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>\u00a0</p>\n<h3>The model</h3>\n<p>\u00a0<br/>\nWe\u2019ll make a very simple LSTM network using PyTorch. The layers will be:</p>\n<ol>\n<li>Embedding\n<li>LSTM\n<li>Linear\n<li>Softmax\n</li></li></li></li></ol>\n<p><script src=\"https://gist.github.com/williamFalcon/f75b01b47bf1be8b1e80be173ebdf39c.js\"></script></p>\n<p>\u00a0</p>\n<h3>Trick 2: How to use PyTorch pack_padded_sequence and pad_packed_sequence</h3>\n<p>\u00a0<br/>\nTo recap, we are now feeding a batch where each element HAS BEEN PADDED already. In the forward pass we\u2019ll:</p>\n<ol>\n<li>Embed the sequences\n<li>Use pack_padded_sequence to make sure the LSTM won\u2019t see the padded items\n<li>Run the packed_batch into the LSTM\n<li>Undo the packing by using pad_packed_sequence\n<li>Transform the lstm output so we can feed to linear layer\n<li>Run through log_softmax\n<li>Convert shape back so we finish with (batch_size, seq_len, nb_tags)\n</li></li></li></li></li></li></li></ol>\n<p><script src=\"https://gist.github.com/williamFalcon/b0dc6d25b39e7da0d05e5713ef0a57af.js\"></script></p>\n<p>\u00a0</p>\n<h3>Trick 3: Mask out network outputs we don\u2019t want to consider in our loss\u00a0function</h3>\n<p>\u00a0<br/>\n<center><img src=\"https://cdn-images-1.medium.com/max/800/1*3U8qtLOIee4TV7mtv-nJvA.jpeg\" width=\"75%\"/><br/>\n<font size=\"-1\">Mask out those padded activations</font></center></p>\n<p>Finally, we\u2019re ready to calculate the loss function. The main point here is that we don\u2019t want to take into account the network output for padded elements.</p>\n<p><strong>Intuition alert:\u00a0</strong>Best way to think about doing this is to FLATTEN ALL network outputs AND labels. Then calculate the loss on that ONE sequence.</p>\n<p><script src=\"https://gist.github.com/williamFalcon/42da07d5cea5d00151f9cfde30f092b6.js\"></script></p>\n<p>Waaaaaaaa\u2026 It\u2019s that easy. Now you can train your model MUCH faster with mini-batches and get back to obsessing over JB (still won\u2019t tell, don\u2019t worry).<br/>\nI know how you\u2019re feeling now\u2026</p>\n<p><img class=\"aligncenter\" src=\"https://cdn-images-1.medium.com/max/800/1*SmFYrU8wxx9P7PIkzsEusQ.gif\" width=\"50%\"/></p>\n<p>This is of course a very barebones LSTM. Things you can do to fancy up your model (not comprehensive):</p>\n<ol>\n<li>Initialize with Glove embeddings.\n<li>Use GRU cell.\n<li>Use Bidirectional mechanism (don\u2019t forget to modify init_hidden).\n<li>Use character level features by creating an encoding vector with a Convolutional network and appending to the word vector.\n<li>Add dropout.\n<li>Increase number of layers\n<li>\u2026 soooo much more\n<li>And of course, a very thorough hyper-parameter search using the best hyperparemeter optimization library for Python:\u00a0<a href=\"https://github.com/williamFalcon/test_tube\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>test-tube</strong></a><strong>\u00a0</strong>(disclaimer: I wrote test-tube).\n</li></li></li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>In Summary:</h3>\n<p>\u00a0<br/>\nThis is how you get your sanity back in PyTorch with variable length batched inputs to an LSTM</p>\n<ol>\n<li>Sort inputs by largest sequence first\n<li>Make all the same length by padding to largest sequence in the batch\n<li>Use pack_padded_sequence to make sure LSTM doesn\u2019t see padded items (Facebook team, you really should rename this API).\n<li>Undo step 3 with pad_packed_sequence.\n<li>Flatten outputs and labels into ONE LONG VECTOR.\n<li>Mask out outputs you don\u2019t want\n<li>Calculate cross-entropy on that.\n</li></li></li></li></li></li></li></ol>\n<p>\u00a0</p>\n<h3>Full Code:</h3>\n<p>\u00a0<br/>\n<script src=\"https://gist.github.com/williamFalcon/f27c7b90e34b4ba88ced042d9ef33edd.js\"></script></p>\n<p>\u00a0<br/>\n<b>Bio: <a href=\"https://www.linkedin.com/in/wfalcon/\" rel=\"noopener noreferrer\" target=\"_blank\">William Falcon</a></b> is a PhD Candidate, AI, Neuroscience (NYU), and Co-Founder @Nextgenvest. He is a former Product Manager and iOS Eng. Prior at Goldman Sachs, Bonobos, Columbia.</p>\n<p><a href=\"https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\" rel=\"noopener noreferrer\" target=\"_blank\">Original</a>. Reposted with permission.</p>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"/2018/05/pytorch-tensor-basics.html\">PyTorch Tensor Basics</a>\n<li><a href=\"/2018/04/getting-started-pytorch-understanding-automatic-differentiation.html\">Getting Started with PyTorch Part 1: Understanding How Automatic Differentiation Works</a>\n<li><a href=\"/2017/10/guide-time-series-prediction-recurrent-neural-networks-lstms.html\">A Guide For Time Series Prediction Using Recurrent Neural Networks (LSTMs)</a>\n</li></li></li></ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets';\n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "website": "kdnuggets"}