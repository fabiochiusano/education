{"content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/zlipton\" rel=\"author\" title=\"Posts by Zachary Chase Lipton\">Zachary Chase Lipton</a>, UCSD.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"/2016/11/foundations-algorithmic-bias.html/3#comments\">comments</a></div>\n<p><em>Reposted with permission from <a href=\"http://approximatelycorrect.com/2016/11/07/the-foundations-of-algorithmic-bias/\">approximatelycorrect.com</a><br>\n</br></em></p>\n<p>This morning, millions of people woke up and impulsively checked Facebook.\u00a0They were greeted immediately by content curated by Facebook\u2019s newsfeed algorithms.\u00a0To\u00a0some degree, this news might have influenced their perceptions of the day\u2019s news,\u00a0the economy\u2019s outlook, and the state of the election.\u00a0Every year, millions of people apply for jobs.\u00a0Increasingly, their success might lie, in part, in the hands of computer programs\u00a0tasked with matching applications to job openings. And every year, roughly 12 million people are arrested. Throughout the criminal justice system, computer-generated risk-assessments are used to determine which arrestees should be set free.\u00a0In all these situations, algorithms are tasked with making decisions.</p>\n<p><img alt=\"Courts deploy computerized algorithms\" class=\"aligncenter\" src=\"http://approximatelycorrect.com/wp-content/uploads/futurama-judge.png\" width=\"70%\"/></p>\n<p>Algorithmic decision-making mediates more and more of our interactions,\u00a0influencing our social experiences, the news we see, our finances, and our career opportunities.\u00a0We task computer programs with approving lines of credit,\u00a0curating news, and filtering job applicants.\u00a0Courts even deploy computerized algorithms to predict \u201crisk of recidivism\u201d,\u00a0the probability that an individual relapses into criminal behavior.\u00a0It seems likely that this\u00a0trend\u00a0will only accelerate as breakthroughs in artificial intelligence\u00a0rapidly broadened the capabilities of software.</p>\n<p>Turning decision-making over to algorithms naturally raises worries about our ability\u00a0to assess and enforce the neutrality of these new decision makers.\u00a0How can we be sure that the algorithmically curated news doesn\u2019t have a political party bias\u00a0or job listings don\u2019t reflect a gender or racial bias?\u00a0What other biases might our automated processes be exhibiting that that we wouldn\u2019t even know to look for?</p>\n<p>The rise of machine learning complicates these concerns.\u00a0Traditional software is typically composed from simple, hand-coded logic rules.\u00a0IF condition X holds THEN perform action Y<i>. \u00a0</i>But machine learning relies on complex statistical models to discover patterns in large datasets. Take loan approval for instance.\u00a0Given\u00a0years of credit history and other side information, a machine learning algorithm might then output a probability that the applicant will default. \u00a0The logic behind this assessment wouldn\u2019t be coded by hand.\u00a0Instead, the model would extrapolate from the records of thousands or millions of other customers.</p>\n<p>On highly specialized problems, and given enough data,\u00a0machine learning algorithms can often make predictions with near-human or super-human accuracy.\u00a0But it\u2019s often hard to say precisely why a decision was made.\u00a0So how can we ensure that these decisions don\u2019t encode bias? How can we ensure that giving these algorithms decision-making power doesn\u2019t amount to a breach of\u00a0ethics?\u00a0The potential for prejudice hasn\u2019t gone under the radar.\u00a0In the last year alone,\u00a0<a href=\"https://www.technologyreview.com/s/601775/why-we-should-expect-algorithms-to-be-biased/\">MIT Technology Review</a>\u00a0[1],\u00a0<a href=\"https://www.theguardian.com/commentisfree/2016/jun/26/algorithms-racial-bias-offenders-florida\">the Guardian</a>\u00a0[2],\u00a0and the\u00a0<a href=\"http://www.nytimes.com/2016/05/19/opinion/the-real-bias-built-in-at-facebook.html\">New York Times</a>\u00a0[3],\u00a0all published thought pieces cautioning against algorithmic bias. Some of\u00a0the best coverage has come from ProPublica, which\u00a0<a href=\"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\">quantitatively studied racial bias in a widely used \u00a0criminal risk-assessment score</a>\u00a0[4].</p>\n<p>Each article counters the notion that algorithms are necessarily objective.\u00a0Technology Review invokes Fred Berenson\u2019s assertion\u00a0that we are susceptible to \u2018mathwashing\u2019.\u00a0That is, we tend to (misguidedly) assume that any system built with complex mathematics\u00a0at its core must somehow be objective, devoid of the biases that plague human decision-making.</p>\n<p>Alas, the public discourse rarely throws light on\u00a0the precise mechanisms by which bias actually enters algorithmic decision-making processes.\u00a0Tech Review for example, points to the abundance of men working in computer science without explaining how this might alter the behavior of their algorithms.\u00a0You might think that the bias seeped through via the air filtration system.\u00a0The Guardian makes a compelling argument that the \u201crecidivism\u201d predictor encodes racial bias, producing evidence to support the claim.\u00a0But they never discuss how this came to be,\u00a0describing the algorithms simply as black boxes.\u00a0Similarly, the New York Times piece calls attention to bias and to the opacity of FaceBook algorithms for new curation,\u00a0but doesn\u2019t elucidate the precise mechanisms by which undesirable outcomes manifest. Admirably, in the\u00a0ProPublica piece,\u00a0author Julia Adwin\u00a0sought the risk-assessment algorithm itself, but software-company Northpointe would not share the precise proprietary formula.</p>\n<p>It\u2019s encouraging that these pieces have helped to spark a global conversation\u00a0about the responsibilities of programmatic decision-makers.\u00a0However, the mystical quality of the discussion threatens to stymie progress.\u00a0If we don\u2019t know how algorithms can become biased, how can we know when to suspect them?\u00a0Moreover, without this understanding, how can we hope to counteract the bias?</p>\n<p>To bring some rigor to the dialogue, let\u2019s first run through a crash-course on what algorithms are, how they make\u00a0decisions, and where machine learning enters the picture.\u00a0Armed with this information, we\u2019ll then introduce a catalogue\u00a0of fundamental ways that things can go wrong.</p>\n<p><strong>[ALGORITHMS]</strong></p>\n<p>To start, let\u2019s briefly explain\u00a0<i>algorithms</i>.\u00a0Algorithms are the instructions that tell your computer precisely how to accomplish some task. \u00a0Typically, this means how to take some input and producing some output.\u00a0The software that takes two addresses on a map and returns the shortest route between them is an algorithm.\u00a0So is the method that doctors use to calculate cardiac risk.\u00a0This particular algorithm takes the age, blood pressure, smoking status, and a few other inputs,\u00a0combines them according to a precise formula, and outputs the risk of a cardiovascular event.</p>\n<p>Compared to\u00a0these simple examples, many of the algorithms at the heart of technologies like self-driving cars and recommender systems\u00a0are\u00a0considerably more complex, containing many instructions, advanced mathematical operations, and complicated logic. Sometimes, the line between an algorithm and what might better be described as a complex software systems can become blurred.</p>\n<p>Consider the algorithms behind Google\u2019s search service.\u00a0From the outside it might appear to be monolithic,\u00a0but it\u2019s actually a complex software system,\u00a0encompassing multiple sub-algorithms, each of which may be maintained by large teams of engineers and scientists and consisting of millions of lines of code.</p>\n<p>There\u2019s little that can be said universally about algorithms.\u00a0Collectively, they\u2019re neither racist nor neutral, fast nor slow, sentient nor insensate.\u00a0If you could\u00a0simulate\u00a0your\u00a0brain\u00a0with a computer program, perfectly capturing the behavior of each neuron, that program would itself be an\u00a0algorithm. So, in\u00a0an important sense, there\u2019s nothing fundamentally special about algorithmic decisions.\u00a0In any situation in which human decisions might exhibit bias, so might those made by computerized algorithms.\u00a0One\u00a0important difference between human and algorithmic bias might be that\u00a0for humans, we\u00a0know to suspect bias, and\u00a0we have some intuition for what sorts of bias to expect.</p>\n<p>To dispense with any doubt that an algorithm might encode bias,\u00a0consider the following rule for extending a line of credit:\u00a0<i>If race=white THEN approve loan ELSE deny</i>.\u00a0This program, however simple, constitutes an algorithm and yet reflects an obvious bias.\u00a0Of course, this explicit racism might be easy to detect\u00a0and straightforward to challenge legally.\u00a0Deciphering its logic doesn\u2019t require formidable expertise.</p>\n<p>But today\u2019s large-scale software and machine-learning systems can grow opaque.\u00a0Even the programmer of a system might struggle to say why precisely makes any individual system.\u00a0For complex algorithms, biases may exist, but detecting the bias, identifying its cause, and correcting may not always be straightforward. Nevertheless, there exist some common patterns for how\u00a0bias can\u00a0creep into systems.\u00a0Understanding these patterns may\u00a0prove vital to guarding against preventable problems.</p>\n<p><strong>[MACHINE LEARNING]</strong></p>\n<p>Now let\u2019s review the basics of machine learning.\u00a0Machine learning refers to powerful set of techniques for building algorithms that improve as a function of experience.\u00a0The field of machine learning addresses a broad class of problems and algorithmic solutions\u00a0but we\u2019re going to focus on supervised learning, the kind directly concerned with pattern recognition and \u00a0predictive modelling.</p>\n<p>Most machine learning in the wild today consists of supervised learning.\u00a0When Facebook recognizes your face in a photograph, when your mailbox filters spam, and when your bank predicts default risk \u2013 these are all examples of supervised machine learning in action.</p>\n<p>We use machine learning because sometimes it\u2019s impossible to specify\u00a0a\u00a0good enough program a priori.\u00a0Let\u2019s say you wanted to build a\u00a0spam filter.\u00a0You might be tempted to implement a rule-based system with a blacklist of particularly spammy \u00a0words.\u00a0Is any email referring to \u201cWestern Union\u201d spam?\u00a0Perhaps. But even so, that only describes a small percentage of spam.\u00a0There\u2019s still the solicitations from illegal drug companies,\u00a0pornographic sites, and the legendary Nigerian prince who wants to wire you millions of dollars.</p>\n<p>Suppose now that through herculean effort you produced a perfect spam filter,\u00a0cobbling together 1000s of consistent rules to cover all the known cases of spam while letting all legitimate email pass through.\u00a0As soon as you\u2019d completed this far-fetched feat and secured some well-deserved sleep,\u00a0you\u2019d wake up to find that the spam filter no longer worked as well.\u00a0The spammers would have invented new varieties of spam, invalidating all your hard work.</p>\n<p>Machine learning proposes an alternative way to deal with these problems.\u00a0Even if we can\u2019t specify precisely what constitutes spam, we might know it when we see it.\u00a0Instead of coming up with the exact solution ourselves by enumerating rules,\u00a0we can compile a large dataset containing emails known either to be spam or to be safe.\u00a0The dataset might consist of millions of emails,\u00a0each of which would be characterized by a large number of attributes and annotated according to whether it\u2019s believed (by a human) to actually spam or not.\u00a0Typical attributes might include the words themselves, the time the email was sent, the email address, server, and domain from which it was sent, and statistics about previous correspondence with this address.</p>\n</div> ", "url": "https://www.kdnuggets.com/2016/11/foundations-algorithmic-bias.html", "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  The Foundations of Algorithmic Bias</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2016/11/foundations-algorithmic-bias.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb The Foundations of Algorithmic Bias Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/16/11-16-cmu-teaching-faculty.html\" rel=\"prev\" title=\"CMU: Teaching Faculty, Machine Learning\"/>\n<link href=\"https://www.kdnuggets.com/2016/11/top-tweets-nov09-15.html\" rel=\"next\" title=\"Top KDnuggets tweets, Nov 9-15: #Trump, limits of #prediction; #TensorFlow French-to-English machine translation\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2016/11/foundations-algorithmic-bias.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=58294\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2016/11/foundations-algorithmic-bias.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-58294 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 16-Nov, 2016  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/opinions-interviews.html\">Opinions, Interviews</a> \u00bb The Foundations of Algorithmic Bias (\u00a0<a href=\"/2016/n42.html\">16:n42</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">The Foundations of Algorithmic Bias</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/16/11-16-cmu-teaching-faculty.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/11/top-tweets-nov09-15.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <span class=\"http-likes\" style=\"float: left; font-size:14px\">http likes 57</span> <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/algorithms\" rel=\"tag\">Algorithms</a>, <a href=\"https://www.kdnuggets.com/tag/bias\" rel=\"tag\">Bias</a>, <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/facebook\" rel=\"tag\">Facebook</a>, <a href=\"https://www.kdnuggets.com/tag/google\" rel=\"tag\">Google</a>, <a href=\"https://www.kdnuggets.com/tag/image-recognition\" rel=\"tag\">Image Recognition</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a>, <a href=\"https://www.kdnuggets.com/tag/zachary-lipton\" rel=\"tag\">Zachary Lipton</a></div>\n<br/>\n<p class=\"excerpt\">\n     We might hope that algorithmic decision making would be free of biases. But increasingly, the public is starting to realize that machine learning systems can exhibit these same biases and more. In this post, we look at precisely how that happens. \n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/zlipton\" rel=\"author\" title=\"Posts by Zachary Chase Lipton\">Zachary Chase Lipton</a>, UCSD.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/><a href=\"/2016/11/foundations-algorithmic-bias.html/3#comments\">comments</a></div>\n<p><em>Reposted with permission from <a href=\"http://approximatelycorrect.com/2016/11/07/the-foundations-of-algorithmic-bias/\">approximatelycorrect.com</a><br>\n</br></em></p>\n<p>This morning, millions of people woke up and impulsively checked Facebook.\u00a0They were greeted immediately by content curated by Facebook\u2019s newsfeed algorithms.\u00a0To\u00a0some degree, this news might have influenced their perceptions of the day\u2019s news,\u00a0the economy\u2019s outlook, and the state of the election.\u00a0Every year, millions of people apply for jobs.\u00a0Increasingly, their success might lie, in part, in the hands of computer programs\u00a0tasked with matching applications to job openings. And every year, roughly 12 million people are arrested. Throughout the criminal justice system, computer-generated risk-assessments are used to determine which arrestees should be set free.\u00a0In all these situations, algorithms are tasked with making decisions.</p>\n<p><img alt=\"Courts deploy computerized algorithms\" class=\"aligncenter\" src=\"http://approximatelycorrect.com/wp-content/uploads/futurama-judge.png\" width=\"70%\"/></p>\n<p>Algorithmic decision-making mediates more and more of our interactions,\u00a0influencing our social experiences, the news we see, our finances, and our career opportunities.\u00a0We task computer programs with approving lines of credit,\u00a0curating news, and filtering job applicants.\u00a0Courts even deploy computerized algorithms to predict \u201crisk of recidivism\u201d,\u00a0the probability that an individual relapses into criminal behavior.\u00a0It seems likely that this\u00a0trend\u00a0will only accelerate as breakthroughs in artificial intelligence\u00a0rapidly broadened the capabilities of software.</p>\n<p>Turning decision-making over to algorithms naturally raises worries about our ability\u00a0to assess and enforce the neutrality of these new decision makers.\u00a0How can we be sure that the algorithmically curated news doesn\u2019t have a political party bias\u00a0or job listings don\u2019t reflect a gender or racial bias?\u00a0What other biases might our automated processes be exhibiting that that we wouldn\u2019t even know to look for?</p>\n<p>The rise of machine learning complicates these concerns.\u00a0Traditional software is typically composed from simple, hand-coded logic rules.\u00a0IF condition X holds THEN perform action Y<i>. \u00a0</i>But machine learning relies on complex statistical models to discover patterns in large datasets. Take loan approval for instance.\u00a0Given\u00a0years of credit history and other side information, a machine learning algorithm might then output a probability that the applicant will default. \u00a0The logic behind this assessment wouldn\u2019t be coded by hand.\u00a0Instead, the model would extrapolate from the records of thousands or millions of other customers.</p>\n<p>On highly specialized problems, and given enough data,\u00a0machine learning algorithms can often make predictions with near-human or super-human accuracy.\u00a0But it\u2019s often hard to say precisely why a decision was made.\u00a0So how can we ensure that these decisions don\u2019t encode bias? How can we ensure that giving these algorithms decision-making power doesn\u2019t amount to a breach of\u00a0ethics?\u00a0The potential for prejudice hasn\u2019t gone under the radar.\u00a0In the last year alone,\u00a0<a href=\"https://www.technologyreview.com/s/601775/why-we-should-expect-algorithms-to-be-biased/\">MIT Technology Review</a>\u00a0[1],\u00a0<a href=\"https://www.theguardian.com/commentisfree/2016/jun/26/algorithms-racial-bias-offenders-florida\">the Guardian</a>\u00a0[2],\u00a0and the\u00a0<a href=\"http://www.nytimes.com/2016/05/19/opinion/the-real-bias-built-in-at-facebook.html\">New York Times</a>\u00a0[3],\u00a0all published thought pieces cautioning against algorithmic bias. Some of\u00a0the best coverage has come from ProPublica, which\u00a0<a href=\"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\">quantitatively studied racial bias in a widely used \u00a0criminal risk-assessment score</a>\u00a0[4].</p>\n<p>Each article counters the notion that algorithms are necessarily objective.\u00a0Technology Review invokes Fred Berenson\u2019s assertion\u00a0that we are susceptible to \u2018mathwashing\u2019.\u00a0That is, we tend to (misguidedly) assume that any system built with complex mathematics\u00a0at its core must somehow be objective, devoid of the biases that plague human decision-making.</p>\n<p>Alas, the public discourse rarely throws light on\u00a0the precise mechanisms by which bias actually enters algorithmic decision-making processes.\u00a0Tech Review for example, points to the abundance of men working in computer science without explaining how this might alter the behavior of their algorithms.\u00a0You might think that the bias seeped through via the air filtration system.\u00a0The Guardian makes a compelling argument that the \u201crecidivism\u201d predictor encodes racial bias, producing evidence to support the claim.\u00a0But they never discuss how this came to be,\u00a0describing the algorithms simply as black boxes.\u00a0Similarly, the New York Times piece calls attention to bias and to the opacity of FaceBook algorithms for new curation,\u00a0but doesn\u2019t elucidate the precise mechanisms by which undesirable outcomes manifest. Admirably, in the\u00a0ProPublica piece,\u00a0author Julia Adwin\u00a0sought the risk-assessment algorithm itself, but software-company Northpointe would not share the precise proprietary formula.</p>\n<p>It\u2019s encouraging that these pieces have helped to spark a global conversation\u00a0about the responsibilities of programmatic decision-makers.\u00a0However, the mystical quality of the discussion threatens to stymie progress.\u00a0If we don\u2019t know how algorithms can become biased, how can we know when to suspect them?\u00a0Moreover, without this understanding, how can we hope to counteract the bias?</p>\n<p>To bring some rigor to the dialogue, let\u2019s first run through a crash-course on what algorithms are, how they make\u00a0decisions, and where machine learning enters the picture.\u00a0Armed with this information, we\u2019ll then introduce a catalogue\u00a0of fundamental ways that things can go wrong.</p>\n<p><strong>[ALGORITHMS]</strong></p>\n<p>To start, let\u2019s briefly explain\u00a0<i>algorithms</i>.\u00a0Algorithms are the instructions that tell your computer precisely how to accomplish some task. \u00a0Typically, this means how to take some input and producing some output.\u00a0The software that takes two addresses on a map and returns the shortest route between them is an algorithm.\u00a0So is the method that doctors use to calculate cardiac risk.\u00a0This particular algorithm takes the age, blood pressure, smoking status, and a few other inputs,\u00a0combines them according to a precise formula, and outputs the risk of a cardiovascular event.</p>\n<p>Compared to\u00a0these simple examples, many of the algorithms at the heart of technologies like self-driving cars and recommender systems\u00a0are\u00a0considerably more complex, containing many instructions, advanced mathematical operations, and complicated logic. Sometimes, the line between an algorithm and what might better be described as a complex software systems can become blurred.</p>\n<p>Consider the algorithms behind Google\u2019s search service.\u00a0From the outside it might appear to be monolithic,\u00a0but it\u2019s actually a complex software system,\u00a0encompassing multiple sub-algorithms, each of which may be maintained by large teams of engineers and scientists and consisting of millions of lines of code.</p>\n<p>There\u2019s little that can be said universally about algorithms.\u00a0Collectively, they\u2019re neither racist nor neutral, fast nor slow, sentient nor insensate.\u00a0If you could\u00a0simulate\u00a0your\u00a0brain\u00a0with a computer program, perfectly capturing the behavior of each neuron, that program would itself be an\u00a0algorithm. So, in\u00a0an important sense, there\u2019s nothing fundamentally special about algorithmic decisions.\u00a0In any situation in which human decisions might exhibit bias, so might those made by computerized algorithms.\u00a0One\u00a0important difference between human and algorithmic bias might be that\u00a0for humans, we\u00a0know to suspect bias, and\u00a0we have some intuition for what sorts of bias to expect.</p>\n<p>To dispense with any doubt that an algorithm might encode bias,\u00a0consider the following rule for extending a line of credit:\u00a0<i>If race=white THEN approve loan ELSE deny</i>.\u00a0This program, however simple, constitutes an algorithm and yet reflects an obvious bias.\u00a0Of course, this explicit racism might be easy to detect\u00a0and straightforward to challenge legally.\u00a0Deciphering its logic doesn\u2019t require formidable expertise.</p>\n<p>But today\u2019s large-scale software and machine-learning systems can grow opaque.\u00a0Even the programmer of a system might struggle to say why precisely makes any individual system.\u00a0For complex algorithms, biases may exist, but detecting the bias, identifying its cause, and correcting may not always be straightforward. Nevertheless, there exist some common patterns for how\u00a0bias can\u00a0creep into systems.\u00a0Understanding these patterns may\u00a0prove vital to guarding against preventable problems.</p>\n<p><strong>[MACHINE LEARNING]</strong></p>\n<p>Now let\u2019s review the basics of machine learning.\u00a0Machine learning refers to powerful set of techniques for building algorithms that improve as a function of experience.\u00a0The field of machine learning addresses a broad class of problems and algorithmic solutions\u00a0but we\u2019re going to focus on supervised learning, the kind directly concerned with pattern recognition and \u00a0predictive modelling.</p>\n<p>Most machine learning in the wild today consists of supervised learning.\u00a0When Facebook recognizes your face in a photograph, when your mailbox filters spam, and when your bank predicts default risk \u2013 these are all examples of supervised machine learning in action.</p>\n<p>We use machine learning because sometimes it\u2019s impossible to specify\u00a0a\u00a0good enough program a priori.\u00a0Let\u2019s say you wanted to build a\u00a0spam filter.\u00a0You might be tempted to implement a rule-based system with a blacklist of particularly spammy \u00a0words.\u00a0Is any email referring to \u201cWestern Union\u201d spam?\u00a0Perhaps. But even so, that only describes a small percentage of spam.\u00a0There\u2019s still the solicitations from illegal drug companies,\u00a0pornographic sites, and the legendary Nigerian prince who wants to wire you millions of dollars.</p>\n<p>Suppose now that through herculean effort you produced a perfect spam filter,\u00a0cobbling together 1000s of consistent rules to cover all the known cases of spam while letting all legitimate email pass through.\u00a0As soon as you\u2019d completed this far-fetched feat and secured some well-deserved sleep,\u00a0you\u2019d wake up to find that the spam filter no longer worked as well.\u00a0The spammers would have invented new varieties of spam, invalidating all your hard work.</p>\n<p>Machine learning proposes an alternative way to deal with these problems.\u00a0Even if we can\u2019t specify precisely what constitutes spam, we might know it when we see it.\u00a0Instead of coming up with the exact solution ourselves by enumerating rules,\u00a0we can compile a large dataset containing emails known either to be spam or to be safe.\u00a0The dataset might consist of millions of emails,\u00a0each of which would be characterized by a large number of attributes and annotated according to whether it\u2019s believed (by a human) to actually spam or not.\u00a0Typical attributes might include the words themselves, the time the email was sent, the email address, server, and domain from which it was sent, and statistics about previous correspondence with this address.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2016/11/foundations-algorithmic-bias.html/2\">2</a> <a href=\"https://www.kdnuggets.com/2016/11/foundations-algorithmic-bias.html/3\">3</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/16/11-16-cmu-teaching-faculty.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2016/11/top-tweets-nov09-15.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-1-another-10']);\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-2-simplilearn']);\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-3-typical']);\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-4-pareto']);\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/03/data-science-job-applications.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-5-tell-you']);\"><b>What no one will tell you about data science job applications</b></a>\n<li> <a href=\"/2019/03/women-ai-big-data-science-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-6-inspiring-women']);\"><b>19 Inspiring Women in AI, Big Data, Data Science, Machine Learning</b></a>\n<li> <a href=\"/2019/03/favorite-ml-ai-breakthroughs.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-mp-7-breakthroughs']);\"><b>My favorite mind-blowing Machine Learning/AI breakthroughs</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-1-ann-optim-ga']);\"><b>Artificial Neural Networks Optimization using Genetic Algorithm with Python</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-2-typical']);\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-3-azure-cert']);\"><b>8 Reasons Why You Should Get a Microsoft Azure Certification</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-4-pareto']);\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-5-r-vs-py-viz']);\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/work-data-science-ai-big-data.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-6-how-work']);\"><b>How To Work In Data Science, AI, Big Data</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-02-ms-7-dl-toolset']);\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/jmp-statistical-thinking-free-online-course.html\">Statistical Thinking for Industrial Problem Solving (ST...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datarobot-from-business-intelligence-machine-intelligence.html\">From Business Intelligence to Machine Intelligence</a><li> <a href=\"https://www.kdnuggets.com/2019/04/ai-makes-decision.html\">What is missing when AI makes a decision?</a><li> <a href=\"https://www.kdnuggets.com/2019/04/spatio-temporal-statistics-primer.html\">Spatio-Temporal Statistics: A Primer</a><li> <a href=\"https://www.kdnuggets.com/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\">Another 10 Free Must-See Courses for Machine Learning a...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html\">Download your DATAx guide to AI in Marketing</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/datax-download-guide-ai-marketing.html\">Download your DATAx guide to AI in Marketing</a><li> <a href=\"https://www.kdnuggets.com/2019/04/strata-kdnuggets-offer-save-london.html\">KDnuggets Offer: Save 20% on Strata in London</a><li> <a href=\"https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html\">Training a Champion: Building Deep Neural Nets for Big Data An...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/building-recommender-system.html\">Building a Recommender System</a><li> <a href=\"https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html\">Predict Age and Gender Using Convolutional Neural Network and ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-mar27-apr02.html\">Top tweets, Mar 27 \u2013 Apr 02: Here is a great explanat...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/odsc-east-selling-out-india-announced.html\">ODSC East is selling out; ODSC India announced</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-03-accelerate-ai-data-science-career-expo-2019.html\">Accelerate AI and Data Science Career Expo, May 4, 2019</a><li> <a href=\"https://www.kdnuggets.com/2019/04/formulated-data-career-datasciencego-san-diego.html\">Grow your data career at DataScienceGO, San Diego, Sep 27-29</a><li> <a href=\"https://www.kdnuggets.com/2019/04/nlp-pytorch.html\">Getting started with NLP using the PyTorch framework</a><li> <a href=\"https://www.kdnuggets.com/2019/04/diy-your-data-science-education.html\">How to DIY Your Data Science Education</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-8-data-science-use-cases-gaming.html\">Top 8 Data Science Use Cases in Gaming</a><li> <a href=\"https://www.kdnuggets.com/2019/n13.html\">KDnuggets 19:n13, Apr 3: Top 10 Data Scientist Coding Mista...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/psu-make-better-data-driven-business-decisions.html\">Make better data-driven business decisions</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0325-0331.html\">Top Stories, Mar 25-31: R vs Python for Data Visualization; Th...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-two-predictive-analytics-world-events-europe-fall.html\">Two Predictive Analytics World Events in Europe This Fall</a><li> <a href=\"https://www.kdnuggets.com/2019/04/7-qualities-big-data-visualization-tools.html\">7 Qualities Your Big Data Visualization Tools Absolutely Must ...</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-faculty-ai-machine-learning.html\">Yeshiva University: Tenure-track Faculty in AI and Machine Lea...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html\">Which Face is Real?</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-02-yeshiva-university-program-director-faculty-artificial-intelligence-machine-learning.html\">Yeshiva University: Program Director / Tenure Track Faculty Me...</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2016/index.html\">2016</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/index.html\">Nov</a> \u00bb <a href=\"https://www.kdnuggets.com/2016/11/opinions-interviews.html\">Opinions, Interviews</a> \u00bb The Foundations of Algorithmic Bias (\u00a0<a href=\"/2016/n42.html\">16:n42</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1554633746\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.763 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-07 06:42:26 -->\n<!-- Compression = gzip -->", "title": "The Foundations of Algorithmic Bias  ", "content": "\n By  Zachary Chase Lipton  , UCSD.   \n  comments   \n Reposted with permission from  approximatelycorrect.com  \n    \n This morning, millions of people woke up and impulsively checked Facebook.\u00a0They were greeted immediately by content curated by Facebook\u2019s newsfeed algorithms.\u00a0To\u00a0some degree, this news might have influenced their perceptions of the day\u2019s news,\u00a0the economy\u2019s outlook, and the state of the election.\u00a0Every year, millions of people apply for jobs.\u00a0Increasingly, their success might lie, in part, in the hands of computer programs\u00a0tasked with matching applications to job openings. And every year, roughly 12 million people are arrested. Throughout the criminal justice system, computer-generated risk-assessments are used to determine which arrestees should be set free.\u00a0In all these situations, algorithms are tasked with making decisions.  \n   \n Algorithmic decision-making mediates more and more of our interactions,\u00a0influencing our social experiences, the news we see, our finances, and our career opportunities.\u00a0We task computer programs with approving lines of credit,\u00a0curating news, and filtering job applicants.\u00a0Courts even deploy computerized algorithms to predict \u201crisk of recidivism\u201d,\u00a0the probability that an individual relapses into criminal behavior.\u00a0It seems likely that this\u00a0trend\u00a0will only accelerate as breakthroughs in artificial intelligence\u00a0rapidly broadened the capabilities of software.  \n Turning decision-making over to algorithms naturally raises worries about our ability\u00a0to assess and enforce the neutrality of these new decision makers.\u00a0How can we be sure that the algorithmically curated news doesn\u2019t have a political party bias\u00a0or job listings don\u2019t reflect a gender or racial bias?\u00a0What other biases might our automated processes be exhibiting that that we wouldn\u2019t even know to look for?  \n The rise of machine learning complicates these concerns.\u00a0Traditional software is typically composed from simple, hand-coded logic rules.\u00a0IF condition X holds THEN perform action Y . \u00a0  But machine learning relies on complex statistical models to discover patterns in large datasets. Take loan approval for instance.\u00a0Given\u00a0years of credit history and other side information, a machine learning algorithm might then output a probability that the applicant will default. \u00a0The logic behind this assessment wouldn\u2019t be coded by hand.\u00a0Instead, the model would extrapolate from the records of thousands or millions of other customers.  \n On highly specialized problems, and given enough data,\u00a0machine learning algorithms can often make predictions with near-human or super-human accuracy.\u00a0But it\u2019s often hard to say precisely why a decision was made.\u00a0So how can we ensure that these decisions don\u2019t encode bias? How can we ensure that giving these algorithms decision-making power doesn\u2019t amount to a breach of\u00a0ethics?\u00a0The potential for prejudice hasn\u2019t gone under the radar.\u00a0In the last year alone,\u00a0 MIT Technology Review  \u00a0[1],\u00a0 the Guardian  \u00a0[2],\u00a0and the\u00a0 New York Times  \u00a0[3],\u00a0all published thought pieces cautioning against algorithmic bias. Some of\u00a0the best coverage has come from ProPublica, which\u00a0 quantitatively studied racial bias in a widely used \u00a0criminal risk-assessment score  \u00a0[4].  \n Each article counters the notion that algorithms are necessarily objective.\u00a0Technology Review invokes Fred Berenson\u2019s assertion\u00a0that we are susceptible to \u2018mathwashing\u2019.\u00a0That is, we tend to (misguidedly) assume that any system built with complex mathematics\u00a0at its core must somehow be objective, devoid of the biases that plague human decision-making.  \n Alas, the public discourse rarely throws light on\u00a0the precise mechanisms by which bias actually enters algorithmic decision-making processes.\u00a0Tech Review for example, points to the abundance of men working in computer science without explaining how this might alter the behavior of their algorithms.\u00a0You might think that the bias seeped through via the air filtration system.\u00a0The Guardian makes a compelling argument that the \u201crecidivism\u201d predictor encodes racial bias, producing evidence to support the claim.\u00a0But they never discuss how this came to be,\u00a0describing the algorithms simply as black boxes.\u00a0Similarly, the New York Times piece calls attention to bias and to the opacity of FaceBook algorithms for new curation,\u00a0but doesn\u2019t elucidate the precise mechanisms by which undesirable outcomes manifest. Admirably, in the\u00a0ProPublica piece,\u00a0author Julia Adwin\u00a0sought the risk-assessment algorithm itself, but software-company Northpointe would not share the precise proprietary formula.  \n It\u2019s encouraging that these pieces have helped to spark a global conversation\u00a0about the responsibilities of programmatic decision-makers.\u00a0However, the mystical quality of the discussion threatens to stymie progress.\u00a0If we don\u2019t know how algorithms can become biased, how can we know when to suspect them?\u00a0Moreover, without this understanding, how can we hope to counteract the bias?  \n To bring some rigor to the dialogue, let\u2019s first run through a crash-course on what algorithms are, how they make\u00a0decisions, and where machine learning enters the picture.\u00a0Armed with this information, we\u2019ll then introduce a catalogue\u00a0of fundamental ways that things can go wrong.  \n [ALGORITHMS]   \n To start, let\u2019s briefly explain\u00a0 algorithms  .\u00a0Algorithms are the instructions that tell your computer precisely how to accomplish some task. \u00a0Typically, this means how to take some input and producing some output.\u00a0The software that takes two addresses on a map and returns the shortest route between them is an algorithm.\u00a0So is the method that doctors use to calculate cardiac risk.\u00a0This particular algorithm takes the age, blood pressure, smoking status, and a few other inputs,\u00a0combines them according to a precise formula, and outputs the risk of a cardiovascular event.  \n Compared to\u00a0these simple examples, many of the algorithms at the heart of technologies like self-driving cars and recommender systems\u00a0are\u00a0considerably more complex, containing many instructions, advanced mathematical operations, and complicated logic. Sometimes, the line between an algorithm and what might better be described as a complex software systems can become blurred.  \n Consider the algorithms behind Google\u2019s search service.\u00a0From the outside it might appear to be monolithic,\u00a0but it\u2019s actually a complex software system,\u00a0encompassing multiple sub-algorithms, each of which may be maintained by large teams of engineers and scientists and consisting of millions of lines of code.  \n There\u2019s little that can be said universally about algorithms.\u00a0Collectively, they\u2019re neither racist nor neutral, fast nor slow, sentient nor insensate.\u00a0If you could\u00a0simulate\u00a0your\u00a0brain\u00a0with a computer program, perfectly capturing the behavior of each neuron, that program would itself be an\u00a0algorithm. So, in\u00a0an important sense, there\u2019s nothing fundamentally special about algorithmic decisions.\u00a0In any situation in which human decisions might exhibit bias, so might those made by computerized algorithms.\u00a0One\u00a0important difference between human and algorithmic bias might be that\u00a0for humans, we\u00a0know to suspect bias, and\u00a0we have some intuition for what sorts of bias to expect.  \n To dispense with any doubt that an algorithm might encode bias,\u00a0consider the following rule for extending a line of credit:\u00a0 If race=white THEN approve loan ELSE deny  .\u00a0This program, however simple, constitutes an algorithm and yet reflects an obvious bias.\u00a0Of course, this explicit racism might be easy to detect\u00a0and straightforward to challenge legally.\u00a0Deciphering its logic doesn\u2019t require formidable expertise.  \n But today\u2019s large-scale software and machine-learning systems can grow opaque.\u00a0Even the programmer of a system might struggle to say why precisely makes any individual system.\u00a0For complex algorithms, biases may exist, but detecting the bias, identifying its cause, and correcting may not always be straightforward. Nevertheless, there exist some common patterns for how\u00a0bias can\u00a0creep into systems.\u00a0Understanding these patterns may\u00a0prove vital to guarding against preventable problems.  \n [MACHINE LEARNING]   \n Now let\u2019s review the basics of machine learning.\u00a0Machine learning refers to powerful set of techniques for building algorithms that improve as a function of experience.\u00a0The field of machine learning addresses a broad class of problems and algorithmic solutions\u00a0but we\u2019re going to focus on supervised learning, the kind directly concerned with pattern recognition and \u00a0predictive modelling.  \n Most machine learning in the wild today consists of supervised learning.\u00a0When Facebook recognizes your face in a photograph, when your mailbox filters spam, and when your bank predicts default risk \u2013 these are all examples of supervised machine learning in action.  \n We use machine learning because sometimes it\u2019s impossible to specify\u00a0a\u00a0good enough program a priori.\u00a0Let\u2019s say you wanted to build a\u00a0spam filter.\u00a0You might be tempted to implement a rule-based system with a blacklist of particularly spammy \u00a0words.\u00a0Is any email referring to \u201cWestern Union\u201d spam?\u00a0Perhaps. But even so, that only describes a small percentage of spam.\u00a0There\u2019s still the solicitations from illegal drug companies,\u00a0pornographic sites, and the legendary Nigerian prince who wants to wire you millions of dollars.  \n Suppose now that through herculean effort you produced a perfect spam filter,\u00a0cobbling together 1000s of consistent rules to cover all the known cases of spam while letting all legitimate email pass through.\u00a0As soon as you\u2019d completed this far-fetched feat and secured some well-deserved sleep,\u00a0you\u2019d wake up to find that the spam filter no longer worked as well.\u00a0The spammers would have invented new varieties of spam, invalidating all your hard work.  \n Machine learning proposes an alternative way to deal with these problems.\u00a0Even if we can\u2019t specify precisely what constitutes spam, we might know it when we see it.\u00a0Instead of coming up with the exact solution ourselves by enumerating rules,\u00a0we can compile a large dataset containing emails known either to be spam or to be safe.\u00a0The dataset might consist of millions of emails,\u00a0each of which would be characterized by a large number of attributes and annotated according to whether it\u2019s believed (by a human) to actually spam or not.\u00a0Typical attributes might include the words themselves, the time the email was sent, the email address, server, and domain from which it was sent, and statistics about previous correspondence with this address.  \n  ", "title_html": "<h1 id=\"title\">The Foundations of Algorithmic Bias</h1> "}