{"title_html": "<h1 id=\"title\">The Rise of Generative Adversarial Networks</h1> ", "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  The Rise of Generative Adversarial Networks</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb The Rise of Generative Adversarial Networks Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/jobs/19/04-19-nasdaq100-leader-data-science.html\" rel=\"prev\" title=\"NASDAQ 100: Leader of Data Science [East Coast]\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/paw-data-driven-government-workshops-announced.html\" rel=\"next\" title=\"Data Driven Government Workshops Announced!\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=93059\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-93059 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 19-Apr, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/opinions.html\">Opinions</a> \u00bb The Rise of Generative Adversarial Networks (\u00a0<a href=\"/2019/n16.html\">19:n16</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">The Rise of Generative Adversarial Networks</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/19/04-19-nasdaq100-leader-data-science.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/04/paw-data-driven-government-workshops-announced.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/art\" rel=\"tag\">Art</a>, <a href=\"https://www.kdnuggets.com/tag/deep-fakes\" rel=\"tag\">Deep Fakes</a>, <a href=\"https://www.kdnuggets.com/tag/gans\" rel=\"tag\">GANs</a>, <a href=\"https://www.kdnuggets.com/tag/generative-adversarial-network\" rel=\"tag\">Generative Adversarial Network</a>, <a href=\"https://www.kdnuggets.com/tag/ian-goodfellow\" rel=\"tag\">Ian Goodfellow</a></div>\n<br/>\n<p class=\"excerpt\">\n     A comprehensive overview of Generative Adversarial Networks, covering its birth, different architectures including DCGAN, StyleGAN and BigGAN, as well as some real-world examples.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/kailash-ahirwar-b1a59128/\">Kailash Ahirwar</a></b>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*DxLcti_LW1peTc8QRYsXHw.jpeg\" width=\"100%\"/></p>\n<p><strong>Credit:\u00a0<a data-href=\"https://en.wikipedia.org/wiki/Edmond_de_Belamy\" href=\"https://en.wikipedia.org/wiki/Edmond_de_Belamy\">https://en.wikipedia.org/wiki/Edmond_de_Belamy</a></strong></p>\n<p>5 years back, Generative Adversarial Networks(GANs) started a revolution in deep learning. This revolution has produced some major technological breakthroughs. Generative Adversarial Networks were introduced by Ian Goodfellow and others in the paper titled \u201cGenerative Adversarial Networks\u201d\u200a\u2014\u200a<a data-href=\"https://arxiv.org/abs/1406.2661\" href=\"https://arxiv.org/abs/1406.2661\">https://arxiv.org/abs/1406.2661</a>. Academia accepted GANs with open hands and industry welcomed GANs with much fanfare too. The rise of GANs was inevitable.</p>\n<p><span data-creator-ids=\"anon\">First, the best thing about GANs is their nature of learning, which is unsupervised.</span>\u00a0GANs don\u2019t need labeled data, which makes GANs powerful as the boring work of data labeling is not required.</p>\n<p>Second, the potential use-cases of GANs have put GANs at the center of conversations. They can generate high-quality images, enhance photos, generate images from text, convert images from one domain to another, change the appearance of the face image as age progresses and many more. The list is endless. We will cover some of the widely popular GAN architectures in this article.</p>\n<p>Third, the endless research put around GANs is so mesmerizing that it grabs the attention of every other industry. We will be talking about major technological breakthroughs in the later section of this article.</p>\n<h3>The Birth</h3>\n<p>Generative Adversarial Network or GAN for short is a setup of two networks, a generator network, and a discriminator network. These two networks can be neural networks, ranging from convolutional neural networks, recurrent neural networks to auto-encoders. In this setup, two networks are engaged in a competitive game and trying to outdo each other, simultaneously, helping each other at their own tasks. After thousands of iterations, if everything goes well, the generator network gets perfect at generating realistically looking fake images and the discriminator network gets perfect at telling whether the image shown to it is fake or real. In other terms, the generator network transforms a random noise vector from a latent space(Not all GANs sample from a latent space) to a sample from real data set. Training a GAN is a very intuitive process. We simultaneously train both networks and they both get better with time.</p>\n<p>GANs have plenty of real-world use cases like image generation, artwork generation, music generation, and video generation. Also, they can enhance the quality of your images, stylize or colorize your images, generate faces and can perform many more interesting tasks.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/0*AMKi83krt4kDBY6s.png\" width=\"100%\"/></p>\n<p><strong>Credit: O\u2019Reilly</strong></p>\n<p>The above image shows the architecture of a vanilla GAN network. First, a D-dimensional noise vector is sampled from a latent space and fed to the generator network. The generator network converts this noise vector to an image. Then this generated image is fed to the discriminator network for classification. The discriminator network keeps getting images from the real dataset and the images generated by the generator network. Its job is to discriminate between real and fake images. All GAN architectures follow the same design. This was the birth of GANs. Now explore the adolescent stage of GANs.</p>\n<h3>The Adolescence</h3>\n<p>In its adolescence, GANs produced widely popular architectures like DCGAN, StyleGAN, BigGAN, StackGAN, Pix2pix, Age-cGAN, CycleGAN. These architectures were presented with very promising results. By looking at the results, it was pretty clear that the GANs have reached in its adolescent stage. Let\u2019s explore these architectures in detail.</p>\n<h4>DCGAN</h4>\n<p>For the first time, convolutional neural networks were used within GANs and achieved impressive results. Before this, CNNs have shown unprecedented results in supervised computer vision tasks. But in GANs, CNNs were unexplored. DCGANs were introduced in the paper titled \u201cUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\u201d by Alec Radford, Luke Metz, Soumith Chintala. It was a major milestone in GANs research as it introduced major architectural changes to tackle problems like training instability, mode collapse, and internal covariate shift. Since then, numerous GAN architectures were introduced based on the architecture of DCGAN.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*BgeQMKbogG0aG3Uw0e0Msw.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1511.06434.pdf\" href=\"https://arxiv.org/pdf/1511.06434.pdf\">https://arxiv.org/pdf/1511.06434.pdf</a></strong></p>\n<h4>BigGAN</h4>\n<p>This is the latest development in GANs for image generation. A Google intern and two researchers from Google\u2019s DeepMind division released a paper titled \u201cLarge Scale GAN Training for High Fidelity Natural Image Synthesis\u201d, available at<a data-href=\"https://arxiv.org/abs/1809.11096\" href=\"https://arxiv.org/abs/1809.11096\">\u00a0https://arxiv.org/abs/1809.11096</a>. This paper is an internship project by Andrew Brock from Heriot-Watt University in collaboration with Jeff Donahue and Karen Simonyan from DeepMind.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/1*9hTIFDUzPbnxcHZIkMNepQ.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a href=\"https://arxiv.org/pdf/1809.11096.pdf\">https://arxiv.org/pdf/1809.11096.pdf</a></strong></p>\n<p>These images are generated by BigGAN and as you see they are of impressive quality. For the first time, GANs have generated images with high fidelity and low variety gap. Previous highest Inception Score was 52.52 and BigGAN achieved an Inception Score of 166.3, which was 100% better than the State of the art(SOTA). Also, they improved The Frechet Inception Distance (FID) score from 18.65 to 9.6. These were very impressive results and I hope to see more development in this area. The most important improvement was orthogonal regularization to the generator.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/1*4rsKMM6d_FDGi3dYTGkUJA.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1809.11096.pdf\" href=\"https://arxiv.org/pdf/1809.11096.pdf\">https://arxiv.org/pdf/1809.11096.pdf</a></strong></p>\n<p>Isn\u2019t it impressive!</p>\n<h4>StyleGAN</h4>\n<p>StyleGAN is another major breakthrough in GANs research. StyleGAN was introduced by Nvidia, in the paper titled \u201cA Style-Based Generator Architecture for Generative Adversarial Network\u201d, available at the following link<a data-href=\"https://arxiv.org/pdf/1710.10196.pdf\" href=\"https://arxiv.org/pdf/1710.10196.pdf\">\u00a0https://arxiv.org/pdf/1710.10196.pdf</a>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*No5lv7YyFUduZ-1M-qx5Bg.gif\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf\" href=\"https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf\">https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf</a></strong></p>\n<p>StyleGAN sets a new record in Face generation tasks. At the core of the algorithm is the style transfer techniques or style mixing. Apart from generating faces, it can generate high-quality images of cars, bedrooms etc. This is a major improvement in the GANs field and an inspiration for fellow deep learning researchers.</p>\n<h4>StackGAN</h4>\n<p>StackGANs were proposed by Han Zhang, Tao Xu, Hongsheng Li, and others in their paper titled StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks, which is available at the following link:<a data-href=\"https://arxiv.org/pdf/1612.03242.pdf\" href=\"https://arxiv.org/pdf/1612.03242.pdf\">\u00a0https://arxiv.org/pdf/1612.03242.pdf</a>. They used StackGANs to explore text-to-image synthesis with impressive results. A StackGAN is a pair of networks that generate realistic looking images when provided with a text description. My book titled \u201cGenerative Adversarial Networks Projects\u201d has a chapter dedicated to StackGANs.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*xNCTl8oGiBeB1YjEweTZxg.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1612.03242.pdf\" href=\"https://arxiv.org/pdf/1612.03242.pdf\">https://arxiv.org/pdf/1612.03242.pdf</a></strong></p>\n<p>As you can see in the above image, StackGAN generated realistically looking images of birds when provided with a text description. The most important thing is that the generated images correctly resembles the text provided. Text-to-image synthesis has many real-world applications like generating images from text descriptions, converting a story in textual form to comic form, to create internal representations of text descriptions.</p>\n<h4>CycleGAN</h4>\n<p>CycleGANs have some really interesting use-cases, such as converting photos to paintings and vice versa, converting a picture taken in summer to a photo taken in winter and vice versa, or converting pictures of horses to pictures of zebras and vice versa. CycleGANs were proposed by Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros in a paper titled \u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\u201d, which is available at the following link:<a data-href=\"https://arxiv.org/pdf/1703.10593.pdf\" href=\"https://arxiv.org/pdf/1703.10593.pdf\">\u00a0https://arxiv.org/pdf/1703.10593</a>. CycleGANs explore different image-to-image translation use-cases.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/1*V81VkAl9yiucz9eGFAlxgQ.jpeg\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1703.10593.pdf\" href=\"https://arxiv.org/pdf/1703.10593.pdf\">https://arxiv.org/pdf/1703.10593.pdf</a></strong></p>\n<h4>Pix2pix</h4>\n<p>For image-to-image translation tasks, pix2pix also shown impressive results. Be it converting night images to day images or vice versa, colorizing black and white images, translating sketches to photos and many more, Pix2pix has excelled in all these use-cases. The pix2pix network was introduced by Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros in their paper titled \u201cImage-to-Image Translation with Conditional Adversarial Networks\u201d, which is available at the following link:\u00a0<a data-href=\"https://arxiv.org/abs/1611.07004\" href=\"https://arxiv.org/abs/1611.07004\">https://arxiv.org/abs/1611.07004</a>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*XqcBcoE9VyKuupxIiWL6Bg.jpeg\" width=\"100%\"/></p>\n<p><strong>Credit:\u00a0<a data-href=\"https://phillipi.github.io/pix2pix/\" href=\"https://phillipi.github.io/pix2pix/\">https://phillipi.github.io/pix2pix/</a></strong></p>\n<p>This was an interactive demo, capable of generating real images from sketches.</p>\n<h4>Age-cGAN (Age Conditional Generative Adversarial Networks)</h4>\n<p>Face aging has many industry use cases, including cross-age face recognition, finding lost children, and in entertainment. Face aging with Conditional GANs was proposed by Grigory Antipov, Moez Baccouche, and Jean-Luc Dugelay in their paper titled Face Aging with Conditional Generative Adversarial Networks, which is available at the following link:\u00a0<a data-href=\"https://arxiv.org/pdf/1702.01983.pdf.\" href=\"https://arxiv.org/pdf/1702.01983.pdf.\">https://arxiv.org/pdf/1702.01983.pdf.</a></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*p1VK22zXlezG-T712nEhbQ.png\" width=\"100%\"/></p>\n<p>This image shows how Age-cGAN translated face from the source age to the target age.</p>\n<p>These were some widely popular GAN architectures. Besides these, there are thousands of GAN architectures. It depends on your requirements which architecture will suit your need.</p>\n<h3>The Rise</h3>\n<p>As Famous Theoretical Physicist Richard Feynman says:</p>\n<blockquote><p><em>\u201cWhat I can\u2019t create, I don\u2019t understand\u201d</em></p></blockquote>\n<p>The idea behind GANs was to train networks which understand the data. GANs now started to understand the data, with this understanding they started to create realistic looking images. Let\u2019s witness the rise of GANs.</p>\n<h4>Edmond de\u00a0Belamy</h4>\n<p><em>Edmond de Belamy,\u00a0</em>a painting created by Generative Adversarial Networks was sold for a staggering amount of $432, 500 at Christie\u2019s auction. It was a big step in the progress of GANs. For the first time, the whole world witnessed GANs and their potential. Before this, GANs were mostly confined in research labs and used by machine learning engineers. This act became an entry of GANs to the general public.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*ihb6F_7BZWpoRgh27SB5rg.jpeg\" width=\"100%\"/></p>\n<p><strong>This Person Does Not Exist</strong></p>\n<p>You may be familiar with the website\u00a0<a href=\"https://thispersondoesnotexist.com/\">https://thispersondoesnotexist.com</a>. Last month, this was all over the Internet. The website,\u00a0<a href=\"https://thispersondoesnotexist.com/\">https://thispersondoesnotexist.com</a>\u00a0created by Philip Wan, who is a software engineer at Uber. He created this website based on the code released by NVIDIA titled StyleGAN. Every time you hit refresh, it generates a new fake face, which looks surprisingly real unable to tell whether it is fake or not. This is scary AF but disruptive at the same time. This technology has the potential to create endless virtual worlds.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*Y6KW2MrcE0fYL1ikOMu5xg.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a href=\"https://thispersondoesnotexist.com/\">https://thispersondoesnotexist.com/</a></strong></p>\n<p>Isn\u2019t it amazing!</p>\n<p><strong>Deep Fakes</strong><br>\nDeepFakes is another scary AF but disruptive technology. Based on GANs, this can paste people\u2019s faces onto a target person in videos. DeepFakes was all over the Internet too. People speculated the downsides of this technology. But for AI researchers, this was a major breakthrough. This technology has the potential to save millions of dollars in the film industry where hours of editing required to change stuntman\u2019s face with actors face.</br></p>\n<p>This technology will always be scary, but it is up to us to use it for social good.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*RalCJrBisSXSy88C_kXZVw.png\" width=\"100%\"/></p>\n<p><strong>Credit:\u00a0<a data-href=\"https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/\" href=\"https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/\">https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/</a></strong></p>\n<h4>The Trend</h4>\n<p>StyleGAN currently is the sixth most trending python project on GitHub. The number of named GANs till now proposed are in thousands. This repository has a list of popular GANs and their respective papers\u00a0<a data-href=\"https://github.com/hindupuravinash/the-gan-zoo\" href=\"https://github.com/hindupuravinash/the-gan-zoo\">https://github.com/hindupuravinash/the-gan-zoo</a></p>\n<h4>In Real-world</h4>\n<p>GANs have been used to enhance the graphics of games. I am super excited about this use-case of GANs. Recently, NVIDIA released a video, in which, it showed how GANs are used to gamify the environment in the video.</p>\n<h4>Conclusion</h4>\n<p>In this article, we have seen how GANs rose to fame and became a global phenomenon. I hope, we see the democratization of GANs in the coming years. In this article, we started with the birth of GANs. Then, we explored some widely popular GAN architectures. Finally, we witnessed the rise of GANs. When I see negative press around GANs, I am baffled. I believe, it is our responsibility to make everyone aware of the repercussions of GANs and how can we ethically and morally use GANs for our best. Let\u2019s all come together and spread positivity around GANs. GANs have so much potential to create new industries and jobs. We just have to make sure that it doesn\u2019t go into wrong hands.</p>\n<p><a href=\"https://blog.usejournal.com/the-rise-of-generative-adversarial-networks-be52d424e517\">Original</a>. Reposted with permission.</p>\n<p><strong>Bio</strong>:\u00a0<a href=\"https://www.linkedin.com/in/kailash-ahirwar-b1a59128/\">Kailash Ahirwar</a>\u00a0is a Machine Learning and Deep Learning Enthusiast, Democratising Machine Learning and Deep Learning, making it available for one and all.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html\">Which Face is Real?</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html\">My favorite mind-blowing Machine Learning/AI breakthroughs</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/deep-learning-major-advances-review.html\">State of Deep Learning and Major Advances: H2 2018 Review</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/jobs/19/04-19-nasdaq100-leader-data-science.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/04/paw-data-driven-government-workshops-announced.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-1-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-2-another-10-books');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/recognize-good-data-scientist-job-from-bad.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-3-good-from-bad');\"><b>How to Recognize a Good Data Scientist Job From a Bad One</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-4-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/04/introduction-time-series-forecasting-simple-neural-networks-lstm.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-5-intro-ts');\"><b>An Introduction on Time Series Forecasting with Simple Neural Networks &amp; LSTM</b></a>\n<li> <a href=\"/2019/03/random-forest-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-6-explain-rf');\"><b>Explaining Random Forest (with Python Implementation)</b></a>\n<li> <a href=\"/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-mp-7-age-gender');\"><b>Predict Age and Gender Using Convolutional Neural Network and OpenCV</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-1-optimization-ga');\"><b>Artificial Neural Networks Optimization using Genetic Algorithm with Python</b></a>\n<li> <a href=\"/2019/04/another-10-free-must-see-courses-machine-learning-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-2-another-10-courses');\"><b>Another 10 Free Must-See Courses for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2019/04/top-10-coding-mistakes-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-3-mistakes');\"><b>Top 10 Coding Mistakes Made by Data Scientists</b></a>\n<li> <a href=\"/2019/03/r-vs-python-data-visualization.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-4-r-py-viz');\"><b>R vs Python for Data Visualization</b></a>\n<li> <a href=\"/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-5-azure-cert');\"><b>8 Reasons Why You Should Get a Microsoft Azure Certification</b></a>\n<li> <a href=\"/2019/03/deep-learning-toolset-overview.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-6-dl-toolset');\"><b>The Deep Learning Toolset \u2014 An Overview</b></a>\n<li> <a href=\"/2019/03/work-data-science-ai-big-data.html\" onclick=\"ga('send','pageview','/x/pbc/2019/04-16-ms-7-how-work');\"><b>How To Work In Data Science, AI, Big Data</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/paw-data-driven-government-workshops-announced.html\">Data Driven Government Workshops Announced!</a><li> <a href=\"https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html\">The Rise of Generative Adversarial Networks</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-19-nasdaq100-leader-data-science.html\">NASDAQ 100: Leader of Data Science [East Coast]</a><li> <a href=\"https://www.kdnuggets.com/2019/04/data-visualization-python-matplotlib-seaborn.html\">Data Visualization in Python: Matplotlib vs Seaborn</a><li> <a href=\"https://www.kdnuggets.com/2019/04/intel-unleash-faster-python-data.html\">Unleash a faster Python on your data</a><li> <a href=\"https://www.kdnuggets.com/2019/04/sisense-blox-beyond-dashboards.html\">Sisense BloX \u2013 Go Beyond Dashboards</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/04/sisense-blox-beyond-dashboards.html\">Sisense BloX \u2013 Go Beyond Dashboards</a><li> <a href=\"https://www.kdnuggets.com/2019/04/3-big-problems-big-data.html\">3 Big Problems with Big Data and How to Solve Them</a><li> <a href=\"https://www.kdnuggets.com/2019/04/distributed-artificial-intelligence-multi-agent-systems-agent-based-modeling-swarm-intelligence.html\">Distributed Artificial Intelligence: A primer on Multi-Agent S...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/how-optimization-works.html\">How Optimization Works</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-tweets-apr10-apr16.html\">Top tweets, Apr 10\u201316: Math for Programmers teaches you t...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/datax-san-francisco-over-500-data-professionals.html\">DATAx San Francisco | 14-15 May | Over 500 Data Professionals</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-17-bottomline-technologies-data-scientist.html\">Bottomline Technologies, Inc: Data Scientist [McLean, VA or Po...</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-17-ten-x-data-scientist.html\">Ten-X: Data Scientist [San Mateo, CA]</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/04-17-ten-x-data-engineer.html\">Ten-X: Sr Data Engineer [San Mateo, CA]</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-data-visualization-techniques.html\">Best Data Visualization Techniques for small and large data</a><li> <a href=\"https://www.kdnuggets.com/2019/04/building-flask-api-automatically-extract-named-entities-spacy.html\">Building a Flask API to Automatically Extract Named Entities U...</a><li> <a href=\"https://www.kdnuggets.com/2019/n15.html\">KDnuggets 19:n15, Apr 17: Time Series Forecasting with Neur...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/northwestern-ms-data-science.html\">Northwestern\u2019s MS in Data Science</a><li> <a href=\"https://www.kdnuggets.com/2019/04/penn-online-ms-data-analytics.html\">Penn State Online MS in Data Analytics.</a><li> <a href=\"https://www.kdnuggets.com/2019/04/introduction-clustering-algorithms.html\">How Machines Make Sense of Big Data: an Introduction to Cluste...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/best-masters-data-science-analytics-europe.html\">2019 Best Masters in Data Science and Analytics \u2013 Europe Edi...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/k-means-clustering-unsupervised-learning-recommender-systems.html\">K-Means Clustering: Unsupervised Learning for Recommender Systems</a><li> <a href=\"https://www.kdnuggets.com/2019/04/data-science-with-optimus-part-2-setting-dataops-environment.html\">Data Science with Optimus Part 2: Setting your DataOps Environ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/top-news-week-0408-0414.html\">Top Stories, Apr 8-14: How to Recognize a Good Data Scientist ...</a><li> <a href=\"https://www.kdnuggets.com/2019/04/paw-hot-deep-learning-applications-las-vegas.html\">Hot Deep Learning Applications at Deep Learning World \u2013 Las ...</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/index.html\">Apr</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/04/opinions.html\">Opinions</a> \u00bb The Rise of Generative Adversarial Networks (\u00a0<a href=\"/2019/n16.html\">19:n16</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1555892600\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"center\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"center\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.720 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-04-21 20:23:20 -->\n<!-- Compression = gzip -->", "content": "\n    comments   \n By  Kailash Ahirwar   .  \n   \n Credit:\u00a0 https://en.wikipedia.org/wiki/Edmond_de_Belamy    \n 5 years back, Generative Adversarial Networks(GANs) started a revolution in deep learning. This revolution has produced some major technological breakthroughs. Generative Adversarial Networks were introduced by Ian Goodfellow and others in the paper titled \u201cGenerative Adversarial Networks\u201d\u200a\u2014\u200a https://arxiv.org/abs/1406.2661  . Academia accepted GANs with open hands and industry welcomed GANs with much fanfare too. The rise of GANs was inevitable.  \n First, the best thing about GANs is their nature of learning, which is unsupervised.  \u00a0GANs don\u2019t need labeled data, which makes GANs powerful as the boring work of data labeling is not required.  \n Second, the potential use-cases of GANs have put GANs at the center of conversations. They can generate high-quality images, enhance photos, generate images from text, convert images from one domain to another, change the appearance of the face image as age progresses and many more. The list is endless. We will cover some of the widely popular GAN architectures in this article.  \n Third, the endless research put around GANs is so mesmerizing that it grabs the attention of every other industry. We will be talking about major technological breakthroughs in the later section of this article.  \n The Birth  \n Generative Adversarial Network or GAN for short is a setup of two networks, a generator network, and a discriminator network. These two networks can be neural networks, ranging from convolutional neural networks, recurrent neural networks to auto-encoders. In this setup, two networks are engaged in a competitive game and trying to outdo each other, simultaneously, helping each other at their own tasks. After thousands of iterations, if everything goes well, the generator network gets perfect at generating realistically looking fake images and the discriminator network gets perfect at telling whether the image shown to it is fake or real. In other terms, the generator network transforms a random noise vector from a latent space(Not all GANs sample from a latent space) to a sample from real data set. Training a GAN is a very intuitive process. We simultaneously train both networks and they both get better with time.  \n GANs have plenty of real-world use cases like image generation, artwork generation, music generation, and video generation. Also, they can enhance the quality of your images, stylize or colorize your images, generate faces and can perform many more interesting tasks.  \n   \n Credit: O\u2019Reilly   \n The above image shows the architecture of a vanilla GAN network. First, a D-dimensional noise vector is sampled from a latent space and fed to the generator network. The generator network converts this noise vector to an image. Then this generated image is fed to the discriminator network for classification. The discriminator network keeps getting images from the real dataset and the images generated by the generator network. Its job is to discriminate between real and fake images. All GAN architectures follow the same design. This was the birth of GANs. Now explore the adolescent stage of GANs.  \n The Adolescence  \n In its adolescence, GANs produced widely popular architectures like DCGAN, StyleGAN, BigGAN, StackGAN, Pix2pix, Age-cGAN, CycleGAN. These architectures were presented with very promising results. By looking at the results, it was pretty clear that the GANs have reached in its adolescent stage. Let\u2019s explore these architectures in detail.  \n DCGAN  \n For the first time, convolutional neural networks were used within GANs and achieved impressive results. Before this, CNNs have shown unprecedented results in supervised computer vision tasks. But in GANs, CNNs were unexplored. DCGANs were introduced in the paper titled \u201cUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\u201d by Alec Radford, Luke Metz, Soumith Chintala. It was a major milestone in GANs research as it introduced major architectural changes to tackle problems like training instability, mode collapse, and internal covariate shift. Since then, numerous GAN architectures were introduced based on the architecture of DCGAN.  \n   \n Source:\u00a0 https://arxiv.org/pdf/1511.06434.pdf    \n BigGAN  \n This is the latest development in GANs for image generation. A Google intern and two researchers from Google\u2019s DeepMind division released a paper titled \u201cLarge Scale GAN Training for High Fidelity Natural Image Synthesis\u201d, available at \u00a0https://arxiv.org/abs/1809.11096  . This paper is an internship project by Andrew Brock from Heriot-Watt University in collaboration with Jeff Donahue and Karen Simonyan from DeepMind.  \n   \n Source:\u00a0 https://arxiv.org/pdf/1809.11096.pdf    \n These images are generated by BigGAN and as you see they are of impressive quality. For the first time, GANs have generated images with high fidelity and low variety gap. Previous highest Inception Score was 52.52 and BigGAN achieved an Inception Score of 166.3, which was 100% better than the State of the art(SOTA). Also, they improved The Frechet Inception Distance (FID) score from 18.65 to 9.6. These were very impressive results and I hope to see more development in this area. The most important improvement was orthogonal regularization to the generator.  \n   \n Source:\u00a0 https://arxiv.org/pdf/1809.11096.pdf    \n Isn\u2019t it impressive!  \n StyleGAN  \n StyleGAN is another major breakthrough in GANs research. StyleGAN was introduced by Nvidia, in the paper titled \u201cA Style-Based Generator Architecture for Generative Adversarial Network\u201d, available at the following link \u00a0https://arxiv.org/pdf/1710.10196.pdf  .  \n   \n Source:\u00a0 https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf    \n StyleGAN sets a new record in Face generation tasks. At the core of the algorithm is the style transfer techniques or style mixing. Apart from generating faces, it can generate high-quality images of cars, bedrooms etc. This is a major improvement in the GANs field and an inspiration for fellow deep learning researchers.  \n StackGAN  \n StackGANs were proposed by Han Zhang, Tao Xu, Hongsheng Li, and others in their paper titled StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks, which is available at the following link: \u00a0https://arxiv.org/pdf/1612.03242.pdf  . They used StackGANs to explore text-to-image synthesis with impressive results. A StackGAN is a pair of networks that generate realistic looking images when provided with a text description. My book titled \u201cGenerative Adversarial Networks Projects\u201d has a chapter dedicated to StackGANs.  \n   \n Source:\u00a0 https://arxiv.org/pdf/1612.03242.pdf    \n As you can see in the above image, StackGAN generated realistically looking images of birds when provided with a text description. The most important thing is that the generated images correctly resembles the text provided. Text-to-image synthesis has many real-world applications like generating images from text descriptions, converting a story in textual form to comic form, to create internal representations of text descriptions.  \n CycleGAN  \n CycleGANs have some really interesting use-cases, such as converting photos to paintings and vice versa, converting a picture taken in summer to a photo taken in winter and vice versa, or converting pictures of horses to pictures of zebras and vice versa. CycleGANs were proposed by Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros in a paper titled \u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\u201d, which is available at the following link: \u00a0https://arxiv.org/pdf/1703.10593  . CycleGANs explore different image-to-image translation use-cases.  \n   \n Source:\u00a0 https://arxiv.org/pdf/1703.10593.pdf    \n Pix2pix  \n For image-to-image translation tasks, pix2pix also shown impressive results. Be it converting night images to day images or vice versa, colorizing black and white images, translating sketches to photos and many more, Pix2pix has excelled in all these use-cases. The pix2pix network was introduced by Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros in their paper titled \u201cImage-to-Image Translation with Conditional Adversarial Networks\u201d, which is available at the following link:\u00a0 https://arxiv.org/abs/1611.07004  .  \n   \n Credit:\u00a0 https://phillipi.github.io/pix2pix/    \n This was an interactive demo, capable of generating real images from sketches.  \n Age-cGAN (Age Conditional Generative Adversarial Networks)  \n Face aging has many industry use cases, including cross-age face recognition, finding lost children, and in entertainment. Face aging with Conditional GANs was proposed by Grigory Antipov, Moez Baccouche, and Jean-Luc Dugelay in their paper titled Face Aging with Conditional Generative Adversarial Networks, which is available at the following link:\u00a0 https://arxiv.org/pdf/1702.01983.pdf.   \n   \n This image shows how Age-cGAN translated face from the source age to the target age.  \n These were some widely popular GAN architectures. Besides these, there are thousands of GAN architectures. It depends on your requirements which architecture will suit your need.  \n The Rise  \n As Famous Theoretical Physicist Richard Feynman says:  \n \u201cWhat I can\u2019t create, I don\u2019t understand\u201d    \n The idea behind GANs was to train networks which understand the data. GANs now started to understand the data, with this understanding they started to create realistic looking images. Let\u2019s witness the rise of GANs.  \n Edmond de\u00a0Belamy  \n Edmond de Belamy,\u00a0  a painting created by Generative Adversarial Networks was sold for a staggering amount of $432, 500 at Christie\u2019s auction. It was a big step in the progress of GANs. For the first time, the whole world witnessed GANs and their potential. Before this, GANs were mostly confined in research labs and used by machine learning engineers. This act became an entry of GANs to the general public.  \n   \n This Person Does Not Exist   \n You may be familiar with the website\u00a0 https://thispersondoesnotexist.com  . Last month, this was all over the Internet. The website,\u00a0 https://thispersondoesnotexist.com  \u00a0created by Philip Wan, who is a software engineer at Uber. He created this website based on the code released by NVIDIA titled StyleGAN. Every time you hit refresh, it generates a new fake face, which looks surprisingly real unable to tell whether it is fake or not. This is scary AF but disruptive at the same time. This technology has the potential to create endless virtual worlds.  \n   \n Source:\u00a0 https://thispersondoesnotexist.com/    \n Isn\u2019t it amazing!  \n Deep Fakes  \nDeepFakes is another scary AF but disruptive technology. Based on GANs, this can paste people\u2019s faces onto a target person in videos. DeepFakes was all over the Internet too. People speculated the downsides of this technology. But for AI researchers, this was a major breakthrough. This technology has the potential to save millions of dollars in the film industry where hours of editing required to change stuntman\u2019s face with actors face.   \n This technology will always be scary, but it is up to us to use it for social good.  \n   \n Credit:\u00a0 https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/    \n The Trend  \n StyleGAN currently is the sixth most trending python project on GitHub. The number of named GANs till now proposed are in thousands. This repository has a list of popular GANs and their respective papers\u00a0 https://github.com/hindupuravinash/the-gan-zoo   \n In Real-world  \n GANs have been used to enhance the graphics of games. I am super excited about this use-case of GANs. Recently, NVIDIA released a video, in which, it showed how GANs are used to gamify the environment in the video.  \n Conclusion  \n In this article, we have seen how GANs rose to fame and became a global phenomenon. I hope, we see the democratization of GANs in the coming years. In this article, we started with the birth of GANs. Then, we explored some widely popular GAN architectures. Finally, we witnessed the rise of GANs. When I see negative press around GANs, I am baffled. I believe, it is our responsibility to make everyone aware of the repercussions of GANs and how can we ethically and morally use GANs for our best. Let\u2019s all come together and spread positivity around GANs. GANs have so much potential to create new industries and jobs. We just have to make sure that it doesn\u2019t go into wrong hands.  \n Original  . Reposted with permission.  \n Bio  :\u00a0 Kailash Ahirwar  \u00a0is a Machine Learning and Deep Learning Enthusiast, Democratising Machine Learning and Deep Learning, making it available for one and all.  \n Resources:   \n \n On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education   \n Software for Analytics, Data Science, Data Mining, and Machine Learning   \n  \n Related:   \n \n Which Face is Real?   \n My favorite mind-blowing Machine Learning/AI breakthroughs   \n State of Deep Learning and Major Advances: H2 2018 Review   \n  \n   \n  \n     \n  ", "title": "The Rise of Generative Adversarial Networks  ", "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"https://www.linkedin.com/in/kailash-ahirwar-b1a59128/\">Kailash Ahirwar</a></b>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*DxLcti_LW1peTc8QRYsXHw.jpeg\" width=\"100%\"/></p>\n<p><strong>Credit:\u00a0<a data-href=\"https://en.wikipedia.org/wiki/Edmond_de_Belamy\" href=\"https://en.wikipedia.org/wiki/Edmond_de_Belamy\">https://en.wikipedia.org/wiki/Edmond_de_Belamy</a></strong></p>\n<p>5 years back, Generative Adversarial Networks(GANs) started a revolution in deep learning. This revolution has produced some major technological breakthroughs. Generative Adversarial Networks were introduced by Ian Goodfellow and others in the paper titled \u201cGenerative Adversarial Networks\u201d\u200a\u2014\u200a<a data-href=\"https://arxiv.org/abs/1406.2661\" href=\"https://arxiv.org/abs/1406.2661\">https://arxiv.org/abs/1406.2661</a>. Academia accepted GANs with open hands and industry welcomed GANs with much fanfare too. The rise of GANs was inevitable.</p>\n<p><span data-creator-ids=\"anon\">First, the best thing about GANs is their nature of learning, which is unsupervised.</span>\u00a0GANs don\u2019t need labeled data, which makes GANs powerful as the boring work of data labeling is not required.</p>\n<p>Second, the potential use-cases of GANs have put GANs at the center of conversations. They can generate high-quality images, enhance photos, generate images from text, convert images from one domain to another, change the appearance of the face image as age progresses and many more. The list is endless. We will cover some of the widely popular GAN architectures in this article.</p>\n<p>Third, the endless research put around GANs is so mesmerizing that it grabs the attention of every other industry. We will be talking about major technological breakthroughs in the later section of this article.</p>\n<h3>The Birth</h3>\n<p>Generative Adversarial Network or GAN for short is a setup of two networks, a generator network, and a discriminator network. These two networks can be neural networks, ranging from convolutional neural networks, recurrent neural networks to auto-encoders. In this setup, two networks are engaged in a competitive game and trying to outdo each other, simultaneously, helping each other at their own tasks. After thousands of iterations, if everything goes well, the generator network gets perfect at generating realistically looking fake images and the discriminator network gets perfect at telling whether the image shown to it is fake or real. In other terms, the generator network transforms a random noise vector from a latent space(Not all GANs sample from a latent space) to a sample from real data set. Training a GAN is a very intuitive process. We simultaneously train both networks and they both get better with time.</p>\n<p>GANs have plenty of real-world use cases like image generation, artwork generation, music generation, and video generation. Also, they can enhance the quality of your images, stylize or colorize your images, generate faces and can perform many more interesting tasks.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/0*AMKi83krt4kDBY6s.png\" width=\"100%\"/></p>\n<p><strong>Credit: O\u2019Reilly</strong></p>\n<p>The above image shows the architecture of a vanilla GAN network. First, a D-dimensional noise vector is sampled from a latent space and fed to the generator network. The generator network converts this noise vector to an image. Then this generated image is fed to the discriminator network for classification. The discriminator network keeps getting images from the real dataset and the images generated by the generator network. Its job is to discriminate between real and fake images. All GAN architectures follow the same design. This was the birth of GANs. Now explore the adolescent stage of GANs.</p>\n<h3>The Adolescence</h3>\n<p>In its adolescence, GANs produced widely popular architectures like DCGAN, StyleGAN, BigGAN, StackGAN, Pix2pix, Age-cGAN, CycleGAN. These architectures were presented with very promising results. By looking at the results, it was pretty clear that the GANs have reached in its adolescent stage. Let\u2019s explore these architectures in detail.</p>\n<h4>DCGAN</h4>\n<p>For the first time, convolutional neural networks were used within GANs and achieved impressive results. Before this, CNNs have shown unprecedented results in supervised computer vision tasks. But in GANs, CNNs were unexplored. DCGANs were introduced in the paper titled \u201cUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\u201d by Alec Radford, Luke Metz, Soumith Chintala. It was a major milestone in GANs research as it introduced major architectural changes to tackle problems like training instability, mode collapse, and internal covariate shift. Since then, numerous GAN architectures were introduced based on the architecture of DCGAN.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*BgeQMKbogG0aG3Uw0e0Msw.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1511.06434.pdf\" href=\"https://arxiv.org/pdf/1511.06434.pdf\">https://arxiv.org/pdf/1511.06434.pdf</a></strong></p>\n<h4>BigGAN</h4>\n<p>This is the latest development in GANs for image generation. A Google intern and two researchers from Google\u2019s DeepMind division released a paper titled \u201cLarge Scale GAN Training for High Fidelity Natural Image Synthesis\u201d, available at<a data-href=\"https://arxiv.org/abs/1809.11096\" href=\"https://arxiv.org/abs/1809.11096\">\u00a0https://arxiv.org/abs/1809.11096</a>. This paper is an internship project by Andrew Brock from Heriot-Watt University in collaboration with Jeff Donahue and Karen Simonyan from DeepMind.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/1*9hTIFDUzPbnxcHZIkMNepQ.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a href=\"https://arxiv.org/pdf/1809.11096.pdf\">https://arxiv.org/pdf/1809.11096.pdf</a></strong></p>\n<p>These images are generated by BigGAN and as you see they are of impressive quality. For the first time, GANs have generated images with high fidelity and low variety gap. Previous highest Inception Score was 52.52 and BigGAN achieved an Inception Score of 166.3, which was 100% better than the State of the art(SOTA). Also, they improved The Frechet Inception Distance (FID) score from 18.65 to 9.6. These were very impressive results and I hope to see more development in this area. The most important improvement was orthogonal regularization to the generator.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/1*4rsKMM6d_FDGi3dYTGkUJA.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1809.11096.pdf\" href=\"https://arxiv.org/pdf/1809.11096.pdf\">https://arxiv.org/pdf/1809.11096.pdf</a></strong></p>\n<p>Isn\u2019t it impressive!</p>\n<h4>StyleGAN</h4>\n<p>StyleGAN is another major breakthrough in GANs research. StyleGAN was introduced by Nvidia, in the paper titled \u201cA Style-Based Generator Architecture for Generative Adversarial Network\u201d, available at the following link<a data-href=\"https://arxiv.org/pdf/1710.10196.pdf\" href=\"https://arxiv.org/pdf/1710.10196.pdf\">\u00a0https://arxiv.org/pdf/1710.10196.pdf</a>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*No5lv7YyFUduZ-1M-qx5Bg.gif\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf\" href=\"https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf\">https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf</a></strong></p>\n<p>StyleGAN sets a new record in Face generation tasks. At the core of the algorithm is the style transfer techniques or style mixing. Apart from generating faces, it can generate high-quality images of cars, bedrooms etc. This is a major improvement in the GANs field and an inspiration for fellow deep learning researchers.</p>\n<h4>StackGAN</h4>\n<p>StackGANs were proposed by Han Zhang, Tao Xu, Hongsheng Li, and others in their paper titled StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks, which is available at the following link:<a data-href=\"https://arxiv.org/pdf/1612.03242.pdf\" href=\"https://arxiv.org/pdf/1612.03242.pdf\">\u00a0https://arxiv.org/pdf/1612.03242.pdf</a>. They used StackGANs to explore text-to-image synthesis with impressive results. A StackGAN is a pair of networks that generate realistic looking images when provided with a text description. My book titled \u201cGenerative Adversarial Networks Projects\u201d has a chapter dedicated to StackGANs.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*xNCTl8oGiBeB1YjEweTZxg.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1612.03242.pdf\" href=\"https://arxiv.org/pdf/1612.03242.pdf\">https://arxiv.org/pdf/1612.03242.pdf</a></strong></p>\n<p>As you can see in the above image, StackGAN generated realistically looking images of birds when provided with a text description. The most important thing is that the generated images correctly resembles the text provided. Text-to-image synthesis has many real-world applications like generating images from text descriptions, converting a story in textual form to comic form, to create internal representations of text descriptions.</p>\n<h4>CycleGAN</h4>\n<p>CycleGANs have some really interesting use-cases, such as converting photos to paintings and vice versa, converting a picture taken in summer to a photo taken in winter and vice versa, or converting pictures of horses to pictures of zebras and vice versa. CycleGANs were proposed by Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros in a paper titled \u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\u201d, which is available at the following link:<a data-href=\"https://arxiv.org/pdf/1703.10593.pdf\" href=\"https://arxiv.org/pdf/1703.10593.pdf\">\u00a0https://arxiv.org/pdf/1703.10593</a>. CycleGANs explore different image-to-image translation use-cases.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/2400/1*V81VkAl9yiucz9eGFAlxgQ.jpeg\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a data-href=\"https://arxiv.org/pdf/1703.10593.pdf\" href=\"https://arxiv.org/pdf/1703.10593.pdf\">https://arxiv.org/pdf/1703.10593.pdf</a></strong></p>\n<h4>Pix2pix</h4>\n<p>For image-to-image translation tasks, pix2pix also shown impressive results. Be it converting night images to day images or vice versa, colorizing black and white images, translating sketches to photos and many more, Pix2pix has excelled in all these use-cases. The pix2pix network was introduced by Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros in their paper titled \u201cImage-to-Image Translation with Conditional Adversarial Networks\u201d, which is available at the following link:\u00a0<a data-href=\"https://arxiv.org/abs/1611.07004\" href=\"https://arxiv.org/abs/1611.07004\">https://arxiv.org/abs/1611.07004</a>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*XqcBcoE9VyKuupxIiWL6Bg.jpeg\" width=\"100%\"/></p>\n<p><strong>Credit:\u00a0<a data-href=\"https://phillipi.github.io/pix2pix/\" href=\"https://phillipi.github.io/pix2pix/\">https://phillipi.github.io/pix2pix/</a></strong></p>\n<p>This was an interactive demo, capable of generating real images from sketches.</p>\n<h4>Age-cGAN (Age Conditional Generative Adversarial Networks)</h4>\n<p>Face aging has many industry use cases, including cross-age face recognition, finding lost children, and in entertainment. Face aging with Conditional GANs was proposed by Grigory Antipov, Moez Baccouche, and Jean-Luc Dugelay in their paper titled Face Aging with Conditional Generative Adversarial Networks, which is available at the following link:\u00a0<a data-href=\"https://arxiv.org/pdf/1702.01983.pdf.\" href=\"https://arxiv.org/pdf/1702.01983.pdf.\">https://arxiv.org/pdf/1702.01983.pdf.</a></p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*p1VK22zXlezG-T712nEhbQ.png\" width=\"100%\"/></p>\n<p>This image shows how Age-cGAN translated face from the source age to the target age.</p>\n<p>These were some widely popular GAN architectures. Besides these, there are thousands of GAN architectures. It depends on your requirements which architecture will suit your need.</p>\n<h3>The Rise</h3>\n<p>As Famous Theoretical Physicist Richard Feynman says:</p>\n<blockquote><p><em>\u201cWhat I can\u2019t create, I don\u2019t understand\u201d</em></p></blockquote>\n<p>The idea behind GANs was to train networks which understand the data. GANs now started to understand the data, with this understanding they started to create realistic looking images. Let\u2019s witness the rise of GANs.</p>\n<h4>Edmond de\u00a0Belamy</h4>\n<p><em>Edmond de Belamy,\u00a0</em>a painting created by Generative Adversarial Networks was sold for a staggering amount of $432, 500 at Christie\u2019s auction. It was a big step in the progress of GANs. For the first time, the whole world witnessed GANs and their potential. Before this, GANs were mostly confined in research labs and used by machine learning engineers. This act became an entry of GANs to the general public.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*ihb6F_7BZWpoRgh27SB5rg.jpeg\" width=\"100%\"/></p>\n<p><strong>This Person Does Not Exist</strong></p>\n<p>You may be familiar with the website\u00a0<a href=\"https://thispersondoesnotexist.com/\">https://thispersondoesnotexist.com</a>. Last month, this was all over the Internet. The website,\u00a0<a href=\"https://thispersondoesnotexist.com/\">https://thispersondoesnotexist.com</a>\u00a0created by Philip Wan, who is a software engineer at Uber. He created this website based on the code released by NVIDIA titled StyleGAN. Every time you hit refresh, it generates a new fake face, which looks surprisingly real unable to tell whether it is fake or not. This is scary AF but disruptive at the same time. This technology has the potential to create endless virtual worlds.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*Y6KW2MrcE0fYL1ikOMu5xg.png\" width=\"100%\"/></p>\n<p><strong>Source:\u00a0<a href=\"https://thispersondoesnotexist.com/\">https://thispersondoesnotexist.com/</a></strong></p>\n<p>Isn\u2019t it amazing!</p>\n<p><strong>Deep Fakes</strong><br>\nDeepFakes is another scary AF but disruptive technology. Based on GANs, this can paste people\u2019s faces onto a target person in videos. DeepFakes was all over the Internet too. People speculated the downsides of this technology. But for AI researchers, this was a major breakthrough. This technology has the potential to save millions of dollars in the film industry where hours of editing required to change stuntman\u2019s face with actors face.</br></p>\n<p>This technology will always be scary, but it is up to us to use it for social good.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*RalCJrBisSXSy88C_kXZVw.png\" width=\"100%\"/></p>\n<p><strong>Credit:\u00a0<a data-href=\"https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/\" href=\"https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/\">https://thenextweb.com/artificial-intelligence/2018/02/21/deepfakes-algorithm-nails-donald-trump-in-most-convincing-fake-yet/</a></strong></p>\n<h4>The Trend</h4>\n<p>StyleGAN currently is the sixth most trending python project on GitHub. The number of named GANs till now proposed are in thousands. This repository has a list of popular GANs and their respective papers\u00a0<a data-href=\"https://github.com/hindupuravinash/the-gan-zoo\" href=\"https://github.com/hindupuravinash/the-gan-zoo\">https://github.com/hindupuravinash/the-gan-zoo</a></p>\n<h4>In Real-world</h4>\n<p>GANs have been used to enhance the graphics of games. I am super excited about this use-case of GANs. Recently, NVIDIA released a video, in which, it showed how GANs are used to gamify the environment in the video.</p>\n<h4>Conclusion</h4>\n<p>In this article, we have seen how GANs rose to fame and became a global phenomenon. I hope, we see the democratization of GANs in the coming years. In this article, we started with the birth of GANs. Then, we explored some widely popular GAN architectures. Finally, we witnessed the rise of GANs. When I see negative press around GANs, I am baffled. I believe, it is our responsibility to make everyone aware of the repercussions of GANs and how can we ethically and morally use GANs for our best. Let\u2019s all come together and spread positivity around GANs. GANs have so much potential to create new industries and jobs. We just have to make sure that it doesn\u2019t go into wrong hands.</p>\n<p><a href=\"https://blog.usejournal.com/the-rise-of-generative-adversarial-networks-be52d424e517\">Original</a>. Reposted with permission.</p>\n<p><strong>Bio</strong>:\u00a0<a href=\"https://www.linkedin.com/in/kailash-ahirwar-b1a59128/\">Kailash Ahirwar</a>\u00a0is a Machine Learning and Deep Learning Enthusiast, Democratising Machine Learning and Deep Learning, making it available for one and all.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html\">Which Face is Real?</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html\">My favorite mind-blowing Machine Learning/AI breakthroughs</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/deep-learning-major-advances-review.html\">State of Deep Learning and Major Advances: H2 2018 Review</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p> <script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div> ", "url": "https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html"}