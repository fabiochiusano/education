{"url": "https://www.kdnuggets.com/2019/03/explainable-ai.html", "title": "Explainable AI or Halting Faulty Models ahead of Disaster", "title_html": "<h1 id=\"title\">Explainable AI or Halting Faulty Models ahead of Disaster</h1>", "content": "\n  comments \n By Tobias Goerke \n Equipping Titanic with Anchors: Halting Faulty Models ahead of Disaster \n On Kaggle, a surprisingly large number of the Titanic challenge entries exhibit a score of 100%. Experienced machine learning experts will know about the challenge's complexity and rightfully question the results' validity. At the same time, submissions like this Notebook illustrate how the Titanic competition's leaderboard can be forged effortlessly; A top-performing model can be created by collecting and including the publicly accessible list of survivors. Clearly, such overfit models only work for one very specific use case and are virtually useless for predicting outcomes in any other situation (not to mention the ethics of cheating). So, how can we make sure we have trained or are provided with a model that we can actually use in production? How can machine learning systems be deployed without likely ensuing disaster? \n Explainable artificial intelligence, or XAI, seeks to answer these questions. It aims to provide explanations which are understandable for humans to ultimately increase trust in produced models. Based on the idea that humans can superiorly generalize even in unknown situations, a user can then check this explanation and see if the model uses the right cues to infer its decision. If it does, it probably classifies similar, albeit unknown, situations correctly and creates trust. \n  \n A novel addition to this new field of research, called anchors, seems particularly promising (find the paper here). It was proposed by the inventor of the LIME approach and patches several shortcomings of its predecessors. Anchors provides local explanations to any black box classifier regardless of the underlying technology and algorithm. Each explanation is valid for a single selected prediction using IF-THEN rules, of which each predicate fixes one feature of the input instance. Therefore, each result provides clear coverage, i.e., states for which other instances it is valid and with which probability. \n This article examines two different models that were trained on the Titanic training dataset. The anchors algorithm is then used to explain why and based on which features these black boxes predict a passenger's survival or death. \n Implementation Process Overview \n Before going into detail with the tutorial's implementation, anchors' mode of operations and components is briefly outlined: at its core, the algorithm deploys a perturbation-based strategy. That means that the observed or explained instance gets perturbed, i.e., its feature values changed to some application-specific policy. The resulting data instances resemble neighbors of the initial instance. This way, feature importances, and contributions can be determined systematically by evaluating them using the model.\nUnderstandably, querying the model often is expensive. Also, there can be no exhaustive search in the case of continuous or sufficiently complex models. Reinforcement learning and its multi-armed bandits (MABs) provide a solution to this problem. They help to significantly reduce the number of samples required by using stochastic exploration approaches. \n The above process, algorithmic improvements and several add-ons are implemented by our newly released anchorj Java application. anchorj was designed as a high-performance alternative to the initial author's proof-of-concept (see here) and can be found on GitHub. It constitutes the first open-source Java anchors implementation and is licensed under the BSD 3-Clause License. Thus, it can be used freely with minimal restrictions. \n Open collaboration and discussions on this open-source GitHub project are more than welcome. \n The Explained Instances \n We produce explanations of two data instances from the training set that exhibit distinct attributes and whose explanations can well be comprehended by users. \n \nLucy Noel Martha Dyer-Edwards, The Countess of Rothes, Age 33, First Class Passenger, Cabin B77, Fare 86.5$, Survived.\nMr. Patrick Dooley, Age 32, Third Class Passenger, Cabin unknown, Fare 7.75$, Did not survive.\n \n Humans can most probably make an educated guess about why the Countess of Rothes did survive the Titanic disaster, while third class passenger Mr. Dooley did not (see here for more info). Using this knowledge users can validate the models when given explanations about a model's functioning. \n Preparation: Dataset and Models \n The provided .csv files containing all data instances are easily loaded by using our implementation. Further, models are used that are able to predict outcomes for these instances. These will later be explained by using anchorj. One is a pre-trained GBM imported from h4O/R and the other is a random forest. However, it really does not matter which kind of model is used. Anchors is able to deal with any type of model, as long as its predict/classify function is accessible. \n Creating Explanations \n Using anchorj is as simple as defining the model and the instance to be explained. All other parameters can be configured optionally. \n AnchorResult anchor = anchorTabular\r\n    .createDefaultBuilder(h4oModel::predict, explainedInstance)\r\n    // Many more options\r\n    .build()\r\n    .constructAnchor();\r\n \n The results are visualized below: \n Countess of Rothes \n Imported Model: \n IF Sex = 'female' AND \r\nSibSp = '0' AND \r\nPclass = '1' AND \r\nAge IN RANGE [28,38]\r\nTHEN PREDICT 1\r\nWITH PRECISION 1.0 AND COVERAGE 0.01\r\n \n Random Forest: \n IF Sex = 'female' AND \r\nFare IN RANGE [53,512] AND \r\nPclass = '1' \r\nTHEN PREDICT 1\r\nWITH PRECISION 1.0 AND COVERAGE 0.08\r\n \n Patrick Dooley \n Imported Model: \n IF Sex = 'male' AND \r\nAge IN RANGE [28,38] AND \r\nFare IN RANGE [0,8] AND \r\nSibSp = '0' \r\nTHEN PREDICT 0\r\nWITH PRECISION 1.0 AND COVERAGE 0.05\r\n \n Random Forest: \n IF Sex = 'male' AND \r\nPclass = '3' AND \r\nCabin = 'false' AND \r\nParch = '0' \r\nTHEN PREDICT 0\r\nWITH PRECISION 1.0 AND COVERAGE 0.33\r\n \n Explaining the explanation: a result's first part consists of its predicates, i.e., conditions and prediction specifying for which instances it is valid. After this, the precision and coverage are stated. In our case, coverage refers to the share of entries the rule holds for. The last rule, for example, covers 33% of the instances, meaning 33% are male, third-class and so forth. In these cases, the result is 100% precise, meaning for these passengers the prediction is the same with a 100% probability. \n These results show that both models have learned mostly correct associations. Both models come to their decisions by \"thinking\" that female first-class passengers likely survive, while male passengers do not. However, the imported model takes into account more specific features that are probably harder to generalize.\nIn combination with the low accuracy and coverage, this points to a faulty model which probably generalizes poorly. On the contrary, the random forest takes features into account that we would actually expect to be present in an explanation. Its explanations also exhibit a high coverage, indicating it has learned generally valid coherencies.\nNonetheless, both models miss taking the name of the passengers into account. We would expect longer, aristocratic, names to be an indicator for survival. The knowledge we gained out of these explanations could be used to amend the random forests model's training process until, ultimately, explanations are satisfactorily, and build trust. \n Summary and Collaboration \n Anchors and anchorj aim to make machine learning productively viable by providing the means to detect faulty models before they are deployed. They close the gap between opportunities created by machine learning technology and the associated risks. In our example, we have shown how a specific model can be validated or refuted by including humans into the loop. \n Anchors' application is not limited to this type of problem. It can, for example, be used by global explainers to explain a larger part of the model. Such algorithms and various other features are included in our implementation. See you on GitHub! \n Bio: Tobias Goerke is an IT-Consultant and XAI researcher at the viadee Consulting AG, Germany. He recently finished his M.Sc. in Information Systems. \n Resources: \n \nOn-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education\nSoftware for Analytics, Data Science, Data Mining, and Machine Learning\n \n Related: \n \nThe AI Black Box Explanation Problem\nExplainable Artificial Intelligence\nA Case For Explainable AI & Machine Learning\n \n  \n  \n \n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n  \n", "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Explainable AI or Halting Faulty Models ahead of Disaster</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/explainable-ai.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Explainable AI or Halting Faulty Models ahead of Disaster Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/how-choose-right-chart-type.html\" rel=\"prev\" title=\"How to Choose the Right Chart Type\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/activestate-python-programmer.html\" rel=\"next\" title=\"[PDF] Python: The Programmer\u2019s Lingua Franca\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/03/explainable-ai.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=92292\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/explainable-ai.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-92292 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 27-Mar, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/opinions.html\">Opinions</a> \u00bb Explainable AI or Halting Faulty Models ahead of Disaster (\u00a0<a href=\"/2019/n13.html\">19:n13</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Explainable AI or Halting Faulty Models ahead of Disaster</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/how-choose-right-chart-type.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/activestate-python-programmer.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/ai\" rel=\"tag\">AI</a>, <a href=\"https://www.kdnuggets.com/tag/explainable-ai\" rel=\"tag\">Explainable AI</a>, <a href=\"https://www.kdnuggets.com/tag/kaggle\" rel=\"tag\">Kaggle</a>, <a href=\"https://www.kdnuggets.com/tag/lime\" rel=\"tag\">LIME</a>, <a href=\"https://www.kdnuggets.com/tag/titanic\" rel=\"tag\">Titanic</a></div>\n<br/>\n<p class=\"excerpt\">\n     A brief overview of a new method for explainable AI (XAI), called anchors, introduce its open-source implementation and show how to use it to explain models predicting the survival of Titanic passengers. \n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By Tobias Goerke</b></p>\n<h3 id=\"equipping-titanic-with-anchors-br-halting-faulty-models-ahead-of-disaster\">Equipping Titanic with Anchors: Halting Faulty Models ahead of Disaster</h3>\n<p>On Kaggle, a surprisingly large number of the Titanic challenge entries exhibit a score of 100%. Experienced machine learning experts will know about the challenge's complexity and rightfully question the results' validity. At the same time, submissions like <a href=\"https://www.kaggle.com/tarunpaparaju/how-top-lb-got-their-score-use-titanic-to-learn\">this Notebook</a> illustrate how the Titanic competition's leaderboard can be forged effortlessly; A top-performing model can be created by collecting and including the publicly accessible list of survivors. Clearly, such overfit models only work for one very specific use case and are virtually useless for predicting outcomes in any other situation (not to mention the ethics of cheating). So, how can we make sure we have trained or are provided with a model that we can actually use in production? How can machine learning systems be deployed without likely ensuing disaster?</p>\n<p><em>Explainable artificial intelligence</em>, or <strong>XAI</strong>, seeks to answer these questions. It aims to provide explanations which are understandable for humans to ultimately increase trust in produced models. Based on the idea that humans can superiorly generalize even in unknown situations, a user can then check this explanation and see if the model uses the right cues to infer its decision. If it does, it probably classifies similar, albeit unknown, situations correctly and creates trust.</p>\n<p><img alt=\"AI\" class=\"size-full wp-image-59142 alignleft\" sizes=\"(max-width: 565px) 100vw, 565px\" src=\"https://www.kdnuggets.com/wp-content/uploads/artificial-intelligence-agi.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/artificial-intelligence-agi.jpg 565w, https://www.kdnuggets.com/wp-content/uploads/artificial-intelligence-agi-300x159.jpg 300w\" width=\"50%\"/></p>\n<p>A novel addition to this new field of research, called <strong>anchors</strong>, seems particularly promising (find the paper <a href=\"https://homes.cs.washington.edu/~marcotcr/aaai18.pdf\">here</a>). It was proposed by the inventor of the <strong>LIME</strong> approach and patches several shortcomings of its predecessors. Anchors provides local explanations to any black box classifier regardless of the underlying technology and algorithm. Each explanation is valid for a single selected prediction using <em>IF-THEN rules</em>, of which each predicate fixes one feature of the input instance. Therefore, each result provides clear <em>coverage</em>, i.e., states for which other instances it is valid and with which probability.</p>\n<p>This article examines two different models that were trained on the Titanic training dataset. The anchors algorithm is then used to explain <em>why</em> and based on which features these black boxes predict a passenger's survival or death.</p>\n<h4 id=\"implementation-process-overview\">Implementation Process Overview</h4>\n<p>Before going into detail with the tutorial's implementation, anchors' mode of operations and components is briefly outlined: at its core, the algorithm deploys a <em>perturbation</em>-based strategy. That means that the observed or explained instance gets perturbed, i.e., its feature values changed to some application-specific policy. The resulting data instances resemble neighbors of the initial instance. This way, feature importances, and contributions can be determined systematically by evaluating them using the model.<br>\nUnderstandably, querying the model often is expensive. Also, there can be no exhaustive search in the case of continuous or sufficiently complex models. Reinforcement learning and its <em>multi-armed bandits (MABs)</em> provide a solution to this problem. They help to significantly reduce the number of samples required by using stochastic exploration approaches.</br></p>\n<p>The above process, algorithmic improvements and several add-ons are implemented by our newly released <strong>anchorj</strong> Java application. anchorj was designed as a high-performance alternative to the initial author's proof-of-concept (see <a href=\"https://github.com/marcotcr/anchor\">here</a>) and can be found on <a href=\"https://github.com/viadee/javaAnchorExplainer\">GitHub</a>. It constitutes the <strong>first open-source Java anchors implementation</strong> and is licensed under the BSD 3-Clause License. Thus, it can be <strong>used freely with minimal restrictions</strong>.</p>\n<p><strong>Open collaboration and discussions on this open-source GitHub project are more than welcome.</strong></p>\n<h4 id=\"the-explained-instances\">The Explained Instances</h4>\n<p>We produce explanations of two data instances from the training set that exhibit distinct attributes and whose explanations can well be comprehended by users.</p>\n<ol>\n<li>Lucy Noel Martha Dyer-Edwards, The Countess of Rothes, Age 33, First Class Passenger, Cabin B77, Fare 86.5$, Survived.</li>\n<li>Mr. Patrick Dooley, Age 32, Third Class Passenger, Cabin unknown, Fare 7.75$, Did not survive.</li>\n</ol>\n<p>Humans can most probably make an educated guess about why the Countess of Rothes did survive the Titanic disaster, while third class passenger Mr. Dooley did not (<a href=\"https://www.huffingtonpost.com/frances-wilson/survive-the-titanic_b_1020672.html?guccounter=1&amp;guce_referrer_us=aHR0cHM6Ly9kdWNrZHVja2dvLmNvbS8&amp;guce_referrer_cs=Xc3TANoVUz5834QElWIOSA&amp;slideshow=true#gallery/5bb60e50e4b039c2956797b0/0\">see here for more info)</a>. Using this knowledge users can validate the models when given explanations about a model's functioning.</p>\n<h4 id=\"preparation-dataset-and-models\">Preparation: Dataset and Models</h4>\n<p>The provided <em>.csv</em> files containing all data instances are easily loaded by using our implementation. Further, models are used that are able to predict outcomes for these instances. These will later be explained by using anchorj. One is a pre-trained GBM imported from h4O/R and the other is a random forest. However, it really does not matter which kind of model is used. Anchors is able to deal with <em>any</em> type of model, as long as its predict/classify function is accessible.</p>\n<h4 id=\"creating-explanations\">Creating Explanations</h4>\n<p>Using anchorj is as simple as defining the model and the instance to be explained. All other parameters can be configured optionally.</p>\n<pre>AnchorResult anchor = anchorTabular\r\n    .createDefaultBuilder(h4oModel::predict, explainedInstance)\r\n    // Many more options\r\n    .build()\r\n    .constructAnchor();\r\n</pre>\n<p>The results are visualized below:</p>\n<h4 id=\"countess-of-rothes-\">Countess of Rothes</h4>\n<p>Imported Model:</p>\n<pre>IF Sex = 'female' AND \r\nSibSp = '0' AND \r\nPclass = '1' AND \r\nAge IN RANGE [28,38]\r\nTHEN PREDICT 1\r\nWITH PRECISION 1.0 AND COVERAGE 0.01\r\n</pre>\n<p>Random Forest:</p>\n<pre>IF Sex = 'female' AND \r\nFare IN RANGE [53,512] AND \r\nPclass = '1' \r\nTHEN PREDICT 1\r\nWITH PRECISION 1.0 AND COVERAGE 0.08\r\n</pre>\n<h4 id=\"patrick-dooley\">Patrick Dooley</h4>\n<p>Imported Model:</p>\n<pre>IF Sex = 'male' AND \r\nAge IN RANGE [28,38] AND \r\nFare IN RANGE [0,8] AND \r\nSibSp = '0' \r\nTHEN PREDICT 0\r\nWITH PRECISION 1.0 AND COVERAGE 0.05\r\n</pre>\n<p>Random Forest:</p>\n<pre>IF Sex = 'male' AND \r\nPclass = '3' AND \r\nCabin = 'false' AND \r\nParch = '0' \r\nTHEN PREDICT 0\r\nWITH PRECISION 1.0 AND COVERAGE 0.33\r\n</pre>\n<p>Explaining the explanation: a result's first part consists of its predicates, i.e., conditions and prediction specifying for which instances it is valid. After this, the precision and coverage are stated. In our case, coverage refers to the share of entries the rule holds for. The last rule, for example, covers <em>33%</em> of the instances, meaning <em>33%</em> are male, third-class and so forth. In these cases, the result is <em>100%</em> precise, meaning for these passengers the prediction is the same with a <em>100%</em> probability.</p>\n<p>These results show that both models have learned mostly correct associations. Both models come to their decisions by \"thinking\" that female first-class passengers likely survive, while male passengers do not. However, the imported model takes into account more specific features that are probably harder to generalize.<br>\nIn combination with the low accuracy and coverage, this points to a faulty model which probably generalizes poorly. On the contrary, the random forest takes features into account that we would actually expect to be present in an explanation. Its explanations also exhibit a high coverage, indicating it has learned generally valid coherencies.<br>\nNonetheless, both models miss taking the name of the passengers into account. We would expect longer, aristocratic, names to be an indicator for survival. The knowledge we gained out of these explanations could be used to amend the random forests model's training process until, ultimately, explanations are satisfactorily, and build trust.</br></br></p>\n<h4 id=\"summary-and-collaboration\">Summary and Collaboration</h4>\n<p>Anchors and anchorj aim to make machine learning <em>productively viable</em> by providing the means to detect <em>faulty models</em> before they are deployed. They close the gap between opportunities created by machine learning technology and the associated risks. In our example, we have shown how a specific model can be validated or refuted by including humans into the loop.</p>\n<p>Anchors' application is not limited to this type of problem. It can, for example, be used by global explainers to explain a larger part of the model. Such algorithms and various other features are included in our implementation. See you on GitHub!</p>\n<p><b>Bio: </b>Tobias Goerke is an IT-Consultant and XAI researcher at the viadee Consulting AG, Germany. He recently finished his M.Sc. in Information Systems.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/03/ai-black-box-explanation-problem.html\">The AI Black Box Explanation Problem</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/01/explainable-ai.html\">Explainable Artificial Intelligence</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/explainable-ai-machine-learning.html\">A Case For Explainable AI &amp; Machine Learning</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/how-choose-right-chart-type.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/activestate-python-programmer.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-1-another-10');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-2-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/03/data-science-job-applications.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-3-tell-you');\"><b>What no one will tell you about data science job applications</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/02/asking-great-questions-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-5-great-questions');\"><b>Asking Great Questions as a Data Scientist</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/03/women-ai-big-data-science-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-7-19-inspiring-women');\"><b>19 Inspiring Women in AI, Big Data, Data Science, Machine Learning</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-1-ann-genetic');\"><b>Artificial Neural Networks Optimization using Genetic Algorithm with Python</b></a>\n<li> <a href=\"/2019/02/artificial-neural-network-implementation-using-numpy-and-image-classification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-2-ann-numpy-images');\"><b>Artificial Neural Network Implementation using NumPy and Image Classification</b></a>\n<li> <a href=\"/2019/02/setup-python-environment-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-3-py-ml-setup');\"><b>How to Setup a Python Environment for Machine Learning</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-5-azure-cert');\"><b>8 Reasons Why You Should Get a Microsoft Azure Certification</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/02/running-r-and-python-in-jupyter.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-7-r-python-jupyter');\"><b>Running R and Python in Jupyter</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/03/datathon-data-science-hackathon-april.html\">Datathon 2019: The International Data Science Hackathon...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/random-forest-python.html\">Explaining Random Forest (with Python Implementation)</a><li> <a href=\"https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html\">A Beginner\u2019s Guide to Linear Regression in Python wit...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html\">Interpolation in Autoencoders via an Adversarial Regula...</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/03-29-cisco-machine-learning-engineer-support-bot-b.html\">Cisco: Machine Learning Engineer/Support Bot Designer [...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/delaware-gain-skills-need-data-driven-career.html\">Gain the Skills You Need to Level-Up in Your Data-Drive...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/03/delaware-gain-skills-need-data-driven-career.html\">Gain the Skills You Need to Level-Up in Your Data-Driven Career</a><li> <a href=\"https://www.kdnuggets.com/2019/03/d3js-graph-gallery-data-visualization.html\">D3.js Graph Gallery for Data Visualization</a><li> <a href=\"https://www.kdnuggets.com/2019/03/7-gotchas-data-engineers-google-bigquery.html\">7 \u201cGotchas\u201d for Data Engineers New to Google BigQuery</a><li> <a href=\"https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html\">The Deep Learning Toolset\u200a\u2014\u200aAn Overview</a><li> <a href=\"https://www.kdnuggets.com/2019/03/top-tweets-mar20-26.html\">Top tweets, Mar 20-26: 10 More Free Must-Read Books for Mac...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/ieg-network-google-intel-facebook.html\">Network with Google, Intel, Facebook, LinkedIn &amp; more</a><li> <a href=\"https://www.kdnuggets.com/2019/03/activestate-python-programmer.html\">[PDF] Python: The Programmer\u2019s Lingua Franca</a><li> <a href=\"https://www.kdnuggets.com/2019/03/explainable-ai.html\">Explainable AI or Halting Faulty Models ahead of Disaster</a><li> <a href=\"https://www.kdnuggets.com/2019/03/how-choose-right-chart-type.html\">How to Choose the Right Chart Type</a><li> <a href=\"https://www.kdnuggets.com/2019/03/data-pipelines-luigi-airflow-everything-need-know.html\">Data Pipelines, Luigi, Airflow: Everything you need to know</a><li> <a href=\"https://www.kdnuggets.com/2019/n12.html\">KDnuggets 19:n12, Mar 27: My Best Tips for Agile Data Scien...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/top-news-week-0318-0324.html\">Top Stories, Mar 18-24: Another 10 Free Must-Read Books for Ma...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/databricks-solve-big-problems-data-science-ebook.html\">How to solve 4 big problems in data science \u2013 eBook.</a><li> <a href=\"https://www.kdnuggets.com/2019/03/four-levels-analytics-maturity.html\">The Four Levels of Analytics Maturity</a><li> <a href=\"https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html\">Pedestrian Detection in Aerial Images Using RetinaNet</a><li> <a href=\"https://www.kdnuggets.com/2019/03/data-science-decision-makers.html\">Data Science for Decision Makers: A Discussion with Dr Stelios...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/coursera-earn-ibm-data-science-certificate.html\">Earn an IBM Data Science Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/03/databricks-scaling-big-data-ai-spark-ai-summit-2019.html\">Scaling Big Data and AI \u2013 Spark + AI Summit 2019</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/03-25-pear-therapeutics-data-scientist.html\">Pear Therapeutics: Data Scientist (Analytics) [San Francisco, ...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/ai-black-box-explanation-problem.html\">The AI Black Box Explanation Problem</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/opinions.html\">Opinions</a> \u00bb Explainable AI or Halting Faulty Models ahead of Disaster (\u00a0<a href=\"/2019/n13.html\">19:n13</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1553990857\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"bottom-right\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"bottom-right\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.703 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-03-30 20:07:37 -->\n<!-- Compression = gzip -->", "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By Tobias Goerke</b></p>\n<h3 id=\"equipping-titanic-with-anchors-br-halting-faulty-models-ahead-of-disaster\">Equipping Titanic with Anchors: Halting Faulty Models ahead of Disaster</h3>\n<p>On Kaggle, a surprisingly large number of the Titanic challenge entries exhibit a score of 100%. Experienced machine learning experts will know about the challenge's complexity and rightfully question the results' validity. At the same time, submissions like <a href=\"https://www.kaggle.com/tarunpaparaju/how-top-lb-got-their-score-use-titanic-to-learn\">this Notebook</a> illustrate how the Titanic competition's leaderboard can be forged effortlessly; A top-performing model can be created by collecting and including the publicly accessible list of survivors. Clearly, such overfit models only work for one very specific use case and are virtually useless for predicting outcomes in any other situation (not to mention the ethics of cheating). So, how can we make sure we have trained or are provided with a model that we can actually use in production? How can machine learning systems be deployed without likely ensuing disaster?</p>\n<p><em>Explainable artificial intelligence</em>, or <strong>XAI</strong>, seeks to answer these questions. It aims to provide explanations which are understandable for humans to ultimately increase trust in produced models. Based on the idea that humans can superiorly generalize even in unknown situations, a user can then check this explanation and see if the model uses the right cues to infer its decision. If it does, it probably classifies similar, albeit unknown, situations correctly and creates trust.</p>\n<p><img alt=\"AI\" class=\"size-full wp-image-59142 alignleft\" sizes=\"(max-width: 565px) 100vw, 565px\" src=\"https://www.kdnuggets.com/wp-content/uploads/artificial-intelligence-agi.jpg\" srcset=\"https://www.kdnuggets.com/wp-content/uploads/artificial-intelligence-agi.jpg 565w, https://www.kdnuggets.com/wp-content/uploads/artificial-intelligence-agi-300x159.jpg 300w\" width=\"50%\"/></p>\n<p>A novel addition to this new field of research, called <strong>anchors</strong>, seems particularly promising (find the paper <a href=\"https://homes.cs.washington.edu/~marcotcr/aaai18.pdf\">here</a>). It was proposed by the inventor of the <strong>LIME</strong> approach and patches several shortcomings of its predecessors. Anchors provides local explanations to any black box classifier regardless of the underlying technology and algorithm. Each explanation is valid for a single selected prediction using <em>IF-THEN rules</em>, of which each predicate fixes one feature of the input instance. Therefore, each result provides clear <em>coverage</em>, i.e., states for which other instances it is valid and with which probability.</p>\n<p>This article examines two different models that were trained on the Titanic training dataset. The anchors algorithm is then used to explain <em>why</em> and based on which features these black boxes predict a passenger's survival or death.</p>\n<h4 id=\"implementation-process-overview\">Implementation Process Overview</h4>\n<p>Before going into detail with the tutorial's implementation, anchors' mode of operations and components is briefly outlined: at its core, the algorithm deploys a <em>perturbation</em>-based strategy. That means that the observed or explained instance gets perturbed, i.e., its feature values changed to some application-specific policy. The resulting data instances resemble neighbors of the initial instance. This way, feature importances, and contributions can be determined systematically by evaluating them using the model.<br>\nUnderstandably, querying the model often is expensive. Also, there can be no exhaustive search in the case of continuous or sufficiently complex models. Reinforcement learning and its <em>multi-armed bandits (MABs)</em> provide a solution to this problem. They help to significantly reduce the number of samples required by using stochastic exploration approaches.</br></p>\n<p>The above process, algorithmic improvements and several add-ons are implemented by our newly released <strong>anchorj</strong> Java application. anchorj was designed as a high-performance alternative to the initial author's proof-of-concept (see <a href=\"https://github.com/marcotcr/anchor\">here</a>) and can be found on <a href=\"https://github.com/viadee/javaAnchorExplainer\">GitHub</a>. It constitutes the <strong>first open-source Java anchors implementation</strong> and is licensed under the BSD 3-Clause License. Thus, it can be <strong>used freely with minimal restrictions</strong>.</p>\n<p><strong>Open collaboration and discussions on this open-source GitHub project are more than welcome.</strong></p>\n<h4 id=\"the-explained-instances\">The Explained Instances</h4>\n<p>We produce explanations of two data instances from the training set that exhibit distinct attributes and whose explanations can well be comprehended by users.</p>\n<ol>\n<li>Lucy Noel Martha Dyer-Edwards, The Countess of Rothes, Age 33, First Class Passenger, Cabin B77, Fare 86.5$, Survived.</li>\n<li>Mr. Patrick Dooley, Age 32, Third Class Passenger, Cabin unknown, Fare 7.75$, Did not survive.</li>\n</ol>\n<p>Humans can most probably make an educated guess about why the Countess of Rothes did survive the Titanic disaster, while third class passenger Mr. Dooley did not (<a href=\"https://www.huffingtonpost.com/frances-wilson/survive-the-titanic_b_1020672.html?guccounter=1&amp;guce_referrer_us=aHR0cHM6Ly9kdWNrZHVja2dvLmNvbS8&amp;guce_referrer_cs=Xc3TANoVUz5834QElWIOSA&amp;slideshow=true#gallery/5bb60e50e4b039c2956797b0/0\">see here for more info)</a>. Using this knowledge users can validate the models when given explanations about a model's functioning.</p>\n<h4 id=\"preparation-dataset-and-models\">Preparation: Dataset and Models</h4>\n<p>The provided <em>.csv</em> files containing all data instances are easily loaded by using our implementation. Further, models are used that are able to predict outcomes for these instances. These will later be explained by using anchorj. One is a pre-trained GBM imported from h4O/R and the other is a random forest. However, it really does not matter which kind of model is used. Anchors is able to deal with <em>any</em> type of model, as long as its predict/classify function is accessible.</p>\n<h4 id=\"creating-explanations\">Creating Explanations</h4>\n<p>Using anchorj is as simple as defining the model and the instance to be explained. All other parameters can be configured optionally.</p>\n<pre>AnchorResult anchor = anchorTabular\r\n    .createDefaultBuilder(h4oModel::predict, explainedInstance)\r\n    // Many more options\r\n    .build()\r\n    .constructAnchor();\r\n</pre>\n<p>The results are visualized below:</p>\n<h4 id=\"countess-of-rothes-\">Countess of Rothes</h4>\n<p>Imported Model:</p>\n<pre>IF Sex = 'female' AND \r\nSibSp = '0' AND \r\nPclass = '1' AND \r\nAge IN RANGE [28,38]\r\nTHEN PREDICT 1\r\nWITH PRECISION 1.0 AND COVERAGE 0.01\r\n</pre>\n<p>Random Forest:</p>\n<pre>IF Sex = 'female' AND \r\nFare IN RANGE [53,512] AND \r\nPclass = '1' \r\nTHEN PREDICT 1\r\nWITH PRECISION 1.0 AND COVERAGE 0.08\r\n</pre>\n<h4 id=\"patrick-dooley\">Patrick Dooley</h4>\n<p>Imported Model:</p>\n<pre>IF Sex = 'male' AND \r\nAge IN RANGE [28,38] AND \r\nFare IN RANGE [0,8] AND \r\nSibSp = '0' \r\nTHEN PREDICT 0\r\nWITH PRECISION 1.0 AND COVERAGE 0.05\r\n</pre>\n<p>Random Forest:</p>\n<pre>IF Sex = 'male' AND \r\nPclass = '3' AND \r\nCabin = 'false' AND \r\nParch = '0' \r\nTHEN PREDICT 0\r\nWITH PRECISION 1.0 AND COVERAGE 0.33\r\n</pre>\n<p>Explaining the explanation: a result's first part consists of its predicates, i.e., conditions and prediction specifying for which instances it is valid. After this, the precision and coverage are stated. In our case, coverage refers to the share of entries the rule holds for. The last rule, for example, covers <em>33%</em> of the instances, meaning <em>33%</em> are male, third-class and so forth. In these cases, the result is <em>100%</em> precise, meaning for these passengers the prediction is the same with a <em>100%</em> probability.</p>\n<p>These results show that both models have learned mostly correct associations. Both models come to their decisions by \"thinking\" that female first-class passengers likely survive, while male passengers do not. However, the imported model takes into account more specific features that are probably harder to generalize.<br>\nIn combination with the low accuracy and coverage, this points to a faulty model which probably generalizes poorly. On the contrary, the random forest takes features into account that we would actually expect to be present in an explanation. Its explanations also exhibit a high coverage, indicating it has learned generally valid coherencies.<br>\nNonetheless, both models miss taking the name of the passengers into account. We would expect longer, aristocratic, names to be an indicator for survival. The knowledge we gained out of these explanations could be used to amend the random forests model's training process until, ultimately, explanations are satisfactorily, and build trust.</br></br></p>\n<h4 id=\"summary-and-collaboration\">Summary and Collaboration</h4>\n<p>Anchors and anchorj aim to make machine learning <em>productively viable</em> by providing the means to detect <em>faulty models</em> before they are deployed. They close the gap between opportunities created by machine learning technology and the associated risks. In our example, we have shown how a specific model can be validated or refuted by including humans into the loop.</p>\n<p>Anchors' application is not limited to this type of problem. It can, for example, be used by global explainers to explain a larger part of the model. Such algorithms and various other features are included in our implementation. See you on GitHub!</p>\n<p><b>Bio: </b>Tobias Goerke is an IT-Consultant and XAI researcher at the viadee Consulting AG, Germany. He recently finished his M.Sc. in Information Systems.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2019/03/ai-black-box-explanation-problem.html\">The AI Black Box Explanation Problem</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/01/explainable-ai.html\">Explainable Artificial Intelligence</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/12/explainable-ai-machine-learning.html\">A Case For Explainable AI &amp; Machine Learning</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>"}