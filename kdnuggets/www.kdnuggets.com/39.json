{"url": "https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html", "title": "Artificial Neural Networks Optimization using Genetic Algorithm with Python", "title_html": "<h1 id=\"title\"><img align=\"right\" alt=\"Gold Blog\" src=\"/images/tkb-1903-g.png\" width=\"94\"/>Artificial Neural Networks Optimization using Genetic Algorithm with Python</h1>", "content": "\n By Ahmed Gad, KDnuggets Contributor. \n  comments \n  \n In a previous tutorial titled \"Artificial Neural Network Implementation using NumPy and Classification of the Fruits360 Image Dataset\" available in my LinkedIn profile at this link https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad, an artificial neural network (ANN) is created for classifying 4 classes of the Fruits360 image dataset. The source code used in this tutorial is available in my GitHub page here: https://github.com/ahmedfgad/NumPyANN \n A quick summary of this tutorial is extracting the feature vector (360 bins hue channel histogram) and reducing it to just 102 element by using a filter-based technique using the standard deviation. Later, the ANN is built from scratch using NumPy. \n The ANN was not completely created as just the forward pass was made ready but there is no backward pass for updating the network weights. This is why the accuracy is very low and not exceeds 45%. The solution to this problem is using an optimization technique for updating the network weights. This tutorial extends the previous one to use the genetic algorithm (GA) for optimizing the network weights. \n It is worth-mentioning that both the previous and this tutorial are based on my 2018 book cited as \"Ahmed Fawzy Gad 'Practical Computer Vision Applications Using Deep Learning with CNNs'. Dec. 2018, Apress, 978-1-4842-4167-7 \". The book is available at Springer at this link: https://springer.com/us/book/9781484241660. You can find all details within this book. \n The source code used in this tutorial is available in my GitHub page here: https://github.com/ahmedfgad/NeuralGenetic \n \u00a0 \n Read More about Genetic Algorithm \n \u00a0 \n Before starting this tutorial, I recommended reading about how the genetic algorithm works and its implementation in Python using NumPy from scratch based on my previous tutorials found at these links: \n \nIntroduction to Optimization with Genetic Algorithm\n\nhttps://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/\nhttps://www.kdnuggets.com/2018/03/introduction-optimization-with-genetic-algorithm.html\nhttps://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b\nhttps://www.springer.com/us/book/9781484241660\n\n \n \nGenetic Algorithm (GA) Optimization - Step-by-Step Example\n\nhttps://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example\n\n \n \nGenetic Algorithm Implementation in Python\n\nhttps://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/\n/2018/07/genetic-algorithm-implementation-python.html\nhttps://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6\nhttps://github.com/ahmedfgad/GeneticAlgorithmPython\n\n \n After understanding how GA works based on numerical examples in addition to implementation using Python, we can start using GA to optimize the ANN by updating its weights (parameters). \n \u00a0 \n Using GA with ANN \n \u00a0 \n GA creates multiple solutions to a given problem and evolves them through a number of generations. Each solution holds all parameters that might help to enhance the results. For ANN, weights in all layers help achieve high accuracy. Thus, a single solution in GA will contain all weights in the ANN. According to the network structure discussed in the previous tutorial and given in the figure below, the ANN has 4 layers (1 input, 2 hidden, and 1 output). Any weight in any layer will be part of the same solution. A single solution to such network will contain a total number of weights equal to 102x150+150x60+60x4=24,540. If the population has 8 solutions with 24,540 parameters per solution, then the total number of parameters in the entire population is 24,540x8=196,320. \n  \n Looking at the above figure, the parameters of the network are in matrix form because this makes calculations of ANN much easier. For each layer, there is an associated weights matrix. Just multiply the inputs matrix by the parameters matrix of a given layer to return the outputs in such layer. Chromosomes in GA are 1D vectors and thus we have to convert the weights matrices into 1D vectors. \n Because matrix multiplication is a good option to work with ANN, we will still represent the ANN parameters in the matrix form when using the ANN. Thus, matrix form is used when working with ANN and vector form is used when working with GA. This makes us need to convert the matrix to vector and vice versa. The next figure summarizes the steps of using \n GA with ANN. This figure is referred to as the main figure. \n  \n \u00a0 \n Weights Matrices to 1D Vector \n \u00a0 \n Each solution in the population will have two representations. First is a 1D vector for working with GA and second is a matrix to work with ANN. Because there are 3 weights matrices for the 3 layers (2 hidden + 1 output), there will be 3 vectors, one for each matrix. Because a solution in GA is represented as a single 1D vector, such 3 individual 1D vectors will be concatenated into a single 1D vector. Each solution will be represented as a vector of length 24,540. The next Python code creates a function named mat_to_vector() that converts the parameters of all solutions within the population from matrix to vector. \n \n\r\ndef mat_to_vector(mat_pop_weights):\r\n    pop_weights_vector = []\r\n    for sol_idx in range(mat_pop_weights.shape[0]):\r\n        curr_vector = []\r\n        for layer_idx in range(mat_pop_weights.shape[1]):\r\n            vector_weights = numpy.reshape(mat_pop_weights[sol_idx, layer_idx], newshape=(mat_pop_weights[sol_idx, layer_idx].size))\r\n            curr_vector.extend(vector_weights)\r\n        pop_weights_vector.append(curr_vector)\r\n    return numpy.array(pop_weights_vector)\r\n\r\n\n \n  \n The function accepts an argument representing the population of all solutions in order to loop through them and return their vector representation. At the beginning of the function, an empty list variable named pop_weights_vector is created to hold the result (vectors of all solutions). For each solution in matrix form, there is an inner loop that loops through its three matrices. For each matrix, it is converted into a vector using the numpy.reshape() function which accepts the input matrix and the output size to which the matrix will be reshaped. The variable curr_vector accepts all vectors for a single solution. After all vectors are generated, they get appended into the pop_weights_vector variable. \n Note that we used the numpy.extend() function for vectors belonging to the same solution and numpy.append() for vectors belonging to different solutions. The reason is that numpy.extend() takes the numbers within the 3 vectors belonging to the same solution and concatenate them together. In other words, calling this function for two lists returns a new single list with numbers from both lists. This is suitable in order to create just a 1D chromosome for each solution. But numpy.append() will return three lists for each solution. Calling it for two lists, it returns a new list which is split into two sub-lists. This is not our objective. Finally, the function mat_to_vector() returns the population solutions as a NumPy array for easy manipulation later. \n \u00a0 \n Implementing GA Steps  \n \u00a0\nAfter converting all solutions from matrices to vectors and concatenated together, we are ready to go through the GA steps discussed in the tutorial titled \"Introduction to Optimization with Genetic Algorithm\". The steps are presented in the main figure and also summarized in the next figure. \n  \n Remember that GA uses a fitness function to returns a fitness value for each solution. The higher the fitness value the better the solution. The best solutions are returned as parents in the parents selection step. \n One of the common fitness functions for a classifier such as ANN is the accuracy. It is the ratio between the correctly classified samples and the total number of samples. It is calculated according to the next equation. The classification accuracy of each solution is calculated according to steps in the main figure. \n \n \n The single 1D vector of each solution is converted back into 3 matrices, one matrix for each layer (2 hidden and 1 output). Conversion takes place using a function called vector_to_mat(). It is defined in the next code.  \n \n\r\ndef vector_to_mat(vector_pop_weights, mat_pop_weights):\r\n\r\n    mat_weights = []\r\n\r\n    for sol_idx in range(mat_pop_weights.shape[0]):\r\n\r\n        start = 0\r\n\r\n        end = 0\r\n\r\n        for layer_idx in range(mat_pop_weights.shape[1]):\r\n\r\n            end = end + mat_pop_weights[sol_idx, layer_idx].size\r\n\r\n            curr_vector = vector_pop_weights[sol_idx, start:end]\r\n\r\n            mat_layer_weights = numpy.reshape(curr_vector, newshape=(mat_pop_weights[sol_idx, layer_idx].shape))\r\n\r\n            mat_weights.append(mat_layer_weights)\r\n\r\n            start = end\r\n\r\n    return numpy.reshape(mat_weights, newshape=mat_pop_weights.shape)\r\n\r\n\n \n  \n It reverses the work done previously. But there is an important question. If the vector of a given solution is just one piece, how we can split into three different parts, each part represents a matrix? The size of the first parameters matrix between the input layer and the hidden layer is 102x150. When being converted into a vector, its length will be 15,300. Because it is the first vector to be inserted in the curr_vector variable according to the mat_to_vector() function, then its indices start from index 0 and end at index 15,299. The mat_pop_weights is used as an argument for the vector_to_mat() function in order to know the size of each matrix. We are not interested in using the weights from the mat_pop_weights variable but just the matrices sizes are used from it. \n For the second vector in the same solution, it will be the result of converting a matrix of size 150x60. Thus the vector length is 9,000. Such a vector is inserted into the curr_vector variable just before the previous vector of length 15,300. As a result, it will start from index 15,300 and ends at index 15,300+9,000-1=24,299. The -1 is used because Python starts indexing at 0. For the last vector created from the parameters matrix of size 60x4, its length is 240. Because it is added into the curr_vector variable exactly after the previous vector of length 9,000, then its index will start after it. That is its start index is 24,300 and its end index is 24,300+240-1=24,539. So, we can successfully restore the vector into the original 3 matrices. \n The matrices returned for each solution are used to predict the class label for each of the 1,962 samples in the used dataset to calculate the accuracy. This is done using 2 functions which are predict_outputs() and fitness() according to the next code. \n \n\r\ndef predict_outputs(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\r\n\r\n    predictions = numpy.zeros(shape=(data_inputs.shape[0]))\r\n\r\n    for sample_idx in range(data_inputs.shape[0]):\r\n\r\n        r1 = data_inputs[sample_idx, :]\r\n\r\n        for curr_weights in weights_mat:\r\n\r\n            r1 = numpy.matmul(a=r1, b=curr_weights)\r\n\r\n            if activation == \"relu\":\r\n\r\n                r1 = relu(r1)\r\n\r\n            elif activation == \"sigmoid\":\r\n\r\n                r1 = sigmoid(r1)\r\n\r\n        predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\r\n\r\n        predictions[sample_idx] = predicted_label\r\n\r\n    correct_predictions = numpy.where(predictions == data_outputs)[0].size\r\n\r\n    accuracy = (correct_predictions/data_outputs.size)*100\r\n\r\n    return accuracy, predictions\r\n\r\n\r\n\r\ndef fitness(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\r\n\r\n    accuracy = numpy.empty(shape=(weights_mat.shape[0]))\r\n\r\n    for sol_idx in range(weights_mat.shape[0]):\r\n\r\n        curr_sol_mat = weights_mat[sol_idx, :]\r\n\r\n        accuracy[sol_idx], _ = predict_outputs(curr_sol_mat, data_inputs, data_outputs, activation=activation)\r\n\r\n    return accuracy\r\n\r\n\n \n  \n The predict_outputs() function accepts the weights of a single solution, inputs, and outputs of the training data, and an optional parameter that specifies which activation function to use. It returns the accuracy of just one solution not all solutions within the population. It order to return the fitness value (i.e. accuracy) of all solutions within the population, the fitness() function loops through each solution, pass it to the predict_outputs() function, store the accuracy of all solutions into the accuracy array, and finally return such an array. \n After calculating the fitness value (i.e. accuracy) for all solutions, the remaining steps of GA in the main figure are applied the same way done previously. The best parents are selected, based on their accuracy, into the mating pool. Then mutation and crossover variants are applied in order to produce the offspring. The population of the new generation is created using both offspring and parents. These steps are repeated for a number of generations. \n", "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Artificial Neural Networks Optimization using Genetic Algorithm with Python</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Artificial Neural Networks Optimization using Genetic Algorithm with Python Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html\" rel=\"prev\" title=\"How To Work In Data Science, AI, Big Data\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/overcoming-distrust-path-productive-analytics.html\" rel=\"next\" title=\"Overcoming distrust on the path to productive analytics\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=91819\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-91819 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 18-Mar, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/tutorials.html\">Tutorials, Overviews</a> \u00bb Artificial Neural Networks Optimization using Genetic Algorithm with Python (\u00a0<a href=\"/2019/n11.html\">19:n11</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\"><img align=\"right\" alt=\"Gold Blog\" src=\"/images/tkb-1903-g.png\" width=\"94\"/>Artificial Neural Networks Optimization using Genetic Algorithm with Python</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/overcoming-distrust-path-productive-analytics.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/ai\" rel=\"tag\">AI</a>, <a href=\"https://www.kdnuggets.com/tag/algorithms\" rel=\"tag\">Algorithms</a>, <a href=\"https://www.kdnuggets.com/tag/deep-learning\" rel=\"tag\">Deep Learning</a>, <a href=\"https://www.kdnuggets.com/tag/machine-learning\" rel=\"tag\">Machine Learning</a>, <a href=\"https://www.kdnuggets.com/tag/neural-networks\" rel=\"tag\">Neural Networks</a>, <a href=\"https://www.kdnuggets.com/tag/numpy\" rel=\"tag\">numpy</a>, <a href=\"https://www.kdnuggets.com/tag/optimization\" rel=\"tag\">Optimization</a>, <a href=\"https://www.kdnuggets.com/tag/python\" rel=\"tag\">Python</a></div>\n<br/>\n<p class=\"excerpt\">\n     This tutorial explains the usage of the genetic algorithm for optimizing the network weights of an Artificial Neural Network for improved performance.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/ahmed-gad\" rel=\"author\" title=\"Posts by Ahmed Gad\">Ahmed Gad</a>, KDnuggets Contributor.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html?page=2#comments\">comments</a></div>\n<div style=\"text-align:center\"><img alt=\"practical-computer-vision-applications-deepl-learning\" src=\"https://i.ibb.co/51NKzMx/cover.jpg\nhttps://i.ibb.co/xzZpwRW/ga-ann.png\" width=\"99%\"/></div>\n<p>In a previous tutorial titled \"<strong>Artificial Neural Network Implementation using NumPy and Classification of the Fruits360 Image Dataset</strong>\" available in my LinkedIn profile at this link <a href=\"https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad</a>, an artificial neural network (ANN) is created for classifying 4 classes of the Fruits360 image dataset. The source code used in this tutorial is available in my GitHub page here: <a href=\"https://github.com/ahmedfgad/NumPyANN\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/ahmedfgad/NumPyANN</a></p>\n<p>A quick summary of this tutorial is extracting the feature vector (360 bins hue channel histogram) and reducing it to just 102 element by using a filter-based technique using the standard deviation. Later, the ANN is built from scratch using NumPy.</p>\n<p>The ANN was not completely created as just the forward pass was made ready but there is no backward pass for updating the network weights. This is why the accuracy is very low and not exceeds 45%. The solution to this problem is using an optimization technique for updating the network weights. This tutorial extends the previous one to use the genetic algorithm (GA) for optimizing the network weights.</p>\n<p>It is worth-mentioning that both the previous and this tutorial are based on my 2018 book cited as \"<strong>Ahmed Fawzy Gad 'Practical Computer Vision Applications Using Deep Learning with CNNs'. Dec. 2018, Apress, 978-1-4842-4167-7</strong> \". The book is available at Springer at this link: <a href=\"https://springer.com/us/book/9781484241660\" rel=\"noopener noreferrer\" target=\"_blank\">https://springer.com/us/book/9781484241660</a>. You can find all details within this book.</p>\n<p>The source code used in this tutorial is available in my GitHub page here: <a href=\"https://github.com/ahmedfgad/NeuralGenetic\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/ahmedfgad/NeuralGenetic</a></p>\n<p>\u00a0</p>\n<h3>Read More about Genetic Algorithm</h3>\n<p>\u00a0</p>\n<p>Before starting this tutorial, I recommended reading about how the genetic algorithm works and its implementation in Python using NumPy from scratch based on my previous tutorials found at these links:</p>\n<ul>\n<li>Introduction to Optimization with Genetic Algorithm\n<ul>\n<li><a href=\"https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/</a></li>\n<li><a href=\"/2018/03/introduction-optimization-with-genetic-algorithm.html\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.kdnuggets.com/2018/03/introduction-optimization-with-genetic-algorithm.html</a></li>\n<li><a href=\"https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b\" rel=\"noopener noreferrer\" target=\"_blank\">https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b</a></li>\n<li><a href=\"https://www.springer.com/us/book/9781484241660\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.springer.com/us/book/9781484241660</a></li>\n</ul>\n</li></ul>\n<ul>\n<li>Genetic Algorithm (GA) Optimization - Step-by-Step Example\n<ul>\n<li><a href=\"https://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example</a></li>\n</ul>\n</li></ul>\n<ul>\n<li>Genetic Algorithm Implementation in Python\n<ul>\n<li><a href=\"https://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/</a></li>\n<li><a href=\"/2018/07/genetic-algorithm-implementation-python.html\" rel=\"noopener noreferrer\" target=\"_blank\">/2018/07/genetic-algorithm-implementation-python.html</a></li>\n<li><a href=\"https://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6\" rel=\"noopener noreferrer\" target=\"_blank\">https://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6</a></li>\n<li><a href=\"https://github.com/ahmedfgad/GeneticAlgorithmPython\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/ahmedfgad/GeneticAlgorithmPython</a></li>\n</ul>\n</li></ul>\n<p>After understanding how GA works based on numerical examples in addition to implementation using Python, we can start using GA to optimize the ANN by updating its weights (parameters).</p>\n<p>\u00a0</p>\n<h3>Using GA with ANN</h3>\n<p>\u00a0</p>\n<p>GA creates multiple solutions to a given problem and evolves them through a number of generations. Each solution holds all parameters that might help to enhance the results. For ANN, weights in all layers help achieve high accuracy. Thus, a single solution in GA will contain all weights in the ANN. According to the network structure discussed in the previous tutorial and given in the figure below, the ANN has 4 layers (1 input, 2 hidden, and 1 output). Any weight in any layer will be part of the same solution. A single solution to such network will contain a total number of weights equal to 102x150+150x60+60x4=24,540. If the population has 8 solutions with 24,540 parameters per solution, then the total number of parameters in the entire population is 24,540x8=196,320.</p>\n<div style=\"text-align:center\"><img alt=\"artificial-neural-network\" src=\"https://www.kdnuggets.com/wp-content/uploads/ann.png\" width=\"80%\"/></div>\n<p>Looking at the above figure, the parameters of the network are in matrix form because this makes calculations of ANN much easier. For each layer, there is an associated weights matrix. Just multiply the inputs matrix by the parameters matrix of a given layer to return the outputs in such layer. Chromosomes in GA are 1D vectors and thus we have to convert the weights matrices into 1D vectors.</p>\n<p>Because matrix multiplication is a good option to work with ANN, we will still represent the ANN parameters in the matrix form when using the ANN. Thus, matrix form is used when working with ANN and vector form is used when working with GA. This makes us need to convert the matrix to vector and vice versa. The next figure summarizes the steps of using</p>\n<p>GA with ANN. This figure is referred to as the <strong>main figure</strong>.</p>\n<div style=\"text-align:center\"><img alt=\"figure-name\" src=\"https://i.ibb.co/xzZpwRW/ga-ann.png\" width=\"90%\"/></div>\n<p>\u00a0</p>\n<h3>Weights Matrices to 1D Vector</h3>\n<p>\u00a0</p>\n<p>Each solution in the population will have two representations. First is a 1D vector for working with GA and second is a matrix to work with ANN. Because there are 3 weights matrices for the 3 layers (2 hidden + 1 output), there will be 3 vectors, one for each matrix. Because a solution in GA is represented as a single 1D vector, such 3 individual 1D vectors will be concatenated into a single 1D vector. Each solution will be represented as a vector of length 24,540. The next Python code creates a function named <strong>mat_to_vector()</strong> that converts the parameters of all solutions within the population from matrix to vector.</p>\n<div style=\"width:98%;border:1px solid #ccc;overflow:auto;padding-left:10px;padding-bottom:10px;padding-top:10px\">\n<pre>\r\ndef mat_to_vector(mat_pop_weights):\r\n    pop_weights_vector = []\r\n    for sol_idx in range(mat_pop_weights.shape[0]):\r\n        curr_vector = []\r\n        for layer_idx in range(mat_pop_weights.shape[1]):\r\n            vector_weights = numpy.reshape(mat_pop_weights[sol_idx, layer_idx], newshape=(mat_pop_weights[sol_idx, layer_idx].size))\r\n            curr_vector.extend(vector_weights)\r\n        pop_weights_vector.append(curr_vector)\r\n    return numpy.array(pop_weights_vector)\r\n\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The function accepts an argument representing the population of all solutions in order to loop through them and return their vector representation. At the beginning of the function, an empty list variable named <strong>pop_weights_vector</strong> is created to hold the result (vectors of all solutions). For each solution in matrix form, there is an inner loop that loops through its three matrices. For each matrix, it is converted into a vector using the <strong>numpy.reshape()</strong> function which accepts the input matrix and the output size to which the matrix will be reshaped. The variable <strong>curr_vector</strong> accepts all vectors for a single solution. After all vectors are generated, they get appended into the <strong>pop_weights_vector</strong> variable.</p>\n<p>Note that we used the <strong>numpy.extend()</strong> function for vectors belonging to the same solution and <strong>numpy.append()</strong> for vectors belonging to different solutions. The reason is that <strong>numpy.extend()</strong> takes the numbers within the 3 vectors belonging to the same solution and concatenate them together. In other words, calling this function for two lists returns a new single list with numbers from both lists. This is suitable in order to create just a 1D chromosome for each solution. But <strong>numpy.append()</strong> will return three lists for each solution. Calling it for two lists, it returns a new list which is split into two sub-lists. This is not our objective. Finally, the function <strong>mat_to_vector()</strong> returns the population solutions as a NumPy array for easy manipulation later.</p>\n<p>\u00a0</p>\n<h3>Implementing GA Steps </h3>\n<p>\u00a0<br>\nAfter converting all solutions from matrices to vectors and concatenated together, we are ready to go through the GA steps discussed in the tutorial titled <strong>\"Introduction to Optimization with Genetic Algorithm\"</strong>. The steps are presented in the <strong>main figure</strong> and also summarized in the next figure.</br></p>\n<div style=\"text-align:center\"><img alt=\"genetic-algorithm-steps\" src=\"https://www.kdnuggets.com/wp-content/uploads/implementing-ga-steps-1.png\" width=\"90%\"/></div>\n<p>Remember that GA uses a fitness function to returns a fitness value for each solution. The higher the fitness value the better the solution. The best solutions are returned as parents in the <strong>parents selection</strong> step.</p>\n<p>One of the common fitness functions for a classifier such as ANN is the accuracy. It is the ratio between the correctly classified samples and the total number of samples. It is calculated according to the next equation. The classification accuracy of each solution is calculated according to steps in the <strong>main figure</strong>.</p>\n<div style=\"text-align:center\"><img alt=\"Equation\" src=\"https://latex.codecogs.com/gif.latex?\\boldsymbol{\\mathbf{\\mathit{Accuracy = \\frac{NumCorrectClassify}{TotalNumSamples}}}}\" width=\"25%\"/>\n</div>\n<p>The single 1D vector of each solution is converted back into 3 matrices, one matrix for each layer (2 hidden and 1 output). Conversion takes place using a function called <strong>vector_to_mat()</strong>. It is defined in the next code. </p>\n<div style=\"width:98%;border:1px solid #ccc;overflow:auto;padding-left:10px;padding-bottom:10px;padding-top:10px\">\n<pre>\r\ndef vector_to_mat(vector_pop_weights, mat_pop_weights):\r\n\r\n    mat_weights = []\r\n\r\n    for sol_idx in range(mat_pop_weights.shape[0]):\r\n\r\n        start = 0\r\n\r\n        end = 0\r\n\r\n        for layer_idx in range(mat_pop_weights.shape[1]):\r\n\r\n            end = end + mat_pop_weights[sol_idx, layer_idx].size\r\n\r\n            curr_vector = vector_pop_weights[sol_idx, start:end]\r\n\r\n            mat_layer_weights = numpy.reshape(curr_vector, newshape=(mat_pop_weights[sol_idx, layer_idx].shape))\r\n\r\n            mat_weights.append(mat_layer_weights)\r\n\r\n            start = end\r\n\r\n    return numpy.reshape(mat_weights, newshape=mat_pop_weights.shape)\r\n\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>It reverses the work done previously. But there is an important question. If the vector of a given solution is just one piece, how we can split into three different parts, each part represents a matrix? The size of the first parameters matrix between the input layer and the hidden layer is 102x150. When being converted into a vector, its length will be 15,300. Because it is the first vector to be inserted in the <strong>curr_vector</strong> variable according to the <strong>mat_to_vector()</strong> function, then its indices start from index 0 and end at index 15,299. The <strong>mat_pop_weights</strong> is used as an argument for the <strong>vector_to_mat()</strong> function in order to know the size of each matrix. We are not interested in using the weights from the <strong>mat_pop_weights</strong> variable but just the matrices sizes are used from it.</p>\n<p>For the second vector in the same solution, it will be the result of converting a matrix of size 150x60. Thus the vector length is 9,000. Such a vector is inserted into the <strong>curr_vector</strong> variable just before the previous vector of length 15,300. As a result, it will start from index 15,300 and ends at index 15,300+9,000-1=24,299. The -1 is used because Python starts indexing at 0. For the last vector created from the parameters matrix of size 60x4, its length is 240. Because it is added into the <strong>curr_vector</strong> variable exactly after the previous vector of length 9,000, then its index will start after it. That is its start index is 24,300 and its end index is 24,300+240-1=24,539. So, we can successfully restore the vector into the original 3 matrices.</p>\n<p>The matrices returned for each solution are used to predict the class label for each of the 1,962 samples in the used dataset to calculate the accuracy. This is done using 2 functions which are <strong>predict_outputs()</strong> and <strong>fitness()</strong> according to the next code.</p>\n<div style=\"width:98%;border:1px solid #ccc;overflow:auto;padding-left:10px;padding-bottom:10px;padding-top:10px\">\n<pre>\r\ndef predict_outputs(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\r\n\r\n    predictions = numpy.zeros(shape=(data_inputs.shape[0]))\r\n\r\n    for sample_idx in range(data_inputs.shape[0]):\r\n\r\n        r1 = data_inputs[sample_idx, :]\r\n\r\n        for curr_weights in weights_mat:\r\n\r\n            r1 = numpy.matmul(a=r1, b=curr_weights)\r\n\r\n            if activation == \"relu\":\r\n\r\n                r1 = relu(r1)\r\n\r\n            elif activation == \"sigmoid\":\r\n\r\n                r1 = sigmoid(r1)\r\n\r\n        predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\r\n\r\n        predictions[sample_idx] = predicted_label\r\n\r\n    correct_predictions = numpy.where(predictions == data_outputs)[0].size\r\n\r\n    accuracy = (correct_predictions/data_outputs.size)*100\r\n\r\n    return accuracy, predictions\r\n\r\n\r\n\r\ndef fitness(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\r\n\r\n    accuracy = numpy.empty(shape=(weights_mat.shape[0]))\r\n\r\n    for sol_idx in range(weights_mat.shape[0]):\r\n\r\n        curr_sol_mat = weights_mat[sol_idx, :]\r\n\r\n        accuracy[sol_idx], _ = predict_outputs(curr_sol_mat, data_inputs, data_outputs, activation=activation)\r\n\r\n    return accuracy\r\n\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The <strong>predict_outputs()</strong> function accepts the weights of a single solution, inputs, and outputs of the training data, and an optional parameter that specifies which activation function to use. It returns the accuracy of just one solution not all solutions within the population. It order to return the fitness value (i.e. accuracy) of all solutions within the population, the <strong>fitness()</strong> function loops through each solution, pass it to the <strong>predict_outputs()</strong> function, store the accuracy of all solutions into the <strong>accuracy</strong> array, and finally return such an array.</p>\n<p>After calculating the fitness value (i.e. accuracy) for all solutions, the remaining steps of GA in the main figure are applied the same way done previously. The best parents are selected, based on their accuracy, into the mating pool. Then mutation and crossover variants are applied in order to produce the offspring. The population of the new generation is created using both offspring and parents. These steps are repeated for a number of generations.</p>\n</div>\n<div class=\"page-link\"><p>Pages: 1 <a href=\"https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html/2\">2</a></p></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/03/work-data-science-ai-big-data.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/03/overcoming-distrust-path-productive-analytics.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-1-another-10');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-2-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/03/data-science-job-applications.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-3-tell-you');\"><b>What no one will tell you about data science job applications</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/02/asking-great-questions-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-5-great-questions');\"><b>Asking Great Questions as a Data Scientist</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/03/women-ai-big-data-science-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-7-19-inspiring-women');\"><b>19 Inspiring Women in AI, Big Data, Data Science, Machine Learning</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-1-ann-genetic');\"><b>Artificial Neural Networks Optimization using Genetic Algorithm with Python</b></a>\n<li> <a href=\"/2019/02/artificial-neural-network-implementation-using-numpy-and-image-classification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-2-ann-numpy-images');\"><b>Artificial Neural Network Implementation using NumPy and Image Classification</b></a>\n<li> <a href=\"/2019/02/setup-python-environment-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-3-py-ml-setup');\"><b>How to Setup a Python Environment for Machine Learning</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-5-azure-cert');\"><b>8 Reasons Why You Should Get a Microsoft Azure Certification</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/02/running-r-and-python-in-jupyter.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-7-r-python-jupyter');\"><b>Running R and Python in Jupyter</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/03/datathon-data-science-hackathon-april.html\">Datathon 2019: The International Data Science Hackathon...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/random-forest-python.html\">Explaining Random Forest (with Python Implementation)</a><li> <a href=\"https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html\">A Beginner\u2019s Guide to Linear Regression in Python wit...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html\">Interpolation in Autoencoders via an Adversarial Regula...</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/03-29-cisco-machine-learning-engineer-support-bot-b.html\">Cisco: Machine Learning Engineer/Support Bot Designer [...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/delaware-gain-skills-need-data-driven-career.html\">Gain the Skills You Need to Level-Up in Your Data-Drive...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n<div class=\"latn\" style=\"margin-top: 15px;\">\n<h3><b>More Recent Stories</b></h3>\n<ul class=\"next-posts\">\n<li> <a href=\"https://www.kdnuggets.com/2019/03/delaware-gain-skills-need-data-driven-career.html\">Gain the Skills You Need to Level-Up in Your Data-Driven Career</a><li> <a href=\"https://www.kdnuggets.com/2019/03/d3js-graph-gallery-data-visualization.html\">D3.js Graph Gallery for Data Visualization</a><li> <a href=\"https://www.kdnuggets.com/2019/03/7-gotchas-data-engineers-google-bigquery.html\">7 \u201cGotchas\u201d for Data Engineers New to Google BigQuery</a><li> <a href=\"https://www.kdnuggets.com/2019/03/deep-learning-toolset-overview.html\">The Deep Learning Toolset\u200a\u2014\u200aAn Overview</a><li> <a href=\"https://www.kdnuggets.com/2019/03/top-tweets-mar20-26.html\">Top tweets, Mar 20-26: 10 More Free Must-Read Books for Mac...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/ieg-network-google-intel-facebook.html\">Network with Google, Intel, Facebook, LinkedIn &amp; more</a><li> <a href=\"https://www.kdnuggets.com/2019/03/activestate-python-programmer.html\">[PDF] Python: The Programmer\u2019s Lingua Franca</a><li> <a href=\"https://www.kdnuggets.com/2019/03/explainable-ai.html\">Explainable AI or Halting Faulty Models ahead of Disaster</a><li> <a href=\"https://www.kdnuggets.com/2019/03/how-choose-right-chart-type.html\">How to Choose the Right Chart Type</a><li> <a href=\"https://www.kdnuggets.com/2019/03/data-pipelines-luigi-airflow-everything-need-know.html\">Data Pipelines, Luigi, Airflow: Everything you need to know</a><li> <a href=\"https://www.kdnuggets.com/2019/n12.html\">KDnuggets 19:n12, Mar 27: My Best Tips for Agile Data Scien...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/top-news-week-0318-0324.html\">Top Stories, Mar 18-24: Another 10 Free Must-Read Books for Ma...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/databricks-solve-big-problems-data-science-ebook.html\">How to solve 4 big problems in data science \u2013 eBook.</a><li> <a href=\"https://www.kdnuggets.com/2019/03/four-levels-analytics-maturity.html\">The Four Levels of Analytics Maturity</a><li> <a href=\"https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html\">Pedestrian Detection in Aerial Images Using RetinaNet</a><li> <a href=\"https://www.kdnuggets.com/2019/03/data-science-decision-makers.html\">Data Science for Decision Makers: A Discussion with Dr Stelios...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/coursera-earn-ibm-data-science-certificate.html\">Earn an IBM Data Science Certificate</a><li> <a href=\"https://www.kdnuggets.com/2019/03/databricks-scaling-big-data-ai-spark-ai-summit-2019.html\">Scaling Big Data and AI \u2013 Spark + AI Summit 2019</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/03-25-pear-therapeutics-data-scientist.html\">Pear Therapeutics: Data Scientist (Analytics) [San Francisco, ...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/ai-black-box-explanation-problem.html\">The AI Black Box Explanation Problem</a></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></li></ul>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/index.html\">Mar</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/03/tutorials.html\">Tutorials, Overviews</a> \u00bb Artificial Neural Networks Optimization using Genetic Algorithm with Python (\u00a0<a href=\"/2019/n11.html\">19:n11</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1553990530\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"bottom-right\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"bottom-right\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></div>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n</body>\n</html>\n<!-- Dynamic page generated in 0.707 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-03-30 20:02:10 -->\n<!-- Compression = gzip -->", "content_html": "<div class=\"post\" id=\"post-\">\n<div class=\"author-link\"><b>By <a href=\"https://www.kdnuggets.com/author/ahmed-gad\" rel=\"author\" title=\"Posts by Ahmed Gad\">Ahmed Gad</a>, KDnuggets Contributor.</b></div>\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html?page=2#comments\">comments</a></div>\n<div style=\"text-align:center\"><img alt=\"practical-computer-vision-applications-deepl-learning\" src=\"https://i.ibb.co/51NKzMx/cover.jpg\nhttps://i.ibb.co/xzZpwRW/ga-ann.png\" width=\"99%\"/></div>\n<p>In a previous tutorial titled \"<strong>Artificial Neural Network Implementation using NumPy and Classification of the Fruits360 Image Dataset</strong>\" available in my LinkedIn profile at this link <a href=\"https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad</a>, an artificial neural network (ANN) is created for classifying 4 classes of the Fruits360 image dataset. The source code used in this tutorial is available in my GitHub page here: <a href=\"https://github.com/ahmedfgad/NumPyANN\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/ahmedfgad/NumPyANN</a></p>\n<p>A quick summary of this tutorial is extracting the feature vector (360 bins hue channel histogram) and reducing it to just 102 element by using a filter-based technique using the standard deviation. Later, the ANN is built from scratch using NumPy.</p>\n<p>The ANN was not completely created as just the forward pass was made ready but there is no backward pass for updating the network weights. This is why the accuracy is very low and not exceeds 45%. The solution to this problem is using an optimization technique for updating the network weights. This tutorial extends the previous one to use the genetic algorithm (GA) for optimizing the network weights.</p>\n<p>It is worth-mentioning that both the previous and this tutorial are based on my 2018 book cited as \"<strong>Ahmed Fawzy Gad 'Practical Computer Vision Applications Using Deep Learning with CNNs'. Dec. 2018, Apress, 978-1-4842-4167-7</strong> \". The book is available at Springer at this link: <a href=\"https://springer.com/us/book/9781484241660\" rel=\"noopener noreferrer\" target=\"_blank\">https://springer.com/us/book/9781484241660</a>. You can find all details within this book.</p>\n<p>The source code used in this tutorial is available in my GitHub page here: <a href=\"https://github.com/ahmedfgad/NeuralGenetic\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/ahmedfgad/NeuralGenetic</a></p>\n<p>\u00a0</p>\n<h3>Read More about Genetic Algorithm</h3>\n<p>\u00a0</p>\n<p>Before starting this tutorial, I recommended reading about how the genetic algorithm works and its implementation in Python using NumPy from scratch based on my previous tutorials found at these links:</p>\n<ul>\n<li>Introduction to Optimization with Genetic Algorithm\n<ul>\n<li><a href=\"https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/</a></li>\n<li><a href=\"/2018/03/introduction-optimization-with-genetic-algorithm.html\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.kdnuggets.com/2018/03/introduction-optimization-with-genetic-algorithm.html</a></li>\n<li><a href=\"https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b\" rel=\"noopener noreferrer\" target=\"_blank\">https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b</a></li>\n<li><a href=\"https://www.springer.com/us/book/9781484241660\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.springer.com/us/book/9781484241660</a></li>\n</ul>\n</li></ul>\n<ul>\n<li>Genetic Algorithm (GA) Optimization - Step-by-Step Example\n<ul>\n<li><a href=\"https://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example</a></li>\n</ul>\n</li></ul>\n<ul>\n<li>Genetic Algorithm Implementation in Python\n<ul>\n<li><a href=\"https://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/\" rel=\"noopener noreferrer\" target=\"_blank\">https://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/</a></li>\n<li><a href=\"/2018/07/genetic-algorithm-implementation-python.html\" rel=\"noopener noreferrer\" target=\"_blank\">/2018/07/genetic-algorithm-implementation-python.html</a></li>\n<li><a href=\"https://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6\" rel=\"noopener noreferrer\" target=\"_blank\">https://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6</a></li>\n<li><a href=\"https://github.com/ahmedfgad/GeneticAlgorithmPython\" rel=\"noopener noreferrer\" target=\"_blank\">https://github.com/ahmedfgad/GeneticAlgorithmPython</a></li>\n</ul>\n</li></ul>\n<p>After understanding how GA works based on numerical examples in addition to implementation using Python, we can start using GA to optimize the ANN by updating its weights (parameters).</p>\n<p>\u00a0</p>\n<h3>Using GA with ANN</h3>\n<p>\u00a0</p>\n<p>GA creates multiple solutions to a given problem and evolves them through a number of generations. Each solution holds all parameters that might help to enhance the results. For ANN, weights in all layers help achieve high accuracy. Thus, a single solution in GA will contain all weights in the ANN. According to the network structure discussed in the previous tutorial and given in the figure below, the ANN has 4 layers (1 input, 2 hidden, and 1 output). Any weight in any layer will be part of the same solution. A single solution to such network will contain a total number of weights equal to 102x150+150x60+60x4=24,540. If the population has 8 solutions with 24,540 parameters per solution, then the total number of parameters in the entire population is 24,540x8=196,320.</p>\n<div style=\"text-align:center\"><img alt=\"artificial-neural-network\" src=\"https://www.kdnuggets.com/wp-content/uploads/ann.png\" width=\"80%\"/></div>\n<p>Looking at the above figure, the parameters of the network are in matrix form because this makes calculations of ANN much easier. For each layer, there is an associated weights matrix. Just multiply the inputs matrix by the parameters matrix of a given layer to return the outputs in such layer. Chromosomes in GA are 1D vectors and thus we have to convert the weights matrices into 1D vectors.</p>\n<p>Because matrix multiplication is a good option to work with ANN, we will still represent the ANN parameters in the matrix form when using the ANN. Thus, matrix form is used when working with ANN and vector form is used when working with GA. This makes us need to convert the matrix to vector and vice versa. The next figure summarizes the steps of using</p>\n<p>GA with ANN. This figure is referred to as the <strong>main figure</strong>.</p>\n<div style=\"text-align:center\"><img alt=\"figure-name\" src=\"https://i.ibb.co/xzZpwRW/ga-ann.png\" width=\"90%\"/></div>\n<p>\u00a0</p>\n<h3>Weights Matrices to 1D Vector</h3>\n<p>\u00a0</p>\n<p>Each solution in the population will have two representations. First is a 1D vector for working with GA and second is a matrix to work with ANN. Because there are 3 weights matrices for the 3 layers (2 hidden + 1 output), there will be 3 vectors, one for each matrix. Because a solution in GA is represented as a single 1D vector, such 3 individual 1D vectors will be concatenated into a single 1D vector. Each solution will be represented as a vector of length 24,540. The next Python code creates a function named <strong>mat_to_vector()</strong> that converts the parameters of all solutions within the population from matrix to vector.</p>\n<div style=\"width:98%;border:1px solid #ccc;overflow:auto;padding-left:10px;padding-bottom:10px;padding-top:10px\">\n<pre>\r\ndef mat_to_vector(mat_pop_weights):\r\n    pop_weights_vector = []\r\n    for sol_idx in range(mat_pop_weights.shape[0]):\r\n        curr_vector = []\r\n        for layer_idx in range(mat_pop_weights.shape[1]):\r\n            vector_weights = numpy.reshape(mat_pop_weights[sol_idx, layer_idx], newshape=(mat_pop_weights[sol_idx, layer_idx].size))\r\n            curr_vector.extend(vector_weights)\r\n        pop_weights_vector.append(curr_vector)\r\n    return numpy.array(pop_weights_vector)\r\n\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The function accepts an argument representing the population of all solutions in order to loop through them and return their vector representation. At the beginning of the function, an empty list variable named <strong>pop_weights_vector</strong> is created to hold the result (vectors of all solutions). For each solution in matrix form, there is an inner loop that loops through its three matrices. For each matrix, it is converted into a vector using the <strong>numpy.reshape()</strong> function which accepts the input matrix and the output size to which the matrix will be reshaped. The variable <strong>curr_vector</strong> accepts all vectors for a single solution. After all vectors are generated, they get appended into the <strong>pop_weights_vector</strong> variable.</p>\n<p>Note that we used the <strong>numpy.extend()</strong> function for vectors belonging to the same solution and <strong>numpy.append()</strong> for vectors belonging to different solutions. The reason is that <strong>numpy.extend()</strong> takes the numbers within the 3 vectors belonging to the same solution and concatenate them together. In other words, calling this function for two lists returns a new single list with numbers from both lists. This is suitable in order to create just a 1D chromosome for each solution. But <strong>numpy.append()</strong> will return three lists for each solution. Calling it for two lists, it returns a new list which is split into two sub-lists. This is not our objective. Finally, the function <strong>mat_to_vector()</strong> returns the population solutions as a NumPy array for easy manipulation later.</p>\n<p>\u00a0</p>\n<h3>Implementing GA Steps </h3>\n<p>\u00a0<br>\nAfter converting all solutions from matrices to vectors and concatenated together, we are ready to go through the GA steps discussed in the tutorial titled <strong>\"Introduction to Optimization with Genetic Algorithm\"</strong>. The steps are presented in the <strong>main figure</strong> and also summarized in the next figure.</br></p>\n<div style=\"text-align:center\"><img alt=\"genetic-algorithm-steps\" src=\"https://www.kdnuggets.com/wp-content/uploads/implementing-ga-steps-1.png\" width=\"90%\"/></div>\n<p>Remember that GA uses a fitness function to returns a fitness value for each solution. The higher the fitness value the better the solution. The best solutions are returned as parents in the <strong>parents selection</strong> step.</p>\n<p>One of the common fitness functions for a classifier such as ANN is the accuracy. It is the ratio between the correctly classified samples and the total number of samples. It is calculated according to the next equation. The classification accuracy of each solution is calculated according to steps in the <strong>main figure</strong>.</p>\n<div style=\"text-align:center\"><img alt=\"Equation\" src=\"https://latex.codecogs.com/gif.latex?\\boldsymbol{\\mathbf{\\mathit{Accuracy = \\frac{NumCorrectClassify}{TotalNumSamples}}}}\" width=\"25%\"/>\n</div>\n<p>The single 1D vector of each solution is converted back into 3 matrices, one matrix for each layer (2 hidden and 1 output). Conversion takes place using a function called <strong>vector_to_mat()</strong>. It is defined in the next code. </p>\n<div style=\"width:98%;border:1px solid #ccc;overflow:auto;padding-left:10px;padding-bottom:10px;padding-top:10px\">\n<pre>\r\ndef vector_to_mat(vector_pop_weights, mat_pop_weights):\r\n\r\n    mat_weights = []\r\n\r\n    for sol_idx in range(mat_pop_weights.shape[0]):\r\n\r\n        start = 0\r\n\r\n        end = 0\r\n\r\n        for layer_idx in range(mat_pop_weights.shape[1]):\r\n\r\n            end = end + mat_pop_weights[sol_idx, layer_idx].size\r\n\r\n            curr_vector = vector_pop_weights[sol_idx, start:end]\r\n\r\n            mat_layer_weights = numpy.reshape(curr_vector, newshape=(mat_pop_weights[sol_idx, layer_idx].shape))\r\n\r\n            mat_weights.append(mat_layer_weights)\r\n\r\n            start = end\r\n\r\n    return numpy.reshape(mat_weights, newshape=mat_pop_weights.shape)\r\n\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>It reverses the work done previously. But there is an important question. If the vector of a given solution is just one piece, how we can split into three different parts, each part represents a matrix? The size of the first parameters matrix between the input layer and the hidden layer is 102x150. When being converted into a vector, its length will be 15,300. Because it is the first vector to be inserted in the <strong>curr_vector</strong> variable according to the <strong>mat_to_vector()</strong> function, then its indices start from index 0 and end at index 15,299. The <strong>mat_pop_weights</strong> is used as an argument for the <strong>vector_to_mat()</strong> function in order to know the size of each matrix. We are not interested in using the weights from the <strong>mat_pop_weights</strong> variable but just the matrices sizes are used from it.</p>\n<p>For the second vector in the same solution, it will be the result of converting a matrix of size 150x60. Thus the vector length is 9,000. Such a vector is inserted into the <strong>curr_vector</strong> variable just before the previous vector of length 15,300. As a result, it will start from index 15,300 and ends at index 15,300+9,000-1=24,299. The -1 is used because Python starts indexing at 0. For the last vector created from the parameters matrix of size 60x4, its length is 240. Because it is added into the <strong>curr_vector</strong> variable exactly after the previous vector of length 9,000, then its index will start after it. That is its start index is 24,300 and its end index is 24,300+240-1=24,539. So, we can successfully restore the vector into the original 3 matrices.</p>\n<p>The matrices returned for each solution are used to predict the class label for each of the 1,962 samples in the used dataset to calculate the accuracy. This is done using 2 functions which are <strong>predict_outputs()</strong> and <strong>fitness()</strong> according to the next code.</p>\n<div style=\"width:98%;border:1px solid #ccc;overflow:auto;padding-left:10px;padding-bottom:10px;padding-top:10px\">\n<pre>\r\ndef predict_outputs(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\r\n\r\n    predictions = numpy.zeros(shape=(data_inputs.shape[0]))\r\n\r\n    for sample_idx in range(data_inputs.shape[0]):\r\n\r\n        r1 = data_inputs[sample_idx, :]\r\n\r\n        for curr_weights in weights_mat:\r\n\r\n            r1 = numpy.matmul(a=r1, b=curr_weights)\r\n\r\n            if activation == \"relu\":\r\n\r\n                r1 = relu(r1)\r\n\r\n            elif activation == \"sigmoid\":\r\n\r\n                r1 = sigmoid(r1)\r\n\r\n        predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\r\n\r\n        predictions[sample_idx] = predicted_label\r\n\r\n    correct_predictions = numpy.where(predictions == data_outputs)[0].size\r\n\r\n    accuracy = (correct_predictions/data_outputs.size)*100\r\n\r\n    return accuracy, predictions\r\n\r\n\r\n\r\ndef fitness(weights_mat, data_inputs, data_outputs, activation=\"relu\"):\r\n\r\n    accuracy = numpy.empty(shape=(weights_mat.shape[0]))\r\n\r\n    for sol_idx in range(weights_mat.shape[0]):\r\n\r\n        curr_sol_mat = weights_mat[sol_idx, :]\r\n\r\n        accuracy[sol_idx], _ = predict_outputs(curr_sol_mat, data_inputs, data_outputs, activation=activation)\r\n\r\n    return accuracy\r\n\r\n</pre>\n</div>\n<p><br class=\"blank\"/></p>\n<p>The <strong>predict_outputs()</strong> function accepts the weights of a single solution, inputs, and outputs of the training data, and an optional parameter that specifies which activation function to use. It returns the accuracy of just one solution not all solutions within the population. It order to return the fitness value (i.e. accuracy) of all solutions within the population, the <strong>fitness()</strong> function loops through each solution, pass it to the <strong>predict_outputs()</strong> function, store the accuracy of all solutions into the <strong>accuracy</strong> array, and finally return such an array.</p>\n<p>After calculating the fitness value (i.e. accuracy) for all solutions, the remaining steps of GA in the main figure are applied the same way done previously. The best parents are selected, based on their accuracy, into the mating pool. Then mutation and crossover variants are applied in order to produce the offspring. The population of the new generation is created using both offspring and parents. These steps are repeated for a number of generations.</p>\n</div>"}