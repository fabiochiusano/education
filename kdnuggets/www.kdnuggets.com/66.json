{"url": "https://www.kdnuggets.com/2019/01/random-forests-explained-intuitively.html", "title": "Random forests explained intuitively", "title_html": "<h1 id=\"title\">Random forests explained intuitively</h1>", "content": "\n  comments \n By Manish Barnwal. \n  \n Random Forests algorithm has always fascinated me. I like how this algorithm can be easily explained to anyone without much hassle. One quick example, I use very frequently to explain the working of random forests is the way a company has multiple rounds of interview to hire a candidate. Let me elaborate. \n Say, you appeared for the position of a Statistical Analyst at WalmartLabs. Now like most of the companies, you don\u2019t just have one round of interview. You have multiple rounds of interviews. Each one of these interviews is chaired by independent panels. Each panel assesses the candidate separately and independently. Generally, even the questions asked in these interviews differ from each other.\u00a0Randomness\u00a0is important here. \n The other thing of utmost importance is\u00a0diversity. The reason we have a panel of interviews is that we assume a committee of people generally takes better decision than a single individual. Now, this committee is not any collection of people. We make sure that the interview panel is a little diversified in terms of topics to be covered in each interview, the type of questions asked, and many other details. You don\u2019t go about asking the same question in each round of interviews. \n After having all the rounds of interviews, the final call whether to select or reject the candidate is based on the majority of the decision from each panel. If out of 5 panel of interviewers, 3 recommends a hire and two against a hire, we tend to go ahead with selecting the candidate. I hope you get the gist. \n If you have heard about the decision tree, then you are not very far from understanding what random forests are. There are two keywords here\u200a\u2014\u200arandom and forests. Let us first understand what forest means. Random forest is a collection of many decision trees. Instead of relying on a single decision tree, you build many decision trees say 100 of them. And you know what a collection of trees is called\u200a\u2014\u200aa forest. So you now understand why is it called a forest. \n Why is it called random\u00a0then? \n Say our dataset has 1,000 rows and 30 columns. \n There are two levels of randomness in this algorithm: \n \nAt row level: Each of these decision trees gets a random sample of the training data (say 10%) i.e. each of these trees will be trained independently on 100 randomly chosen rows out of 1,000 rows of data. Keep in mind that each of these decision trees is getting trained on 100 randomly chosen rows from the dataset i.e they are different from each other in terms of predictions.\nAt column level: The second level of randomness is introduced at the column level. Not all the columns are passed into training each of the decision trees. Say we want only 10% of columns to be sent to each tree. This means a randomly selected 3 column will be sent to each tree. So for the first decision tree, maybe column C1, C2, and C4 were chosen. The next DT will have C4, C5, C10 as chosen columns and so on.\n \n Let me draw an analogy now. \n Let us now understand how an interview selection process resembles a random forest algorithm. Each panel in the interview process is actually a decision tree. Each panel gives a result whether the candidate is a pass or fail and then a majority of these results is declared as final. Say there were 5 panels, 3 said yes and 2 said no. The final verdict will be yes. \n Something similar happens in the random forest as well. The results from each of the tree are taken and the final result is declared accordingly. Voting and averaging is used to predict in the case of classification and regression respectively. \n With the advent of huge computational power at our disposal, we hardly think for even a second before we apply random forests. And very conveniently our predictions are made. Let us try to understand other aspects of this algorithm. \n When is a random forest a poor choice relative to other algorithms? \n \nRandom forests don\u2019t train well on smaller datasetsas it fails to pick on the pattern. To simplify, say we know that 1 pen costs INR 1, 2 pens cost INR 2, 3 pens cost INR 6. In this case, linear regression will easily estimate the cost of 4 pens but random forests will fail to come up with a good estimate.\nThere is a problem of interpretability with random forest.You can\u2019t see or understand the relationship between the response and the independent variables.\u00a0Understand that a random forest is a predictive tool and not a descriptive tool.\u00a0You get variable importance but this may not suffice in many analysis of interests where the objective might be to see the relationship between response and the independent features.\nThe\u00a0time taken to train random forestsmay sometimes be too huge as you train multiple decision trees. Also, in the case of a categorical variable, the time complexity increases exponentially. For a categorical column with n levels, RF tries split at 2^n -1 points to find the maximal splitting point. However, with the power of H2O, we can now train random forests pretty fast. You may want to read about H2O at\u00a0H2O in R explained.\nIn case of a regression problem,\u00a0the range of values response variable can takeis determined by the values already available in the training dataset. Unlike linear regression, decision trees and hence random forest can\u2019t take values outside the training data.\n \n What are the advantages of using random\u00a0forest? \n \nSince we are using multiple decision trees,\u00a0the bias remains the same as that of a single decision tree. However, the variance decreases and thus we decrease the chances of overfitting. I have explained bias and variance intuitively at\u00a0The curse of bias and variance.\nWhen all you care about is the predictions and\u00a0want a quick and dirty way-out, random forest comes to the rescue. You don\u2019t have to worry much about the assumptions of the model or linearity in the dataset.\n \n Did you find the article useful? If you did, share your thoughts in the comments. Share this post with people who you think would enjoy reading this. Let\u2019s talk more about data-science. \n Bio: Manish Barnwal is a Data Scientist at Zeta Global building recommendation engines for media publishing houses. \n Original. Reposted with permission. \n Resources: \n \nOn-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education\nSoftware for Analytics, Data Science, Data Mining, and Machine Learning\n \n Related: \n \nData Scientist Interviews Demystified\nA Tour of The Top 10 Algorithms for Machine Learning Newbies\nIntroduction to Python Ensembles\n \n  \n  \n \n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n  \n", "html": "<!DOCTYPE html>\n\n<html lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<head profile=\"http://gmpg.org/xfn/11\">\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n<title>  Random forests explained intuitively</title>\n<link href=\"/wp-content/themes/kdn17/images/favicon.ico\" rel=\"shortcut icon\"/>\n<link href=\"/wp-content/themes/kdn17/style.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"/wp-content/themes/kdn17/js/jquery-1.9.1.min.js\" type=\"text/javascript\"></script>\n<script src=\"/aps/kda_all.js\" type=\"text/javascript\"></script>\n<link href=\"/feed/\" rel=\"alternate\" title=\"KDnuggets: Analytics, Big Data, Data Mining and Data Science Feed\" type=\"application/rss+xml\"/>\n<link href=\"//s.w.org\" rel=\"dns-prefetch\"/>\n<link href=\"https://www.kdnuggets.com/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/comments/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/random-forests-explained-intuitively.html/feed\" rel=\"alternate\" title=\"KDnuggets \u00bb Random forests explained intuitively Comments Feed\" type=\"application/rss+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-json/\" rel=\"https://api.w.org/\"/>\n<link href=\"https://www.kdnuggets.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\n<link href=\"https://www.kdnuggets.com/wp-includes/wlwmanifest.xml\" rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/building-image-search-service-from-scratch.html\" rel=\"prev\" title=\"Building an image search service from scratch\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/dataiku-latest-research-data-science-platforms.html\" rel=\"next\" title=\"Get the latest analyst research on data science platforms\"/>\n<meta content=\"WordPress 4.9.10\" name=\"generator\">\n<link href=\"https://www.kdnuggets.com/2019/01/random-forests-explained-intuitively.html\" rel=\"canonical\"/>\n<link href=\"https://www.kdnuggets.com/?p=89926\" rel=\"shortlink\"/>\n<link href=\"https://www.kdnuggets.com/2019/01/random-forests-explained-intuitively.html\" rel=\"canonical\"/>\n<!-- BEGIN ExactMetrics v5.3.7 Universal Analytics - https://exactmetrics.com/ -->\n<script>\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n\t(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n\tm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n  ga('create', 'UA-361129-1', 'auto');\n  ga('send', 'pageview');\n</script>\n<!-- END ExactMetrics Universal Analytics -->\n</meta></head>\n<body class=\"post-template-default single single-post postid-89926 single-format-standard\">\n<div class=\"main_wrapper\"><!-- publ: 30-Jan, 2019  -->\n<div id=\"wrapper\">\n<div id=\"header\">\n<div id=\"header_log\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<h1>KDnuggets</h1>\n<div class=\"text-container\">\n            \u00a0\u00a0<a href=\"/news/subscribe.html\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a> \u00a0|\n <a href=\"https://twitter.com/kdnuggets\" target=\"_blank\"><img alt=\"Twitter\" height=\"48\" src=\"/images/tw_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n <a href=\"https://www.facebook.com/kdnuggets\" target=\"_blank\"><img alt=\"Facebook\" height=\"48\" src=\"/images/fb_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \u00a0\u00a0\n<a href=\"https://www.linkedin.com/groups/54257/\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"48\" src=\"/images/in_c48.png\" style=\"vertical-align: bottom\" width=\"48\"/></a> \n\u00a0|\u00a0 <a href=\"/contact.html\"><b>Contact</b></a>\n</div>\n</div>\n<div class=\"search\">\n<form action=\"/\" id=\"searchform\" method=\"get\">\n<input id=\"s\" name=\"s\" placeholder=\"search KDnuggets\" type=\"text\" value=\"\"/>\n<input type=\"submit\" value=\"Search\"/></form>\n</div>\n<div href=\"#\" id=\"pull\">\n<img class=\"menu\" src=\"/images/menu-30.png\">\n<div class=\"logo\">\n<a href=\"/\"></a>\n</div>\n<img class=\"search-icon\" src=\"/images/search-icon.png\">\n</img></img></div>\n<div id=\"pull-menu\">\n<div class=\"navigation\"><ul class=\"menu\" id=\"menu-menu\"><li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-1070\" id=\"menu-item-1070\"><a href=\"/software/index.html\" title=\"Data Science Software\">SOFTWARE</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13756\" id=\"menu-item-13756\"><a href=\"/news/index.html\" title=\"News\">News/Blog</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-46286\" id=\"menu-item-46286\"><a href=\"/news/top-stories.html\">Top stories</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42152\" id=\"menu-item-42152\"><a href=\"https://www.kdnuggets.com/opinions/index.html\" title=\"Opinions\">Opinions</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-46415\" id=\"menu-item-46415\"><a href=\"https://www.kdnuggets.com/tutorials/index.html\">Tutorials</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13364\" id=\"menu-item-13364\"><a href=\"/jobs/index.html\" title=\"Jobs in Analytics, Data Science\">JOBS</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-63505\" id=\"menu-item-63505\"><a href=\"https://www.kdnuggets.com/companies/index.html\">Companies</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13366\" id=\"menu-item-13366\"><a href=\"/courses/index.html\">Courses</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1499\" id=\"menu-item-1499\"><a href=\"https://www.kdnuggets.com/datasets/index.html\">Datasets</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-14286\" id=\"menu-item-14286\"><a href=\"https://www.kdnuggets.com/education/index.html\" title=\"Education in Analytics, Big Data, Data Science\">EDUCATION</a></li>\n<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-51558\" id=\"menu-item-51558\"><a href=\"https://www.kdnuggets.com/education/analytics-data-mining-certificates.html\" title=\"Certificates in Analytics, Big Data, Data Science\">Certificates</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-14752\" id=\"menu-item-14752\"><a href=\"/meetings/index.html\">Meetings</a></li>\n<li class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-13721\" id=\"menu-item-13721\"><a href=\"/webcasts/index.html\" title=\"Webcasts and Webinars\">Webinars</a></li>\n</ul></div></div>\n</div> <!--#header end-->\n<div id=\"spacer\">\n         \u00a0\n      </div>\n<div id=\"content_wrapper\">\n<div id=\"ad_wrapper\">\n<script type=\"text/javascript\">\n\tjQuery(function() {\n   \t    var pull        = $('#pull');\n            menu        = $('#header .navigation ul');\n            menuImage = $('#header img.menu');\n            mobileMenu        = $('#pull-menu-mobile');\n            search = $('img.search-icon');\n            searchBar = $('div.search');\n            searchClick = false;\n            search.on('click', function() {\n                  searchBar.slideToggle();\n                  searchClick = true;\n            });  \n     \t    $(menuImage).on('click', function(e) {\n\t        //e.preventDefault();\n                if (!searchClick) {\n                  menu.slideToggle();\n                }\n                searchClick = false;\n\t    });\n           /* pullMobile.on('click', function(e) {\n              e.preventDefault();\n                if (!searchClick) {\n                  mobileMenu.slideToggle();\n                }\n                searchClick = false;\n\t    });*/\n            \n\t});\n\tkpath = '/'; kda_top(); kda_sid_init(); kda_sid_n=3;\n\t</script>\n</div> <div class=\"breadcumb\">\n<br/>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/index.html\">Jan</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/tutorials.html\">Tutorials, Overviews</a> \u00bb Random forests explained intuitively (\u00a0<a href=\"/2019/n06.html\">19:n06</a>\u00a0)    </div>\n<div class=\"single\" id=\"content\">\n<div id=\"post-header\">\n<h1 id=\"title\">Random forests explained intuitively</h1>\n<div class=\"pagi\">\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/01/building-image-search-service-from-scratch.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"> <strong>Previous post</strong></img></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/01/dataiku-latest-research-data-science-platforms.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/>\u00a0<br/>\u00a0\n    <div class=\"addthis_native_toolbox\"></div>\n</div>\n<div class=\"tag-data\">Tags: <a href=\"https://www.kdnuggets.com/tag/decision-trees\" rel=\"tag\">Decision Trees</a>, <a href=\"https://www.kdnuggets.com/tag/explained\" rel=\"tag\">Explained</a>, <a href=\"https://www.kdnuggets.com/tag/random-forests\" rel=\"tag\">Random Forests</a></div>\n<br/>\n<p class=\"excerpt\">\n     A detailed explanation of random forests, with real life use cases, a discussion into when a random forest is a poor choice relative to other algorithms, and looking at some of the advantages of using random forest.\n  </p>\n</div>\n<div id=\"post-header-ad\">\n<script type=\"text/javascript\">kda_sid_write(1); kda_sid_n=2;</script>\n</div>\n<hr class=\"grey-line\"/><br/>\n<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"http://manishbarnwal.com/\">Manish Barnwal</a></b>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/0*Trm62aYhiZuWcTl8.jpg\" width=\"100%\"/></p>\n<p>Random Forests algorithm has always fascinated me. I like how this algorithm can be easily explained to anyone without much hassle. One quick example, I use very frequently to explain the working of random forests is the way a company has multiple rounds of interview to hire a candidate. Let me elaborate.</p>\n<p>Say, you appeared for the position of a Statistical Analyst at WalmartLabs. Now like most of the companies, you don\u2019t just have one round of interview. You have multiple rounds of interviews. Each one of these interviews is chaired by independent panels. Each panel assesses the candidate separately and independently. Generally, even the questions asked in these interviews differ from each other.\u00a0<strong>Randomness</strong>\u00a0is important here.</p>\n<p>The other thing of utmost importance is\u00a0<strong>diversity</strong>. The reason we have a panel of interviews is that we assume a committee of people generally takes better decision than a single individual. Now, this committee is not any collection of people. We make sure that the interview panel is a little diversified in terms of topics to be covered in each interview, the type of questions asked, and many other details. You don\u2019t go about asking the same question in each round of interviews.</p>\n<p>After having all the rounds of interviews, the final call whether to select or reject the candidate is based on the majority of the decision from each panel. If out of 5 panel of interviewers, 3 recommends a hire and two against a hire, we tend to go ahead with selecting the candidate. I hope you get the gist.</p>\n<p>If you have heard about the decision tree, then you are not very far from understanding what random forests are. There are two keywords here\u200a\u2014\u200arandom and forests. Let us first understand what forest means. Random forest is a collection of many decision trees. Instead of relying on a single decision tree, you build many decision trees say 100 of them. And you know what a collection of trees is called\u200a\u2014\u200aa forest. So you now understand why is it called a forest.</p>\n<p><strong>Why is it called random\u00a0then?</strong></p>\n<p>Say our dataset has 1,000 rows and 30 columns.</p>\n<p>There are two levels of randomness in this algorithm:</p>\n<ul>\n<li><strong>At row level</strong>: Each of these decision trees gets a random sample of the training data (say 10%) i.e. each of these trees will be trained independently on 100 randomly chosen rows out of 1,000 rows of data. Keep in mind that each of these decision trees is getting trained on 100 randomly chosen rows from the dataset i.e they are different from each other in terms of predictions.</li>\n<li><strong>At column level</strong>: The second level of randomness is introduced at the column level. Not all the columns are passed into training each of the decision trees. Say we want only 10% of columns to be sent to each tree. This means a randomly selected 3 column will be sent to each tree. So for the first decision tree, maybe column C1, C2, and C4 were chosen. The next DT will have C4, C5, C10 as chosen columns and so on.</li>\n</ul>\n<p>Let me draw an analogy now.</p>\n<p>Let us now understand how an interview selection process resembles a random forest algorithm. Each panel in the interview process is actually a decision tree. Each panel gives a result whether the candidate is a pass or fail and then a majority of these results is declared as final. Say there were 5 panels, 3 said yes and 2 said no. The final verdict will be yes.</p>\n<p>Something similar happens in the random forest as well. The results from each of the tree are taken and the final result is declared accordingly. Voting and averaging is used to predict in the case of classification and regression respectively.</p>\n<p>With the advent of huge computational power at our disposal, we hardly think for even a second before we apply random forests. And very conveniently our predictions are made. Let us try to understand other aspects of this algorithm.</p>\n<p><strong>When is a random forest a poor choice relative to other algorithms?</strong></p>\n<ol>\n<li><strong>Random forests don\u2019t train well on smaller datasets</strong>as it fails to pick on the pattern. To simplify, say we know that 1 pen costs INR 1, 2 pens cost INR 2, 3 pens cost INR 6. In this case, linear regression will easily estimate the cost of 4 pens but random forests will fail to come up with a good estimate.</li>\n<li><strong>There is a problem of interpretability with random forest.</strong>You can\u2019t see or understand the relationship between the response and the independent variables.\u00a0Understand that a random forest is a predictive tool and not a descriptive tool.\u00a0You get variable importance but this may not suffice in many analysis of interests where the objective might be to see the relationship between response and the independent features.</li>\n<li>The\u00a0<strong>time taken to train random forests</strong>may sometimes be too huge as you train multiple decision trees. Also, in the case of a categorical variable, the time complexity increases exponentially. For a categorical column with n levels, RF tries split at 2^n -1 points to find the maximal splitting point. However, with the power of H2O, we can now train random forests pretty fast. You may want to read about H2O at\u00a0<a href=\"http://manishbarnwal.com/blog/2017/03/28/h2o_with_r/\"><strong>H2O in R explained</strong></a>.</li>\n<li>In case of a regression problem,\u00a0<strong>the range of values response variable can take</strong>is determined by the values already available in the training dataset. Unlike linear regression, decision trees and hence random forest can\u2019t take values outside the training data.</li>\n</ol>\n<p><strong>What are the advantages of using random\u00a0forest?</strong></p>\n<ol>\n<li>Since we are using multiple decision trees,\u00a0<strong>the bias remains the same as that of a single decision tree</strong>. However, the variance decreases and thus we decrease the chances of overfitting. I have explained bias and variance intuitively at\u00a0<a href=\"http://manishbarnwal.com/blog/2017/02/08/the_curse_of_bias_and_variance/\"><strong>The curse of bias and variance</strong></a>.</li>\n<li>When all you care about is the predictions and\u00a0<strong>want a quick and dirty way-out</strong>, random forest comes to the rescue. You don\u2019t have to worry much about the assumptions of the model or linearity in the dataset.</li>\n</ol>\n<p>Did you find the article useful? If you did, share your thoughts in the comments. Share this post with people who you think would enjoy reading this. Let\u2019s talk more about data-science.</p>\n<p><b>Bio</b>: <a href=\"http://manishbarnwal.com/\">Manish Barnwal</a> is a Data Scientist at Zeta Global building recommendation engines for media publishing houses.</p>\n<p><a href=\"https://medium.com/theboredhuman/random-forests-explained-intuitively-2cecb9e1a7b5\">Original</a>. Reposted with permission.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2018/08/data-scientist-interviews-demystified.html\">Data Scientist Interviews Demystified</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/02/tour-top-10-algorithms-machine-learning-newbies.html\">A Tour of The Top 10 Algorithms for Machine Learning Newbies</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html\">Introduction to Python Ensembles</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>\n<div class=\"page-link\"></div>\n<div class=\"pagi\">\n<hr class=\"grey-line\"/>\n<div class=\"pagi-left\">\n<a href=\"https://www.kdnuggets.com/2019/01/building-image-search-service-from-scratch.html\" rel=\"prev\"><img height=\"10\" src=\"/images/prv.gif\" width=\"8\"/> <strong>Previous post</strong></a></div>\n<div class=\"pagi-right\">\n<a href=\"https://www.kdnuggets.com/2019/01/dataiku-latest-research-data-science-platforms.html\" rel=\"next\"><strong>Next post</strong> <img height=\"10\" src=\"/images/nxt.gif\" width=\"8\"/></a></div>\n<br/><br/>\n<div>\n<hr class=\"grey-line\"/><br/>\n<h2>Top Stories Past 30 Days</h2>\n<table align=\"center\" cellpadding=\"3\" cellspacing=\"10\" class=\"latn\" width=\"100%\">\n<tr>\n<td valign=\"top\" width=\"50%\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Popular</b></th></tr>\n<tr><td>\n<ol class=\"three_ol\"><li> <a href=\"/2019/03/another-10-free-must-read-books-for-machine-learning-and-data-science.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-1-another-10');\"><b>Another 10 Free Must-Read Books for Machine Learning and Data Science</b></a>\n<li> <a href=\"/2018/05/simplilearn-9-must-have-skills-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-2-simplilearn');\"><b>9 Must-have skills you need to become a Data Scientist, updated</b></a>\n<li> <a href=\"/2019/03/data-science-job-applications.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-3-tell-you');\"><b>What no one will tell you about data science job applications</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/02/asking-great-questions-data-scientist.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-5-great-questions');\"><b>Asking Great Questions as a Data Scientist</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/03/women-ai-big-data-science-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-mp-7-19-inspiring-women');\"><b>19 Inspiring Women in AI, Big Data, Data Science, Machine Learning</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td> <td valign=\"top\">\n<table cellpadding=\"3\" cellspacing=\"2\">\n<tr><th><b>Most Shared</b></th></tr>\n<tr><td><ol class=\"three_ol\">\n<li> <a href=\"/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-1-ann-genetic');\"><b>Artificial Neural Networks Optimization using Genetic Algorithm with Python</b></a>\n<li> <a href=\"/2019/02/artificial-neural-network-implementation-using-numpy-and-image-classification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-2-ann-numpy-images');\"><b>Artificial Neural Network Implementation using NumPy and Image Classification</b></a>\n<li> <a href=\"/2019/02/setup-python-environment-machine-learning.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-3-py-ml-setup');\"><b>How to Setup a Python Environment for Machine Learning</b></a>\n<li> <a href=\"/2019/03/typical-data-scientist-2019.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-4-typical');\"><b>Who is a typical Data Scientist in 2019?</b></a>\n<li> <a href=\"/2019/03/simplilearn-8-reasons-microsoft-azure-certification.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-5-azure-cert');\"><b>8 Reasons Why You Should Get a Microsoft Azure Certification</b></a>\n<li> <a href=\"/2019/03/pareto-principle-data-scientists.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-6-pareto');\"><b>The Pareto Principle for Data Scientists</b></a>\n<li> <a href=\"/2019/02/running-r-and-python-in-jupyter.html\" onclick=\"ga('send','pageview','/x/pbc/2019/03-26-ms-7-r-python-jupyter');\"><b>Running R and Python in Jupyter</b></a>\n</li></li></li></li></li></li></li></ol>\n</td></tr>\n</table>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<!--#content end--></div>\n<div id=\"sidebar\">\n<div class=\"latn\">\n<h3><b><a href=\"/news/index.html\">Latest News</a></b></h3>\n<ul style=\"font-size:14px; margin-top:5px\">\n<li> <a href=\"https://www.kdnuggets.com/2019/03/datathon-data-science-hackathon-april.html\">Datathon 2019: The International Data Science Hackathon...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/random-forest-python.html\">Explaining Random Forest (with Python Implementation)</a><li> <a href=\"https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html\">A Beginner\u2019s Guide to Linear Regression in Python wit...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html\">Interpolation in Autoencoders via an Adversarial Regula...</a><li> <a href=\"https://www.kdnuggets.com/jobs/19/03-29-cisco-machine-learning-engineer-support-bot-b.html\">Cisco: Machine Learning Engineer/Support Bot Designer [...</a><li> <a href=\"https://www.kdnuggets.com/2019/03/delaware-gain-skills-need-data-driven-career.html\">Gain the Skills You Need to Level-Up in Your Data-Drive...</a></li></li></li></li></li></li></ul>\n</div>\n<div>\n<script type=\"text/javascript\">kda_sid_write(kda_sid_n);</script>\n</div>\n<br/><script src=\"/aps/sbm.js\" type=\"text/javascript\"></script>\n</div>\n</div><div class=\"breadcrumbs_bottom\">\n<div class=\"breadcumb\">\n<br>\n<a href=\"/\">KDnuggets Home</a> \u00bb <a href=\"/news/index.html\">News</a> \u00bb <a href=\"/2019/index.html\">2019</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/index.html\">Jan</a> \u00bb <a href=\"https://www.kdnuggets.com/2019/01/tutorials.html\">Tutorials, Overviews</a> \u00bb Random forests explained intuitively (\u00a0<a href=\"/2019/n06.html\">19:n06</a>\u00a0)    </br></div>\n</div>\n<!--#content_wrapper end--></div>\n<br>\n<div id=\"footer\">\n<br/>\u00a9 2019 KDnuggets. <a href=\"/about/index.html\">About KDnuggets</a>. \u00a0<a href=\"/news/privacy-policy.html\">Privacy policy</a>. <a href=\"/terms-of-service.html\">Terms of Service</a><br/>\u00a0\n<div class=\"kd_bottom\">\n<div class=\"footer-container\">\n<div class=\"footer-news\">\n<a href=\"/news/subscribe.html\" onclick=\"_gaq.push(['_trackPageview','/x/bot/sub']);\" target=\"_blank\"><b>Subscribe to KDnuggets News</b></a>\n</div>\n<div class=\"footer-sm\">\n<a href=\"https://twitter.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/twt']);\" target=\"_blank\"><img height=\"32\" src=\"/images/tw_c48.png\" width=\"32\"/></a>\n<a href=\"https://facebook.com/kdnuggets\" onclick=\"_gaq.push(['_trackPageview','/x/bot/fb']);\" target=\"_blank\"><img alt=\"Facebook\" height=\"32\" src=\"/images/fb_c48.png\" width=\"32\"/></a>\n<a href=\"https://www.linkedin.com/groups/54257\" onclick=\"_gaq.push(['_trackPageview','/x/bot/in']);\" target=\"_blank\"><img alt=\"LinkedIn\" height=\"32\" src=\"/images/in_c48.png\" width=\"32\"/></a>\n</div>\n</div>\n<div class=\"close-footer\">X</div>\n</div>\n<script type=\"text/javascript\">\n  jQuery('.close-footer').click(\n      function(){       \n         jQuery('.kd_bottom').hide();\n      }\n   );\n</script> </div>\n<div class=\"clear\"><!--blank--></div>\n</br></div>\n<div style=\"display: none;\"><div id=\"boxzilla-box-82996-content\"><script type=\"text/javascript\">(function() {\n\tif (!window.mc4wp) {\n\t\twindow.mc4wp = {\n\t\t\tlisteners: [],\n\t\t\tforms    : {\n\t\t\t\ton: function (event, callback) {\n\t\t\t\t\twindow.mc4wp.listeners.push({\n\t\t\t\t\t\tevent   : event,\n\t\t\t\t\t\tcallback: callback\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n})();\n</script><!-- MailChimp for WordPress v4.1.14 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-77281\" data-id=\"77281\" data-name=\"Subscribe to KDnuggets News\" id=\"mc4wp-form-1\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"header-container\">\n<img align=\"left\" src=\"/wp-content/uploads/envelope.png\"><a href=\"/news/subscribe.html\">Get KDnuggets, a leading newsletter on AI, \r\n  Data Science, and Machine Learning</a>\n</img></div>\n<div class=\"form-fields\">\n<div class=\"field-container\"><label>Email:</label><input maxlength=\"60\" name=\"EMAIL\" placeholder=\"Your email\" required=\"\" size=\"30\" type=\"email\"/></div>\n<div class=\"field-container submit-container\"><div class=\"form-button\" onclick=\"document.getElementById('mc4wp-form-1').submit()\">Sign Up</div></div>\n</div>\n<label style=\"display: none !important;\">Leave this field empty if you're human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\"/></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1554005144\"/><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"77281\"/><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-1\"/></div><div class=\"mc4wp-response\"></div></form><!-- / MailChimp for WordPress Plugin -->\n</div></div><script type=\"text/javascript\">(function() {function addEventListener(element,event,handler) {\n\tif(element.addEventListener) {\n\t\telement.addEventListener(event,handler, false);\n\t} else if(element.attachEvent){\n\t\telement.attachEvent('on'+event,handler);\n\t}\n}function maybePrefixUrlField() {\n\tif(this.value.trim() !== '' && this.value.indexOf('http') !== 0) {\n\t\tthis.value = \"http://\" + this.value;\n\t}\n}\n\nvar urlFields = document.querySelectorAll('.mc4wp-form input[type=\"url\"]');\nif( urlFields && urlFields.length > 0 ) {\n\tfor( var j=0; j < urlFields.length; j++ ) {\n\t\taddEventListener(urlFields[j],'blur',maybePrefixUrlField);\n\t}\n}/* test if browser supports date fields */\nvar testInput = document.createElement('input');\ntestInput.setAttribute('type', 'date');\nif( testInput.type !== 'date') {\n\n\t/* add placeholder & pattern to all date fields */\n\tvar dateFields = document.querySelectorAll('.mc4wp-form input[type=\"date\"]');\n\tfor(var i=0; i<dateFields.length; i++) {\n\t\tif(!dateFields[i].placeholder) {\n\t\t\tdateFields[i].placeholder = 'YYYY-MM-DD';\n\t\t}\n\t\tif(!dateFields[i].pattern) {\n\t\t\tdateFields[i].pattern = '[0-9]{4}-(0[1-9]|1[012])-(0[1-9]|1[0-9]|2[0-9]|3[01])';\n\t\t}\n\t}\n}\n\n})();</script><script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_options = {\"testMode\":\"\",\"boxes\":[{\"id\":82996,\"icon\":\"&times;\",\"content\":\"\",\"css\":{\"background_color\":\"#eeee22\",\"width\":600,\"border_width\":2,\"border_style\":\"double\",\"position\":\"bottom-right\"},\"trigger\":{\"method\":\"time_on_page\",\"value\":\"3\"},\"animation\":\"fade\",\"cookie\":{\"triggered\":0,\"dismissed\":336},\"rehide\":true,\"position\":\"bottom-right\",\"screenWidthCondition\":{\"condition\":\"larger\",\"value\":500},\"closable\":true,\"post\":{\"id\":82996,\"title\":\"Subscribe to KDnuggets\",\"slug\":\"subscribe-to-kdnuggets\"}}]};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla/assets/js/script.min.js?ver=3.2.5\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar boxzilla_stats_config = {\"ajaxurl\":\"https:\\/\\/www.kdnuggets.com\\/wp-admin\\/admin-ajax.php?action=boxzilla_stats_track\"};\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/boxzilla-stats/assets/js/tracking.min.js?ver=1.0.4\" type=\"text/javascript\"></script>\n<script src=\"https://www.kdnuggets.com/wp-includes/js/wp-embed.min.js?ver=4.9.10\" type=\"text/javascript\"></script>\n<script type=\"text/javascript\">\n/* <![CDATA[ */\nvar mc4wp_forms_config = [];\n/* ]]> */\n</script>\n<script src=\"https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/forms-api.min.js?ver=4.1.14\" type=\"text/javascript\"></script>\n<!--[if lte IE 9]>\n<script type='text/javascript' src='https://www.kdnuggets.com/wp-content/plugins/mailchimp-for-wp/assets/js/third-party/placeholders.min.js?ver=4.1.14'></script>\n<![endif]-->\n<!--/.main_wrapper--></body></html>\n<script src=\"https://s7.addthis.com/js/300/addthis_widget.js#pubid=gpsaddthis\" type=\"text/javascript\"></script>\n\n\n<!-- Dynamic page generated in 0.660 seconds. -->\n<!-- Cached page generated by WP-Super-Cache on 2019-03-31 00:05:44 -->\n<!-- Compression = gzip -->", "content_html": "<div class=\"post\" id=\"post-\">\n<div align=\"right\"><img alt=\"c\" height=\"12\" src=\"/images/comment.gif\" width=\"16\"/> <a href=\"#comments\">comments</a></div>\n<p><b>By <a href=\"http://manishbarnwal.com/\">Manish Barnwal</a></b>.</p>\n<p><img src=\"https://cdn-images-1.medium.com/max/1000/0*Trm62aYhiZuWcTl8.jpg\" width=\"100%\"/></p>\n<p>Random Forests algorithm has always fascinated me. I like how this algorithm can be easily explained to anyone without much hassle. One quick example, I use very frequently to explain the working of random forests is the way a company has multiple rounds of interview to hire a candidate. Let me elaborate.</p>\n<p>Say, you appeared for the position of a Statistical Analyst at WalmartLabs. Now like most of the companies, you don\u2019t just have one round of interview. You have multiple rounds of interviews. Each one of these interviews is chaired by independent panels. Each panel assesses the candidate separately and independently. Generally, even the questions asked in these interviews differ from each other.\u00a0<strong>Randomness</strong>\u00a0is important here.</p>\n<p>The other thing of utmost importance is\u00a0<strong>diversity</strong>. The reason we have a panel of interviews is that we assume a committee of people generally takes better decision than a single individual. Now, this committee is not any collection of people. We make sure that the interview panel is a little diversified in terms of topics to be covered in each interview, the type of questions asked, and many other details. You don\u2019t go about asking the same question in each round of interviews.</p>\n<p>After having all the rounds of interviews, the final call whether to select or reject the candidate is based on the majority of the decision from each panel. If out of 5 panel of interviewers, 3 recommends a hire and two against a hire, we tend to go ahead with selecting the candidate. I hope you get the gist.</p>\n<p>If you have heard about the decision tree, then you are not very far from understanding what random forests are. There are two keywords here\u200a\u2014\u200arandom and forests. Let us first understand what forest means. Random forest is a collection of many decision trees. Instead of relying on a single decision tree, you build many decision trees say 100 of them. And you know what a collection of trees is called\u200a\u2014\u200aa forest. So you now understand why is it called a forest.</p>\n<p><strong>Why is it called random\u00a0then?</strong></p>\n<p>Say our dataset has 1,000 rows and 30 columns.</p>\n<p>There are two levels of randomness in this algorithm:</p>\n<ul>\n<li><strong>At row level</strong>: Each of these decision trees gets a random sample of the training data (say 10%) i.e. each of these trees will be trained independently on 100 randomly chosen rows out of 1,000 rows of data. Keep in mind that each of these decision trees is getting trained on 100 randomly chosen rows from the dataset i.e they are different from each other in terms of predictions.</li>\n<li><strong>At column level</strong>: The second level of randomness is introduced at the column level. Not all the columns are passed into training each of the decision trees. Say we want only 10% of columns to be sent to each tree. This means a randomly selected 3 column will be sent to each tree. So for the first decision tree, maybe column C1, C2, and C4 were chosen. The next DT will have C4, C5, C10 as chosen columns and so on.</li>\n</ul>\n<p>Let me draw an analogy now.</p>\n<p>Let us now understand how an interview selection process resembles a random forest algorithm. Each panel in the interview process is actually a decision tree. Each panel gives a result whether the candidate is a pass or fail and then a majority of these results is declared as final. Say there were 5 panels, 3 said yes and 2 said no. The final verdict will be yes.</p>\n<p>Something similar happens in the random forest as well. The results from each of the tree are taken and the final result is declared accordingly. Voting and averaging is used to predict in the case of classification and regression respectively.</p>\n<p>With the advent of huge computational power at our disposal, we hardly think for even a second before we apply random forests. And very conveniently our predictions are made. Let us try to understand other aspects of this algorithm.</p>\n<p><strong>When is a random forest a poor choice relative to other algorithms?</strong></p>\n<ol>\n<li><strong>Random forests don\u2019t train well on smaller datasets</strong>as it fails to pick on the pattern. To simplify, say we know that 1 pen costs INR 1, 2 pens cost INR 2, 3 pens cost INR 6. In this case, linear regression will easily estimate the cost of 4 pens but random forests will fail to come up with a good estimate.</li>\n<li><strong>There is a problem of interpretability with random forest.</strong>You can\u2019t see or understand the relationship between the response and the independent variables.\u00a0Understand that a random forest is a predictive tool and not a descriptive tool.\u00a0You get variable importance but this may not suffice in many analysis of interests where the objective might be to see the relationship between response and the independent features.</li>\n<li>The\u00a0<strong>time taken to train random forests</strong>may sometimes be too huge as you train multiple decision trees. Also, in the case of a categorical variable, the time complexity increases exponentially. For a categorical column with n levels, RF tries split at 2^n -1 points to find the maximal splitting point. However, with the power of H2O, we can now train random forests pretty fast. You may want to read about H2O at\u00a0<a href=\"http://manishbarnwal.com/blog/2017/03/28/h2o_with_r/\"><strong>H2O in R explained</strong></a>.</li>\n<li>In case of a regression problem,\u00a0<strong>the range of values response variable can take</strong>is determined by the values already available in the training dataset. Unlike linear regression, decision trees and hence random forest can\u2019t take values outside the training data.</li>\n</ol>\n<p><strong>What are the advantages of using random\u00a0forest?</strong></p>\n<ol>\n<li>Since we are using multiple decision trees,\u00a0<strong>the bias remains the same as that of a single decision tree</strong>. However, the variance decreases and thus we decrease the chances of overfitting. I have explained bias and variance intuitively at\u00a0<a href=\"http://manishbarnwal.com/blog/2017/02/08/the_curse_of_bias_and_variance/\"><strong>The curse of bias and variance</strong></a>.</li>\n<li>When all you care about is the predictions and\u00a0<strong>want a quick and dirty way-out</strong>, random forest comes to the rescue. You don\u2019t have to worry much about the assumptions of the model or linearity in the dataset.</li>\n</ol>\n<p>Did you find the article useful? If you did, share your thoughts in the comments. Share this post with people who you think would enjoy reading this. Let\u2019s talk more about data-science.</p>\n<p><b>Bio</b>: <a href=\"http://manishbarnwal.com/\">Manish Barnwal</a> is a Data Scientist at Zeta Global building recommendation engines for media publishing houses.</p>\n<p><a href=\"https://medium.com/theboredhuman/random-forests-explained-intuitively-2cecb9e1a7b5\">Original</a>. Reposted with permission.</p>\n<p><strong>Resources:</strong></p>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/education/online.html\">On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning education</a></li>\n<li><a href=\"https://www.kdnuggets.com/software/index.html\">Software for Analytics, Data Science, Data Mining, and Machine Learning</a></li>\n</ul>\n<p><b>Related:</b></p>\n<ul class=\"three_ul\">\n<li><a href=\"https://www.kdnuggets.com/2018/08/data-scientist-interviews-demystified.html\">Data Scientist Interviews Demystified</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/02/tour-top-10-algorithms-machine-learning-newbies.html\">A Tour of The Top 10 Algorithms for Machine Learning Newbies</a></li>\n<li><a href=\"https://www.kdnuggets.com/2018/02/introduction-python-ensembles.html\">Introduction to Python Ensembles</a></li>\n</ul>\n<p><a name=\"comments\"></a></p>\n<div id=\"disqus_thread\"></div>\n<p><script type=\"text/javascript\">\n var disqus_shortname = 'kdnuggets'; \n (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = 'https://kdnuggets.disqus.com/embed.js';\n (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })();\n </script></p>\n</div>"}